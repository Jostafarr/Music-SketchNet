{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "In this file we train SketchNet\n",
    "'''\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from SketchVAE.sketchvae import SketchVAE\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.distributions import Normal\n",
    "from SketchNet.sketchnet import SketchNet\n",
    "from utils.helpers import *\n",
    "import time\n",
    "###############################\n",
    "# initial parameters\n",
    "s_dir = \"\" # folder address\n",
    "zp_dims = 128\n",
    "zr_dims = 128\n",
    "pf_dims = 512\n",
    "gen_dims = 1024\n",
    "combine_dims = 512\n",
    "combine_head = 4\n",
    "combine_num = 4\n",
    "pf_num = 2\n",
    "inpaint_len = 4\n",
    "seq_len = 16\n",
    "total_len = 16\n",
    "batch_size = 32\n",
    "n_epochs = 15 \n",
    "save_path = \"model_backup\"\n",
    "save_period = 5 # save every 5 epochs\n",
    "data_path = [\n",
    "    \"data/irish-dis-measure-vae-train-whole.npy\",\n",
    "    \"data/irish-dis-measure-vae-validate-whole.npy\",\n",
    "    \"data/irish-dis-measure-vae-test-whole.npy\"\n",
    "]\n",
    "lr = 1e-4\n",
    "decay = 0.9999\n",
    "##############################\n",
    "##############  for vae init ##############\n",
    "vae_hidden_dims = 1024\n",
    "vae_zp_dims = 128\n",
    "vae_zr_dims = 128\n",
    "vae_beta = 0.1\n",
    "vae_input_dims = 130\n",
    "vae_pitch_dims = 129\n",
    "vae_rhythm_dims = 3\n",
    "vae_seq_len = 6 * 4\n",
    "vae_beat_num = 4\n",
    "vae_tick_num = 6\n",
    "############################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup schedule\n",
    "class CustomSchedule:\n",
    "    def __init__(self, d_model, warmup_steps=4000, optimizer=None):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.optimizer = optimizer\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "        self._step = 0\n",
    "        self._rate = 0\n",
    "\n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def rate(self, step=None):\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        arg1 = step ** (-0.5)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return self.d_model ** (-0.5) * min(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed data:\n",
      "processed finish! zeros: 256\n",
      "torch.Size([39798, 16, 24]) torch.Size([39798, 16, 24]) torch.Size([39798, 16, 24]) torch.Size([39798, 16]) torch.Size([39798, 16, 24, 3])\n",
      "processed data:\n",
      "processed finish! zeros: 1\n",
      "torch.Size([2927, 16, 24]) torch.Size([2927, 16, 24]) torch.Size([2927, 16, 24]) torch.Size([2927, 16]) torch.Size([2927, 16, 24, 3])\n",
      "91\n"
     ]
    }
   ],
   "source": [
    "# input data dis-measure-vae\n",
    "def processed_data_tensor(data):\n",
    "    print(\"processed data:\")\n",
    "    gd = [] \n",
    "    px = []\n",
    "    rx = []\n",
    "    len_x = []\n",
    "    nrx = []\n",
    "    total = 0\n",
    "    for i, d in enumerate(data):\n",
    "        gd.append([list(dd[0]) for dd in d])\n",
    "        px.append([list(dd[1]) for dd in d])\n",
    "        rx.append([list(dd[2]) for dd in d])\n",
    "        len_x.append([dd[3] for dd in d])\n",
    "        if len(gd[-1][-1]) != vae_seq_len:\n",
    "            gd[-1][-1].extend([128] * (vae_seq_len - len(gd[-1][-1])))\n",
    "            px[-1][-1].extend([128] * (vae_seq_len - len(px[-1][-1])))\n",
    "            rx[-1][-1].extend([2] * (vae_seq_len - len(rx[-1][-1])))\n",
    "    for i,d in enumerate(len_x):\n",
    "        for j,dd in enumerate(d):\n",
    "            if len_x[i][j] == 0:\n",
    "                gd[i][j][0] = 60\n",
    "                px[i][j][0] = 60\n",
    "                rx[i][j][0] = 1\n",
    "                len_x[i][j] = 1\n",
    "                total += 1\n",
    "    gd = np.array(gd)\n",
    "    px = np.array(px)\n",
    "    rx = np.array(rx)\n",
    "    len_x = np.array(len_x)\n",
    "    for d in rx:\n",
    "        nnrx = []\n",
    "        for dd in d:\n",
    "            temp = np.zeros((vae_seq_len, vae_rhythm_dims))\n",
    "            lins = np.arange(0, len(dd))\n",
    "            temp[lins, dd - 1] = 1\n",
    "            nnrx.append(temp)\n",
    "        nrx.append(nnrx)\n",
    "    nrx = np.array(nrx)\n",
    "    gd = torch.from_numpy(gd).long()\n",
    "    px = torch.from_numpy(px).long()\n",
    "    rx = torch.from_numpy(rx).float()\n",
    "    len_x = torch.from_numpy(len_x).long()\n",
    "    nrx = torch.from_numpy(nrx).float()\n",
    "    print(\"processed finish! zeros:\", total)\n",
    "    print(gd.size(),px.size(),rx.size(),len_x.size(),nrx.size())\n",
    "    return TensorDataset(px, rx, len_x, nrx, gd)\n",
    "\n",
    "train_set = np.load(os.path.join(s_dir,data_path[0]),allow_pickle = True)\n",
    "train_loader = DataLoader(\n",
    "    dataset = processed_data_tensor(train_set),\n",
    "    batch_size = batch_size, \n",
    "    shuffle = True, \n",
    "    num_workers = 8, \n",
    "    pin_memory = True, \n",
    "    drop_last = True\n",
    ")\n",
    "\n",
    "validate_set = np.load(os.path.join(s_dir,data_path[1]),allow_pickle = True)\n",
    "validate_loader = DataLoader(\n",
    "    dataset = processed_data_tensor(validate_set),\n",
    "    batch_size = batch_size, \n",
    "    shuffle = False, \n",
    "    num_workers = 8, \n",
    "    pin_memory = True, \n",
    "    drop_last = True\n",
    ")\n",
    "validate_data = []\n",
    "for i,d in enumerate(validate_loader):\n",
    "    validate_data.append(d)\n",
    "print(len(validate_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:  Tesla V100-SXM2-32GB\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# load VAE model\n",
    "vae_model = SketchVAE(\n",
    "    vae_input_dims, vae_pitch_dims, vae_rhythm_dims, vae_hidden_dims, \n",
    "    vae_zp_dims, vae_zr_dims, vae_seq_len, vae_beat_num, vae_tick_num, 4000)\n",
    "dic = torch.load(os.path.join(save_path, \"sketchvae-param.pt\"))\n",
    "\n",
    "for name in list(dic.keys()):\n",
    "    dic[name.replace('module.', '')] = dic.pop(name)\n",
    "vae_model.load_state_dict(dic)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('Using: ', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "    vae_model.cuda()\n",
    "else:\n",
    "    print('Using: CPU')\n",
    "vae_model.eval()\n",
    "print(vae_model.training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:  Tesla V100-SXM2-32GB\n",
      "SketchNet(\n",
      "  (past_p_gru): GRU(128, 512, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (past_r_gru): GRU(128, 512, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (future_p_gru): GRU(128, 512, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (future_r_gru): GRU(128, 512, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (gen_p_gru): GRU(128, 1024, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (gen_r_gru): GRU(128, 1024, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (gen_p_out): Linear(in_features=2048, out_features=128, bias=True)\n",
      "  (gen_r_out): Linear(in_features=2048, out_features=128, bias=True)\n",
      "  (combine_in): Linear(in_features=256, out_features=512, bias=True)\n",
      "  (combine_posenc): PositionalEncoding()\n",
      "  (combine_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (combine_nn): ModuleList(\n",
      "    (0): CombineLayer(\n",
      "      (slf_attn): MultiHeadAttention(\n",
      "        (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (fc): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (attention): ScaledDotProductAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (pos_ffn): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): CombineLayer(\n",
      "      (slf_attn): MultiHeadAttention(\n",
      "        (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (fc): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (attention): ScaledDotProductAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (pos_ffn): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (2): CombineLayer(\n",
      "      (slf_attn): MultiHeadAttention(\n",
      "        (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (fc): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (attention): ScaledDotProductAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (pos_ffn): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (3): CombineLayer(\n",
      "      (slf_attn): MultiHeadAttention(\n",
      "        (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (fc): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (attention): ScaledDotProductAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (pos_ffn): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (combine_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "  (combine_out): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (vae_model): SketchVAE(\n",
      "    (p_embedding): Embedding(130, 10)\n",
      "    (p_encoder_gru): GRU(10, 1024, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "    (p_linear_mu): Linear(in_features=4096, out_features=128, bias=True)\n",
      "    (p_linear_var): Linear(in_features=4096, out_features=128, bias=True)\n",
      "    (r_encoder_gru): GRU(3, 1024, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "    (r_linear_mu): Linear(in_features=4096, out_features=128, bias=True)\n",
      "    (r_linear_var): Linear(in_features=4096, out_features=128, bias=True)\n",
      "    (z_to_beat_hidden): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=2048, bias=True)\n",
      "      (1): SELU()\n",
      "    )\n",
      "    (beat_gru): GRU(1, 1024, num_layers=2, batch_first=True, dropout=0.2)\n",
      "    (beat_to_tick_hidden): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "      (1): SELU()\n",
      "    )\n",
      "    (beat_to_tick_input): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (1): SELU()\n",
      "    )\n",
      "    (d_embedding): Embedding(130, 10)\n",
      "    (tick_gru): GRU(1034, 1024, num_layers=2, batch_first=True, dropout=0.2)\n",
      "    (tick_to_note): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=130, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# import model\n",
    "\n",
    "# think about traning with mse\n",
    "model = SketchNet(\n",
    "    zp_dims, zr_dims, \n",
    "    pf_dims, gen_dims, combine_dims,\n",
    "    pf_num, combine_num, combine_head,\n",
    "    inpaint_len, total_len, \n",
    "    vae_model, True\n",
    ")\n",
    "# stage-1 traning result\n",
    "dic = torch.load(os.path.join(save_path,\"sketchnet-stage-1-param.pt\"))\n",
    "for name in list(dic.keys()):\n",
    "    dic[name.replace('module.', '')] = dic.pop(name)\n",
    "model.load_state_dict(dic)\n",
    "model.set_stage(\"sketch\")\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),lr=lr)\n",
    "scheduler = CustomSchedule(combine_dims, optimizer=optimizer)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('Using: ', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "    model.cuda()\n",
    "else:\n",
    "    print('Using: CPU')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "epoch: 0\n",
      "__________________________________________\n",
      "batch 0 loss: 4.49439 acc: 0.64323 | v_loss: 4.13550 v_acc: 0.66992 |  iteration: 1 teacher: 0 stage: sketch lr: 0.000000\n",
      "batch 1 loss: 3.69742 acc: 0.66829 | v_loss: 4.31203 v_acc: 0.66211 |  iteration: 2 teacher: 1 stage: sketch lr: 0.000000\n",
      "batch 2 loss: 4.13041 acc: 0.65397 | v_loss: 4.54849 v_acc: 0.63802 |  iteration: 3 teacher: 1 stage: sketch lr: 0.000001\n",
      "batch 3 loss: 4.00195 acc: 0.66276 | v_loss: 3.99588 v_acc: 0.66764 |  iteration: 4 teacher: 0 stage: sketch lr: 0.000001\n",
      "batch 4 loss: 4.04750 acc: 0.66374 | v_loss: 4.28190 v_acc: 0.65007 |  iteration: 5 teacher: 0 stage: sketch lr: 0.000001\n",
      "batch 5 loss: 4.52034 acc: 0.64453 | v_loss: 3.86095 v_acc: 0.66960 |  iteration: 6 teacher: 0 stage: sketch lr: 0.000001\n",
      "batch 6 loss: 4.10044 acc: 0.66536 | v_loss: 4.13147 v_acc: 0.65755 |  iteration: 7 teacher: 1 stage: sketch lr: 0.000001\n",
      "batch 7 loss: 4.41390 acc: 0.64095 | v_loss: 4.66618 v_acc: 0.63216 |  iteration: 8 teacher: 1 stage: sketch lr: 0.000001\n",
      "batch 8 loss: 4.22745 acc: 0.65723 | v_loss: 4.00725 v_acc: 0.66667 |  iteration: 9 teacher: 1 stage: sketch lr: 0.000002\n",
      "batch 9 loss: 3.95859 acc: 0.66243 | v_loss: 3.80520 v_acc: 0.66699 |  iteration: 10 teacher: 0 stage: sketch lr: 0.000002\n",
      "batch 10 loss: 4.20088 acc: 0.65137 | v_loss: 3.97802 v_acc: 0.65560 |  iteration: 11 teacher: 1 stage: sketch lr: 0.000002\n",
      "batch 11 loss: 3.97707 acc: 0.65462 | v_loss: 3.49861 v_acc: 0.67122 |  iteration: 12 teacher: 1 stage: sketch lr: 0.000002\n",
      "batch 12 loss: 4.11206 acc: 0.65267 | v_loss: 3.81519 v_acc: 0.66113 |  iteration: 13 teacher: 0 stage: sketch lr: 0.000002\n",
      "batch 13 loss: 3.66919 acc: 0.66536 | v_loss: 3.66353 v_acc: 0.66602 |  iteration: 14 teacher: 1 stage: sketch lr: 0.000002\n",
      "batch 14 loss: 4.13244 acc: 0.64746 | v_loss: 3.74689 v_acc: 0.66211 |  iteration: 15 teacher: 0 stage: sketch lr: 0.000003\n",
      "batch 15 loss: 3.76615 acc: 0.66504 | v_loss: 4.00000 v_acc: 0.64811 |  iteration: 16 teacher: 0 stage: sketch lr: 0.000003\n",
      "batch 16 loss: 3.91926 acc: 0.65072 | v_loss: 3.52475 v_acc: 0.66829 |  iteration: 17 teacher: 1 stage: sketch lr: 0.000003\n",
      "batch 17 loss: 3.77863 acc: 0.65788 | v_loss: 3.78698 v_acc: 0.65625 |  iteration: 18 teacher: 1 stage: sketch lr: 0.000003\n",
      "batch 18 loss: 4.03203 acc: 0.64616 | v_loss: 4.16456 v_acc: 0.63444 |  iteration: 19 teacher: 1 stage: sketch lr: 0.000003\n",
      "batch 19 loss: 3.85369 acc: 0.65039 | v_loss: 4.31346 v_acc: 0.62728 |  iteration: 20 teacher: 0 stage: sketch lr: 0.000003\n",
      "batch 20 loss: 3.80627 acc: 0.65658 | v_loss: 4.02014 v_acc: 0.63411 |  iteration: 21 teacher: 1 stage: sketch lr: 0.000004\n",
      "batch 21 loss: 3.73022 acc: 0.65690 | v_loss: 3.30445 v_acc: 0.66569 |  iteration: 22 teacher: 1 stage: sketch lr: 0.000004\n",
      "batch 22 loss: 3.28434 acc: 0.66797 | v_loss: 3.47033 v_acc: 0.64811 |  iteration: 23 teacher: 1 stage: sketch lr: 0.000004\n",
      "batch 23 loss: 3.54339 acc: 0.65332 | v_loss: 3.95051 v_acc: 0.64258 |  iteration: 24 teacher: 1 stage: sketch lr: 0.000004\n",
      "batch 24 loss: 3.60641 acc: 0.64714 | v_loss: 3.03951 v_acc: 0.66276 |  iteration: 25 teacher: 1 stage: sketch lr: 0.000004\n",
      "batch 25 loss: 3.51015 acc: 0.66178 | v_loss: 3.57256 v_acc: 0.64681 |  iteration: 26 teacher: 1 stage: sketch lr: 0.000005\n",
      "batch 26 loss: 3.58603 acc: 0.64681 | v_loss: 3.34049 v_acc: 0.65560 |  iteration: 27 teacher: 0 stage: sketch lr: 0.000005\n",
      "batch 27 loss: 3.32325 acc: 0.65983 | v_loss: 3.30871 v_acc: 0.65625 |  iteration: 28 teacher: 0 stage: sketch lr: 0.000005\n",
      "batch 28 loss: 3.36619 acc: 0.65234 | v_loss: 3.68939 v_acc: 0.63216 |  iteration: 29 teacher: 1 stage: sketch lr: 0.000005\n",
      "batch 29 loss: 3.58526 acc: 0.64974 | v_loss: 3.28226 v_acc: 0.64909 |  iteration: 30 teacher: 1 stage: sketch lr: 0.000005\n",
      "batch 30 loss: 3.38641 acc: 0.65072 | v_loss: 3.39688 v_acc: 0.63607 |  iteration: 31 teacher: 0 stage: sketch lr: 0.000005\n",
      "batch 31 loss: 3.25312 acc: 0.65527 | v_loss: 2.87837 v_acc: 0.66341 |  iteration: 32 teacher: 0 stage: sketch lr: 0.000006\n",
      "batch 32 loss: 2.82748 acc: 0.66960 | v_loss: 3.12372 v_acc: 0.65104 |  iteration: 33 teacher: 0 stage: sketch lr: 0.000006\n",
      "batch 33 loss: 2.87188 acc: 0.66341 | v_loss: 2.52003 v_acc: 0.66960 |  iteration: 34 teacher: 0 stage: sketch lr: 0.000006\n",
      "batch 34 loss: 3.07418 acc: 0.65104 | v_loss: 3.26331 v_acc: 0.63346 |  iteration: 35 teacher: 0 stage: sketch lr: 0.000006\n",
      "batch 35 loss: 2.81425 acc: 0.65983 | v_loss: 2.62005 v_acc: 0.65462 |  iteration: 36 teacher: 0 stage: sketch lr: 0.000006\n",
      "batch 36 loss: 3.03063 acc: 0.64453 | v_loss: 2.88544 v_acc: 0.64095 |  iteration: 37 teacher: 0 stage: sketch lr: 0.000006\n",
      "batch 37 loss: 2.79603 acc: 0.65397 | v_loss: 2.90019 v_acc: 0.63704 |  iteration: 38 teacher: 1 stage: sketch lr: 0.000007\n",
      "batch 38 loss: 2.62194 acc: 0.66667 | v_loss: 2.95553 v_acc: 0.62598 |  iteration: 39 teacher: 1 stage: sketch lr: 0.000007\n",
      "batch 39 loss: 2.64332 acc: 0.65007 | v_loss: 2.75070 v_acc: 0.63509 |  iteration: 40 teacher: 0 stage: sketch lr: 0.000007\n",
      "batch 40 loss: 2.47275 acc: 0.66504 | v_loss: 2.19953 v_acc: 0.66406 |  iteration: 41 teacher: 1 stage: sketch lr: 0.000007\n",
      "batch 41 loss: 2.47703 acc: 0.65625 | v_loss: 2.50283 v_acc: 0.64323 |  iteration: 42 teacher: 0 stage: sketch lr: 0.000007\n",
      "batch 42 loss: 2.61851 acc: 0.64746 | v_loss: 2.39523 v_acc: 0.64974 |  iteration: 43 teacher: 0 stage: sketch lr: 0.000008\n",
      "batch 43 loss: 2.81432 acc: 0.64128 | v_loss: 2.93537 v_acc: 0.61882 |  iteration: 44 teacher: 1 stage: sketch lr: 0.000008\n",
      "batch 44 loss: 2.43247 acc: 0.65690 | v_loss: 2.68641 v_acc: 0.63021 |  iteration: 45 teacher: 1 stage: sketch lr: 0.000008\n",
      "batch 45 loss: 2.53587 acc: 0.64844 | v_loss: 2.00833 v_acc: 0.66504 |  iteration: 46 teacher: 1 stage: sketch lr: 0.000008\n",
      "batch 46 loss: 2.45383 acc: 0.64290 | v_loss: 2.39418 v_acc: 0.64160 |  iteration: 47 teacher: 1 stage: sketch lr: 0.000008\n",
      "batch 47 loss: 2.38225 acc: 0.65560 | v_loss: 2.10928 v_acc: 0.65658 |  iteration: 48 teacher: 1 stage: sketch lr: 0.000008\n",
      "batch 48 loss: 2.34195 acc: 0.64974 | v_loss: 2.47084 v_acc: 0.63281 |  iteration: 49 teacher: 1 stage: sketch lr: 0.000009\n",
      "batch 49 loss: 2.42151 acc: 0.64486 | v_loss: 2.11640 v_acc: 0.65462 |  iteration: 50 teacher: 0 stage: sketch lr: 0.000009\n",
      "batch 50 loss: 2.00750 acc: 0.66829 | v_loss: 1.94540 v_acc: 0.66276 |  iteration: 51 teacher: 0 stage: sketch lr: 0.000009\n",
      "batch 51 loss: 2.22548 acc: 0.66016 | v_loss: 1.86065 v_acc: 0.66927 |  iteration: 52 teacher: 1 stage: sketch lr: 0.000009\n",
      "batch 52 loss: 2.45337 acc: 0.64421 | v_loss: 2.03064 v_acc: 0.66243 |  iteration: 53 teacher: 0 stage: sketch lr: 0.000009\n",
      "batch 53 loss: 2.33299 acc: 0.65983 | v_loss: 2.07729 v_acc: 0.65690 |  iteration: 54 teacher: 1 stage: sketch lr: 0.000009\n",
      "batch 54 loss: 2.14387 acc: 0.65885 | v_loss: 2.04909 v_acc: 0.65723 |  iteration: 55 teacher: 0 stage: sketch lr: 0.000010\n",
      "batch 55 loss: 2.18956 acc: 0.65039 | v_loss: 1.88752 v_acc: 0.66536 |  iteration: 56 teacher: 0 stage: sketch lr: 0.000010\n",
      "batch 56 loss: 2.33729 acc: 0.64355 | v_loss: 1.98815 v_acc: 0.65788 |  iteration: 57 teacher: 0 stage: sketch lr: 0.000010\n",
      "batch 57 loss: 2.30495 acc: 0.64648 | v_loss: 2.16651 v_acc: 0.64714 |  iteration: 58 teacher: 0 stage: sketch lr: 0.000010\n",
      "batch 58 loss: 2.00088 acc: 0.66504 | v_loss: 2.26862 v_acc: 0.64128 |  iteration: 59 teacher: 0 stage: sketch lr: 0.000010\n",
      "batch 59 loss: 1.94239 acc: 0.66243 | v_loss: 1.91878 v_acc: 0.65918 |  iteration: 60 teacher: 0 stage: sketch lr: 0.000010\n",
      "batch 60 loss: 2.03155 acc: 0.65560 | v_loss: 1.70656 v_acc: 0.67122 |  iteration: 61 teacher: 0 stage: sketch lr: 0.000011\n",
      "batch 61 loss: 2.18560 acc: 0.64941 | v_loss: 1.73896 v_acc: 0.67188 |  iteration: 62 teacher: 1 stage: sketch lr: 0.000011\n",
      "batch 62 loss: 2.03697 acc: 0.65918 | v_loss: 1.74986 v_acc: 0.66992 |  iteration: 63 teacher: 1 stage: sketch lr: 0.000011\n",
      "batch 63 loss: 2.32273 acc: 0.64225 | v_loss: 2.14650 v_acc: 0.64388 |  iteration: 64 teacher: 1 stage: sketch lr: 0.000011\n",
      "batch 64 loss: 1.97023 acc: 0.66081 | v_loss: 2.01625 v_acc: 0.65137 |  iteration: 65 teacher: 1 stage: sketch lr: 0.000011\n",
      "batch 65 loss: 2.05629 acc: 0.65495 | v_loss: 2.14532 v_acc: 0.64681 |  iteration: 66 teacher: 0 stage: sketch lr: 0.000012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 66 loss: 2.02520 acc: 0.65658 | v_loss: 2.51530 v_acc: 0.62370 |  iteration: 67 teacher: 1 stage: sketch lr: 0.000012\n",
      "batch 67 loss: 2.14753 acc: 0.64779 | v_loss: 2.27943 v_acc: 0.63835 |  iteration: 68 teacher: 0 stage: sketch lr: 0.000012\n",
      "batch 68 loss: 2.43286 acc: 0.63444 | v_loss: 1.87237 v_acc: 0.67415 |  iteration: 69 teacher: 1 stage: sketch lr: 0.000012\n",
      "batch 69 loss: 2.10046 acc: 0.65462 | v_loss: 1.91073 v_acc: 0.66927 |  iteration: 70 teacher: 1 stage: sketch lr: 0.000012\n",
      "batch 70 loss: 1.88043 acc: 0.66862 | v_loss: 1.76721 v_acc: 0.67513 |  iteration: 71 teacher: 0 stage: sketch lr: 0.000012\n",
      "batch 71 loss: 2.08845 acc: 0.65430 | v_loss: 1.90802 v_acc: 0.66569 |  iteration: 72 teacher: 0 stage: sketch lr: 0.000013\n",
      "batch 72 loss: 1.87090 acc: 0.66992 | v_loss: 1.90982 v_acc: 0.67350 |  iteration: 73 teacher: 0 stage: sketch lr: 0.000013\n",
      "batch 73 loss: 1.98974 acc: 0.66211 | v_loss: 1.81301 v_acc: 0.67546 |  iteration: 74 teacher: 1 stage: sketch lr: 0.000013\n",
      "batch 74 loss: 2.03511 acc: 0.65788 | v_loss: 1.83857 v_acc: 0.68262 |  iteration: 75 teacher: 1 stage: sketch lr: 0.000013\n",
      "batch 75 loss: 2.11188 acc: 0.65430 | v_loss: 1.93988 v_acc: 0.66602 |  iteration: 76 teacher: 1 stage: sketch lr: 0.000013\n",
      "batch 76 loss: 1.92634 acc: 0.66471 | v_loss: 1.78980 v_acc: 0.66764 |  iteration: 77 teacher: 0 stage: sketch lr: 0.000013\n",
      "batch 77 loss: 2.15655 acc: 0.64811 | v_loss: 1.65186 v_acc: 0.68522 |  iteration: 78 teacher: 0 stage: sketch lr: 0.000014\n",
      "batch 78 loss: 1.79626 acc: 0.67643 | v_loss: 1.93006 v_acc: 0.65885 |  iteration: 79 teacher: 0 stage: sketch lr: 0.000014\n",
      "batch 79 loss: 1.87283 acc: 0.67480 | v_loss: 1.72002 v_acc: 0.68229 |  iteration: 80 teacher: 0 stage: sketch lr: 0.000014\n",
      "batch 80 loss: 1.90483 acc: 0.66829 | v_loss: 1.74476 v_acc: 0.68717 |  iteration: 81 teacher: 0 stage: sketch lr: 0.000014\n",
      "batch 81 loss: 1.99872 acc: 0.66309 | v_loss: 1.85884 v_acc: 0.67513 |  iteration: 82 teacher: 0 stage: sketch lr: 0.000014\n",
      "batch 82 loss: 1.82059 acc: 0.67480 | v_loss: 1.96105 v_acc: 0.67155 |  iteration: 83 teacher: 1 stage: sketch lr: 0.000014\n",
      "batch 83 loss: 1.87855 acc: 0.67285 | v_loss: 1.63430 v_acc: 0.70964 |  iteration: 84 teacher: 1 stage: sketch lr: 0.000015\n",
      "batch 84 loss: 1.91941 acc: 0.67448 | v_loss: 1.94320 v_acc: 0.68815 |  iteration: 85 teacher: 1 stage: sketch lr: 0.000015\n",
      "batch 85 loss: 1.92283 acc: 0.67188 | v_loss: 1.79858 v_acc: 0.67806 |  iteration: 86 teacher: 1 stage: sketch lr: 0.000015\n",
      "batch 86 loss: 1.89638 acc: 0.67643 | v_loss: 1.77259 v_acc: 0.67969 |  iteration: 87 teacher: 0 stage: sketch lr: 0.000015\n",
      "batch 87 loss: 1.91874 acc: 0.67383 | v_loss: 1.68294 v_acc: 0.68424 |  iteration: 88 teacher: 0 stage: sketch lr: 0.000015\n",
      "batch 88 loss: 1.77434 acc: 0.67936 | v_loss: 1.77761 v_acc: 0.67676 |  iteration: 89 teacher: 0 stage: sketch lr: 0.000016\n",
      "batch 89 loss: 1.83030 acc: 0.67578 | v_loss: 1.82247 v_acc: 0.67220 |  iteration: 90 teacher: 0 stage: sketch lr: 0.000016\n",
      "batch 90 loss: 1.87944 acc: 0.67025 | v_loss: 1.83058 v_acc: 0.67839 |  iteration: 91 teacher: 0 stage: sketch lr: 0.000016\n",
      "batch 91 loss: 1.77241 acc: 0.67741 | v_loss: 1.72363 v_acc: 0.68066 |  iteration: 92 teacher: 0 stage: sketch lr: 0.000016\n",
      "batch 92 loss: 2.00128 acc: 0.66471 | v_loss: 1.73488 v_acc: 0.67936 |  iteration: 93 teacher: 1 stage: sketch lr: 0.000016\n",
      "batch 93 loss: 1.87446 acc: 0.67350 | v_loss: 1.84228 v_acc: 0.68880 |  iteration: 94 teacher: 0 stage: sketch lr: 0.000016\n",
      "batch 94 loss: 1.84209 acc: 0.66927 | v_loss: 1.66799 v_acc: 0.69206 |  iteration: 95 teacher: 0 stage: sketch lr: 0.000017\n",
      "batch 95 loss: 1.78925 acc: 0.68587 | v_loss: 1.68864 v_acc: 0.69694 |  iteration: 96 teacher: 0 stage: sketch lr: 0.000017\n",
      "batch 96 loss: 1.87062 acc: 0.67285 | v_loss: 1.69331 v_acc: 0.68359 |  iteration: 97 teacher: 1 stage: sketch lr: 0.000017\n",
      "batch 97 loss: 1.85724 acc: 0.67741 | v_loss: 1.77266 v_acc: 0.68424 |  iteration: 98 teacher: 0 stage: sketch lr: 0.000017\n",
      "batch 98 loss: 1.71083 acc: 0.68587 | v_loss: 2.09978 v_acc: 0.66276 |  iteration: 99 teacher: 0 stage: sketch lr: 0.000017\n",
      "batch 99 loss: 1.86941 acc: 0.68164 | v_loss: 1.68306 v_acc: 0.69010 |  iteration: 100 teacher: 0 stage: sketch lr: 0.000017\n",
      "batch 100 loss: 1.97061 acc: 0.67220 | v_loss: 1.69721 v_acc: 0.69076 |  iteration: 101 teacher: 1 stage: sketch lr: 0.000018\n",
      "batch 101 loss: 1.92762 acc: 0.66960 | v_loss: 1.68499 v_acc: 0.69141 |  iteration: 102 teacher: 0 stage: sketch lr: 0.000018\n",
      "batch 102 loss: 1.67628 acc: 0.69792 | v_loss: 1.67246 v_acc: 0.68717 |  iteration: 103 teacher: 1 stage: sketch lr: 0.000018\n",
      "batch 103 loss: 1.79968 acc: 0.69010 | v_loss: 1.52186 v_acc: 0.71615 |  iteration: 104 teacher: 0 stage: sketch lr: 0.000018\n",
      "batch 104 loss: 1.76148 acc: 0.68717 | v_loss: 1.61137 v_acc: 0.70247 |  iteration: 105 teacher: 0 stage: sketch lr: 0.000018\n",
      "batch 105 loss: 1.74151 acc: 0.69108 | v_loss: 1.68993 v_acc: 0.68327 |  iteration: 106 teacher: 0 stage: sketch lr: 0.000019\n",
      "batch 106 loss: 1.91662 acc: 0.67188 | v_loss: 1.61568 v_acc: 0.70117 |  iteration: 107 teacher: 1 stage: sketch lr: 0.000019\n",
      "batch 107 loss: 1.74746 acc: 0.69043 | v_loss: 1.69021 v_acc: 0.69987 |  iteration: 108 teacher: 1 stage: sketch lr: 0.000019\n",
      "batch 108 loss: 1.87459 acc: 0.67415 | v_loss: 1.62307 v_acc: 0.69792 |  iteration: 109 teacher: 1 stage: sketch lr: 0.000019\n",
      "batch 109 loss: 1.75825 acc: 0.67936 | v_loss: 1.60898 v_acc: 0.70768 |  iteration: 110 teacher: 1 stage: sketch lr: 0.000019\n",
      "batch 110 loss: 1.69646 acc: 0.69466 | v_loss: 1.77462 v_acc: 0.68815 |  iteration: 111 teacher: 1 stage: sketch lr: 0.000019\n",
      "batch 111 loss: 1.69417 acc: 0.68880 | v_loss: 1.65410 v_acc: 0.70801 |  iteration: 112 teacher: 0 stage: sketch lr: 0.000020\n",
      "batch 112 loss: 1.87617 acc: 0.68294 | v_loss: 1.50158 v_acc: 0.72526 |  iteration: 113 teacher: 1 stage: sketch lr: 0.000020\n",
      "batch 113 loss: 1.84430 acc: 0.67806 | v_loss: 1.73523 v_acc: 0.69043 |  iteration: 114 teacher: 0 stage: sketch lr: 0.000020\n",
      "batch 114 loss: 1.77767 acc: 0.69141 | v_loss: 1.78125 v_acc: 0.68197 |  iteration: 115 teacher: 1 stage: sketch lr: 0.000020\n",
      "batch 115 loss: 1.76040 acc: 0.68620 | v_loss: 1.74781 v_acc: 0.68587 |  iteration: 116 teacher: 0 stage: sketch lr: 0.000020\n",
      "batch 116 loss: 1.84029 acc: 0.68620 | v_loss: 1.67416 v_acc: 0.69076 |  iteration: 117 teacher: 1 stage: sketch lr: 0.000020\n",
      "batch 117 loss: 1.70152 acc: 0.69336 | v_loss: 1.81228 v_acc: 0.68099 |  iteration: 118 teacher: 0 stage: sketch lr: 0.000021\n",
      "batch 118 loss: 1.78107 acc: 0.68620 | v_loss: 1.63964 v_acc: 0.70052 |  iteration: 119 teacher: 1 stage: sketch lr: 0.000021\n",
      "batch 119 loss: 1.80056 acc: 0.68294 | v_loss: 1.82232 v_acc: 0.68132 |  iteration: 120 teacher: 0 stage: sketch lr: 0.000021\n",
      "batch 120 loss: 1.77323 acc: 0.68392 | v_loss: 1.62314 v_acc: 0.69954 |  iteration: 121 teacher: 1 stage: sketch lr: 0.000021\n",
      "batch 121 loss: 1.70143 acc: 0.68913 | v_loss: 1.62321 v_acc: 0.70866 |  iteration: 122 teacher: 1 stage: sketch lr: 0.000021\n",
      "batch 122 loss: 1.74360 acc: 0.69564 | v_loss: 1.66479 v_acc: 0.69434 |  iteration: 123 teacher: 0 stage: sketch lr: 0.000021\n",
      "batch 123 loss: 1.78351 acc: 0.68848 | v_loss: 1.77821 v_acc: 0.68685 |  iteration: 124 teacher: 1 stage: sketch lr: 0.000022\n",
      "batch 124 loss: 1.71161 acc: 0.68848 | v_loss: 1.61384 v_acc: 0.69434 |  iteration: 125 teacher: 1 stage: sketch lr: 0.000022\n",
      "batch 125 loss: 1.67172 acc: 0.69466 | v_loss: 1.89726 v_acc: 0.67448 |  iteration: 126 teacher: 0 stage: sketch lr: 0.000022\n",
      "batch 126 loss: 1.70084 acc: 0.69238 | v_loss: 1.62397 v_acc: 0.70801 |  iteration: 127 teacher: 0 stage: sketch lr: 0.000022\n",
      "batch 127 loss: 1.76608 acc: 0.68880 | v_loss: 1.91188 v_acc: 0.66895 |  iteration: 128 teacher: 0 stage: sketch lr: 0.000022\n",
      "batch 128 loss: 1.72393 acc: 0.69759 | v_loss: 1.89218 v_acc: 0.67936 |  iteration: 129 teacher: 1 stage: sketch lr: 0.000023\n",
      "batch 129 loss: 1.70806 acc: 0.69401 | v_loss: 1.78250 v_acc: 0.68783 |  iteration: 130 teacher: 0 stage: sketch lr: 0.000023\n",
      "batch 130 loss: 1.81774 acc: 0.68424 | v_loss: 1.70055 v_acc: 0.69076 |  iteration: 131 teacher: 0 stage: sketch lr: 0.000023\n",
      "batch 131 loss: 1.75285 acc: 0.68620 | v_loss: 1.59745 v_acc: 0.70182 |  iteration: 132 teacher: 0 stage: sketch lr: 0.000023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 132 loss: 1.68741 acc: 0.69531 | v_loss: 1.73943 v_acc: 0.69173 |  iteration: 133 teacher: 0 stage: sketch lr: 0.000023\n",
      "batch 133 loss: 1.73576 acc: 0.68685 | v_loss: 1.60544 v_acc: 0.70964 |  iteration: 134 teacher: 1 stage: sketch lr: 0.000023\n",
      "batch 134 loss: 1.74398 acc: 0.69434 | v_loss: 1.96239 v_acc: 0.67350 |  iteration: 135 teacher: 1 stage: sketch lr: 0.000024\n",
      "batch 135 loss: 1.69067 acc: 0.69759 | v_loss: 1.74712 v_acc: 0.69889 |  iteration: 136 teacher: 1 stage: sketch lr: 0.000024\n",
      "batch 136 loss: 1.78759 acc: 0.69303 | v_loss: 1.58373 v_acc: 0.70703 |  iteration: 137 teacher: 1 stage: sketch lr: 0.000024\n",
      "batch 137 loss: 1.66339 acc: 0.69694 | v_loss: 1.74571 v_acc: 0.69857 |  iteration: 138 teacher: 1 stage: sketch lr: 0.000024\n",
      "batch 138 loss: 1.65795 acc: 0.69792 | v_loss: 1.66773 v_acc: 0.69141 |  iteration: 139 teacher: 0 stage: sketch lr: 0.000024\n",
      "batch 139 loss: 1.67570 acc: 0.68913 | v_loss: 1.74753 v_acc: 0.68783 |  iteration: 140 teacher: 0 stage: sketch lr: 0.000024\n",
      "batch 140 loss: 1.71910 acc: 0.69466 | v_loss: 1.62310 v_acc: 0.71094 |  iteration: 141 teacher: 1 stage: sketch lr: 0.000025\n",
      "batch 141 loss: 1.82579 acc: 0.68685 | v_loss: 1.53943 v_acc: 0.71484 |  iteration: 142 teacher: 1 stage: sketch lr: 0.000025\n",
      "batch 142 loss: 1.68786 acc: 0.69303 | v_loss: 1.53522 v_acc: 0.71419 |  iteration: 143 teacher: 1 stage: sketch lr: 0.000025\n",
      "batch 143 loss: 1.67801 acc: 0.70410 | v_loss: 1.61453 v_acc: 0.70801 |  iteration: 144 teacher: 1 stage: sketch lr: 0.000025\n",
      "batch 144 loss: 1.89070 acc: 0.68327 | v_loss: 1.70149 v_acc: 0.69499 |  iteration: 145 teacher: 1 stage: sketch lr: 0.000025\n",
      "batch 145 loss: 1.69382 acc: 0.69824 | v_loss: 1.65660 v_acc: 0.69629 |  iteration: 146 teacher: 0 stage: sketch lr: 0.000026\n",
      "batch 146 loss: 1.84305 acc: 0.67773 | v_loss: 1.60296 v_acc: 0.70671 |  iteration: 147 teacher: 0 stage: sketch lr: 0.000026\n",
      "batch 147 loss: 1.65681 acc: 0.70475 | v_loss: 1.59591 v_acc: 0.72005 |  iteration: 148 teacher: 1 stage: sketch lr: 0.000026\n",
      "batch 148 loss: 1.68238 acc: 0.69954 | v_loss: 1.71845 v_acc: 0.69043 |  iteration: 149 teacher: 1 stage: sketch lr: 0.000026\n",
      "batch 149 loss: 1.78507 acc: 0.69629 | v_loss: 1.61536 v_acc: 0.71712 |  iteration: 150 teacher: 0 stage: sketch lr: 0.000026\n",
      "batch 150 loss: 1.72727 acc: 0.69303 | v_loss: 1.58281 v_acc: 0.70768 |  iteration: 151 teacher: 1 stage: sketch lr: 0.000026\n",
      "batch 151 loss: 1.63559 acc: 0.70247 | v_loss: 1.49397 v_acc: 0.71908 |  iteration: 152 teacher: 0 stage: sketch lr: 0.000027\n",
      "batch 152 loss: 1.77090 acc: 0.69173 | v_loss: 1.51919 v_acc: 0.71289 |  iteration: 153 teacher: 1 stage: sketch lr: 0.000027\n",
      "batch 153 loss: 1.69850 acc: 0.69727 | v_loss: 1.57616 v_acc: 0.69824 |  iteration: 154 teacher: 1 stage: sketch lr: 0.000027\n",
      "batch 154 loss: 1.62733 acc: 0.70410 | v_loss: 1.68907 v_acc: 0.69434 |  iteration: 155 teacher: 1 stage: sketch lr: 0.000027\n",
      "batch 155 loss: 1.67110 acc: 0.69727 | v_loss: 1.66189 v_acc: 0.70312 |  iteration: 156 teacher: 0 stage: sketch lr: 0.000027\n",
      "batch 156 loss: 1.66901 acc: 0.69173 | v_loss: 1.86710 v_acc: 0.68197 |  iteration: 157 teacher: 0 stage: sketch lr: 0.000027\n",
      "batch 157 loss: 1.59027 acc: 0.70768 | v_loss: 1.93027 v_acc: 0.68457 |  iteration: 158 teacher: 0 stage: sketch lr: 0.000028\n",
      "batch 158 loss: 1.62429 acc: 0.70443 | v_loss: 1.78475 v_acc: 0.68913 |  iteration: 159 teacher: 1 stage: sketch lr: 0.000028\n",
      "batch 159 loss: 1.67867 acc: 0.69954 | v_loss: 1.58362 v_acc: 0.71549 |  iteration: 160 teacher: 1 stage: sketch lr: 0.000028\n",
      "batch 160 loss: 1.68280 acc: 0.70475 | v_loss: 1.67700 v_acc: 0.69759 |  iteration: 161 teacher: 1 stage: sketch lr: 0.000028\n",
      "batch 161 loss: 1.76976 acc: 0.68978 | v_loss: 1.55090 v_acc: 0.71387 |  iteration: 162 teacher: 1 stage: sketch lr: 0.000028\n",
      "batch 162 loss: 1.65190 acc: 0.70117 | v_loss: 1.68281 v_acc: 0.69466 |  iteration: 163 teacher: 0 stage: sketch lr: 0.000028\n",
      "batch 163 loss: 1.61426 acc: 0.70931 | v_loss: 1.62587 v_acc: 0.71224 |  iteration: 164 teacher: 0 stage: sketch lr: 0.000029\n",
      "batch 164 loss: 1.61590 acc: 0.70182 | v_loss: 1.54988 v_acc: 0.71908 |  iteration: 165 teacher: 0 stage: sketch lr: 0.000029\n",
      "batch 165 loss: 1.57358 acc: 0.71191 | v_loss: 1.58937 v_acc: 0.71061 |  iteration: 166 teacher: 1 stage: sketch lr: 0.000029\n",
      "batch 166 loss: 1.62557 acc: 0.70703 | v_loss: 1.63360 v_acc: 0.70540 |  iteration: 167 teacher: 0 stage: sketch lr: 0.000029\n",
      "batch 167 loss: 1.60385 acc: 0.71126 | v_loss: 1.57723 v_acc: 0.71875 |  iteration: 168 teacher: 0 stage: sketch lr: 0.000029\n",
      "batch 168 loss: 1.66709 acc: 0.69694 | v_loss: 1.53821 v_acc: 0.71322 |  iteration: 169 teacher: 0 stage: sketch lr: 0.000030\n",
      "batch 169 loss: 1.62127 acc: 0.70378 | v_loss: 1.70351 v_acc: 0.69401 |  iteration: 170 teacher: 1 stage: sketch lr: 0.000030\n",
      "batch 170 loss: 1.63453 acc: 0.70671 | v_loss: 1.58580 v_acc: 0.70345 |  iteration: 171 teacher: 0 stage: sketch lr: 0.000030\n",
      "batch 171 loss: 1.66157 acc: 0.70280 | v_loss: 1.61301 v_acc: 0.70638 |  iteration: 172 teacher: 1 stage: sketch lr: 0.000030\n",
      "batch 172 loss: 1.63020 acc: 0.70410 | v_loss: 1.70837 v_acc: 0.69173 |  iteration: 173 teacher: 1 stage: sketch lr: 0.000030\n",
      "batch 173 loss: 1.70360 acc: 0.69336 | v_loss: 1.77872 v_acc: 0.68783 |  iteration: 174 teacher: 0 stage: sketch lr: 0.000030\n",
      "batch 174 loss: 1.67622 acc: 0.70020 | v_loss: 1.49687 v_acc: 0.72754 |  iteration: 175 teacher: 1 stage: sketch lr: 0.000031\n",
      "batch 175 loss: 1.69050 acc: 0.69401 | v_loss: 1.73110 v_acc: 0.70410 |  iteration: 176 teacher: 0 stage: sketch lr: 0.000031\n",
      "batch 176 loss: 1.66670 acc: 0.69759 | v_loss: 1.66804 v_acc: 0.69010 |  iteration: 177 teacher: 1 stage: sketch lr: 0.000031\n",
      "batch 177 loss: 1.61467 acc: 0.70866 | v_loss: 1.66913 v_acc: 0.69336 |  iteration: 178 teacher: 0 stage: sketch lr: 0.000031\n",
      "batch 178 loss: 1.68937 acc: 0.69499 | v_loss: 1.57941 v_acc: 0.70312 |  iteration: 179 teacher: 1 stage: sketch lr: 0.000031\n",
      "batch 179 loss: 1.71085 acc: 0.70150 | v_loss: 1.66039 v_acc: 0.69629 |  iteration: 180 teacher: 1 stage: sketch lr: 0.000031\n",
      "batch 180 loss: 1.62950 acc: 0.70117 | v_loss: 1.70050 v_acc: 0.68913 |  iteration: 181 teacher: 0 stage: sketch lr: 0.000032\n",
      "batch 181 loss: 1.66635 acc: 0.69727 | v_loss: 1.65604 v_acc: 0.70085 |  iteration: 182 teacher: 1 stage: sketch lr: 0.000032\n",
      "batch 182 loss: 1.64312 acc: 0.70020 | v_loss: 1.61246 v_acc: 0.70215 |  iteration: 183 teacher: 1 stage: sketch lr: 0.000032\n",
      "batch 183 loss: 1.68259 acc: 0.69661 | v_loss: 1.59888 v_acc: 0.70573 |  iteration: 184 teacher: 1 stage: sketch lr: 0.000032\n",
      "batch 184 loss: 1.60736 acc: 0.70768 | v_loss: 1.64132 v_acc: 0.70540 |  iteration: 185 teacher: 1 stage: sketch lr: 0.000032\n",
      "batch 185 loss: 1.66383 acc: 0.69368 | v_loss: 1.57099 v_acc: 0.70801 |  iteration: 186 teacher: 0 stage: sketch lr: 0.000032\n",
      "batch 186 loss: 1.65174 acc: 0.70378 | v_loss: 1.56498 v_acc: 0.71842 |  iteration: 187 teacher: 0 stage: sketch lr: 0.000033\n",
      "batch 187 loss: 1.68048 acc: 0.70312 | v_loss: 1.61137 v_acc: 0.69596 |  iteration: 188 teacher: 1 stage: sketch lr: 0.000033\n",
      "batch 188 loss: 1.71405 acc: 0.69564 | v_loss: 1.63995 v_acc: 0.70117 |  iteration: 189 teacher: 1 stage: sketch lr: 0.000033\n",
      "batch 189 loss: 1.71070 acc: 0.69824 | v_loss: 1.85135 v_acc: 0.68132 |  iteration: 190 teacher: 1 stage: sketch lr: 0.000033\n",
      "batch 190 loss: 1.65304 acc: 0.70931 | v_loss: 1.58147 v_acc: 0.70703 |  iteration: 191 teacher: 0 stage: sketch lr: 0.000033\n",
      "batch 191 loss: 1.66445 acc: 0.70345 | v_loss: 1.64629 v_acc: 0.69271 |  iteration: 192 teacher: 0 stage: sketch lr: 0.000034\n",
      "batch 192 loss: 1.58967 acc: 0.71484 | v_loss: 1.59147 v_acc: 0.70671 |  iteration: 193 teacher: 0 stage: sketch lr: 0.000034\n",
      "batch 193 loss: 1.68187 acc: 0.69824 | v_loss: 1.60211 v_acc: 0.70085 |  iteration: 194 teacher: 1 stage: sketch lr: 0.000034\n",
      "batch 194 loss: 1.69554 acc: 0.69987 | v_loss: 1.43729 v_acc: 0.73438 |  iteration: 195 teacher: 1 stage: sketch lr: 0.000034\n",
      "batch 195 loss: 1.73075 acc: 0.69727 | v_loss: 1.53838 v_acc: 0.70898 |  iteration: 196 teacher: 1 stage: sketch lr: 0.000034\n",
      "batch 196 loss: 1.69730 acc: 0.69792 | v_loss: 1.62619 v_acc: 0.70345 |  iteration: 197 teacher: 1 stage: sketch lr: 0.000034\n",
      "batch 197 loss: 1.60589 acc: 0.70475 | v_loss: 1.56570 v_acc: 0.71191 |  iteration: 198 teacher: 0 stage: sketch lr: 0.000035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 198 loss: 1.68930 acc: 0.69531 | v_loss: 1.61775 v_acc: 0.70898 |  iteration: 199 teacher: 0 stage: sketch lr: 0.000035\n",
      "batch 199 loss: 1.67995 acc: 0.70182 | v_loss: 1.53933 v_acc: 0.71159 |  iteration: 200 teacher: 0 stage: sketch lr: 0.000035\n",
      "batch 200 loss: 1.63530 acc: 0.70150 | v_loss: 1.53781 v_acc: 0.71940 |  iteration: 201 teacher: 0 stage: sketch lr: 0.000035\n",
      "batch 201 loss: 1.64198 acc: 0.69434 | v_loss: 1.70539 v_acc: 0.69401 |  iteration: 202 teacher: 0 stage: sketch lr: 0.000035\n",
      "batch 202 loss: 1.66873 acc: 0.70312 | v_loss: 1.55474 v_acc: 0.72591 |  iteration: 203 teacher: 0 stage: sketch lr: 0.000035\n",
      "batch 203 loss: 1.76989 acc: 0.69010 | v_loss: 1.42286 v_acc: 0.73958 |  iteration: 204 teacher: 0 stage: sketch lr: 0.000036\n",
      "batch 204 loss: 1.86058 acc: 0.67773 | v_loss: 1.65751 v_acc: 0.70117 |  iteration: 205 teacher: 1 stage: sketch lr: 0.000036\n",
      "batch 205 loss: 1.69577 acc: 0.69889 | v_loss: 1.71593 v_acc: 0.69206 |  iteration: 206 teacher: 0 stage: sketch lr: 0.000036\n",
      "batch 206 loss: 1.69157 acc: 0.70117 | v_loss: 1.67975 v_acc: 0.69499 |  iteration: 207 teacher: 1 stage: sketch lr: 0.000036\n",
      "batch 207 loss: 1.59037 acc: 0.71094 | v_loss: 1.61284 v_acc: 0.70540 |  iteration: 208 teacher: 1 stage: sketch lr: 0.000036\n",
      "batch 208 loss: 1.60438 acc: 0.70703 | v_loss: 1.72220 v_acc: 0.69076 |  iteration: 209 teacher: 1 stage: sketch lr: 0.000037\n",
      "batch 209 loss: 1.62591 acc: 0.70215 | v_loss: 1.59019 v_acc: 0.70638 |  iteration: 210 teacher: 0 stage: sketch lr: 0.000037\n",
      "batch 210 loss: 1.69551 acc: 0.69238 | v_loss: 1.71622 v_acc: 0.69303 |  iteration: 211 teacher: 0 stage: sketch lr: 0.000037\n",
      "batch 211 loss: 1.71066 acc: 0.69629 | v_loss: 1.57423 v_acc: 0.71061 |  iteration: 212 teacher: 1 stage: sketch lr: 0.000037\n",
      "batch 212 loss: 1.60513 acc: 0.71094 | v_loss: 1.54506 v_acc: 0.71810 |  iteration: 213 teacher: 1 stage: sketch lr: 0.000037\n",
      "batch 213 loss: 1.70389 acc: 0.69238 | v_loss: 1.57411 v_acc: 0.71191 |  iteration: 214 teacher: 1 stage: sketch lr: 0.000037\n",
      "batch 214 loss: 1.66686 acc: 0.70117 | v_loss: 1.72704 v_acc: 0.69076 |  iteration: 215 teacher: 0 stage: sketch lr: 0.000038\n",
      "batch 215 loss: 1.63217 acc: 0.70052 | v_loss: 1.56956 v_acc: 0.70182 |  iteration: 216 teacher: 1 stage: sketch lr: 0.000038\n",
      "batch 216 loss: 1.64751 acc: 0.70215 | v_loss: 1.83918 v_acc: 0.67839 |  iteration: 217 teacher: 0 stage: sketch lr: 0.000038\n",
      "batch 217 loss: 1.61472 acc: 0.70703 | v_loss: 1.55554 v_acc: 0.71647 |  iteration: 218 teacher: 0 stage: sketch lr: 0.000038\n",
      "batch 218 loss: 1.63341 acc: 0.70573 | v_loss: 1.83789 v_acc: 0.67318 |  iteration: 219 teacher: 1 stage: sketch lr: 0.000038\n",
      "batch 219 loss: 1.63576 acc: 0.70215 | v_loss: 1.81081 v_acc: 0.68783 |  iteration: 220 teacher: 0 stage: sketch lr: 0.000038\n",
      "batch 220 loss: 1.72903 acc: 0.69173 | v_loss: 1.69989 v_acc: 0.69043 |  iteration: 221 teacher: 1 stage: sketch lr: 0.000039\n",
      "batch 221 loss: 1.63050 acc: 0.70671 | v_loss: 1.63268 v_acc: 0.69824 |  iteration: 222 teacher: 1 stage: sketch lr: 0.000039\n",
      "batch 222 loss: 1.71420 acc: 0.69531 | v_loss: 1.53608 v_acc: 0.71126 |  iteration: 223 teacher: 1 stage: sketch lr: 0.000039\n",
      "batch 223 loss: 1.68904 acc: 0.69824 | v_loss: 1.67779 v_acc: 0.69759 |  iteration: 224 teacher: 1 stage: sketch lr: 0.000039\n",
      "batch 224 loss: 1.59540 acc: 0.71159 | v_loss: 1.55495 v_acc: 0.71615 |  iteration: 225 teacher: 0 stage: sketch lr: 0.000039\n",
      "batch 225 loss: 1.65518 acc: 0.70117 | v_loss: 1.87815 v_acc: 0.67611 |  iteration: 226 teacher: 1 stage: sketch lr: 0.000039\n",
      "batch 226 loss: 1.63795 acc: 0.70508 | v_loss: 1.67009 v_acc: 0.70345 |  iteration: 227 teacher: 0 stage: sketch lr: 0.000040\n",
      "batch 227 loss: 1.74624 acc: 0.68880 | v_loss: 1.53318 v_acc: 0.71908 |  iteration: 228 teacher: 1 stage: sketch lr: 0.000040\n",
      "batch 228 loss: 1.64505 acc: 0.69824 | v_loss: 1.68086 v_acc: 0.70605 |  iteration: 229 teacher: 0 stage: sketch lr: 0.000040\n",
      "batch 229 loss: 1.72034 acc: 0.69401 | v_loss: 1.62004 v_acc: 0.70117 |  iteration: 230 teacher: 1 stage: sketch lr: 0.000040\n",
      "batch 230 loss: 1.60769 acc: 0.70833 | v_loss: 1.68397 v_acc: 0.69336 |  iteration: 231 teacher: 0 stage: sketch lr: 0.000040\n",
      "batch 231 loss: 1.63620 acc: 0.70345 | v_loss: 1.58997 v_acc: 0.71322 |  iteration: 232 teacher: 1 stage: sketch lr: 0.000041\n",
      "batch 232 loss: 1.62571 acc: 0.70671 | v_loss: 1.51233 v_acc: 0.71973 |  iteration: 233 teacher: 1 stage: sketch lr: 0.000041\n",
      "batch 233 loss: 1.63455 acc: 0.70931 | v_loss: 1.50549 v_acc: 0.71908 |  iteration: 234 teacher: 0 stage: sketch lr: 0.000041\n",
      "batch 234 loss: 1.70766 acc: 0.69661 | v_loss: 1.58919 v_acc: 0.70964 |  iteration: 235 teacher: 1 stage: sketch lr: 0.000041\n",
      "batch 235 loss: 1.65264 acc: 0.70052 | v_loss: 1.64709 v_acc: 0.70052 |  iteration: 236 teacher: 1 stage: sketch lr: 0.000041\n",
      "batch 236 loss: 1.72669 acc: 0.69043 | v_loss: 1.60447 v_acc: 0.70573 |  iteration: 237 teacher: 0 stage: sketch lr: 0.000041\n",
      "batch 237 loss: 1.62478 acc: 0.70280 | v_loss: 1.54047 v_acc: 0.71484 |  iteration: 238 teacher: 0 stage: sketch lr: 0.000042\n",
      "batch 238 loss: 1.56779 acc: 0.71387 | v_loss: 1.53450 v_acc: 0.72689 |  iteration: 239 teacher: 0 stage: sketch lr: 0.000042\n",
      "batch 239 loss: 1.63200 acc: 0.70768 | v_loss: 1.65492 v_acc: 0.69434 |  iteration: 240 teacher: 0 stage: sketch lr: 0.000042\n",
      "batch 240 loss: 1.56118 acc: 0.71322 | v_loss: 1.54481 v_acc: 0.72298 |  iteration: 241 teacher: 0 stage: sketch lr: 0.000042\n",
      "batch 241 loss: 1.67113 acc: 0.70182 | v_loss: 1.54045 v_acc: 0.71257 |  iteration: 242 teacher: 0 stage: sketch lr: 0.000042\n",
      "batch 242 loss: 1.66642 acc: 0.70801 | v_loss: 1.45657 v_acc: 0.72721 |  iteration: 243 teacher: 1 stage: sketch lr: 0.000042\n",
      "batch 243 loss: 1.59492 acc: 0.70833 | v_loss: 1.48500 v_acc: 0.71777 |  iteration: 244 teacher: 1 stage: sketch lr: 0.000043\n",
      "batch 244 loss: 1.63873 acc: 0.70508 | v_loss: 1.52825 v_acc: 0.70508 |  iteration: 245 teacher: 0 stage: sketch lr: 0.000043\n",
      "batch 245 loss: 1.61570 acc: 0.70215 | v_loss: 1.63388 v_acc: 0.70085 |  iteration: 246 teacher: 0 stage: sketch lr: 0.000043\n",
      "batch 246 loss: 1.65445 acc: 0.69889 | v_loss: 1.60479 v_acc: 0.70768 |  iteration: 247 teacher: 0 stage: sketch lr: 0.000043\n",
      "batch 247 loss: 1.62690 acc: 0.70378 | v_loss: 1.86223 v_acc: 0.68359 |  iteration: 248 teacher: 1 stage: sketch lr: 0.000043\n",
      "batch 248 loss: 1.61878 acc: 0.69727 | v_loss: 1.85310 v_acc: 0.69108 |  iteration: 249 teacher: 0 stage: sketch lr: 0.000043\n",
      "batch 249 loss: 1.64844 acc: 0.69499 | v_loss: 1.71743 v_acc: 0.69434 |  iteration: 250 teacher: 1 stage: sketch lr: 0.000044\n",
      "batch 250 loss: 1.63469 acc: 0.69987 | v_loss: 1.53386 v_acc: 0.72396 |  iteration: 251 teacher: 0 stage: sketch lr: 0.000044\n",
      "batch 251 loss: 1.64829 acc: 0.70443 | v_loss: 1.64846 v_acc: 0.70182 |  iteration: 252 teacher: 0 stage: sketch lr: 0.000044\n",
      "batch 252 loss: 1.66273 acc: 0.69727 | v_loss: 1.50007 v_acc: 0.72266 |  iteration: 253 teacher: 0 stage: sketch lr: 0.000044\n",
      "batch 253 loss: 1.55294 acc: 0.71680 | v_loss: 1.65328 v_acc: 0.69824 |  iteration: 254 teacher: 1 stage: sketch lr: 0.000044\n",
      "batch 254 loss: 1.61758 acc: 0.70247 | v_loss: 1.56910 v_acc: 0.72005 |  iteration: 255 teacher: 0 stage: sketch lr: 0.000045\n",
      "batch 255 loss: 1.61758 acc: 0.70280 | v_loss: 1.51476 v_acc: 0.72298 |  iteration: 256 teacher: 1 stage: sketch lr: 0.000045\n",
      "batch 256 loss: 1.67217 acc: 0.70280 | v_loss: 1.52851 v_acc: 0.71940 |  iteration: 257 teacher: 0 stage: sketch lr: 0.000045\n",
      "batch 257 loss: 1.65537 acc: 0.70020 | v_loss: 1.57057 v_acc: 0.71094 |  iteration: 258 teacher: 0 stage: sketch lr: 0.000045\n",
      "batch 258 loss: 1.74614 acc: 0.69857 | v_loss: 1.52405 v_acc: 0.72135 |  iteration: 259 teacher: 0 stage: sketch lr: 0.000045\n",
      "batch 259 loss: 1.64478 acc: 0.70833 | v_loss: 1.51162 v_acc: 0.71680 |  iteration: 260 teacher: 1 stage: sketch lr: 0.000045\n",
      "batch 260 loss: 1.58806 acc: 0.71224 | v_loss: 1.61627 v_acc: 0.70182 |  iteration: 261 teacher: 1 stage: sketch lr: 0.000046\n",
      "batch 261 loss: 1.60472 acc: 0.70247 | v_loss: 1.54219 v_acc: 0.71126 |  iteration: 262 teacher: 0 stage: sketch lr: 0.000046\n",
      "batch 262 loss: 1.66293 acc: 0.70215 | v_loss: 1.55778 v_acc: 0.71289 |  iteration: 263 teacher: 1 stage: sketch lr: 0.000046\n",
      "batch 263 loss: 1.56425 acc: 0.70866 | v_loss: 1.65102 v_acc: 0.69401 |  iteration: 264 teacher: 0 stage: sketch lr: 0.000046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 264 loss: 1.63861 acc: 0.69596 | v_loss: 1.74020 v_acc: 0.69238 |  iteration: 265 teacher: 0 stage: sketch lr: 0.000046\n",
      "batch 265 loss: 1.62612 acc: 0.69694 | v_loss: 1.46848 v_acc: 0.73210 |  iteration: 266 teacher: 0 stage: sketch lr: 0.000046\n",
      "batch 266 loss: 1.63437 acc: 0.70150 | v_loss: 1.67725 v_acc: 0.70573 |  iteration: 267 teacher: 1 stage: sketch lr: 0.000047\n",
      "batch 267 loss: 1.67626 acc: 0.69629 | v_loss: 1.60498 v_acc: 0.70020 |  iteration: 268 teacher: 1 stage: sketch lr: 0.000047\n",
      "batch 268 loss: 1.57342 acc: 0.70638 | v_loss: 1.62190 v_acc: 0.69954 |  iteration: 269 teacher: 1 stage: sketch lr: 0.000047\n",
      "batch 269 loss: 1.63595 acc: 0.69889 | v_loss: 1.54682 v_acc: 0.70638 |  iteration: 270 teacher: 0 stage: sketch lr: 0.000047\n",
      "batch 270 loss: 1.66021 acc: 0.70312 | v_loss: 1.62042 v_acc: 0.70508 |  iteration: 271 teacher: 0 stage: sketch lr: 0.000047\n",
      "batch 271 loss: 1.56787 acc: 0.71029 | v_loss: 1.68036 v_acc: 0.68717 |  iteration: 272 teacher: 0 stage: sketch lr: 0.000048\n",
      "batch 272 loss: 1.65242 acc: 0.69727 | v_loss: 1.57772 v_acc: 0.70768 |  iteration: 273 teacher: 0 stage: sketch lr: 0.000048\n",
      "batch 273 loss: 1.70015 acc: 0.69401 | v_loss: 1.55355 v_acc: 0.70964 |  iteration: 274 teacher: 1 stage: sketch lr: 0.000048\n",
      "batch 274 loss: 1.60848 acc: 0.70866 | v_loss: 1.57229 v_acc: 0.71094 |  iteration: 275 teacher: 1 stage: sketch lr: 0.000048\n",
      "batch 275 loss: 1.59864 acc: 0.70410 | v_loss: 1.58890 v_acc: 0.70866 |  iteration: 276 teacher: 0 stage: sketch lr: 0.000048\n",
      "batch 276 loss: 1.56730 acc: 0.70410 | v_loss: 1.49745 v_acc: 0.71452 |  iteration: 277 teacher: 1 stage: sketch lr: 0.000048\n",
      "batch 277 loss: 1.67125 acc: 0.70085 | v_loss: 1.51416 v_acc: 0.72233 |  iteration: 278 teacher: 1 stage: sketch lr: 0.000049\n",
      "batch 278 loss: 1.57550 acc: 0.71419 | v_loss: 1.55236 v_acc: 0.70345 |  iteration: 279 teacher: 1 stage: sketch lr: 0.000049\n",
      "batch 279 loss: 1.50935 acc: 0.72591 | v_loss: 1.57761 v_acc: 0.70703 |  iteration: 280 teacher: 0 stage: sketch lr: 0.000049\n",
      "batch 280 loss: 1.66281 acc: 0.69727 | v_loss: 1.78430 v_acc: 0.68457 |  iteration: 281 teacher: 1 stage: sketch lr: 0.000049\n",
      "batch 281 loss: 1.66290 acc: 0.70768 | v_loss: 1.52395 v_acc: 0.71159 |  iteration: 282 teacher: 0 stage: sketch lr: 0.000049\n",
      "batch 282 loss: 1.61361 acc: 0.70182 | v_loss: 1.60426 v_acc: 0.69303 |  iteration: 283 teacher: 0 stage: sketch lr: 0.000049\n",
      "batch 283 loss: 1.66607 acc: 0.69596 | v_loss: 1.53689 v_acc: 0.70964 |  iteration: 284 teacher: 1 stage: sketch lr: 0.000050\n",
      "batch 284 loss: 1.66658 acc: 0.69564 | v_loss: 1.53017 v_acc: 0.71094 |  iteration: 285 teacher: 1 stage: sketch lr: 0.000050\n",
      "batch 285 loss: 1.70843 acc: 0.69727 | v_loss: 1.41895 v_acc: 0.73568 |  iteration: 286 teacher: 0 stage: sketch lr: 0.000050\n",
      "batch 286 loss: 1.69925 acc: 0.69434 | v_loss: 1.49617 v_acc: 0.71322 |  iteration: 287 teacher: 1 stage: sketch lr: 0.000050\n",
      "batch 287 loss: 1.58081 acc: 0.70703 | v_loss: 1.60009 v_acc: 0.70605 |  iteration: 288 teacher: 1 stage: sketch lr: 0.000050\n",
      "batch 288 loss: 1.62183 acc: 0.70833 | v_loss: 1.51512 v_acc: 0.72005 |  iteration: 289 teacher: 0 stage: sketch lr: 0.000050\n",
      "batch 289 loss: 1.62117 acc: 0.70736 | v_loss: 1.56348 v_acc: 0.71549 |  iteration: 290 teacher: 0 stage: sketch lr: 0.000051\n",
      "batch 290 loss: 1.65929 acc: 0.70020 | v_loss: 1.49139 v_acc: 0.71908 |  iteration: 291 teacher: 1 stage: sketch lr: 0.000051\n",
      "batch 291 loss: 1.57574 acc: 0.71419 | v_loss: 1.49935 v_acc: 0.72168 |  iteration: 292 teacher: 0 stage: sketch lr: 0.000051\n",
      "batch 292 loss: 1.60876 acc: 0.70540 | v_loss: 1.62249 v_acc: 0.69759 |  iteration: 293 teacher: 1 stage: sketch lr: 0.000051\n",
      "batch 293 loss: 1.65220 acc: 0.70117 | v_loss: 1.49275 v_acc: 0.73079 |  iteration: 294 teacher: 0 stage: sketch lr: 0.000051\n",
      "batch 294 loss: 1.68682 acc: 0.69824 | v_loss: 1.36987 v_acc: 0.74772 |  iteration: 295 teacher: 0 stage: sketch lr: 0.000052\n",
      "batch 295 loss: 1.61421 acc: 0.70475 | v_loss: 1.59750 v_acc: 0.70736 |  iteration: 296 teacher: 1 stage: sketch lr: 0.000052\n",
      "batch 296 loss: 1.53228 acc: 0.71419 | v_loss: 1.67302 v_acc: 0.69889 |  iteration: 297 teacher: 0 stage: sketch lr: 0.000052\n",
      "batch 297 loss: 1.68521 acc: 0.69499 | v_loss: 1.61430 v_acc: 0.69727 |  iteration: 298 teacher: 1 stage: sketch lr: 0.000052\n",
      "batch 298 loss: 1.64876 acc: 0.69694 | v_loss: 1.53470 v_acc: 0.70996 |  iteration: 299 teacher: 1 stage: sketch lr: 0.000052\n",
      "batch 299 loss: 1.63563 acc: 0.70638 | v_loss: 1.66841 v_acc: 0.69401 |  iteration: 300 teacher: 1 stage: sketch lr: 0.000052\n",
      "batch 300 loss: 1.63116 acc: 0.69922 | v_loss: 1.54186 v_acc: 0.71094 |  iteration: 301 teacher: 0 stage: sketch lr: 0.000053\n",
      "batch 301 loss: 1.52712 acc: 0.71257 | v_loss: 1.65249 v_acc: 0.69727 |  iteration: 302 teacher: 0 stage: sketch lr: 0.000053\n",
      "batch 302 loss: 1.55156 acc: 0.71484 | v_loss: 1.55886 v_acc: 0.71387 |  iteration: 303 teacher: 0 stage: sketch lr: 0.000053\n",
      "batch 303 loss: 1.60616 acc: 0.70378 | v_loss: 1.50435 v_acc: 0.72103 |  iteration: 304 teacher: 0 stage: sketch lr: 0.000053\n",
      "batch 304 loss: 1.60619 acc: 0.70508 | v_loss: 1.55262 v_acc: 0.71680 |  iteration: 305 teacher: 0 stage: sketch lr: 0.000053\n",
      "batch 305 loss: 1.62426 acc: 0.70540 | v_loss: 1.61222 v_acc: 0.70410 |  iteration: 306 teacher: 0 stage: sketch lr: 0.000053\n",
      "batch 306 loss: 1.57917 acc: 0.71061 | v_loss: 1.54051 v_acc: 0.70540 |  iteration: 307 teacher: 0 stage: sketch lr: 0.000054\n",
      "batch 307 loss: 1.70665 acc: 0.69238 | v_loss: 1.77636 v_acc: 0.68522 |  iteration: 308 teacher: 1 stage: sketch lr: 0.000054\n",
      "batch 308 loss: 1.55319 acc: 0.70931 | v_loss: 1.51810 v_acc: 0.71940 |  iteration: 309 teacher: 1 stage: sketch lr: 0.000054\n",
      "batch 309 loss: 1.63123 acc: 0.70964 | v_loss: 1.77771 v_acc: 0.68424 |  iteration: 310 teacher: 1 stage: sketch lr: 0.000054\n",
      "batch 310 loss: 1.59850 acc: 0.70768 | v_loss: 1.71659 v_acc: 0.69922 |  iteration: 311 teacher: 1 stage: sketch lr: 0.000054\n",
      "batch 311 loss: 1.52441 acc: 0.72070 | v_loss: 1.66399 v_acc: 0.69303 |  iteration: 312 teacher: 0 stage: sketch lr: 0.000055\n",
      "batch 312 loss: 1.54926 acc: 0.71777 | v_loss: 1.54428 v_acc: 0.70508 |  iteration: 313 teacher: 0 stage: sketch lr: 0.000055\n",
      "batch 313 loss: 1.55785 acc: 0.71191 | v_loss: 1.48808 v_acc: 0.71647 |  iteration: 314 teacher: 1 stage: sketch lr: 0.000055\n",
      "batch 314 loss: 1.55950 acc: 0.70801 | v_loss: 1.61745 v_acc: 0.70052 |  iteration: 315 teacher: 1 stage: sketch lr: 0.000055\n",
      "batch 315 loss: 1.51668 acc: 0.71810 | v_loss: 1.50349 v_acc: 0.72135 |  iteration: 316 teacher: 0 stage: sketch lr: 0.000055\n",
      "batch 316 loss: 1.52378 acc: 0.72070 | v_loss: 1.82721 v_acc: 0.67741 |  iteration: 317 teacher: 0 stage: sketch lr: 0.000055\n",
      "batch 317 loss: 1.54313 acc: 0.72103 | v_loss: 1.59350 v_acc: 0.70768 |  iteration: 318 teacher: 0 stage: sketch lr: 0.000056\n",
      "batch 318 loss: 1.59787 acc: 0.70378 | v_loss: 1.51415 v_acc: 0.71745 |  iteration: 319 teacher: 0 stage: sketch lr: 0.000056\n",
      "batch 319 loss: 1.75215 acc: 0.68880 | v_loss: 1.60893 v_acc: 0.71322 |  iteration: 320 teacher: 0 stage: sketch lr: 0.000056\n",
      "batch 320 loss: 1.59544 acc: 0.70150 | v_loss: 1.58341 v_acc: 0.70215 |  iteration: 321 teacher: 0 stage: sketch lr: 0.000056\n",
      "batch 321 loss: 1.62176 acc: 0.70801 | v_loss: 1.63305 v_acc: 0.69857 |  iteration: 322 teacher: 1 stage: sketch lr: 0.000056\n",
      "batch 322 loss: 1.64293 acc: 0.70020 | v_loss: 1.56079 v_acc: 0.71615 |  iteration: 323 teacher: 1 stage: sketch lr: 0.000056\n",
      "batch 323 loss: 1.63751 acc: 0.70768 | v_loss: 1.47803 v_acc: 0.72201 |  iteration: 324 teacher: 0 stage: sketch lr: 0.000057\n",
      "batch 324 loss: 1.56307 acc: 0.71549 | v_loss: 1.46842 v_acc: 0.72689 |  iteration: 325 teacher: 1 stage: sketch lr: 0.000057\n",
      "batch 325 loss: 1.57869 acc: 0.70736 | v_loss: 1.55484 v_acc: 0.71224 |  iteration: 326 teacher: 0 stage: sketch lr: 0.000057\n",
      "batch 326 loss: 1.61001 acc: 0.70312 | v_loss: 1.60269 v_acc: 0.70345 |  iteration: 327 teacher: 0 stage: sketch lr: 0.000057\n",
      "batch 327 loss: 1.63709 acc: 0.69922 | v_loss: 1.56881 v_acc: 0.70964 |  iteration: 328 teacher: 0 stage: sketch lr: 0.000057\n",
      "batch 328 loss: 1.59798 acc: 0.70996 | v_loss: 1.51235 v_acc: 0.71973 |  iteration: 329 teacher: 1 stage: sketch lr: 0.000057\n",
      "batch 329 loss: 1.60113 acc: 0.70898 | v_loss: 1.49577 v_acc: 0.73079 |  iteration: 330 teacher: 0 stage: sketch lr: 0.000058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 330 loss: 1.51834 acc: 0.71777 | v_loss: 1.60294 v_acc: 0.69661 |  iteration: 331 teacher: 0 stage: sketch lr: 0.000058\n",
      "batch 331 loss: 1.64155 acc: 0.70280 | v_loss: 1.47392 v_acc: 0.73079 |  iteration: 332 teacher: 0 stage: sketch lr: 0.000058\n",
      "batch 332 loss: 1.58767 acc: 0.70443 | v_loss: 1.49363 v_acc: 0.71777 |  iteration: 333 teacher: 1 stage: sketch lr: 0.000058\n",
      "batch 333 loss: 1.67123 acc: 0.69792 | v_loss: 1.45701 v_acc: 0.72656 |  iteration: 334 teacher: 1 stage: sketch lr: 0.000058\n",
      "batch 334 loss: 1.56857 acc: 0.71159 | v_loss: 1.44871 v_acc: 0.72396 |  iteration: 335 teacher: 1 stage: sketch lr: 0.000059\n",
      "batch 335 loss: 1.57910 acc: 0.70443 | v_loss: 1.48413 v_acc: 0.70801 |  iteration: 336 teacher: 0 stage: sketch lr: 0.000059\n",
      "batch 336 loss: 1.55748 acc: 0.71452 | v_loss: 1.60559 v_acc: 0.70280 |  iteration: 337 teacher: 1 stage: sketch lr: 0.000059\n",
      "batch 337 loss: 1.56971 acc: 0.70833 | v_loss: 1.56528 v_acc: 0.71126 |  iteration: 338 teacher: 1 stage: sketch lr: 0.000059\n",
      "batch 338 loss: 1.60711 acc: 0.70508 | v_loss: 1.80106 v_acc: 0.69010 |  iteration: 339 teacher: 1 stage: sketch lr: 0.000059\n",
      "batch 339 loss: 1.56838 acc: 0.70801 | v_loss: 1.75209 v_acc: 0.69596 |  iteration: 340 teacher: 0 stage: sketch lr: 0.000059\n",
      "batch 340 loss: 1.59218 acc: 0.70638 | v_loss: 1.67072 v_acc: 0.70052 |  iteration: 341 teacher: 0 stage: sketch lr: 0.000060\n",
      "batch 341 loss: 1.65537 acc: 0.70020 | v_loss: 1.47579 v_acc: 0.72982 |  iteration: 342 teacher: 1 stage: sketch lr: 0.000060\n",
      "batch 342 loss: 1.57783 acc: 0.70964 | v_loss: 1.62093 v_acc: 0.70638 |  iteration: 343 teacher: 0 stage: sketch lr: 0.000060\n",
      "batch 343 loss: 1.60814 acc: 0.69922 | v_loss: 1.45373 v_acc: 0.72493 |  iteration: 344 teacher: 1 stage: sketch lr: 0.000060\n",
      "batch 344 loss: 1.66600 acc: 0.69661 | v_loss: 1.61855 v_acc: 0.69987 |  iteration: 345 teacher: 1 stage: sketch lr: 0.000060\n",
      "batch 345 loss: 1.63160 acc: 0.70247 | v_loss: 1.55431 v_acc: 0.72493 |  iteration: 346 teacher: 1 stage: sketch lr: 0.000060\n",
      "batch 346 loss: 1.53521 acc: 0.71777 | v_loss: 1.49347 v_acc: 0.72526 |  iteration: 347 teacher: 1 stage: sketch lr: 0.000061\n",
      "batch 347 loss: 1.61684 acc: 0.70540 | v_loss: 1.49093 v_acc: 0.72428 |  iteration: 348 teacher: 0 stage: sketch lr: 0.000061\n",
      "batch 348 loss: 1.53903 acc: 0.71126 | v_loss: 1.52385 v_acc: 0.71712 |  iteration: 349 teacher: 1 stage: sketch lr: 0.000061\n",
      "batch 349 loss: 1.55308 acc: 0.71224 | v_loss: 1.48881 v_acc: 0.72396 |  iteration: 350 teacher: 1 stage: sketch lr: 0.000061\n",
      "batch 350 loss: 1.63957 acc: 0.70410 | v_loss: 1.49990 v_acc: 0.71842 |  iteration: 351 teacher: 0 stage: sketch lr: 0.000061\n",
      "batch 351 loss: 1.52939 acc: 0.72038 | v_loss: 1.56615 v_acc: 0.70182 |  iteration: 352 teacher: 1 stage: sketch lr: 0.000061\n",
      "batch 352 loss: 1.60523 acc: 0.70443 | v_loss: 1.51854 v_acc: 0.71647 |  iteration: 353 teacher: 0 stage: sketch lr: 0.000062\n",
      "batch 353 loss: 1.55663 acc: 0.70866 | v_loss: 1.54371 v_acc: 0.71452 |  iteration: 354 teacher: 1 stage: sketch lr: 0.000062\n",
      "batch 354 loss: 1.54599 acc: 0.71387 | v_loss: 1.61397 v_acc: 0.69629 |  iteration: 355 teacher: 0 stage: sketch lr: 0.000062\n",
      "batch 355 loss: 1.69767 acc: 0.69857 | v_loss: 1.69472 v_acc: 0.70117 |  iteration: 356 teacher: 1 stage: sketch lr: 0.000062\n",
      "batch 356 loss: 1.54300 acc: 0.71582 | v_loss: 1.45911 v_acc: 0.73633 |  iteration: 357 teacher: 0 stage: sketch lr: 0.000062\n",
      "batch 357 loss: 1.57873 acc: 0.70768 | v_loss: 1.61706 v_acc: 0.71094 |  iteration: 358 teacher: 1 stage: sketch lr: 0.000063\n",
      "batch 358 loss: 1.51096 acc: 0.71842 | v_loss: 1.56136 v_acc: 0.70443 |  iteration: 359 teacher: 0 stage: sketch lr: 0.000063\n",
      "batch 359 loss: 1.66330 acc: 0.70150 | v_loss: 1.59496 v_acc: 0.70443 |  iteration: 360 teacher: 0 stage: sketch lr: 0.000063\n",
      "batch 360 loss: 1.64446 acc: 0.70638 | v_loss: 1.56112 v_acc: 0.70964 |  iteration: 361 teacher: 0 stage: sketch lr: 0.000063\n",
      "batch 361 loss: 1.60743 acc: 0.70638 | v_loss: 1.61276 v_acc: 0.70573 |  iteration: 362 teacher: 0 stage: sketch lr: 0.000063\n",
      "batch 362 loss: 1.61569 acc: 0.70085 | v_loss: 1.67317 v_acc: 0.68945 |  iteration: 363 teacher: 1 stage: sketch lr: 0.000063\n",
      "batch 363 loss: 1.54024 acc: 0.71810 | v_loss: 1.55466 v_acc: 0.71191 |  iteration: 364 teacher: 0 stage: sketch lr: 0.000064\n",
      "batch 364 loss: 1.56109 acc: 0.70996 | v_loss: 1.50943 v_acc: 0.72135 |  iteration: 365 teacher: 0 stage: sketch lr: 0.000064\n",
      "batch 365 loss: 1.54855 acc: 0.71582 | v_loss: 1.54827 v_acc: 0.71419 |  iteration: 366 teacher: 0 stage: sketch lr: 0.000064\n",
      "batch 366 loss: 1.57830 acc: 0.70540 | v_loss: 1.53326 v_acc: 0.71647 |  iteration: 367 teacher: 0 stage: sketch lr: 0.000064\n",
      "batch 367 loss: 1.59359 acc: 0.70801 | v_loss: 1.46722 v_acc: 0.71842 |  iteration: 368 teacher: 0 stage: sketch lr: 0.000064\n",
      "batch 368 loss: 1.59380 acc: 0.71387 | v_loss: 1.47708 v_acc: 0.72754 |  iteration: 369 teacher: 0 stage: sketch lr: 0.000064\n",
      "batch 369 loss: 1.62223 acc: 0.70508 | v_loss: 1.53079 v_acc: 0.70964 |  iteration: 370 teacher: 0 stage: sketch lr: 0.000065\n",
      "batch 370 loss: 1.57775 acc: 0.71159 | v_loss: 1.54830 v_acc: 0.71029 |  iteration: 371 teacher: 0 stage: sketch lr: 0.000065\n",
      "batch 371 loss: 1.55570 acc: 0.70866 | v_loss: 1.68909 v_acc: 0.69824 |  iteration: 372 teacher: 0 stage: sketch lr: 0.000065\n",
      "batch 372 loss: 1.55893 acc: 0.70833 | v_loss: 1.53594 v_acc: 0.71061 |  iteration: 373 teacher: 1 stage: sketch lr: 0.000065\n",
      "batch 373 loss: 1.59333 acc: 0.70768 | v_loss: 1.63810 v_acc: 0.69889 |  iteration: 374 teacher: 1 stage: sketch lr: 0.000065\n",
      "batch 374 loss: 1.56506 acc: 0.70898 | v_loss: 1.52467 v_acc: 0.71419 |  iteration: 375 teacher: 1 stage: sketch lr: 0.000066\n",
      "batch 375 loss: 1.57700 acc: 0.71126 | v_loss: 1.52471 v_acc: 0.71615 |  iteration: 376 teacher: 0 stage: sketch lr: 0.000066\n",
      "batch 376 loss: 1.58366 acc: 0.71257 | v_loss: 1.39626 v_acc: 0.74089 |  iteration: 377 teacher: 1 stage: sketch lr: 0.000066\n",
      "batch 377 loss: 1.61083 acc: 0.70768 | v_loss: 1.48013 v_acc: 0.71973 |  iteration: 378 teacher: 1 stage: sketch lr: 0.000066\n",
      "batch 378 loss: 1.58723 acc: 0.71289 | v_loss: 1.51627 v_acc: 0.71322 |  iteration: 379 teacher: 1 stage: sketch lr: 0.000066\n",
      "batch 379 loss: 1.77289 acc: 0.69564 | v_loss: 1.49747 v_acc: 0.72363 |  iteration: 380 teacher: 1 stage: sketch lr: 0.000066\n",
      "batch 380 loss: 1.54458 acc: 0.71322 | v_loss: 1.54472 v_acc: 0.71810 |  iteration: 381 teacher: 0 stage: sketch lr: 0.000067\n",
      "batch 381 loss: 1.50346 acc: 0.72233 | v_loss: 1.47140 v_acc: 0.72266 |  iteration: 382 teacher: 1 stage: sketch lr: 0.000067\n",
      "batch 382 loss: 1.63501 acc: 0.70020 | v_loss: 1.49275 v_acc: 0.72266 |  iteration: 383 teacher: 0 stage: sketch lr: 0.000067\n",
      "batch 383 loss: 1.55856 acc: 0.70996 | v_loss: 1.60285 v_acc: 0.70703 |  iteration: 384 teacher: 0 stage: sketch lr: 0.000067\n",
      "batch 384 loss: 1.53055 acc: 0.72201 | v_loss: 1.48688 v_acc: 0.72917 |  iteration: 385 teacher: 0 stage: sketch lr: 0.000067\n",
      "batch 385 loss: 1.62770 acc: 0.70182 | v_loss: 1.33919 v_acc: 0.74642 |  iteration: 386 teacher: 0 stage: sketch lr: 0.000067\n",
      "batch 386 loss: 1.56915 acc: 0.71387 | v_loss: 1.58938 v_acc: 0.70671 |  iteration: 387 teacher: 1 stage: sketch lr: 0.000068\n",
      "batch 387 loss: 1.54124 acc: 0.71680 | v_loss: 1.60990 v_acc: 0.70833 |  iteration: 388 teacher: 1 stage: sketch lr: 0.000068\n",
      "batch 388 loss: 1.59591 acc: 0.70345 | v_loss: 1.58039 v_acc: 0.70573 |  iteration: 389 teacher: 1 stage: sketch lr: 0.000068\n",
      "batch 389 loss: 1.57065 acc: 0.71517 | v_loss: 1.49962 v_acc: 0.72070 |  iteration: 390 teacher: 1 stage: sketch lr: 0.000068\n",
      "batch 390 loss: 1.64130 acc: 0.69889 | v_loss: 1.63493 v_acc: 0.70150 |  iteration: 391 teacher: 1 stage: sketch lr: 0.000068\n",
      "batch 391 loss: 1.56201 acc: 0.71061 | v_loss: 1.51007 v_acc: 0.71452 |  iteration: 392 teacher: 0 stage: sketch lr: 0.000068\n",
      "batch 392 loss: 1.52575 acc: 0.72331 | v_loss: 1.64281 v_acc: 0.70020 |  iteration: 393 teacher: 0 stage: sketch lr: 0.000069\n",
      "batch 393 loss: 1.53950 acc: 0.71322 | v_loss: 1.55874 v_acc: 0.71582 |  iteration: 394 teacher: 0 stage: sketch lr: 0.000069\n",
      "batch 394 loss: 1.67724 acc: 0.70052 | v_loss: 1.47810 v_acc: 0.72624 |  iteration: 395 teacher: 1 stage: sketch lr: 0.000069\n",
      "batch 395 loss: 1.50557 acc: 0.71908 | v_loss: 1.51258 v_acc: 0.71908 |  iteration: 396 teacher: 0 stage: sketch lr: 0.000069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 396 loss: 1.54574 acc: 0.71615 | v_loss: 1.58672 v_acc: 0.70833 |  iteration: 397 teacher: 0 stage: sketch lr: 0.000069\n",
      "batch 397 loss: 1.58203 acc: 0.70996 | v_loss: 1.53546 v_acc: 0.71029 |  iteration: 398 teacher: 1 stage: sketch lr: 0.000070\n",
      "batch 398 loss: 1.58683 acc: 0.70736 | v_loss: 1.71783 v_acc: 0.69271 |  iteration: 399 teacher: 1 stage: sketch lr: 0.000070\n",
      "batch 399 loss: 1.51323 acc: 0.71712 | v_loss: 1.50502 v_acc: 0.72331 |  iteration: 400 teacher: 0 stage: sketch lr: 0.000070\n",
      "batch 400 loss: 1.52087 acc: 0.72038 | v_loss: 1.71213 v_acc: 0.69629 |  iteration: 401 teacher: 0 stage: sketch lr: 0.000070\n",
      "batch 401 loss: 1.55464 acc: 0.71322 | v_loss: 1.65235 v_acc: 0.71061 |  iteration: 402 teacher: 1 stage: sketch lr: 0.000070\n",
      "batch 402 loss: 1.57110 acc: 0.71615 | v_loss: 1.66256 v_acc: 0.69596 |  iteration: 403 teacher: 0 stage: sketch lr: 0.000070\n",
      "batch 403 loss: 1.55061 acc: 0.72852 | v_loss: 1.54942 v_acc: 0.70671 |  iteration: 404 teacher: 1 stage: sketch lr: 0.000071\n",
      "batch 404 loss: 1.57660 acc: 0.71908 | v_loss: 1.49954 v_acc: 0.71647 |  iteration: 405 teacher: 1 stage: sketch lr: 0.000071\n",
      "batch 405 loss: 1.57764 acc: 0.71549 | v_loss: 1.61153 v_acc: 0.70052 |  iteration: 406 teacher: 1 stage: sketch lr: 0.000071\n",
      "batch 406 loss: 1.52507 acc: 0.71908 | v_loss: 1.51099 v_acc: 0.72233 |  iteration: 407 teacher: 0 stage: sketch lr: 0.000071\n",
      "batch 407 loss: 1.66372 acc: 0.69466 | v_loss: 1.80045 v_acc: 0.68587 |  iteration: 408 teacher: 1 stage: sketch lr: 0.000071\n",
      "batch 408 loss: 1.56855 acc: 0.71777 | v_loss: 1.57817 v_acc: 0.70964 |  iteration: 409 teacher: 0 stage: sketch lr: 0.000071\n",
      "batch 409 loss: 1.56607 acc: 0.71615 | v_loss: 1.49657 v_acc: 0.72591 |  iteration: 410 teacher: 1 stage: sketch lr: 0.000072\n",
      "batch 410 loss: 1.56429 acc: 0.71126 | v_loss: 1.57009 v_acc: 0.71842 |  iteration: 411 teacher: 1 stage: sketch lr: 0.000072\n",
      "batch 411 loss: 1.60242 acc: 0.70996 | v_loss: 1.55947 v_acc: 0.71224 |  iteration: 412 teacher: 1 stage: sketch lr: 0.000072\n",
      "batch 412 loss: 1.60523 acc: 0.71159 | v_loss: 1.61772 v_acc: 0.69922 |  iteration: 413 teacher: 0 stage: sketch lr: 0.000072\n",
      "batch 413 loss: 1.50354 acc: 0.71452 | v_loss: 1.52621 v_acc: 0.72168 |  iteration: 414 teacher: 1 stage: sketch lr: 0.000072\n",
      "batch 414 loss: 1.59893 acc: 0.70150 | v_loss: 1.44299 v_acc: 0.72689 |  iteration: 415 teacher: 1 stage: sketch lr: 0.000072\n",
      "batch 415 loss: 1.55840 acc: 0.71224 | v_loss: 1.43478 v_acc: 0.73438 |  iteration: 416 teacher: 0 stage: sketch lr: 0.000073\n",
      "batch 416 loss: 1.54040 acc: 0.71029 | v_loss: 1.53938 v_acc: 0.71745 |  iteration: 417 teacher: 0 stage: sketch lr: 0.000073\n",
      "batch 417 loss: 1.56064 acc: 0.70964 | v_loss: 1.60189 v_acc: 0.70573 |  iteration: 418 teacher: 0 stage: sketch lr: 0.000073\n",
      "batch 418 loss: 1.56397 acc: 0.71387 | v_loss: 1.55554 v_acc: 0.71126 |  iteration: 419 teacher: 1 stage: sketch lr: 0.000073\n",
      "batch 419 loss: 1.56921 acc: 0.71029 | v_loss: 1.50998 v_acc: 0.71973 |  iteration: 420 teacher: 1 stage: sketch lr: 0.000073\n",
      "batch 420 loss: 1.59700 acc: 0.70996 | v_loss: 1.51078 v_acc: 0.72917 |  iteration: 421 teacher: 0 stage: sketch lr: 0.000074\n",
      "batch 421 loss: 1.63606 acc: 0.69824 | v_loss: 1.60903 v_acc: 0.70182 |  iteration: 422 teacher: 0 stage: sketch lr: 0.000074\n",
      "batch 422 loss: 1.64248 acc: 0.69987 | v_loss: 1.46398 v_acc: 0.73796 |  iteration: 423 teacher: 0 stage: sketch lr: 0.000074\n",
      "batch 423 loss: 1.53132 acc: 0.71875 | v_loss: 1.47993 v_acc: 0.72428 |  iteration: 424 teacher: 0 stage: sketch lr: 0.000074\n",
      "batch 424 loss: 1.61852 acc: 0.70150 | v_loss: 1.43431 v_acc: 0.73438 |  iteration: 425 teacher: 0 stage: sketch lr: 0.000074\n",
      "batch 425 loss: 1.49138 acc: 0.72461 | v_loss: 1.44507 v_acc: 0.73014 |  iteration: 426 teacher: 1 stage: sketch lr: 0.000074\n",
      "batch 426 loss: 1.53943 acc: 0.71354 | v_loss: 1.45738 v_acc: 0.71777 |  iteration: 427 teacher: 1 stage: sketch lr: 0.000075\n",
      "batch 427 loss: 1.59099 acc: 0.70964 | v_loss: 1.60830 v_acc: 0.70475 |  iteration: 428 teacher: 1 stage: sketch lr: 0.000075\n",
      "batch 428 loss: 1.62121 acc: 0.70736 | v_loss: 1.53599 v_acc: 0.71549 |  iteration: 429 teacher: 1 stage: sketch lr: 0.000075\n",
      "batch 429 loss: 1.55541 acc: 0.71549 | v_loss: 1.71173 v_acc: 0.70378 |  iteration: 430 teacher: 0 stage: sketch lr: 0.000075\n",
      "batch 430 loss: 1.55571 acc: 0.70996 | v_loss: 1.67488 v_acc: 0.71159 |  iteration: 431 teacher: 0 stage: sketch lr: 0.000075\n",
      "batch 431 loss: 1.57015 acc: 0.71419 | v_loss: 1.65894 v_acc: 0.70703 |  iteration: 432 teacher: 0 stage: sketch lr: 0.000075\n",
      "batch 432 loss: 1.49553 acc: 0.72233 | v_loss: 1.46036 v_acc: 0.73568 |  iteration: 433 teacher: 1 stage: sketch lr: 0.000076\n",
      "batch 433 loss: 1.67338 acc: 0.70117 | v_loss: 1.62152 v_acc: 0.71094 |  iteration: 434 teacher: 1 stage: sketch lr: 0.000076\n",
      "batch 434 loss: 1.59750 acc: 0.70638 | v_loss: 1.43880 v_acc: 0.72949 |  iteration: 435 teacher: 0 stage: sketch lr: 0.000076\n",
      "batch 435 loss: 1.55338 acc: 0.71777 | v_loss: 1.60505 v_acc: 0.70443 |  iteration: 436 teacher: 1 stage: sketch lr: 0.000076\n",
      "batch 436 loss: 1.52535 acc: 0.71712 | v_loss: 1.52265 v_acc: 0.72493 |  iteration: 437 teacher: 1 stage: sketch lr: 0.000076\n",
      "batch 437 loss: 1.70272 acc: 0.70182 | v_loss: 1.47534 v_acc: 0.72624 |  iteration: 438 teacher: 1 stage: sketch lr: 0.000077\n",
      "batch 438 loss: 1.63199 acc: 0.70345 | v_loss: 1.47943 v_acc: 0.73014 |  iteration: 439 teacher: 1 stage: sketch lr: 0.000077\n",
      "batch 439 loss: 1.54297 acc: 0.71257 | v_loss: 1.52943 v_acc: 0.71452 |  iteration: 440 teacher: 0 stage: sketch lr: 0.000077\n",
      "batch 440 loss: 1.55249 acc: 0.71452 | v_loss: 1.45930 v_acc: 0.72949 |  iteration: 441 teacher: 0 stage: sketch lr: 0.000077\n",
      "batch 441 loss: 1.50830 acc: 0.71940 | v_loss: 1.48481 v_acc: 0.71940 |  iteration: 442 teacher: 0 stage: sketch lr: 0.000077\n",
      "batch 442 loss: 1.56559 acc: 0.71257 | v_loss: 1.57236 v_acc: 0.70508 |  iteration: 443 teacher: 1 stage: sketch lr: 0.000077\n",
      "batch 443 loss: 1.66349 acc: 0.69596 | v_loss: 1.48668 v_acc: 0.71680 |  iteration: 444 teacher: 1 stage: sketch lr: 0.000078\n",
      "batch 444 loss: 1.53254 acc: 0.71615 | v_loss: 1.53132 v_acc: 0.71582 |  iteration: 445 teacher: 0 stage: sketch lr: 0.000078\n",
      "batch 445 loss: 1.59507 acc: 0.71875 | v_loss: 1.56530 v_acc: 0.70931 |  iteration: 446 teacher: 0 stage: sketch lr: 0.000078\n",
      "batch 446 loss: 1.52182 acc: 0.71387 | v_loss: 1.63289 v_acc: 0.70964 |  iteration: 447 teacher: 1 stage: sketch lr: 0.000078\n",
      "batch 447 loss: 1.54653 acc: 0.71582 | v_loss: 1.43156 v_acc: 0.74186 |  iteration: 448 teacher: 1 stage: sketch lr: 0.000078\n",
      "batch 448 loss: 1.50639 acc: 0.72298 | v_loss: 1.55943 v_acc: 0.71940 |  iteration: 449 teacher: 1 stage: sketch lr: 0.000078\n",
      "batch 449 loss: 1.53555 acc: 0.72038 | v_loss: 1.52856 v_acc: 0.71094 |  iteration: 450 teacher: 1 stage: sketch lr: 0.000079\n",
      "batch 450 loss: 1.57508 acc: 0.71224 | v_loss: 1.58603 v_acc: 0.70964 |  iteration: 451 teacher: 0 stage: sketch lr: 0.000079\n",
      "batch 451 loss: 1.54946 acc: 0.71745 | v_loss: 1.52415 v_acc: 0.71354 |  iteration: 452 teacher: 0 stage: sketch lr: 0.000079\n",
      "batch 452 loss: 1.48274 acc: 0.73242 | v_loss: 1.56726 v_acc: 0.70898 |  iteration: 453 teacher: 0 stage: sketch lr: 0.000079\n",
      "batch 453 loss: 1.47985 acc: 0.72070 | v_loss: 1.66107 v_acc: 0.69336 |  iteration: 454 teacher: 1 stage: sketch lr: 0.000079\n",
      "batch 454 loss: 1.60323 acc: 0.71875 | v_loss: 1.53697 v_acc: 0.71680 |  iteration: 455 teacher: 1 stage: sketch lr: 0.000079\n",
      "batch 455 loss: 1.56863 acc: 0.71419 | v_loss: 1.48688 v_acc: 0.72331 |  iteration: 456 teacher: 1 stage: sketch lr: 0.000080\n",
      "batch 456 loss: 1.50920 acc: 0.72331 | v_loss: 1.50107 v_acc: 0.72038 |  iteration: 457 teacher: 1 stage: sketch lr: 0.000080\n",
      "batch 457 loss: 1.50621 acc: 0.72103 | v_loss: 1.50271 v_acc: 0.72038 |  iteration: 458 teacher: 0 stage: sketch lr: 0.000080\n",
      "batch 458 loss: 1.59747 acc: 0.70736 | v_loss: 1.45640 v_acc: 0.72396 |  iteration: 459 teacher: 0 stage: sketch lr: 0.000080\n",
      "batch 459 loss: 1.54440 acc: 0.71419 | v_loss: 1.45284 v_acc: 0.73177 |  iteration: 460 teacher: 1 stage: sketch lr: 0.000080\n",
      "batch 460 loss: 1.68011 acc: 0.70117 | v_loss: 1.49407 v_acc: 0.71680 |  iteration: 461 teacher: 1 stage: sketch lr: 0.000081\n",
      "batch 461 loss: 1.68236 acc: 0.69857 | v_loss: 1.52664 v_acc: 0.71061 |  iteration: 462 teacher: 0 stage: sketch lr: 0.000081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 462 loss: 1.55026 acc: 0.71257 | v_loss: 1.64819 v_acc: 0.70312 |  iteration: 463 teacher: 0 stage: sketch lr: 0.000081\n",
      "batch 463 loss: 1.56216 acc: 0.71680 | v_loss: 1.50222 v_acc: 0.71289 |  iteration: 464 teacher: 0 stage: sketch lr: 0.000081\n",
      "batch 464 loss: 1.49778 acc: 0.72559 | v_loss: 1.59232 v_acc: 0.69792 |  iteration: 465 teacher: 0 stage: sketch lr: 0.000081\n",
      "batch 465 loss: 1.54475 acc: 0.71582 | v_loss: 1.50472 v_acc: 0.71875 |  iteration: 466 teacher: 1 stage: sketch lr: 0.000081\n",
      "batch 466 loss: 1.56059 acc: 0.70931 | v_loss: 1.49783 v_acc: 0.71517 |  iteration: 467 teacher: 0 stage: sketch lr: 0.000082\n",
      "batch 467 loss: 1.49422 acc: 0.72135 | v_loss: 1.36652 v_acc: 0.74251 |  iteration: 468 teacher: 0 stage: sketch lr: 0.000082\n",
      "batch 468 loss: 1.46991 acc: 0.72331 | v_loss: 1.45367 v_acc: 0.72526 |  iteration: 469 teacher: 0 stage: sketch lr: 0.000082\n",
      "batch 469 loss: 1.48605 acc: 0.72298 | v_loss: 1.43309 v_acc: 0.74967 |  iteration: 470 teacher: 0 stage: sketch lr: 0.000082\n",
      "batch 470 loss: 1.52088 acc: 0.71908 | v_loss: 1.46311 v_acc: 0.72656 |  iteration: 471 teacher: 0 stage: sketch lr: 0.000082\n",
      "batch 471 loss: 1.47857 acc: 0.72428 | v_loss: 1.52794 v_acc: 0.71842 |  iteration: 472 teacher: 0 stage: sketch lr: 0.000082\n",
      "batch 472 loss: 1.55979 acc: 0.71061 | v_loss: 1.42655 v_acc: 0.72559 |  iteration: 473 teacher: 0 stage: sketch lr: 0.000083\n",
      "batch 473 loss: 1.55338 acc: 0.71289 | v_loss: 1.45522 v_acc: 0.72721 |  iteration: 474 teacher: 0 stage: sketch lr: 0.000083\n",
      "batch 474 loss: 1.48124 acc: 0.71712 | v_loss: 1.57191 v_acc: 0.71354 |  iteration: 475 teacher: 0 stage: sketch lr: 0.000083\n",
      "batch 475 loss: 1.51035 acc: 0.71875 | v_loss: 1.47104 v_acc: 0.72559 |  iteration: 476 teacher: 1 stage: sketch lr: 0.000083\n",
      "batch 476 loss: 1.52566 acc: 0.71680 | v_loss: 1.30399 v_acc: 0.75195 |  iteration: 477 teacher: 0 stage: sketch lr: 0.000083\n",
      "batch 477 loss: 1.48296 acc: 0.72917 | v_loss: 1.55555 v_acc: 0.71159 |  iteration: 478 teacher: 0 stage: sketch lr: 0.000084\n",
      "batch 478 loss: 1.55906 acc: 0.71647 | v_loss: 1.55709 v_acc: 0.71745 |  iteration: 479 teacher: 1 stage: sketch lr: 0.000084\n",
      "batch 479 loss: 1.54246 acc: 0.71940 | v_loss: 1.49468 v_acc: 0.72786 |  iteration: 480 teacher: 1 stage: sketch lr: 0.000084\n",
      "batch 480 loss: 1.55406 acc: 0.71322 | v_loss: 1.43736 v_acc: 0.73112 |  iteration: 481 teacher: 0 stage: sketch lr: 0.000084\n",
      "batch 481 loss: 1.54744 acc: 0.71061 | v_loss: 1.59395 v_acc: 0.70312 |  iteration: 482 teacher: 1 stage: sketch lr: 0.000084\n",
      "batch 482 loss: 1.57019 acc: 0.71419 | v_loss: 1.47838 v_acc: 0.72363 |  iteration: 483 teacher: 0 stage: sketch lr: 0.000084\n",
      "batch 483 loss: 1.52737 acc: 0.71354 | v_loss: 1.60840 v_acc: 0.70573 |  iteration: 484 teacher: 1 stage: sketch lr: 0.000085\n",
      "batch 484 loss: 1.61917 acc: 0.70410 | v_loss: 1.52723 v_acc: 0.71875 |  iteration: 485 teacher: 1 stage: sketch lr: 0.000085\n",
      "batch 485 loss: 1.49352 acc: 0.72428 | v_loss: 1.45434 v_acc: 0.73177 |  iteration: 486 teacher: 0 stage: sketch lr: 0.000085\n",
      "batch 486 loss: 1.54946 acc: 0.71647 | v_loss: 1.45220 v_acc: 0.72168 |  iteration: 487 teacher: 0 stage: sketch lr: 0.000085\n",
      "batch 487 loss: 1.49336 acc: 0.72103 | v_loss: 1.55880 v_acc: 0.71387 |  iteration: 488 teacher: 1 stage: sketch lr: 0.000085\n",
      "batch 488 loss: 1.56169 acc: 0.71419 | v_loss: 1.50450 v_acc: 0.71517 |  iteration: 489 teacher: 0 stage: sketch lr: 0.000085\n",
      "batch 489 loss: 1.51520 acc: 0.71680 | v_loss: 1.63197 v_acc: 0.70605 |  iteration: 490 teacher: 1 stage: sketch lr: 0.000086\n",
      "batch 490 loss: 1.55829 acc: 0.70833 | v_loss: 1.46803 v_acc: 0.72819 |  iteration: 491 teacher: 1 stage: sketch lr: 0.000086\n",
      "batch 491 loss: 1.50782 acc: 0.72038 | v_loss: 1.66912 v_acc: 0.69694 |  iteration: 492 teacher: 0 stage: sketch lr: 0.000086\n",
      "batch 492 loss: 1.57943 acc: 0.70964 | v_loss: 1.63822 v_acc: 0.71322 |  iteration: 493 teacher: 1 stage: sketch lr: 0.000086\n",
      "batch 493 loss: 1.59070 acc: 0.71745 | v_loss: 1.63804 v_acc: 0.69824 |  iteration: 494 teacher: 1 stage: sketch lr: 0.000086\n",
      "batch 494 loss: 1.57741 acc: 0.71842 | v_loss: 1.53192 v_acc: 0.71224 |  iteration: 495 teacher: 1 stage: sketch lr: 0.000086\n",
      "batch 495 loss: 1.49681 acc: 0.72428 | v_loss: 1.47059 v_acc: 0.71387 |  iteration: 496 teacher: 1 stage: sketch lr: 0.000087\n",
      "batch 496 loss: 1.60746 acc: 0.70768 | v_loss: 1.57852 v_acc: 0.70638 |  iteration: 497 teacher: 0 stage: sketch lr: 0.000087\n",
      "batch 497 loss: 1.51111 acc: 0.72754 | v_loss: 1.47092 v_acc: 0.72493 |  iteration: 498 teacher: 0 stage: sketch lr: 0.000087\n",
      "batch 498 loss: 1.65673 acc: 0.69336 | v_loss: 1.72063 v_acc: 0.69629 |  iteration: 499 teacher: 1 stage: sketch lr: 0.000087\n",
      "batch 499 loss: 1.57082 acc: 0.70996 | v_loss: 1.55307 v_acc: 0.71908 |  iteration: 500 teacher: 1 stage: sketch lr: 0.000087\n",
      "batch 500 loss: 1.53260 acc: 0.71810 | v_loss: 1.45131 v_acc: 0.72624 |  iteration: 501 teacher: 0 stage: sketch lr: 0.000088\n",
      "batch 501 loss: 1.57098 acc: 0.70833 | v_loss: 1.55064 v_acc: 0.72103 |  iteration: 502 teacher: 1 stage: sketch lr: 0.000088\n",
      "batch 502 loss: 1.57393 acc: 0.70931 | v_loss: 1.53028 v_acc: 0.71257 |  iteration: 503 teacher: 1 stage: sketch lr: 0.000088\n",
      "batch 503 loss: 1.50198 acc: 0.72689 | v_loss: 1.60700 v_acc: 0.69759 |  iteration: 504 teacher: 0 stage: sketch lr: 0.000088\n",
      "batch 504 loss: 1.57508 acc: 0.71159 | v_loss: 1.48258 v_acc: 0.72461 |  iteration: 505 teacher: 1 stage: sketch lr: 0.000088\n",
      "batch 505 loss: 1.50119 acc: 0.72266 | v_loss: 1.40986 v_acc: 0.73145 |  iteration: 506 teacher: 1 stage: sketch lr: 0.000088\n",
      "batch 506 loss: 1.59615 acc: 0.70378 | v_loss: 1.42005 v_acc: 0.73665 |  iteration: 507 teacher: 1 stage: sketch lr: 0.000089\n",
      "batch 507 loss: 1.56427 acc: 0.71257 | v_loss: 1.52312 v_acc: 0.71908 |  iteration: 508 teacher: 1 stage: sketch lr: 0.000089\n",
      "batch 508 loss: 1.47242 acc: 0.72591 | v_loss: 1.57797 v_acc: 0.71126 |  iteration: 509 teacher: 1 stage: sketch lr: 0.000089\n",
      "batch 509 loss: 1.51916 acc: 0.72233 | v_loss: 1.51963 v_acc: 0.71549 |  iteration: 510 teacher: 0 stage: sketch lr: 0.000089\n",
      "batch 510 loss: 1.46997 acc: 0.72298 | v_loss: 1.46750 v_acc: 0.72852 |  iteration: 511 teacher: 1 stage: sketch lr: 0.000089\n",
      "batch 511 loss: 1.51833 acc: 0.71289 | v_loss: 1.45052 v_acc: 0.73405 |  iteration: 512 teacher: 1 stage: sketch lr: 0.000089\n",
      "batch 512 loss: 1.63858 acc: 0.70736 | v_loss: 1.55776 v_acc: 0.70671 |  iteration: 513 teacher: 1 stage: sketch lr: 0.000090\n",
      "batch 513 loss: 1.45431 acc: 0.72721 | v_loss: 1.42362 v_acc: 0.73861 |  iteration: 514 teacher: 1 stage: sketch lr: 0.000090\n",
      "batch 514 loss: 1.57797 acc: 0.70801 | v_loss: 1.42805 v_acc: 0.73079 |  iteration: 515 teacher: 1 stage: sketch lr: 0.000090\n",
      "batch 515 loss: 1.51648 acc: 0.71647 | v_loss: 1.39082 v_acc: 0.73828 |  iteration: 516 teacher: 1 stage: sketch lr: 0.000090\n",
      "batch 516 loss: 1.50813 acc: 0.71973 | v_loss: 1.39388 v_acc: 0.73275 |  iteration: 517 teacher: 1 stage: sketch lr: 0.000090\n",
      "batch 517 loss: 1.52216 acc: 0.71354 | v_loss: 1.41386 v_acc: 0.72917 |  iteration: 518 teacher: 1 stage: sketch lr: 0.000090\n",
      "batch 518 loss: 1.51953 acc: 0.72038 | v_loss: 1.56869 v_acc: 0.70736 |  iteration: 519 teacher: 1 stage: sketch lr: 0.000091\n",
      "batch 519 loss: 1.49884 acc: 0.72819 | v_loss: 1.50982 v_acc: 0.72233 |  iteration: 520 teacher: 1 stage: sketch lr: 0.000091\n",
      "batch 520 loss: 1.58511 acc: 0.71322 | v_loss: 1.52737 v_acc: 0.73112 |  iteration: 521 teacher: 1 stage: sketch lr: 0.000091\n",
      "batch 521 loss: 1.55851 acc: 0.71745 | v_loss: 1.62841 v_acc: 0.71224 |  iteration: 522 teacher: 1 stage: sketch lr: 0.000091\n",
      "batch 522 loss: 1.55770 acc: 0.71257 | v_loss: 1.61617 v_acc: 0.70703 |  iteration: 523 teacher: 0 stage: sketch lr: 0.000091\n",
      "batch 523 loss: 1.58012 acc: 0.70996 | v_loss: 1.42070 v_acc: 0.74609 |  iteration: 524 teacher: 1 stage: sketch lr: 0.000092\n",
      "batch 524 loss: 1.51845 acc: 0.71777 | v_loss: 1.58862 v_acc: 0.71257 |  iteration: 525 teacher: 1 stage: sketch lr: 0.000092\n",
      "batch 525 loss: 1.69943 acc: 0.71289 | v_loss: 1.39910 v_acc: 0.73047 |  iteration: 526 teacher: 1 stage: sketch lr: 0.000092\n",
      "batch 526 loss: 1.54192 acc: 0.70866 | v_loss: 1.54757 v_acc: 0.70833 |  iteration: 527 teacher: 0 stage: sketch lr: 0.000092\n",
      "batch 527 loss: 1.54668 acc: 0.71159 | v_loss: 1.51522 v_acc: 0.72461 |  iteration: 528 teacher: 1 stage: sketch lr: 0.000092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 528 loss: 1.50720 acc: 0.72461 | v_loss: 1.44978 v_acc: 0.73242 |  iteration: 529 teacher: 1 stage: sketch lr: 0.000092\n",
      "batch 529 loss: 1.47537 acc: 0.72754 | v_loss: 1.46517 v_acc: 0.73014 |  iteration: 530 teacher: 0 stage: sketch lr: 0.000093\n",
      "batch 530 loss: 1.53116 acc: 0.71973 | v_loss: 1.50353 v_acc: 0.72201 |  iteration: 531 teacher: 1 stage: sketch lr: 0.000093\n",
      "batch 531 loss: 1.52085 acc: 0.71940 | v_loss: 1.43535 v_acc: 0.73600 |  iteration: 532 teacher: 0 stage: sketch lr: 0.000093\n",
      "batch 532 loss: 1.52997 acc: 0.71191 | v_loss: 1.45963 v_acc: 0.72201 |  iteration: 533 teacher: 0 stage: sketch lr: 0.000093\n",
      "batch 533 loss: 1.53017 acc: 0.71908 | v_loss: 1.58519 v_acc: 0.70247 |  iteration: 534 teacher: 1 stage: sketch lr: 0.000093\n",
      "batch 534 loss: 1.54026 acc: 0.71842 | v_loss: 1.46285 v_acc: 0.72331 |  iteration: 535 teacher: 0 stage: sketch lr: 0.000093\n",
      "batch 535 loss: 1.43393 acc: 0.73275 | v_loss: 1.50159 v_acc: 0.72038 |  iteration: 536 teacher: 0 stage: sketch lr: 0.000094\n",
      "batch 536 loss: 1.49801 acc: 0.72005 | v_loss: 1.46898 v_acc: 0.72624 |  iteration: 537 teacher: 0 stage: sketch lr: 0.000094\n",
      "batch 537 loss: 1.56179 acc: 0.70964 | v_loss: 1.56180 v_acc: 0.71289 |  iteration: 538 teacher: 1 stage: sketch lr: 0.000094\n",
      "batch 538 loss: 1.54448 acc: 0.71257 | v_loss: 1.41928 v_acc: 0.74316 |  iteration: 539 teacher: 1 stage: sketch lr: 0.000094\n",
      "batch 539 loss: 1.56109 acc: 0.71387 | v_loss: 1.53411 v_acc: 0.72461 |  iteration: 540 teacher: 1 stage: sketch lr: 0.000094\n",
      "batch 540 loss: 1.51099 acc: 0.72331 | v_loss: 1.50295 v_acc: 0.71061 |  iteration: 541 teacher: 1 stage: sketch lr: 0.000095\n",
      "batch 541 loss: 1.52449 acc: 0.71517 | v_loss: 1.54926 v_acc: 0.71712 |  iteration: 542 teacher: 1 stage: sketch lr: 0.000095\n",
      "batch 542 loss: 1.56767 acc: 0.70964 | v_loss: 1.50551 v_acc: 0.71354 |  iteration: 543 teacher: 0 stage: sketch lr: 0.000095\n",
      "batch 543 loss: 1.52608 acc: 0.71354 | v_loss: 1.52070 v_acc: 0.71224 |  iteration: 544 teacher: 1 stage: sketch lr: 0.000095\n",
      "batch 544 loss: 1.45855 acc: 0.73340 | v_loss: 1.62656 v_acc: 0.69759 |  iteration: 545 teacher: 0 stage: sketch lr: 0.000095\n",
      "batch 545 loss: 1.52632 acc: 0.71322 | v_loss: 1.48757 v_acc: 0.72233 |  iteration: 546 teacher: 0 stage: sketch lr: 0.000095\n",
      "batch 546 loss: 1.50539 acc: 0.71875 | v_loss: 1.45084 v_acc: 0.73275 |  iteration: 547 teacher: 0 stage: sketch lr: 0.000096\n",
      "batch 547 loss: 1.48163 acc: 0.72624 | v_loss: 1.47764 v_acc: 0.72135 |  iteration: 548 teacher: 0 stage: sketch lr: 0.000096\n",
      "batch 548 loss: 1.55463 acc: 0.71517 | v_loss: 1.46654 v_acc: 0.72298 |  iteration: 549 teacher: 0 stage: sketch lr: 0.000096\n",
      "batch 549 loss: 1.49586 acc: 0.71647 | v_loss: 1.42683 v_acc: 0.72786 |  iteration: 550 teacher: 1 stage: sketch lr: 0.000096\n",
      "batch 550 loss: 1.48629 acc: 0.71940 | v_loss: 1.41558 v_acc: 0.73340 |  iteration: 551 teacher: 0 stage: sketch lr: 0.000096\n",
      "batch 551 loss: 1.50896 acc: 0.71582 | v_loss: 1.46839 v_acc: 0.72070 |  iteration: 552 teacher: 1 stage: sketch lr: 0.000096\n",
      "batch 552 loss: 1.53699 acc: 0.71322 | v_loss: 1.51612 v_acc: 0.71842 |  iteration: 553 teacher: 1 stage: sketch lr: 0.000097\n",
      "batch 553 loss: 1.52851 acc: 0.71777 | v_loss: 1.60448 v_acc: 0.70866 |  iteration: 554 teacher: 1 stage: sketch lr: 0.000097\n",
      "batch 554 loss: 1.49424 acc: 0.72396 | v_loss: 1.46971 v_acc: 0.71908 |  iteration: 555 teacher: 0 stage: sketch lr: 0.000097\n",
      "batch 555 loss: 1.48092 acc: 0.72721 | v_loss: 1.55932 v_acc: 0.70508 |  iteration: 556 teacher: 0 stage: sketch lr: 0.000097\n",
      "batch 556 loss: 1.54607 acc: 0.71094 | v_loss: 1.47894 v_acc: 0.72070 |  iteration: 557 teacher: 1 stage: sketch lr: 0.000097\n",
      "batch 557 loss: 1.51739 acc: 0.71517 | v_loss: 1.47113 v_acc: 0.72526 |  iteration: 558 teacher: 0 stage: sketch lr: 0.000097\n",
      "batch 558 loss: 1.49030 acc: 0.72168 | v_loss: 1.32787 v_acc: 0.74512 |  iteration: 559 teacher: 0 stage: sketch lr: 0.000098\n",
      "batch 559 loss: 1.51138 acc: 0.71973 | v_loss: 1.40272 v_acc: 0.73177 |  iteration: 560 teacher: 0 stage: sketch lr: 0.000098\n",
      "batch 560 loss: 1.52623 acc: 0.71680 | v_loss: 1.38071 v_acc: 0.75195 |  iteration: 561 teacher: 1 stage: sketch lr: 0.000098\n",
      "batch 561 loss: 1.49964 acc: 0.71908 | v_loss: 1.42280 v_acc: 0.73112 |  iteration: 562 teacher: 1 stage: sketch lr: 0.000098\n",
      "batch 562 loss: 1.50208 acc: 0.72591 | v_loss: 1.49316 v_acc: 0.72168 |  iteration: 563 teacher: 0 stage: sketch lr: 0.000098\n",
      "batch 563 loss: 1.45268 acc: 0.72624 | v_loss: 1.39287 v_acc: 0.72982 |  iteration: 564 teacher: 1 stage: sketch lr: 0.000099\n",
      "batch 564 loss: 1.46461 acc: 0.72201 | v_loss: 1.42133 v_acc: 0.73112 |  iteration: 565 teacher: 0 stage: sketch lr: 0.000099\n",
      "batch 565 loss: 1.48890 acc: 0.72233 | v_loss: 1.54067 v_acc: 0.72038 |  iteration: 566 teacher: 0 stage: sketch lr: 0.000099\n",
      "batch 566 loss: 1.50978 acc: 0.71777 | v_loss: 1.44357 v_acc: 0.73079 |  iteration: 567 teacher: 1 stage: sketch lr: 0.000099\n",
      "batch 567 loss: 1.51371 acc: 0.71810 | v_loss: 1.25888 v_acc: 0.75944 |  iteration: 568 teacher: 1 stage: sketch lr: 0.000099\n",
      "batch 568 loss: 1.56362 acc: 0.71159 | v_loss: 1.51978 v_acc: 0.71517 |  iteration: 569 teacher: 1 stage: sketch lr: 0.000099\n",
      "batch 569 loss: 1.53722 acc: 0.72135 | v_loss: 1.51471 v_acc: 0.72135 |  iteration: 570 teacher: 1 stage: sketch lr: 0.000100\n",
      "batch 570 loss: 1.48960 acc: 0.72038 | v_loss: 1.44533 v_acc: 0.73438 |  iteration: 571 teacher: 0 stage: sketch lr: 0.000100\n",
      "batch 571 loss: 1.44270 acc: 0.72721 | v_loss: 1.37901 v_acc: 0.74089 |  iteration: 572 teacher: 1 stage: sketch lr: 0.000100\n",
      "batch 572 loss: 1.56366 acc: 0.71484 | v_loss: 1.56162 v_acc: 0.70736 |  iteration: 573 teacher: 1 stage: sketch lr: 0.000100\n",
      "batch 573 loss: 1.44926 acc: 0.72949 | v_loss: 1.44247 v_acc: 0.72884 |  iteration: 574 teacher: 0 stage: sketch lr: 0.000100\n",
      "batch 574 loss: 1.56639 acc: 0.71517 | v_loss: 1.57260 v_acc: 0.71452 |  iteration: 575 teacher: 1 stage: sketch lr: 0.000100\n",
      "batch 575 loss: 1.50462 acc: 0.72103 | v_loss: 1.49595 v_acc: 0.72070 |  iteration: 576 teacher: 1 stage: sketch lr: 0.000101\n",
      "batch 576 loss: 1.47465 acc: 0.72103 | v_loss: 1.42818 v_acc: 0.73242 |  iteration: 577 teacher: 0 stage: sketch lr: 0.000101\n",
      "batch 577 loss: 1.52865 acc: 0.72005 | v_loss: 1.42782 v_acc: 0.72428 |  iteration: 578 teacher: 0 stage: sketch lr: 0.000101\n",
      "batch 578 loss: 1.48910 acc: 0.72721 | v_loss: 1.52965 v_acc: 0.71224 |  iteration: 579 teacher: 1 stage: sketch lr: 0.000101\n",
      "batch 579 loss: 1.41988 acc: 0.73210 | v_loss: 1.48035 v_acc: 0.71842 |  iteration: 580 teacher: 0 stage: sketch lr: 0.000101\n",
      "batch 580 loss: 1.49070 acc: 0.72428 | v_loss: 1.57534 v_acc: 0.70898 |  iteration: 581 teacher: 1 stage: sketch lr: 0.000101\n",
      "batch 581 loss: 1.51407 acc: 0.71484 | v_loss: 1.42173 v_acc: 0.73438 |  iteration: 582 teacher: 0 stage: sketch lr: 0.000102\n",
      "batch 582 loss: 1.54098 acc: 0.71680 | v_loss: 1.61042 v_acc: 0.69954 |  iteration: 583 teacher: 0 stage: sketch lr: 0.000102\n",
      "batch 583 loss: 1.46655 acc: 0.72428 | v_loss: 1.59552 v_acc: 0.72038 |  iteration: 584 teacher: 0 stage: sketch lr: 0.000102\n",
      "batch 584 loss: 1.47157 acc: 0.71940 | v_loss: 1.58150 v_acc: 0.70443 |  iteration: 585 teacher: 0 stage: sketch lr: 0.000102\n",
      "batch 585 loss: 1.52734 acc: 0.71973 | v_loss: 1.47458 v_acc: 0.72363 |  iteration: 586 teacher: 1 stage: sketch lr: 0.000102\n",
      "batch 586 loss: 1.57161 acc: 0.70671 | v_loss: 1.43186 v_acc: 0.72038 |  iteration: 587 teacher: 0 stage: sketch lr: 0.000103\n",
      "batch 587 loss: 1.49683 acc: 0.71940 | v_loss: 1.53964 v_acc: 0.71810 |  iteration: 588 teacher: 0 stage: sketch lr: 0.000103\n",
      "batch 588 loss: 1.58549 acc: 0.71159 | v_loss: 1.44826 v_acc: 0.72884 |  iteration: 589 teacher: 1 stage: sketch lr: 0.000103\n",
      "batch 589 loss: 1.55596 acc: 0.71745 | v_loss: 1.64686 v_acc: 0.70052 |  iteration: 590 teacher: 1 stage: sketch lr: 0.000103\n",
      "batch 590 loss: 1.40883 acc: 0.73926 | v_loss: 1.50140 v_acc: 0.72331 |  iteration: 591 teacher: 1 stage: sketch lr: 0.000103\n",
      "batch 591 loss: 1.44866 acc: 0.72754 | v_loss: 1.38959 v_acc: 0.73340 |  iteration: 592 teacher: 0 stage: sketch lr: 0.000103\n",
      "batch 592 loss: 1.54517 acc: 0.71191 | v_loss: 1.52099 v_acc: 0.72331 |  iteration: 593 teacher: 1 stage: sketch lr: 0.000104\n",
      "batch 593 loss: 1.46236 acc: 0.72493 | v_loss: 1.48410 v_acc: 0.71842 |  iteration: 594 teacher: 1 stage: sketch lr: 0.000104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 594 loss: 1.50928 acc: 0.71549 | v_loss: 1.57038 v_acc: 0.70150 |  iteration: 595 teacher: 1 stage: sketch lr: 0.000104\n",
      "batch 595 loss: 1.44976 acc: 0.73177 | v_loss: 1.44778 v_acc: 0.72689 |  iteration: 596 teacher: 1 stage: sketch lr: 0.000104\n",
      "batch 596 loss: 1.45988 acc: 0.72721 | v_loss: 1.37728 v_acc: 0.73535 |  iteration: 597 teacher: 0 stage: sketch lr: 0.000104\n",
      "batch 597 loss: 1.54962 acc: 0.71517 | v_loss: 1.37662 v_acc: 0.74251 |  iteration: 598 teacher: 1 stage: sketch lr: 0.000104\n",
      "batch 598 loss: 1.49442 acc: 0.71842 | v_loss: 1.47807 v_acc: 0.72103 |  iteration: 599 teacher: 0 stage: sketch lr: 0.000105\n",
      "batch 599 loss: 1.48420 acc: 0.72038 | v_loss: 1.53339 v_acc: 0.71680 |  iteration: 600 teacher: 1 stage: sketch lr: 0.000105\n",
      "batch 600 loss: 1.54149 acc: 0.71029 | v_loss: 1.47730 v_acc: 0.72103 |  iteration: 601 teacher: 1 stage: sketch lr: 0.000105\n",
      "batch 601 loss: 1.54441 acc: 0.71549 | v_loss: 1.42532 v_acc: 0.73372 |  iteration: 602 teacher: 1 stage: sketch lr: 0.000105\n",
      "batch 602 loss: 1.49169 acc: 0.72331 | v_loss: 1.41897 v_acc: 0.73828 |  iteration: 603 teacher: 0 stage: sketch lr: 0.000105\n",
      "batch 603 loss: 1.44298 acc: 0.72852 | v_loss: 1.51899 v_acc: 0.71289 |  iteration: 604 teacher: 0 stage: sketch lr: 0.000106\n",
      "batch 604 loss: 1.52744 acc: 0.71615 | v_loss: 1.39882 v_acc: 0.73893 |  iteration: 605 teacher: 0 stage: sketch lr: 0.000106\n",
      "batch 605 loss: 1.48477 acc: 0.72819 | v_loss: 1.39218 v_acc: 0.73763 |  iteration: 606 teacher: 0 stage: sketch lr: 0.000106\n",
      "batch 606 loss: 1.51328 acc: 0.71419 | v_loss: 1.35075 v_acc: 0.74121 |  iteration: 607 teacher: 1 stage: sketch lr: 0.000106\n",
      "batch 607 loss: 1.43716 acc: 0.73145 | v_loss: 1.36173 v_acc: 0.73926 |  iteration: 608 teacher: 0 stage: sketch lr: 0.000106\n",
      "batch 608 loss: 1.45689 acc: 0.72819 | v_loss: 1.37762 v_acc: 0.73470 |  iteration: 609 teacher: 0 stage: sketch lr: 0.000106\n",
      "batch 609 loss: 1.53439 acc: 0.71289 | v_loss: 1.53382 v_acc: 0.71029 |  iteration: 610 teacher: 0 stage: sketch lr: 0.000107\n",
      "batch 610 loss: 1.50195 acc: 0.72038 | v_loss: 1.46850 v_acc: 0.72591 |  iteration: 611 teacher: 0 stage: sketch lr: 0.000107\n",
      "batch 611 loss: 1.48875 acc: 0.72591 | v_loss: 1.44990 v_acc: 0.74316 |  iteration: 612 teacher: 0 stage: sketch lr: 0.000107\n",
      "batch 612 loss: 1.44247 acc: 0.72819 | v_loss: 1.57469 v_acc: 0.71582 |  iteration: 613 teacher: 0 stage: sketch lr: 0.000107\n",
      "batch 613 loss: 1.54943 acc: 0.71517 | v_loss: 1.58594 v_acc: 0.71289 |  iteration: 614 teacher: 1 stage: sketch lr: 0.000107\n",
      "batch 614 loss: 1.50525 acc: 0.72363 | v_loss: 1.35076 v_acc: 0.74740 |  iteration: 615 teacher: 1 stage: sketch lr: 0.000107\n",
      "batch 615 loss: 1.57741 acc: 0.71061 | v_loss: 1.53843 v_acc: 0.71647 |  iteration: 616 teacher: 0 stage: sketch lr: 0.000108\n",
      "batch 616 loss: 1.44933 acc: 0.72591 | v_loss: 1.36380 v_acc: 0.73958 |  iteration: 617 teacher: 1 stage: sketch lr: 0.000108\n",
      "batch 617 loss: 1.43460 acc: 0.73145 | v_loss: 1.49707 v_acc: 0.71582 |  iteration: 618 teacher: 0 stage: sketch lr: 0.000108\n",
      "batch 618 loss: 1.50787 acc: 0.72331 | v_loss: 1.47138 v_acc: 0.73568 |  iteration: 619 teacher: 1 stage: sketch lr: 0.000108\n",
      "batch 619 loss: 1.42088 acc: 0.72917 | v_loss: 1.42176 v_acc: 0.73438 |  iteration: 620 teacher: 0 stage: sketch lr: 0.000108\n",
      "batch 620 loss: 1.52409 acc: 0.71387 | v_loss: 1.42823 v_acc: 0.73177 |  iteration: 621 teacher: 1 stage: sketch lr: 0.000108\n",
      "batch 621 loss: 1.42005 acc: 0.73047 | v_loss: 1.47436 v_acc: 0.72363 |  iteration: 622 teacher: 0 stage: sketch lr: 0.000109\n",
      "batch 622 loss: 1.52271 acc: 0.71224 | v_loss: 1.39125 v_acc: 0.73893 |  iteration: 623 teacher: 1 stage: sketch lr: 0.000109\n",
      "batch 623 loss: 1.42958 acc: 0.73405 | v_loss: 1.41454 v_acc: 0.72852 |  iteration: 624 teacher: 0 stage: sketch lr: 0.000109\n",
      "batch 624 loss: 1.44604 acc: 0.72982 | v_loss: 1.52141 v_acc: 0.71126 |  iteration: 625 teacher: 0 stage: sketch lr: 0.000109\n",
      "batch 625 loss: 1.53250 acc: 0.72103 | v_loss: 1.42396 v_acc: 0.72819 |  iteration: 626 teacher: 0 stage: sketch lr: 0.000109\n",
      "batch 626 loss: 1.42707 acc: 0.72786 | v_loss: 1.44921 v_acc: 0.73047 |  iteration: 627 teacher: 0 stage: sketch lr: 0.000110\n",
      "batch 627 loss: 1.45067 acc: 0.73079 | v_loss: 1.42419 v_acc: 0.73340 |  iteration: 628 teacher: 1 stage: sketch lr: 0.000110\n",
      "batch 628 loss: 1.52385 acc: 0.72070 | v_loss: 1.51211 v_acc: 0.71940 |  iteration: 629 teacher: 1 stage: sketch lr: 0.000110\n",
      "batch 629 loss: 1.48594 acc: 0.72298 | v_loss: 1.36223 v_acc: 0.74512 |  iteration: 630 teacher: 1 stage: sketch lr: 0.000110\n",
      "batch 630 loss: 1.49496 acc: 0.72005 | v_loss: 1.48946 v_acc: 0.72819 |  iteration: 631 teacher: 0 stage: sketch lr: 0.000110\n",
      "batch 631 loss: 1.50444 acc: 0.72103 | v_loss: 1.45496 v_acc: 0.72298 |  iteration: 632 teacher: 1 stage: sketch lr: 0.000110\n",
      "batch 632 loss: 1.50989 acc: 0.71745 | v_loss: 1.50844 v_acc: 0.71777 |  iteration: 633 teacher: 1 stage: sketch lr: 0.000111\n",
      "batch 633 loss: 1.48160 acc: 0.73047 | v_loss: 1.43416 v_acc: 0.72298 |  iteration: 634 teacher: 1 stage: sketch lr: 0.000111\n",
      "batch 634 loss: 1.52488 acc: 0.71452 | v_loss: 1.48225 v_acc: 0.71517 |  iteration: 635 teacher: 1 stage: sketch lr: 0.000111\n",
      "batch 635 loss: 1.47168 acc: 0.72038 | v_loss: 1.58143 v_acc: 0.70150 |  iteration: 636 teacher: 0 stage: sketch lr: 0.000111\n",
      "batch 636 loss: 1.52132 acc: 0.71419 | v_loss: 1.43251 v_acc: 0.73210 |  iteration: 637 teacher: 0 stage: sketch lr: 0.000111\n",
      "batch 637 loss: 1.39457 acc: 0.73307 | v_loss: 1.42097 v_acc: 0.73665 |  iteration: 638 teacher: 1 stage: sketch lr: 0.000111\n",
      "batch 638 loss: 1.51252 acc: 0.72070 | v_loss: 1.43982 v_acc: 0.72819 |  iteration: 639 teacher: 0 stage: sketch lr: 0.000112\n",
      "batch 639 loss: 1.44648 acc: 0.72786 | v_loss: 1.42379 v_acc: 0.72949 |  iteration: 640 teacher: 0 stage: sketch lr: 0.000112\n",
      "batch 640 loss: 1.39981 acc: 0.73665 | v_loss: 1.39773 v_acc: 0.73177 |  iteration: 641 teacher: 1 stage: sketch lr: 0.000112\n",
      "batch 641 loss: 1.49182 acc: 0.71940 | v_loss: 1.37175 v_acc: 0.73828 |  iteration: 642 teacher: 1 stage: sketch lr: 0.000112\n",
      "batch 642 loss: 1.43939 acc: 0.72982 | v_loss: 1.44825 v_acc: 0.72721 |  iteration: 643 teacher: 1 stage: sketch lr: 0.000112\n",
      "batch 643 loss: 1.41923 acc: 0.73079 | v_loss: 1.48472 v_acc: 0.72526 |  iteration: 644 teacher: 1 stage: sketch lr: 0.000113\n",
      "batch 644 loss: 1.47176 acc: 0.72201 | v_loss: 1.56694 v_acc: 0.71517 |  iteration: 645 teacher: 1 stage: sketch lr: 0.000113\n",
      "batch 645 loss: 1.55092 acc: 0.71452 | v_loss: 1.44017 v_acc: 0.72428 |  iteration: 646 teacher: 1 stage: sketch lr: 0.000113\n",
      "batch 646 loss: 1.47573 acc: 0.72266 | v_loss: 1.50939 v_acc: 0.71745 |  iteration: 647 teacher: 0 stage: sketch lr: 0.000113\n",
      "batch 647 loss: 1.43062 acc: 0.73079 | v_loss: 1.44675 v_acc: 0.72233 |  iteration: 648 teacher: 0 stage: sketch lr: 0.000113\n",
      "batch 648 loss: 1.45930 acc: 0.72624 | v_loss: 1.43927 v_acc: 0.73112 |  iteration: 649 teacher: 0 stage: sketch lr: 0.000113\n",
      "batch 649 loss: 1.51983 acc: 0.71517 | v_loss: 1.28987 v_acc: 0.74837 |  iteration: 650 teacher: 0 stage: sketch lr: 0.000114\n",
      "batch 650 loss: 1.45829 acc: 0.72461 | v_loss: 1.36488 v_acc: 0.73340 |  iteration: 651 teacher: 0 stage: sketch lr: 0.000114\n",
      "batch 651 loss: 1.43928 acc: 0.72786 | v_loss: 1.35562 v_acc: 0.75684 |  iteration: 652 teacher: 0 stage: sketch lr: 0.000114\n",
      "batch 652 loss: 1.40505 acc: 0.74382 | v_loss: 1.37738 v_acc: 0.73893 |  iteration: 653 teacher: 0 stage: sketch lr: 0.000114\n",
      "batch 653 loss: 1.50687 acc: 0.72070 | v_loss: 1.44181 v_acc: 0.73372 |  iteration: 654 teacher: 0 stage: sketch lr: 0.000114\n",
      "batch 654 loss: 1.49748 acc: 0.72005 | v_loss: 1.37192 v_acc: 0.73210 |  iteration: 655 teacher: 0 stage: sketch lr: 0.000114\n",
      "batch 655 loss: 1.47830 acc: 0.72298 | v_loss: 1.36749 v_acc: 0.74219 |  iteration: 656 teacher: 1 stage: sketch lr: 0.000115\n",
      "batch 656 loss: 1.49388 acc: 0.72559 | v_loss: 1.49793 v_acc: 0.72201 |  iteration: 657 teacher: 1 stage: sketch lr: 0.000115\n",
      "batch 657 loss: 1.45025 acc: 0.73079 | v_loss: 1.41644 v_acc: 0.73861 |  iteration: 658 teacher: 0 stage: sketch lr: 0.000115\n",
      "batch 658 loss: 1.40055 acc: 0.73307 | v_loss: 1.22837 v_acc: 0.76660 |  iteration: 659 teacher: 1 stage: sketch lr: 0.000115\n",
      "batch 659 loss: 1.43917 acc: 0.72754 | v_loss: 1.47295 v_acc: 0.72559 |  iteration: 660 teacher: 1 stage: sketch lr: 0.000115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 660 loss: 1.44326 acc: 0.73047 | v_loss: 1.48271 v_acc: 0.72363 |  iteration: 661 teacher: 0 stage: sketch lr: 0.000115\n",
      "batch 661 loss: 1.43788 acc: 0.71973 | v_loss: 1.41482 v_acc: 0.73958 |  iteration: 662 teacher: 1 stage: sketch lr: 0.000116\n",
      "batch 662 loss: 1.47007 acc: 0.72103 | v_loss: 1.33145 v_acc: 0.74935 |  iteration: 663 teacher: 1 stage: sketch lr: 0.000116\n",
      "batch 663 loss: 1.47638 acc: 0.72721 | v_loss: 1.51307 v_acc: 0.71517 |  iteration: 664 teacher: 1 stage: sketch lr: 0.000116\n",
      "batch 664 loss: 1.40959 acc: 0.73730 | v_loss: 1.41903 v_acc: 0.73145 |  iteration: 665 teacher: 1 stage: sketch lr: 0.000116\n",
      "batch 665 loss: 1.47857 acc: 0.72689 | v_loss: 1.52720 v_acc: 0.71940 |  iteration: 666 teacher: 0 stage: sketch lr: 0.000116\n",
      "batch 666 loss: 1.49212 acc: 0.72917 | v_loss: 1.46043 v_acc: 0.72982 |  iteration: 667 teacher: 1 stage: sketch lr: 0.000117\n",
      "batch 667 loss: 1.42327 acc: 0.73730 | v_loss: 1.42949 v_acc: 0.73926 |  iteration: 668 teacher: 0 stage: sketch lr: 0.000117\n",
      "batch 668 loss: 1.55157 acc: 0.71224 | v_loss: 1.38909 v_acc: 0.73535 |  iteration: 669 teacher: 1 stage: sketch lr: 0.000117\n",
      "batch 669 loss: 1.50562 acc: 0.71745 | v_loss: 1.48407 v_acc: 0.71777 |  iteration: 670 teacher: 0 stage: sketch lr: 0.000117\n",
      "batch 670 loss: 1.42718 acc: 0.72819 | v_loss: 1.46183 v_acc: 0.72201 |  iteration: 671 teacher: 1 stage: sketch lr: 0.000117\n",
      "batch 671 loss: 1.47819 acc: 0.72461 | v_loss: 1.55985 v_acc: 0.70996 |  iteration: 672 teacher: 1 stage: sketch lr: 0.000117\n",
      "batch 672 loss: 1.45513 acc: 0.72819 | v_loss: 1.37458 v_acc: 0.73926 |  iteration: 673 teacher: 0 stage: sketch lr: 0.000118\n",
      "batch 673 loss: 1.40960 acc: 0.73763 | v_loss: 1.61409 v_acc: 0.70150 |  iteration: 674 teacher: 0 stage: sketch lr: 0.000118\n",
      "batch 674 loss: 1.46091 acc: 0.72461 | v_loss: 1.52633 v_acc: 0.72493 |  iteration: 675 teacher: 0 stage: sketch lr: 0.000118\n",
      "batch 675 loss: 1.45226 acc: 0.73210 | v_loss: 1.53859 v_acc: 0.71126 |  iteration: 676 teacher: 0 stage: sketch lr: 0.000118\n",
      "batch 676 loss: 1.47356 acc: 0.71973 | v_loss: 1.43805 v_acc: 0.72884 |  iteration: 677 teacher: 0 stage: sketch lr: 0.000118\n",
      "batch 677 loss: 1.44636 acc: 0.72982 | v_loss: 1.40575 v_acc: 0.72559 |  iteration: 678 teacher: 0 stage: sketch lr: 0.000118\n",
      "batch 678 loss: 1.42157 acc: 0.72396 | v_loss: 1.49578 v_acc: 0.72624 |  iteration: 679 teacher: 0 stage: sketch lr: 0.000119\n",
      "batch 679 loss: 1.45732 acc: 0.72754 | v_loss: 1.42988 v_acc: 0.73340 |  iteration: 680 teacher: 1 stage: sketch lr: 0.000119\n",
      "batch 680 loss: 1.55239 acc: 0.71354 | v_loss: 1.60457 v_acc: 0.71191 |  iteration: 681 teacher: 1 stage: sketch lr: 0.000119\n",
      "batch 681 loss: 1.49593 acc: 0.72070 | v_loss: 1.49755 v_acc: 0.72135 |  iteration: 682 teacher: 1 stage: sketch lr: 0.000119\n",
      "batch 682 loss: 1.42844 acc: 0.72656 | v_loss: 1.34178 v_acc: 0.73893 |  iteration: 683 teacher: 0 stage: sketch lr: 0.000119\n",
      "batch 683 loss: 1.44905 acc: 0.72786 | v_loss: 1.47114 v_acc: 0.73470 |  iteration: 684 teacher: 0 stage: sketch lr: 0.000119\n",
      "batch 684 loss: 1.53649 acc: 0.71745 | v_loss: 1.46006 v_acc: 0.72363 |  iteration: 685 teacher: 1 stage: sketch lr: 0.000120\n",
      "batch 685 loss: 1.41415 acc: 0.73372 | v_loss: 1.52547 v_acc: 0.71517 |  iteration: 686 teacher: 1 stage: sketch lr: 0.000120\n",
      "batch 686 loss: 1.38643 acc: 0.74023 | v_loss: 1.40143 v_acc: 0.74154 |  iteration: 687 teacher: 1 stage: sketch lr: 0.000120\n",
      "batch 687 loss: 1.43164 acc: 0.73145 | v_loss: 1.34461 v_acc: 0.74414 |  iteration: 688 teacher: 1 stage: sketch lr: 0.000120\n",
      "batch 688 loss: 1.47815 acc: 0.72493 | v_loss: 1.35005 v_acc: 0.74674 |  iteration: 689 teacher: 1 stage: sketch lr: 0.000120\n",
      "batch 689 loss: 1.41638 acc: 0.73405 | v_loss: 1.45526 v_acc: 0.72559 |  iteration: 690 teacher: 1 stage: sketch lr: 0.000121\n",
      "batch 690 loss: 1.40375 acc: 0.74154 | v_loss: 1.49956 v_acc: 0.71842 |  iteration: 691 teacher: 0 stage: sketch lr: 0.000121\n",
      "batch 691 loss: 1.41751 acc: 0.73079 | v_loss: 1.49599 v_acc: 0.72396 |  iteration: 692 teacher: 1 stage: sketch lr: 0.000121\n",
      "batch 692 loss: 1.46945 acc: 0.73145 | v_loss: 1.38388 v_acc: 0.74251 |  iteration: 693 teacher: 1 stage: sketch lr: 0.000121\n",
      "batch 693 loss: 1.64789 acc: 0.70345 | v_loss: 1.36595 v_acc: 0.74870 |  iteration: 694 teacher: 1 stage: sketch lr: 0.000121\n",
      "batch 694 loss: 1.44787 acc: 0.72786 | v_loss: 1.46520 v_acc: 0.72298 |  iteration: 695 teacher: 0 stage: sketch lr: 0.000121\n",
      "batch 695 loss: 1.54660 acc: 0.71419 | v_loss: 1.37685 v_acc: 0.74479 |  iteration: 696 teacher: 1 stage: sketch lr: 0.000122\n",
      "batch 696 loss: 1.54069 acc: 0.71224 | v_loss: 1.37589 v_acc: 0.74479 |  iteration: 697 teacher: 1 stage: sketch lr: 0.000122\n",
      "batch 697 loss: 1.39640 acc: 0.73861 | v_loss: 1.31967 v_acc: 0.74902 |  iteration: 698 teacher: 0 stage: sketch lr: 0.000122\n",
      "batch 698 loss: 1.40701 acc: 0.73470 | v_loss: 1.29326 v_acc: 0.75260 |  iteration: 699 teacher: 0 stage: sketch lr: 0.000122\n",
      "batch 699 loss: 1.39640 acc: 0.73470 | v_loss: 1.33599 v_acc: 0.74251 |  iteration: 700 teacher: 0 stage: sketch lr: 0.000122\n",
      "batch 700 loss: 1.44169 acc: 0.73079 | v_loss: 1.50825 v_acc: 0.71452 |  iteration: 701 teacher: 0 stage: sketch lr: 0.000122\n",
      "batch 701 loss: 1.56852 acc: 0.70638 | v_loss: 1.42195 v_acc: 0.73438 |  iteration: 702 teacher: 1 stage: sketch lr: 0.000123\n",
      "batch 702 loss: 1.48386 acc: 0.72428 | v_loss: 1.37017 v_acc: 0.75814 |  iteration: 703 teacher: 0 stage: sketch lr: 0.000123\n",
      "batch 703 loss: 1.53626 acc: 0.71712 | v_loss: 1.52442 v_acc: 0.71973 |  iteration: 704 teacher: 1 stage: sketch lr: 0.000123\n",
      "batch 704 loss: 1.46489 acc: 0.72396 | v_loss: 1.50848 v_acc: 0.73112 |  iteration: 705 teacher: 0 stage: sketch lr: 0.000123\n",
      "batch 705 loss: 1.58860 acc: 0.70833 | v_loss: 1.34817 v_acc: 0.75944 |  iteration: 706 teacher: 1 stage: sketch lr: 0.000123\n",
      "batch 706 loss: 1.54330 acc: 0.71061 | v_loss: 1.54921 v_acc: 0.72819 |  iteration: 707 teacher: 1 stage: sketch lr: 0.000124\n",
      "batch 707 loss: 1.44642 acc: 0.73145 | v_loss: 1.31079 v_acc: 0.75130 |  iteration: 708 teacher: 0 stage: sketch lr: 0.000124\n",
      "batch 708 loss: 1.51994 acc: 0.71647 | v_loss: 1.42403 v_acc: 0.72689 |  iteration: 709 teacher: 1 stage: sketch lr: 0.000124\n",
      "batch 709 loss: 1.40680 acc: 0.73307 | v_loss: 1.48318 v_acc: 0.73112 |  iteration: 710 teacher: 0 stage: sketch lr: 0.000124\n",
      "batch 710 loss: 1.39643 acc: 0.73340 | v_loss: 1.41725 v_acc: 0.73763 |  iteration: 711 teacher: 1 stage: sketch lr: 0.000124\n",
      "batch 711 loss: 1.46274 acc: 0.72559 | v_loss: 1.41184 v_acc: 0.73600 |  iteration: 712 teacher: 0 stage: sketch lr: 0.000124\n",
      "batch 712 loss: 1.39519 acc: 0.73698 | v_loss: 1.42417 v_acc: 0.73145 |  iteration: 713 teacher: 0 stage: sketch lr: 0.000125\n",
      "batch 713 loss: 1.42353 acc: 0.72917 | v_loss: 1.35243 v_acc: 0.75326 |  iteration: 714 teacher: 1 stage: sketch lr: 0.000125\n",
      "batch 714 loss: 1.40539 acc: 0.73340 | v_loss: 1.37628 v_acc: 0.74349 |  iteration: 715 teacher: 0 stage: sketch lr: 0.000125\n",
      "batch 715 loss: 1.48406 acc: 0.72526 | v_loss: 1.53268 v_acc: 0.70801 |  iteration: 716 teacher: 0 stage: sketch lr: 0.000125\n",
      "batch 716 loss: 1.50247 acc: 0.71680 | v_loss: 1.37879 v_acc: 0.73405 |  iteration: 717 teacher: 1 stage: sketch lr: 0.000125\n",
      "batch 717 loss: 1.46979 acc: 0.72949 | v_loss: 1.41495 v_acc: 0.73438 |  iteration: 718 teacher: 1 stage: sketch lr: 0.000125\n",
      "batch 718 loss: 1.42952 acc: 0.73145 | v_loss: 1.36998 v_acc: 0.74382 |  iteration: 719 teacher: 0 stage: sketch lr: 0.000126\n",
      "batch 719 loss: 1.42232 acc: 0.72884 | v_loss: 1.46204 v_acc: 0.72526 |  iteration: 720 teacher: 1 stage: sketch lr: 0.000126\n",
      "batch 720 loss: 1.44385 acc: 0.72298 | v_loss: 1.32065 v_acc: 0.75098 |  iteration: 721 teacher: 1 stage: sketch lr: 0.000126\n",
      "batch 721 loss: 1.48886 acc: 0.72266 | v_loss: 1.44058 v_acc: 0.73145 |  iteration: 722 teacher: 0 stage: sketch lr: 0.000126\n",
      "batch 722 loss: 1.34786 acc: 0.74967 | v_loss: 1.39864 v_acc: 0.73438 |  iteration: 723 teacher: 1 stage: sketch lr: 0.000126\n",
      "batch 723 loss: 1.42837 acc: 0.73275 | v_loss: 1.49098 v_acc: 0.72949 |  iteration: 724 teacher: 1 stage: sketch lr: 0.000126\n",
      "batch 724 loss: 1.46306 acc: 0.73047 | v_loss: 1.37448 v_acc: 0.73177 |  iteration: 725 teacher: 0 stage: sketch lr: 0.000127\n",
      "batch 725 loss: 1.42981 acc: 0.73210 | v_loss: 1.42490 v_acc: 0.73145 |  iteration: 726 teacher: 0 stage: sketch lr: 0.000127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 726 loss: 1.54929 acc: 0.72233 | v_loss: 1.51597 v_acc: 0.71680 |  iteration: 727 teacher: 1 stage: sketch lr: 0.000127\n",
      "batch 727 loss: 1.40732 acc: 0.73503 | v_loss: 1.38174 v_acc: 0.74089 |  iteration: 728 teacher: 0 stage: sketch lr: 0.000127\n",
      "batch 728 loss: 1.45540 acc: 0.72624 | v_loss: 1.35875 v_acc: 0.74577 |  iteration: 729 teacher: 1 stage: sketch lr: 0.000127\n",
      "batch 729 loss: 1.42573 acc: 0.72917 | v_loss: 1.38901 v_acc: 0.73503 |  iteration: 730 teacher: 0 stage: sketch lr: 0.000128\n",
      "batch 730 loss: 1.46322 acc: 0.72559 | v_loss: 1.42159 v_acc: 0.73503 |  iteration: 731 teacher: 0 stage: sketch lr: 0.000128\n",
      "batch 731 loss: 1.42082 acc: 0.73600 | v_loss: 1.40734 v_acc: 0.73470 |  iteration: 732 teacher: 0 stage: sketch lr: 0.000128\n",
      "batch 732 loss: 1.39794 acc: 0.73470 | v_loss: 1.28005 v_acc: 0.75521 |  iteration: 733 teacher: 1 stage: sketch lr: 0.000128\n",
      "batch 733 loss: 1.40868 acc: 0.73145 | v_loss: 1.40997 v_acc: 0.73079 |  iteration: 734 teacher: 0 stage: sketch lr: 0.000128\n",
      "batch 734 loss: 1.47145 acc: 0.72689 | v_loss: 1.45553 v_acc: 0.72689 |  iteration: 735 teacher: 1 stage: sketch lr: 0.000128\n",
      "batch 735 loss: 1.37905 acc: 0.73991 | v_loss: 1.48181 v_acc: 0.72884 |  iteration: 736 teacher: 0 stage: sketch lr: 0.000129\n",
      "batch 736 loss: 1.43060 acc: 0.73340 | v_loss: 1.41611 v_acc: 0.72721 |  iteration: 737 teacher: 1 stage: sketch lr: 0.000129\n",
      "batch 737 loss: 1.45739 acc: 0.72982 | v_loss: 1.43965 v_acc: 0.73177 |  iteration: 738 teacher: 0 stage: sketch lr: 0.000129\n",
      "batch 738 loss: 1.48638 acc: 0.72363 | v_loss: 1.40739 v_acc: 0.73210 |  iteration: 739 teacher: 1 stage: sketch lr: 0.000129\n",
      "batch 739 loss: 1.50837 acc: 0.71647 | v_loss: 1.38576 v_acc: 0.73893 |  iteration: 740 teacher: 1 stage: sketch lr: 0.000129\n",
      "batch 740 loss: 1.41233 acc: 0.73568 | v_loss: 1.23104 v_acc: 0.76237 |  iteration: 741 teacher: 0 stage: sketch lr: 0.000129\n",
      "batch 741 loss: 1.41235 acc: 0.73665 | v_loss: 1.32950 v_acc: 0.74544 |  iteration: 742 teacher: 1 stage: sketch lr: 0.000130\n",
      "batch 742 loss: 1.40302 acc: 0.73210 | v_loss: 1.28784 v_acc: 0.76562 |  iteration: 743 teacher: 1 stage: sketch lr: 0.000130\n",
      "batch 743 loss: 1.32802 acc: 0.74349 | v_loss: 1.31888 v_acc: 0.75163 |  iteration: 744 teacher: 0 stage: sketch lr: 0.000130\n",
      "batch 744 loss: 1.46258 acc: 0.72917 | v_loss: 1.38300 v_acc: 0.74544 |  iteration: 745 teacher: 0 stage: sketch lr: 0.000130\n",
      "batch 745 loss: 1.39406 acc: 0.73372 | v_loss: 1.32155 v_acc: 0.74447 |  iteration: 746 teacher: 1 stage: sketch lr: 0.000130\n",
      "batch 746 loss: 1.29136 acc: 0.75618 | v_loss: 1.30209 v_acc: 0.75163 |  iteration: 747 teacher: 0 stage: sketch lr: 0.000130\n",
      "batch 747 loss: 1.38697 acc: 0.74316 | v_loss: 1.42021 v_acc: 0.72982 |  iteration: 748 teacher: 1 stage: sketch lr: 0.000131\n",
      "batch 748 loss: 1.38091 acc: 0.73470 | v_loss: 1.35421 v_acc: 0.74707 |  iteration: 749 teacher: 1 stage: sketch lr: 0.000131\n",
      "batch 749 loss: 1.38151 acc: 0.73926 | v_loss: 1.16749 v_acc: 0.77344 |  iteration: 750 teacher: 1 stage: sketch lr: 0.000131\n",
      "batch 750 loss: 1.34589 acc: 0.74935 | v_loss: 1.43617 v_acc: 0.72624 |  iteration: 751 teacher: 0 stage: sketch lr: 0.000131\n",
      "batch 751 loss: 1.31051 acc: 0.75391 | v_loss: 1.40839 v_acc: 0.73763 |  iteration: 752 teacher: 0 stage: sketch lr: 0.000131\n",
      "batch 752 loss: 1.38705 acc: 0.73893 | v_loss: 1.37348 v_acc: 0.75260 |  iteration: 753 teacher: 1 stage: sketch lr: 0.000132\n",
      "batch 753 loss: 1.36384 acc: 0.73861 | v_loss: 1.29648 v_acc: 0.75326 |  iteration: 754 teacher: 1 stage: sketch lr: 0.000132\n",
      "batch 754 loss: 1.42284 acc: 0.72982 | v_loss: 1.50599 v_acc: 0.71842 |  iteration: 755 teacher: 0 stage: sketch lr: 0.000132\n",
      "batch 755 loss: 1.43412 acc: 0.73796 | v_loss: 1.38953 v_acc: 0.73405 |  iteration: 756 teacher: 1 stage: sketch lr: 0.000132\n",
      "batch 756 loss: 1.38360 acc: 0.73730 | v_loss: 1.47879 v_acc: 0.73112 |  iteration: 757 teacher: 0 stage: sketch lr: 0.000132\n",
      "batch 757 loss: 1.41287 acc: 0.73242 | v_loss: 1.41901 v_acc: 0.73470 |  iteration: 758 teacher: 0 stage: sketch lr: 0.000132\n",
      "batch 758 loss: 1.40079 acc: 0.73470 | v_loss: 1.33521 v_acc: 0.74935 |  iteration: 759 teacher: 1 stage: sketch lr: 0.000133\n",
      "batch 759 loss: 1.40482 acc: 0.73991 | v_loss: 1.35411 v_acc: 0.73958 |  iteration: 760 teacher: 1 stage: sketch lr: 0.000133\n",
      "batch 760 loss: 1.40786 acc: 0.74121 | v_loss: 1.39420 v_acc: 0.73372 |  iteration: 761 teacher: 0 stage: sketch lr: 0.000133\n",
      "batch 761 loss: 1.40959 acc: 0.73275 | v_loss: 1.39690 v_acc: 0.73242 |  iteration: 762 teacher: 0 stage: sketch lr: 0.000133\n",
      "batch 762 loss: 1.43888 acc: 0.73307 | v_loss: 1.47980 v_acc: 0.72396 |  iteration: 763 teacher: 1 stage: sketch lr: 0.000133\n",
      "batch 763 loss: 1.49518 acc: 0.72721 | v_loss: 1.29571 v_acc: 0.75326 |  iteration: 764 teacher: 0 stage: sketch lr: 0.000133\n",
      "batch 764 loss: 1.47200 acc: 0.73014 | v_loss: 1.51255 v_acc: 0.71940 |  iteration: 765 teacher: 1 stage: sketch lr: 0.000134\n",
      "batch 765 loss: 1.37234 acc: 0.73991 | v_loss: 1.47918 v_acc: 0.73405 |  iteration: 766 teacher: 1 stage: sketch lr: 0.000134\n",
      "batch 766 loss: 1.40094 acc: 0.73438 | v_loss: 1.46166 v_acc: 0.72103 |  iteration: 767 teacher: 0 stage: sketch lr: 0.000134\n",
      "batch 767 loss: 1.41174 acc: 0.74023 | v_loss: 1.38963 v_acc: 0.73600 |  iteration: 768 teacher: 1 stage: sketch lr: 0.000134\n",
      "batch 768 loss: 1.46845 acc: 0.72559 | v_loss: 1.33372 v_acc: 0.74154 |  iteration: 769 teacher: 1 stage: sketch lr: 0.000134\n",
      "batch 769 loss: 1.41731 acc: 0.73275 | v_loss: 1.45798 v_acc: 0.73210 |  iteration: 770 teacher: 1 stage: sketch lr: 0.000135\n",
      "batch 770 loss: 1.26860 acc: 0.75553 | v_loss: 1.38086 v_acc: 0.73958 |  iteration: 771 teacher: 0 stage: sketch lr: 0.000135\n",
      "batch 771 loss: 1.45790 acc: 0.72493 | v_loss: 1.54020 v_acc: 0.71387 |  iteration: 772 teacher: 1 stage: sketch lr: 0.000135\n",
      "batch 772 loss: 1.43493 acc: 0.72461 | v_loss: 1.43423 v_acc: 0.73730 |  iteration: 773 teacher: 1 stage: sketch lr: 0.000135\n",
      "batch 773 loss: 1.42419 acc: 0.73047 | v_loss: 1.35523 v_acc: 0.74414 |  iteration: 774 teacher: 1 stage: sketch lr: 0.000135\n",
      "batch 774 loss: 1.44934 acc: 0.73926 | v_loss: 1.43671 v_acc: 0.73828 |  iteration: 775 teacher: 0 stage: sketch lr: 0.000135\n",
      "batch 775 loss: 1.38509 acc: 0.73275 | v_loss: 1.41714 v_acc: 0.73470 |  iteration: 776 teacher: 1 stage: sketch lr: 0.000136\n",
      "batch 776 loss: 1.40987 acc: 0.73242 | v_loss: 1.44898 v_acc: 0.72331 |  iteration: 777 teacher: 0 stage: sketch lr: 0.000136\n",
      "batch 777 loss: 1.41527 acc: 0.72624 | v_loss: 1.35387 v_acc: 0.74577 |  iteration: 778 teacher: 1 stage: sketch lr: 0.000136\n",
      "batch 778 loss: 1.36794 acc: 0.74382 | v_loss: 1.32512 v_acc: 0.74805 |  iteration: 779 teacher: 0 stage: sketch lr: 0.000136\n",
      "batch 779 loss: 1.44721 acc: 0.72396 | v_loss: 1.28529 v_acc: 0.75456 |  iteration: 780 teacher: 0 stage: sketch lr: 0.000136\n",
      "batch 780 loss: 1.52084 acc: 0.71745 | v_loss: 1.39216 v_acc: 0.73828 |  iteration: 781 teacher: 1 stage: sketch lr: 0.000136\n",
      "batch 781 loss: 1.33475 acc: 0.74577 | v_loss: 1.47765 v_acc: 0.72656 |  iteration: 782 teacher: 1 stage: sketch lr: 0.000137\n",
      "batch 782 loss: 1.39625 acc: 0.73763 | v_loss: 1.44624 v_acc: 0.72721 |  iteration: 783 teacher: 0 stage: sketch lr: 0.000137\n",
      "batch 783 loss: 1.33041 acc: 0.74902 | v_loss: 1.33366 v_acc: 0.75195 |  iteration: 784 teacher: 0 stage: sketch lr: 0.000137\n",
      "batch 784 loss: 1.40304 acc: 0.73340 | v_loss: 1.29827 v_acc: 0.75716 |  iteration: 785 teacher: 1 stage: sketch lr: 0.000137\n",
      "batch 785 loss: 1.49027 acc: 0.71908 | v_loss: 1.42770 v_acc: 0.72656 |  iteration: 786 teacher: 1 stage: sketch lr: 0.000137\n",
      "batch 786 loss: 1.43618 acc: 0.73145 | v_loss: 1.37201 v_acc: 0.74642 |  iteration: 787 teacher: 1 stage: sketch lr: 0.000137\n",
      "batch 787 loss: 1.48083 acc: 0.72656 | v_loss: 1.34269 v_acc: 0.74121 |  iteration: 788 teacher: 1 stage: sketch lr: 0.000138\n",
      "batch 788 loss: 1.46159 acc: 0.73307 | v_loss: 1.28419 v_acc: 0.74154 |  iteration: 789 teacher: 1 stage: sketch lr: 0.000138\n",
      "batch 789 loss: 1.33946 acc: 0.74382 | v_loss: 1.25903 v_acc: 0.76074 |  iteration: 790 teacher: 0 stage: sketch lr: 0.000138\n",
      "batch 790 loss: 1.40880 acc: 0.73665 | v_loss: 1.31590 v_acc: 0.74447 |  iteration: 791 teacher: 1 stage: sketch lr: 0.000138\n",
      "batch 791 loss: 1.40882 acc: 0.73340 | v_loss: 1.48695 v_acc: 0.71484 |  iteration: 792 teacher: 0 stage: sketch lr: 0.000138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 792 loss: 1.42872 acc: 0.73568 | v_loss: 1.36315 v_acc: 0.74154 |  iteration: 793 teacher: 1 stage: sketch lr: 0.000139\n",
      "batch 793 loss: 1.35682 acc: 0.73730 | v_loss: 1.27040 v_acc: 0.76953 |  iteration: 794 teacher: 0 stage: sketch lr: 0.000139\n",
      "batch 794 loss: 1.49559 acc: 0.73242 | v_loss: 1.46783 v_acc: 0.72624 |  iteration: 795 teacher: 1 stage: sketch lr: 0.000139\n",
      "batch 795 loss: 1.40236 acc: 0.73600 | v_loss: 1.47214 v_acc: 0.72461 |  iteration: 796 teacher: 0 stage: sketch lr: 0.000139\n",
      "batch 796 loss: 1.34505 acc: 0.74479 | v_loss: 1.29839 v_acc: 0.74902 |  iteration: 797 teacher: 0 stage: sketch lr: 0.000139\n",
      "batch 797 loss: 1.33052 acc: 0.73958 | v_loss: 1.39921 v_acc: 0.72721 |  iteration: 798 teacher: 0 stage: sketch lr: 0.000139\n",
      "batch 798 loss: 1.37363 acc: 0.73698 | v_loss: 1.26364 v_acc: 0.75423 |  iteration: 799 teacher: 1 stage: sketch lr: 0.000140\n",
      "batch 799 loss: 1.40652 acc: 0.73014 | v_loss: 1.36334 v_acc: 0.73079 |  iteration: 800 teacher: 0 stage: sketch lr: 0.000140\n",
      "batch 800 loss: 1.38060 acc: 0.74251 | v_loss: 1.42441 v_acc: 0.74837 |  iteration: 801 teacher: 1 stage: sketch lr: 0.000140\n",
      "batch 801 loss: 1.35556 acc: 0.73796 | v_loss: 1.42249 v_acc: 0.74186 |  iteration: 802 teacher: 0 stage: sketch lr: 0.000140\n",
      "batch 802 loss: 1.46253 acc: 0.72917 | v_loss: 1.37048 v_acc: 0.74414 |  iteration: 803 teacher: 1 stage: sketch lr: 0.000140\n",
      "batch 803 loss: 1.38312 acc: 0.73698 | v_loss: 1.41615 v_acc: 0.73177 |  iteration: 804 teacher: 1 stage: sketch lr: 0.000140\n",
      "batch 804 loss: 1.35009 acc: 0.74447 | v_loss: 1.35668 v_acc: 0.75065 |  iteration: 805 teacher: 0 stage: sketch lr: 0.000141\n",
      "batch 805 loss: 1.38373 acc: 0.74154 | v_loss: 1.34811 v_acc: 0.73926 |  iteration: 806 teacher: 0 stage: sketch lr: 0.000141\n",
      "batch 806 loss: 1.48969 acc: 0.72201 | v_loss: 1.52755 v_acc: 0.71094 |  iteration: 807 teacher: 1 stage: sketch lr: 0.000141\n",
      "batch 807 loss: 1.33985 acc: 0.74805 | v_loss: 1.33291 v_acc: 0.74479 |  iteration: 808 teacher: 0 stage: sketch lr: 0.000141\n",
      "batch 808 loss: 1.38359 acc: 0.73893 | v_loss: 1.38217 v_acc: 0.73730 |  iteration: 809 teacher: 0 stage: sketch lr: 0.000141\n",
      "batch 809 loss: 1.37919 acc: 0.74186 | v_loss: 1.33778 v_acc: 0.74967 |  iteration: 810 teacher: 1 stage: sketch lr: 0.000142\n",
      "batch 810 loss: 1.40766 acc: 0.73958 | v_loss: 1.39072 v_acc: 0.73470 |  iteration: 811 teacher: 0 stage: sketch lr: 0.000142\n",
      "batch 811 loss: 1.42520 acc: 0.72721 | v_loss: 1.27621 v_acc: 0.75749 |  iteration: 812 teacher: 0 stage: sketch lr: 0.000142\n",
      "batch 812 loss: 1.42765 acc: 0.72884 | v_loss: 1.40457 v_acc: 0.73665 |  iteration: 813 teacher: 1 stage: sketch lr: 0.000142\n",
      "batch 813 loss: 1.33510 acc: 0.74121 | v_loss: 1.34644 v_acc: 0.74284 |  iteration: 814 teacher: 0 stage: sketch lr: 0.000142\n",
      "batch 814 loss: 1.33490 acc: 0.74805 | v_loss: 1.44700 v_acc: 0.73503 |  iteration: 815 teacher: 0 stage: sketch lr: 0.000142\n",
      "batch 815 loss: 1.47560 acc: 0.72591 | v_loss: 1.30251 v_acc: 0.74056 |  iteration: 816 teacher: 1 stage: sketch lr: 0.000143\n",
      "batch 816 loss: 1.39089 acc: 0.73698 | v_loss: 1.37949 v_acc: 0.73405 |  iteration: 817 teacher: 1 stage: sketch lr: 0.000143\n",
      "batch 817 loss: 1.33057 acc: 0.74479 | v_loss: 1.40461 v_acc: 0.72526 |  iteration: 818 teacher: 0 stage: sketch lr: 0.000143\n",
      "batch 818 loss: 1.44351 acc: 0.72526 | v_loss: 1.30797 v_acc: 0.74642 |  iteration: 819 teacher: 0 stage: sketch lr: 0.000143\n",
      "batch 819 loss: 1.47154 acc: 0.71647 | v_loss: 1.29844 v_acc: 0.75000 |  iteration: 820 teacher: 1 stage: sketch lr: 0.000143\n",
      "batch 820 loss: 1.37801 acc: 0.73665 | v_loss: 1.30704 v_acc: 0.74251 |  iteration: 821 teacher: 1 stage: sketch lr: 0.000143\n",
      "batch 821 loss: 1.46236 acc: 0.72428 | v_loss: 1.37260 v_acc: 0.73698 |  iteration: 822 teacher: 1 stage: sketch lr: 0.000144\n",
      "batch 822 loss: 1.49213 acc: 0.71777 | v_loss: 1.36694 v_acc: 0.73763 |  iteration: 823 teacher: 1 stage: sketch lr: 0.000144\n",
      "batch 823 loss: 1.32461 acc: 0.74935 | v_loss: 1.18019 v_acc: 0.76986 |  iteration: 824 teacher: 0 stage: sketch lr: 0.000144\n",
      "batch 824 loss: 1.41062 acc: 0.73210 | v_loss: 1.40439 v_acc: 0.73633 |  iteration: 825 teacher: 1 stage: sketch lr: 0.000144\n",
      "batch 825 loss: 1.25057 acc: 0.76042 | v_loss: 1.41963 v_acc: 0.73340 |  iteration: 826 teacher: 0 stage: sketch lr: 0.000144\n",
      "batch 826 loss: 1.43779 acc: 0.73470 | v_loss: 1.41470 v_acc: 0.73893 |  iteration: 827 teacher: 1 stage: sketch lr: 0.000144\n",
      "batch 827 loss: 1.33398 acc: 0.74447 | v_loss: 1.36412 v_acc: 0.73633 |  iteration: 828 teacher: 0 stage: sketch lr: 0.000145\n",
      "batch 828 loss: 1.28787 acc: 0.75293 | v_loss: 1.34392 v_acc: 0.73796 |  iteration: 829 teacher: 0 stage: sketch lr: 0.000145\n",
      "batch 829 loss: 1.36199 acc: 0.73828 | v_loss: 1.32783 v_acc: 0.74154 |  iteration: 830 teacher: 0 stage: sketch lr: 0.000145\n",
      "batch 830 loss: 1.32688 acc: 0.74544 | v_loss: 1.30017 v_acc: 0.75260 |  iteration: 831 teacher: 1 stage: sketch lr: 0.000145\n",
      "batch 831 loss: 1.27250 acc: 0.74772 | v_loss: 1.12601 v_acc: 0.77441 |  iteration: 832 teacher: 1 stage: sketch lr: 0.000145\n",
      "batch 832 loss: 1.36643 acc: 0.74023 | v_loss: 1.25067 v_acc: 0.74967 |  iteration: 833 teacher: 1 stage: sketch lr: 0.000146\n",
      "batch 833 loss: 1.38677 acc: 0.73991 | v_loss: 1.25389 v_acc: 0.76562 |  iteration: 834 teacher: 1 stage: sketch lr: 0.000146\n",
      "batch 834 loss: 1.33807 acc: 0.73926 | v_loss: 1.28832 v_acc: 0.75944 |  iteration: 835 teacher: 1 stage: sketch lr: 0.000146\n",
      "batch 835 loss: 1.34612 acc: 0.73828 | v_loss: 1.32404 v_acc: 0.74935 |  iteration: 836 teacher: 0 stage: sketch lr: 0.000146\n",
      "batch 836 loss: 1.34933 acc: 0.73763 | v_loss: 1.29333 v_acc: 0.74935 |  iteration: 837 teacher: 1 stage: sketch lr: 0.000146\n",
      "batch 837 loss: 1.29059 acc: 0.75651 | v_loss: 1.24736 v_acc: 0.75456 |  iteration: 838 teacher: 0 stage: sketch lr: 0.000146\n",
      "batch 838 loss: 1.40332 acc: 0.73275 | v_loss: 1.36518 v_acc: 0.73600 |  iteration: 839 teacher: 0 stage: sketch lr: 0.000147\n",
      "batch 839 loss: 1.32262 acc: 0.74642 | v_loss: 1.28797 v_acc: 0.75716 |  iteration: 840 teacher: 0 stage: sketch lr: 0.000147\n",
      "batch 840 loss: 1.36744 acc: 0.73861 | v_loss: 1.09855 v_acc: 0.78581 |  iteration: 841 teacher: 1 stage: sketch lr: 0.000147\n",
      "batch 841 loss: 1.26660 acc: 0.75814 | v_loss: 1.38034 v_acc: 0.73372 |  iteration: 842 teacher: 0 stage: sketch lr: 0.000147\n",
      "batch 842 loss: 1.42852 acc: 0.73307 | v_loss: 1.32559 v_acc: 0.75000 |  iteration: 843 teacher: 0 stage: sketch lr: 0.000147\n",
      "batch 843 loss: 1.30763 acc: 0.74577 | v_loss: 1.35544 v_acc: 0.75130 |  iteration: 844 teacher: 0 stage: sketch lr: 0.000147\n",
      "batch 844 loss: 1.32508 acc: 0.74577 | v_loss: 1.25619 v_acc: 0.75944 |  iteration: 845 teacher: 0 stage: sketch lr: 0.000148\n",
      "batch 845 loss: 1.32820 acc: 0.74902 | v_loss: 1.39678 v_acc: 0.72331 |  iteration: 846 teacher: 0 stage: sketch lr: 0.000148\n",
      "batch 846 loss: 1.45015 acc: 0.73014 | v_loss: 1.37456 v_acc: 0.74089 |  iteration: 847 teacher: 1 stage: sketch lr: 0.000148\n",
      "batch 847 loss: 1.40538 acc: 0.73177 | v_loss: 1.45858 v_acc: 0.72982 |  iteration: 848 teacher: 0 stage: sketch lr: 0.000148\n",
      "batch 848 loss: 1.34180 acc: 0.73796 | v_loss: 1.34739 v_acc: 0.74316 |  iteration: 849 teacher: 0 stage: sketch lr: 0.000148\n",
      "batch 849 loss: 1.42937 acc: 0.72624 | v_loss: 1.29352 v_acc: 0.75684 |  iteration: 850 teacher: 1 stage: sketch lr: 0.000148\n",
      "batch 850 loss: 1.30826 acc: 0.74870 | v_loss: 1.26558 v_acc: 0.74674 |  iteration: 851 teacher: 1 stage: sketch lr: 0.000149\n",
      "batch 851 loss: 1.28828 acc: 0.75195 | v_loss: 1.36178 v_acc: 0.73568 |  iteration: 852 teacher: 0 stage: sketch lr: 0.000149\n",
      "batch 852 loss: 1.30263 acc: 0.74902 | v_loss: 1.33599 v_acc: 0.73828 |  iteration: 853 teacher: 0 stage: sketch lr: 0.000149\n",
      "batch 853 loss: 1.36736 acc: 0.73372 | v_loss: 1.38540 v_acc: 0.73112 |  iteration: 854 teacher: 1 stage: sketch lr: 0.000149\n",
      "batch 854 loss: 1.33921 acc: 0.74089 | v_loss: 1.24631 v_acc: 0.75684 |  iteration: 855 teacher: 1 stage: sketch lr: 0.000149\n",
      "batch 855 loss: 1.45788 acc: 0.72428 | v_loss: 1.47264 v_acc: 0.71582 |  iteration: 856 teacher: 0 stage: sketch lr: 0.000150\n",
      "batch 856 loss: 1.29852 acc: 0.74154 | v_loss: 1.33890 v_acc: 0.73698 |  iteration: 857 teacher: 1 stage: sketch lr: 0.000150\n",
      "batch 857 loss: 1.38082 acc: 0.73047 | v_loss: 1.39107 v_acc: 0.73503 |  iteration: 858 teacher: 1 stage: sketch lr: 0.000150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 858 loss: 1.44350 acc: 0.72884 | v_loss: 1.35116 v_acc: 0.73730 |  iteration: 859 teacher: 1 stage: sketch lr: 0.000150\n",
      "batch 859 loss: 1.34745 acc: 0.74023 | v_loss: 1.28735 v_acc: 0.74935 |  iteration: 860 teacher: 1 stage: sketch lr: 0.000150\n",
      "batch 860 loss: 1.28099 acc: 0.75456 | v_loss: 1.33308 v_acc: 0.74154 |  iteration: 861 teacher: 0 stage: sketch lr: 0.000150\n",
      "batch 861 loss: 1.30212 acc: 0.74479 | v_loss: 1.33077 v_acc: 0.74772 |  iteration: 862 teacher: 0 stage: sketch lr: 0.000151\n",
      "batch 862 loss: 1.42513 acc: 0.72949 | v_loss: 1.45470 v_acc: 0.72624 |  iteration: 863 teacher: 1 stage: sketch lr: 0.000151\n",
      "batch 863 loss: 1.31493 acc: 0.74577 | v_loss: 1.36901 v_acc: 0.73861 |  iteration: 864 teacher: 0 stage: sketch lr: 0.000151\n",
      "batch 864 loss: 1.35673 acc: 0.73861 | v_loss: 1.28302 v_acc: 0.74902 |  iteration: 865 teacher: 0 stage: sketch lr: 0.000151\n",
      "batch 865 loss: 1.39630 acc: 0.73600 | v_loss: 1.33842 v_acc: 0.74740 |  iteration: 866 teacher: 1 stage: sketch lr: 0.000151\n",
      "batch 866 loss: 1.34361 acc: 0.74935 | v_loss: 1.34097 v_acc: 0.74284 |  iteration: 867 teacher: 0 stage: sketch lr: 0.000151\n",
      "batch 867 loss: 1.29997 acc: 0.74609 | v_loss: 1.34426 v_acc: 0.73926 |  iteration: 868 teacher: 0 stage: sketch lr: 0.000152\n",
      "batch 868 loss: 1.32123 acc: 0.74414 | v_loss: 1.31934 v_acc: 0.74967 |  iteration: 869 teacher: 0 stage: sketch lr: 0.000152\n",
      "batch 869 loss: 1.23460 acc: 0.75879 | v_loss: 1.27404 v_acc: 0.75684 |  iteration: 870 teacher: 0 stage: sketch lr: 0.000152\n",
      "batch 870 loss: 1.34007 acc: 0.73958 | v_loss: 1.19232 v_acc: 0.76270 |  iteration: 871 teacher: 1 stage: sketch lr: 0.000152\n",
      "batch 871 loss: 1.30570 acc: 0.74772 | v_loss: 1.31684 v_acc: 0.74121 |  iteration: 872 teacher: 0 stage: sketch lr: 0.000152\n",
      "batch 872 loss: 1.35856 acc: 0.74056 | v_loss: 1.36359 v_acc: 0.73307 |  iteration: 873 teacher: 1 stage: sketch lr: 0.000153\n",
      "batch 873 loss: 1.36638 acc: 0.72754 | v_loss: 1.34967 v_acc: 0.73633 |  iteration: 874 teacher: 1 stage: sketch lr: 0.000153\n",
      "batch 874 loss: 1.32790 acc: 0.73991 | v_loss: 1.27777 v_acc: 0.75684 |  iteration: 875 teacher: 0 stage: sketch lr: 0.000153\n",
      "batch 875 loss: 1.38044 acc: 0.72884 | v_loss: 1.21275 v_acc: 0.76335 |  iteration: 876 teacher: 1 stage: sketch lr: 0.000153\n",
      "batch 876 loss: 1.33070 acc: 0.73730 | v_loss: 1.33246 v_acc: 0.74772 |  iteration: 877 teacher: 0 stage: sketch lr: 0.000153\n",
      "batch 877 loss: 1.36554 acc: 0.74089 | v_loss: 1.27366 v_acc: 0.75781 |  iteration: 878 teacher: 0 stage: sketch lr: 0.000153\n",
      "batch 878 loss: 1.33801 acc: 0.74251 | v_loss: 1.23901 v_acc: 0.76335 |  iteration: 879 teacher: 1 stage: sketch lr: 0.000154\n",
      "batch 879 loss: 1.22284 acc: 0.75456 | v_loss: 1.20263 v_acc: 0.76204 |  iteration: 880 teacher: 0 stage: sketch lr: 0.000154\n",
      "batch 880 loss: 1.32656 acc: 0.74870 | v_loss: 1.15309 v_acc: 0.76628 |  iteration: 881 teacher: 1 stage: sketch lr: 0.000154\n",
      "batch 881 loss: 1.27491 acc: 0.75716 | v_loss: 1.24381 v_acc: 0.75326 |  iteration: 882 teacher: 0 stage: sketch lr: 0.000154\n",
      "batch 882 loss: 1.31246 acc: 0.74740 | v_loss: 1.38633 v_acc: 0.72786 |  iteration: 883 teacher: 1 stage: sketch lr: 0.000154\n",
      "batch 883 loss: 1.36849 acc: 0.73991 | v_loss: 1.27582 v_acc: 0.76009 |  iteration: 884 teacher: 1 stage: sketch lr: 0.000154\n",
      "batch 884 loss: 1.33308 acc: 0.74284 | v_loss: 1.20158 v_acc: 0.77311 |  iteration: 885 teacher: 1 stage: sketch lr: 0.000155\n",
      "batch 885 loss: 1.38402 acc: 0.73796 | v_loss: 1.32938 v_acc: 0.73861 |  iteration: 886 teacher: 0 stage: sketch lr: 0.000155\n",
      "batch 886 loss: 1.26062 acc: 0.75130 | v_loss: 1.35409 v_acc: 0.74512 |  iteration: 887 teacher: 0 stage: sketch lr: 0.000155\n",
      "batch 887 loss: 1.30104 acc: 0.74837 | v_loss: 1.23119 v_acc: 0.75749 |  iteration: 888 teacher: 0 stage: sketch lr: 0.000155\n",
      "batch 888 loss: 1.32499 acc: 0.74382 | v_loss: 1.27523 v_acc: 0.74870 |  iteration: 889 teacher: 0 stage: sketch lr: 0.000155\n",
      "batch 889 loss: 1.31682 acc: 0.74870 | v_loss: 1.20002 v_acc: 0.76237 |  iteration: 890 teacher: 0 stage: sketch lr: 0.000155\n",
      "batch 890 loss: 1.36689 acc: 0.74056 | v_loss: 1.30494 v_acc: 0.74219 |  iteration: 891 teacher: 0 stage: sketch lr: 0.000156\n",
      "batch 891 loss: 1.23604 acc: 0.75195 | v_loss: 1.32730 v_acc: 0.74284 |  iteration: 892 teacher: 1 stage: sketch lr: 0.000156\n",
      "batch 892 loss: 1.36113 acc: 0.74316 | v_loss: 1.30297 v_acc: 0.75065 |  iteration: 893 teacher: 1 stage: sketch lr: 0.000156\n",
      "batch 893 loss: 1.22184 acc: 0.75391 | v_loss: 1.22954 v_acc: 0.76009 |  iteration: 894 teacher: 0 stage: sketch lr: 0.000156\n",
      "batch 894 loss: 1.25513 acc: 0.75293 | v_loss: 1.29523 v_acc: 0.74674 |  iteration: 895 teacher: 0 stage: sketch lr: 0.000156\n",
      "batch 895 loss: 1.23861 acc: 0.76270 | v_loss: 1.18717 v_acc: 0.77051 |  iteration: 896 teacher: 0 stage: sketch lr: 0.000157\n",
      "batch 896 loss: 1.32900 acc: 0.74707 | v_loss: 1.24956 v_acc: 0.75651 |  iteration: 897 teacher: 0 stage: sketch lr: 0.000157\n",
      "batch 897 loss: 1.33608 acc: 0.73893 | v_loss: 1.47284 v_acc: 0.71549 |  iteration: 898 teacher: 1 stage: sketch lr: 0.000157\n",
      "batch 898 loss: 1.29417 acc: 0.74772 | v_loss: 1.21991 v_acc: 0.75911 |  iteration: 899 teacher: 0 stage: sketch lr: 0.000157\n",
      "batch 899 loss: 1.42846 acc: 0.72266 | v_loss: 1.29748 v_acc: 0.74512 |  iteration: 900 teacher: 1 stage: sketch lr: 0.000157\n",
      "batch 900 loss: 1.26807 acc: 0.74837 | v_loss: 1.25392 v_acc: 0.76074 |  iteration: 901 teacher: 0 stage: sketch lr: 0.000157\n",
      "batch 901 loss: 1.27290 acc: 0.75716 | v_loss: 1.32482 v_acc: 0.74609 |  iteration: 902 teacher: 0 stage: sketch lr: 0.000158\n",
      "batch 902 loss: 1.23181 acc: 0.75293 | v_loss: 1.16597 v_acc: 0.76758 |  iteration: 903 teacher: 0 stage: sketch lr: 0.000158\n",
      "batch 903 loss: 1.26191 acc: 0.74902 | v_loss: 1.32877 v_acc: 0.73861 |  iteration: 904 teacher: 0 stage: sketch lr: 0.000158\n",
      "batch 904 loss: 1.36510 acc: 0.74056 | v_loss: 1.27206 v_acc: 0.74902 |  iteration: 905 teacher: 1 stage: sketch lr: 0.000158\n",
      "batch 905 loss: 1.33877 acc: 0.74251 | v_loss: 1.41602 v_acc: 0.72982 |  iteration: 906 teacher: 1 stage: sketch lr: 0.000158\n",
      "batch 906 loss: 1.28955 acc: 0.74967 | v_loss: 1.22780 v_acc: 0.75228 |  iteration: 907 teacher: 0 stage: sketch lr: 0.000158\n",
      "batch 907 loss: 1.26022 acc: 0.75391 | v_loss: 1.26436 v_acc: 0.75000 |  iteration: 908 teacher: 0 stage: sketch lr: 0.000159\n",
      "batch 908 loss: 1.28399 acc: 0.74512 | v_loss: 1.33255 v_acc: 0.74902 |  iteration: 909 teacher: 1 stage: sketch lr: 0.000159\n",
      "batch 909 loss: 1.53115 acc: 0.72233 | v_loss: 1.22757 v_acc: 0.75423 |  iteration: 910 teacher: 1 stage: sketch lr: 0.000159\n",
      "batch 910 loss: 1.26107 acc: 0.75228 | v_loss: 1.22336 v_acc: 0.76139 |  iteration: 911 teacher: 0 stage: sketch lr: 0.000159\n",
      "batch 911 loss: 1.25539 acc: 0.75130 | v_loss: 1.17012 v_acc: 0.76139 |  iteration: 912 teacher: 0 stage: sketch lr: 0.000159\n",
      "batch 912 loss: 1.29542 acc: 0.74967 | v_loss: 1.36038 v_acc: 0.74023 |  iteration: 913 teacher: 0 stage: sketch lr: 0.000159\n",
      "batch 913 loss: 1.32813 acc: 0.73275 | v_loss: 1.29619 v_acc: 0.75033 |  iteration: 914 teacher: 1 stage: sketch lr: 0.000160\n",
      "batch 914 loss: 1.26769 acc: 0.74674 | v_loss: 1.10080 v_acc: 0.77734 |  iteration: 915 teacher: 0 stage: sketch lr: 0.000160\n",
      "batch 915 loss: 1.28168 acc: 0.74642 | v_loss: 1.34444 v_acc: 0.74837 |  iteration: 916 teacher: 1 stage: sketch lr: 0.000160\n",
      "batch 916 loss: 1.38232 acc: 0.74284 | v_loss: 1.39797 v_acc: 0.73470 |  iteration: 917 teacher: 1 stage: sketch lr: 0.000160\n",
      "batch 917 loss: 1.39352 acc: 0.73730 | v_loss: 1.33275 v_acc: 0.74967 |  iteration: 918 teacher: 1 stage: sketch lr: 0.000160\n",
      "batch 918 loss: 1.26721 acc: 0.75488 | v_loss: 1.29717 v_acc: 0.74902 |  iteration: 919 teacher: 1 stage: sketch lr: 0.000161\n",
      "batch 919 loss: 1.24814 acc: 0.76204 | v_loss: 1.27608 v_acc: 0.75033 |  iteration: 920 teacher: 1 stage: sketch lr: 0.000161\n",
      "batch 920 loss: 1.27103 acc: 0.75260 | v_loss: 1.28362 v_acc: 0.75000 |  iteration: 921 teacher: 1 stage: sketch lr: 0.000161\n",
      "batch 921 loss: 1.35527 acc: 0.73535 | v_loss: 1.29389 v_acc: 0.74870 |  iteration: 922 teacher: 1 stage: sketch lr: 0.000161\n",
      "batch 922 loss: 1.34611 acc: 0.73828 | v_loss: 1.00762 v_acc: 0.78776 |  iteration: 923 teacher: 1 stage: sketch lr: 0.000161\n",
      "batch 923 loss: 1.26306 acc: 0.74349 | v_loss: 1.22300 v_acc: 0.75163 |  iteration: 924 teacher: 0 stage: sketch lr: 0.000161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 924 loss: 1.34608 acc: 0.73665 | v_loss: 1.22476 v_acc: 0.76628 |  iteration: 925 teacher: 1 stage: sketch lr: 0.000162\n",
      "batch 925 loss: 1.36061 acc: 0.73796 | v_loss: 1.17773 v_acc: 0.77018 |  iteration: 926 teacher: 1 stage: sketch lr: 0.000162\n",
      "batch 926 loss: 1.23343 acc: 0.75749 | v_loss: 1.25129 v_acc: 0.75879 |  iteration: 927 teacher: 0 stage: sketch lr: 0.000162\n",
      "batch 927 loss: 1.36808 acc: 0.73307 | v_loss: 1.25787 v_acc: 0.74186 |  iteration: 928 teacher: 1 stage: sketch lr: 0.000162\n",
      "batch 928 loss: 1.26567 acc: 0.75358 | v_loss: 1.16303 v_acc: 0.76921 |  iteration: 929 teacher: 1 stage: sketch lr: 0.000162\n",
      "batch 929 loss: 1.30751 acc: 0.74089 | v_loss: 1.31828 v_acc: 0.74251 |  iteration: 930 teacher: 0 stage: sketch lr: 0.000162\n",
      "batch 930 loss: 1.29902 acc: 0.74707 | v_loss: 1.19351 v_acc: 0.76172 |  iteration: 931 teacher: 1 stage: sketch lr: 0.000163\n",
      "batch 931 loss: 1.29431 acc: 0.74479 | v_loss: 1.04584 v_acc: 0.79395 |  iteration: 932 teacher: 1 stage: sketch lr: 0.000163\n",
      "batch 932 loss: 1.33065 acc: 0.74251 | v_loss: 1.35365 v_acc: 0.73861 |  iteration: 933 teacher: 1 stage: sketch lr: 0.000163\n",
      "batch 933 loss: 1.34865 acc: 0.73275 | v_loss: 1.24517 v_acc: 0.75326 |  iteration: 934 teacher: 1 stage: sketch lr: 0.000163\n",
      "batch 934 loss: 1.26254 acc: 0.75488 | v_loss: 1.34813 v_acc: 0.75749 |  iteration: 935 teacher: 0 stage: sketch lr: 0.000163\n",
      "batch 935 loss: 1.32365 acc: 0.74414 | v_loss: 1.19508 v_acc: 0.76562 |  iteration: 936 teacher: 0 stage: sketch lr: 0.000164\n",
      "batch 936 loss: 1.40402 acc: 0.72884 | v_loss: 1.28490 v_acc: 0.74219 |  iteration: 937 teacher: 1 stage: sketch lr: 0.000164\n",
      "batch 937 loss: 1.22851 acc: 0.75879 | v_loss: 1.30136 v_acc: 0.74935 |  iteration: 938 teacher: 0 stage: sketch lr: 0.000164\n",
      "batch 938 loss: 1.25749 acc: 0.75488 | v_loss: 1.39465 v_acc: 0.73698 |  iteration: 939 teacher: 1 stage: sketch lr: 0.000164\n",
      "batch 939 loss: 1.26916 acc: 0.75684 | v_loss: 1.23651 v_acc: 0.75618 |  iteration: 940 teacher: 1 stage: sketch lr: 0.000164\n",
      "batch 940 loss: 1.21918 acc: 0.76400 | v_loss: 1.22032 v_acc: 0.76855 |  iteration: 941 teacher: 0 stage: sketch lr: 0.000164\n",
      "batch 941 loss: 1.41241 acc: 0.73340 | v_loss: 1.12887 v_acc: 0.76888 |  iteration: 942 teacher: 1 stage: sketch lr: 0.000165\n",
      "batch 942 loss: 1.30842 acc: 0.74382 | v_loss: 1.29129 v_acc: 0.74023 |  iteration: 943 teacher: 1 stage: sketch lr: 0.000165\n",
      "batch 943 loss: 1.25606 acc: 0.75651 | v_loss: 1.24879 v_acc: 0.75977 |  iteration: 944 teacher: 1 stage: sketch lr: 0.000165\n",
      "batch 944 loss: 1.30786 acc: 0.74121 | v_loss: 1.30580 v_acc: 0.73991 |  iteration: 945 teacher: 1 stage: sketch lr: 0.000165\n",
      "batch 945 loss: 1.29341 acc: 0.75000 | v_loss: 1.16853 v_acc: 0.77148 |  iteration: 946 teacher: 0 stage: sketch lr: 0.000165\n",
      "batch 946 loss: 1.29621 acc: 0.75098 | v_loss: 1.36331 v_acc: 0.73503 |  iteration: 947 teacher: 0 stage: sketch lr: 0.000165\n",
      "batch 947 loss: 1.32544 acc: 0.74251 | v_loss: 1.29528 v_acc: 0.74935 |  iteration: 948 teacher: 0 stage: sketch lr: 0.000166\n",
      "batch 948 loss: 1.20574 acc: 0.76237 | v_loss: 1.27295 v_acc: 0.74121 |  iteration: 949 teacher: 1 stage: sketch lr: 0.000166\n",
      "batch 949 loss: 1.25844 acc: 0.74837 | v_loss: 1.30200 v_acc: 0.74414 |  iteration: 950 teacher: 1 stage: sketch lr: 0.000166\n",
      "batch 950 loss: 1.32699 acc: 0.73503 | v_loss: 1.16430 v_acc: 0.76107 |  iteration: 951 teacher: 1 stage: sketch lr: 0.000166\n",
      "batch 951 loss: 1.25529 acc: 0.74674 | v_loss: 1.24761 v_acc: 0.75911 |  iteration: 952 teacher: 1 stage: sketch lr: 0.000166\n",
      "batch 952 loss: 1.22415 acc: 0.75911 | v_loss: 1.26189 v_acc: 0.75684 |  iteration: 953 teacher: 0 stage: sketch lr: 0.000166\n",
      "batch 953 loss: 1.29991 acc: 0.74740 | v_loss: 1.40192 v_acc: 0.72689 |  iteration: 954 teacher: 0 stage: sketch lr: 0.000167\n",
      "batch 954 loss: 1.27484 acc: 0.75781 | v_loss: 1.32078 v_acc: 0.74707 |  iteration: 955 teacher: 0 stage: sketch lr: 0.000167\n",
      "batch 955 loss: 1.24999 acc: 0.75944 | v_loss: 1.21058 v_acc: 0.75130 |  iteration: 956 teacher: 1 stage: sketch lr: 0.000167\n",
      "batch 956 loss: 1.31448 acc: 0.74479 | v_loss: 1.26942 v_acc: 0.75651 |  iteration: 957 teacher: 0 stage: sketch lr: 0.000167\n",
      "batch 957 loss: 1.27517 acc: 0.74674 | v_loss: 1.28298 v_acc: 0.75065 |  iteration: 958 teacher: 1 stage: sketch lr: 0.000167\n",
      "batch 958 loss: 1.19366 acc: 0.76400 | v_loss: 1.27066 v_acc: 0.74707 |  iteration: 959 teacher: 0 stage: sketch lr: 0.000168\n",
      "batch 959 loss: 1.24156 acc: 0.76139 | v_loss: 1.20995 v_acc: 0.76074 |  iteration: 960 teacher: 0 stage: sketch lr: 0.000168\n",
      "batch 960 loss: 1.39446 acc: 0.73047 | v_loss: 1.20758 v_acc: 0.76725 |  iteration: 961 teacher: 1 stage: sketch lr: 0.000168\n",
      "batch 961 loss: 1.18075 acc: 0.76107 | v_loss: 1.13937 v_acc: 0.76888 |  iteration: 962 teacher: 0 stage: sketch lr: 0.000168\n",
      "batch 962 loss: 1.28122 acc: 0.75586 | v_loss: 1.26723 v_acc: 0.75391 |  iteration: 963 teacher: 1 stage: sketch lr: 0.000168\n",
      "batch 963 loss: 1.22440 acc: 0.75944 | v_loss: 1.24909 v_acc: 0.75163 |  iteration: 964 teacher: 1 stage: sketch lr: 0.000168\n",
      "batch 964 loss: 1.24007 acc: 0.76139 | v_loss: 1.28928 v_acc: 0.74447 |  iteration: 965 teacher: 0 stage: sketch lr: 0.000169\n",
      "batch 965 loss: 1.29047 acc: 0.74577 | v_loss: 1.22347 v_acc: 0.76432 |  iteration: 966 teacher: 1 stage: sketch lr: 0.000169\n",
      "batch 966 loss: 1.30310 acc: 0.75065 | v_loss: 1.15380 v_acc: 0.77539 |  iteration: 967 teacher: 1 stage: sketch lr: 0.000169\n",
      "batch 967 loss: 1.24085 acc: 0.75553 | v_loss: 1.22495 v_acc: 0.75326 |  iteration: 968 teacher: 1 stage: sketch lr: 0.000169\n",
      "batch 968 loss: 1.26955 acc: 0.75521 | v_loss: 1.20072 v_acc: 0.76367 |  iteration: 969 teacher: 1 stage: sketch lr: 0.000169\n",
      "batch 969 loss: 1.09171 acc: 0.77604 | v_loss: 1.18086 v_acc: 0.76074 |  iteration: 970 teacher: 0 stage: sketch lr: 0.000169\n",
      "batch 970 loss: 1.27604 acc: 0.74772 | v_loss: 1.12263 v_acc: 0.77344 |  iteration: 971 teacher: 1 stage: sketch lr: 0.000170\n",
      "batch 971 loss: 1.18950 acc: 0.76042 | v_loss: 1.09079 v_acc: 0.77246 |  iteration: 972 teacher: 0 stage: sketch lr: 0.000170\n",
      "batch 972 loss: 1.18119 acc: 0.76595 | v_loss: 1.19445 v_acc: 0.75586 |  iteration: 973 teacher: 0 stage: sketch lr: 0.000170\n",
      "batch 973 loss: 1.10804 acc: 0.77572 | v_loss: 1.29202 v_acc: 0.74089 |  iteration: 974 teacher: 0 stage: sketch lr: 0.000170\n",
      "batch 974 loss: 1.30549 acc: 0.74186 | v_loss: 1.19783 v_acc: 0.76204 |  iteration: 975 teacher: 1 stage: sketch lr: 0.000170\n",
      "batch 975 loss: 1.41198 acc: 0.73145 | v_loss: 1.16773 v_acc: 0.77832 |  iteration: 976 teacher: 1 stage: sketch lr: 0.000171\n",
      "batch 976 loss: 1.41506 acc: 0.71615 | v_loss: 1.28464 v_acc: 0.73242 |  iteration: 977 teacher: 1 stage: sketch lr: 0.000171\n",
      "batch 977 loss: 1.23782 acc: 0.75358 | v_loss: 1.27122 v_acc: 0.74316 |  iteration: 978 teacher: 1 stage: sketch lr: 0.000171\n",
      "batch 978 loss: 1.18312 acc: 0.76302 | v_loss: 1.15887 v_acc: 0.77376 |  iteration: 979 teacher: 0 stage: sketch lr: 0.000171\n",
      "batch 979 loss: 1.23691 acc: 0.75586 | v_loss: 1.18832 v_acc: 0.76172 |  iteration: 980 teacher: 1 stage: sketch lr: 0.000171\n",
      "batch 980 loss: 1.24611 acc: 0.75423 | v_loss: 1.15826 v_acc: 0.77116 |  iteration: 981 teacher: 1 stage: sketch lr: 0.000171\n",
      "batch 981 loss: 1.35511 acc: 0.74479 | v_loss: 1.31116 v_acc: 0.74805 |  iteration: 982 teacher: 1 stage: sketch lr: 0.000172\n",
      "batch 982 loss: 1.24701 acc: 0.75814 | v_loss: 1.25294 v_acc: 0.75033 |  iteration: 983 teacher: 0 stage: sketch lr: 0.000172\n",
      "batch 983 loss: 1.24538 acc: 0.75163 | v_loss: 1.24180 v_acc: 0.76270 |  iteration: 984 teacher: 1 stage: sketch lr: 0.000172\n",
      "batch 984 loss: 1.24529 acc: 0.75260 | v_loss: 1.18255 v_acc: 0.75846 |  iteration: 985 teacher: 1 stage: sketch lr: 0.000172\n",
      "batch 985 loss: 1.15663 acc: 0.76270 | v_loss: 1.24121 v_acc: 0.75260 |  iteration: 986 teacher: 0 stage: sketch lr: 0.000172\n",
      "batch 986 loss: 1.17400 acc: 0.76139 | v_loss: 1.08515 v_acc: 0.78060 |  iteration: 987 teacher: 1 stage: sketch lr: 0.000172\n",
      "batch 987 loss: 1.19292 acc: 0.76204 | v_loss: 1.12460 v_acc: 0.76855 |  iteration: 988 teacher: 0 stage: sketch lr: 0.000173\n",
      "batch 988 loss: 1.16403 acc: 0.76530 | v_loss: 1.43538 v_acc: 0.73145 |  iteration: 989 teacher: 0 stage: sketch lr: 0.000173\n",
      "batch 989 loss: 1.19038 acc: 0.75944 | v_loss: 1.13740 v_acc: 0.77018 |  iteration: 990 teacher: 0 stage: sketch lr: 0.000173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 990 loss: 1.15063 acc: 0.76628 | v_loss: 1.21929 v_acc: 0.75293 |  iteration: 991 teacher: 1 stage: sketch lr: 0.000173\n",
      "batch 991 loss: 1.19241 acc: 0.76107 | v_loss: 1.17108 v_acc: 0.76823 |  iteration: 992 teacher: 1 stage: sketch lr: 0.000173\n",
      "batch 992 loss: 1.26816 acc: 0.74642 | v_loss: 1.23739 v_acc: 0.75293 |  iteration: 993 teacher: 1 stage: sketch lr: 0.000173\n",
      "batch 993 loss: 1.23788 acc: 0.74707 | v_loss: 1.09000 v_acc: 0.77409 |  iteration: 994 teacher: 0 stage: sketch lr: 0.000174\n",
      "batch 994 loss: 1.35664 acc: 0.73112 | v_loss: 1.28598 v_acc: 0.74023 |  iteration: 995 teacher: 1 stage: sketch lr: 0.000174\n",
      "batch 995 loss: 1.25996 acc: 0.74642 | v_loss: 1.15309 v_acc: 0.76530 |  iteration: 996 teacher: 0 stage: sketch lr: 0.000174\n",
      "batch 996 loss: 1.21390 acc: 0.74512 | v_loss: 1.34637 v_acc: 0.73763 |  iteration: 997 teacher: 1 stage: sketch lr: 0.000174\n",
      "batch 997 loss: 1.28502 acc: 0.74284 | v_loss: 1.19470 v_acc: 0.75293 |  iteration: 998 teacher: 1 stage: sketch lr: 0.000174\n",
      "batch 998 loss: 1.14476 acc: 0.77018 | v_loss: 1.28535 v_acc: 0.74154 |  iteration: 999 teacher: 1 stage: sketch lr: 0.000175\n",
      "batch 999 loss: 1.23898 acc: 0.76497 | v_loss: 1.23618 v_acc: 0.74544 |  iteration: 1000 teacher: 0 stage: sketch lr: 0.000175\n",
      "batch 1000 loss: 1.15690 acc: 0.76986 | v_loss: 1.18134 v_acc: 0.75684 |  iteration: 1001 teacher: 1 stage: sketch lr: 0.000175\n",
      "batch 1001 loss: 1.21368 acc: 0.75781 | v_loss: 1.21383 v_acc: 0.76107 |  iteration: 1002 teacher: 0 stage: sketch lr: 0.000175\n",
      "batch 1002 loss: 1.24861 acc: 0.75195 | v_loss: 1.10439 v_acc: 0.76758 |  iteration: 1003 teacher: 0 stage: sketch lr: 0.000175\n",
      "batch 1003 loss: 1.29985 acc: 0.74251 | v_loss: 1.26557 v_acc: 0.74447 |  iteration: 1004 teacher: 1 stage: sketch lr: 0.000175\n",
      "batch 1004 loss: 1.26155 acc: 0.74967 | v_loss: 1.24467 v_acc: 0.75033 |  iteration: 1005 teacher: 1 stage: sketch lr: 0.000176\n",
      "batch 1005 loss: 1.24797 acc: 0.75586 | v_loss: 1.09201 v_acc: 0.77051 |  iteration: 1006 teacher: 0 stage: sketch lr: 0.000176\n",
      "batch 1006 loss: 1.25900 acc: 0.74902 | v_loss: 1.26520 v_acc: 0.74447 |  iteration: 1007 teacher: 1 stage: sketch lr: 0.000176\n",
      "batch 1007 loss: 1.21404 acc: 0.74479 | v_loss: 1.32591 v_acc: 0.74056 |  iteration: 1008 teacher: 1 stage: sketch lr: 0.000176\n",
      "batch 1008 loss: 1.14955 acc: 0.77474 | v_loss: 1.22827 v_acc: 0.74479 |  iteration: 1009 teacher: 1 stage: sketch lr: 0.000176\n",
      "batch 1009 loss: 1.17061 acc: 0.74967 | v_loss: 1.20409 v_acc: 0.75228 |  iteration: 1010 teacher: 0 stage: sketch lr: 0.000176\n",
      "batch 1010 loss: 1.19210 acc: 0.76497 | v_loss: 1.21285 v_acc: 0.75781 |  iteration: 1011 teacher: 0 stage: sketch lr: 0.000177\n",
      "batch 1011 loss: 1.17184 acc: 0.76367 | v_loss: 1.16433 v_acc: 0.76432 |  iteration: 1012 teacher: 0 stage: sketch lr: 0.000177\n",
      "batch 1012 loss: 1.26216 acc: 0.74837 | v_loss: 1.19080 v_acc: 0.77083 |  iteration: 1013 teacher: 1 stage: sketch lr: 0.000177\n",
      "batch 1013 loss: 1.36541 acc: 0.73405 | v_loss: 1.04857 v_acc: 0.78451 |  iteration: 1014 teacher: 1 stage: sketch lr: 0.000177\n",
      "batch 1014 loss: 1.25947 acc: 0.75944 | v_loss: 1.15236 v_acc: 0.76270 |  iteration: 1015 teacher: 0 stage: sketch lr: 0.000177\n",
      "batch 1015 loss: 1.18620 acc: 0.76107 | v_loss: 1.21962 v_acc: 0.76465 |  iteration: 1016 teacher: 0 stage: sketch lr: 0.000177\n",
      "batch 1016 loss: 1.14450 acc: 0.76172 | v_loss: 1.14706 v_acc: 0.76823 |  iteration: 1017 teacher: 0 stage: sketch lr: 0.000178\n",
      "batch 1017 loss: 1.15933 acc: 0.76302 | v_loss: 1.20841 v_acc: 0.76823 |  iteration: 1018 teacher: 0 stage: sketch lr: 0.000178\n",
      "batch 1018 loss: 1.22108 acc: 0.75098 | v_loss: 1.14049 v_acc: 0.76204 |  iteration: 1019 teacher: 1 stage: sketch lr: 0.000178\n",
      "batch 1019 loss: 1.33210 acc: 0.74837 | v_loss: 1.02207 v_acc: 0.78288 |  iteration: 1020 teacher: 1 stage: sketch lr: 0.000178\n",
      "batch 1020 loss: 1.13735 acc: 0.77311 | v_loss: 1.22883 v_acc: 0.74967 |  iteration: 1021 teacher: 0 stage: sketch lr: 0.000178\n",
      "batch 1021 loss: 1.16762 acc: 0.75944 | v_loss: 1.12480 v_acc: 0.76855 |  iteration: 1022 teacher: 0 stage: sketch lr: 0.000179\n",
      "batch 1022 loss: 1.14602 acc: 0.76660 | v_loss: 0.97923 v_acc: 0.79329 |  iteration: 1023 teacher: 0 stage: sketch lr: 0.000179\n",
      "batch 1023 loss: 1.21600 acc: 0.74935 | v_loss: 1.24059 v_acc: 0.75618 |  iteration: 1024 teacher: 0 stage: sketch lr: 0.000179\n",
      "batch 1024 loss: 1.21264 acc: 0.75521 | v_loss: 1.14482 v_acc: 0.76107 |  iteration: 1025 teacher: 1 stage: sketch lr: 0.000179\n",
      "batch 1025 loss: 1.21883 acc: 0.75651 | v_loss: 1.34058 v_acc: 0.73340 |  iteration: 1026 teacher: 1 stage: sketch lr: 0.000179\n",
      "batch 1026 loss: 1.32316 acc: 0.73730 | v_loss: 1.20516 v_acc: 0.75553 |  iteration: 1027 teacher: 1 stage: sketch lr: 0.000179\n",
      "batch 1027 loss: 1.15767 acc: 0.76400 | v_loss: 1.23630 v_acc: 0.73503 |  iteration: 1028 teacher: 0 stage: sketch lr: 0.000180\n",
      "batch 1028 loss: 1.20792 acc: 0.75618 | v_loss: 1.24296 v_acc: 0.75716 |  iteration: 1029 teacher: 1 stage: sketch lr: 0.000180\n",
      "batch 1029 loss: 1.29044 acc: 0.73926 | v_loss: 1.33578 v_acc: 0.74967 |  iteration: 1030 teacher: 1 stage: sketch lr: 0.000180\n",
      "batch 1030 loss: 1.24506 acc: 0.75749 | v_loss: 1.17918 v_acc: 0.76530 |  iteration: 1031 teacher: 0 stage: sketch lr: 0.000180\n",
      "batch 1031 loss: 1.09255 acc: 0.77734 | v_loss: 1.13929 v_acc: 0.76270 |  iteration: 1032 teacher: 0 stage: sketch lr: 0.000180\n",
      "batch 1032 loss: 1.11899 acc: 0.76921 | v_loss: 1.01102 v_acc: 0.77832 |  iteration: 1033 teacher: 0 stage: sketch lr: 0.000180\n",
      "batch 1033 loss: 1.31548 acc: 0.73861 | v_loss: 1.25151 v_acc: 0.75391 |  iteration: 1034 teacher: 1 stage: sketch lr: 0.000181\n",
      "batch 1034 loss: 1.16170 acc: 0.77214 | v_loss: 1.14763 v_acc: 0.77279 |  iteration: 1035 teacher: 0 stage: sketch lr: 0.000181\n",
      "batch 1035 loss: 1.16129 acc: 0.76660 | v_loss: 1.20369 v_acc: 0.75456 |  iteration: 1036 teacher: 1 stage: sketch lr: 0.000181\n",
      "batch 1036 loss: 1.11131 acc: 0.77279 | v_loss: 1.10904 v_acc: 0.77441 |  iteration: 1037 teacher: 0 stage: sketch lr: 0.000181\n",
      "batch 1037 loss: 1.20154 acc: 0.75553 | v_loss: 1.24601 v_acc: 0.74609 |  iteration: 1038 teacher: 0 stage: sketch lr: 0.000181\n",
      "batch 1038 loss: 1.26870 acc: 0.74740 | v_loss: 1.19551 v_acc: 0.76237 |  iteration: 1039 teacher: 1 stage: sketch lr: 0.000182\n",
      "batch 1039 loss: 1.13573 acc: 0.76302 | v_loss: 1.23622 v_acc: 0.73926 |  iteration: 1040 teacher: 1 stage: sketch lr: 0.000182\n",
      "batch 1040 loss: 1.17555 acc: 0.75618 | v_loss: 1.22134 v_acc: 0.74674 |  iteration: 1041 teacher: 1 stage: sketch lr: 0.000182\n",
      "batch 1041 loss: 1.28137 acc: 0.74284 | v_loss: 1.13854 v_acc: 0.76758 |  iteration: 1042 teacher: 1 stage: sketch lr: 0.000182\n",
      "batch 1042 loss: 1.15081 acc: 0.76237 | v_loss: 1.15754 v_acc: 0.76953 |  iteration: 1043 teacher: 0 stage: sketch lr: 0.000182\n",
      "batch 1043 loss: 1.20222 acc: 0.75195 | v_loss: 1.15102 v_acc: 0.76758 |  iteration: 1044 teacher: 1 stage: sketch lr: 0.000182\n",
      "batch 1044 loss: 1.10114 acc: 0.77246 | v_loss: 1.27481 v_acc: 0.74251 |  iteration: 1045 teacher: 0 stage: sketch lr: 0.000183\n",
      "batch 1045 loss: 1.21564 acc: 0.75716 | v_loss: 1.13461 v_acc: 0.76595 |  iteration: 1046 teacher: 1 stage: sketch lr: 0.000183\n",
      "batch 1046 loss: 1.22614 acc: 0.74772 | v_loss: 1.10624 v_acc: 0.76986 |  iteration: 1047 teacher: 1 stage: sketch lr: 0.000183\n",
      "batch 1047 loss: 1.08826 acc: 0.76921 | v_loss: 1.09353 v_acc: 0.77832 |  iteration: 1048 teacher: 1 stage: sketch lr: 0.000183\n",
      "batch 1048 loss: 1.16880 acc: 0.76042 | v_loss: 1.12955 v_acc: 0.77083 |  iteration: 1049 teacher: 1 stage: sketch lr: 0.000183\n",
      "batch 1049 loss: 1.03011 acc: 0.78451 | v_loss: 1.12250 v_acc: 0.76823 |  iteration: 1050 teacher: 1 stage: sketch lr: 0.000183\n",
      "batch 1050 loss: 1.07389 acc: 0.77897 | v_loss: 1.03597 v_acc: 0.78288 |  iteration: 1051 teacher: 0 stage: sketch lr: 0.000184\n",
      "batch 1051 loss: 1.11525 acc: 0.76693 | v_loss: 0.97433 v_acc: 0.79362 |  iteration: 1052 teacher: 1 stage: sketch lr: 0.000184\n",
      "batch 1052 loss: 1.06337 acc: 0.77344 | v_loss: 0.99640 v_acc: 0.79004 |  iteration: 1053 teacher: 0 stage: sketch lr: 0.000184\n",
      "batch 1053 loss: 1.08290 acc: 0.77214 | v_loss: 1.15213 v_acc: 0.75977 |  iteration: 1054 teacher: 1 stage: sketch lr: 0.000184\n",
      "batch 1054 loss: 1.11446 acc: 0.76530 | v_loss: 1.04697 v_acc: 0.77702 |  iteration: 1055 teacher: 0 stage: sketch lr: 0.000184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1055 loss: 1.00193 acc: 0.78125 | v_loss: 1.14323 v_acc: 0.75879 |  iteration: 1056 teacher: 0 stage: sketch lr: 0.000184\n",
      "batch 1056 loss: 1.07176 acc: 0.77767 | v_loss: 1.05800 v_acc: 0.78353 |  iteration: 1057 teacher: 1 stage: sketch lr: 0.000185\n",
      "batch 1057 loss: 1.10359 acc: 0.76888 | v_loss: 1.08459 v_acc: 0.77637 |  iteration: 1058 teacher: 1 stage: sketch lr: 0.000185\n",
      "batch 1058 loss: 1.07030 acc: 0.77897 | v_loss: 1.15440 v_acc: 0.76139 |  iteration: 1059 teacher: 1 stage: sketch lr: 0.000185\n",
      "batch 1059 loss: 1.01556 acc: 0.78027 | v_loss: 1.10538 v_acc: 0.77441 |  iteration: 1060 teacher: 1 stage: sketch lr: 0.000185\n",
      "batch 1060 loss: 1.03447 acc: 0.77539 | v_loss: 1.00245 v_acc: 0.78613 |  iteration: 1061 teacher: 0 stage: sketch lr: 0.000185\n",
      "batch 1061 loss: 1.12928 acc: 0.75814 | v_loss: 0.95640 v_acc: 0.79297 |  iteration: 1062 teacher: 1 stage: sketch lr: 0.000186\n",
      "batch 1062 loss: 0.97570 acc: 0.79102 | v_loss: 0.97302 v_acc: 0.78971 |  iteration: 1063 teacher: 0 stage: sketch lr: 0.000186\n",
      "batch 1063 loss: 1.05196 acc: 0.77311 | v_loss: 1.07818 v_acc: 0.77637 |  iteration: 1064 teacher: 1 stage: sketch lr: 0.000186\n",
      "batch 1064 loss: 0.97050 acc: 0.79395 | v_loss: 1.14107 v_acc: 0.76204 |  iteration: 1065 teacher: 0 stage: sketch lr: 0.000186\n",
      "batch 1065 loss: 1.05143 acc: 0.77246 | v_loss: 1.03263 v_acc: 0.78483 |  iteration: 1066 teacher: 0 stage: sketch lr: 0.000186\n",
      "batch 1066 loss: 1.18579 acc: 0.75326 | v_loss: 1.13274 v_acc: 0.77637 |  iteration: 1067 teacher: 1 stage: sketch lr: 0.000186\n",
      "batch 1067 loss: 1.10216 acc: 0.77051 | v_loss: 1.18400 v_acc: 0.75195 |  iteration: 1068 teacher: 0 stage: sketch lr: 0.000187\n",
      "batch 1068 loss: 1.05730 acc: 0.77279 | v_loss: 1.16022 v_acc: 0.76107 |  iteration: 1069 teacher: 0 stage: sketch lr: 0.000187\n",
      "batch 1069 loss: 1.00153 acc: 0.77930 | v_loss: 1.07057 v_acc: 0.77734 |  iteration: 1070 teacher: 0 stage: sketch lr: 0.000187\n",
      "batch 1070 loss: 1.17613 acc: 0.75521 | v_loss: 1.11588 v_acc: 0.76400 |  iteration: 1071 teacher: 1 stage: sketch lr: 0.000187\n",
      "batch 1071 loss: 1.03963 acc: 0.77962 | v_loss: 0.95488 v_acc: 0.79492 |  iteration: 1072 teacher: 0 stage: sketch lr: 0.000187\n",
      "batch 1072 loss: 0.99407 acc: 0.78548 | v_loss: 1.12032 v_acc: 0.77181 |  iteration: 1073 teacher: 0 stage: sketch lr: 0.000187\n",
      "batch 1073 loss: 0.93047 acc: 0.80013 | v_loss: 1.02077 v_acc: 0.78288 |  iteration: 1074 teacher: 0 stage: sketch lr: 0.000188\n",
      "batch 1074 loss: 1.10123 acc: 0.75911 | v_loss: 1.14334 v_acc: 0.77637 |  iteration: 1075 teacher: 0 stage: sketch lr: 0.000188\n",
      "batch 1075 loss: 1.01967 acc: 0.77311 | v_loss: 1.05662 v_acc: 0.77181 |  iteration: 1076 teacher: 0 stage: sketch lr: 0.000188\n",
      "batch 1076 loss: 0.98021 acc: 0.78190 | v_loss: 1.14962 v_acc: 0.75846 |  iteration: 1077 teacher: 0 stage: sketch lr: 0.000188\n",
      "batch 1077 loss: 1.12708 acc: 0.76562 | v_loss: 0.93899 v_acc: 0.78906 |  iteration: 1078 teacher: 1 stage: sketch lr: 0.000188\n",
      "batch 1078 loss: 1.07946 acc: 0.76595 | v_loss: 0.96961 v_acc: 0.78711 |  iteration: 1079 teacher: 1 stage: sketch lr: 0.000188\n",
      "batch 1079 loss: 1.28545 acc: 0.73828 | v_loss: 1.28735 v_acc: 0.73079 |  iteration: 1080 teacher: 1 stage: sketch lr: 0.000189\n",
      "batch 1080 loss: 1.03190 acc: 0.76758 | v_loss: 1.03450 v_acc: 0.78548 |  iteration: 1081 teacher: 0 stage: sketch lr: 0.000189\n",
      "batch 1081 loss: 1.04690 acc: 0.76921 | v_loss: 1.01323 v_acc: 0.78613 |  iteration: 1082 teacher: 0 stage: sketch lr: 0.000189\n",
      "batch 1082 loss: 1.16681 acc: 0.74870 | v_loss: 0.99066 v_acc: 0.78581 |  iteration: 1083 teacher: 1 stage: sketch lr: 0.000189\n",
      "batch 1083 loss: 1.02187 acc: 0.77832 | v_loss: 1.00191 v_acc: 0.78255 |  iteration: 1084 teacher: 0 stage: sketch lr: 0.000189\n",
      "batch 1084 loss: 0.96097 acc: 0.79004 | v_loss: 0.92578 v_acc: 0.80339 |  iteration: 1085 teacher: 0 stage: sketch lr: 0.000190\n",
      "batch 1085 loss: 0.96830 acc: 0.77669 | v_loss: 1.09848 v_acc: 0.76921 |  iteration: 1086 teacher: 0 stage: sketch lr: 0.000190\n",
      "batch 1086 loss: 1.00548 acc: 0.77604 | v_loss: 0.93109 v_acc: 0.78483 |  iteration: 1087 teacher: 0 stage: sketch lr: 0.000190\n",
      "batch 1087 loss: 1.09537 acc: 0.76074 | v_loss: 1.27704 v_acc: 0.74772 |  iteration: 1088 teacher: 1 stage: sketch lr: 0.000190\n",
      "batch 1088 loss: 0.98663 acc: 0.77767 | v_loss: 1.04322 v_acc: 0.77018 |  iteration: 1089 teacher: 0 stage: sketch lr: 0.000190\n",
      "batch 1089 loss: 1.06858 acc: 0.75814 | v_loss: 1.09384 v_acc: 0.76302 |  iteration: 1090 teacher: 1 stage: sketch lr: 0.000190\n",
      "batch 1090 loss: 1.07968 acc: 0.76204 | v_loss: 1.12346 v_acc: 0.76725 |  iteration: 1091 teacher: 1 stage: sketch lr: 0.000191\n",
      "batch 1091 loss: 0.99598 acc: 0.77702 | v_loss: 0.95120 v_acc: 0.79069 |  iteration: 1092 teacher: 0 stage: sketch lr: 0.000191\n",
      "batch 1092 loss: 0.93394 acc: 0.79362 | v_loss: 1.04694 v_acc: 0.78971 |  iteration: 1093 teacher: 0 stage: sketch lr: 0.000191\n",
      "batch 1093 loss: 1.01543 acc: 0.77799 | v_loss: 0.89904 v_acc: 0.79199 |  iteration: 1094 teacher: 1 stage: sketch lr: 0.000191\n",
      "batch 1094 loss: 1.04446 acc: 0.77344 | v_loss: 1.08830 v_acc: 0.76107 |  iteration: 1095 teacher: 1 stage: sketch lr: 0.000191\n",
      "batch 1095 loss: 0.98692 acc: 0.78158 | v_loss: 0.95841 v_acc: 0.78027 |  iteration: 1096 teacher: 0 stage: sketch lr: 0.000191\n",
      "batch 1096 loss: 0.96016 acc: 0.78841 | v_loss: 0.85958 v_acc: 0.80632 |  iteration: 1097 teacher: 1 stage: sketch lr: 0.000192\n",
      "batch 1097 loss: 0.94064 acc: 0.78158 | v_loss: 0.89216 v_acc: 0.78906 |  iteration: 1098 teacher: 1 stage: sketch lr: 0.000192\n",
      "batch 1098 loss: 1.08943 acc: 0.76921 | v_loss: 1.05647 v_acc: 0.76367 |  iteration: 1099 teacher: 1 stage: sketch lr: 0.000192\n",
      "batch 1099 loss: 0.87735 acc: 0.78743 | v_loss: 1.02093 v_acc: 0.76921 |  iteration: 1100 teacher: 0 stage: sketch lr: 0.000192\n",
      "batch 1100 loss: 1.18348 acc: 0.75716 | v_loss: 1.07266 v_acc: 0.76270 |  iteration: 1101 teacher: 1 stage: sketch lr: 0.000192\n",
      "batch 1101 loss: 0.93296 acc: 0.77832 | v_loss: 1.12322 v_acc: 0.76335 |  iteration: 1102 teacher: 1 stage: sketch lr: 0.000193\n",
      "batch 1102 loss: 0.92593 acc: 0.77734 | v_loss: 0.95573 v_acc: 0.78548 |  iteration: 1103 teacher: 0 stage: sketch lr: 0.000193\n",
      "batch 1103 loss: 0.79325 acc: 0.80111 | v_loss: 0.90590 v_acc: 0.79395 |  iteration: 1104 teacher: 0 stage: sketch lr: 0.000193\n",
      "batch 1104 loss: 0.91731 acc: 0.78027 | v_loss: 0.84752 v_acc: 0.80924 |  iteration: 1105 teacher: 0 stage: sketch lr: 0.000193\n",
      "batch 1105 loss: 0.88463 acc: 0.79004 | v_loss: 0.87927 v_acc: 0.79818 |  iteration: 1106 teacher: 0 stage: sketch lr: 0.000193\n",
      "batch 1106 loss: 0.92375 acc: 0.78776 | v_loss: 1.29297 v_acc: 0.75098 |  iteration: 1107 teacher: 1 stage: sketch lr: 0.000193\n",
      "batch 1107 loss: 0.99600 acc: 0.76302 | v_loss: 0.79678 v_acc: 0.80013 |  iteration: 1108 teacher: 0 stage: sketch lr: 0.000194\n",
      "batch 1108 loss: 0.96085 acc: 0.77962 | v_loss: 0.98888 v_acc: 0.77962 |  iteration: 1109 teacher: 1 stage: sketch lr: 0.000194\n",
      "batch 1109 loss: 0.96389 acc: 0.77637 | v_loss: 0.87247 v_acc: 0.78809 |  iteration: 1110 teacher: 1 stage: sketch lr: 0.000194\n",
      "batch 1110 loss: 0.91828 acc: 0.78092 | v_loss: 0.84629 v_acc: 0.80501 |  iteration: 1111 teacher: 1 stage: sketch lr: 0.000194\n",
      "batch 1111 loss: 0.99472 acc: 0.76465 | v_loss: 0.97398 v_acc: 0.78027 |  iteration: 1112 teacher: 1 stage: sketch lr: 0.000194\n",
      "batch 1112 loss: 0.90377 acc: 0.78711 | v_loss: 0.96889 v_acc: 0.78190 |  iteration: 1113 teacher: 0 stage: sketch lr: 0.000194\n",
      "batch 1113 loss: 0.84981 acc: 0.79167 | v_loss: 0.75469 v_acc: 0.81217 |  iteration: 1114 teacher: 0 stage: sketch lr: 0.000195\n",
      "batch 1114 loss: 0.95119 acc: 0.77376 | v_loss: 0.96073 v_acc: 0.76823 |  iteration: 1115 teacher: 1 stage: sketch lr: 0.000195\n",
      "batch 1115 loss: 0.88727 acc: 0.78711 | v_loss: 0.87368 v_acc: 0.78385 |  iteration: 1116 teacher: 0 stage: sketch lr: 0.000195\n",
      "batch 1116 loss: 0.81871 acc: 0.79818 | v_loss: 1.14997 v_acc: 0.75716 |  iteration: 1117 teacher: 0 stage: sketch lr: 0.000195\n",
      "batch 1117 loss: 0.83672 acc: 0.79460 | v_loss: 0.85106 v_acc: 0.79688 |  iteration: 1118 teacher: 0 stage: sketch lr: 0.000195\n",
      "batch 1118 loss: 0.77763 acc: 0.80469 | v_loss: 0.89114 v_acc: 0.77734 |  iteration: 1119 teacher: 1 stage: sketch lr: 0.000195\n",
      "batch 1119 loss: 0.85512 acc: 0.78906 | v_loss: 0.81811 v_acc: 0.79329 |  iteration: 1120 teacher: 0 stage: sketch lr: 0.000196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1120 loss: 0.80281 acc: 0.79492 | v_loss: 1.01819 v_acc: 0.76693 |  iteration: 1121 teacher: 0 stage: sketch lr: 0.000196\n",
      "batch 1121 loss: 0.95259 acc: 0.77409 | v_loss: 1.02429 v_acc: 0.77279 |  iteration: 1122 teacher: 1 stage: sketch lr: 0.000196\n",
      "batch 1122 loss: 1.54215 acc: 0.73014 | v_loss: 0.89888 v_acc: 0.78125 |  iteration: 1123 teacher: 1 stage: sketch lr: 0.000196\n",
      "batch 1123 loss: 1.01845 acc: 0.74902 | v_loss: 0.89118 v_acc: 0.77279 |  iteration: 1124 teacher: 0 stage: sketch lr: 0.000196\n",
      "batch 1124 loss: 0.84770 acc: 0.79069 | v_loss: 1.18412 v_acc: 0.74121 |  iteration: 1125 teacher: 0 stage: sketch lr: 0.000197\n",
      "batch 1125 loss: 0.86858 acc: 0.76628 | v_loss: 0.83970 v_acc: 0.79492 |  iteration: 1126 teacher: 1 stage: sketch lr: 0.000197\n",
      "batch 1126 loss: 0.81323 acc: 0.78841 | v_loss: 1.04557 v_acc: 0.77116 |  iteration: 1127 teacher: 0 stage: sketch lr: 0.000197\n",
      "batch 1127 loss: 1.08376 acc: 0.74870 | v_loss: 1.03782 v_acc: 0.76953 |  iteration: 1128 teacher: 1 stage: sketch lr: 0.000197\n",
      "batch 1128 loss: 0.94839 acc: 0.77083 | v_loss: 0.93554 v_acc: 0.77116 |  iteration: 1129 teacher: 0 stage: sketch lr: 0.000197\n",
      "batch 1129 loss: 0.79206 acc: 0.79590 | v_loss: 0.90420 v_acc: 0.77181 |  iteration: 1130 teacher: 0 stage: sketch lr: 0.000197\n",
      "batch 1130 loss: 0.88018 acc: 0.78711 | v_loss: 1.03774 v_acc: 0.75358 |  iteration: 1131 teacher: 0 stage: sketch lr: 0.000198\n",
      "batch 1131 loss: 0.81864 acc: 0.78353 | v_loss: 1.00404 v_acc: 0.77181 |  iteration: 1132 teacher: 0 stage: sketch lr: 0.000198\n",
      "batch 1132 loss: 0.75367 acc: 0.79850 | v_loss: 0.84074 v_acc: 0.80664 |  iteration: 1133 teacher: 0 stage: sketch lr: 0.000198\n",
      "batch 1133 loss: 0.99138 acc: 0.77572 | v_loss: 0.97769 v_acc: 0.78092 |  iteration: 1134 teacher: 1 stage: sketch lr: 0.000198\n",
      "batch 1134 loss: 0.87027 acc: 0.78516 | v_loss: 0.89778 v_acc: 0.80664 |  iteration: 1135 teacher: 0 stage: sketch lr: 0.000198\n",
      "batch 1135 loss: 0.79226 acc: 0.79557 | v_loss: 0.93681 v_acc: 0.76432 |  iteration: 1136 teacher: 0 stage: sketch lr: 0.000198\n",
      "batch 1136 loss: 0.78728 acc: 0.79329 | v_loss: 0.79013 v_acc: 0.79427 |  iteration: 1137 teacher: 0 stage: sketch lr: 0.000199\n",
      "batch 1137 loss: 0.80600 acc: 0.78743 | v_loss: 1.02146 v_acc: 0.77637 |  iteration: 1138 teacher: 0 stage: sketch lr: 0.000199\n",
      "batch 1138 loss: 0.71892 acc: 0.80762 | v_loss: 0.88528 v_acc: 0.79232 |  iteration: 1139 teacher: 0 stage: sketch lr: 0.000199\n",
      "batch 1139 loss: 0.80083 acc: 0.80078 | v_loss: 0.89028 v_acc: 0.79199 |  iteration: 1140 teacher: 0 stage: sketch lr: 0.000199\n",
      "batch 1140 loss: 1.17916 acc: 0.74414 | v_loss: 0.95347 v_acc: 0.77734 |  iteration: 1141 teacher: 1 stage: sketch lr: 0.000199\n",
      "batch 1141 loss: 0.85098 acc: 0.78678 | v_loss: 0.83935 v_acc: 0.80046 |  iteration: 1142 teacher: 0 stage: sketch lr: 0.000199\n",
      "batch 1142 loss: 0.89419 acc: 0.77930 | v_loss: 0.76073 v_acc: 0.80436 |  iteration: 1143 teacher: 1 stage: sketch lr: 0.000200\n",
      "batch 1143 loss: 0.87287 acc: 0.77409 | v_loss: 0.81263 v_acc: 0.80697 |  iteration: 1144 teacher: 1 stage: sketch lr: 0.000200\n",
      "batch 1144 loss: 0.78376 acc: 0.79622 | v_loss: 0.90788 v_acc: 0.78190 |  iteration: 1145 teacher: 0 stage: sketch lr: 0.000200\n",
      "batch 1145 loss: 0.70888 acc: 0.80241 | v_loss: 0.84385 v_acc: 0.79688 |  iteration: 1146 teacher: 0 stage: sketch lr: 0.000200\n",
      "batch 1146 loss: 0.73785 acc: 0.79818 | v_loss: 0.88496 v_acc: 0.79264 |  iteration: 1147 teacher: 1 stage: sketch lr: 0.000200\n",
      "batch 1147 loss: 0.81949 acc: 0.79167 | v_loss: 0.67413 v_acc: 0.82031 |  iteration: 1148 teacher: 0 stage: sketch lr: 0.000201\n",
      "batch 1148 loss: 0.71572 acc: 0.80729 | v_loss: 0.80535 v_acc: 0.79753 |  iteration: 1149 teacher: 0 stage: sketch lr: 0.000201\n",
      "batch 1149 loss: 0.73370 acc: 0.80566 | v_loss: 0.84601 v_acc: 0.78776 |  iteration: 1150 teacher: 0 stage: sketch lr: 0.000201\n",
      "batch 1150 loss: 0.80197 acc: 0.78451 | v_loss: 0.98090 v_acc: 0.78027 |  iteration: 1151 teacher: 0 stage: sketch lr: 0.000201\n",
      "batch 1151 loss: 0.67782 acc: 0.81803 | v_loss: 0.68385 v_acc: 0.81608 |  iteration: 1152 teacher: 0 stage: sketch lr: 0.000201\n",
      "batch 1152 loss: 0.78204 acc: 0.79525 | v_loss: 0.66202 v_acc: 0.82585 |  iteration: 1153 teacher: 0 stage: sketch lr: 0.000201\n",
      "batch 1153 loss: 0.74899 acc: 0.80599 | v_loss: 0.79359 v_acc: 0.81022 |  iteration: 1154 teacher: 0 stage: sketch lr: 0.000202\n",
      "batch 1154 loss: 0.70765 acc: 0.79980 | v_loss: 0.76900 v_acc: 0.81673 |  iteration: 1155 teacher: 0 stage: sketch lr: 0.000202\n",
      "batch 1155 loss: 0.69027 acc: 0.81185 | v_loss: 0.90454 v_acc: 0.78451 |  iteration: 1156 teacher: 0 stage: sketch lr: 0.000202\n",
      "batch 1156 loss: 0.91087 acc: 0.79167 | v_loss: 0.68782 v_acc: 0.83073 |  iteration: 1157 teacher: 1 stage: sketch lr: 0.000202\n",
      "batch 1157 loss: 0.66527 acc: 0.82585 | v_loss: 0.85065 v_acc: 0.80208 |  iteration: 1158 teacher: 0 stage: sketch lr: 0.000202\n",
      "batch 1158 loss: 0.93753 acc: 0.78190 | v_loss: 0.88379 v_acc: 0.77767 |  iteration: 1159 teacher: 1 stage: sketch lr: 0.000202\n",
      "batch 1159 loss: 0.70625 acc: 0.80241 | v_loss: 0.88250 v_acc: 0.77572 |  iteration: 1160 teacher: 0 stage: sketch lr: 0.000203\n",
      "batch 1160 loss: 0.70296 acc: 0.80469 | v_loss: 0.72292 v_acc: 0.81706 |  iteration: 1161 teacher: 0 stage: sketch lr: 0.000203\n",
      "batch 1161 loss: 0.64414 acc: 0.81738 | v_loss: 0.62305 v_acc: 0.82617 |  iteration: 1162 teacher: 0 stage: sketch lr: 0.000203\n",
      "batch 1162 loss: 0.69623 acc: 0.81120 | v_loss: 0.57953 v_acc: 0.84115 |  iteration: 1163 teacher: 0 stage: sketch lr: 0.000203\n",
      "batch 1163 loss: 0.58481 acc: 0.83040 | v_loss: 0.78675 v_acc: 0.81120 |  iteration: 1164 teacher: 0 stage: sketch lr: 0.000203\n",
      "batch 1164 loss: 0.78304 acc: 0.79557 | v_loss: 0.80851 v_acc: 0.80794 |  iteration: 1165 teacher: 1 stage: sketch lr: 0.000204\n",
      "batch 1165 loss: 0.84662 acc: 0.79297 | v_loss: 0.96745 v_acc: 0.79492 |  iteration: 1166 teacher: 1 stage: sketch lr: 0.000204\n",
      "batch 1166 loss: 0.64484 acc: 0.83301 | v_loss: 0.76095 v_acc: 0.81217 |  iteration: 1167 teacher: 0 stage: sketch lr: 0.000204\n",
      "batch 1167 loss: 0.79445 acc: 0.79850 | v_loss: 0.82521 v_acc: 0.80566 |  iteration: 1168 teacher: 1 stage: sketch lr: 0.000204\n",
      "batch 1168 loss: 0.71196 acc: 0.80827 | v_loss: 0.63230 v_acc: 0.83301 |  iteration: 1169 teacher: 0 stage: sketch lr: 0.000204\n",
      "batch 1169 loss: 0.69302 acc: 0.81087 | v_loss: 0.75329 v_acc: 0.81217 |  iteration: 1170 teacher: 0 stage: sketch lr: 0.000204\n",
      "batch 1170 loss: 0.66131 acc: 0.81250 | v_loss: 1.00921 v_acc: 0.77279 |  iteration: 1171 teacher: 0 stage: sketch lr: 0.000205\n",
      "batch 1171 loss: 0.73119 acc: 0.80371 | v_loss: 0.79345 v_acc: 0.81999 |  iteration: 1172 teacher: 1 stage: sketch lr: 0.000205\n",
      "batch 1172 loss: 0.69608 acc: 0.80762 | v_loss: 0.68775 v_acc: 0.81999 |  iteration: 1173 teacher: 1 stage: sketch lr: 0.000205\n",
      "batch 1173 loss: 0.59276 acc: 0.83529 | v_loss: 0.67151 v_acc: 0.82715 |  iteration: 1174 teacher: 0 stage: sketch lr: 0.000205\n",
      "batch 1174 loss: 0.60993 acc: 0.82812 | v_loss: 0.68595 v_acc: 0.82747 |  iteration: 1175 teacher: 0 stage: sketch lr: 0.000205\n",
      "batch 1175 loss: 0.89920 acc: 0.78516 | v_loss: 0.71046 v_acc: 0.82878 |  iteration: 1176 teacher: 1 stage: sketch lr: 0.000205\n",
      "batch 1176 loss: 0.81625 acc: 0.79102 | v_loss: 0.81347 v_acc: 0.80013 |  iteration: 1177 teacher: 1 stage: sketch lr: 0.000206\n",
      "batch 1177 loss: 0.82494 acc: 0.79818 | v_loss: 0.63931 v_acc: 0.83789 |  iteration: 1178 teacher: 1 stage: sketch lr: 0.000206\n",
      "batch 1178 loss: 0.73606 acc: 0.80143 | v_loss: 1.19959 v_acc: 0.77539 |  iteration: 1179 teacher: 1 stage: sketch lr: 0.000206\n",
      "batch 1179 loss: 0.78999 acc: 0.78906 | v_loss: 0.87175 v_acc: 0.79655 |  iteration: 1180 teacher: 1 stage: sketch lr: 0.000206\n",
      "batch 1180 loss: 0.65734 acc: 0.81250 | v_loss: 0.93589 v_acc: 0.79264 |  iteration: 1181 teacher: 1 stage: sketch lr: 0.000206\n",
      "batch 1181 loss: 0.76633 acc: 0.80599 | v_loss: 0.82165 v_acc: 0.80339 |  iteration: 1182 teacher: 1 stage: sketch lr: 0.000206\n",
      "batch 1182 loss: 0.65709 acc: 0.82292 | v_loss: 0.77522 v_acc: 0.80306 |  iteration: 1183 teacher: 1 stage: sketch lr: 0.000207\n",
      "batch 1183 loss: 0.60770 acc: 0.82617 | v_loss: 0.80819 v_acc: 0.80827 |  iteration: 1184 teacher: 0 stage: sketch lr: 0.000207\n",
      "batch 1184 loss: 0.59521 acc: 0.83138 | v_loss: 0.70105 v_acc: 0.83040 |  iteration: 1185 teacher: 0 stage: sketch lr: 0.000207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1185 loss: 0.74894 acc: 0.79818 | v_loss: 0.80515 v_acc: 0.80306 |  iteration: 1186 teacher: 1 stage: sketch lr: 0.000207\n",
      "batch 1186 loss: 0.91563 acc: 0.76888 | v_loss: 0.78444 v_acc: 0.81803 |  iteration: 1187 teacher: 1 stage: sketch lr: 0.000207\n",
      "batch 1187 loss: 0.75221 acc: 0.80859 | v_loss: 0.76004 v_acc: 0.81543 |  iteration: 1188 teacher: 1 stage: sketch lr: 0.000208\n",
      "batch 1188 loss: 0.79354 acc: 0.80208 | v_loss: 0.64572 v_acc: 0.83366 |  iteration: 1189 teacher: 1 stage: sketch lr: 0.000208\n",
      "batch 1189 loss: 0.61516 acc: 0.82975 | v_loss: 0.85882 v_acc: 0.79785 |  iteration: 1190 teacher: 0 stage: sketch lr: 0.000208\n",
      "batch 1190 loss: 0.67312 acc: 0.81022 | v_loss: 0.78414 v_acc: 0.80176 |  iteration: 1191 teacher: 0 stage: sketch lr: 0.000208\n",
      "batch 1191 loss: 0.95914 acc: 0.75814 | v_loss: 0.85074 v_acc: 0.79720 |  iteration: 1192 teacher: 1 stage: sketch lr: 0.000208\n",
      "batch 1192 loss: 0.66393 acc: 0.82227 | v_loss: 1.11629 v_acc: 0.78190 |  iteration: 1193 teacher: 0 stage: sketch lr: 0.000208\n",
      "batch 1193 loss: 0.90373 acc: 0.78027 | v_loss: 0.72323 v_acc: 0.82324 |  iteration: 1194 teacher: 1 stage: sketch lr: 0.000209\n",
      "batch 1194 loss: 0.63114 acc: 0.83073 | v_loss: 0.74538 v_acc: 0.81641 |  iteration: 1195 teacher: 0 stage: sketch lr: 0.000209\n",
      "batch 1195 loss: 0.92400 acc: 0.77018 | v_loss: 0.73946 v_acc: 0.82780 |  iteration: 1196 teacher: 1 stage: sketch lr: 0.000209\n",
      "batch 1196 loss: 0.74054 acc: 0.80990 | v_loss: 0.67241 v_acc: 0.82910 |  iteration: 1197 teacher: 1 stage: sketch lr: 0.000209\n",
      "batch 1197 loss: 0.64117 acc: 0.82975 | v_loss: 1.09818 v_acc: 0.78288 |  iteration: 1198 teacher: 0 stage: sketch lr: 0.000209\n",
      "batch 1198 loss: 0.92323 acc: 0.76855 | v_loss: 0.64137 v_acc: 0.83691 |  iteration: 1199 teacher: 1 stage: sketch lr: 0.000209\n",
      "batch 1199 loss: 0.70092 acc: 0.81934 | v_loss: 0.84627 v_acc: 0.80729 |  iteration: 1200 teacher: 0 stage: sketch lr: 0.000210\n",
      "batch 1200 loss: 0.73051 acc: 0.80957 | v_loss: 0.71925 v_acc: 0.82845 |  iteration: 1201 teacher: 0 stage: sketch lr: 0.000210\n",
      "batch 1201 loss: 0.69801 acc: 0.81022 | v_loss: 0.67765 v_acc: 0.82259 |  iteration: 1202 teacher: 1 stage: sketch lr: 0.000210\n",
      "batch 1202 loss: 0.74797 acc: 0.80371 | v_loss: 0.80423 v_acc: 0.80632 |  iteration: 1203 teacher: 0 stage: sketch lr: 0.000210\n",
      "batch 1203 loss: 0.65998 acc: 0.82585 | v_loss: 0.83307 v_acc: 0.80078 |  iteration: 1204 teacher: 0 stage: sketch lr: 0.000210\n",
      "batch 1204 loss: 0.56891 acc: 0.83138 | v_loss: 0.64115 v_acc: 0.83887 |  iteration: 1205 teacher: 0 stage: sketch lr: 0.000211\n",
      "batch 1205 loss: 0.62429 acc: 0.82552 | v_loss: 0.85286 v_acc: 0.79915 |  iteration: 1206 teacher: 1 stage: sketch lr: 0.000211\n",
      "batch 1206 loss: 0.67027 acc: 0.81087 | v_loss: 0.66679 v_acc: 0.82715 |  iteration: 1207 teacher: 1 stage: sketch lr: 0.000211\n",
      "batch 1207 loss: 0.66611 acc: 0.80924 | v_loss: 1.03138 v_acc: 0.78678 |  iteration: 1208 teacher: 1 stage: sketch lr: 0.000211\n",
      "batch 1208 loss: 0.53447 acc: 0.84473 | v_loss: 0.71543 v_acc: 0.83203 |  iteration: 1209 teacher: 0 stage: sketch lr: 0.000211\n",
      "batch 1209 loss: 0.56385 acc: 0.84180 | v_loss: 0.74515 v_acc: 0.82129 |  iteration: 1210 teacher: 1 stage: sketch lr: 0.000211\n",
      "batch 1210 loss: 0.61532 acc: 0.82650 | v_loss: 0.58902 v_acc: 0.84049 |  iteration: 1211 teacher: 0 stage: sketch lr: 0.000212\n",
      "batch 1211 loss: 0.72738 acc: 0.81055 | v_loss: 0.87000 v_acc: 0.79785 |  iteration: 1212 teacher: 1 stage: sketch lr: 0.000212\n",
      "batch 1212 loss: 0.55007 acc: 0.84245 | v_loss: 0.74291 v_acc: 0.82487 |  iteration: 1213 teacher: 0 stage: sketch lr: 0.000212\n",
      "batch 1213 loss: 0.63826 acc: 0.82780 | v_loss: 0.66919 v_acc: 0.82422 |  iteration: 1214 teacher: 1 stage: sketch lr: 0.000212\n",
      "batch 1214 loss: 0.63687 acc: 0.82975 | v_loss: 0.60481 v_acc: 0.83724 |  iteration: 1215 teacher: 0 stage: sketch lr: 0.000212\n",
      "batch 1215 loss: 0.58946 acc: 0.83561 | v_loss: 0.83689 v_acc: 0.80078 |  iteration: 1216 teacher: 1 stage: sketch lr: 0.000212\n",
      "batch 1216 loss: 0.85904 acc: 0.79036 | v_loss: 0.72808 v_acc: 0.83171 |  iteration: 1217 teacher: 1 stage: sketch lr: 0.000213\n",
      "batch 1217 loss: 0.57245 acc: 0.83105 | v_loss: 0.84703 v_acc: 0.79590 |  iteration: 1218 teacher: 0 stage: sketch lr: 0.000213\n",
      "batch 1218 loss: 0.70970 acc: 0.81641 | v_loss: 0.83232 v_acc: 0.79297 |  iteration: 1219 teacher: 1 stage: sketch lr: 0.000213\n",
      "batch 1219 loss: 0.69950 acc: 0.80892 | v_loss: 0.77669 v_acc: 0.80436 |  iteration: 1220 teacher: 1 stage: sketch lr: 0.000213\n",
      "batch 1220 loss: 0.65206 acc: 0.81348 | v_loss: 0.75876 v_acc: 0.80371 |  iteration: 1221 teacher: 1 stage: sketch lr: 0.000213\n",
      "batch 1221 loss: 0.57085 acc: 0.83398 | v_loss: 0.82202 v_acc: 0.80241 |  iteration: 1222 teacher: 1 stage: sketch lr: 0.000213\n",
      "batch 1222 loss: 0.52133 acc: 0.84570 | v_loss: 0.84800 v_acc: 0.80013 |  iteration: 1223 teacher: 0 stage: sketch lr: 0.000214\n",
      "batch 1223 loss: 0.57857 acc: 0.84049 | v_loss: 0.70785 v_acc: 0.83496 |  iteration: 1224 teacher: 0 stage: sketch lr: 0.000214\n",
      "batch 1224 loss: 0.56713 acc: 0.83659 | v_loss: 0.78787 v_acc: 0.81673 |  iteration: 1225 teacher: 0 stage: sketch lr: 0.000214\n",
      "batch 1225 loss: 0.67254 acc: 0.82552 | v_loss: 0.77511 v_acc: 0.83301 |  iteration: 1226 teacher: 1 stage: sketch lr: 0.000214\n",
      "batch 1226 loss: 0.66771 acc: 0.82454 | v_loss: 0.80068 v_acc: 0.79362 |  iteration: 1227 teacher: 1 stage: sketch lr: 0.000214\n",
      "batch 1227 loss: 0.64138 acc: 0.82585 | v_loss: 0.65915 v_acc: 0.82878 |  iteration: 1228 teacher: 1 stage: sketch lr: 0.000215\n",
      "batch 1228 loss: 0.55120 acc: 0.84212 | v_loss: 0.90956 v_acc: 0.80273 |  iteration: 1229 teacher: 0 stage: sketch lr: 0.000215\n",
      "batch 1229 loss: 0.55802 acc: 0.83724 | v_loss: 0.75486 v_acc: 0.82389 |  iteration: 1230 teacher: 0 stage: sketch lr: 0.000215\n",
      "batch 1230 loss: 0.49141 acc: 0.85872 | v_loss: 0.70187 v_acc: 0.82715 |  iteration: 1231 teacher: 0 stage: sketch lr: 0.000215\n",
      "batch 1231 loss: 0.53363 acc: 0.85026 | v_loss: 0.71856 v_acc: 0.81738 |  iteration: 1232 teacher: 0 stage: sketch lr: 0.000215\n",
      "batch 1232 loss: 0.67413 acc: 0.81120 | v_loss: 0.67851 v_acc: 0.83757 |  iteration: 1233 teacher: 1 stage: sketch lr: 0.000215\n",
      "batch 1233 loss: 0.54076 acc: 0.85124 | v_loss: 0.58931 v_acc: 0.84570 |  iteration: 1234 teacher: 0 stage: sketch lr: 0.000216\n",
      "batch 1234 loss: 0.78191 acc: 0.79232 | v_loss: 0.67936 v_acc: 0.83952 |  iteration: 1235 teacher: 1 stage: sketch lr: 0.000216\n",
      "batch 1235 loss: 0.72528 acc: 0.80827 | v_loss: 0.82052 v_acc: 0.79167 |  iteration: 1236 teacher: 1 stage: sketch lr: 0.000216\n",
      "batch 1236 loss: 0.55292 acc: 0.83008 | v_loss: 0.79493 v_acc: 0.81803 |  iteration: 1237 teacher: 0 stage: sketch lr: 0.000216\n",
      "batch 1237 loss: 0.61390 acc: 0.83496 | v_loss: 0.77814 v_acc: 0.81966 |  iteration: 1238 teacher: 1 stage: sketch lr: 0.000216\n",
      "batch 1238 loss: 0.53025 acc: 0.85091 | v_loss: 0.55599 v_acc: 0.85026 |  iteration: 1239 teacher: 0 stage: sketch lr: 0.000216\n",
      "batch 1239 loss: 0.58563 acc: 0.84180 | v_loss: 0.73810 v_acc: 0.82292 |  iteration: 1240 teacher: 0 stage: sketch lr: 0.000217\n",
      "batch 1240 loss: 0.57522 acc: 0.84245 | v_loss: 0.71813 v_acc: 0.81868 |  iteration: 1241 teacher: 0 stage: sketch lr: 0.000217\n",
      "batch 1241 loss: 0.67729 acc: 0.82064 | v_loss: 0.92303 v_acc: 0.79655 |  iteration: 1242 teacher: 1 stage: sketch lr: 0.000217\n",
      "batch 1242 loss: 0.56846 acc: 0.83659 | v_loss: 0.58971 v_acc: 0.83268 |  iteration: 1243 teacher: 1 stage: sketch lr: 0.000217\n",
      "epoch 0 loss: 1.48469 acc: 0.72913 | v_loss: 1.46098 v_acc: 0.73265 \n",
      "epoch: 1\n",
      "__________________________________________\n",
      "batch 0 loss: 0.62131 acc: 0.82650 | v_loss: 0.78064 v_acc: 0.82227 |  iteration: 1244 teacher: 1 stage: sketch lr: 0.000217\n",
      "batch 1 loss: 0.51198 acc: 0.85286 | v_loss: 0.68246 v_acc: 0.83431 |  iteration: 1245 teacher: 0 stage: sketch lr: 0.000217\n",
      "batch 2 loss: 0.71194 acc: 0.81185 | v_loss: 0.72277 v_acc: 0.82031 |  iteration: 1246 teacher: 1 stage: sketch lr: 0.000218\n",
      "batch 3 loss: 0.64629 acc: 0.82357 | v_loss: 0.70833 v_acc: 0.84017 |  iteration: 1247 teacher: 1 stage: sketch lr: 0.000218\n",
      "batch 4 loss: 0.55018 acc: 0.85286 | v_loss: 0.66387 v_acc: 0.83887 |  iteration: 1248 teacher: 0 stage: sketch lr: 0.000218\n",
      "batch 5 loss: 0.47242 acc: 0.86035 | v_loss: 0.51627 v_acc: 0.85840 |  iteration: 1249 teacher: 0 stage: sketch lr: 0.000218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 6 loss: 0.50044 acc: 0.84570 | v_loss: 0.76585 v_acc: 0.81608 |  iteration: 1250 teacher: 0 stage: sketch lr: 0.000218\n",
      "batch 7 loss: 0.53877 acc: 0.84570 | v_loss: 0.71218 v_acc: 0.81836 |  iteration: 1251 teacher: 0 stage: sketch lr: 0.000219\n",
      "batch 8 loss: 0.72752 acc: 0.80078 | v_loss: 0.76889 v_acc: 0.81608 |  iteration: 1252 teacher: 1 stage: sketch lr: 0.000219\n",
      "batch 9 loss: 0.62822 acc: 0.82780 | v_loss: 0.99423 v_acc: 0.79069 |  iteration: 1253 teacher: 1 stage: sketch lr: 0.000219\n",
      "batch 10 loss: 0.59582 acc: 0.82975 | v_loss: 0.63576 v_acc: 0.84115 |  iteration: 1254 teacher: 1 stage: sketch lr: 0.000219\n",
      "batch 11 loss: 0.53713 acc: 0.84635 | v_loss: 0.69759 v_acc: 0.82845 |  iteration: 1255 teacher: 0 stage: sketch lr: 0.000219\n",
      "batch 12 loss: 0.52773 acc: 0.83984 | v_loss: 0.66473 v_acc: 0.84668 |  iteration: 1256 teacher: 1 stage: sketch lr: 0.000219\n",
      "batch 13 loss: 0.68889 acc: 0.80436 | v_loss: 0.57604 v_acc: 0.85449 |  iteration: 1257 teacher: 1 stage: sketch lr: 0.000220\n",
      "batch 14 loss: 0.61708 acc: 0.83659 | v_loss: 1.09388 v_acc: 0.79102 |  iteration: 1258 teacher: 1 stage: sketch lr: 0.000220\n",
      "batch 15 loss: 0.57293 acc: 0.83659 | v_loss: 0.54973 v_acc: 0.85742 |  iteration: 1259 teacher: 0 stage: sketch lr: 0.000220\n",
      "batch 16 loss: 0.54957 acc: 0.83822 | v_loss: 0.71892 v_acc: 0.83789 |  iteration: 1260 teacher: 1 stage: sketch lr: 0.000220\n",
      "batch 17 loss: 0.51893 acc: 0.84798 | v_loss: 0.66611 v_acc: 0.83236 |  iteration: 1261 teacher: 0 stage: sketch lr: 0.000220\n",
      "batch 18 loss: 0.63724 acc: 0.83268 | v_loss: 0.58305 v_acc: 0.85514 |  iteration: 1262 teacher: 1 stage: sketch lr: 0.000220\n",
      "batch 19 loss: 0.63932 acc: 0.82357 | v_loss: 0.72122 v_acc: 0.82324 |  iteration: 1263 teacher: 1 stage: sketch lr: 0.000221\n",
      "batch 20 loss: 0.61770 acc: 0.83008 | v_loss: 0.79536 v_acc: 0.81673 |  iteration: 1264 teacher: 1 stage: sketch lr: 0.000221\n",
      "batch 21 loss: 0.59327 acc: 0.83431 | v_loss: 0.57418 v_acc: 0.85319 |  iteration: 1265 teacher: 1 stage: sketch lr: 0.000221\n",
      "batch 22 loss: 0.57840 acc: 0.83268 | v_loss: 0.75299 v_acc: 0.82129 |  iteration: 1266 teacher: 1 stage: sketch lr: 0.000221\n",
      "batch 23 loss: 0.59130 acc: 0.82682 | v_loss: 0.57403 v_acc: 0.84538 |  iteration: 1267 teacher: 0 stage: sketch lr: 0.000221\n",
      "batch 24 loss: 0.51415 acc: 0.85482 | v_loss: 1.01139 v_acc: 0.80078 |  iteration: 1268 teacher: 0 stage: sketch lr: 0.000222\n",
      "batch 25 loss: 0.52277 acc: 0.84375 | v_loss: 0.66780 v_acc: 0.83919 |  iteration: 1269 teacher: 0 stage: sketch lr: 0.000222\n",
      "batch 26 loss: 0.48041 acc: 0.85612 | v_loss: 0.70012 v_acc: 0.82585 |  iteration: 1270 teacher: 0 stage: sketch lr: 0.000222\n",
      "batch 27 loss: 0.46680 acc: 0.86296 | v_loss: 0.56660 v_acc: 0.84342 |  iteration: 1271 teacher: 0 stage: sketch lr: 0.000222\n",
      "batch 28 loss: 0.55282 acc: 0.83789 | v_loss: 0.82616 v_acc: 0.80501 |  iteration: 1272 teacher: 0 stage: sketch lr: 0.000222\n",
      "batch 29 loss: 0.46318 acc: 0.86882 | v_loss: 0.64479 v_acc: 0.83626 |  iteration: 1273 teacher: 0 stage: sketch lr: 0.000222\n",
      "batch 30 loss: 0.54270 acc: 0.84115 | v_loss: 0.65761 v_acc: 0.83008 |  iteration: 1274 teacher: 0 stage: sketch lr: 0.000223\n",
      "batch 31 loss: 0.50640 acc: 0.85319 | v_loss: 0.57636 v_acc: 0.84538 |  iteration: 1275 teacher: 0 stage: sketch lr: 0.000223\n",
      "batch 32 loss: 0.66992 acc: 0.82585 | v_loss: 0.88528 v_acc: 0.79395 |  iteration: 1276 teacher: 1 stage: sketch lr: 0.000223\n",
      "batch 33 loss: 0.56959 acc: 0.84570 | v_loss: 0.66927 v_acc: 0.84082 |  iteration: 1277 teacher: 1 stage: sketch lr: 0.000223\n",
      "batch 34 loss: 0.59177 acc: 0.83626 | v_loss: 0.76743 v_acc: 0.81901 |  iteration: 1278 teacher: 1 stage: sketch lr: 0.000223\n",
      "batch 35 loss: 0.53295 acc: 0.84961 | v_loss: 0.80265 v_acc: 0.81152 |  iteration: 1279 teacher: 1 stage: sketch lr: 0.000223\n",
      "batch 36 loss: 0.55327 acc: 0.84505 | v_loss: 0.67994 v_acc: 0.83040 |  iteration: 1280 teacher: 0 stage: sketch lr: 0.000224\n",
      "batch 37 loss: 0.66002 acc: 0.81478 | v_loss: 0.64583 v_acc: 0.82878 |  iteration: 1281 teacher: 1 stage: sketch lr: 0.000224\n",
      "batch 38 loss: 0.64223 acc: 0.82552 | v_loss: 0.71453 v_acc: 0.82878 |  iteration: 1282 teacher: 1 stage: sketch lr: 0.000224\n",
      "batch 39 loss: 0.61416 acc: 0.83789 | v_loss: 0.81077 v_acc: 0.81217 |  iteration: 1283 teacher: 1 stage: sketch lr: 0.000224\n",
      "batch 40 loss: 0.61118 acc: 0.83105 | v_loss: 0.69972 v_acc: 0.82943 |  iteration: 1284 teacher: 0 stage: sketch lr: 0.000224\n",
      "batch 41 loss: 0.51457 acc: 0.85124 | v_loss: 0.70547 v_acc: 0.83073 |  iteration: 1285 teacher: 0 stage: sketch lr: 0.000224\n",
      "batch 42 loss: 0.53486 acc: 0.84017 | v_loss: 0.75379 v_acc: 0.82682 |  iteration: 1286 teacher: 1 stage: sketch lr: 0.000225\n",
      "batch 43 loss: 0.54341 acc: 0.84440 | v_loss: 0.79583 v_acc: 0.80111 |  iteration: 1287 teacher: 1 stage: sketch lr: 0.000225\n",
      "batch 44 loss: 0.54526 acc: 0.84212 | v_loss: 0.61531 v_acc: 0.83887 |  iteration: 1288 teacher: 1 stage: sketch lr: 0.000225\n",
      "batch 45 loss: 0.56937 acc: 0.83822 | v_loss: 0.89847 v_acc: 0.80566 |  iteration: 1289 teacher: 0 stage: sketch lr: 0.000225\n",
      "batch 46 loss: 0.52813 acc: 0.84473 | v_loss: 0.75143 v_acc: 0.82357 |  iteration: 1290 teacher: 1 stage: sketch lr: 0.000225\n",
      "batch 47 loss: 0.61514 acc: 0.82617 | v_loss: 0.75106 v_acc: 0.81706 |  iteration: 1291 teacher: 1 stage: sketch lr: 0.000226\n",
      "batch 48 loss: 0.56738 acc: 0.84310 | v_loss: 0.68932 v_acc: 0.82487 |  iteration: 1292 teacher: 0 stage: sketch lr: 0.000226\n",
      "batch 49 loss: 0.57276 acc: 0.83789 | v_loss: 0.68401 v_acc: 0.83236 |  iteration: 1293 teacher: 1 stage: sketch lr: 0.000226\n",
      "batch 50 loss: 0.56727 acc: 0.84147 | v_loss: 0.60456 v_acc: 0.84961 |  iteration: 1294 teacher: 0 stage: sketch lr: 0.000226\n",
      "batch 51 loss: 0.59801 acc: 0.83464 | v_loss: 0.63918 v_acc: 0.84310 |  iteration: 1295 teacher: 1 stage: sketch lr: 0.000226\n",
      "batch 52 loss: 0.61703 acc: 0.82552 | v_loss: 0.83624 v_acc: 0.79850 |  iteration: 1296 teacher: 1 stage: sketch lr: 0.000226\n",
      "batch 53 loss: 0.52483 acc: 0.85189 | v_loss: 0.74017 v_acc: 0.84375 |  iteration: 1297 teacher: 0 stage: sketch lr: 0.000227\n",
      "batch 54 loss: 0.47666 acc: 0.86556 | v_loss: 0.74535 v_acc: 0.83561 |  iteration: 1298 teacher: 0 stage: sketch lr: 0.000227\n",
      "batch 55 loss: 0.56291 acc: 0.83822 | v_loss: 0.55060 v_acc: 0.85905 |  iteration: 1299 teacher: 1 stage: sketch lr: 0.000227\n",
      "batch 56 loss: 0.57371 acc: 0.84831 | v_loss: 0.71724 v_acc: 0.83464 |  iteration: 1300 teacher: 0 stage: sketch lr: 0.000227\n",
      "batch 57 loss: 0.51399 acc: 0.85189 | v_loss: 0.67809 v_acc: 0.83138 |  iteration: 1301 teacher: 0 stage: sketch lr: 0.000227\n",
      "batch 58 loss: 0.51720 acc: 0.84147 | v_loss: 0.91551 v_acc: 0.79850 |  iteration: 1302 teacher: 1 stage: sketch lr: 0.000227\n",
      "batch 59 loss: 0.55820 acc: 0.84147 | v_loss: 0.51781 v_acc: 0.85026 |  iteration: 1303 teacher: 0 stage: sketch lr: 0.000228\n",
      "batch 60 loss: 0.55685 acc: 0.84635 | v_loss: 0.46913 v_acc: 0.86947 |  iteration: 1304 teacher: 0 stage: sketch lr: 0.000228\n",
      "batch 61 loss: 0.47042 acc: 0.85710 | v_loss: 0.68021 v_acc: 0.85026 |  iteration: 1305 teacher: 0 stage: sketch lr: 0.000228\n",
      "batch 62 loss: 0.40762 acc: 0.87793 | v_loss: 0.70148 v_acc: 0.83789 |  iteration: 1306 teacher: 0 stage: sketch lr: 0.000228\n",
      "batch 63 loss: 0.74274 acc: 0.79915 | v_loss: 0.78993 v_acc: 0.81999 |  iteration: 1307 teacher: 1 stage: sketch lr: 0.000228\n",
      "batch 64 loss: 0.55520 acc: 0.83529 | v_loss: 0.59034 v_acc: 0.85059 |  iteration: 1308 teacher: 1 stage: sketch lr: 0.000228\n",
      "batch 65 loss: 0.49471 acc: 0.85579 | v_loss: 0.69517 v_acc: 0.82943 |  iteration: 1309 teacher: 0 stage: sketch lr: 0.000229\n",
      "batch 66 loss: 0.48462 acc: 0.85286 | v_loss: 0.82585 v_acc: 0.79460 |  iteration: 1310 teacher: 0 stage: sketch lr: 0.000229\n",
      "batch 67 loss: 0.42662 acc: 0.87435 | v_loss: 0.82051 v_acc: 0.80078 |  iteration: 1311 teacher: 0 stage: sketch lr: 0.000229\n",
      "batch 68 loss: 0.65321 acc: 0.82520 | v_loss: 0.62103 v_acc: 0.84798 |  iteration: 1312 teacher: 1 stage: sketch lr: 0.000229\n",
      "batch 69 loss: 0.63810 acc: 0.82129 | v_loss: 0.59233 v_acc: 0.84733 |  iteration: 1313 teacher: 1 stage: sketch lr: 0.000229\n",
      "batch 70 loss: 0.59809 acc: 0.83822 | v_loss: 0.45266 v_acc: 0.87793 |  iteration: 1314 teacher: 1 stage: sketch lr: 0.000230\n",
      "batch 71 loss: 0.52313 acc: 0.85286 | v_loss: 0.64111 v_acc: 0.84440 |  iteration: 1315 teacher: 0 stage: sketch lr: 0.000230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 72 loss: 0.49089 acc: 0.85417 | v_loss: 0.62646 v_acc: 0.83822 |  iteration: 1316 teacher: 0 stage: sketch lr: 0.000230\n",
      "batch 73 loss: 0.72865 acc: 0.81250 | v_loss: 0.90552 v_acc: 0.81543 |  iteration: 1317 teacher: 1 stage: sketch lr: 0.000230\n",
      "batch 74 loss: 0.47858 acc: 0.86198 | v_loss: 0.68122 v_acc: 0.82975 |  iteration: 1318 teacher: 0 stage: sketch lr: 0.000230\n",
      "batch 75 loss: 0.48360 acc: 0.85547 | v_loss: 0.77781 v_acc: 0.82194 |  iteration: 1319 teacher: 0 stage: sketch lr: 0.000230\n",
      "batch 76 loss: 0.43896 acc: 0.86751 | v_loss: 0.55880 v_acc: 0.85807 |  iteration: 1320 teacher: 0 stage: sketch lr: 0.000231\n",
      "batch 77 loss: 0.56880 acc: 0.84375 | v_loss: 0.70612 v_acc: 0.83105 |  iteration: 1321 teacher: 1 stage: sketch lr: 0.000231\n",
      "batch 78 loss: 0.53573 acc: 0.84375 | v_loss: 0.90773 v_acc: 0.79102 |  iteration: 1322 teacher: 0 stage: sketch lr: 0.000231\n",
      "batch 79 loss: 0.59523 acc: 0.84245 | v_loss: 0.68773 v_acc: 0.84115 |  iteration: 1323 teacher: 1 stage: sketch lr: 0.000231\n",
      "batch 80 loss: 0.46863 acc: 0.86751 | v_loss: 0.62828 v_acc: 0.85221 |  iteration: 1324 teacher: 1 stage: sketch lr: 0.000231\n",
      "batch 81 loss: 0.55001 acc: 0.85189 | v_loss: 0.59918 v_acc: 0.84635 |  iteration: 1325 teacher: 1 stage: sketch lr: 0.000231\n",
      "batch 82 loss: 0.49755 acc: 0.85254 | v_loss: 0.58187 v_acc: 0.85514 |  iteration: 1326 teacher: 0 stage: sketch lr: 0.000232\n",
      "batch 83 loss: 0.47106 acc: 0.86133 | v_loss: 0.61720 v_acc: 0.84635 |  iteration: 1327 teacher: 0 stage: sketch lr: 0.000232\n",
      "batch 84 loss: 0.50965 acc: 0.85449 | v_loss: 0.75408 v_acc: 0.81608 |  iteration: 1328 teacher: 0 stage: sketch lr: 0.000232\n",
      "batch 85 loss: 0.49640 acc: 0.85905 | v_loss: 0.49277 v_acc: 0.87663 |  iteration: 1329 teacher: 0 stage: sketch lr: 0.000232\n",
      "batch 86 loss: 0.48710 acc: 0.85514 | v_loss: 1.06406 v_acc: 0.80111 |  iteration: 1330 teacher: 0 stage: sketch lr: 0.000232\n",
      "batch 87 loss: 0.44076 acc: 0.87305 | v_loss: 0.79830 v_acc: 0.82324 |  iteration: 1331 teacher: 0 stage: sketch lr: 0.000233\n",
      "batch 88 loss: 0.47240 acc: 0.86198 | v_loss: 0.80354 v_acc: 0.81999 |  iteration: 1332 teacher: 0 stage: sketch lr: 0.000233\n",
      "batch 89 loss: 0.57614 acc: 0.82682 | v_loss: 0.68026 v_acc: 0.84798 |  iteration: 1333 teacher: 1 stage: sketch lr: 0.000233\n",
      "batch 90 loss: 0.49481 acc: 0.86068 | v_loss: 0.64389 v_acc: 0.83398 |  iteration: 1334 teacher: 0 stage: sketch lr: 0.000233\n",
      "batch 91 loss: 0.48598 acc: 0.86003 | v_loss: 0.70549 v_acc: 0.83691 |  iteration: 1335 teacher: 0 stage: sketch lr: 0.000233\n",
      "batch 92 loss: 0.55851 acc: 0.84798 | v_loss: 0.61360 v_acc: 0.84733 |  iteration: 1336 teacher: 1 stage: sketch lr: 0.000233\n",
      "batch 93 loss: 0.57465 acc: 0.85124 | v_loss: 0.65731 v_acc: 0.83496 |  iteration: 1337 teacher: 1 stage: sketch lr: 0.000234\n",
      "batch 94 loss: 0.51706 acc: 0.84896 | v_loss: 0.61543 v_acc: 0.84831 |  iteration: 1338 teacher: 1 stage: sketch lr: 0.000234\n",
      "batch 95 loss: 0.44317 acc: 0.87565 | v_loss: 0.57499 v_acc: 0.85449 |  iteration: 1339 teacher: 0 stage: sketch lr: 0.000234\n",
      "batch 96 loss: 0.58316 acc: 0.83268 | v_loss: 0.49748 v_acc: 0.87240 |  iteration: 1340 teacher: 1 stage: sketch lr: 0.000234\n",
      "batch 97 loss: 0.50943 acc: 0.85482 | v_loss: 0.79502 v_acc: 0.83236 |  iteration: 1341 teacher: 0 stage: sketch lr: 0.000234\n",
      "batch 98 loss: 0.65029 acc: 0.83008 | v_loss: 0.76179 v_acc: 0.82422 |  iteration: 1342 teacher: 1 stage: sketch lr: 0.000234\n",
      "batch 99 loss: 0.56134 acc: 0.83984 | v_loss: 0.73719 v_acc: 0.82487 |  iteration: 1343 teacher: 1 stage: sketch lr: 0.000235\n",
      "batch 100 loss: 0.53095 acc: 0.85189 | v_loss: 0.99337 v_acc: 0.80501 |  iteration: 1344 teacher: 0 stage: sketch lr: 0.000235\n",
      "batch 101 loss: 0.44685 acc: 0.87402 | v_loss: 0.59377 v_acc: 0.85645 |  iteration: 1345 teacher: 1 stage: sketch lr: 0.000235\n",
      "batch 102 loss: 0.53986 acc: 0.84310 | v_loss: 0.67538 v_acc: 0.84375 |  iteration: 1346 teacher: 1 stage: sketch lr: 0.000235\n",
      "batch 103 loss: 0.56431 acc: 0.84049 | v_loss: 0.68355 v_acc: 0.84668 |  iteration: 1347 teacher: 1 stage: sketch lr: 0.000235\n",
      "batch 104 loss: 0.50525 acc: 0.85514 | v_loss: 0.59295 v_acc: 0.84798 |  iteration: 1348 teacher: 0 stage: sketch lr: 0.000235\n",
      "batch 105 loss: 0.48629 acc: 0.85417 | v_loss: 1.09337 v_acc: 0.78971 |  iteration: 1349 teacher: 0 stage: sketch lr: 0.000236\n",
      "batch 106 loss: 0.63439 acc: 0.82487 | v_loss: 0.51820 v_acc: 0.86784 |  iteration: 1350 teacher: 1 stage: sketch lr: 0.000236\n",
      "batch 107 loss: 0.47724 acc: 0.86686 | v_loss: 0.68694 v_acc: 0.84212 |  iteration: 1351 teacher: 1 stage: sketch lr: 0.000236\n",
      "batch 108 loss: 0.56913 acc: 0.84473 | v_loss: 0.63768 v_acc: 0.84505 |  iteration: 1352 teacher: 1 stage: sketch lr: 0.000236\n",
      "batch 109 loss: 0.51387 acc: 0.85254 | v_loss: 0.52296 v_acc: 0.87077 |  iteration: 1353 teacher: 0 stage: sketch lr: 0.000236\n",
      "batch 110 loss: 0.62054 acc: 0.82129 | v_loss: 0.64161 v_acc: 0.84570 |  iteration: 1354 teacher: 1 stage: sketch lr: 0.000237\n",
      "batch 111 loss: 0.47004 acc: 0.85677 | v_loss: 0.74060 v_acc: 0.82194 |  iteration: 1355 teacher: 0 stage: sketch lr: 0.000237\n",
      "batch 112 loss: 0.52586 acc: 0.85384 | v_loss: 0.53610 v_acc: 0.86882 |  iteration: 1356 teacher: 1 stage: sketch lr: 0.000237\n",
      "batch 113 loss: 0.46858 acc: 0.85384 | v_loss: 0.71213 v_acc: 0.83496 |  iteration: 1357 teacher: 0 stage: sketch lr: 0.000237\n",
      "batch 114 loss: 0.52431 acc: 0.85417 | v_loss: 0.54674 v_acc: 0.85254 |  iteration: 1358 teacher: 1 stage: sketch lr: 0.000237\n",
      "batch 115 loss: 0.50004 acc: 0.85938 | v_loss: 1.01385 v_acc: 0.79948 |  iteration: 1359 teacher: 1 stage: sketch lr: 0.000237\n",
      "batch 116 loss: 0.53749 acc: 0.84766 | v_loss: 0.68977 v_acc: 0.84342 |  iteration: 1360 teacher: 0 stage: sketch lr: 0.000238\n",
      "batch 117 loss: 0.49978 acc: 0.85840 | v_loss: 0.72739 v_acc: 0.83952 |  iteration: 1361 teacher: 1 stage: sketch lr: 0.000238\n",
      "batch 118 loss: 0.62541 acc: 0.82943 | v_loss: 0.54406 v_acc: 0.85775 |  iteration: 1362 teacher: 1 stage: sketch lr: 0.000238\n",
      "batch 119 loss: 0.60199 acc: 0.83040 | v_loss: 0.80309 v_acc: 0.81250 |  iteration: 1363 teacher: 1 stage: sketch lr: 0.000238\n",
      "batch 120 loss: 0.58120 acc: 0.83789 | v_loss: 0.66866 v_acc: 0.83398 |  iteration: 1364 teacher: 1 stage: sketch lr: 0.000238\n",
      "batch 121 loss: 0.48707 acc: 0.85352 | v_loss: 0.53473 v_acc: 0.85807 |  iteration: 1365 teacher: 0 stage: sketch lr: 0.000238\n",
      "batch 122 loss: 0.48842 acc: 0.85449 | v_loss: 0.52243 v_acc: 0.86328 |  iteration: 1366 teacher: 0 stage: sketch lr: 0.000239\n",
      "batch 123 loss: 0.44501 acc: 0.87500 | v_loss: 0.82306 v_acc: 0.81478 |  iteration: 1367 teacher: 0 stage: sketch lr: 0.000239\n",
      "batch 124 loss: 0.39151 acc: 0.88574 | v_loss: 0.63474 v_acc: 0.85286 |  iteration: 1368 teacher: 0 stage: sketch lr: 0.000239\n",
      "batch 125 loss: 0.47926 acc: 0.85905 | v_loss: 0.73571 v_acc: 0.82682 |  iteration: 1369 teacher: 1 stage: sketch lr: 0.000239\n",
      "batch 126 loss: 0.49246 acc: 0.86816 | v_loss: 0.80220 v_acc: 0.80697 |  iteration: 1370 teacher: 0 stage: sketch lr: 0.000239\n",
      "batch 127 loss: 0.37592 acc: 0.87760 | v_loss: 0.67934 v_acc: 0.82129 |  iteration: 1371 teacher: 0 stage: sketch lr: 0.000240\n",
      "batch 128 loss: 0.53794 acc: 0.84375 | v_loss: 0.65775 v_acc: 0.82487 |  iteration: 1372 teacher: 0 stage: sketch lr: 0.000240\n",
      "batch 129 loss: 0.53641 acc: 0.84863 | v_loss: 0.71192 v_acc: 0.83105 |  iteration: 1373 teacher: 1 stage: sketch lr: 0.000240\n",
      "batch 130 loss: 0.45051 acc: 0.87077 | v_loss: 0.80708 v_acc: 0.82292 |  iteration: 1374 teacher: 1 stage: sketch lr: 0.000240\n",
      "batch 131 loss: 0.47956 acc: 0.85514 | v_loss: 0.66566 v_acc: 0.84668 |  iteration: 1375 teacher: 0 stage: sketch lr: 0.000240\n",
      "batch 132 loss: 0.42509 acc: 0.87598 | v_loss: 0.77760 v_acc: 0.83008 |  iteration: 1376 teacher: 0 stage: sketch lr: 0.000240\n",
      "batch 133 loss: 0.47844 acc: 0.86198 | v_loss: 0.79173 v_acc: 0.83659 |  iteration: 1377 teacher: 0 stage: sketch lr: 0.000241\n",
      "batch 134 loss: 0.44092 acc: 0.86914 | v_loss: 0.73796 v_acc: 0.81999 |  iteration: 1378 teacher: 0 stage: sketch lr: 0.000241\n",
      "batch 135 loss: 0.59161 acc: 0.83464 | v_loss: 0.60129 v_acc: 0.85514 |  iteration: 1379 teacher: 1 stage: sketch lr: 0.000241\n",
      "batch 136 loss: 0.55324 acc: 0.85156 | v_loss: 0.87820 v_acc: 0.81706 |  iteration: 1380 teacher: 0 stage: sketch lr: 0.000241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 137 loss: 0.40086 acc: 0.88216 | v_loss: 0.73019 v_acc: 0.83529 |  iteration: 1381 teacher: 0 stage: sketch lr: 0.000241\n",
      "batch 138 loss: 0.54978 acc: 0.84798 | v_loss: 0.71874 v_acc: 0.82454 |  iteration: 1382 teacher: 1 stage: sketch lr: 0.000241\n",
      "batch 139 loss: 0.42972 acc: 0.86979 | v_loss: 0.68681 v_acc: 0.83724 |  iteration: 1383 teacher: 0 stage: sketch lr: 0.000242\n",
      "batch 140 loss: 0.48364 acc: 0.85254 | v_loss: 0.60407 v_acc: 0.85254 |  iteration: 1384 teacher: 1 stage: sketch lr: 0.000242\n",
      "batch 141 loss: 0.46524 acc: 0.86589 | v_loss: 0.57215 v_acc: 0.85872 |  iteration: 1385 teacher: 0 stage: sketch lr: 0.000242\n",
      "batch 142 loss: 0.48515 acc: 0.85905 | v_loss: 0.64008 v_acc: 0.84668 |  iteration: 1386 teacher: 0 stage: sketch lr: 0.000242\n",
      "batch 143 loss: 0.51265 acc: 0.85775 | v_loss: 0.75794 v_acc: 0.81315 |  iteration: 1387 teacher: 1 stage: sketch lr: 0.000242\n",
      "batch 144 loss: 0.47054 acc: 0.86914 | v_loss: 0.70852 v_acc: 0.84310 |  iteration: 1388 teacher: 0 stage: sketch lr: 0.000242\n",
      "batch 145 loss: 0.56951 acc: 0.85449 | v_loss: 0.73592 v_acc: 0.84115 |  iteration: 1389 teacher: 1 stage: sketch lr: 0.000243\n",
      "batch 146 loss: 0.54242 acc: 0.84310 | v_loss: 0.47742 v_acc: 0.86979 |  iteration: 1390 teacher: 1 stage: sketch lr: 0.000243\n",
      "batch 147 loss: 0.51502 acc: 0.85742 | v_loss: 0.71116 v_acc: 0.83268 |  iteration: 1391 teacher: 1 stage: sketch lr: 0.000243\n",
      "batch 148 loss: 0.49659 acc: 0.85775 | v_loss: 0.66719 v_acc: 0.83529 |  iteration: 1392 teacher: 1 stage: sketch lr: 0.000243\n",
      "batch 149 loss: 0.48543 acc: 0.85417 | v_loss: 0.89671 v_acc: 0.80208 |  iteration: 1393 teacher: 0 stage: sketch lr: 0.000243\n",
      "batch 150 loss: 0.55106 acc: 0.84473 | v_loss: 0.51781 v_acc: 0.85775 |  iteration: 1394 teacher: 1 stage: sketch lr: 0.000244\n",
      "batch 151 loss: 0.57507 acc: 0.84180 | v_loss: 0.49612 v_acc: 0.87240 |  iteration: 1395 teacher: 1 stage: sketch lr: 0.000244\n",
      "batch 152 loss: 0.61080 acc: 0.83757 | v_loss: 0.65550 v_acc: 0.84603 |  iteration: 1396 teacher: 1 stage: sketch lr: 0.000244\n",
      "batch 153 loss: 0.55390 acc: 0.84017 | v_loss: 0.71831 v_acc: 0.83431 |  iteration: 1397 teacher: 1 stage: sketch lr: 0.000244\n",
      "batch 154 loss: 0.53478 acc: 0.84961 | v_loss: 0.80063 v_acc: 0.82064 |  iteration: 1398 teacher: 0 stage: sketch lr: 0.000244\n",
      "batch 155 loss: 0.43076 acc: 0.87663 | v_loss: 0.60080 v_acc: 0.85124 |  iteration: 1399 teacher: 0 stage: sketch lr: 0.000244\n",
      "batch 156 loss: 0.41684 acc: 0.87402 | v_loss: 0.69507 v_acc: 0.83659 |  iteration: 1400 teacher: 0 stage: sketch lr: 0.000245\n",
      "batch 157 loss: 0.47895 acc: 0.85872 | v_loss: 0.80882 v_acc: 0.81022 |  iteration: 1401 teacher: 0 stage: sketch lr: 0.000245\n",
      "batch 158 loss: 0.51569 acc: 0.85286 | v_loss: 0.80016 v_acc: 0.81152 |  iteration: 1402 teacher: 0 stage: sketch lr: 0.000245\n",
      "batch 159 loss: 0.58373 acc: 0.84505 | v_loss: 0.65202 v_acc: 0.84831 |  iteration: 1403 teacher: 1 stage: sketch lr: 0.000245\n",
      "batch 160 loss: 0.49779 acc: 0.86068 | v_loss: 0.55614 v_acc: 0.85384 |  iteration: 1404 teacher: 0 stage: sketch lr: 0.000245\n",
      "batch 161 loss: 0.56134 acc: 0.83626 | v_loss: 0.44122 v_acc: 0.87663 |  iteration: 1405 teacher: 0 stage: sketch lr: 0.000245\n",
      "batch 162 loss: 0.49125 acc: 0.85384 | v_loss: 0.66213 v_acc: 0.83887 |  iteration: 1406 teacher: 0 stage: sketch lr: 0.000246\n",
      "batch 163 loss: 0.44821 acc: 0.86523 | v_loss: 0.62939 v_acc: 0.84180 |  iteration: 1407 teacher: 0 stage: sketch lr: 0.000246\n",
      "batch 164 loss: 0.46066 acc: 0.86589 | v_loss: 0.89949 v_acc: 0.82324 |  iteration: 1408 teacher: 0 stage: sketch lr: 0.000246\n",
      "batch 165 loss: 0.43414 acc: 0.87207 | v_loss: 0.65727 v_acc: 0.84180 |  iteration: 1409 teacher: 0 stage: sketch lr: 0.000246\n",
      "batch 166 loss: 0.54911 acc: 0.84733 | v_loss: 0.77943 v_acc: 0.82259 |  iteration: 1410 teacher: 0 stage: sketch lr: 0.000246\n",
      "batch 167 loss: 0.50438 acc: 0.85254 | v_loss: 0.53078 v_acc: 0.86361 |  iteration: 1411 teacher: 0 stage: sketch lr: 0.000246\n",
      "batch 168 loss: 0.41560 acc: 0.87728 | v_loss: 0.65878 v_acc: 0.83691 |  iteration: 1412 teacher: 0 stage: sketch lr: 0.000247\n",
      "batch 169 loss: 0.57171 acc: 0.84017 | v_loss: 0.98529 v_acc: 0.78158 |  iteration: 1413 teacher: 1 stage: sketch lr: 0.000247\n",
      "batch 170 loss: 0.55900 acc: 0.85286 | v_loss: 0.64116 v_acc: 0.84733 |  iteration: 1414 teacher: 0 stage: sketch lr: 0.000247\n",
      "batch 171 loss: 0.50901 acc: 0.84831 | v_loss: 0.60750 v_acc: 0.85319 |  iteration: 1415 teacher: 1 stage: sketch lr: 0.000247\n",
      "batch 172 loss: 0.50636 acc: 0.85775 | v_loss: 0.57622 v_acc: 0.85417 |  iteration: 1416 teacher: 1 stage: sketch lr: 0.000247\n",
      "batch 173 loss: 0.43943 acc: 0.86849 | v_loss: 0.60862 v_acc: 0.84928 |  iteration: 1417 teacher: 0 stage: sketch lr: 0.000248\n",
      "batch 174 loss: 0.45212 acc: 0.86719 | v_loss: 0.58054 v_acc: 0.86296 |  iteration: 1418 teacher: 0 stage: sketch lr: 0.000248\n",
      "batch 175 loss: 0.47871 acc: 0.86263 | v_loss: 0.74605 v_acc: 0.81934 |  iteration: 1419 teacher: 0 stage: sketch lr: 0.000248\n",
      "batch 176 loss: 0.35356 acc: 0.88900 | v_loss: 0.50889 v_acc: 0.87988 |  iteration: 1420 teacher: 0 stage: sketch lr: 0.000248\n",
      "batch 177 loss: 0.44991 acc: 0.87174 | v_loss: 1.01429 v_acc: 0.80664 |  iteration: 1421 teacher: 0 stage: sketch lr: 0.000248\n",
      "batch 178 loss: 0.45040 acc: 0.86393 | v_loss: 0.74968 v_acc: 0.83366 |  iteration: 1422 teacher: 0 stage: sketch lr: 0.000248\n",
      "batch 179 loss: 0.44393 acc: 0.87207 | v_loss: 0.82309 v_acc: 0.82617 |  iteration: 1423 teacher: 0 stage: sketch lr: 0.000249\n",
      "batch 180 loss: 0.69103 acc: 0.81966 | v_loss: 0.67269 v_acc: 0.84408 |  iteration: 1424 teacher: 1 stage: sketch lr: 0.000249\n",
      "batch 181 loss: 0.42796 acc: 0.87044 | v_loss: 0.64684 v_acc: 0.84831 |  iteration: 1425 teacher: 0 stage: sketch lr: 0.000249\n",
      "batch 182 loss: 0.47088 acc: 0.85970 | v_loss: 0.67826 v_acc: 0.84440 |  iteration: 1426 teacher: 0 stage: sketch lr: 0.000249\n",
      "batch 183 loss: 0.64630 acc: 0.81934 | v_loss: 0.63839 v_acc: 0.85514 |  iteration: 1427 teacher: 1 stage: sketch lr: 0.000249\n",
      "batch 184 loss: 0.48034 acc: 0.86621 | v_loss: 0.63524 v_acc: 0.84896 |  iteration: 1428 teacher: 0 stage: sketch lr: 0.000249\n",
      "batch 185 loss: 0.53277 acc: 0.84342 | v_loss: 0.60736 v_acc: 0.85482 |  iteration: 1429 teacher: 0 stage: sketch lr: 0.000250\n",
      "batch 186 loss: 0.42166 acc: 0.88086 | v_loss: 0.57210 v_acc: 0.86068 |  iteration: 1430 teacher: 0 stage: sketch lr: 0.000250\n",
      "batch 187 loss: 0.50639 acc: 0.85612 | v_loss: 0.48380 v_acc: 0.87305 |  iteration: 1431 teacher: 1 stage: sketch lr: 0.000250\n",
      "batch 188 loss: 0.46383 acc: 0.86816 | v_loss: 0.75450 v_acc: 0.82975 |  iteration: 1432 teacher: 0 stage: sketch lr: 0.000250\n",
      "batch 189 loss: 0.63087 acc: 0.83496 | v_loss: 0.71984 v_acc: 0.83008 |  iteration: 1433 teacher: 1 stage: sketch lr: 0.000250\n",
      "batch 190 loss: 0.50484 acc: 0.85482 | v_loss: 0.77200 v_acc: 0.82650 |  iteration: 1434 teacher: 0 stage: sketch lr: 0.000251\n",
      "batch 191 loss: 0.51698 acc: 0.85482 | v_loss: 0.90371 v_acc: 0.80566 |  iteration: 1435 teacher: 0 stage: sketch lr: 0.000251\n",
      "batch 192 loss: 0.40872 acc: 0.88184 | v_loss: 0.57869 v_acc: 0.85579 |  iteration: 1436 teacher: 0 stage: sketch lr: 0.000251\n",
      "batch 193 loss: 0.45481 acc: 0.86719 | v_loss: 0.66101 v_acc: 0.83659 |  iteration: 1437 teacher: 0 stage: sketch lr: 0.000251\n",
      "batch 194 loss: 0.58900 acc: 0.83561 | v_loss: 0.65941 v_acc: 0.84831 |  iteration: 1438 teacher: 1 stage: sketch lr: 0.000251\n",
      "batch 195 loss: 0.48003 acc: 0.85417 | v_loss: 0.53483 v_acc: 0.86458 |  iteration: 1439 teacher: 0 stage: sketch lr: 0.000251\n",
      "batch 196 loss: 0.54909 acc: 0.84863 | v_loss: 1.10330 v_acc: 0.78906 |  iteration: 1440 teacher: 1 stage: sketch lr: 0.000252\n",
      "batch 197 loss: 0.43942 acc: 0.87109 | v_loss: 0.51694 v_acc: 0.87174 |  iteration: 1441 teacher: 1 stage: sketch lr: 0.000252\n",
      "batch 198 loss: 0.50707 acc: 0.86035 | v_loss: 0.72588 v_acc: 0.83887 |  iteration: 1442 teacher: 1 stage: sketch lr: 0.000252\n",
      "batch 199 loss: 0.53860 acc: 0.85872 | v_loss: 0.60006 v_acc: 0.85286 |  iteration: 1443 teacher: 1 stage: sketch lr: 0.000252\n",
      "batch 200 loss: 0.47846 acc: 0.86100 | v_loss: 0.52303 v_acc: 0.86784 |  iteration: 1444 teacher: 1 stage: sketch lr: 0.000252\n",
      "batch 201 loss: 0.59190 acc: 0.83464 | v_loss: 0.63077 v_acc: 0.85156 |  iteration: 1445 teacher: 1 stage: sketch lr: 0.000252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 202 loss: 0.40326 acc: 0.88672 | v_loss: 0.78524 v_acc: 0.82617 |  iteration: 1446 teacher: 0 stage: sketch lr: 0.000253\n",
      "batch 203 loss: 0.49024 acc: 0.85221 | v_loss: 0.57522 v_acc: 0.85905 |  iteration: 1447 teacher: 1 stage: sketch lr: 0.000253\n",
      "batch 204 loss: 0.51670 acc: 0.85059 | v_loss: 0.66901 v_acc: 0.83724 |  iteration: 1448 teacher: 0 stage: sketch lr: 0.000253\n",
      "batch 205 loss: 0.46486 acc: 0.86719 | v_loss: 0.55545 v_acc: 0.84961 |  iteration: 1449 teacher: 1 stage: sketch lr: 0.000253\n",
      "batch 206 loss: 0.48874 acc: 0.85254 | v_loss: 1.03697 v_acc: 0.79102 |  iteration: 1450 teacher: 1 stage: sketch lr: 0.000253\n",
      "batch 207 loss: 0.58392 acc: 0.84342 | v_loss: 0.70005 v_acc: 0.84180 |  iteration: 1451 teacher: 1 stage: sketch lr: 0.000253\n",
      "batch 208 loss: 0.40075 acc: 0.87337 | v_loss: 0.74360 v_acc: 0.83105 |  iteration: 1452 teacher: 0 stage: sketch lr: 0.000254\n",
      "batch 209 loss: 0.48827 acc: 0.86556 | v_loss: 0.54820 v_acc: 0.85970 |  iteration: 1453 teacher: 0 stage: sketch lr: 0.000254\n",
      "batch 210 loss: 0.52014 acc: 0.85384 | v_loss: 0.76733 v_acc: 0.82487 |  iteration: 1454 teacher: 0 stage: sketch lr: 0.000254\n",
      "batch 211 loss: 0.41691 acc: 0.86914 | v_loss: 0.64789 v_acc: 0.83496 |  iteration: 1455 teacher: 0 stage: sketch lr: 0.000254\n",
      "batch 212 loss: 0.46556 acc: 0.86523 | v_loss: 0.65730 v_acc: 0.84212 |  iteration: 1456 teacher: 0 stage: sketch lr: 0.000254\n",
      "batch 213 loss: 0.60946 acc: 0.82520 | v_loss: 0.56836 v_acc: 0.85547 |  iteration: 1457 teacher: 1 stage: sketch lr: 0.000255\n",
      "batch 214 loss: 0.44819 acc: 0.87435 | v_loss: 0.83982 v_acc: 0.81348 |  iteration: 1458 teacher: 0 stage: sketch lr: 0.000255\n",
      "batch 215 loss: 0.50677 acc: 0.85905 | v_loss: 0.62187 v_acc: 0.85286 |  iteration: 1459 teacher: 0 stage: sketch lr: 0.000255\n",
      "batch 216 loss: 0.47488 acc: 0.86100 | v_loss: 0.69107 v_acc: 0.83561 |  iteration: 1460 teacher: 0 stage: sketch lr: 0.000255\n",
      "batch 217 loss: 0.56042 acc: 0.84701 | v_loss: 0.79302 v_acc: 0.81738 |  iteration: 1461 teacher: 1 stage: sketch lr: 0.000255\n",
      "batch 218 loss: 0.48409 acc: 0.85938 | v_loss: 0.58891 v_acc: 0.84603 |  iteration: 1462 teacher: 0 stage: sketch lr: 0.000255\n",
      "batch 219 loss: 0.48985 acc: 0.85742 | v_loss: 0.67890 v_acc: 0.82747 |  iteration: 1463 teacher: 1 stage: sketch lr: 0.000256\n",
      "batch 220 loss: 0.60170 acc: 0.83236 | v_loss: 0.73813 v_acc: 0.82975 |  iteration: 1464 teacher: 1 stage: sketch lr: 0.000256\n",
      "batch 221 loss: 0.51553 acc: 0.85352 | v_loss: 0.79148 v_acc: 0.82520 |  iteration: 1465 teacher: 1 stage: sketch lr: 0.000256\n",
      "batch 222 loss: 0.49683 acc: 0.85710 | v_loss: 0.65447 v_acc: 0.84701 |  iteration: 1466 teacher: 1 stage: sketch lr: 0.000256\n",
      "batch 223 loss: 0.53614 acc: 0.85417 | v_loss: 0.69373 v_acc: 0.84310 |  iteration: 1467 teacher: 0 stage: sketch lr: 0.000256\n",
      "batch 224 loss: 0.49968 acc: 0.85840 | v_loss: 0.72782 v_acc: 0.84798 |  iteration: 1468 teacher: 0 stage: sketch lr: 0.000256\n",
      "batch 225 loss: 0.54577 acc: 0.84993 | v_loss: 0.73696 v_acc: 0.81803 |  iteration: 1469 teacher: 1 stage: sketch lr: 0.000257\n",
      "batch 226 loss: 0.44266 acc: 0.87142 | v_loss: 0.58037 v_acc: 0.85221 |  iteration: 1470 teacher: 0 stage: sketch lr: 0.000257\n",
      "batch 227 loss: 0.38205 acc: 0.88542 | v_loss: 0.89529 v_acc: 0.80924 |  iteration: 1471 teacher: 0 stage: sketch lr: 0.000257\n",
      "batch 228 loss: 0.42595 acc: 0.87630 | v_loss: 0.75355 v_acc: 0.81934 |  iteration: 1472 teacher: 0 stage: sketch lr: 0.000257\n",
      "batch 229 loss: 0.49241 acc: 0.86133 | v_loss: 0.65950 v_acc: 0.83659 |  iteration: 1473 teacher: 1 stage: sketch lr: 0.000257\n",
      "batch 230 loss: 0.42526 acc: 0.87826 | v_loss: 0.68595 v_acc: 0.83301 |  iteration: 1474 teacher: 0 stage: sketch lr: 0.000257\n",
      "batch 231 loss: 0.40121 acc: 0.88151 | v_loss: 0.57269 v_acc: 0.86068 |  iteration: 1475 teacher: 0 stage: sketch lr: 0.000258\n",
      "batch 232 loss: 0.40863 acc: 0.88021 | v_loss: 0.54108 v_acc: 0.85514 |  iteration: 1476 teacher: 0 stage: sketch lr: 0.000258\n",
      "batch 233 loss: 0.47156 acc: 0.86784 | v_loss: 0.58076 v_acc: 0.86491 |  iteration: 1477 teacher: 0 stage: sketch lr: 0.000258\n",
      "batch 234 loss: 0.42303 acc: 0.87370 | v_loss: 0.75378 v_acc: 0.81283 |  iteration: 1478 teacher: 1 stage: sketch lr: 0.000258\n",
      "batch 235 loss: 0.44699 acc: 0.86914 | v_loss: 0.66640 v_acc: 0.84896 |  iteration: 1479 teacher: 0 stage: sketch lr: 0.000258\n",
      "batch 236 loss: 0.41679 acc: 0.87305 | v_loss: 0.69519 v_acc: 0.84342 |  iteration: 1480 teacher: 0 stage: sketch lr: 0.000259\n",
      "batch 237 loss: 0.37187 acc: 0.88151 | v_loss: 0.48679 v_acc: 0.86947 |  iteration: 1481 teacher: 0 stage: sketch lr: 0.000259\n",
      "batch 238 loss: 0.50097 acc: 0.85775 | v_loss: 0.67432 v_acc: 0.84701 |  iteration: 1482 teacher: 1 stage: sketch lr: 0.000259\n",
      "batch 239 loss: 0.62419 acc: 0.83529 | v_loss: 0.65218 v_acc: 0.83659 |  iteration: 1483 teacher: 1 stage: sketch lr: 0.000259\n",
      "batch 240 loss: 0.40696 acc: 0.88281 | v_loss: 0.96201 v_acc: 0.79753 |  iteration: 1484 teacher: 1 stage: sketch lr: 0.000259\n",
      "batch 241 loss: 0.50506 acc: 0.86035 | v_loss: 0.50455 v_acc: 0.86556 |  iteration: 1485 teacher: 1 stage: sketch lr: 0.000259\n",
      "batch 242 loss: 0.46526 acc: 0.86523 | v_loss: 0.46852 v_acc: 0.87760 |  iteration: 1486 teacher: 1 stage: sketch lr: 0.000260\n",
      "batch 243 loss: 0.42494 acc: 0.87695 | v_loss: 0.69147 v_acc: 0.85221 |  iteration: 1487 teacher: 0 stage: sketch lr: 0.000260\n",
      "batch 244 loss: 0.42657 acc: 0.87337 | v_loss: 0.74632 v_acc: 0.84180 |  iteration: 1488 teacher: 1 stage: sketch lr: 0.000260\n",
      "batch 245 loss: 0.53419 acc: 0.85514 | v_loss: 0.81802 v_acc: 0.81543 |  iteration: 1489 teacher: 1 stage: sketch lr: 0.000260\n",
      "batch 246 loss: 0.53383 acc: 0.84798 | v_loss: 0.57550 v_acc: 0.86198 |  iteration: 1490 teacher: 1 stage: sketch lr: 0.000260\n",
      "batch 247 loss: 0.43141 acc: 0.86979 | v_loss: 0.68929 v_acc: 0.83659 |  iteration: 1491 teacher: 0 stage: sketch lr: 0.000260\n",
      "batch 248 loss: 0.41324 acc: 0.87109 | v_loss: 0.75714 v_acc: 0.81022 |  iteration: 1492 teacher: 0 stage: sketch lr: 0.000261\n",
      "batch 249 loss: 0.41976 acc: 0.88021 | v_loss: 0.75637 v_acc: 0.81120 |  iteration: 1493 teacher: 0 stage: sketch lr: 0.000261\n",
      "batch 250 loss: 0.46991 acc: 0.85775 | v_loss: 0.61683 v_acc: 0.84766 |  iteration: 1494 teacher: 0 stage: sketch lr: 0.000261\n",
      "batch 251 loss: 0.47522 acc: 0.86328 | v_loss: 0.52319 v_acc: 0.86589 |  iteration: 1495 teacher: 1 stage: sketch lr: 0.000261\n",
      "batch 252 loss: 0.41284 acc: 0.87337 | v_loss: 0.43873 v_acc: 0.88607 |  iteration: 1496 teacher: 0 stage: sketch lr: 0.000261\n",
      "batch 253 loss: 0.44838 acc: 0.86979 | v_loss: 0.63891 v_acc: 0.85124 |  iteration: 1497 teacher: 0 stage: sketch lr: 0.000262\n",
      "batch 254 loss: 0.42541 acc: 0.87630 | v_loss: 0.62802 v_acc: 0.84701 |  iteration: 1498 teacher: 0 stage: sketch lr: 0.000262\n",
      "batch 255 loss: 0.47307 acc: 0.86719 | v_loss: 0.90374 v_acc: 0.82194 |  iteration: 1499 teacher: 1 stage: sketch lr: 0.000262\n",
      "batch 256 loss: 0.39545 acc: 0.88444 | v_loss: 0.64170 v_acc: 0.83789 |  iteration: 1500 teacher: 0 stage: sketch lr: 0.000262\n",
      "batch 257 loss: 0.57302 acc: 0.84961 | v_loss: 0.71455 v_acc: 0.83659 |  iteration: 1501 teacher: 1 stage: sketch lr: 0.000262\n",
      "batch 258 loss: 0.47807 acc: 0.86133 | v_loss: 0.55782 v_acc: 0.85254 |  iteration: 1502 teacher: 1 stage: sketch lr: 0.000262\n",
      "batch 259 loss: 0.55563 acc: 0.84342 | v_loss: 0.70943 v_acc: 0.83561 |  iteration: 1503 teacher: 1 stage: sketch lr: 0.000263\n",
      "batch 260 loss: 0.54769 acc: 0.84147 | v_loss: 0.87509 v_acc: 0.78906 |  iteration: 1504 teacher: 1 stage: sketch lr: 0.000263\n",
      "batch 261 loss: 0.48636 acc: 0.86165 | v_loss: 0.62361 v_acc: 0.85514 |  iteration: 1505 teacher: 1 stage: sketch lr: 0.000263\n",
      "batch 262 loss: 0.49761 acc: 0.85612 | v_loss: 0.57378 v_acc: 0.86523 |  iteration: 1506 teacher: 0 stage: sketch lr: 0.000263\n",
      "batch 263 loss: 0.51448 acc: 0.84961 | v_loss: 0.62411 v_acc: 0.84473 |  iteration: 1507 teacher: 1 stage: sketch lr: 0.000263\n",
      "batch 264 loss: 0.48240 acc: 0.86686 | v_loss: 0.55945 v_acc: 0.86393 |  iteration: 1508 teacher: 0 stage: sketch lr: 0.000263\n",
      "batch 265 loss: 0.55969 acc: 0.85840 | v_loss: 0.57977 v_acc: 0.86426 |  iteration: 1509 teacher: 1 stage: sketch lr: 0.000264\n",
      "batch 266 loss: 0.43127 acc: 0.86751 | v_loss: 0.72988 v_acc: 0.82943 |  iteration: 1510 teacher: 0 stage: sketch lr: 0.000264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 267 loss: 0.52835 acc: 0.85547 | v_loss: 0.46896 v_acc: 0.88118 |  iteration: 1511 teacher: 1 stage: sketch lr: 0.000264\n",
      "batch 268 loss: 0.46527 acc: 0.86035 | v_loss: 1.03700 v_acc: 0.80306 |  iteration: 1512 teacher: 1 stage: sketch lr: 0.000264\n",
      "batch 269 loss: 0.46157 acc: 0.86393 | v_loss: 0.73910 v_acc: 0.83171 |  iteration: 1513 teacher: 1 stage: sketch lr: 0.000264\n",
      "batch 270 loss: 0.43828 acc: 0.87305 | v_loss: 0.77786 v_acc: 0.82812 |  iteration: 1514 teacher: 0 stage: sketch lr: 0.000264\n",
      "batch 271 loss: 0.49360 acc: 0.85905 | v_loss: 0.65613 v_acc: 0.84635 |  iteration: 1515 teacher: 0 stage: sketch lr: 0.000265\n",
      "batch 272 loss: 0.48532 acc: 0.85775 | v_loss: 0.65598 v_acc: 0.83984 |  iteration: 1516 teacher: 0 stage: sketch lr: 0.000265\n",
      "batch 273 loss: 0.41781 acc: 0.86784 | v_loss: 0.65909 v_acc: 0.85352 |  iteration: 1517 teacher: 0 stage: sketch lr: 0.000265\n",
      "batch 274 loss: 0.49151 acc: 0.86296 | v_loss: 0.57329 v_acc: 0.85775 |  iteration: 1518 teacher: 1 stage: sketch lr: 0.000265\n",
      "batch 275 loss: 0.51766 acc: 0.85514 | v_loss: 0.65541 v_acc: 0.83822 |  iteration: 1519 teacher: 1 stage: sketch lr: 0.000265\n",
      "batch 276 loss: 0.44964 acc: 0.87402 | v_loss: 0.65903 v_acc: 0.85579 |  iteration: 1520 teacher: 1 stage: sketch lr: 0.000266\n",
      "batch 277 loss: 0.44183 acc: 0.87012 | v_loss: 0.55218 v_acc: 0.86556 |  iteration: 1521 teacher: 0 stage: sketch lr: 0.000266\n",
      "batch 278 loss: 0.46333 acc: 0.87077 | v_loss: 0.46707 v_acc: 0.88216 |  iteration: 1522 teacher: 0 stage: sketch lr: 0.000266\n",
      "batch 279 loss: 0.42265 acc: 0.87630 | v_loss: 0.84469 v_acc: 0.81673 |  iteration: 1523 teacher: 0 stage: sketch lr: 0.000266\n",
      "batch 280 loss: 0.45606 acc: 0.86914 | v_loss: 0.69742 v_acc: 0.83236 |  iteration: 1524 teacher: 0 stage: sketch lr: 0.000266\n",
      "batch 281 loss: 0.48499 acc: 0.86361 | v_loss: 0.75792 v_acc: 0.81999 |  iteration: 1525 teacher: 0 stage: sketch lr: 0.000266\n",
      "batch 282 loss: 0.46728 acc: 0.86361 | v_loss: 0.93333 v_acc: 0.80371 |  iteration: 1526 teacher: 0 stage: sketch lr: 0.000267\n",
      "batch 283 loss: 0.57451 acc: 0.83301 | v_loss: 0.53793 v_acc: 0.86328 |  iteration: 1527 teacher: 0 stage: sketch lr: 0.000267\n",
      "batch 284 loss: 0.61086 acc: 0.82845 | v_loss: 0.61845 v_acc: 0.85059 |  iteration: 1528 teacher: 1 stage: sketch lr: 0.000267\n",
      "batch 285 loss: 0.40583 acc: 0.87337 | v_loss: 0.66608 v_acc: 0.85059 |  iteration: 1529 teacher: 1 stage: sketch lr: 0.000267\n",
      "batch 286 loss: 0.40079 acc: 0.88900 | v_loss: 0.53999 v_acc: 0.87012 |  iteration: 1530 teacher: 0 stage: sketch lr: 0.000267\n",
      "batch 287 loss: 0.43665 acc: 0.87663 | v_loss: 1.12091 v_acc: 0.79102 |  iteration: 1531 teacher: 0 stage: sketch lr: 0.000267\n",
      "batch 288 loss: 0.39576 acc: 0.88802 | v_loss: 0.52097 v_acc: 0.87598 |  iteration: 1532 teacher: 0 stage: sketch lr: 0.000268\n",
      "batch 289 loss: 0.43405 acc: 0.87500 | v_loss: 0.73131 v_acc: 0.84701 |  iteration: 1533 teacher: 1 stage: sketch lr: 0.000268\n",
      "batch 290 loss: 0.53759 acc: 0.85189 | v_loss: 0.61244 v_acc: 0.85645 |  iteration: 1534 teacher: 0 stage: sketch lr: 0.000268\n",
      "batch 291 loss: 0.36222 acc: 0.88932 | v_loss: 0.51384 v_acc: 0.87956 |  iteration: 1535 teacher: 0 stage: sketch lr: 0.000268\n",
      "batch 292 loss: 0.54106 acc: 0.85645 | v_loss: 0.64155 v_acc: 0.84928 |  iteration: 1536 teacher: 1 stage: sketch lr: 0.000268\n",
      "batch 293 loss: 0.42477 acc: 0.86979 | v_loss: 0.76745 v_acc: 0.82715 |  iteration: 1537 teacher: 0 stage: sketch lr: 0.000269\n",
      "batch 294 loss: 0.52594 acc: 0.85124 | v_loss: 0.53816 v_acc: 0.86165 |  iteration: 1538 teacher: 1 stage: sketch lr: 0.000269\n",
      "batch 295 loss: 0.47569 acc: 0.86621 | v_loss: 0.72369 v_acc: 0.82747 |  iteration: 1539 teacher: 1 stage: sketch lr: 0.000269\n",
      "batch 296 loss: 0.57688 acc: 0.83757 | v_loss: 0.54313 v_acc: 0.86198 |  iteration: 1540 teacher: 1 stage: sketch lr: 0.000269\n",
      "batch 297 loss: 0.50445 acc: 0.85124 | v_loss: 0.98249 v_acc: 0.79818 |  iteration: 1541 teacher: 0 stage: sketch lr: 0.000269\n",
      "batch 298 loss: 0.48844 acc: 0.86035 | v_loss: 0.62480 v_acc: 0.85384 |  iteration: 1542 teacher: 1 stage: sketch lr: 0.000269\n",
      "batch 299 loss: 0.46288 acc: 0.86979 | v_loss: 0.69466 v_acc: 0.83984 |  iteration: 1543 teacher: 1 stage: sketch lr: 0.000270\n",
      "batch 300 loss: 0.42458 acc: 0.87533 | v_loss: 0.53832 v_acc: 0.86784 |  iteration: 1544 teacher: 1 stage: sketch lr: 0.000270\n",
      "batch 301 loss: 0.38857 acc: 0.88704 | v_loss: 0.78561 v_acc: 0.81999 |  iteration: 1545 teacher: 0 stage: sketch lr: 0.000270\n",
      "batch 302 loss: 0.51793 acc: 0.85091 | v_loss: 0.57406 v_acc: 0.85547 |  iteration: 1546 teacher: 1 stage: sketch lr: 0.000270\n",
      "batch 303 loss: 0.45922 acc: 0.87077 | v_loss: 0.57082 v_acc: 0.85384 |  iteration: 1547 teacher: 1 stage: sketch lr: 0.000270\n",
      "batch 304 loss: 0.43497 acc: 0.86979 | v_loss: 0.52976 v_acc: 0.86816 |  iteration: 1548 teacher: 0 stage: sketch lr: 0.000270\n",
      "batch 305 loss: 0.43444 acc: 0.87077 | v_loss: 0.81712 v_acc: 0.81868 |  iteration: 1549 teacher: 1 stage: sketch lr: 0.000271\n",
      "batch 306 loss: 0.49452 acc: 0.86328 | v_loss: 0.63720 v_acc: 0.85905 |  iteration: 1550 teacher: 0 stage: sketch lr: 0.000271\n",
      "batch 307 loss: 0.39573 acc: 0.88932 | v_loss: 0.71683 v_acc: 0.83561 |  iteration: 1551 teacher: 0 stage: sketch lr: 0.000271\n",
      "batch 308 loss: 0.46060 acc: 0.86621 | v_loss: 0.78435 v_acc: 0.82324 |  iteration: 1552 teacher: 1 stage: sketch lr: 0.000271\n",
      "batch 309 loss: 0.46788 acc: 0.86003 | v_loss: 0.59906 v_acc: 0.84896 |  iteration: 1553 teacher: 0 stage: sketch lr: 0.000271\n",
      "batch 310 loss: 0.52180 acc: 0.86003 | v_loss: 0.69644 v_acc: 0.82292 |  iteration: 1554 teacher: 1 stage: sketch lr: 0.000271\n",
      "batch 311 loss: 0.46241 acc: 0.86328 | v_loss: 0.79120 v_acc: 0.82129 |  iteration: 1555 teacher: 1 stage: sketch lr: 0.000272\n",
      "batch 312 loss: 0.48442 acc: 0.85840 | v_loss: 0.92488 v_acc: 0.80892 |  iteration: 1556 teacher: 1 stage: sketch lr: 0.000272\n",
      "batch 313 loss: 0.52366 acc: 0.84473 | v_loss: 0.69358 v_acc: 0.84342 |  iteration: 1557 teacher: 1 stage: sketch lr: 0.000272\n",
      "batch 314 loss: 0.53538 acc: 0.85514 | v_loss: 0.71336 v_acc: 0.84245 |  iteration: 1558 teacher: 1 stage: sketch lr: 0.000272\n",
      "batch 315 loss: 0.45501 acc: 0.87305 | v_loss: 0.75161 v_acc: 0.84212 |  iteration: 1559 teacher: 1 stage: sketch lr: 0.000272\n",
      "batch 316 loss: 0.51795 acc: 0.85807 | v_loss: 0.70658 v_acc: 0.82747 |  iteration: 1560 teacher: 0 stage: sketch lr: 0.000273\n",
      "batch 317 loss: 0.46730 acc: 0.86784 | v_loss: 0.57032 v_acc: 0.85677 |  iteration: 1561 teacher: 0 stage: sketch lr: 0.000273\n",
      "batch 318 loss: 0.48253 acc: 0.86393 | v_loss: 0.89773 v_acc: 0.81022 |  iteration: 1562 teacher: 0 stage: sketch lr: 0.000273\n",
      "batch 319 loss: 0.47122 acc: 0.85742 | v_loss: 0.70428 v_acc: 0.83301 |  iteration: 1563 teacher: 0 stage: sketch lr: 0.000273\n",
      "batch 320 loss: 0.39804 acc: 0.88477 | v_loss: 0.68730 v_acc: 0.83203 |  iteration: 1564 teacher: 1 stage: sketch lr: 0.000273\n",
      "batch 321 loss: 0.46228 acc: 0.86426 | v_loss: 0.68784 v_acc: 0.82845 |  iteration: 1565 teacher: 1 stage: sketch lr: 0.000273\n",
      "batch 322 loss: 0.40359 acc: 0.87272 | v_loss: 0.57164 v_acc: 0.86133 |  iteration: 1566 teacher: 0 stage: sketch lr: 0.000274\n",
      "batch 323 loss: 0.51867 acc: 0.85547 | v_loss: 0.54175 v_acc: 0.86751 |  iteration: 1567 teacher: 1 stage: sketch lr: 0.000274\n",
      "batch 324 loss: 0.46002 acc: 0.86947 | v_loss: 0.57786 v_acc: 0.86068 |  iteration: 1568 teacher: 0 stage: sketch lr: 0.000274\n",
      "batch 325 loss: 0.41894 acc: 0.87793 | v_loss: 0.75356 v_acc: 0.82096 |  iteration: 1569 teacher: 0 stage: sketch lr: 0.000274\n",
      "batch 326 loss: 0.51491 acc: 0.86263 | v_loss: 0.68626 v_acc: 0.84961 |  iteration: 1570 teacher: 1 stage: sketch lr: 0.000274\n",
      "batch 327 loss: 0.47567 acc: 0.86361 | v_loss: 0.70701 v_acc: 0.84017 |  iteration: 1571 teacher: 0 stage: sketch lr: 0.000274\n",
      "batch 328 loss: 0.42012 acc: 0.87240 | v_loss: 0.48452 v_acc: 0.87370 |  iteration: 1572 teacher: 0 stage: sketch lr: 0.000275\n",
      "batch 329 loss: 0.44754 acc: 0.86849 | v_loss: 0.66652 v_acc: 0.84635 |  iteration: 1573 teacher: 0 stage: sketch lr: 0.000275\n",
      "batch 330 loss: 0.48025 acc: 0.86816 | v_loss: 0.61325 v_acc: 0.84277 |  iteration: 1574 teacher: 0 stage: sketch lr: 0.000275\n",
      "batch 331 loss: 0.52777 acc: 0.85840 | v_loss: 0.93180 v_acc: 0.80664 |  iteration: 1575 teacher: 0 stage: sketch lr: 0.000275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 332 loss: 0.49396 acc: 0.85872 | v_loss: 0.48010 v_acc: 0.86751 |  iteration: 1576 teacher: 1 stage: sketch lr: 0.000275\n",
      "batch 333 loss: 0.45976 acc: 0.86686 | v_loss: 0.42366 v_acc: 0.88835 |  iteration: 1577 teacher: 1 stage: sketch lr: 0.000275\n",
      "batch 334 loss: 0.42307 acc: 0.86719 | v_loss: 0.65203 v_acc: 0.85254 |  iteration: 1578 teacher: 0 stage: sketch lr: 0.000276\n",
      "batch 335 loss: 0.40318 acc: 0.87858 | v_loss: 0.69215 v_acc: 0.84863 |  iteration: 1579 teacher: 1 stage: sketch lr: 0.000276\n",
      "batch 336 loss: 0.49454 acc: 0.85872 | v_loss: 0.75087 v_acc: 0.83040 |  iteration: 1580 teacher: 1 stage: sketch lr: 0.000276\n",
      "batch 337 loss: 0.40831 acc: 0.88118 | v_loss: 0.55120 v_acc: 0.86621 |  iteration: 1581 teacher: 0 stage: sketch lr: 0.000276\n",
      "batch 338 loss: 0.34893 acc: 0.89225 | v_loss: 0.67814 v_acc: 0.84082 |  iteration: 1582 teacher: 0 stage: sketch lr: 0.000276\n",
      "batch 339 loss: 0.41857 acc: 0.87923 | v_loss: 0.76847 v_acc: 0.82194 |  iteration: 1583 teacher: 1 stage: sketch lr: 0.000277\n",
      "batch 340 loss: 0.41086 acc: 0.88021 | v_loss: 0.76550 v_acc: 0.81673 |  iteration: 1584 teacher: 0 stage: sketch lr: 0.000277\n",
      "batch 341 loss: 0.38094 acc: 0.89030 | v_loss: 0.58302 v_acc: 0.85482 |  iteration: 1585 teacher: 0 stage: sketch lr: 0.000277\n",
      "batch 342 loss: 0.52013 acc: 0.85319 | v_loss: 0.48948 v_acc: 0.86719 |  iteration: 1586 teacher: 1 stage: sketch lr: 0.000277\n",
      "batch 343 loss: 0.43669 acc: 0.86979 | v_loss: 0.38963 v_acc: 0.89388 |  iteration: 1587 teacher: 0 stage: sketch lr: 0.000277\n",
      "batch 344 loss: 0.34588 acc: 0.89062 | v_loss: 0.55829 v_acc: 0.86589 |  iteration: 1588 teacher: 0 stage: sketch lr: 0.000277\n",
      "batch 345 loss: 0.53891 acc: 0.85189 | v_loss: 0.62697 v_acc: 0.85221 |  iteration: 1589 teacher: 1 stage: sketch lr: 0.000278\n",
      "batch 346 loss: 0.43789 acc: 0.87044 | v_loss: 0.88905 v_acc: 0.81543 |  iteration: 1590 teacher: 1 stage: sketch lr: 0.000278\n",
      "batch 347 loss: 0.52184 acc: 0.86133 | v_loss: 0.69541 v_acc: 0.83529 |  iteration: 1591 teacher: 1 stage: sketch lr: 0.000278\n",
      "batch 348 loss: 0.50500 acc: 0.85677 | v_loss: 0.76082 v_acc: 0.82910 |  iteration: 1592 teacher: 1 stage: sketch lr: 0.000278\n",
      "batch 349 loss: 0.46816 acc: 0.86361 | v_loss: 0.50992 v_acc: 0.86393 |  iteration: 1593 teacher: 0 stage: sketch lr: 0.000278\n",
      "batch 350 loss: 0.43688 acc: 0.87044 | v_loss: 0.69643 v_acc: 0.83724 |  iteration: 1594 teacher: 0 stage: sketch lr: 0.000278\n",
      "batch 351 loss: 0.47657 acc: 0.86458 | v_loss: 0.94089 v_acc: 0.79818 |  iteration: 1595 teacher: 1 stage: sketch lr: 0.000279\n",
      "batch 352 loss: 0.46073 acc: 0.86751 | v_loss: 0.62528 v_acc: 0.85091 |  iteration: 1596 teacher: 0 stage: sketch lr: 0.000279\n",
      "batch 353 loss: 0.51355 acc: 0.84961 | v_loss: 0.61285 v_acc: 0.85449 |  iteration: 1597 teacher: 0 stage: sketch lr: 0.000279\n",
      "batch 354 loss: 0.50094 acc: 0.86361 | v_loss: 0.60742 v_acc: 0.85645 |  iteration: 1598 teacher: 1 stage: sketch lr: 0.000279\n",
      "batch 355 loss: 0.46977 acc: 0.86165 | v_loss: 0.57561 v_acc: 0.86068 |  iteration: 1599 teacher: 1 stage: sketch lr: 0.000279\n",
      "batch 356 loss: 0.49603 acc: 0.85221 | v_loss: 0.58972 v_acc: 0.85286 |  iteration: 1600 teacher: 0 stage: sketch lr: 0.000280\n",
      "batch 357 loss: 0.42108 acc: 0.87272 | v_loss: 0.72907 v_acc: 0.82520 |  iteration: 1601 teacher: 0 stage: sketch lr: 0.000280\n",
      "batch 358 loss: 0.36516 acc: 0.89030 | v_loss: 0.43094 v_acc: 0.89355 |  iteration: 1602 teacher: 0 stage: sketch lr: 0.000280\n",
      "batch 359 loss: 0.52519 acc: 0.84603 | v_loss: 1.05358 v_acc: 0.79915 |  iteration: 1603 teacher: 1 stage: sketch lr: 0.000280\n",
      "batch 360 loss: 0.41435 acc: 0.88151 | v_loss: 0.73601 v_acc: 0.83008 |  iteration: 1604 teacher: 0 stage: sketch lr: 0.000280\n",
      "batch 361 loss: 0.50598 acc: 0.85449 | v_loss: 0.77083 v_acc: 0.83040 |  iteration: 1605 teacher: 1 stage: sketch lr: 0.000280\n",
      "batch 362 loss: 0.40874 acc: 0.87858 | v_loss: 0.64393 v_acc: 0.85091 |  iteration: 1606 teacher: 0 stage: sketch lr: 0.000281\n",
      "batch 363 loss: 0.40333 acc: 0.88281 | v_loss: 0.60149 v_acc: 0.85254 |  iteration: 1607 teacher: 0 stage: sketch lr: 0.000281\n",
      "batch 364 loss: 0.39519 acc: 0.88053 | v_loss: 0.64825 v_acc: 0.85319 |  iteration: 1608 teacher: 0 stage: sketch lr: 0.000281\n",
      "batch 365 loss: 0.52173 acc: 0.84408 | v_loss: 0.59449 v_acc: 0.85872 |  iteration: 1609 teacher: 1 stage: sketch lr: 0.000281\n",
      "batch 366 loss: 0.44973 acc: 0.86784 | v_loss: 0.67097 v_acc: 0.84212 |  iteration: 1610 teacher: 1 stage: sketch lr: 0.000281\n",
      "batch 367 loss: 0.41319 acc: 0.87793 | v_loss: 0.62173 v_acc: 0.85840 |  iteration: 1611 teacher: 1 stage: sketch lr: 0.000281\n",
      "batch 368 loss: 0.46566 acc: 0.85872 | v_loss: 0.55109 v_acc: 0.86393 |  iteration: 1612 teacher: 1 stage: sketch lr: 0.000282\n",
      "batch 369 loss: 0.45610 acc: 0.86979 | v_loss: 0.46038 v_acc: 0.87630 |  iteration: 1613 teacher: 0 stage: sketch lr: 0.000282\n",
      "batch 370 loss: 0.35331 acc: 0.89486 | v_loss: 0.73233 v_acc: 0.82585 |  iteration: 1614 teacher: 0 stage: sketch lr: 0.000282\n",
      "batch 371 loss: 0.36815 acc: 0.89062 | v_loss: 0.66470 v_acc: 0.83757 |  iteration: 1615 teacher: 1 stage: sketch lr: 0.000282\n",
      "batch 372 loss: 0.37750 acc: 0.89225 | v_loss: 0.68949 v_acc: 0.82878 |  iteration: 1616 teacher: 0 stage: sketch lr: 0.000282\n",
      "batch 373 loss: 0.39371 acc: 0.88997 | v_loss: 0.90892 v_acc: 0.81868 |  iteration: 1617 teacher: 0 stage: sketch lr: 0.000282\n",
      "batch 374 loss: 0.44182 acc: 0.86491 | v_loss: 0.51567 v_acc: 0.87174 |  iteration: 1618 teacher: 0 stage: sketch lr: 0.000283\n",
      "batch 375 loss: 0.45985 acc: 0.86133 | v_loss: 0.65978 v_acc: 0.84310 |  iteration: 1619 teacher: 0 stage: sketch lr: 0.000283\n",
      "batch 376 loss: 0.39336 acc: 0.87272 | v_loss: 0.61027 v_acc: 0.85840 |  iteration: 1620 teacher: 0 stage: sketch lr: 0.000283\n",
      "batch 377 loss: 0.38394 acc: 0.88574 | v_loss: 0.54633 v_acc: 0.87012 |  iteration: 1621 teacher: 0 stage: sketch lr: 0.000283\n",
      "batch 378 loss: 0.44469 acc: 0.86914 | v_loss: 1.13334 v_acc: 0.78678 |  iteration: 1622 teacher: 0 stage: sketch lr: 0.000283\n",
      "batch 379 loss: 0.48677 acc: 0.85840 | v_loss: 0.50481 v_acc: 0.88053 |  iteration: 1623 teacher: 1 stage: sketch lr: 0.000284\n",
      "batch 380 loss: 0.46188 acc: 0.87109 | v_loss: 0.69256 v_acc: 0.84928 |  iteration: 1624 teacher: 1 stage: sketch lr: 0.000284\n",
      "batch 381 loss: 0.39612 acc: 0.87956 | v_loss: 0.59530 v_acc: 0.85677 |  iteration: 1625 teacher: 0 stage: sketch lr: 0.000284\n",
      "batch 382 loss: 0.38491 acc: 0.88932 | v_loss: 0.50174 v_acc: 0.87988 |  iteration: 1626 teacher: 1 stage: sketch lr: 0.000284\n",
      "batch 383 loss: 0.48997 acc: 0.86296 | v_loss: 0.59145 v_acc: 0.85970 |  iteration: 1627 teacher: 1 stage: sketch lr: 0.000284\n",
      "batch 384 loss: 0.48349 acc: 0.86947 | v_loss: 0.73271 v_acc: 0.83398 |  iteration: 1628 teacher: 0 stage: sketch lr: 0.000284\n",
      "batch 385 loss: 0.42321 acc: 0.87956 | v_loss: 0.50314 v_acc: 0.88053 |  iteration: 1629 teacher: 1 stage: sketch lr: 0.000285\n",
      "batch 386 loss: 0.32279 acc: 0.89714 | v_loss: 0.70851 v_acc: 0.83984 |  iteration: 1630 teacher: 0 stage: sketch lr: 0.000285\n",
      "batch 387 loss: 0.43886 acc: 0.87272 | v_loss: 0.48390 v_acc: 0.86589 |  iteration: 1631 teacher: 1 stage: sketch lr: 0.000285\n",
      "batch 388 loss: 0.34990 acc: 0.89681 | v_loss: 0.98645 v_acc: 0.80404 |  iteration: 1632 teacher: 1 stage: sketch lr: 0.000285\n",
      "batch 389 loss: 0.39321 acc: 0.88509 | v_loss: 0.67110 v_acc: 0.85189 |  iteration: 1633 teacher: 0 stage: sketch lr: 0.000285\n",
      "batch 390 loss: 0.39882 acc: 0.87826 | v_loss: 0.72615 v_acc: 0.84277 |  iteration: 1634 teacher: 0 stage: sketch lr: 0.000285\n",
      "batch 391 loss: 0.41226 acc: 0.87923 | v_loss: 0.53306 v_acc: 0.86133 |  iteration: 1635 teacher: 1 stage: sketch lr: 0.000286\n",
      "batch 392 loss: 0.39752 acc: 0.88249 | v_loss: 0.76024 v_acc: 0.82650 |  iteration: 1636 teacher: 0 stage: sketch lr: 0.000286\n",
      "batch 393 loss: 0.46917 acc: 0.87012 | v_loss: 0.55643 v_acc: 0.86426 |  iteration: 1637 teacher: 1 stage: sketch lr: 0.000286\n",
      "batch 394 loss: 0.41740 acc: 0.87793 | v_loss: 0.59574 v_acc: 0.84928 |  iteration: 1638 teacher: 1 stage: sketch lr: 0.000286\n",
      "batch 395 loss: 0.36650 acc: 0.89355 | v_loss: 0.52316 v_acc: 0.86816 |  iteration: 1639 teacher: 1 stage: sketch lr: 0.000286\n",
      "batch 396 loss: 0.44896 acc: 0.87370 | v_loss: 0.83945 v_acc: 0.82194 |  iteration: 1640 teacher: 1 stage: sketch lr: 0.000286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 397 loss: 0.46019 acc: 0.86947 | v_loss: 0.61831 v_acc: 0.85645 |  iteration: 1641 teacher: 0 stage: sketch lr: 0.000287\n",
      "batch 398 loss: 0.38144 acc: 0.88672 | v_loss: 0.66115 v_acc: 0.84440 |  iteration: 1642 teacher: 1 stage: sketch lr: 0.000287\n",
      "batch 399 loss: 0.41262 acc: 0.88509 | v_loss: 0.73838 v_acc: 0.82878 |  iteration: 1643 teacher: 0 stage: sketch lr: 0.000287\n",
      "batch 400 loss: 0.51547 acc: 0.85319 | v_loss: 0.55950 v_acc: 0.85254 |  iteration: 1644 teacher: 0 stage: sketch lr: 0.000287\n",
      "batch 401 loss: 0.32592 acc: 0.90202 | v_loss: 0.64710 v_acc: 0.83757 |  iteration: 1645 teacher: 1 stage: sketch lr: 0.000287\n",
      "batch 402 loss: 0.37418 acc: 0.88379 | v_loss: 0.66793 v_acc: 0.84408 |  iteration: 1646 teacher: 1 stage: sketch lr: 0.000288\n",
      "batch 403 loss: 0.38738 acc: 0.88086 | v_loss: 0.83642 v_acc: 0.82715 |  iteration: 1647 teacher: 0 stage: sketch lr: 0.000288\n",
      "batch 404 loss: 0.41106 acc: 0.88249 | v_loss: 0.65709 v_acc: 0.85514 |  iteration: 1648 teacher: 0 stage: sketch lr: 0.000288\n",
      "batch 405 loss: 0.38552 acc: 0.87988 | v_loss: 0.67861 v_acc: 0.84277 |  iteration: 1649 teacher: 0 stage: sketch lr: 0.000288\n",
      "batch 406 loss: 0.47159 acc: 0.86003 | v_loss: 0.74748 v_acc: 0.84635 |  iteration: 1650 teacher: 1 stage: sketch lr: 0.000288\n",
      "batch 407 loss: 0.35885 acc: 0.89128 | v_loss: 0.66970 v_acc: 0.83431 |  iteration: 1651 teacher: 0 stage: sketch lr: 0.000288\n",
      "batch 408 loss: 0.49422 acc: 0.85352 | v_loss: 0.57211 v_acc: 0.86523 |  iteration: 1652 teacher: 1 stage: sketch lr: 0.000289\n",
      "batch 409 loss: 0.51136 acc: 0.85091 | v_loss: 0.90044 v_acc: 0.82129 |  iteration: 1653 teacher: 1 stage: sketch lr: 0.000289\n",
      "batch 410 loss: 0.44893 acc: 0.86719 | v_loss: 0.71059 v_acc: 0.84668 |  iteration: 1654 teacher: 0 stage: sketch lr: 0.000289\n",
      "batch 411 loss: 0.40357 acc: 0.87956 | v_loss: 0.66467 v_acc: 0.84277 |  iteration: 1655 teacher: 1 stage: sketch lr: 0.000289\n",
      "batch 412 loss: 0.42724 acc: 0.87695 | v_loss: 0.67211 v_acc: 0.84180 |  iteration: 1656 teacher: 0 stage: sketch lr: 0.000289\n",
      "batch 413 loss: 0.41627 acc: 0.87240 | v_loss: 0.60117 v_acc: 0.86263 |  iteration: 1657 teacher: 0 stage: sketch lr: 0.000289\n",
      "batch 414 loss: 0.51548 acc: 0.86068 | v_loss: 0.54322 v_acc: 0.86849 |  iteration: 1658 teacher: 1 stage: sketch lr: 0.000290\n",
      "batch 415 loss: 0.48443 acc: 0.86165 | v_loss: 0.59968 v_acc: 0.85710 |  iteration: 1659 teacher: 0 stage: sketch lr: 0.000290\n",
      "batch 416 loss: 0.42632 acc: 0.87956 | v_loss: 0.74003 v_acc: 0.82096 |  iteration: 1660 teacher: 0 stage: sketch lr: 0.000290\n",
      "batch 417 loss: 0.44029 acc: 0.86914 | v_loss: 0.60958 v_acc: 0.86263 |  iteration: 1661 teacher: 1 stage: sketch lr: 0.000290\n",
      "batch 418 loss: 0.40774 acc: 0.88249 | v_loss: 0.70650 v_acc: 0.84375 |  iteration: 1662 teacher: 1 stage: sketch lr: 0.000290\n",
      "batch 419 loss: 0.42702 acc: 0.87240 | v_loss: 0.49009 v_acc: 0.86849 |  iteration: 1663 teacher: 1 stage: sketch lr: 0.000291\n",
      "batch 420 loss: 0.37192 acc: 0.88574 | v_loss: 0.63684 v_acc: 0.84570 |  iteration: 1664 teacher: 0 stage: sketch lr: 0.000291\n",
      "batch 421 loss: 0.44010 acc: 0.87109 | v_loss: 0.61134 v_acc: 0.84863 |  iteration: 1665 teacher: 0 stage: sketch lr: 0.000291\n",
      "batch 422 loss: 0.40154 acc: 0.88118 | v_loss: 0.87429 v_acc: 0.80990 |  iteration: 1666 teacher: 1 stage: sketch lr: 0.000291\n",
      "batch 423 loss: 0.42281 acc: 0.87500 | v_loss: 0.46359 v_acc: 0.87760 |  iteration: 1667 teacher: 1 stage: sketch lr: 0.000291\n",
      "batch 424 loss: 0.43123 acc: 0.86393 | v_loss: 0.38471 v_acc: 0.89453 |  iteration: 1668 teacher: 0 stage: sketch lr: 0.000291\n",
      "batch 425 loss: 0.39871 acc: 0.88281 | v_loss: 0.64429 v_acc: 0.85710 |  iteration: 1669 teacher: 1 stage: sketch lr: 0.000292\n",
      "batch 426 loss: 0.41867 acc: 0.87370 | v_loss: 0.68765 v_acc: 0.85514 |  iteration: 1670 teacher: 1 stage: sketch lr: 0.000292\n",
      "batch 427 loss: 0.43038 acc: 0.87695 | v_loss: 0.74717 v_acc: 0.83529 |  iteration: 1671 teacher: 1 stage: sketch lr: 0.000292\n",
      "batch 428 loss: 0.42509 acc: 0.87858 | v_loss: 0.58471 v_acc: 0.86751 |  iteration: 1672 teacher: 1 stage: sketch lr: 0.000292\n",
      "batch 429 loss: 0.40679 acc: 0.87760 | v_loss: 0.61906 v_acc: 0.84635 |  iteration: 1673 teacher: 0 stage: sketch lr: 0.000292\n",
      "batch 430 loss: 0.44456 acc: 0.87109 | v_loss: 0.74940 v_acc: 0.81771 |  iteration: 1674 teacher: 1 stage: sketch lr: 0.000292\n",
      "batch 431 loss: 0.45895 acc: 0.86751 | v_loss: 0.71168 v_acc: 0.82227 |  iteration: 1675 teacher: 1 stage: sketch lr: 0.000293\n",
      "batch 432 loss: 0.41766 acc: 0.87663 | v_loss: 0.57631 v_acc: 0.86165 |  iteration: 1676 teacher: 0 stage: sketch lr: 0.000293\n",
      "batch 433 loss: 0.42942 acc: 0.87402 | v_loss: 0.48124 v_acc: 0.86393 |  iteration: 1677 teacher: 0 stage: sketch lr: 0.000293\n",
      "batch 434 loss: 0.42282 acc: 0.88021 | v_loss: 0.38875 v_acc: 0.89030 |  iteration: 1678 teacher: 1 stage: sketch lr: 0.000293\n",
      "batch 435 loss: 0.34238 acc: 0.90332 | v_loss: 0.57463 v_acc: 0.86816 |  iteration: 1679 teacher: 1 stage: sketch lr: 0.000293\n",
      "batch 436 loss: 0.37722 acc: 0.88379 | v_loss: 0.59767 v_acc: 0.84635 |  iteration: 1680 teacher: 0 stage: sketch lr: 0.000293\n",
      "batch 437 loss: 0.36314 acc: 0.89095 | v_loss: 0.86050 v_acc: 0.82747 |  iteration: 1681 teacher: 1 stage: sketch lr: 0.000294\n",
      "batch 438 loss: 0.40078 acc: 0.87663 | v_loss: 0.60955 v_acc: 0.85938 |  iteration: 1682 teacher: 0 stage: sketch lr: 0.000294\n",
      "batch 439 loss: 0.39395 acc: 0.88444 | v_loss: 0.74874 v_acc: 0.83431 |  iteration: 1683 teacher: 1 stage: sketch lr: 0.000294\n",
      "batch 440 loss: 0.36729 acc: 0.89258 | v_loss: 0.51942 v_acc: 0.87142 |  iteration: 1684 teacher: 1 stage: sketch lr: 0.000294\n",
      "batch 441 loss: 0.38922 acc: 0.88411 | v_loss: 0.63741 v_acc: 0.85352 |  iteration: 1685 teacher: 0 stage: sketch lr: 0.000294\n",
      "batch 442 loss: 0.43844 acc: 0.88053 | v_loss: 0.86689 v_acc: 0.81348 |  iteration: 1686 teacher: 1 stage: sketch lr: 0.000295\n",
      "batch 443 loss: 0.43821 acc: 0.87337 | v_loss: 0.58088 v_acc: 0.87077 |  iteration: 1687 teacher: 0 stage: sketch lr: 0.000295\n",
      "batch 444 loss: 0.30952 acc: 0.90690 | v_loss: 0.57644 v_acc: 0.86914 |  iteration: 1688 teacher: 0 stage: sketch lr: 0.000295\n",
      "batch 445 loss: 0.34982 acc: 0.89518 | v_loss: 0.54949 v_acc: 0.86458 |  iteration: 1689 teacher: 0 stage: sketch lr: 0.000295\n",
      "batch 446 loss: 0.45212 acc: 0.86751 | v_loss: 0.49715 v_acc: 0.88021 |  iteration: 1690 teacher: 1 stage: sketch lr: 0.000295\n",
      "batch 447 loss: 0.44000 acc: 0.86947 | v_loss: 0.56876 v_acc: 0.86784 |  iteration: 1691 teacher: 1 stage: sketch lr: 0.000295\n",
      "batch 448 loss: 0.40763 acc: 0.87826 | v_loss: 0.74118 v_acc: 0.82975 |  iteration: 1692 teacher: 1 stage: sketch lr: 0.000296\n",
      "batch 449 loss: 0.41559 acc: 0.88444 | v_loss: 0.45287 v_acc: 0.89095 |  iteration: 1693 teacher: 0 stage: sketch lr: 0.000296\n",
      "batch 450 loss: 0.35683 acc: 0.89160 | v_loss: 0.97381 v_acc: 0.81087 |  iteration: 1694 teacher: 0 stage: sketch lr: 0.000296\n",
      "batch 451 loss: 0.44529 acc: 0.86816 | v_loss: 0.74779 v_acc: 0.83691 |  iteration: 1695 teacher: 0 stage: sketch lr: 0.000296\n",
      "batch 452 loss: 0.43978 acc: 0.87044 | v_loss: 0.77265 v_acc: 0.82650 |  iteration: 1696 teacher: 1 stage: sketch lr: 0.000296\n",
      "batch 453 loss: 0.44655 acc: 0.86947 | v_loss: 0.61777 v_acc: 0.86198 |  iteration: 1697 teacher: 1 stage: sketch lr: 0.000296\n",
      "batch 454 loss: 0.42014 acc: 0.87663 | v_loss: 0.62280 v_acc: 0.84538 |  iteration: 1698 teacher: 0 stage: sketch lr: 0.000297\n",
      "batch 455 loss: 0.41902 acc: 0.87337 | v_loss: 0.68004 v_acc: 0.85124 |  iteration: 1699 teacher: 0 stage: sketch lr: 0.000297\n",
      "batch 456 loss: 0.37531 acc: 0.89030 | v_loss: 0.59909 v_acc: 0.86426 |  iteration: 1700 teacher: 0 stage: sketch lr: 0.000297\n",
      "batch 457 loss: 0.50246 acc: 0.86230 | v_loss: 0.63097 v_acc: 0.85221 |  iteration: 1701 teacher: 1 stage: sketch lr: 0.000297\n",
      "batch 458 loss: 0.44377 acc: 0.87598 | v_loss: 0.62213 v_acc: 0.86458 |  iteration: 1702 teacher: 1 stage: sketch lr: 0.000297\n",
      "batch 459 loss: 0.38719 acc: 0.88216 | v_loss: 0.55961 v_acc: 0.86230 |  iteration: 1703 teacher: 0 stage: sketch lr: 0.000298\n",
      "batch 460 loss: 0.40818 acc: 0.87305 | v_loss: 0.41381 v_acc: 0.88867 |  iteration: 1704 teacher: 0 stage: sketch lr: 0.000298\n",
      "batch 461 loss: 0.36726 acc: 0.88574 | v_loss: 0.74673 v_acc: 0.84310 |  iteration: 1705 teacher: 0 stage: sketch lr: 0.000298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 462 loss: 0.44335 acc: 0.86491 | v_loss: 0.68312 v_acc: 0.84408 |  iteration: 1706 teacher: 1 stage: sketch lr: 0.000298\n",
      "batch 463 loss: 0.37329 acc: 0.89681 | v_loss: 0.77293 v_acc: 0.83268 |  iteration: 1707 teacher: 1 stage: sketch lr: 0.000298\n",
      "batch 464 loss: 0.46894 acc: 0.86816 | v_loss: 0.91217 v_acc: 0.81803 |  iteration: 1708 teacher: 0 stage: sketch lr: 0.000298\n",
      "batch 465 loss: 0.48010 acc: 0.86393 | v_loss: 0.53033 v_acc: 0.87533 |  iteration: 1709 teacher: 0 stage: sketch lr: 0.000299\n",
      "batch 466 loss: 0.38359 acc: 0.88118 | v_loss: 0.61778 v_acc: 0.85091 |  iteration: 1710 teacher: 0 stage: sketch lr: 0.000299\n",
      "batch 467 loss: 0.37771 acc: 0.88346 | v_loss: 0.61420 v_acc: 0.85775 |  iteration: 1711 teacher: 1 stage: sketch lr: 0.000299\n",
      "batch 468 loss: 0.40303 acc: 0.88053 | v_loss: 0.51522 v_acc: 0.87142 |  iteration: 1712 teacher: 0 stage: sketch lr: 0.000299\n",
      "batch 469 loss: 0.43811 acc: 0.86458 | v_loss: 1.08017 v_acc: 0.79622 |  iteration: 1713 teacher: 1 stage: sketch lr: 0.000299\n",
      "batch 470 loss: 0.58258 acc: 0.84017 | v_loss: 0.48945 v_acc: 0.87923 |  iteration: 1714 teacher: 1 stage: sketch lr: 0.000299\n",
      "batch 471 loss: 0.42758 acc: 0.86914 | v_loss: 0.65914 v_acc: 0.85254 |  iteration: 1715 teacher: 0 stage: sketch lr: 0.000300\n",
      "batch 472 loss: 0.46934 acc: 0.86393 | v_loss: 0.60684 v_acc: 0.86133 |  iteration: 1716 teacher: 0 stage: sketch lr: 0.000300\n",
      "batch 473 loss: 0.40211 acc: 0.87630 | v_loss: 0.48335 v_acc: 0.88770 |  iteration: 1717 teacher: 1 stage: sketch lr: 0.000300\n",
      "batch 474 loss: 0.47326 acc: 0.86816 | v_loss: 0.58353 v_acc: 0.86361 |  iteration: 1718 teacher: 1 stage: sketch lr: 0.000300\n",
      "batch 475 loss: 0.40963 acc: 0.88281 | v_loss: 0.70742 v_acc: 0.84049 |  iteration: 1719 teacher: 0 stage: sketch lr: 0.000300\n",
      "batch 476 loss: 0.41576 acc: 0.88118 | v_loss: 0.56624 v_acc: 0.86882 |  iteration: 1720 teacher: 0 stage: sketch lr: 0.000300\n",
      "batch 477 loss: 0.51486 acc: 0.86100 | v_loss: 0.72291 v_acc: 0.84017 |  iteration: 1721 teacher: 1 stage: sketch lr: 0.000301\n",
      "batch 478 loss: 0.41605 acc: 0.87174 | v_loss: 0.50531 v_acc: 0.86621 |  iteration: 1722 teacher: 1 stage: sketch lr: 0.000301\n",
      "batch 479 loss: 0.40154 acc: 0.88281 | v_loss: 1.06486 v_acc: 0.81380 |  iteration: 1723 teacher: 1 stage: sketch lr: 0.000301\n",
      "batch 480 loss: 0.40131 acc: 0.88639 | v_loss: 0.66500 v_acc: 0.86133 |  iteration: 1724 teacher: 0 stage: sketch lr: 0.000301\n",
      "batch 481 loss: 0.34433 acc: 0.90560 | v_loss: 0.69978 v_acc: 0.85319 |  iteration: 1725 teacher: 1 stage: sketch lr: 0.000301\n",
      "batch 482 loss: 0.38349 acc: 0.89225 | v_loss: 0.50810 v_acc: 0.86849 |  iteration: 1726 teacher: 0 stage: sketch lr: 0.000302\n",
      "batch 483 loss: 0.38183 acc: 0.88574 | v_loss: 0.74959 v_acc: 0.83594 |  iteration: 1727 teacher: 0 stage: sketch lr: 0.000302\n",
      "batch 484 loss: 0.35879 acc: 0.88932 | v_loss: 0.56379 v_acc: 0.86035 |  iteration: 1728 teacher: 1 stage: sketch lr: 0.000302\n",
      "batch 485 loss: 0.42547 acc: 0.87240 | v_loss: 0.57621 v_acc: 0.85352 |  iteration: 1729 teacher: 0 stage: sketch lr: 0.000302\n",
      "batch 486 loss: 0.40643 acc: 0.87988 | v_loss: 0.52223 v_acc: 0.87012 |  iteration: 1730 teacher: 0 stage: sketch lr: 0.000302\n",
      "batch 487 loss: 0.45538 acc: 0.87272 | v_loss: 0.83667 v_acc: 0.82227 |  iteration: 1731 teacher: 0 stage: sketch lr: 0.000302\n",
      "batch 488 loss: 0.44263 acc: 0.87663 | v_loss: 0.59425 v_acc: 0.86068 |  iteration: 1732 teacher: 1 stage: sketch lr: 0.000303\n",
      "batch 489 loss: 0.36608 acc: 0.88932 | v_loss: 0.65625 v_acc: 0.85059 |  iteration: 1733 teacher: 1 stage: sketch lr: 0.000303\n",
      "batch 490 loss: 0.39832 acc: 0.88249 | v_loss: 0.79644 v_acc: 0.81966 |  iteration: 1734 teacher: 1 stage: sketch lr: 0.000303\n",
      "batch 491 loss: 0.45718 acc: 0.87533 | v_loss: 0.59936 v_acc: 0.84766 |  iteration: 1735 teacher: 1 stage: sketch lr: 0.000303\n",
      "batch 492 loss: 0.36749 acc: 0.89193 | v_loss: 0.63521 v_acc: 0.83464 |  iteration: 1736 teacher: 0 stage: sketch lr: 0.000303\n",
      "batch 493 loss: 0.40496 acc: 0.87598 | v_loss: 0.66875 v_acc: 0.85124 |  iteration: 1737 teacher: 0 stage: sketch lr: 0.000303\n",
      "batch 494 loss: 0.43895 acc: 0.87337 | v_loss: 0.77942 v_acc: 0.82292 |  iteration: 1738 teacher: 1 stage: sketch lr: 0.000304\n",
      "batch 495 loss: 0.42482 acc: 0.87207 | v_loss: 0.64581 v_acc: 0.85482 |  iteration: 1739 teacher: 0 stage: sketch lr: 0.000304\n",
      "batch 496 loss: 0.39682 acc: 0.87012 | v_loss: 0.68104 v_acc: 0.85091 |  iteration: 1740 teacher: 1 stage: sketch lr: 0.000304\n",
      "batch 497 loss: 0.36984 acc: 0.88607 | v_loss: 0.75760 v_acc: 0.84603 |  iteration: 1741 teacher: 0 stage: sketch lr: 0.000304\n",
      "batch 498 loss: 0.36061 acc: 0.89779 | v_loss: 0.68355 v_acc: 0.83561 |  iteration: 1742 teacher: 0 stage: sketch lr: 0.000304\n",
      "batch 499 loss: 0.40723 acc: 0.87923 | v_loss: 0.51710 v_acc: 0.87630 |  iteration: 1743 teacher: 1 stage: sketch lr: 0.000304\n",
      "batch 500 loss: 0.42679 acc: 0.87663 | v_loss: 0.88338 v_acc: 0.82520 |  iteration: 1744 teacher: 1 stage: sketch lr: 0.000305\n",
      "batch 501 loss: 0.40322 acc: 0.87695 | v_loss: 0.69158 v_acc: 0.85514 |  iteration: 1745 teacher: 1 stage: sketch lr: 0.000305\n",
      "batch 502 loss: 0.34985 acc: 0.89583 | v_loss: 0.67942 v_acc: 0.84277 |  iteration: 1746 teacher: 0 stage: sketch lr: 0.000305\n",
      "batch 503 loss: 0.35733 acc: 0.89128 | v_loss: 0.61682 v_acc: 0.85189 |  iteration: 1747 teacher: 0 stage: sketch lr: 0.000305\n",
      "batch 504 loss: 0.38628 acc: 0.88607 | v_loss: 0.60116 v_acc: 0.85970 |  iteration: 1748 teacher: 1 stage: sketch lr: 0.000305\n",
      "batch 505 loss: 0.32280 acc: 0.90820 | v_loss: 0.52473 v_acc: 0.87533 |  iteration: 1749 teacher: 0 stage: sketch lr: 0.000306\n",
      "batch 506 loss: 0.41677 acc: 0.88574 | v_loss: 0.57625 v_acc: 0.86849 |  iteration: 1750 teacher: 1 stage: sketch lr: 0.000306\n",
      "batch 507 loss: 0.40541 acc: 0.87760 | v_loss: 0.71703 v_acc: 0.83561 |  iteration: 1751 teacher: 0 stage: sketch lr: 0.000306\n",
      "batch 508 loss: 0.43615 acc: 0.88151 | v_loss: 0.67881 v_acc: 0.86035 |  iteration: 1752 teacher: 1 stage: sketch lr: 0.000306\n",
      "batch 509 loss: 0.38583 acc: 0.88444 | v_loss: 0.66281 v_acc: 0.85775 |  iteration: 1753 teacher: 1 stage: sketch lr: 0.000306\n",
      "batch 510 loss: 0.39549 acc: 0.88672 | v_loss: 0.43871 v_acc: 0.88770 |  iteration: 1754 teacher: 1 stage: sketch lr: 0.000306\n",
      "batch 511 loss: 0.34139 acc: 0.89290 | v_loss: 0.60903 v_acc: 0.85872 |  iteration: 1755 teacher: 0 stage: sketch lr: 0.000307\n",
      "batch 512 loss: 0.43845 acc: 0.87435 | v_loss: 0.60856 v_acc: 0.84961 |  iteration: 1756 teacher: 1 stage: sketch lr: 0.000307\n",
      "batch 513 loss: 0.38764 acc: 0.88607 | v_loss: 0.90654 v_acc: 0.81380 |  iteration: 1757 teacher: 0 stage: sketch lr: 0.000307\n",
      "batch 514 loss: 0.38310 acc: 0.88216 | v_loss: 0.44188 v_acc: 0.89030 |  iteration: 1758 teacher: 1 stage: sketch lr: 0.000307\n",
      "batch 515 loss: 0.39957 acc: 0.88802 | v_loss: 0.38673 v_acc: 0.89714 |  iteration: 1759 teacher: 0 stage: sketch lr: 0.000307\n",
      "batch 516 loss: 0.38247 acc: 0.88737 | v_loss: 0.61532 v_acc: 0.86263 |  iteration: 1760 teacher: 1 stage: sketch lr: 0.000307\n",
      "batch 517 loss: 0.37416 acc: 0.89225 | v_loss: 0.65952 v_acc: 0.86263 |  iteration: 1761 teacher: 0 stage: sketch lr: 0.000308\n",
      "batch 518 loss: 0.38186 acc: 0.88021 | v_loss: 0.76612 v_acc: 0.83464 |  iteration: 1762 teacher: 0 stage: sketch lr: 0.000308\n",
      "batch 519 loss: 0.42341 acc: 0.87077 | v_loss: 0.52852 v_acc: 0.87207 |  iteration: 1763 teacher: 0 stage: sketch lr: 0.000308\n",
      "batch 520 loss: 0.48349 acc: 0.87044 | v_loss: 0.62888 v_acc: 0.84863 |  iteration: 1764 teacher: 1 stage: sketch lr: 0.000308\n",
      "batch 521 loss: 0.36676 acc: 0.89616 | v_loss: 0.71471 v_acc: 0.82487 |  iteration: 1765 teacher: 0 stage: sketch lr: 0.000308\n",
      "batch 522 loss: 0.40777 acc: 0.87695 | v_loss: 0.74967 v_acc: 0.82389 |  iteration: 1766 teacher: 0 stage: sketch lr: 0.000309\n",
      "batch 523 loss: 0.39355 acc: 0.88216 | v_loss: 0.54635 v_acc: 0.87240 |  iteration: 1767 teacher: 1 stage: sketch lr: 0.000309\n",
      "batch 524 loss: 0.44467 acc: 0.87305 | v_loss: 0.50780 v_acc: 0.87467 |  iteration: 1768 teacher: 1 stage: sketch lr: 0.000309\n",
      "batch 525 loss: 0.45029 acc: 0.86003 | v_loss: 0.37969 v_acc: 0.90007 |  iteration: 1769 teacher: 0 stage: sketch lr: 0.000309\n",
      "batch 526 loss: 0.40584 acc: 0.87858 | v_loss: 0.54420 v_acc: 0.87760 |  iteration: 1770 teacher: 0 stage: sketch lr: 0.000309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 527 loss: 0.29899 acc: 0.90560 | v_loss: 0.57484 v_acc: 0.86686 |  iteration: 1771 teacher: 1 stage: sketch lr: 0.000309\n",
      "batch 528 loss: 0.40292 acc: 0.88867 | v_loss: 0.90468 v_acc: 0.83138 |  iteration: 1772 teacher: 1 stage: sketch lr: 0.000310\n",
      "batch 529 loss: 0.41575 acc: 0.87695 | v_loss: 0.59856 v_acc: 0.85710 |  iteration: 1773 teacher: 0 stage: sketch lr: 0.000310\n",
      "batch 530 loss: 0.39317 acc: 0.88314 | v_loss: 0.68462 v_acc: 0.84701 |  iteration: 1774 teacher: 0 stage: sketch lr: 0.000310\n",
      "batch 531 loss: 0.43592 acc: 0.87663 | v_loss: 0.48402 v_acc: 0.87565 |  iteration: 1775 teacher: 0 stage: sketch lr: 0.000310\n",
      "batch 532 loss: 0.35530 acc: 0.89290 | v_loss: 0.63713 v_acc: 0.85449 |  iteration: 1776 teacher: 0 stage: sketch lr: 0.000310\n",
      "batch 533 loss: 0.37744 acc: 0.88770 | v_loss: 0.87933 v_acc: 0.81999 |  iteration: 1777 teacher: 1 stage: sketch lr: 0.000310\n",
      "batch 534 loss: 0.39274 acc: 0.88346 | v_loss: 0.59754 v_acc: 0.86719 |  iteration: 1778 teacher: 1 stage: sketch lr: 0.000311\n",
      "batch 535 loss: 0.43461 acc: 0.88346 | v_loss: 0.54541 v_acc: 0.87272 |  iteration: 1779 teacher: 1 stage: sketch lr: 0.000311\n",
      "batch 536 loss: 0.34580 acc: 0.89714 | v_loss: 0.51907 v_acc: 0.86882 |  iteration: 1780 teacher: 0 stage: sketch lr: 0.000311\n",
      "batch 537 loss: 0.39240 acc: 0.88053 | v_loss: 0.50004 v_acc: 0.87793 |  iteration: 1781 teacher: 1 stage: sketch lr: 0.000311\n",
      "batch 538 loss: 0.42952 acc: 0.87826 | v_loss: 0.55812 v_acc: 0.87533 |  iteration: 1782 teacher: 1 stage: sketch lr: 0.000311\n",
      "batch 539 loss: 0.34670 acc: 0.88997 | v_loss: 0.67519 v_acc: 0.83984 |  iteration: 1783 teacher: 1 stage: sketch lr: 0.000311\n",
      "batch 540 loss: 0.42106 acc: 0.87826 | v_loss: 0.43324 v_acc: 0.90755 |  iteration: 1784 teacher: 1 stage: sketch lr: 0.000312\n",
      "batch 541 loss: 0.39221 acc: 0.87988 | v_loss: 0.99696 v_acc: 0.81771 |  iteration: 1785 teacher: 1 stage: sketch lr: 0.000312\n",
      "batch 542 loss: 0.41212 acc: 0.87598 | v_loss: 0.71519 v_acc: 0.85156 |  iteration: 1786 teacher: 0 stage: sketch lr: 0.000312\n",
      "batch 543 loss: 0.31886 acc: 0.90560 | v_loss: 0.73805 v_acc: 0.83431 |  iteration: 1787 teacher: 1 stage: sketch lr: 0.000312\n",
      "batch 544 loss: 0.39037 acc: 0.88867 | v_loss: 0.60056 v_acc: 0.86686 |  iteration: 1788 teacher: 0 stage: sketch lr: 0.000312\n",
      "batch 545 loss: 0.34926 acc: 0.89128 | v_loss: 0.59209 v_acc: 0.86328 |  iteration: 1789 teacher: 0 stage: sketch lr: 0.000313\n",
      "batch 546 loss: 0.34829 acc: 0.89323 | v_loss: 0.64555 v_acc: 0.86003 |  iteration: 1790 teacher: 0 stage: sketch lr: 0.000313\n",
      "batch 547 loss: 0.36756 acc: 0.89876 | v_loss: 0.60428 v_acc: 0.86589 |  iteration: 1791 teacher: 1 stage: sketch lr: 0.000313\n",
      "batch 548 loss: 0.34613 acc: 0.88932 | v_loss: 0.59799 v_acc: 0.85807 |  iteration: 1792 teacher: 0 stage: sketch lr: 0.000313\n",
      "batch 549 loss: 0.35736 acc: 0.89323 | v_loss: 0.55251 v_acc: 0.87988 |  iteration: 1793 teacher: 1 stage: sketch lr: 0.000313\n",
      "batch 550 loss: 0.41557 acc: 0.87695 | v_loss: 0.52817 v_acc: 0.87077 |  iteration: 1794 teacher: 1 stage: sketch lr: 0.000313\n",
      "batch 551 loss: 0.35293 acc: 0.89974 | v_loss: 0.40959 v_acc: 0.89421 |  iteration: 1795 teacher: 0 stage: sketch lr: 0.000314\n",
      "batch 552 loss: 0.40591 acc: 0.88509 | v_loss: 0.73053 v_acc: 0.83529 |  iteration: 1796 teacher: 1 stage: sketch lr: 0.000314\n",
      "batch 553 loss: 0.32920 acc: 0.89876 | v_loss: 0.61230 v_acc: 0.85221 |  iteration: 1797 teacher: 0 stage: sketch lr: 0.000314\n",
      "batch 554 loss: 0.33166 acc: 0.89616 | v_loss: 0.71124 v_acc: 0.83789 |  iteration: 1798 teacher: 0 stage: sketch lr: 0.000314\n",
      "batch 555 loss: 0.32249 acc: 0.90462 | v_loss: 0.90617 v_acc: 0.82227 |  iteration: 1799 teacher: 1 stage: sketch lr: 0.000314\n",
      "batch 556 loss: 0.37833 acc: 0.88477 | v_loss: 0.53284 v_acc: 0.87272 |  iteration: 1800 teacher: 0 stage: sketch lr: 0.000314\n",
      "batch 557 loss: 0.40443 acc: 0.87891 | v_loss: 0.61899 v_acc: 0.85840 |  iteration: 1801 teacher: 0 stage: sketch lr: 0.000315\n",
      "batch 558 loss: 0.36333 acc: 0.89128 | v_loss: 0.59628 v_acc: 0.86882 |  iteration: 1802 teacher: 0 stage: sketch lr: 0.000315\n",
      "batch 559 loss: 0.35928 acc: 0.88997 | v_loss: 0.52446 v_acc: 0.87305 |  iteration: 1803 teacher: 0 stage: sketch lr: 0.000315\n",
      "batch 560 loss: 0.48815 acc: 0.87826 | v_loss: 1.11915 v_acc: 0.80924 |  iteration: 1804 teacher: 1 stage: sketch lr: 0.000315\n",
      "batch 561 loss: 0.37890 acc: 0.88900 | v_loss: 0.46333 v_acc: 0.88607 |  iteration: 1805 teacher: 1 stage: sketch lr: 0.000315\n",
      "batch 562 loss: 0.44040 acc: 0.87630 | v_loss: 0.67857 v_acc: 0.86133 |  iteration: 1806 teacher: 1 stage: sketch lr: 0.000315\n",
      "batch 563 loss: 0.34889 acc: 0.89811 | v_loss: 0.60776 v_acc: 0.85742 |  iteration: 1807 teacher: 1 stage: sketch lr: 0.000316\n",
      "batch 564 loss: 0.37752 acc: 0.89551 | v_loss: 0.45765 v_acc: 0.88867 |  iteration: 1808 teacher: 1 stage: sketch lr: 0.000316\n",
      "batch 565 loss: 0.33720 acc: 0.89779 | v_loss: 0.56809 v_acc: 0.86686 |  iteration: 1809 teacher: 0 stage: sketch lr: 0.000316\n",
      "batch 566 loss: 0.34651 acc: 0.88867 | v_loss: 0.69676 v_acc: 0.84668 |  iteration: 1810 teacher: 0 stage: sketch lr: 0.000316\n",
      "batch 567 loss: 0.44561 acc: 0.87109 | v_loss: 0.52783 v_acc: 0.87598 |  iteration: 1811 teacher: 1 stage: sketch lr: 0.000316\n",
      "batch 568 loss: 0.32282 acc: 0.90072 | v_loss: 0.69682 v_acc: 0.85026 |  iteration: 1812 teacher: 0 stage: sketch lr: 0.000317\n",
      "batch 569 loss: 0.34142 acc: 0.89421 | v_loss: 0.48830 v_acc: 0.87272 |  iteration: 1813 teacher: 1 stage: sketch lr: 0.000317\n",
      "batch 570 loss: 0.43179 acc: 0.88314 | v_loss: 1.03306 v_acc: 0.80241 |  iteration: 1814 teacher: 0 stage: sketch lr: 0.000317\n",
      "batch 571 loss: 0.41215 acc: 0.88542 | v_loss: 0.64085 v_acc: 0.86328 |  iteration: 1815 teacher: 0 stage: sketch lr: 0.000317\n",
      "batch 572 loss: 0.41066 acc: 0.88379 | v_loss: 0.70399 v_acc: 0.84831 |  iteration: 1816 teacher: 0 stage: sketch lr: 0.000317\n",
      "batch 573 loss: 0.37734 acc: 0.88509 | v_loss: 0.50664 v_acc: 0.86784 |  iteration: 1817 teacher: 0 stage: sketch lr: 0.000317\n",
      "batch 574 loss: 0.41091 acc: 0.87077 | v_loss: 0.76484 v_acc: 0.83171 |  iteration: 1818 teacher: 1 stage: sketch lr: 0.000318\n",
      "batch 575 loss: 0.37361 acc: 0.89030 | v_loss: 0.53155 v_acc: 0.86751 |  iteration: 1819 teacher: 1 stage: sketch lr: 0.000318\n",
      "batch 576 loss: 0.33976 acc: 0.89714 | v_loss: 0.55648 v_acc: 0.86491 |  iteration: 1820 teacher: 1 stage: sketch lr: 0.000318\n",
      "batch 577 loss: 0.37792 acc: 0.88704 | v_loss: 0.50218 v_acc: 0.87370 |  iteration: 1821 teacher: 0 stage: sketch lr: 0.000318\n",
      "batch 578 loss: 0.43003 acc: 0.88021 | v_loss: 0.74638 v_acc: 0.83919 |  iteration: 1822 teacher: 1 stage: sketch lr: 0.000318\n",
      "batch 579 loss: 0.39985 acc: 0.88444 | v_loss: 0.58358 v_acc: 0.87174 |  iteration: 1823 teacher: 1 stage: sketch lr: 0.000318\n",
      "batch 580 loss: 0.41011 acc: 0.86882 | v_loss: 0.64717 v_acc: 0.85645 |  iteration: 1824 teacher: 0 stage: sketch lr: 0.000319\n",
      "batch 581 loss: 0.33245 acc: 0.90495 | v_loss: 0.74046 v_acc: 0.83073 |  iteration: 1825 teacher: 0 stage: sketch lr: 0.000319\n",
      "batch 582 loss: 0.42302 acc: 0.87988 | v_loss: 0.53175 v_acc: 0.86361 |  iteration: 1826 teacher: 0 stage: sketch lr: 0.000319\n",
      "batch 583 loss: 0.41717 acc: 0.87891 | v_loss: 0.61341 v_acc: 0.84212 |  iteration: 1827 teacher: 1 stage: sketch lr: 0.000319\n",
      "batch 584 loss: 0.47041 acc: 0.86849 | v_loss: 0.66508 v_acc: 0.84408 |  iteration: 1828 teacher: 1 stage: sketch lr: 0.000319\n",
      "batch 585 loss: 0.37481 acc: 0.89160 | v_loss: 0.81853 v_acc: 0.83431 |  iteration: 1829 teacher: 1 stage: sketch lr: 0.000320\n",
      "batch 586 loss: 0.31874 acc: 0.90299 | v_loss: 0.64126 v_acc: 0.85677 |  iteration: 1830 teacher: 0 stage: sketch lr: 0.000320\n",
      "batch 587 loss: 0.34858 acc: 0.89681 | v_loss: 0.66668 v_acc: 0.85449 |  iteration: 1831 teacher: 1 stage: sketch lr: 0.000320\n",
      "batch 588 loss: 0.42914 acc: 0.88021 | v_loss: 0.69866 v_acc: 0.84928 |  iteration: 1832 teacher: 1 stage: sketch lr: 0.000320\n",
      "batch 589 loss: 0.44731 acc: 0.86361 | v_loss: 0.66835 v_acc: 0.83854 |  iteration: 1833 teacher: 1 stage: sketch lr: 0.000320\n",
      "batch 590 loss: 0.48906 acc: 0.86784 | v_loss: 0.50773 v_acc: 0.87826 |  iteration: 1834 teacher: 1 stage: sketch lr: 0.000320\n",
      "batch 591 loss: 0.31182 acc: 0.90658 | v_loss: 0.88215 v_acc: 0.83203 |  iteration: 1835 teacher: 0 stage: sketch lr: 0.000321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 592 loss: 0.45526 acc: 0.87988 | v_loss: 0.68678 v_acc: 0.84993 |  iteration: 1836 teacher: 1 stage: sketch lr: 0.000321\n",
      "batch 593 loss: 0.41482 acc: 0.87370 | v_loss: 0.62644 v_acc: 0.85547 |  iteration: 1837 teacher: 1 stage: sketch lr: 0.000321\n",
      "batch 594 loss: 0.37364 acc: 0.88965 | v_loss: 0.60120 v_acc: 0.85384 |  iteration: 1838 teacher: 1 stage: sketch lr: 0.000321\n",
      "batch 595 loss: 0.34421 acc: 0.89290 | v_loss: 0.52808 v_acc: 0.87663 |  iteration: 1839 teacher: 0 stage: sketch lr: 0.000321\n",
      "batch 596 loss: 0.35024 acc: 0.89909 | v_loss: 0.52580 v_acc: 0.88021 |  iteration: 1840 teacher: 0 stage: sketch lr: 0.000321\n",
      "batch 597 loss: 0.37299 acc: 0.89388 | v_loss: 0.55973 v_acc: 0.87077 |  iteration: 1841 teacher: 0 stage: sketch lr: 0.000322\n",
      "batch 598 loss: 0.40297 acc: 0.88737 | v_loss: 0.68344 v_acc: 0.83822 |  iteration: 1842 teacher: 1 stage: sketch lr: 0.000322\n",
      "batch 599 loss: 0.38261 acc: 0.88835 | v_loss: 0.61234 v_acc: 0.87435 |  iteration: 1843 teacher: 1 stage: sketch lr: 0.000322\n",
      "batch 600 loss: 0.39688 acc: 0.88835 | v_loss: 0.71831 v_acc: 0.85742 |  iteration: 1844 teacher: 1 stage: sketch lr: 0.000322\n",
      "batch 601 loss: 0.33928 acc: 0.90299 | v_loss: 0.43871 v_acc: 0.88965 |  iteration: 1845 teacher: 0 stage: sketch lr: 0.000322\n",
      "batch 602 loss: 0.37297 acc: 0.89616 | v_loss: 0.65078 v_acc: 0.85547 |  iteration: 1846 teacher: 1 stage: sketch lr: 0.000322\n",
      "batch 603 loss: 0.41888 acc: 0.88411 | v_loss: 0.57664 v_acc: 0.86230 |  iteration: 1847 teacher: 0 stage: sketch lr: 0.000323\n",
      "batch 604 loss: 0.48437 acc: 0.87663 | v_loss: 0.92464 v_acc: 0.82357 |  iteration: 1848 teacher: 1 stage: sketch lr: 0.000323\n",
      "batch 605 loss: 0.44267 acc: 0.87923 | v_loss: 0.46266 v_acc: 0.88509 |  iteration: 1849 teacher: 0 stage: sketch lr: 0.000323\n",
      "batch 606 loss: 0.43789 acc: 0.86719 | v_loss: 0.36433 v_acc: 0.90332 |  iteration: 1850 teacher: 1 stage: sketch lr: 0.000323\n",
      "batch 607 loss: 0.35177 acc: 0.89616 | v_loss: 0.59533 v_acc: 0.87044 |  iteration: 1851 teacher: 1 stage: sketch lr: 0.000323\n",
      "batch 608 loss: 0.37108 acc: 0.89095 | v_loss: 0.63574 v_acc: 0.86035 |  iteration: 1852 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 609 loss: 0.36331 acc: 0.88574 | v_loss: 0.72523 v_acc: 0.83626 |  iteration: 1853 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 610 loss: 0.35470 acc: 0.89160 | v_loss: 0.48480 v_acc: 0.87598 |  iteration: 1854 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 611 loss: 0.55604 acc: 0.84635 | v_loss: 0.57468 v_acc: 0.86165 |  iteration: 1855 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 612 loss: 0.42129 acc: 0.88639 | v_loss: 0.71990 v_acc: 0.82780 |  iteration: 1856 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 613 loss: 0.49284 acc: 0.87109 | v_loss: 0.74458 v_acc: 0.81901 |  iteration: 1857 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 614 loss: 0.42691 acc: 0.87207 | v_loss: 0.55836 v_acc: 0.86296 |  iteration: 1858 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 615 loss: 0.40106 acc: 0.88216 | v_loss: 0.45992 v_acc: 0.87956 |  iteration: 1859 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 616 loss: 0.42020 acc: 0.86947 | v_loss: 0.38506 v_acc: 0.89225 |  iteration: 1860 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 617 loss: 0.39053 acc: 0.87663 | v_loss: 0.51840 v_acc: 0.88314 |  iteration: 1861 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 618 loss: 0.49561 acc: 0.85742 | v_loss: 0.56991 v_acc: 0.86784 |  iteration: 1862 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 619 loss: 0.37731 acc: 0.89095 | v_loss: 0.88470 v_acc: 0.83496 |  iteration: 1863 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 620 loss: 0.37243 acc: 0.89323 | v_loss: 0.59575 v_acc: 0.85938 |  iteration: 1864 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 621 loss: 0.37085 acc: 0.89095 | v_loss: 0.70534 v_acc: 0.84212 |  iteration: 1865 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 622 loss: 0.38912 acc: 0.88770 | v_loss: 0.46211 v_acc: 0.88151 |  iteration: 1866 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 623 loss: 0.38334 acc: 0.89062 | v_loss: 0.63598 v_acc: 0.86393 |  iteration: 1867 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 624 loss: 0.39385 acc: 0.88346 | v_loss: 0.84318 v_acc: 0.82292 |  iteration: 1868 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 625 loss: 0.41146 acc: 0.88704 | v_loss: 0.60135 v_acc: 0.86523 |  iteration: 1869 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 626 loss: 0.40371 acc: 0.89225 | v_loss: 0.58806 v_acc: 0.86426 |  iteration: 1870 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 627 loss: 0.35007 acc: 0.89714 | v_loss: 0.56365 v_acc: 0.86328 |  iteration: 1871 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 628 loss: 0.39929 acc: 0.88737 | v_loss: 0.47698 v_acc: 0.88900 |  iteration: 1872 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 629 loss: 0.31266 acc: 0.90104 | v_loss: 0.55833 v_acc: 0.87337 |  iteration: 1873 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 630 loss: 0.40947 acc: 0.89160 | v_loss: 0.68960 v_acc: 0.84310 |  iteration: 1874 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 631 loss: 0.42104 acc: 0.87370 | v_loss: 0.44977 v_acc: 0.89811 |  iteration: 1875 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 632 loss: 0.40431 acc: 0.88477 | v_loss: 1.00645 v_acc: 0.80859 |  iteration: 1876 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 633 loss: 0.36558 acc: 0.88932 | v_loss: 0.70272 v_acc: 0.85059 |  iteration: 1877 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 634 loss: 0.36083 acc: 0.89193 | v_loss: 0.80314 v_acc: 0.83333 |  iteration: 1878 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 635 loss: 0.43713 acc: 0.87663 | v_loss: 0.65350 v_acc: 0.85938 |  iteration: 1879 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 636 loss: 0.32057 acc: 0.90332 | v_loss: 0.56952 v_acc: 0.86849 |  iteration: 1880 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 637 loss: 0.43731 acc: 0.87109 | v_loss: 0.65322 v_acc: 0.86198 |  iteration: 1881 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 638 loss: 0.38364 acc: 0.88835 | v_loss: 0.58193 v_acc: 0.86914 |  iteration: 1882 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 639 loss: 0.39584 acc: 0.88086 | v_loss: 0.63066 v_acc: 0.85710 |  iteration: 1883 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 640 loss: 0.37677 acc: 0.88379 | v_loss: 0.56243 v_acc: 0.88021 |  iteration: 1884 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 641 loss: 0.43079 acc: 0.88281 | v_loss: 0.52152 v_acc: 0.87923 |  iteration: 1885 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 642 loss: 0.41973 acc: 0.87467 | v_loss: 0.42507 v_acc: 0.89681 |  iteration: 1886 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 643 loss: 0.39457 acc: 0.88542 | v_loss: 0.72249 v_acc: 0.83073 |  iteration: 1887 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 644 loss: 0.34710 acc: 0.89746 | v_loss: 0.60038 v_acc: 0.85514 |  iteration: 1888 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 645 loss: 0.31606 acc: 0.90495 | v_loss: 0.66610 v_acc: 0.84733 |  iteration: 1889 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 646 loss: 0.33878 acc: 0.89746 | v_loss: 0.83014 v_acc: 0.83561 |  iteration: 1890 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 647 loss: 0.24053 acc: 0.92285 | v_loss: 0.49847 v_acc: 0.88184 |  iteration: 1891 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 648 loss: 0.33869 acc: 0.90007 | v_loss: 0.66669 v_acc: 0.86035 |  iteration: 1892 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 649 loss: 0.28873 acc: 0.90983 | v_loss: 0.63305 v_acc: 0.87695 |  iteration: 1893 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 650 loss: 0.43002 acc: 0.87728 | v_loss: 0.50478 v_acc: 0.88704 |  iteration: 1894 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 651 loss: 0.35427 acc: 0.89746 | v_loss: 1.07791 v_acc: 0.80599 |  iteration: 1895 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 652 loss: 0.35872 acc: 0.89714 | v_loss: 0.41893 v_acc: 0.90332 |  iteration: 1896 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 653 loss: 0.47706 acc: 0.85775 | v_loss: 0.66683 v_acc: 0.85482 |  iteration: 1897 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 654 loss: 0.40804 acc: 0.87598 | v_loss: 0.56492 v_acc: 0.86556 |  iteration: 1898 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 655 loss: 0.33857 acc: 0.89844 | v_loss: 0.48630 v_acc: 0.88281 |  iteration: 1899 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 656 loss: 0.30125 acc: 0.90918 | v_loss: 0.55078 v_acc: 0.87142 |  iteration: 1900 teacher: 0 stage: sketch lr: 0.000332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 657 loss: 0.33363 acc: 0.89714 | v_loss: 0.67069 v_acc: 0.85124 |  iteration: 1901 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 658 loss: 0.36153 acc: 0.89062 | v_loss: 0.47731 v_acc: 0.88770 |  iteration: 1902 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 659 loss: 0.35511 acc: 0.88997 | v_loss: 0.64733 v_acc: 0.85710 |  iteration: 1903 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 660 loss: 0.42462 acc: 0.87728 | v_loss: 0.42493 v_acc: 0.88281 |  iteration: 1904 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 661 loss: 0.35596 acc: 0.89941 | v_loss: 0.97283 v_acc: 0.82943 |  iteration: 1905 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 662 loss: 0.26356 acc: 0.91667 | v_loss: 0.60101 v_acc: 0.86751 |  iteration: 1906 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 663 loss: 0.40433 acc: 0.88867 | v_loss: 0.67518 v_acc: 0.85579 |  iteration: 1907 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 664 loss: 0.41662 acc: 0.88802 | v_loss: 0.46223 v_acc: 0.88965 |  iteration: 1908 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 665 loss: 0.49216 acc: 0.86426 | v_loss: 0.71651 v_acc: 0.84277 |  iteration: 1909 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 666 loss: 0.35007 acc: 0.89095 | v_loss: 0.51094 v_acc: 0.87435 |  iteration: 1910 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 667 loss: 0.44789 acc: 0.86979 | v_loss: 0.53055 v_acc: 0.86621 |  iteration: 1911 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 668 loss: 0.26764 acc: 0.91569 | v_loss: 0.47922 v_acc: 0.88281 |  iteration: 1912 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 669 loss: 0.41014 acc: 0.88444 | v_loss: 0.72811 v_acc: 0.84473 |  iteration: 1913 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 670 loss: 0.50958 acc: 0.86491 | v_loss: 0.55446 v_acc: 0.87988 |  iteration: 1914 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 671 loss: 0.42685 acc: 0.88542 | v_loss: 0.60737 v_acc: 0.85905 |  iteration: 1915 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 672 loss: 0.35997 acc: 0.89941 | v_loss: 0.68447 v_acc: 0.84017 |  iteration: 1916 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 673 loss: 0.40839 acc: 0.88770 | v_loss: 0.50506 v_acc: 0.87207 |  iteration: 1917 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 674 loss: 0.34808 acc: 0.89486 | v_loss: 0.60521 v_acc: 0.84701 |  iteration: 1918 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 675 loss: 0.29415 acc: 0.91081 | v_loss: 0.64545 v_acc: 0.84766 |  iteration: 1919 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 676 loss: 0.33061 acc: 0.90267 | v_loss: 0.77529 v_acc: 0.83626 |  iteration: 1920 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 677 loss: 0.33850 acc: 0.90332 | v_loss: 0.59600 v_acc: 0.87109 |  iteration: 1921 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 678 loss: 0.42057 acc: 0.87240 | v_loss: 0.63587 v_acc: 0.86751 |  iteration: 1922 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 679 loss: 0.34678 acc: 0.90039 | v_loss: 0.70665 v_acc: 0.85742 |  iteration: 1923 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 680 loss: 0.34947 acc: 0.89714 | v_loss: 0.66116 v_acc: 0.84733 |  iteration: 1924 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 681 loss: 0.32966 acc: 0.90788 | v_loss: 0.51569 v_acc: 0.88379 |  iteration: 1925 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 682 loss: 0.32509 acc: 0.90658 | v_loss: 0.89345 v_acc: 0.82845 |  iteration: 1926 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 683 loss: 0.32805 acc: 0.90885 | v_loss: 0.64456 v_acc: 0.86035 |  iteration: 1927 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 684 loss: 0.39211 acc: 0.89160 | v_loss: 0.64247 v_acc: 0.84863 |  iteration: 1928 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 685 loss: 0.35991 acc: 0.90397 | v_loss: 0.63849 v_acc: 0.86003 |  iteration: 1929 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 686 loss: 0.39859 acc: 0.88509 | v_loss: 0.53720 v_acc: 0.88607 |  iteration: 1930 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 687 loss: 0.33251 acc: 0.89714 | v_loss: 0.50730 v_acc: 0.88346 |  iteration: 1931 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 688 loss: 0.45281 acc: 0.88086 | v_loss: 0.56327 v_acc: 0.87044 |  iteration: 1932 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 689 loss: 0.36395 acc: 0.89355 | v_loss: 0.67635 v_acc: 0.83691 |  iteration: 1933 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 690 loss: 0.31425 acc: 0.90234 | v_loss: 0.59892 v_acc: 0.86816 |  iteration: 1934 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 691 loss: 0.39253 acc: 0.88053 | v_loss: 0.63733 v_acc: 0.85872 |  iteration: 1935 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 692 loss: 0.35306 acc: 0.89486 | v_loss: 0.42734 v_acc: 0.89388 |  iteration: 1936 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 693 loss: 0.41069 acc: 0.88216 | v_loss: 0.61534 v_acc: 0.86263 |  iteration: 1937 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 694 loss: 0.43316 acc: 0.88053 | v_loss: 0.55583 v_acc: 0.86328 |  iteration: 1938 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 695 loss: 0.32679 acc: 0.90332 | v_loss: 0.85981 v_acc: 0.81803 |  iteration: 1939 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 696 loss: 0.39556 acc: 0.88151 | v_loss: 0.42945 v_acc: 0.89258 |  iteration: 1940 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 697 loss: 0.35457 acc: 0.90007 | v_loss: 0.36279 v_acc: 0.91276 |  iteration: 1941 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 698 loss: 0.31864 acc: 0.90983 | v_loss: 0.64907 v_acc: 0.86654 |  iteration: 1942 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 699 loss: 0.33522 acc: 0.90332 | v_loss: 0.65041 v_acc: 0.86589 |  iteration: 1943 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 700 loss: 0.36298 acc: 0.89355 | v_loss: 0.70515 v_acc: 0.84245 |  iteration: 1944 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 701 loss: 0.37178 acc: 0.88932 | v_loss: 0.50676 v_acc: 0.87402 |  iteration: 1945 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 702 loss: 0.48718 acc: 0.85872 | v_loss: 0.57423 v_acc: 0.86491 |  iteration: 1946 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 703 loss: 0.44015 acc: 0.87305 | v_loss: 0.68110 v_acc: 0.83659 |  iteration: 1947 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 704 loss: 0.35075 acc: 0.90169 | v_loss: 0.70245 v_acc: 0.83919 |  iteration: 1948 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 705 loss: 0.31170 acc: 0.90853 | v_loss: 0.53880 v_acc: 0.87077 |  iteration: 1949 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 706 loss: 0.38323 acc: 0.88737 | v_loss: 0.41589 v_acc: 0.89421 |  iteration: 1950 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 707 loss: 0.28262 acc: 0.91341 | v_loss: 0.36293 v_acc: 0.90430 |  iteration: 1951 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 708 loss: 0.41082 acc: 0.88118 | v_loss: 0.53629 v_acc: 0.88314 |  iteration: 1952 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 709 loss: 0.36105 acc: 0.89290 | v_loss: 0.55116 v_acc: 0.86393 |  iteration: 1953 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 710 loss: 0.37656 acc: 0.88607 | v_loss: 0.86977 v_acc: 0.82812 |  iteration: 1954 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 711 loss: 0.36071 acc: 0.89518 | v_loss: 0.56646 v_acc: 0.86816 |  iteration: 1955 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 712 loss: 0.38022 acc: 0.89779 | v_loss: 0.67296 v_acc: 0.85352 |  iteration: 1956 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 713 loss: 0.45350 acc: 0.87923 | v_loss: 0.48839 v_acc: 0.87891 |  iteration: 1957 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 714 loss: 0.38212 acc: 0.89551 | v_loss: 0.61779 v_acc: 0.85970 |  iteration: 1958 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 715 loss: 0.43211 acc: 0.87337 | v_loss: 0.84471 v_acc: 0.81348 |  iteration: 1959 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 716 loss: 0.42110 acc: 0.88086 | v_loss: 0.55943 v_acc: 0.86947 |  iteration: 1960 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 717 loss: 0.47676 acc: 0.86751 | v_loss: 0.53110 v_acc: 0.87663 |  iteration: 1961 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 718 loss: 0.40374 acc: 0.89616 | v_loss: 0.56339 v_acc: 0.85775 |  iteration: 1962 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 719 loss: 0.34344 acc: 0.90137 | v_loss: 0.51307 v_acc: 0.87598 |  iteration: 1963 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 720 loss: 0.32039 acc: 0.90267 | v_loss: 0.51025 v_acc: 0.87337 |  iteration: 1964 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 721 loss: 0.35447 acc: 0.89095 | v_loss: 0.67160 v_acc: 0.84570 |  iteration: 1965 teacher: 0 stage: sketch lr: 0.000343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 722 loss: 0.35146 acc: 0.89323 | v_loss: 0.41203 v_acc: 0.90560 |  iteration: 1966 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 723 loss: 0.42573 acc: 0.87956 | v_loss: 0.98776 v_acc: 0.81445 |  iteration: 1967 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 724 loss: 0.35917 acc: 0.89616 | v_loss: 0.69282 v_acc: 0.85091 |  iteration: 1968 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 725 loss: 0.36368 acc: 0.88965 | v_loss: 0.72245 v_acc: 0.84538 |  iteration: 1969 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 726 loss: 0.39895 acc: 0.87467 | v_loss: 0.59836 v_acc: 0.87272 |  iteration: 1970 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 727 loss: 0.41406 acc: 0.88314 | v_loss: 0.58720 v_acc: 0.86784 |  iteration: 1971 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 728 loss: 0.37248 acc: 0.89941 | v_loss: 0.67629 v_acc: 0.85905 |  iteration: 1972 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 729 loss: 0.37731 acc: 0.88672 | v_loss: 0.54354 v_acc: 0.87598 |  iteration: 1973 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 730 loss: 0.43023 acc: 0.87598 | v_loss: 0.60988 v_acc: 0.86686 |  iteration: 1974 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 731 loss: 0.33639 acc: 0.90560 | v_loss: 0.53801 v_acc: 0.88444 |  iteration: 1975 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 732 loss: 0.36691 acc: 0.88704 | v_loss: 0.49320 v_acc: 0.88053 |  iteration: 1976 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 733 loss: 0.35166 acc: 0.89290 | v_loss: 0.38957 v_acc: 0.90495 |  iteration: 1977 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 734 loss: 0.34654 acc: 0.89388 | v_loss: 0.72111 v_acc: 0.83952 |  iteration: 1978 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 735 loss: 0.31510 acc: 0.90299 | v_loss: 0.61220 v_acc: 0.85677 |  iteration: 1979 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 736 loss: 0.33795 acc: 0.90267 | v_loss: 0.71825 v_acc: 0.84635 |  iteration: 1980 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 737 loss: 0.37853 acc: 0.89225 | v_loss: 0.88543 v_acc: 0.83789 |  iteration: 1981 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 738 loss: 0.37387 acc: 0.89225 | v_loss: 0.50568 v_acc: 0.89128 |  iteration: 1982 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 739 loss: 0.39874 acc: 0.89062 | v_loss: 0.63776 v_acc: 0.86328 |  iteration: 1983 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 740 loss: 0.37476 acc: 0.89355 | v_loss: 0.58761 v_acc: 0.87337 |  iteration: 1984 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 741 loss: 0.36928 acc: 0.88802 | v_loss: 0.51940 v_acc: 0.87272 |  iteration: 1985 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 742 loss: 0.37692 acc: 0.88737 | v_loss: 1.08420 v_acc: 0.79818 |  iteration: 1986 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 743 loss: 0.36888 acc: 0.88639 | v_loss: 0.42559 v_acc: 0.88965 |  iteration: 1987 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 744 loss: 0.39302 acc: 0.87077 | v_loss: 0.66560 v_acc: 0.85384 |  iteration: 1988 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 745 loss: 0.38921 acc: 0.88900 | v_loss: 0.53426 v_acc: 0.87109 |  iteration: 1989 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 746 loss: 0.36616 acc: 0.88672 | v_loss: 0.48080 v_acc: 0.89193 |  iteration: 1990 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 747 loss: 0.39423 acc: 0.88802 | v_loss: 0.56757 v_acc: 0.88086 |  iteration: 1991 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 748 loss: 0.36758 acc: 0.90169 | v_loss: 0.66264 v_acc: 0.86621 |  iteration: 1992 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 749 loss: 0.41123 acc: 0.88965 | v_loss: 0.47031 v_acc: 0.88835 |  iteration: 1993 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 750 loss: 0.38719 acc: 0.88737 | v_loss: 0.66022 v_acc: 0.85189 |  iteration: 1994 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 751 loss: 0.38735 acc: 0.88802 | v_loss: 0.47513 v_acc: 0.87467 |  iteration: 1995 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 752 loss: 0.28783 acc: 0.91146 | v_loss: 0.99153 v_acc: 0.81315 |  iteration: 1996 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 753 loss: 0.36220 acc: 0.89193 | v_loss: 0.65044 v_acc: 0.85775 |  iteration: 1997 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 754 loss: 0.35924 acc: 0.89518 | v_loss: 0.68837 v_acc: 0.86068 |  iteration: 1998 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 755 loss: 0.29963 acc: 0.91504 | v_loss: 0.51112 v_acc: 0.87923 |  iteration: 1999 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 756 loss: 0.34774 acc: 0.89551 | v_loss: 0.71508 v_acc: 0.84310 |  iteration: 2000 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 757 loss: 0.33553 acc: 0.90267 | v_loss: 0.47360 v_acc: 0.88346 |  iteration: 2001 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 758 loss: 0.27721 acc: 0.91569 | v_loss: 0.55578 v_acc: 0.86914 |  iteration: 2002 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 759 loss: 0.34705 acc: 0.89746 | v_loss: 0.50180 v_acc: 0.87077 |  iteration: 2003 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 760 loss: 0.35267 acc: 0.89453 | v_loss: 0.78379 v_acc: 0.83040 |  iteration: 2004 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 761 loss: 0.36829 acc: 0.89160 | v_loss: 0.57302 v_acc: 0.87109 |  iteration: 2005 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 762 loss: 0.38086 acc: 0.88672 | v_loss: 0.56829 v_acc: 0.86621 |  iteration: 2006 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 763 loss: 0.41694 acc: 0.87760 | v_loss: 0.70151 v_acc: 0.84310 |  iteration: 2007 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 764 loss: 0.28490 acc: 0.91211 | v_loss: 0.50956 v_acc: 0.87760 |  iteration: 2008 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 765 loss: 0.39160 acc: 0.88770 | v_loss: 0.58622 v_acc: 0.85742 |  iteration: 2009 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 766 loss: 0.35710 acc: 0.89583 | v_loss: 0.64090 v_acc: 0.85091 |  iteration: 2010 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 767 loss: 0.38127 acc: 0.89290 | v_loss: 0.79726 v_acc: 0.84082 |  iteration: 2011 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 768 loss: 0.39682 acc: 0.88900 | v_loss: 0.59699 v_acc: 0.87467 |  iteration: 2012 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 769 loss: 0.30775 acc: 0.90853 | v_loss: 0.66005 v_acc: 0.86003 |  iteration: 2013 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 770 loss: 0.36135 acc: 0.89453 | v_loss: 0.68658 v_acc: 0.86003 |  iteration: 2014 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 771 loss: 0.34938 acc: 0.88802 | v_loss: 0.62836 v_acc: 0.84961 |  iteration: 2015 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 772 loss: 0.35123 acc: 0.89779 | v_loss: 0.47333 v_acc: 0.88900 |  iteration: 2016 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 773 loss: 0.41184 acc: 0.88151 | v_loss: 0.84412 v_acc: 0.83691 |  iteration: 2017 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 774 loss: 0.35898 acc: 0.90430 | v_loss: 0.64222 v_acc: 0.85840 |  iteration: 2018 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 775 loss: 0.55046 acc: 0.85286 | v_loss: 0.58639 v_acc: 0.86068 |  iteration: 2019 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 776 loss: 0.30225 acc: 0.90788 | v_loss: 0.60520 v_acc: 0.85026 |  iteration: 2020 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 777 loss: 0.32783 acc: 0.89518 | v_loss: 0.50539 v_acc: 0.87663 |  iteration: 2021 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 778 loss: 0.46995 acc: 0.86003 | v_loss: 0.48156 v_acc: 0.88314 |  iteration: 2022 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 779 loss: 0.33401 acc: 0.90202 | v_loss: 0.52844 v_acc: 0.88021 |  iteration: 2023 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 780 loss: 0.34477 acc: 0.89388 | v_loss: 0.68272 v_acc: 0.84245 |  iteration: 2024 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 781 loss: 0.40562 acc: 0.88444 | v_loss: 0.62841 v_acc: 0.87272 |  iteration: 2025 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 782 loss: 0.35231 acc: 0.89388 | v_loss: 0.66121 v_acc: 0.86230 |  iteration: 2026 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 783 loss: 0.44764 acc: 0.87695 | v_loss: 0.42882 v_acc: 0.89844 |  iteration: 2027 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 784 loss: 0.26725 acc: 0.92578 | v_loss: 0.61023 v_acc: 0.86393 |  iteration: 2028 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 785 loss: 0.28605 acc: 0.91569 | v_loss: 0.58327 v_acc: 0.86426 |  iteration: 2029 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 786 loss: 0.34296 acc: 0.89811 | v_loss: 0.84154 v_acc: 0.82585 |  iteration: 2030 teacher: 1 stage: sketch lr: 0.000355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 787 loss: 0.38657 acc: 0.89779 | v_loss: 0.41201 v_acc: 0.89290 |  iteration: 2031 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 788 loss: 0.39663 acc: 0.88574 | v_loss: 0.35536 v_acc: 0.91016 |  iteration: 2032 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 789 loss: 0.42370 acc: 0.86816 | v_loss: 0.59397 v_acc: 0.86654 |  iteration: 2033 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 790 loss: 0.34658 acc: 0.88965 | v_loss: 0.62923 v_acc: 0.86621 |  iteration: 2034 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 791 loss: 0.33134 acc: 0.90072 | v_loss: 0.70755 v_acc: 0.85417 |  iteration: 2035 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 792 loss: 0.33071 acc: 0.90365 | v_loss: 0.48331 v_acc: 0.88509 |  iteration: 2036 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 793 loss: 0.29643 acc: 0.90527 | v_loss: 0.61709 v_acc: 0.85579 |  iteration: 2037 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 794 loss: 0.38015 acc: 0.90072 | v_loss: 0.68105 v_acc: 0.85221 |  iteration: 2038 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 795 loss: 0.36413 acc: 0.89844 | v_loss: 0.71812 v_acc: 0.83594 |  iteration: 2039 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 796 loss: 0.43682 acc: 0.88900 | v_loss: 0.50208 v_acc: 0.87988 |  iteration: 2040 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 797 loss: 0.37355 acc: 0.89355 | v_loss: 0.43154 v_acc: 0.88835 |  iteration: 2041 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 798 loss: 0.41233 acc: 0.88184 | v_loss: 0.35987 v_acc: 0.90169 |  iteration: 2042 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 799 loss: 0.35745 acc: 0.89681 | v_loss: 0.58549 v_acc: 0.86914 |  iteration: 2043 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 800 loss: 0.40238 acc: 0.87142 | v_loss: 0.58320 v_acc: 0.85417 |  iteration: 2044 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 801 loss: 0.37102 acc: 0.88574 | v_loss: 0.83026 v_acc: 0.83691 |  iteration: 2045 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 802 loss: 0.32866 acc: 0.90397 | v_loss: 0.62883 v_acc: 0.85807 |  iteration: 2046 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 803 loss: 0.35952 acc: 0.89258 | v_loss: 0.72571 v_acc: 0.85775 |  iteration: 2047 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 804 loss: 0.40591 acc: 0.88607 | v_loss: 0.49765 v_acc: 0.88509 |  iteration: 2048 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 805 loss: 0.35730 acc: 0.90007 | v_loss: 0.59329 v_acc: 0.86979 |  iteration: 2049 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 806 loss: 0.42950 acc: 0.87891 | v_loss: 0.80172 v_acc: 0.82650 |  iteration: 2050 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 807 loss: 0.35478 acc: 0.89941 | v_loss: 0.54674 v_acc: 0.87728 |  iteration: 2051 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 808 loss: 0.39789 acc: 0.87760 | v_loss: 0.51286 v_acc: 0.87565 |  iteration: 2052 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 809 loss: 0.38798 acc: 0.88997 | v_loss: 0.55732 v_acc: 0.85938 |  iteration: 2053 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 810 loss: 0.39195 acc: 0.88379 | v_loss: 0.50757 v_acc: 0.88184 |  iteration: 2054 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 811 loss: 0.46444 acc: 0.86816 | v_loss: 0.53917 v_acc: 0.87760 |  iteration: 2055 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 812 loss: 0.40274 acc: 0.88444 | v_loss: 0.62769 v_acc: 0.85417 |  iteration: 2056 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 813 loss: 0.32307 acc: 0.90430 | v_loss: 0.43179 v_acc: 0.90625 |  iteration: 2057 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 814 loss: 0.30449 acc: 0.91471 | v_loss: 0.99595 v_acc: 0.81706 |  iteration: 2058 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 815 loss: 0.40845 acc: 0.88184 | v_loss: 0.70485 v_acc: 0.85254 |  iteration: 2059 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 816 loss: 0.39206 acc: 0.88932 | v_loss: 0.74279 v_acc: 0.84277 |  iteration: 2060 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 817 loss: 0.43963 acc: 0.88835 | v_loss: 0.56499 v_acc: 0.88086 |  iteration: 2061 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 818 loss: 0.33389 acc: 0.90430 | v_loss: 0.56594 v_acc: 0.86751 |  iteration: 2062 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 819 loss: 0.37142 acc: 0.89193 | v_loss: 0.63162 v_acc: 0.86263 |  iteration: 2063 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 820 loss: 0.31794 acc: 0.90885 | v_loss: 0.54972 v_acc: 0.87109 |  iteration: 2064 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 821 loss: 0.42740 acc: 0.87630 | v_loss: 0.56769 v_acc: 0.86133 |  iteration: 2065 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 822 loss: 0.42470 acc: 0.87663 | v_loss: 0.55568 v_acc: 0.88704 |  iteration: 2066 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 823 loss: 0.29346 acc: 0.91569 | v_loss: 0.51980 v_acc: 0.88021 |  iteration: 2067 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 824 loss: 0.32243 acc: 0.90202 | v_loss: 0.39098 v_acc: 0.90430 |  iteration: 2068 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 825 loss: 0.29882 acc: 0.90853 | v_loss: 0.67801 v_acc: 0.85579 |  iteration: 2069 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 826 loss: 0.28869 acc: 0.91406 | v_loss: 0.59259 v_acc: 0.85319 |  iteration: 2070 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 827 loss: 0.35295 acc: 0.90072 | v_loss: 0.66213 v_acc: 0.85189 |  iteration: 2071 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 828 loss: 0.37751 acc: 0.89551 | v_loss: 0.86360 v_acc: 0.82845 |  iteration: 2072 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 829 loss: 0.33044 acc: 0.89421 | v_loss: 0.46900 v_acc: 0.88965 |  iteration: 2073 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 830 loss: 0.33829 acc: 0.90267 | v_loss: 0.62611 v_acc: 0.85905 |  iteration: 2074 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 831 loss: 0.35405 acc: 0.90267 | v_loss: 0.57661 v_acc: 0.87467 |  iteration: 2075 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 832 loss: 0.33128 acc: 0.90430 | v_loss: 0.44451 v_acc: 0.89551 |  iteration: 2076 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 833 loss: 0.33666 acc: 0.89714 | v_loss: 1.06651 v_acc: 0.79753 |  iteration: 2077 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 834 loss: 0.39339 acc: 0.88835 | v_loss: 0.43940 v_acc: 0.89486 |  iteration: 2078 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 835 loss: 0.29365 acc: 0.90788 | v_loss: 0.64951 v_acc: 0.86458 |  iteration: 2079 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 836 loss: 0.41330 acc: 0.88411 | v_loss: 0.55750 v_acc: 0.86556 |  iteration: 2080 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 837 loss: 0.37901 acc: 0.88932 | v_loss: 0.49464 v_acc: 0.88314 |  iteration: 2081 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 838 loss: 0.34486 acc: 0.89714 | v_loss: 0.54980 v_acc: 0.87891 |  iteration: 2082 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 839 loss: 0.25913 acc: 0.91960 | v_loss: 0.65470 v_acc: 0.86035 |  iteration: 2083 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 840 loss: 0.35715 acc: 0.89486 | v_loss: 0.50748 v_acc: 0.88411 |  iteration: 2084 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 841 loss: 0.36968 acc: 0.89453 | v_loss: 0.64207 v_acc: 0.85970 |  iteration: 2085 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 842 loss: 0.42252 acc: 0.87728 | v_loss: 0.45753 v_acc: 0.88639 |  iteration: 2086 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 843 loss: 0.34082 acc: 0.90137 | v_loss: 0.95313 v_acc: 0.81836 |  iteration: 2087 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 844 loss: 0.39854 acc: 0.88379 | v_loss: 0.61900 v_acc: 0.86556 |  iteration: 2088 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 845 loss: 0.41332 acc: 0.87695 | v_loss: 0.64374 v_acc: 0.86686 |  iteration: 2089 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 846 loss: 0.24473 acc: 0.92839 | v_loss: 0.46705 v_acc: 0.88411 |  iteration: 2090 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 847 loss: 0.34072 acc: 0.90723 | v_loss: 0.69880 v_acc: 0.85645 |  iteration: 2091 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 848 loss: 0.32119 acc: 0.90234 | v_loss: 0.51001 v_acc: 0.87858 |  iteration: 2092 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 849 loss: 0.33283 acc: 0.90332 | v_loss: 0.51079 v_acc: 0.87923 |  iteration: 2093 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 850 loss: 0.44607 acc: 0.87858 | v_loss: 0.47583 v_acc: 0.87858 |  iteration: 2094 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 851 loss: 0.29053 acc: 0.91764 | v_loss: 0.76559 v_acc: 0.83366 |  iteration: 2095 teacher: 1 stage: sketch lr: 0.000366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 852 loss: 0.36028 acc: 0.89030 | v_loss: 0.56111 v_acc: 0.87044 |  iteration: 2096 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 853 loss: 0.36555 acc: 0.88997 | v_loss: 0.60035 v_acc: 0.85482 |  iteration: 2097 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 854 loss: 0.34391 acc: 0.89941 | v_loss: 0.73059 v_acc: 0.83398 |  iteration: 2098 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 855 loss: 0.29350 acc: 0.91732 | v_loss: 0.51332 v_acc: 0.87467 |  iteration: 2099 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 856 loss: 0.34323 acc: 0.89909 | v_loss: 0.57842 v_acc: 0.86035 |  iteration: 2100 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 857 loss: 0.26754 acc: 0.91667 | v_loss: 0.59747 v_acc: 0.86263 |  iteration: 2101 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 858 loss: 0.38932 acc: 0.88900 | v_loss: 0.82161 v_acc: 0.84245 |  iteration: 2102 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 859 loss: 0.36509 acc: 0.89486 | v_loss: 0.59402 v_acc: 0.86947 |  iteration: 2103 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 860 loss: 0.27718 acc: 0.90983 | v_loss: 0.60171 v_acc: 0.87402 |  iteration: 2104 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 861 loss: 0.36194 acc: 0.88379 | v_loss: 0.70048 v_acc: 0.86458 |  iteration: 2105 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 862 loss: 0.35157 acc: 0.90853 | v_loss: 0.63280 v_acc: 0.85384 |  iteration: 2106 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 863 loss: 0.32401 acc: 0.91113 | v_loss: 0.48451 v_acc: 0.89323 |  iteration: 2107 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 864 loss: 0.28029 acc: 0.91471 | v_loss: 0.88083 v_acc: 0.83659 |  iteration: 2108 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 865 loss: 0.28298 acc: 0.91178 | v_loss: 0.61754 v_acc: 0.87012 |  iteration: 2109 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 866 loss: 0.28687 acc: 0.91309 | v_loss: 0.57424 v_acc: 0.86296 |  iteration: 2110 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 867 loss: 0.39242 acc: 0.88900 | v_loss: 0.59392 v_acc: 0.86328 |  iteration: 2111 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 868 loss: 0.30741 acc: 0.90853 | v_loss: 0.48798 v_acc: 0.88411 |  iteration: 2112 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 869 loss: 0.35396 acc: 0.89974 | v_loss: 0.51876 v_acc: 0.88770 |  iteration: 2113 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 870 loss: 0.36005 acc: 0.89844 | v_loss: 0.56157 v_acc: 0.87500 |  iteration: 2114 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 871 loss: 0.30646 acc: 0.91048 | v_loss: 0.66524 v_acc: 0.84538 |  iteration: 2115 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 872 loss: 0.43501 acc: 0.87435 | v_loss: 0.64011 v_acc: 0.87337 |  iteration: 2116 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 873 loss: 0.35114 acc: 0.89583 | v_loss: 0.68100 v_acc: 0.86198 |  iteration: 2117 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 874 loss: 0.37246 acc: 0.89518 | v_loss: 0.40742 v_acc: 0.89974 |  iteration: 2118 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 875 loss: 0.38667 acc: 0.89290 | v_loss: 0.59211 v_acc: 0.85807 |  iteration: 2119 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 876 loss: 0.33966 acc: 0.90755 | v_loss: 0.53640 v_acc: 0.86914 |  iteration: 2120 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 877 loss: 0.26896 acc: 0.91667 | v_loss: 0.85348 v_acc: 0.83105 |  iteration: 2121 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 878 loss: 0.36691 acc: 0.89876 | v_loss: 0.42056 v_acc: 0.88704 |  iteration: 2122 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 879 loss: 0.34274 acc: 0.89681 | v_loss: 0.32735 v_acc: 0.91927 |  iteration: 2123 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 880 loss: 0.30426 acc: 0.90755 | v_loss: 0.61317 v_acc: 0.87565 |  iteration: 2124 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 881 loss: 0.32335 acc: 0.90039 | v_loss: 0.62369 v_acc: 0.87467 |  iteration: 2125 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 882 loss: 0.34899 acc: 0.90007 | v_loss: 0.72130 v_acc: 0.85482 |  iteration: 2126 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 883 loss: 0.32451 acc: 0.90495 | v_loss: 0.48733 v_acc: 0.89062 |  iteration: 2127 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 884 loss: 0.31297 acc: 0.90820 | v_loss: 0.55983 v_acc: 0.86816 |  iteration: 2128 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 885 loss: 0.27295 acc: 0.92415 | v_loss: 0.67710 v_acc: 0.84180 |  iteration: 2129 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 886 loss: 0.29637 acc: 0.91504 | v_loss: 0.69951 v_acc: 0.84310 |  iteration: 2130 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 887 loss: 0.48878 acc: 0.86849 | v_loss: 0.50177 v_acc: 0.88607 |  iteration: 2131 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 888 loss: 0.27009 acc: 0.91243 | v_loss: 0.46517 v_acc: 0.88118 |  iteration: 2132 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 889 loss: 0.36951 acc: 0.89551 | v_loss: 0.37143 v_acc: 0.90560 |  iteration: 2133 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 890 loss: 0.35834 acc: 0.88932 | v_loss: 0.50972 v_acc: 0.88932 |  iteration: 2134 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 891 loss: 0.43844 acc: 0.88314 | v_loss: 0.53949 v_acc: 0.87793 |  iteration: 2135 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 892 loss: 0.41826 acc: 0.88704 | v_loss: 0.88503 v_acc: 0.83854 |  iteration: 2136 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 893 loss: 0.35552 acc: 0.89648 | v_loss: 0.59590 v_acc: 0.86426 |  iteration: 2137 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 894 loss: 0.37193 acc: 0.89583 | v_loss: 0.68096 v_acc: 0.85905 |  iteration: 2138 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 895 loss: 0.30489 acc: 0.91667 | v_loss: 0.45144 v_acc: 0.88477 |  iteration: 2139 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 896 loss: 0.35626 acc: 0.89421 | v_loss: 0.60333 v_acc: 0.87012 |  iteration: 2140 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 897 loss: 0.40893 acc: 0.89518 | v_loss: 0.83890 v_acc: 0.82292 |  iteration: 2141 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 898 loss: 0.43345 acc: 0.87598 | v_loss: 0.57827 v_acc: 0.87240 |  iteration: 2142 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 899 loss: 0.31431 acc: 0.90169 | v_loss: 0.54054 v_acc: 0.87663 |  iteration: 2143 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 900 loss: 0.33905 acc: 0.90430 | v_loss: 0.54271 v_acc: 0.87142 |  iteration: 2144 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 901 loss: 0.32933 acc: 0.90755 | v_loss: 0.54220 v_acc: 0.87923 |  iteration: 2145 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 902 loss: 0.39802 acc: 0.88770 | v_loss: 0.50327 v_acc: 0.88151 |  iteration: 2146 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 903 loss: 0.25002 acc: 0.92676 | v_loss: 0.64967 v_acc: 0.84798 |  iteration: 2147 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 904 loss: 0.35275 acc: 0.89746 | v_loss: 0.43968 v_acc: 0.90625 |  iteration: 2148 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 905 loss: 0.30415 acc: 0.91374 | v_loss: 0.96294 v_acc: 0.82292 |  iteration: 2149 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 906 loss: 0.35872 acc: 0.89421 | v_loss: 0.71239 v_acc: 0.86328 |  iteration: 2150 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 907 loss: 0.36594 acc: 0.89811 | v_loss: 0.77108 v_acc: 0.84375 |  iteration: 2151 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 908 loss: 0.34665 acc: 0.89974 | v_loss: 0.57707 v_acc: 0.88281 |  iteration: 2152 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 909 loss: 0.41073 acc: 0.87760 | v_loss: 0.53918 v_acc: 0.87240 |  iteration: 2153 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 910 loss: 0.36376 acc: 0.89616 | v_loss: 0.62181 v_acc: 0.86719 |  iteration: 2154 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 911 loss: 0.33557 acc: 0.90560 | v_loss: 0.58012 v_acc: 0.86914 |  iteration: 2155 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 912 loss: 0.32481 acc: 0.90332 | v_loss: 0.55905 v_acc: 0.86686 |  iteration: 2156 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 913 loss: 0.39688 acc: 0.87858 | v_loss: 0.50554 v_acc: 0.88737 |  iteration: 2157 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 914 loss: 0.34534 acc: 0.89746 | v_loss: 0.48077 v_acc: 0.88867 |  iteration: 2158 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 915 loss: 0.33834 acc: 0.90495 | v_loss: 0.40143 v_acc: 0.89811 |  iteration: 2159 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 916 loss: 0.38747 acc: 0.89551 | v_loss: 0.67145 v_acc: 0.85059 |  iteration: 2160 teacher: 0 stage: sketch lr: 0.000377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 917 loss: 0.32179 acc: 0.90495 | v_loss: 0.58954 v_acc: 0.85449 |  iteration: 2161 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 918 loss: 0.39522 acc: 0.87988 | v_loss: 0.63941 v_acc: 0.86230 |  iteration: 2162 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 919 loss: 0.24906 acc: 0.92643 | v_loss: 0.84303 v_acc: 0.84115 |  iteration: 2163 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 920 loss: 0.32825 acc: 0.90137 | v_loss: 0.46469 v_acc: 0.89551 |  iteration: 2164 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 921 loss: 0.31088 acc: 0.90690 | v_loss: 0.63754 v_acc: 0.86849 |  iteration: 2165 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 922 loss: 0.44162 acc: 0.87598 | v_loss: 0.58376 v_acc: 0.88249 |  iteration: 2166 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 923 loss: 0.32072 acc: 0.90169 | v_loss: 0.49462 v_acc: 0.89258 |  iteration: 2167 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 924 loss: 0.35398 acc: 0.90007 | v_loss: 1.13279 v_acc: 0.80566 |  iteration: 2168 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 925 loss: 0.33744 acc: 0.90332 | v_loss: 0.42351 v_acc: 0.90365 |  iteration: 2169 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 926 loss: 0.32919 acc: 0.90137 | v_loss: 0.62084 v_acc: 0.88053 |  iteration: 2170 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 927 loss: 0.35290 acc: 0.89811 | v_loss: 0.54513 v_acc: 0.87728 |  iteration: 2171 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 928 loss: 0.27398 acc: 0.91960 | v_loss: 0.45356 v_acc: 0.89128 |  iteration: 2172 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 929 loss: 0.33175 acc: 0.90625 | v_loss: 0.52715 v_acc: 0.88542 |  iteration: 2173 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 930 loss: 0.37662 acc: 0.89225 | v_loss: 0.62052 v_acc: 0.86882 |  iteration: 2174 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 931 loss: 0.36219 acc: 0.89421 | v_loss: 0.45764 v_acc: 0.89714 |  iteration: 2175 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 932 loss: 0.28420 acc: 0.92285 | v_loss: 0.63888 v_acc: 0.86654 |  iteration: 2176 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 933 loss: 0.31603 acc: 0.91439 | v_loss: 0.46395 v_acc: 0.89583 |  iteration: 2177 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 934 loss: 0.36834 acc: 0.89681 | v_loss: 1.03507 v_acc: 0.82747 |  iteration: 2178 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 935 loss: 0.32592 acc: 0.90755 | v_loss: 0.62506 v_acc: 0.87500 |  iteration: 2179 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 936 loss: 0.39838 acc: 0.89746 | v_loss: 0.67438 v_acc: 0.85286 |  iteration: 2180 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 937 loss: 0.35542 acc: 0.89746 | v_loss: 0.45766 v_acc: 0.88639 |  iteration: 2181 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 938 loss: 0.34819 acc: 0.89844 | v_loss: 0.67678 v_acc: 0.84993 |  iteration: 2182 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 939 loss: 0.24759 acc: 0.93327 | v_loss: 0.48961 v_acc: 0.87923 |  iteration: 2183 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 940 loss: 0.33985 acc: 0.89746 | v_loss: 0.50754 v_acc: 0.87760 |  iteration: 2184 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 941 loss: 0.28878 acc: 0.91016 | v_loss: 0.42713 v_acc: 0.89062 |  iteration: 2185 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 942 loss: 0.27886 acc: 0.91569 | v_loss: 0.79384 v_acc: 0.84212 |  iteration: 2186 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 943 loss: 0.36523 acc: 0.90169 | v_loss: 0.54137 v_acc: 0.88574 |  iteration: 2187 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 944 loss: 0.34789 acc: 0.90658 | v_loss: 0.56978 v_acc: 0.86882 |  iteration: 2188 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 945 loss: 0.29891 acc: 0.91406 | v_loss: 0.69557 v_acc: 0.84082 |  iteration: 2189 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 946 loss: 0.37066 acc: 0.90039 | v_loss: 0.46948 v_acc: 0.88086 |  iteration: 2190 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 947 loss: 0.33839 acc: 0.90983 | v_loss: 0.58543 v_acc: 0.85124 |  iteration: 2191 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 948 loss: 0.38562 acc: 0.87858 | v_loss: 0.57222 v_acc: 0.86426 |  iteration: 2192 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 949 loss: 0.36971 acc: 0.89486 | v_loss: 0.75989 v_acc: 0.84277 |  iteration: 2193 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 950 loss: 0.33167 acc: 0.90169 | v_loss: 0.61451 v_acc: 0.87598 |  iteration: 2194 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 951 loss: 0.33749 acc: 0.90430 | v_loss: 0.62166 v_acc: 0.87793 |  iteration: 2195 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 952 loss: 0.36373 acc: 0.89648 | v_loss: 0.68685 v_acc: 0.87142 |  iteration: 2196 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 953 loss: 0.36382 acc: 0.90234 | v_loss: 0.62315 v_acc: 0.86198 |  iteration: 2197 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 954 loss: 0.30491 acc: 0.91211 | v_loss: 0.45830 v_acc: 0.89974 |  iteration: 2198 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 955 loss: 0.38913 acc: 0.88867 | v_loss: 0.83393 v_acc: 0.84180 |  iteration: 2199 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 956 loss: 0.29810 acc: 0.91504 | v_loss: 0.62725 v_acc: 0.86849 |  iteration: 2200 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 957 loss: 0.27879 acc: 0.91927 | v_loss: 0.56213 v_acc: 0.87435 |  iteration: 2201 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 958 loss: 0.29650 acc: 0.92546 | v_loss: 0.56717 v_acc: 0.86849 |  iteration: 2202 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 959 loss: 0.32791 acc: 0.90104 | v_loss: 0.50296 v_acc: 0.88867 |  iteration: 2203 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 960 loss: 0.31848 acc: 0.90755 | v_loss: 0.50505 v_acc: 0.88314 |  iteration: 2204 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 961 loss: 0.24006 acc: 0.92415 | v_loss: 0.50847 v_acc: 0.88542 |  iteration: 2205 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 962 loss: 0.28858 acc: 0.91536 | v_loss: 0.67896 v_acc: 0.84701 |  iteration: 2206 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 963 loss: 0.33065 acc: 0.90820 | v_loss: 0.62429 v_acc: 0.87598 |  iteration: 2207 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 964 loss: 0.28127 acc: 0.92383 | v_loss: 0.65254 v_acc: 0.86784 |  iteration: 2208 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 965 loss: 0.27290 acc: 0.92285 | v_loss: 0.42224 v_acc: 0.89648 |  iteration: 2209 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 966 loss: 0.33282 acc: 0.91081 | v_loss: 0.60394 v_acc: 0.87044 |  iteration: 2210 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 967 loss: 0.38071 acc: 0.89714 | v_loss: 0.54392 v_acc: 0.87109 |  iteration: 2211 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 968 loss: 0.31748 acc: 0.91146 | v_loss: 0.88196 v_acc: 0.82161 |  iteration: 2212 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 969 loss: 0.28929 acc: 0.91439 | v_loss: 0.38903 v_acc: 0.90430 |  iteration: 2213 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 970 loss: 0.28698 acc: 0.91569 | v_loss: 0.33501 v_acc: 0.91504 |  iteration: 2214 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 971 loss: 0.29380 acc: 0.91699 | v_loss: 0.57269 v_acc: 0.88249 |  iteration: 2215 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 972 loss: 0.42124 acc: 0.88509 | v_loss: 0.58552 v_acc: 0.87663 |  iteration: 2216 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 973 loss: 0.32901 acc: 0.90365 | v_loss: 0.69594 v_acc: 0.84733 |  iteration: 2217 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 974 loss: 0.40260 acc: 0.87695 | v_loss: 0.42734 v_acc: 0.89160 |  iteration: 2218 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 975 loss: 0.40936 acc: 0.87923 | v_loss: 0.57453 v_acc: 0.86914 |  iteration: 2219 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 976 loss: 0.27363 acc: 0.90918 | v_loss: 0.65893 v_acc: 0.85319 |  iteration: 2220 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 977 loss: 0.23685 acc: 0.93164 | v_loss: 0.73515 v_acc: 0.84212 |  iteration: 2221 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 978 loss: 0.46494 acc: 0.87272 | v_loss: 0.51672 v_acc: 0.89290 |  iteration: 2222 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 979 loss: 0.29053 acc: 0.92090 | v_loss: 0.40509 v_acc: 0.90332 |  iteration: 2223 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 980 loss: 0.30351 acc: 0.91829 | v_loss: 0.35155 v_acc: 0.91146 |  iteration: 2224 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 981 loss: 0.32514 acc: 0.90853 | v_loss: 0.48467 v_acc: 0.89388 |  iteration: 2225 teacher: 1 stage: sketch lr: 0.000389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 982 loss: 0.31623 acc: 0.91211 | v_loss: 0.54711 v_acc: 0.87728 |  iteration: 2226 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 983 loss: 0.30935 acc: 0.91536 | v_loss: 0.84328 v_acc: 0.84342 |  iteration: 2227 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 984 loss: 0.32909 acc: 0.90755 | v_loss: 0.58689 v_acc: 0.86426 |  iteration: 2228 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 985 loss: 0.33061 acc: 0.90397 | v_loss: 0.67563 v_acc: 0.86296 |  iteration: 2229 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 986 loss: 0.35448 acc: 0.89844 | v_loss: 0.41641 v_acc: 0.89909 |  iteration: 2230 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 987 loss: 0.29119 acc: 0.91081 | v_loss: 0.56413 v_acc: 0.86979 |  iteration: 2231 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 988 loss: 0.31221 acc: 0.90755 | v_loss: 0.85879 v_acc: 0.82357 |  iteration: 2232 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 989 loss: 0.39887 acc: 0.89128 | v_loss: 0.51726 v_acc: 0.88932 |  iteration: 2233 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 990 loss: 0.25629 acc: 0.92839 | v_loss: 0.53353 v_acc: 0.88281 |  iteration: 2234 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 991 loss: 0.32878 acc: 0.90267 | v_loss: 0.53315 v_acc: 0.88346 |  iteration: 2235 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 992 loss: 0.33726 acc: 0.90072 | v_loss: 0.50452 v_acc: 0.89453 |  iteration: 2236 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 993 loss: 0.32407 acc: 0.90723 | v_loss: 0.46520 v_acc: 0.90495 |  iteration: 2237 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 994 loss: 0.35509 acc: 0.89779 | v_loss: 0.60510 v_acc: 0.86589 |  iteration: 2238 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 995 loss: 0.26807 acc: 0.92806 | v_loss: 0.45516 v_acc: 0.90397 |  iteration: 2239 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 996 loss: 0.34070 acc: 0.90560 | v_loss: 1.06065 v_acc: 0.81706 |  iteration: 2240 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 997 loss: 0.35928 acc: 0.90332 | v_loss: 0.65042 v_acc: 0.87305 |  iteration: 2241 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 998 loss: 0.31250 acc: 0.91243 | v_loss: 0.74625 v_acc: 0.85286 |  iteration: 2242 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 999 loss: 0.34637 acc: 0.90658 | v_loss: 0.55433 v_acc: 0.88802 |  iteration: 2243 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 1000 loss: 0.25432 acc: 0.92773 | v_loss: 0.54359 v_acc: 0.87695 |  iteration: 2244 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 1001 loss: 0.39378 acc: 0.89355 | v_loss: 0.65986 v_acc: 0.86556 |  iteration: 2245 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 1002 loss: 0.35841 acc: 0.89551 | v_loss: 0.57805 v_acc: 0.87663 |  iteration: 2246 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 1003 loss: 0.22824 acc: 0.93034 | v_loss: 0.51139 v_acc: 0.88509 |  iteration: 2247 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 1004 loss: 0.30371 acc: 0.90820 | v_loss: 0.53957 v_acc: 0.89486 |  iteration: 2248 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 1005 loss: 0.20846 acc: 0.93848 | v_loss: 0.50293 v_acc: 0.88704 |  iteration: 2249 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 1006 loss: 0.32874 acc: 0.90690 | v_loss: 0.36095 v_acc: 0.91406 |  iteration: 2250 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 1007 loss: 0.32451 acc: 0.91081 | v_loss: 0.69399 v_acc: 0.85514 |  iteration: 2251 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 1008 loss: 0.30950 acc: 0.90918 | v_loss: 0.61272 v_acc: 0.85742 |  iteration: 2252 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 1009 loss: 0.31738 acc: 0.91374 | v_loss: 0.63563 v_acc: 0.86068 |  iteration: 2253 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 1010 loss: 0.33320 acc: 0.90853 | v_loss: 0.79171 v_acc: 0.84245 |  iteration: 2254 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 1011 loss: 0.25057 acc: 0.92871 | v_loss: 0.45092 v_acc: 0.89746 |  iteration: 2255 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 1012 loss: 0.32733 acc: 0.91016 | v_loss: 0.59434 v_acc: 0.86882 |  iteration: 2256 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 1013 loss: 0.39060 acc: 0.89323 | v_loss: 0.52816 v_acc: 0.88379 |  iteration: 2257 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 1014 loss: 0.32605 acc: 0.90234 | v_loss: 0.45376 v_acc: 0.88639 |  iteration: 2258 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 1015 loss: 0.36382 acc: 0.89323 | v_loss: 1.04253 v_acc: 0.80306 |  iteration: 2259 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 1016 loss: 0.38037 acc: 0.88444 | v_loss: 0.40534 v_acc: 0.90592 |  iteration: 2260 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 1017 loss: 0.23130 acc: 0.92936 | v_loss: 0.61453 v_acc: 0.87077 |  iteration: 2261 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 1018 loss: 0.37476 acc: 0.88770 | v_loss: 0.53000 v_acc: 0.88281 |  iteration: 2262 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 1019 loss: 0.29732 acc: 0.91960 | v_loss: 0.44707 v_acc: 0.90234 |  iteration: 2263 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 1020 loss: 0.31521 acc: 0.90951 | v_loss: 0.54414 v_acc: 0.88281 |  iteration: 2264 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 1021 loss: 0.37619 acc: 0.89421 | v_loss: 0.61555 v_acc: 0.87142 |  iteration: 2265 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 1022 loss: 0.36235 acc: 0.89648 | v_loss: 0.47468 v_acc: 0.89486 |  iteration: 2266 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 1023 loss: 0.32525 acc: 0.91081 | v_loss: 0.63777 v_acc: 0.86296 |  iteration: 2267 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 1024 loss: 0.31725 acc: 0.91243 | v_loss: 0.46414 v_acc: 0.88086 |  iteration: 2268 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 1025 loss: 0.36219 acc: 0.89616 | v_loss: 0.98897 v_acc: 0.80143 |  iteration: 2269 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 1026 loss: 0.39268 acc: 0.89095 | v_loss: 0.55513 v_acc: 0.88021 |  iteration: 2270 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1027 loss: 0.42447 acc: 0.87923 | v_loss: 0.66523 v_acc: 0.85840 |  iteration: 2271 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1028 loss: 0.29706 acc: 0.91016 | v_loss: 0.45429 v_acc: 0.89030 |  iteration: 2272 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1029 loss: 0.51848 acc: 0.87305 | v_loss: 0.69086 v_acc: 0.85189 |  iteration: 2273 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1030 loss: 0.21125 acc: 0.93327 | v_loss: 0.49431 v_acc: 0.88411 |  iteration: 2274 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1031 loss: 0.22910 acc: 0.92871 | v_loss: 0.52228 v_acc: 0.87533 |  iteration: 2275 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1032 loss: 0.28169 acc: 0.92220 | v_loss: 0.46046 v_acc: 0.88704 |  iteration: 2276 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1033 loss: 0.30585 acc: 0.91439 | v_loss: 0.73266 v_acc: 0.84863 |  iteration: 2277 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1034 loss: 0.31649 acc: 0.91341 | v_loss: 0.57991 v_acc: 0.88184 |  iteration: 2278 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1035 loss: 0.33317 acc: 0.90918 | v_loss: 0.54925 v_acc: 0.87207 |  iteration: 2279 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1036 loss: 0.25934 acc: 0.92578 | v_loss: 0.72138 v_acc: 0.83757 |  iteration: 2280 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1037 loss: 0.25317 acc: 0.91764 | v_loss: 0.46034 v_acc: 0.89128 |  iteration: 2281 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1038 loss: 0.35648 acc: 0.90072 | v_loss: 0.56745 v_acc: 0.86426 |  iteration: 2282 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1039 loss: 0.37471 acc: 0.89616 | v_loss: 0.58986 v_acc: 0.87044 |  iteration: 2283 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1040 loss: 0.31494 acc: 0.91732 | v_loss: 0.83559 v_acc: 0.84082 |  iteration: 2284 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1041 loss: 0.28706 acc: 0.91439 | v_loss: 0.59273 v_acc: 0.88542 |  iteration: 2285 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1042 loss: 0.33920 acc: 0.90365 | v_loss: 0.60384 v_acc: 0.87793 |  iteration: 2286 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1043 loss: 0.32716 acc: 0.89811 | v_loss: 0.67024 v_acc: 0.86523 |  iteration: 2287 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1044 loss: 0.45418 acc: 0.87012 | v_loss: 0.62828 v_acc: 0.85124 |  iteration: 2288 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1045 loss: 0.24700 acc: 0.92643 | v_loss: 0.40991 v_acc: 0.90365 |  iteration: 2289 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1046 loss: 0.33108 acc: 0.90658 | v_loss: 0.85130 v_acc: 0.83952 |  iteration: 2290 teacher: 1 stage: sketch lr: 0.000400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1047 loss: 0.27514 acc: 0.91960 | v_loss: 0.62476 v_acc: 0.87402 |  iteration: 2291 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1048 loss: 0.33965 acc: 0.90527 | v_loss: 0.54909 v_acc: 0.86914 |  iteration: 2292 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1049 loss: 0.25717 acc: 0.92285 | v_loss: 0.58579 v_acc: 0.87142 |  iteration: 2293 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 1050 loss: 0.37772 acc: 0.89714 | v_loss: 0.48664 v_acc: 0.89095 |  iteration: 2294 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 1051 loss: 0.35160 acc: 0.89779 | v_loss: 0.47371 v_acc: 0.88802 |  iteration: 2295 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 1052 loss: 0.41386 acc: 0.87663 | v_loss: 0.55222 v_acc: 0.87923 |  iteration: 2296 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 1053 loss: 0.42349 acc: 0.88672 | v_loss: 0.66924 v_acc: 0.84473 |  iteration: 2297 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 1054 loss: 0.41514 acc: 0.88314 | v_loss: 0.62574 v_acc: 0.86719 |  iteration: 2298 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 1055 loss: 0.32118 acc: 0.90527 | v_loss: 0.65171 v_acc: 0.86426 |  iteration: 2299 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 1056 loss: 0.38085 acc: 0.88965 | v_loss: 0.42169 v_acc: 0.89355 |  iteration: 2300 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 1057 loss: 0.28491 acc: 0.91797 | v_loss: 0.57825 v_acc: 0.87598 |  iteration: 2301 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 1058 loss: 0.36024 acc: 0.89583 | v_loss: 0.52262 v_acc: 0.87695 |  iteration: 2302 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 1059 loss: 0.33704 acc: 0.90430 | v_loss: 0.91365 v_acc: 0.82454 |  iteration: 2303 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 1060 loss: 0.29077 acc: 0.91439 | v_loss: 0.41697 v_acc: 0.89941 |  iteration: 2304 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 1061 loss: 0.28274 acc: 0.91471 | v_loss: 0.36866 v_acc: 0.91667 |  iteration: 2305 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 1062 loss: 0.32524 acc: 0.91113 | v_loss: 0.61217 v_acc: 0.88118 |  iteration: 2306 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 1063 loss: 0.23287 acc: 0.93587 | v_loss: 0.62259 v_acc: 0.88314 |  iteration: 2307 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 1064 loss: 0.31815 acc: 0.91960 | v_loss: 0.75809 v_acc: 0.85026 |  iteration: 2308 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 1065 loss: 0.36207 acc: 0.90462 | v_loss: 0.46351 v_acc: 0.89421 |  iteration: 2309 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 1066 loss: 0.35481 acc: 0.90527 | v_loss: 0.53983 v_acc: 0.86914 |  iteration: 2310 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 1067 loss: 0.33154 acc: 0.90983 | v_loss: 0.61598 v_acc: 0.85547 |  iteration: 2311 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 1068 loss: 0.36278 acc: 0.89648 | v_loss: 0.70835 v_acc: 0.83789 |  iteration: 2312 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 1069 loss: 0.34441 acc: 0.89290 | v_loss: 0.52946 v_acc: 0.88932 |  iteration: 2313 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 1070 loss: 0.32252 acc: 0.90885 | v_loss: 0.40743 v_acc: 0.89811 |  iteration: 2314 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 1071 loss: 0.37592 acc: 0.89355 | v_loss: 0.30018 v_acc: 0.92025 |  iteration: 2315 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 1072 loss: 0.38099 acc: 0.89486 | v_loss: 0.49930 v_acc: 0.89583 |  iteration: 2316 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 1073 loss: 0.35018 acc: 0.90267 | v_loss: 0.52482 v_acc: 0.88021 |  iteration: 2317 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 1074 loss: 0.31159 acc: 0.90723 | v_loss: 0.88696 v_acc: 0.84961 |  iteration: 2318 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 1075 loss: 0.29290 acc: 0.91862 | v_loss: 0.59681 v_acc: 0.86784 |  iteration: 2319 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 1076 loss: 0.32080 acc: 0.90625 | v_loss: 0.69819 v_acc: 0.86133 |  iteration: 2320 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 1077 loss: 0.35994 acc: 0.90104 | v_loss: 0.45876 v_acc: 0.89453 |  iteration: 2321 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 1078 loss: 0.29401 acc: 0.92122 | v_loss: 0.57319 v_acc: 0.87891 |  iteration: 2322 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 1079 loss: 0.23025 acc: 0.93587 | v_loss: 0.83014 v_acc: 0.83105 |  iteration: 2323 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 1080 loss: 0.33322 acc: 0.90299 | v_loss: 0.57348 v_acc: 0.88346 |  iteration: 2324 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 1081 loss: 0.27597 acc: 0.92480 | v_loss: 0.55615 v_acc: 0.87435 |  iteration: 2325 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 1082 loss: 0.34886 acc: 0.90234 | v_loss: 0.51754 v_acc: 0.87695 |  iteration: 2326 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 1083 loss: 0.30442 acc: 0.91113 | v_loss: 0.45375 v_acc: 0.89909 |  iteration: 2327 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 1084 loss: 0.38186 acc: 0.89128 | v_loss: 0.45412 v_acc: 0.89616 |  iteration: 2328 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 1085 loss: 0.28470 acc: 0.91374 | v_loss: 0.62732 v_acc: 0.85775 |  iteration: 2329 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 1086 loss: 0.27080 acc: 0.91699 | v_loss: 0.41889 v_acc: 0.90723 |  iteration: 2330 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 1087 loss: 0.42427 acc: 0.88477 | v_loss: 0.89050 v_acc: 0.82780 |  iteration: 2331 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 1088 loss: 0.35275 acc: 0.89746 | v_loss: 0.64002 v_acc: 0.87174 |  iteration: 2332 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 1089 loss: 0.38524 acc: 0.89128 | v_loss: 0.74462 v_acc: 0.84505 |  iteration: 2333 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 1090 loss: 0.33409 acc: 0.90072 | v_loss: 0.52927 v_acc: 0.88867 |  iteration: 2334 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 1091 loss: 0.31913 acc: 0.91276 | v_loss: 0.51978 v_acc: 0.88509 |  iteration: 2335 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 1092 loss: 0.30800 acc: 0.90918 | v_loss: 0.67290 v_acc: 0.86914 |  iteration: 2336 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 1093 loss: 0.33170 acc: 0.90853 | v_loss: 0.56266 v_acc: 0.88574 |  iteration: 2337 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 1094 loss: 0.32378 acc: 0.91048 | v_loss: 0.55415 v_acc: 0.88509 |  iteration: 2338 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 1095 loss: 0.27581 acc: 0.91439 | v_loss: 0.51318 v_acc: 0.89648 |  iteration: 2339 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 1096 loss: 0.28451 acc: 0.92122 | v_loss: 0.49204 v_acc: 0.89225 |  iteration: 2340 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 1097 loss: 0.35200 acc: 0.90820 | v_loss: 0.37743 v_acc: 0.91276 |  iteration: 2341 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 1098 loss: 0.27324 acc: 0.92253 | v_loss: 0.68381 v_acc: 0.85645 |  iteration: 2342 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 1099 loss: 0.29045 acc: 0.91569 | v_loss: 0.56804 v_acc: 0.86035 |  iteration: 2343 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 1100 loss: 0.25999 acc: 0.92415 | v_loss: 0.65292 v_acc: 0.85807 |  iteration: 2344 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 1101 loss: 0.36236 acc: 0.89453 | v_loss: 0.84800 v_acc: 0.83366 |  iteration: 2345 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 1102 loss: 0.30187 acc: 0.92025 | v_loss: 0.47834 v_acc: 0.89616 |  iteration: 2346 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 1103 loss: 0.35882 acc: 0.89095 | v_loss: 0.62187 v_acc: 0.86719 |  iteration: 2347 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 1104 loss: 0.37087 acc: 0.89681 | v_loss: 0.56937 v_acc: 0.88151 |  iteration: 2348 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 1105 loss: 0.48919 acc: 0.88444 | v_loss: 0.47807 v_acc: 0.88639 |  iteration: 2349 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 1106 loss: 0.33670 acc: 0.90658 | v_loss: 1.07709 v_acc: 0.80143 |  iteration: 2350 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 1107 loss: 0.41563 acc: 0.89062 | v_loss: 0.45493 v_acc: 0.89290 |  iteration: 2351 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 1108 loss: 0.30964 acc: 0.90658 | v_loss: 0.58758 v_acc: 0.86165 |  iteration: 2352 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 1109 loss: 0.31422 acc: 0.90625 | v_loss: 0.53490 v_acc: 0.87370 |  iteration: 2353 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 1110 loss: 0.31372 acc: 0.90397 | v_loss: 0.47058 v_acc: 0.89779 |  iteration: 2354 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 1111 loss: 0.30532 acc: 0.91211 | v_loss: 0.54528 v_acc: 0.88607 |  iteration: 2355 teacher: 1 stage: sketch lr: 0.000411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1112 loss: 0.22985 acc: 0.93132 | v_loss: 0.64866 v_acc: 0.86654 |  iteration: 2356 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 1113 loss: 0.35309 acc: 0.90430 | v_loss: 0.50536 v_acc: 0.89909 |  iteration: 2357 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 1114 loss: 0.31197 acc: 0.91243 | v_loss: 0.71371 v_acc: 0.86458 |  iteration: 2358 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 1115 loss: 0.36486 acc: 0.90137 | v_loss: 0.44961 v_acc: 0.88965 |  iteration: 2359 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 1116 loss: 0.32849 acc: 0.91146 | v_loss: 1.04886 v_acc: 0.82585 |  iteration: 2360 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 1117 loss: 0.37900 acc: 0.89844 | v_loss: 0.59759 v_acc: 0.87598 |  iteration: 2361 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 1118 loss: 0.40518 acc: 0.87956 | v_loss: 0.69010 v_acc: 0.86751 |  iteration: 2362 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 1119 loss: 0.25188 acc: 0.92936 | v_loss: 0.45959 v_acc: 0.88639 |  iteration: 2363 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 1120 loss: 0.29715 acc: 0.91667 | v_loss: 0.68119 v_acc: 0.84863 |  iteration: 2364 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 1121 loss: 0.33129 acc: 0.90820 | v_loss: 0.44466 v_acc: 0.89128 |  iteration: 2365 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 1122 loss: 0.31145 acc: 0.90690 | v_loss: 0.49070 v_acc: 0.88346 |  iteration: 2366 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 1123 loss: 0.27883 acc: 0.92155 | v_loss: 0.47592 v_acc: 0.88997 |  iteration: 2367 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 1124 loss: 0.38922 acc: 0.89323 | v_loss: 0.78954 v_acc: 0.83952 |  iteration: 2368 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 1125 loss: 0.43733 acc: 0.87142 | v_loss: 0.51431 v_acc: 0.89030 |  iteration: 2369 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 1126 loss: 0.30037 acc: 0.90788 | v_loss: 0.60805 v_acc: 0.86654 |  iteration: 2370 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 1127 loss: 0.37477 acc: 0.89160 | v_loss: 0.69185 v_acc: 0.84570 |  iteration: 2371 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 1128 loss: 0.32548 acc: 0.91699 | v_loss: 0.46610 v_acc: 0.87956 |  iteration: 2372 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 1129 loss: 0.34142 acc: 0.90690 | v_loss: 0.55124 v_acc: 0.86393 |  iteration: 2373 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 1130 loss: 0.27601 acc: 0.92318 | v_loss: 0.58213 v_acc: 0.86751 |  iteration: 2374 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 1131 loss: 0.35676 acc: 0.90202 | v_loss: 0.81733 v_acc: 0.85059 |  iteration: 2375 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 1132 loss: 0.34988 acc: 0.90332 | v_loss: 0.59251 v_acc: 0.87956 |  iteration: 2376 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 1133 loss: 0.31762 acc: 0.90951 | v_loss: 0.58174 v_acc: 0.88542 |  iteration: 2377 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 1134 loss: 0.23432 acc: 0.93359 | v_loss: 0.65792 v_acc: 0.87956 |  iteration: 2378 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 1135 loss: 0.29480 acc: 0.91699 | v_loss: 0.61282 v_acc: 0.86100 |  iteration: 2379 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 1136 loss: 0.28749 acc: 0.92057 | v_loss: 0.47417 v_acc: 0.89030 |  iteration: 2380 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 1137 loss: 0.36179 acc: 0.90007 | v_loss: 0.86143 v_acc: 0.83919 |  iteration: 2381 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 1138 loss: 0.29244 acc: 0.91471 | v_loss: 0.67295 v_acc: 0.86589 |  iteration: 2382 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 1139 loss: 0.28186 acc: 0.92546 | v_loss: 0.62950 v_acc: 0.86491 |  iteration: 2383 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 1140 loss: 0.34075 acc: 0.90625 | v_loss: 0.57559 v_acc: 0.87402 |  iteration: 2384 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 1141 loss: 0.35936 acc: 0.90365 | v_loss: 0.52428 v_acc: 0.88997 |  iteration: 2385 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 1142 loss: 0.29906 acc: 0.90983 | v_loss: 0.48954 v_acc: 0.88281 |  iteration: 2386 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 1143 loss: 0.37843 acc: 0.88802 | v_loss: 0.55884 v_acc: 0.87760 |  iteration: 2387 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 1144 loss: 0.32342 acc: 0.91113 | v_loss: 0.63457 v_acc: 0.84603 |  iteration: 2388 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 1145 loss: 0.30181 acc: 0.90788 | v_loss: 0.60468 v_acc: 0.87142 |  iteration: 2389 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 1146 loss: 0.28857 acc: 0.91471 | v_loss: 0.64545 v_acc: 0.87142 |  iteration: 2390 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1147 loss: 0.29425 acc: 0.91081 | v_loss: 0.43607 v_acc: 0.90299 |  iteration: 2391 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1148 loss: 0.40139 acc: 0.88737 | v_loss: 0.56821 v_acc: 0.87630 |  iteration: 2392 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1149 loss: 0.30804 acc: 0.91048 | v_loss: 0.50810 v_acc: 0.88379 |  iteration: 2393 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1150 loss: 0.32880 acc: 0.91276 | v_loss: 0.92853 v_acc: 0.82682 |  iteration: 2394 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1151 loss: 0.26230 acc: 0.92611 | v_loss: 0.37294 v_acc: 0.90592 |  iteration: 2395 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1152 loss: 0.37430 acc: 0.89616 | v_loss: 0.35433 v_acc: 0.91960 |  iteration: 2396 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1153 loss: 0.28384 acc: 0.91406 | v_loss: 0.58121 v_acc: 0.88151 |  iteration: 2397 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1154 loss: 0.33990 acc: 0.90234 | v_loss: 0.59124 v_acc: 0.87891 |  iteration: 2398 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1155 loss: 0.23792 acc: 0.92188 | v_loss: 0.68212 v_acc: 0.86068 |  iteration: 2399 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1156 loss: 0.32944 acc: 0.90234 | v_loss: 0.44757 v_acc: 0.89290 |  iteration: 2400 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1157 loss: 0.24767 acc: 0.93229 | v_loss: 0.54208 v_acc: 0.86751 |  iteration: 2401 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1158 loss: 0.26734 acc: 0.92383 | v_loss: 0.59394 v_acc: 0.87142 |  iteration: 2402 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1159 loss: 0.29946 acc: 0.91211 | v_loss: 0.69295 v_acc: 0.84993 |  iteration: 2403 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1160 loss: 0.34818 acc: 0.90072 | v_loss: 0.52600 v_acc: 0.88900 |  iteration: 2404 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1161 loss: 0.25896 acc: 0.92383 | v_loss: 0.42107 v_acc: 0.89876 |  iteration: 2405 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1162 loss: 0.29215 acc: 0.91536 | v_loss: 0.31256 v_acc: 0.91960 |  iteration: 2406 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1163 loss: 0.22069 acc: 0.93587 | v_loss: 0.50469 v_acc: 0.89095 |  iteration: 2407 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1164 loss: 0.25228 acc: 0.92155 | v_loss: 0.51505 v_acc: 0.88346 |  iteration: 2408 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1165 loss: 0.32758 acc: 0.91309 | v_loss: 0.85661 v_acc: 0.85124 |  iteration: 2409 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1166 loss: 0.43951 acc: 0.88151 | v_loss: 0.59823 v_acc: 0.87663 |  iteration: 2410 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1167 loss: 0.16780 acc: 0.95020 | v_loss: 0.71623 v_acc: 0.86621 |  iteration: 2411 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1168 loss: 0.26533 acc: 0.92969 | v_loss: 0.42911 v_acc: 0.89909 |  iteration: 2412 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1169 loss: 0.33575 acc: 0.90853 | v_loss: 0.59430 v_acc: 0.86979 |  iteration: 2413 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1170 loss: 0.22841 acc: 0.94043 | v_loss: 0.79799 v_acc: 0.84245 |  iteration: 2414 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1171 loss: 0.38652 acc: 0.88867 | v_loss: 0.54129 v_acc: 0.88574 |  iteration: 2415 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1172 loss: 0.33979 acc: 0.90625 | v_loss: 0.53687 v_acc: 0.88444 |  iteration: 2416 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1173 loss: 0.43549 acc: 0.88574 | v_loss: 0.50525 v_acc: 0.88086 |  iteration: 2417 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1174 loss: 0.30321 acc: 0.90983 | v_loss: 0.44834 v_acc: 0.89453 |  iteration: 2418 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1175 loss: 0.32724 acc: 0.90495 | v_loss: 0.47212 v_acc: 0.89811 |  iteration: 2419 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 1176 loss: 0.34405 acc: 0.89876 | v_loss: 0.60203 v_acc: 0.86263 |  iteration: 2420 teacher: 1 stage: sketch lr: 0.000423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1177 loss: 0.32431 acc: 0.90723 | v_loss: 0.37090 v_acc: 0.91536 |  iteration: 2421 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 1178 loss: 0.27415 acc: 0.92383 | v_loss: 0.92485 v_acc: 0.82292 |  iteration: 2422 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 1179 loss: 0.33941 acc: 0.89714 | v_loss: 0.66032 v_acc: 0.86458 |  iteration: 2423 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 1180 loss: 0.32877 acc: 0.90625 | v_loss: 0.69121 v_acc: 0.85384 |  iteration: 2424 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 1181 loss: 0.31826 acc: 0.90983 | v_loss: 0.52723 v_acc: 0.89974 |  iteration: 2425 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 1182 loss: 0.26015 acc: 0.92415 | v_loss: 0.54540 v_acc: 0.88411 |  iteration: 2426 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 1183 loss: 0.29959 acc: 0.91504 | v_loss: 0.64759 v_acc: 0.87305 |  iteration: 2427 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 1184 loss: 0.27325 acc: 0.92708 | v_loss: 0.54709 v_acc: 0.88835 |  iteration: 2428 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 1185 loss: 0.32885 acc: 0.90723 | v_loss: 0.50822 v_acc: 0.89225 |  iteration: 2429 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 1186 loss: 0.29978 acc: 0.91406 | v_loss: 0.58617 v_acc: 0.89062 |  iteration: 2430 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 1187 loss: 0.30676 acc: 0.91374 | v_loss: 0.51581 v_acc: 0.88672 |  iteration: 2431 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 1188 loss: 0.36939 acc: 0.90202 | v_loss: 0.37950 v_acc: 0.91764 |  iteration: 2432 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 1189 loss: 0.31043 acc: 0.91341 | v_loss: 0.61918 v_acc: 0.86263 |  iteration: 2433 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 1190 loss: 0.27673 acc: 0.92057 | v_loss: 0.60386 v_acc: 0.85645 |  iteration: 2434 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 1191 loss: 0.34620 acc: 0.89844 | v_loss: 0.63967 v_acc: 0.85840 |  iteration: 2435 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 1192 loss: 0.38834 acc: 0.88835 | v_loss: 0.79642 v_acc: 0.84505 |  iteration: 2436 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 1193 loss: 0.27805 acc: 0.91960 | v_loss: 0.43309 v_acc: 0.90430 |  iteration: 2437 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 1194 loss: 0.29897 acc: 0.92220 | v_loss: 0.60703 v_acc: 0.87012 |  iteration: 2438 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 1195 loss: 0.27485 acc: 0.92350 | v_loss: 0.56305 v_acc: 0.88770 |  iteration: 2439 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 1196 loss: 0.34329 acc: 0.90397 | v_loss: 0.42927 v_acc: 0.90755 |  iteration: 2440 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 1197 loss: 0.27415 acc: 0.92741 | v_loss: 1.16084 v_acc: 0.80176 |  iteration: 2441 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 1198 loss: 0.29664 acc: 0.91569 | v_loss: 0.37572 v_acc: 0.91536 |  iteration: 2442 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 1199 loss: 0.30552 acc: 0.90820 | v_loss: 0.62486 v_acc: 0.87109 |  iteration: 2443 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 1200 loss: 0.36246 acc: 0.89876 | v_loss: 0.56040 v_acc: 0.88639 |  iteration: 2444 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 1201 loss: 0.37439 acc: 0.89421 | v_loss: 0.48399 v_acc: 0.89909 |  iteration: 2445 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 1202 loss: 0.33303 acc: 0.90397 | v_loss: 0.50716 v_acc: 0.89095 |  iteration: 2446 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 1203 loss: 0.28939 acc: 0.91797 | v_loss: 0.60444 v_acc: 0.87467 |  iteration: 2447 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 1204 loss: 0.33928 acc: 0.91146 | v_loss: 0.47751 v_acc: 0.89844 |  iteration: 2448 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 1205 loss: 0.29154 acc: 0.90951 | v_loss: 0.65552 v_acc: 0.86328 |  iteration: 2449 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 1206 loss: 0.37897 acc: 0.89583 | v_loss: 0.39415 v_acc: 0.90397 |  iteration: 2450 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 1207 loss: 0.26789 acc: 0.93034 | v_loss: 0.96078 v_acc: 0.81348 |  iteration: 2451 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 1208 loss: 0.36642 acc: 0.89648 | v_loss: 0.57630 v_acc: 0.87174 |  iteration: 2452 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 1209 loss: 0.27469 acc: 0.91927 | v_loss: 0.65225 v_acc: 0.85677 |  iteration: 2453 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 1210 loss: 0.29572 acc: 0.91992 | v_loss: 0.52198 v_acc: 0.87272 |  iteration: 2454 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 1211 loss: 0.30872 acc: 0.91504 | v_loss: 0.68390 v_acc: 0.84635 |  iteration: 2455 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 1212 loss: 0.44270 acc: 0.87760 | v_loss: 0.46495 v_acc: 0.89193 |  iteration: 2456 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 1213 loss: 0.33412 acc: 0.90137 | v_loss: 0.49756 v_acc: 0.88444 |  iteration: 2457 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 1214 loss: 0.34135 acc: 0.90527 | v_loss: 0.47602 v_acc: 0.88509 |  iteration: 2458 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 1215 loss: 0.34020 acc: 0.90299 | v_loss: 0.78102 v_acc: 0.85124 |  iteration: 2459 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 1216 loss: 0.25358 acc: 0.92936 | v_loss: 0.56682 v_acc: 0.89193 |  iteration: 2460 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 1217 loss: 0.32447 acc: 0.90267 | v_loss: 0.63399 v_acc: 0.86263 |  iteration: 2461 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 1218 loss: 0.42166 acc: 0.88216 | v_loss: 0.75071 v_acc: 0.84863 |  iteration: 2462 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 1219 loss: 0.36676 acc: 0.90267 | v_loss: 0.46447 v_acc: 0.88867 |  iteration: 2463 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 1220 loss: 0.27119 acc: 0.92057 | v_loss: 0.54024 v_acc: 0.86328 |  iteration: 2464 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 1221 loss: 0.28938 acc: 0.91992 | v_loss: 0.57858 v_acc: 0.86849 |  iteration: 2465 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 1222 loss: 0.28014 acc: 0.91406 | v_loss: 0.73988 v_acc: 0.84831 |  iteration: 2466 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 1223 loss: 0.39058 acc: 0.88281 | v_loss: 0.55720 v_acc: 0.87695 |  iteration: 2467 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 1224 loss: 0.31011 acc: 0.90592 | v_loss: 0.55979 v_acc: 0.88249 |  iteration: 2468 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 1225 loss: 0.30885 acc: 0.90788 | v_loss: 0.68147 v_acc: 0.86914 |  iteration: 2469 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 1226 loss: 0.25202 acc: 0.92741 | v_loss: 0.59137 v_acc: 0.85482 |  iteration: 2470 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 1227 loss: 0.30481 acc: 0.91471 | v_loss: 0.48396 v_acc: 0.89421 |  iteration: 2471 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 1228 loss: 0.34546 acc: 0.91146 | v_loss: 0.82757 v_acc: 0.84115 |  iteration: 2472 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 1229 loss: 0.29114 acc: 0.91243 | v_loss: 0.63633 v_acc: 0.88086 |  iteration: 2473 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 1230 loss: 0.35518 acc: 0.90560 | v_loss: 0.55153 v_acc: 0.87630 |  iteration: 2474 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 1231 loss: 0.27146 acc: 0.91895 | v_loss: 0.59112 v_acc: 0.86979 |  iteration: 2475 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 1232 loss: 0.29588 acc: 0.91146 | v_loss: 0.50619 v_acc: 0.88411 |  iteration: 2476 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 1233 loss: 0.33452 acc: 0.90072 | v_loss: 0.50113 v_acc: 0.88737 |  iteration: 2477 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 1234 loss: 0.44121 acc: 0.88444 | v_loss: 0.54103 v_acc: 0.88184 |  iteration: 2478 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 1235 loss: 0.31258 acc: 0.91016 | v_loss: 0.62685 v_acc: 0.85449 |  iteration: 2479 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 1236 loss: 0.27540 acc: 0.92285 | v_loss: 0.60045 v_acc: 0.87923 |  iteration: 2480 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 1237 loss: 0.26895 acc: 0.92025 | v_loss: 0.65730 v_acc: 0.87533 |  iteration: 2481 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 1238 loss: 0.30269 acc: 0.91243 | v_loss: 0.37968 v_acc: 0.90788 |  iteration: 2482 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 1239 loss: 0.26272 acc: 0.92318 | v_loss: 0.56839 v_acc: 0.87826 |  iteration: 2483 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 1240 loss: 0.30912 acc: 0.91439 | v_loss: 0.51838 v_acc: 0.87467 |  iteration: 2484 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 1241 loss: 0.28008 acc: 0.91992 | v_loss: 0.89550 v_acc: 0.82910 |  iteration: 2485 teacher: 1 stage: sketch lr: 0.000434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1242 loss: 0.22144 acc: 0.93197 | v_loss: 0.39864 v_acc: 0.90072 |  iteration: 2486 teacher: 1 stage: sketch lr: 0.000434\n",
      "epoch 1 loss: 0.40270 acc: 0.88410 | v_loss: 0.63200 v_acc: 0.85740 \n",
      "epoch: 2\n",
      "__________________________________________\n",
      "batch 0 loss: 0.26208 acc: 0.92546 | v_loss: 0.63468 v_acc: 0.86816 |  iteration: 2487 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 1 loss: 0.25218 acc: 0.92643 | v_loss: 0.53681 v_acc: 0.88574 |  iteration: 2488 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 2 loss: 0.29199 acc: 0.91927 | v_loss: 0.54543 v_acc: 0.88770 |  iteration: 2489 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 3 loss: 0.30515 acc: 0.91471 | v_loss: 0.51969 v_acc: 0.90169 |  iteration: 2490 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 4 loss: 0.39324 acc: 0.89518 | v_loss: 0.46453 v_acc: 0.89746 |  iteration: 2491 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 5 loss: 0.31834 acc: 0.90527 | v_loss: 0.40818 v_acc: 0.90820 |  iteration: 2492 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 6 loss: 0.37471 acc: 0.89388 | v_loss: 0.67641 v_acc: 0.86426 |  iteration: 2493 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 7 loss: 0.35016 acc: 0.90137 | v_loss: 0.57169 v_acc: 0.86556 |  iteration: 2494 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 8 loss: 0.28524 acc: 0.91829 | v_loss: 0.63131 v_acc: 0.86393 |  iteration: 2495 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 9 loss: 0.36101 acc: 0.90202 | v_loss: 0.79580 v_acc: 0.84538 |  iteration: 2496 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 10 loss: 0.34670 acc: 0.90397 | v_loss: 0.43429 v_acc: 0.90202 |  iteration: 2497 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 11 loss: 0.30933 acc: 0.91146 | v_loss: 0.56660 v_acc: 0.87272 |  iteration: 2498 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 12 loss: 0.32560 acc: 0.90462 | v_loss: 0.56010 v_acc: 0.88704 |  iteration: 2499 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 13 loss: 0.24258 acc: 0.93001 | v_loss: 0.41362 v_acc: 0.89974 |  iteration: 2500 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 14 loss: 0.40039 acc: 0.88346 | v_loss: 1.12976 v_acc: 0.81283 |  iteration: 2501 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 15 loss: 0.20278 acc: 0.93815 | v_loss: 0.40929 v_acc: 0.91113 |  iteration: 2502 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 16 loss: 0.25116 acc: 0.92090 | v_loss: 0.63688 v_acc: 0.87012 |  iteration: 2503 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 17 loss: 0.39538 acc: 0.89323 | v_loss: 0.55080 v_acc: 0.89095 |  iteration: 2504 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 18 loss: 0.35861 acc: 0.90397 | v_loss: 0.46411 v_acc: 0.89551 |  iteration: 2505 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 19 loss: 0.32264 acc: 0.90560 | v_loss: 0.50130 v_acc: 0.89453 |  iteration: 2506 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 20 loss: 0.31758 acc: 0.91406 | v_loss: 0.62132 v_acc: 0.86947 |  iteration: 2507 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 21 loss: 0.29117 acc: 0.91569 | v_loss: 0.46023 v_acc: 0.90137 |  iteration: 2508 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 22 loss: 0.31034 acc: 0.91634 | v_loss: 0.65573 v_acc: 0.86263 |  iteration: 2509 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 23 loss: 0.26754 acc: 0.92090 | v_loss: 0.42296 v_acc: 0.90267 |  iteration: 2510 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 24 loss: 0.31027 acc: 0.91634 | v_loss: 0.96321 v_acc: 0.82227 |  iteration: 2511 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 25 loss: 0.37544 acc: 0.89681 | v_loss: 0.56033 v_acc: 0.88639 |  iteration: 2512 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 26 loss: 0.35245 acc: 0.89681 | v_loss: 0.69760 v_acc: 0.86621 |  iteration: 2513 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 27 loss: 0.36380 acc: 0.89648 | v_loss: 0.43755 v_acc: 0.89811 |  iteration: 2514 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 28 loss: 0.28387 acc: 0.92057 | v_loss: 0.67250 v_acc: 0.85742 |  iteration: 2515 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 29 loss: 0.35509 acc: 0.90137 | v_loss: 0.46396 v_acc: 0.89193 |  iteration: 2516 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 30 loss: 0.25865 acc: 0.92415 | v_loss: 0.46486 v_acc: 0.88802 |  iteration: 2517 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 31 loss: 0.33622 acc: 0.89486 | v_loss: 0.41640 v_acc: 0.89453 |  iteration: 2518 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 32 loss: 0.30851 acc: 0.90072 | v_loss: 0.71437 v_acc: 0.86100 |  iteration: 2519 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 33 loss: 0.36109 acc: 0.90299 | v_loss: 0.54426 v_acc: 0.88835 |  iteration: 2520 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 34 loss: 0.28610 acc: 0.91862 | v_loss: 0.56760 v_acc: 0.87793 |  iteration: 2521 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 35 loss: 0.29336 acc: 0.92057 | v_loss: 0.69728 v_acc: 0.84310 |  iteration: 2522 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 36 loss: 0.32453 acc: 0.90495 | v_loss: 0.46146 v_acc: 0.88770 |  iteration: 2523 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 37 loss: 0.30962 acc: 0.90951 | v_loss: 0.50972 v_acc: 0.86979 |  iteration: 2524 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 38 loss: 0.30505 acc: 0.90332 | v_loss: 0.55482 v_acc: 0.86523 |  iteration: 2525 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 39 loss: 0.28058 acc: 0.91960 | v_loss: 0.77046 v_acc: 0.84375 |  iteration: 2526 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 40 loss: 0.26563 acc: 0.92285 | v_loss: 0.54124 v_acc: 0.88118 |  iteration: 2527 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 41 loss: 0.35847 acc: 0.90234 | v_loss: 0.55602 v_acc: 0.88314 |  iteration: 2528 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 42 loss: 0.37829 acc: 0.89095 | v_loss: 0.64961 v_acc: 0.87012 |  iteration: 2529 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 43 loss: 0.28055 acc: 0.91211 | v_loss: 0.58811 v_acc: 0.86458 |  iteration: 2530 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 44 loss: 0.28745 acc: 0.91992 | v_loss: 0.42508 v_acc: 0.90397 |  iteration: 2531 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 45 loss: 0.31734 acc: 0.91243 | v_loss: 0.82177 v_acc: 0.84668 |  iteration: 2532 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 46 loss: 0.21022 acc: 0.94271 | v_loss: 0.59852 v_acc: 0.88053 |  iteration: 2533 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 47 loss: 0.23662 acc: 0.92643 | v_loss: 0.56542 v_acc: 0.87500 |  iteration: 2534 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 48 loss: 0.31616 acc: 0.91471 | v_loss: 0.58895 v_acc: 0.87402 |  iteration: 2535 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 49 loss: 0.30325 acc: 0.90788 | v_loss: 0.48213 v_acc: 0.89616 |  iteration: 2536 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 50 loss: 0.25643 acc: 0.92676 | v_loss: 0.47255 v_acc: 0.89355 |  iteration: 2537 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 51 loss: 0.34618 acc: 0.90430 | v_loss: 0.54285 v_acc: 0.87988 |  iteration: 2538 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 52 loss: 0.29591 acc: 0.91439 | v_loss: 0.65291 v_acc: 0.84538 |  iteration: 2539 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 53 loss: 0.36057 acc: 0.90039 | v_loss: 0.58158 v_acc: 0.87956 |  iteration: 2540 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 54 loss: 0.27790 acc: 0.92513 | v_loss: 0.60047 v_acc: 0.87695 |  iteration: 2541 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 55 loss: 0.23931 acc: 0.92643 | v_loss: 0.41799 v_acc: 0.90397 |  iteration: 2542 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 56 loss: 0.24036 acc: 0.92904 | v_loss: 0.60456 v_acc: 0.86751 |  iteration: 2543 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 57 loss: 0.34559 acc: 0.90169 | v_loss: 0.45758 v_acc: 0.88900 |  iteration: 2544 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 58 loss: 0.27204 acc: 0.91569 | v_loss: 0.91420 v_acc: 0.83398 |  iteration: 2545 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 59 loss: 0.29613 acc: 0.91960 | v_loss: 0.39176 v_acc: 0.90560 |  iteration: 2546 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 60 loss: 0.38438 acc: 0.89388 | v_loss: 0.33714 v_acc: 0.92057 |  iteration: 2547 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 61 loss: 0.29050 acc: 0.91862 | v_loss: 0.56213 v_acc: 0.87891 |  iteration: 2548 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 62 loss: 0.28879 acc: 0.91862 | v_loss: 0.54731 v_acc: 0.88639 |  iteration: 2549 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 63 loss: 0.35753 acc: 0.89941 | v_loss: 0.68196 v_acc: 0.85352 |  iteration: 2550 teacher: 0 stage: sketch lr: 0.000445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 64 loss: 0.28152 acc: 0.91211 | v_loss: 0.44258 v_acc: 0.89421 |  iteration: 2551 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 65 loss: 0.36608 acc: 0.88997 | v_loss: 0.56964 v_acc: 0.87370 |  iteration: 2552 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 66 loss: 0.29786 acc: 0.90723 | v_loss: 0.67274 v_acc: 0.85742 |  iteration: 2553 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 67 loss: 0.28482 acc: 0.91797 | v_loss: 0.68829 v_acc: 0.84831 |  iteration: 2554 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 68 loss: 0.36219 acc: 0.90755 | v_loss: 0.51595 v_acc: 0.89779 |  iteration: 2555 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 69 loss: 0.24840 acc: 0.92806 | v_loss: 0.42749 v_acc: 0.90820 |  iteration: 2556 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 70 loss: 0.37676 acc: 0.90104 | v_loss: 0.33211 v_acc: 0.91667 |  iteration: 2557 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 71 loss: 0.28062 acc: 0.92285 | v_loss: 0.48864 v_acc: 0.90462 |  iteration: 2558 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 72 loss: 0.22806 acc: 0.93197 | v_loss: 0.54791 v_acc: 0.87858 |  iteration: 2559 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 73 loss: 0.34671 acc: 0.90072 | v_loss: 0.90281 v_acc: 0.85286 |  iteration: 2560 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 74 loss: 0.25660 acc: 0.93001 | v_loss: 0.59936 v_acc: 0.87272 |  iteration: 2561 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 75 loss: 0.35312 acc: 0.90755 | v_loss: 0.67489 v_acc: 0.86654 |  iteration: 2562 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 76 loss: 0.27555 acc: 0.92708 | v_loss: 0.42666 v_acc: 0.89583 |  iteration: 2563 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 77 loss: 0.33848 acc: 0.90820 | v_loss: 0.54323 v_acc: 0.87858 |  iteration: 2564 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 78 loss: 0.24884 acc: 0.92448 | v_loss: 0.83604 v_acc: 0.82585 |  iteration: 2565 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 79 loss: 0.38706 acc: 0.88932 | v_loss: 0.59771 v_acc: 0.87435 |  iteration: 2566 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 80 loss: 0.33775 acc: 0.90234 | v_loss: 0.52177 v_acc: 0.88184 |  iteration: 2567 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 81 loss: 0.26655 acc: 0.92318 | v_loss: 0.48363 v_acc: 0.88281 |  iteration: 2568 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 82 loss: 0.36753 acc: 0.90397 | v_loss: 0.45314 v_acc: 0.89616 |  iteration: 2569 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 83 loss: 0.22309 acc: 0.93424 | v_loss: 0.45864 v_acc: 0.90202 |  iteration: 2570 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 84 loss: 0.36874 acc: 0.89323 | v_loss: 0.61174 v_acc: 0.86784 |  iteration: 2571 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 85 loss: 0.27062 acc: 0.92057 | v_loss: 0.40092 v_acc: 0.91406 |  iteration: 2572 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 86 loss: 0.29611 acc: 0.91406 | v_loss: 0.93725 v_acc: 0.82812 |  iteration: 2573 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 87 loss: 0.28239 acc: 0.91699 | v_loss: 0.67952 v_acc: 0.87142 |  iteration: 2574 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 88 loss: 0.29040 acc: 0.92090 | v_loss: 0.77404 v_acc: 0.85579 |  iteration: 2575 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 89 loss: 0.29961 acc: 0.91374 | v_loss: 0.53756 v_acc: 0.88574 |  iteration: 2576 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 90 loss: 0.32128 acc: 0.91016 | v_loss: 0.52751 v_acc: 0.88574 |  iteration: 2577 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 91 loss: 0.31260 acc: 0.90951 | v_loss: 0.59922 v_acc: 0.87923 |  iteration: 2578 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 92 loss: 0.24739 acc: 0.92676 | v_loss: 0.53090 v_acc: 0.88607 |  iteration: 2579 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 93 loss: 0.24790 acc: 0.92546 | v_loss: 0.54528 v_acc: 0.88346 |  iteration: 2580 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 94 loss: 0.34184 acc: 0.89583 | v_loss: 0.51686 v_acc: 0.90072 |  iteration: 2581 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 95 loss: 0.26327 acc: 0.92448 | v_loss: 0.46440 v_acc: 0.90267 |  iteration: 2582 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 96 loss: 0.36468 acc: 0.89909 | v_loss: 0.36854 v_acc: 0.91276 |  iteration: 2583 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 97 loss: 0.24047 acc: 0.92806 | v_loss: 0.65428 v_acc: 0.86035 |  iteration: 2584 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 98 loss: 0.20831 acc: 0.93490 | v_loss: 0.59898 v_acc: 0.86003 |  iteration: 2585 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 99 loss: 0.29998 acc: 0.91178 | v_loss: 0.59525 v_acc: 0.86882 |  iteration: 2586 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 100 loss: 0.30330 acc: 0.91243 | v_loss: 0.84705 v_acc: 0.83919 |  iteration: 2587 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 101 loss: 0.29597 acc: 0.91667 | v_loss: 0.45749 v_acc: 0.90072 |  iteration: 2588 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 102 loss: 0.25464 acc: 0.92513 | v_loss: 0.57819 v_acc: 0.87630 |  iteration: 2589 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 103 loss: 0.30954 acc: 0.91178 | v_loss: 0.57182 v_acc: 0.89062 |  iteration: 2590 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 104 loss: 0.34351 acc: 0.90072 | v_loss: 0.43531 v_acc: 0.90527 |  iteration: 2591 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 105 loss: 0.33962 acc: 0.91146 | v_loss: 1.17705 v_acc: 0.81120 |  iteration: 2592 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 106 loss: 0.30580 acc: 0.91764 | v_loss: 0.40177 v_acc: 0.91309 |  iteration: 2593 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 107 loss: 0.30661 acc: 0.91374 | v_loss: 0.63569 v_acc: 0.87044 |  iteration: 2594 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 108 loss: 0.33434 acc: 0.90072 | v_loss: 0.55304 v_acc: 0.88346 |  iteration: 2595 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 109 loss: 0.30557 acc: 0.91406 | v_loss: 0.46192 v_acc: 0.89876 |  iteration: 2596 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 110 loss: 0.31617 acc: 0.91406 | v_loss: 0.55180 v_acc: 0.87956 |  iteration: 2597 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 111 loss: 0.37014 acc: 0.89128 | v_loss: 0.57938 v_acc: 0.87565 |  iteration: 2598 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 112 loss: 0.31774 acc: 0.90820 | v_loss: 0.46878 v_acc: 0.89681 |  iteration: 2599 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 113 loss: 0.27450 acc: 0.91797 | v_loss: 0.62205 v_acc: 0.87207 |  iteration: 2600 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 114 loss: 0.29954 acc: 0.91927 | v_loss: 0.39247 v_acc: 0.90299 |  iteration: 2601 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 115 loss: 0.25208 acc: 0.92611 | v_loss: 1.03239 v_acc: 0.82064 |  iteration: 2602 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 116 loss: 0.28790 acc: 0.91536 | v_loss: 0.61785 v_acc: 0.87272 |  iteration: 2603 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 117 loss: 0.33194 acc: 0.90072 | v_loss: 0.66882 v_acc: 0.87272 |  iteration: 2604 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 118 loss: 0.32446 acc: 0.91211 | v_loss: 0.43940 v_acc: 0.89974 |  iteration: 2605 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 119 loss: 0.25628 acc: 0.93229 | v_loss: 0.67223 v_acc: 0.85905 |  iteration: 2606 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 120 loss: 0.26643 acc: 0.92448 | v_loss: 0.46326 v_acc: 0.88932 |  iteration: 2607 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 121 loss: 0.32097 acc: 0.90788 | v_loss: 0.48087 v_acc: 0.88965 |  iteration: 2608 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 122 loss: 0.32927 acc: 0.90527 | v_loss: 0.45708 v_acc: 0.89486 |  iteration: 2609 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 123 loss: 0.37030 acc: 0.89779 | v_loss: 0.70282 v_acc: 0.85319 |  iteration: 2610 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 124 loss: 0.31737 acc: 0.90690 | v_loss: 0.49286 v_acc: 0.89616 |  iteration: 2611 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 125 loss: 0.26664 acc: 0.91276 | v_loss: 0.54760 v_acc: 0.87207 |  iteration: 2612 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 126 loss: 0.36281 acc: 0.89974 | v_loss: 0.67225 v_acc: 0.85189 |  iteration: 2613 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 127 loss: 0.29591 acc: 0.91797 | v_loss: 0.45601 v_acc: 0.89128 |  iteration: 2614 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 128 loss: 0.27584 acc: 0.92253 | v_loss: 0.55370 v_acc: 0.86686 |  iteration: 2615 teacher: 1 stage: sketch lr: 0.000457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 129 loss: 0.24509 acc: 0.93359 | v_loss: 0.57378 v_acc: 0.87370 |  iteration: 2616 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 130 loss: 0.29890 acc: 0.91048 | v_loss: 0.75215 v_acc: 0.85352 |  iteration: 2617 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 131 loss: 0.34749 acc: 0.90202 | v_loss: 0.56102 v_acc: 0.89095 |  iteration: 2618 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 132 loss: 0.25698 acc: 0.92871 | v_loss: 0.57828 v_acc: 0.89095 |  iteration: 2619 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 133 loss: 0.27619 acc: 0.92025 | v_loss: 0.65430 v_acc: 0.87630 |  iteration: 2620 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 134 loss: 0.21617 acc: 0.93164 | v_loss: 0.66097 v_acc: 0.85124 |  iteration: 2621 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 135 loss: 0.30063 acc: 0.91960 | v_loss: 0.45886 v_acc: 0.89909 |  iteration: 2622 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 136 loss: 0.32563 acc: 0.90332 | v_loss: 0.76669 v_acc: 0.84993 |  iteration: 2623 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 137 loss: 0.22412 acc: 0.93066 | v_loss: 0.62129 v_acc: 0.87695 |  iteration: 2624 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 138 loss: 0.41501 acc: 0.88477 | v_loss: 0.59508 v_acc: 0.86263 |  iteration: 2625 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 139 loss: 0.20358 acc: 0.94010 | v_loss: 0.55294 v_acc: 0.87109 |  iteration: 2626 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 140 loss: 0.33075 acc: 0.90658 | v_loss: 0.47494 v_acc: 0.89258 |  iteration: 2627 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 141 loss: 0.24720 acc: 0.92806 | v_loss: 0.44719 v_acc: 0.89193 |  iteration: 2628 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 142 loss: 0.32797 acc: 0.90788 | v_loss: 0.53240 v_acc: 0.88053 |  iteration: 2629 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 143 loss: 0.22062 acc: 0.93229 | v_loss: 0.62890 v_acc: 0.85482 |  iteration: 2630 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 144 loss: 0.32503 acc: 0.91276 | v_loss: 0.57173 v_acc: 0.88281 |  iteration: 2631 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 145 loss: 0.20058 acc: 0.94173 | v_loss: 0.63555 v_acc: 0.87826 |  iteration: 2632 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 146 loss: 0.35789 acc: 0.89128 | v_loss: 0.39608 v_acc: 0.89974 |  iteration: 2633 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 147 loss: 0.23838 acc: 0.93034 | v_loss: 0.56731 v_acc: 0.87923 |  iteration: 2634 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 148 loss: 0.31988 acc: 0.91374 | v_loss: 0.49593 v_acc: 0.88118 |  iteration: 2635 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 149 loss: 0.26419 acc: 0.92578 | v_loss: 0.89066 v_acc: 0.82650 |  iteration: 2636 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 150 loss: 0.25661 acc: 0.92285 | v_loss: 0.37475 v_acc: 0.90560 |  iteration: 2637 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 151 loss: 0.26351 acc: 0.91634 | v_loss: 0.32031 v_acc: 0.92513 |  iteration: 2638 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 152 loss: 0.26708 acc: 0.91895 | v_loss: 0.58646 v_acc: 0.87663 |  iteration: 2639 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 153 loss: 0.31148 acc: 0.91276 | v_loss: 0.52556 v_acc: 0.88639 |  iteration: 2640 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 154 loss: 0.27108 acc: 0.92318 | v_loss: 0.68784 v_acc: 0.85286 |  iteration: 2641 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 155 loss: 0.36077 acc: 0.90755 | v_loss: 0.41324 v_acc: 0.90462 |  iteration: 2642 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 156 loss: 0.32843 acc: 0.90853 | v_loss: 0.56111 v_acc: 0.86589 |  iteration: 2643 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 157 loss: 0.27316 acc: 0.92350 | v_loss: 0.61032 v_acc: 0.86589 |  iteration: 2644 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 158 loss: 0.37712 acc: 0.89030 | v_loss: 0.70811 v_acc: 0.84831 |  iteration: 2645 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 159 loss: 0.26583 acc: 0.92318 | v_loss: 0.49719 v_acc: 0.89746 |  iteration: 2646 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 160 loss: 0.31582 acc: 0.90723 | v_loss: 0.43067 v_acc: 0.89844 |  iteration: 2647 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 161 loss: 0.34518 acc: 0.89974 | v_loss: 0.31238 v_acc: 0.92383 |  iteration: 2648 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 162 loss: 0.26779 acc: 0.92611 | v_loss: 0.48263 v_acc: 0.89648 |  iteration: 2649 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 163 loss: 0.31221 acc: 0.91146 | v_loss: 0.53839 v_acc: 0.88607 |  iteration: 2650 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 164 loss: 0.32767 acc: 0.91309 | v_loss: 0.84500 v_acc: 0.85286 |  iteration: 2651 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 165 loss: 0.32046 acc: 0.90918 | v_loss: 0.55336 v_acc: 0.87467 |  iteration: 2652 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 166 loss: 0.32094 acc: 0.90885 | v_loss: 0.67585 v_acc: 0.86491 |  iteration: 2653 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 167 loss: 0.28997 acc: 0.91439 | v_loss: 0.43430 v_acc: 0.89323 |  iteration: 2654 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 168 loss: 0.40888 acc: 0.88574 | v_loss: 0.56441 v_acc: 0.87956 |  iteration: 2655 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 169 loss: 0.37787 acc: 0.89323 | v_loss: 0.79706 v_acc: 0.84180 |  iteration: 2656 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 170 loss: 0.31571 acc: 0.90918 | v_loss: 0.52910 v_acc: 0.88509 |  iteration: 2657 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 171 loss: 0.22656 acc: 0.93815 | v_loss: 0.53332 v_acc: 0.89062 |  iteration: 2658 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 172 loss: 0.31594 acc: 0.91699 | v_loss: 0.52142 v_acc: 0.88184 |  iteration: 2659 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 173 loss: 0.28774 acc: 0.92122 | v_loss: 0.42924 v_acc: 0.90234 |  iteration: 2660 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 174 loss: 0.30507 acc: 0.91471 | v_loss: 0.44832 v_acc: 0.91016 |  iteration: 2661 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 175 loss: 0.26333 acc: 0.92448 | v_loss: 0.59783 v_acc: 0.86751 |  iteration: 2662 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 176 loss: 0.31384 acc: 0.91016 | v_loss: 0.38582 v_acc: 0.91602 |  iteration: 2663 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 177 loss: 0.28248 acc: 0.92122 | v_loss: 0.93363 v_acc: 0.82096 |  iteration: 2664 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 178 loss: 0.41138 acc: 0.88802 | v_loss: 0.64242 v_acc: 0.87044 |  iteration: 2665 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 179 loss: 0.27306 acc: 0.91960 | v_loss: 0.72012 v_acc: 0.85449 |  iteration: 2666 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 180 loss: 0.32004 acc: 0.90495 | v_loss: 0.55069 v_acc: 0.88444 |  iteration: 2667 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 181 loss: 0.30247 acc: 0.91146 | v_loss: 0.50941 v_acc: 0.88444 |  iteration: 2668 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 182 loss: 0.22143 acc: 0.93490 | v_loss: 0.61302 v_acc: 0.88021 |  iteration: 2669 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 183 loss: 0.26706 acc: 0.91862 | v_loss: 0.50484 v_acc: 0.89258 |  iteration: 2670 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 184 loss: 0.31758 acc: 0.90658 | v_loss: 0.51337 v_acc: 0.89030 |  iteration: 2671 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 185 loss: 0.29697 acc: 0.91243 | v_loss: 0.54155 v_acc: 0.89095 |  iteration: 2672 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 186 loss: 0.32006 acc: 0.90560 | v_loss: 0.47145 v_acc: 0.89714 |  iteration: 2673 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 187 loss: 0.41436 acc: 0.88281 | v_loss: 0.35972 v_acc: 0.91960 |  iteration: 2674 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 188 loss: 0.27056 acc: 0.92122 | v_loss: 0.65302 v_acc: 0.86491 |  iteration: 2675 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 189 loss: 0.25601 acc: 0.91895 | v_loss: 0.59058 v_acc: 0.86882 |  iteration: 2676 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 190 loss: 0.31909 acc: 0.90755 | v_loss: 0.61007 v_acc: 0.86556 |  iteration: 2677 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 191 loss: 0.27656 acc: 0.92253 | v_loss: 0.88599 v_acc: 0.84212 |  iteration: 2678 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 192 loss: 0.31091 acc: 0.91276 | v_loss: 0.47067 v_acc: 0.90625 |  iteration: 2679 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 193 loss: 0.29812 acc: 0.90560 | v_loss: 0.60240 v_acc: 0.87337 |  iteration: 2680 teacher: 0 stage: sketch lr: 0.000468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 194 loss: 0.27520 acc: 0.92220 | v_loss: 0.53691 v_acc: 0.88542 |  iteration: 2681 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 195 loss: 0.43378 acc: 0.87305 | v_loss: 0.41731 v_acc: 0.90202 |  iteration: 2682 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 196 loss: 0.25468 acc: 0.92220 | v_loss: 1.12332 v_acc: 0.81087 |  iteration: 2683 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 197 loss: 0.25910 acc: 0.92546 | v_loss: 0.37500 v_acc: 0.92057 |  iteration: 2684 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 198 loss: 0.30682 acc: 0.91341 | v_loss: 0.61005 v_acc: 0.87923 |  iteration: 2685 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 199 loss: 0.32468 acc: 0.90853 | v_loss: 0.51104 v_acc: 0.89160 |  iteration: 2686 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 200 loss: 0.28932 acc: 0.92253 | v_loss: 0.42784 v_acc: 0.90104 |  iteration: 2687 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 201 loss: 0.28954 acc: 0.91146 | v_loss: 0.53150 v_acc: 0.88379 |  iteration: 2688 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 202 loss: 0.29276 acc: 0.91374 | v_loss: 0.58921 v_acc: 0.87533 |  iteration: 2689 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 203 loss: 0.27850 acc: 0.91927 | v_loss: 0.45322 v_acc: 0.89355 |  iteration: 2690 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 204 loss: 0.34204 acc: 0.89160 | v_loss: 0.66276 v_acc: 0.85710 |  iteration: 2691 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 205 loss: 0.29893 acc: 0.91667 | v_loss: 0.38315 v_acc: 0.90658 |  iteration: 2692 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 206 loss: 0.33626 acc: 0.90527 | v_loss: 1.01060 v_acc: 0.81868 |  iteration: 2693 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 207 loss: 0.28381 acc: 0.91667 | v_loss: 0.56646 v_acc: 0.88672 |  iteration: 2694 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 208 loss: 0.37702 acc: 0.89941 | v_loss: 0.67648 v_acc: 0.87565 |  iteration: 2695 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 209 loss: 0.20032 acc: 0.93848 | v_loss: 0.43779 v_acc: 0.89811 |  iteration: 2696 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 210 loss: 0.32752 acc: 0.90560 | v_loss: 0.67781 v_acc: 0.86230 |  iteration: 2697 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 211 loss: 0.25841 acc: 0.92871 | v_loss: 0.43562 v_acc: 0.89876 |  iteration: 2698 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 212 loss: 0.35094 acc: 0.90625 | v_loss: 0.48806 v_acc: 0.88411 |  iteration: 2699 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 213 loss: 0.32361 acc: 0.89811 | v_loss: 0.45416 v_acc: 0.88997 |  iteration: 2700 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 214 loss: 0.37298 acc: 0.89128 | v_loss: 0.71927 v_acc: 0.86263 |  iteration: 2701 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 215 loss: 0.25002 acc: 0.92480 | v_loss: 0.52449 v_acc: 0.89714 |  iteration: 2702 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 216 loss: 0.28905 acc: 0.91895 | v_loss: 0.55793 v_acc: 0.87695 |  iteration: 2703 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 217 loss: 0.39122 acc: 0.89616 | v_loss: 0.69793 v_acc: 0.85189 |  iteration: 2704 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 218 loss: 0.29971 acc: 0.91602 | v_loss: 0.47253 v_acc: 0.89193 |  iteration: 2705 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 219 loss: 0.32196 acc: 0.90951 | v_loss: 0.53403 v_acc: 0.86621 |  iteration: 2706 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 220 loss: 0.27643 acc: 0.91471 | v_loss: 0.52430 v_acc: 0.87858 |  iteration: 2707 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 221 loss: 0.29595 acc: 0.92448 | v_loss: 0.76326 v_acc: 0.84831 |  iteration: 2708 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 222 loss: 0.29632 acc: 0.92057 | v_loss: 0.55274 v_acc: 0.88672 |  iteration: 2709 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 223 loss: 0.28500 acc: 0.91862 | v_loss: 0.57955 v_acc: 0.88184 |  iteration: 2710 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 224 loss: 0.34496 acc: 0.89941 | v_loss: 0.63761 v_acc: 0.87956 |  iteration: 2711 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 225 loss: 0.29323 acc: 0.91764 | v_loss: 0.61450 v_acc: 0.85938 |  iteration: 2712 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 226 loss: 0.33707 acc: 0.90690 | v_loss: 0.45283 v_acc: 0.89811 |  iteration: 2713 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 227 loss: 0.33607 acc: 0.91341 | v_loss: 0.78379 v_acc: 0.84831 |  iteration: 2714 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 228 loss: 0.22827 acc: 0.93034 | v_loss: 0.61504 v_acc: 0.87630 |  iteration: 2715 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 229 loss: 0.32358 acc: 0.90918 | v_loss: 0.58332 v_acc: 0.87500 |  iteration: 2716 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 230 loss: 0.33750 acc: 0.90527 | v_loss: 0.54928 v_acc: 0.88021 |  iteration: 2717 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 231 loss: 0.45269 acc: 0.88021 | v_loss: 0.44725 v_acc: 0.90104 |  iteration: 2718 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 232 loss: 0.28567 acc: 0.92643 | v_loss: 0.47683 v_acc: 0.89779 |  iteration: 2719 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 233 loss: 0.35294 acc: 0.90007 | v_loss: 0.54528 v_acc: 0.88542 |  iteration: 2720 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 234 loss: 0.28429 acc: 0.91927 | v_loss: 0.65713 v_acc: 0.85091 |  iteration: 2721 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 235 loss: 0.31187 acc: 0.90951 | v_loss: 0.63178 v_acc: 0.88346 |  iteration: 2722 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 236 loss: 0.21489 acc: 0.93620 | v_loss: 0.65882 v_acc: 0.88411 |  iteration: 2723 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 237 loss: 0.35503 acc: 0.89974 | v_loss: 0.39139 v_acc: 0.90983 |  iteration: 2724 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 238 loss: 0.33087 acc: 0.89453 | v_loss: 0.53621 v_acc: 0.88477 |  iteration: 2725 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 239 loss: 0.32403 acc: 0.91504 | v_loss: 0.50149 v_acc: 0.88965 |  iteration: 2726 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 240 loss: 0.29519 acc: 0.91471 | v_loss: 0.96424 v_acc: 0.82129 |  iteration: 2727 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 241 loss: 0.33743 acc: 0.89616 | v_loss: 0.35889 v_acc: 0.91309 |  iteration: 2728 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 242 loss: 0.26431 acc: 0.92448 | v_loss: 0.34453 v_acc: 0.92480 |  iteration: 2729 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 243 loss: 0.30724 acc: 0.91016 | v_loss: 0.58557 v_acc: 0.88867 |  iteration: 2730 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 244 loss: 0.27259 acc: 0.91764 | v_loss: 0.59517 v_acc: 0.87695 |  iteration: 2731 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 245 loss: 0.38607 acc: 0.89128 | v_loss: 0.71580 v_acc: 0.85319 |  iteration: 2732 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 246 loss: 0.48009 acc: 0.87598 | v_loss: 0.44978 v_acc: 0.90462 |  iteration: 2733 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 247 loss: 0.30953 acc: 0.90820 | v_loss: 0.53744 v_acc: 0.86784 |  iteration: 2734 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 248 loss: 0.40525 acc: 0.89486 | v_loss: 0.60798 v_acc: 0.86751 |  iteration: 2735 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 249 loss: 0.34176 acc: 0.90462 | v_loss: 0.64898 v_acc: 0.84798 |  iteration: 2736 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 250 loss: 0.26242 acc: 0.92904 | v_loss: 0.49019 v_acc: 0.89323 |  iteration: 2737 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 251 loss: 0.39126 acc: 0.89128 | v_loss: 0.40686 v_acc: 0.90332 |  iteration: 2738 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 252 loss: 0.35173 acc: 0.90137 | v_loss: 0.33595 v_acc: 0.91081 |  iteration: 2739 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 253 loss: 0.40965 acc: 0.88770 | v_loss: 0.44919 v_acc: 0.90365 |  iteration: 2740 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 254 loss: 0.23701 acc: 0.92806 | v_loss: 0.49097 v_acc: 0.88704 |  iteration: 2741 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 255 loss: 0.26919 acc: 0.91862 | v_loss: 0.85301 v_acc: 0.84961 |  iteration: 2742 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 256 loss: 0.34563 acc: 0.90169 | v_loss: 0.56068 v_acc: 0.87402 |  iteration: 2743 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 257 loss: 0.36393 acc: 0.89486 | v_loss: 0.67119 v_acc: 0.86328 |  iteration: 2744 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 258 loss: 0.34001 acc: 0.90332 | v_loss: 0.40443 v_acc: 0.90202 |  iteration: 2745 teacher: 0 stage: sketch lr: 0.000480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 259 loss: 0.26611 acc: 0.92318 | v_loss: 0.55477 v_acc: 0.87500 |  iteration: 2746 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 260 loss: 0.29466 acc: 0.91178 | v_loss: 0.85863 v_acc: 0.83366 |  iteration: 2747 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 261 loss: 0.29559 acc: 0.91341 | v_loss: 0.53876 v_acc: 0.89128 |  iteration: 2748 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 262 loss: 0.25528 acc: 0.92415 | v_loss: 0.52611 v_acc: 0.89062 |  iteration: 2749 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 263 loss: 0.33451 acc: 0.90592 | v_loss: 0.53029 v_acc: 0.88216 |  iteration: 2750 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 264 loss: 0.32715 acc: 0.91243 | v_loss: 0.47313 v_acc: 0.89193 |  iteration: 2751 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 265 loss: 0.29653 acc: 0.91699 | v_loss: 0.49693 v_acc: 0.89193 |  iteration: 2752 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 266 loss: 0.25531 acc: 0.92448 | v_loss: 0.65335 v_acc: 0.86133 |  iteration: 2753 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 267 loss: 0.28593 acc: 0.91439 | v_loss: 0.37799 v_acc: 0.91471 |  iteration: 2754 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 268 loss: 0.30493 acc: 0.90853 | v_loss: 1.01214 v_acc: 0.81868 |  iteration: 2755 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 269 loss: 0.29873 acc: 0.91439 | v_loss: 0.64919 v_acc: 0.87500 |  iteration: 2756 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 270 loss: 0.30723 acc: 0.91439 | v_loss: 0.77920 v_acc: 0.84538 |  iteration: 2757 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 271 loss: 0.31337 acc: 0.91634 | v_loss: 0.55683 v_acc: 0.88509 |  iteration: 2758 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 272 loss: 0.26467 acc: 0.92871 | v_loss: 0.55486 v_acc: 0.88737 |  iteration: 2759 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 273 loss: 0.30218 acc: 0.90885 | v_loss: 0.63702 v_acc: 0.88184 |  iteration: 2760 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 274 loss: 0.33250 acc: 0.90592 | v_loss: 0.55847 v_acc: 0.88867 |  iteration: 2761 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 275 loss: 0.35161 acc: 0.90072 | v_loss: 0.53172 v_acc: 0.89290 |  iteration: 2762 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 276 loss: 0.31273 acc: 0.90918 | v_loss: 0.53444 v_acc: 0.89974 |  iteration: 2763 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 277 loss: 0.41465 acc: 0.88997 | v_loss: 0.50123 v_acc: 0.88314 |  iteration: 2764 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 278 loss: 0.31878 acc: 0.91081 | v_loss: 0.39337 v_acc: 0.91536 |  iteration: 2765 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 279 loss: 0.31416 acc: 0.91699 | v_loss: 0.61961 v_acc: 0.86393 |  iteration: 2766 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 280 loss: 0.36692 acc: 0.89486 | v_loss: 0.60751 v_acc: 0.85645 |  iteration: 2767 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 281 loss: 0.25961 acc: 0.92546 | v_loss: 0.65895 v_acc: 0.86426 |  iteration: 2768 teacher: 0 stage: sketch lr: 0.000484\n",
      "batch 282 loss: 0.40224 acc: 0.88509 | v_loss: 0.85337 v_acc: 0.83561 |  iteration: 2769 teacher: 0 stage: sketch lr: 0.000484\n",
      "batch 283 loss: 0.28580 acc: 0.91732 | v_loss: 0.44741 v_acc: 0.90788 |  iteration: 2770 teacher: 0 stage: sketch lr: 0.000484\n",
      "batch 284 loss: 0.31774 acc: 0.91471 | v_loss: 0.60931 v_acc: 0.87337 |  iteration: 2771 teacher: 1 stage: sketch lr: 0.000484\n",
      "batch 285 loss: 0.31290 acc: 0.92057 | v_loss: 0.51938 v_acc: 0.89193 |  iteration: 2772 teacher: 0 stage: sketch lr: 0.000484\n",
      "batch 286 loss: 0.31200 acc: 0.90951 | v_loss: 0.40175 v_acc: 0.90397 |  iteration: 2773 teacher: 0 stage: sketch lr: 0.000484\n",
      "batch 287 loss: 0.41563 acc: 0.89486 | v_loss: 1.10805 v_acc: 0.81217 |  iteration: 2774 teacher: 1 stage: sketch lr: 0.000485\n",
      "batch 288 loss: 0.44127 acc: 0.88281 | v_loss: 0.39762 v_acc: 0.91309 |  iteration: 2775 teacher: 1 stage: sketch lr: 0.000485\n",
      "batch 289 loss: 0.24568 acc: 0.93197 | v_loss: 0.61637 v_acc: 0.87923 |  iteration: 2776 teacher: 0 stage: sketch lr: 0.000485\n",
      "batch 290 loss: 0.30999 acc: 0.91862 | v_loss: 0.53710 v_acc: 0.89876 |  iteration: 2777 teacher: 0 stage: sketch lr: 0.000485\n",
      "batch 291 loss: 0.25733 acc: 0.92708 | v_loss: 0.42988 v_acc: 0.91016 |  iteration: 2778 teacher: 1 stage: sketch lr: 0.000485\n",
      "batch 292 loss: 0.26468 acc: 0.92643 | v_loss: 0.54652 v_acc: 0.88672 |  iteration: 2779 teacher: 1 stage: sketch lr: 0.000485\n",
      "batch 293 loss: 0.24011 acc: 0.93392 | v_loss: 0.68976 v_acc: 0.85775 |  iteration: 2780 teacher: 1 stage: sketch lr: 0.000486\n",
      "batch 294 loss: 0.26353 acc: 0.92253 | v_loss: 0.46869 v_acc: 0.89844 |  iteration: 2781 teacher: 0 stage: sketch lr: 0.000486\n",
      "batch 295 loss: 0.33104 acc: 0.90658 | v_loss: 0.64115 v_acc: 0.87044 |  iteration: 2782 teacher: 1 stage: sketch lr: 0.000486\n",
      "batch 296 loss: 0.28540 acc: 0.91406 | v_loss: 0.42502 v_acc: 0.90202 |  iteration: 2783 teacher: 0 stage: sketch lr: 0.000486\n",
      "batch 297 loss: 0.34671 acc: 0.90462 | v_loss: 0.98901 v_acc: 0.81901 |  iteration: 2784 teacher: 1 stage: sketch lr: 0.000486\n",
      "batch 298 loss: 0.26655 acc: 0.92448 | v_loss: 0.55776 v_acc: 0.88477 |  iteration: 2785 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 299 loss: 0.27430 acc: 0.91406 | v_loss: 0.65551 v_acc: 0.87109 |  iteration: 2786 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 300 loss: 0.39442 acc: 0.88672 | v_loss: 0.42718 v_acc: 0.89876 |  iteration: 2787 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 301 loss: 0.36556 acc: 0.90365 | v_loss: 0.65165 v_acc: 0.86165 |  iteration: 2788 teacher: 1 stage: sketch lr: 0.000487\n",
      "batch 302 loss: 0.36165 acc: 0.89616 | v_loss: 0.48624 v_acc: 0.89128 |  iteration: 2789 teacher: 1 stage: sketch lr: 0.000487\n",
      "batch 303 loss: 0.35872 acc: 0.89551 | v_loss: 0.48642 v_acc: 0.88184 |  iteration: 2790 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 304 loss: 0.20100 acc: 0.94531 | v_loss: 0.45409 v_acc: 0.88770 |  iteration: 2791 teacher: 1 stage: sketch lr: 0.000488\n",
      "batch 305 loss: 0.33084 acc: 0.90527 | v_loss: 0.72455 v_acc: 0.85449 |  iteration: 2792 teacher: 1 stage: sketch lr: 0.000488\n",
      "batch 306 loss: 0.37814 acc: 0.89941 | v_loss: 0.49122 v_acc: 0.89909 |  iteration: 2793 teacher: 1 stage: sketch lr: 0.000488\n",
      "batch 307 loss: 0.35346 acc: 0.90202 | v_loss: 0.57357 v_acc: 0.87598 |  iteration: 2794 teacher: 1 stage: sketch lr: 0.000488\n",
      "batch 308 loss: 0.24531 acc: 0.92806 | v_loss: 0.69471 v_acc: 0.84505 |  iteration: 2795 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 309 loss: 0.26974 acc: 0.92415 | v_loss: 0.51796 v_acc: 0.88997 |  iteration: 2796 teacher: 1 stage: sketch lr: 0.000488\n",
      "batch 310 loss: 0.25382 acc: 0.93229 | v_loss: 0.53086 v_acc: 0.87207 |  iteration: 2797 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 311 loss: 0.29372 acc: 0.91439 | v_loss: 0.57943 v_acc: 0.87240 |  iteration: 2798 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 312 loss: 0.27842 acc: 0.92676 | v_loss: 0.83071 v_acc: 0.84993 |  iteration: 2799 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 313 loss: 0.24285 acc: 0.93034 | v_loss: 0.60174 v_acc: 0.88477 |  iteration: 2800 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 314 loss: 0.37709 acc: 0.90039 | v_loss: 0.59609 v_acc: 0.88184 |  iteration: 2801 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 315 loss: 0.34393 acc: 0.90592 | v_loss: 0.72601 v_acc: 0.87240 |  iteration: 2802 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 316 loss: 0.28042 acc: 0.92383 | v_loss: 0.59705 v_acc: 0.86003 |  iteration: 2803 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 317 loss: 0.39668 acc: 0.89225 | v_loss: 0.45969 v_acc: 0.90169 |  iteration: 2804 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 318 loss: 0.26981 acc: 0.91895 | v_loss: 0.79495 v_acc: 0.83757 |  iteration: 2805 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 319 loss: 0.37912 acc: 0.88672 | v_loss: 0.62673 v_acc: 0.87793 |  iteration: 2806 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 320 loss: 0.28639 acc: 0.92090 | v_loss: 0.59198 v_acc: 0.86882 |  iteration: 2807 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 321 loss: 0.37789 acc: 0.89876 | v_loss: 0.58897 v_acc: 0.87305 |  iteration: 2808 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 322 loss: 0.36019 acc: 0.90560 | v_loss: 0.46624 v_acc: 0.89876 |  iteration: 2809 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 323 loss: 0.24912 acc: 0.92155 | v_loss: 0.47097 v_acc: 0.89453 |  iteration: 2810 teacher: 1 stage: sketch lr: 0.000491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 324 loss: 0.21519 acc: 0.93717 | v_loss: 0.53904 v_acc: 0.88053 |  iteration: 2811 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 325 loss: 0.32310 acc: 0.90788 | v_loss: 0.60114 v_acc: 0.86068 |  iteration: 2812 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 326 loss: 0.29543 acc: 0.92220 | v_loss: 0.59581 v_acc: 0.88053 |  iteration: 2813 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 327 loss: 0.28964 acc: 0.91178 | v_loss: 0.62900 v_acc: 0.87109 |  iteration: 2814 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 328 loss: 0.32886 acc: 0.90592 | v_loss: 0.39670 v_acc: 0.90853 |  iteration: 2815 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 329 loss: 0.25813 acc: 0.92480 | v_loss: 0.61433 v_acc: 0.87826 |  iteration: 2816 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 330 loss: 0.32123 acc: 0.90885 | v_loss: 0.53155 v_acc: 0.87695 |  iteration: 2817 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 331 loss: 0.34690 acc: 0.90072 | v_loss: 0.87500 v_acc: 0.83138 |  iteration: 2818 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 332 loss: 0.29847 acc: 0.91081 | v_loss: 0.38708 v_acc: 0.90625 |  iteration: 2819 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 333 loss: 0.32003 acc: 0.91113 | v_loss: 0.32556 v_acc: 0.92253 |  iteration: 2820 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 334 loss: 0.31665 acc: 0.90853 | v_loss: 0.58358 v_acc: 0.88053 |  iteration: 2821 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 335 loss: 0.28327 acc: 0.91829 | v_loss: 0.61719 v_acc: 0.88118 |  iteration: 2822 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 336 loss: 0.34350 acc: 0.90397 | v_loss: 0.68448 v_acc: 0.86165 |  iteration: 2823 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 337 loss: 0.30122 acc: 0.90951 | v_loss: 0.46733 v_acc: 0.89746 |  iteration: 2824 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 338 loss: 0.29896 acc: 0.91504 | v_loss: 0.51618 v_acc: 0.87728 |  iteration: 2825 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 339 loss: 0.32597 acc: 0.91178 | v_loss: 0.62260 v_acc: 0.86686 |  iteration: 2826 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 340 loss: 0.30728 acc: 0.91439 | v_loss: 0.68533 v_acc: 0.84408 |  iteration: 2827 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 341 loss: 0.27442 acc: 0.92025 | v_loss: 0.50691 v_acc: 0.89128 |  iteration: 2828 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 342 loss: 0.30076 acc: 0.91178 | v_loss: 0.38859 v_acc: 0.90723 |  iteration: 2829 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 343 loss: 0.33659 acc: 0.90853 | v_loss: 0.30186 v_acc: 0.91862 |  iteration: 2830 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 344 loss: 0.34361 acc: 0.90007 | v_loss: 0.48002 v_acc: 0.89095 |  iteration: 2831 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 345 loss: 0.36743 acc: 0.89714 | v_loss: 0.46052 v_acc: 0.88900 |  iteration: 2832 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 346 loss: 0.31277 acc: 0.91081 | v_loss: 0.80735 v_acc: 0.84701 |  iteration: 2833 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 347 loss: 0.36154 acc: 0.89779 | v_loss: 0.55652 v_acc: 0.87402 |  iteration: 2834 teacher: 1 stage: sketch lr: 0.000495\n",
      "batch 348 loss: 0.37918 acc: 0.87923 | v_loss: 0.67666 v_acc: 0.86523 |  iteration: 2835 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 349 loss: 0.25697 acc: 0.92285 | v_loss: 0.43069 v_acc: 0.89811 |  iteration: 2836 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 350 loss: 0.28909 acc: 0.91667 | v_loss: 0.57261 v_acc: 0.88118 |  iteration: 2837 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 351 loss: 0.33010 acc: 0.90918 | v_loss: 0.83754 v_acc: 0.84310 |  iteration: 2838 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 352 loss: 0.24485 acc: 0.92806 | v_loss: 0.60553 v_acc: 0.88411 |  iteration: 2839 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 353 loss: 0.30624 acc: 0.91276 | v_loss: 0.55771 v_acc: 0.88346 |  iteration: 2840 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 354 loss: 0.36191 acc: 0.89844 | v_loss: 0.50921 v_acc: 0.88379 |  iteration: 2841 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 355 loss: 0.32236 acc: 0.90527 | v_loss: 0.41784 v_acc: 0.90495 |  iteration: 2842 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 356 loss: 0.30340 acc: 0.91016 | v_loss: 0.52581 v_acc: 0.88997 |  iteration: 2843 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 357 loss: 0.35649 acc: 0.89193 | v_loss: 0.60187 v_acc: 0.86426 |  iteration: 2844 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 358 loss: 0.25822 acc: 0.92871 | v_loss: 0.40639 v_acc: 0.91992 |  iteration: 2845 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 359 loss: 0.39161 acc: 0.89323 | v_loss: 0.96567 v_acc: 0.82878 |  iteration: 2846 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 360 loss: 0.28700 acc: 0.91341 | v_loss: 0.62803 v_acc: 0.87305 |  iteration: 2847 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 361 loss: 0.28303 acc: 0.92350 | v_loss: 0.72601 v_acc: 0.86296 |  iteration: 2848 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 362 loss: 0.34738 acc: 0.90658 | v_loss: 0.52175 v_acc: 0.88867 |  iteration: 2849 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 363 loss: 0.26915 acc: 0.92936 | v_loss: 0.52270 v_acc: 0.88542 |  iteration: 2850 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 364 loss: 0.38628 acc: 0.88835 | v_loss: 0.63576 v_acc: 0.87598 |  iteration: 2851 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 365 loss: 0.39178 acc: 0.88932 | v_loss: 0.51835 v_acc: 0.88737 |  iteration: 2852 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 366 loss: 0.29313 acc: 0.91667 | v_loss: 0.50277 v_acc: 0.89030 |  iteration: 2853 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 367 loss: 0.27133 acc: 0.92253 | v_loss: 0.46869 v_acc: 0.90299 |  iteration: 2854 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 368 loss: 0.34537 acc: 0.89876 | v_loss: 0.48054 v_acc: 0.89388 |  iteration: 2855 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 369 loss: 0.30632 acc: 0.90983 | v_loss: 0.35711 v_acc: 0.92057 |  iteration: 2856 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 370 loss: 0.27489 acc: 0.92480 | v_loss: 0.63529 v_acc: 0.86263 |  iteration: 2857 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 371 loss: 0.31893 acc: 0.90853 | v_loss: 0.56932 v_acc: 0.86230 |  iteration: 2858 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 372 loss: 0.31064 acc: 0.91732 | v_loss: 0.63938 v_acc: 0.86100 |  iteration: 2859 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 373 loss: 0.27406 acc: 0.92025 | v_loss: 0.83062 v_acc: 0.84310 |  iteration: 2860 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 374 loss: 0.30412 acc: 0.91048 | v_loss: 0.46818 v_acc: 0.89746 |  iteration: 2861 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 375 loss: 0.28669 acc: 0.91504 | v_loss: 0.60376 v_acc: 0.87207 |  iteration: 2862 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 376 loss: 0.35071 acc: 0.89551 | v_loss: 0.55963 v_acc: 0.88965 |  iteration: 2863 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 377 loss: 0.21654 acc: 0.93555 | v_loss: 0.42832 v_acc: 0.90299 |  iteration: 2864 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 378 loss: 0.39387 acc: 0.88932 | v_loss: 1.15500 v_acc: 0.80208 |  iteration: 2865 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 379 loss: 0.24746 acc: 0.93848 | v_loss: 0.35945 v_acc: 0.91309 |  iteration: 2866 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 380 loss: 0.36798 acc: 0.89225 | v_loss: 0.63748 v_acc: 0.86849 |  iteration: 2867 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 381 loss: 0.37039 acc: 0.89453 | v_loss: 0.56141 v_acc: 0.88932 |  iteration: 2868 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 382 loss: 0.31594 acc: 0.91146 | v_loss: 0.45085 v_acc: 0.89746 |  iteration: 2869 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 383 loss: 0.32663 acc: 0.90951 | v_loss: 0.54255 v_acc: 0.87956 |  iteration: 2870 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 384 loss: 0.24325 acc: 0.93034 | v_loss: 0.59483 v_acc: 0.87793 |  iteration: 2871 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 385 loss: 0.39900 acc: 0.89486 | v_loss: 0.44842 v_acc: 0.90527 |  iteration: 2872 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 386 loss: 0.27638 acc: 0.91667 | v_loss: 0.64443 v_acc: 0.87500 |  iteration: 2873 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 387 loss: 0.26175 acc: 0.92122 | v_loss: 0.40096 v_acc: 0.90299 |  iteration: 2874 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 388 loss: 0.27656 acc: 0.92253 | v_loss: 1.02994 v_acc: 0.82064 |  iteration: 2875 teacher: 0 stage: sketch lr: 0.000502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 389 loss: 0.37825 acc: 0.89518 | v_loss: 0.59387 v_acc: 0.87500 |  iteration: 2876 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 390 loss: 0.32508 acc: 0.90755 | v_loss: 0.66570 v_acc: 0.86556 |  iteration: 2877 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 391 loss: 0.37845 acc: 0.90462 | v_loss: 0.43218 v_acc: 0.89323 |  iteration: 2878 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 392 loss: 0.22198 acc: 0.93457 | v_loss: 0.67209 v_acc: 0.85449 |  iteration: 2879 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 393 loss: 0.29924 acc: 0.91341 | v_loss: 0.47218 v_acc: 0.88086 |  iteration: 2880 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 394 loss: 0.33955 acc: 0.89876 | v_loss: 0.48930 v_acc: 0.88802 |  iteration: 2881 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 395 loss: 0.28752 acc: 0.92122 | v_loss: 0.46670 v_acc: 0.88574 |  iteration: 2882 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 396 loss: 0.30668 acc: 0.90397 | v_loss: 0.72466 v_acc: 0.84961 |  iteration: 2883 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 397 loss: 0.39165 acc: 0.88900 | v_loss: 0.50128 v_acc: 0.89128 |  iteration: 2884 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 398 loss: 0.33222 acc: 0.90983 | v_loss: 0.52841 v_acc: 0.87760 |  iteration: 2885 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 399 loss: 0.29965 acc: 0.92090 | v_loss: 0.66874 v_acc: 0.84733 |  iteration: 2886 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 400 loss: 0.22034 acc: 0.93392 | v_loss: 0.50435 v_acc: 0.88379 |  iteration: 2887 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 401 loss: 0.30093 acc: 0.91602 | v_loss: 0.55657 v_acc: 0.86035 |  iteration: 2888 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 402 loss: 0.34046 acc: 0.90560 | v_loss: 0.56776 v_acc: 0.86230 |  iteration: 2889 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 403 loss: 0.38045 acc: 0.88672 | v_loss: 0.77785 v_acc: 0.84798 |  iteration: 2890 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 404 loss: 0.31064 acc: 0.91374 | v_loss: 0.58719 v_acc: 0.89095 |  iteration: 2891 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 405 loss: 0.31914 acc: 0.91829 | v_loss: 0.60195 v_acc: 0.88932 |  iteration: 2892 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 406 loss: 0.37941 acc: 0.89844 | v_loss: 0.66908 v_acc: 0.88151 |  iteration: 2893 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 407 loss: 0.25557 acc: 0.93099 | v_loss: 0.64319 v_acc: 0.84928 |  iteration: 2894 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 408 loss: 0.25380 acc: 0.92415 | v_loss: 0.41343 v_acc: 0.89518 |  iteration: 2895 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 409 loss: 0.38449 acc: 0.88477 | v_loss: 0.81588 v_acc: 0.83203 |  iteration: 2896 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 410 loss: 0.27424 acc: 0.91309 | v_loss: 0.59895 v_acc: 0.86426 |  iteration: 2897 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 411 loss: 0.24580 acc: 0.92513 | v_loss: 0.54863 v_acc: 0.87533 |  iteration: 2898 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 412 loss: 0.36510 acc: 0.89648 | v_loss: 0.54506 v_acc: 0.87533 |  iteration: 2899 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 413 loss: 0.34550 acc: 0.89909 | v_loss: 0.47216 v_acc: 0.89518 |  iteration: 2900 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 414 loss: 0.27449 acc: 0.91927 | v_loss: 0.51086 v_acc: 0.89160 |  iteration: 2901 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 415 loss: 0.32310 acc: 0.92057 | v_loss: 0.53650 v_acc: 0.88737 |  iteration: 2902 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 416 loss: 0.28943 acc: 0.91341 | v_loss: 0.63048 v_acc: 0.84993 |  iteration: 2903 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 417 loss: 0.30952 acc: 0.91146 | v_loss: 0.64196 v_acc: 0.88249 |  iteration: 2904 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 418 loss: 0.40577 acc: 0.89421 | v_loss: 0.64664 v_acc: 0.87598 |  iteration: 2905 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 419 loss: 0.33122 acc: 0.90853 | v_loss: 0.38310 v_acc: 0.90527 |  iteration: 2906 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 420 loss: 0.41271 acc: 0.89225 | v_loss: 0.60804 v_acc: 0.87728 |  iteration: 2907 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 421 loss: 0.37546 acc: 0.89974 | v_loss: 0.52103 v_acc: 0.87663 |  iteration: 2908 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 422 loss: 0.35933 acc: 0.90430 | v_loss: 0.86794 v_acc: 0.81706 |  iteration: 2909 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 423 loss: 0.28337 acc: 0.91276 | v_loss: 0.38447 v_acc: 0.90202 |  iteration: 2910 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 424 loss: 0.36107 acc: 0.89062 | v_loss: 0.31283 v_acc: 0.92773 |  iteration: 2911 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 425 loss: 0.34750 acc: 0.90430 | v_loss: 0.59887 v_acc: 0.87826 |  iteration: 2912 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 426 loss: 0.29662 acc: 0.91732 | v_loss: 0.62169 v_acc: 0.87826 |  iteration: 2913 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 427 loss: 0.22921 acc: 0.93392 | v_loss: 0.66683 v_acc: 0.85970 |  iteration: 2914 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 428 loss: 0.34776 acc: 0.90462 | v_loss: 0.48400 v_acc: 0.89421 |  iteration: 2915 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 429 loss: 0.32127 acc: 0.90853 | v_loss: 0.56947 v_acc: 0.87337 |  iteration: 2916 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 430 loss: 0.42040 acc: 0.88672 | v_loss: 0.61776 v_acc: 0.86589 |  iteration: 2917 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 431 loss: 0.34575 acc: 0.89746 | v_loss: 0.65363 v_acc: 0.84408 |  iteration: 2918 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 432 loss: 0.33276 acc: 0.90365 | v_loss: 0.52587 v_acc: 0.88411 |  iteration: 2919 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 433 loss: 0.32430 acc: 0.90788 | v_loss: 0.40176 v_acc: 0.90234 |  iteration: 2920 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 434 loss: 0.30778 acc: 0.91602 | v_loss: 0.33886 v_acc: 0.91243 |  iteration: 2921 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 435 loss: 0.32428 acc: 0.91602 | v_loss: 0.50594 v_acc: 0.89648 |  iteration: 2922 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 436 loss: 0.31939 acc: 0.90885 | v_loss: 0.52448 v_acc: 0.87793 |  iteration: 2923 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 437 loss: 0.26084 acc: 0.92578 | v_loss: 0.80173 v_acc: 0.85938 |  iteration: 2924 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 438 loss: 0.27562 acc: 0.92253 | v_loss: 0.61275 v_acc: 0.87240 |  iteration: 2925 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 439 loss: 0.23538 acc: 0.93294 | v_loss: 0.68783 v_acc: 0.87370 |  iteration: 2926 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 440 loss: 0.25897 acc: 0.92513 | v_loss: 0.44916 v_acc: 0.89974 |  iteration: 2927 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 441 loss: 0.32130 acc: 0.90820 | v_loss: 0.57974 v_acc: 0.88184 |  iteration: 2928 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 442 loss: 0.33930 acc: 0.91048 | v_loss: 0.82505 v_acc: 0.84863 |  iteration: 2929 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 443 loss: 0.25479 acc: 0.93034 | v_loss: 0.52142 v_acc: 0.88639 |  iteration: 2930 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 444 loss: 0.27145 acc: 0.91895 | v_loss: 0.53460 v_acc: 0.88151 |  iteration: 2931 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 445 loss: 0.26474 acc: 0.92025 | v_loss: 0.50544 v_acc: 0.87728 |  iteration: 2932 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 446 loss: 0.28507 acc: 0.91732 | v_loss: 0.42747 v_acc: 0.90397 |  iteration: 2933 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 447 loss: 0.21745 acc: 0.93717 | v_loss: 0.46873 v_acc: 0.90169 |  iteration: 2934 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 448 loss: 0.28699 acc: 0.91862 | v_loss: 0.63209 v_acc: 0.85612 |  iteration: 2935 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 449 loss: 0.36473 acc: 0.89388 | v_loss: 0.36516 v_acc: 0.92188 |  iteration: 2936 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 450 loss: 0.32780 acc: 0.90820 | v_loss: 0.93154 v_acc: 0.83887 |  iteration: 2937 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 451 loss: 0.34638 acc: 0.90592 | v_loss: 0.62039 v_acc: 0.88281 |  iteration: 2938 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 452 loss: 0.30119 acc: 0.91764 | v_loss: 0.66341 v_acc: 0.86947 |  iteration: 2939 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 453 loss: 0.32312 acc: 0.90397 | v_loss: 0.52210 v_acc: 0.89030 |  iteration: 2940 teacher: 0 stage: sketch lr: 0.000514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 454 loss: 0.28341 acc: 0.92383 | v_loss: 0.49331 v_acc: 0.89095 |  iteration: 2941 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 455 loss: 0.26874 acc: 0.92318 | v_loss: 0.61262 v_acc: 0.88053 |  iteration: 2942 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 456 loss: 0.21251 acc: 0.93587 | v_loss: 0.51760 v_acc: 0.88737 |  iteration: 2943 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 457 loss: 0.27181 acc: 0.91797 | v_loss: 0.50042 v_acc: 0.89258 |  iteration: 2944 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 458 loss: 0.31211 acc: 0.90918 | v_loss: 0.48519 v_acc: 0.90723 |  iteration: 2945 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 459 loss: 0.38826 acc: 0.89128 | v_loss: 0.46951 v_acc: 0.90169 |  iteration: 2946 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 460 loss: 0.30505 acc: 0.91536 | v_loss: 0.36315 v_acc: 0.92676 |  iteration: 2947 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 461 loss: 0.18972 acc: 0.94694 | v_loss: 0.68588 v_acc: 0.86914 |  iteration: 2948 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 462 loss: 0.28539 acc: 0.91309 | v_loss: 0.56525 v_acc: 0.87109 |  iteration: 2949 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 463 loss: 0.32801 acc: 0.90592 | v_loss: 0.59522 v_acc: 0.87305 |  iteration: 2950 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 464 loss: 0.30392 acc: 0.92025 | v_loss: 0.82335 v_acc: 0.84212 |  iteration: 2951 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 465 loss: 0.26634 acc: 0.91829 | v_loss: 0.42081 v_acc: 0.90397 |  iteration: 2952 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 466 loss: 0.36991 acc: 0.89030 | v_loss: 0.58209 v_acc: 0.87272 |  iteration: 2953 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 467 loss: 0.30696 acc: 0.91602 | v_loss: 0.52374 v_acc: 0.88835 |  iteration: 2954 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 468 loss: 0.29909 acc: 0.91211 | v_loss: 0.42132 v_acc: 0.90820 |  iteration: 2955 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 469 loss: 0.30179 acc: 0.91439 | v_loss: 1.15695 v_acc: 0.80371 |  iteration: 2956 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 470 loss: 0.25403 acc: 0.92188 | v_loss: 0.38928 v_acc: 0.91895 |  iteration: 2957 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 471 loss: 0.26788 acc: 0.91927 | v_loss: 0.59657 v_acc: 0.87956 |  iteration: 2958 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 472 loss: 0.29927 acc: 0.91634 | v_loss: 0.53688 v_acc: 0.88932 |  iteration: 2959 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 473 loss: 0.26480 acc: 0.91699 | v_loss: 0.40870 v_acc: 0.91178 |  iteration: 2960 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 474 loss: 0.31859 acc: 0.91113 | v_loss: 0.52659 v_acc: 0.88509 |  iteration: 2961 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 475 loss: 0.37434 acc: 0.90365 | v_loss: 0.58284 v_acc: 0.87370 |  iteration: 2962 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 476 loss: 0.20198 acc: 0.94010 | v_loss: 0.45302 v_acc: 0.89779 |  iteration: 2963 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 477 loss: 0.29953 acc: 0.91309 | v_loss: 0.65840 v_acc: 0.86719 |  iteration: 2964 teacher: 0 stage: sketch lr: 0.000518\n",
      "batch 478 loss: 0.25582 acc: 0.92090 | v_loss: 0.40378 v_acc: 0.90625 |  iteration: 2965 teacher: 0 stage: sketch lr: 0.000518\n",
      "batch 479 loss: 0.27720 acc: 0.92057 | v_loss: 1.00257 v_acc: 0.82487 |  iteration: 2966 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 480 loss: 0.33161 acc: 0.90104 | v_loss: 0.55414 v_acc: 0.88932 |  iteration: 2967 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 481 loss: 0.26221 acc: 0.92578 | v_loss: 0.67019 v_acc: 0.87337 |  iteration: 2968 teacher: 0 stage: sketch lr: 0.000518\n",
      "batch 482 loss: 0.26374 acc: 0.92383 | v_loss: 0.43473 v_acc: 0.89648 |  iteration: 2969 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 483 loss: 0.30399 acc: 0.90820 | v_loss: 0.66031 v_acc: 0.86458 |  iteration: 2970 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 484 loss: 0.26571 acc: 0.92057 | v_loss: 0.43737 v_acc: 0.90072 |  iteration: 2971 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 485 loss: 0.29096 acc: 0.92188 | v_loss: 0.48820 v_acc: 0.88672 |  iteration: 2972 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 486 loss: 0.23954 acc: 0.93001 | v_loss: 0.45477 v_acc: 0.88867 |  iteration: 2973 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 487 loss: 0.27178 acc: 0.91829 | v_loss: 0.71402 v_acc: 0.85579 |  iteration: 2974 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 488 loss: 0.22814 acc: 0.93522 | v_loss: 0.50854 v_acc: 0.90234 |  iteration: 2975 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 489 loss: 0.24528 acc: 0.92773 | v_loss: 0.56855 v_acc: 0.87923 |  iteration: 2976 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 490 loss: 0.30494 acc: 0.91309 | v_loss: 0.67368 v_acc: 0.85612 |  iteration: 2977 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 491 loss: 0.34283 acc: 0.90267 | v_loss: 0.43094 v_acc: 0.89876 |  iteration: 2978 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 492 loss: 0.23267 acc: 0.93034 | v_loss: 0.56266 v_acc: 0.86491 |  iteration: 2979 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 493 loss: 0.28783 acc: 0.91797 | v_loss: 0.55345 v_acc: 0.87793 |  iteration: 2980 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 494 loss: 0.31344 acc: 0.91406 | v_loss: 0.76014 v_acc: 0.86165 |  iteration: 2981 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 495 loss: 0.26534 acc: 0.92611 | v_loss: 0.60056 v_acc: 0.88281 |  iteration: 2982 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 496 loss: 0.31336 acc: 0.90397 | v_loss: 0.60424 v_acc: 0.88249 |  iteration: 2983 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 497 loss: 0.28636 acc: 0.91797 | v_loss: 0.65977 v_acc: 0.88151 |  iteration: 2984 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 498 loss: 0.21555 acc: 0.93815 | v_loss: 0.61722 v_acc: 0.85645 |  iteration: 2985 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 499 loss: 0.29916 acc: 0.91536 | v_loss: 0.43767 v_acc: 0.89844 |  iteration: 2986 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 500 loss: 0.29892 acc: 0.90853 | v_loss: 0.75809 v_acc: 0.84115 |  iteration: 2987 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 501 loss: 0.25600 acc: 0.92871 | v_loss: 0.59929 v_acc: 0.87077 |  iteration: 2988 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 502 loss: 0.27462 acc: 0.91927 | v_loss: 0.57141 v_acc: 0.87044 |  iteration: 2989 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 503 loss: 0.33950 acc: 0.90495 | v_loss: 0.55024 v_acc: 0.88249 |  iteration: 2990 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 504 loss: 0.33833 acc: 0.90299 | v_loss: 0.46513 v_acc: 0.90723 |  iteration: 2991 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 505 loss: 0.29406 acc: 0.91960 | v_loss: 0.50161 v_acc: 0.89323 |  iteration: 2992 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 506 loss: 0.36639 acc: 0.90397 | v_loss: 0.53841 v_acc: 0.88639 |  iteration: 2993 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 507 loss: 0.22689 acc: 0.93783 | v_loss: 0.67201 v_acc: 0.85124 |  iteration: 2994 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 508 loss: 0.25922 acc: 0.92676 | v_loss: 0.64355 v_acc: 0.88477 |  iteration: 2995 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 509 loss: 0.33096 acc: 0.91374 | v_loss: 0.60886 v_acc: 0.88346 |  iteration: 2996 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 510 loss: 0.32071 acc: 0.91471 | v_loss: 0.36739 v_acc: 0.91276 |  iteration: 2997 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 511 loss: 0.35927 acc: 0.90365 | v_loss: 0.55972 v_acc: 0.87956 |  iteration: 2998 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 512 loss: 0.22438 acc: 0.93197 | v_loss: 0.52685 v_acc: 0.87109 |  iteration: 2999 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 513 loss: 0.37345 acc: 0.90007 | v_loss: 0.85959 v_acc: 0.82845 |  iteration: 3000 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 514 loss: 0.33962 acc: 0.90299 | v_loss: 0.35563 v_acc: 0.91536 |  iteration: 3001 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 515 loss: 0.24471 acc: 0.92969 | v_loss: 0.31234 v_acc: 0.92773 |  iteration: 3002 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 516 loss: 0.25993 acc: 0.92806 | v_loss: 0.60266 v_acc: 0.88118 |  iteration: 3003 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 517 loss: 0.37126 acc: 0.90234 | v_loss: 0.58115 v_acc: 0.88802 |  iteration: 3004 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 518 loss: 0.31111 acc: 0.91406 | v_loss: 0.71338 v_acc: 0.85905 |  iteration: 3005 teacher: 0 stage: sketch lr: 0.000525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 519 loss: 0.28015 acc: 0.92090 | v_loss: 0.41027 v_acc: 0.90267 |  iteration: 3006 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 520 loss: 0.24355 acc: 0.92839 | v_loss: 0.50926 v_acc: 0.86947 |  iteration: 3007 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 521 loss: 0.34112 acc: 0.90267 | v_loss: 0.60109 v_acc: 0.86556 |  iteration: 3008 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 522 loss: 0.30813 acc: 0.92057 | v_loss: 0.66522 v_acc: 0.85579 |  iteration: 3009 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 523 loss: 0.31322 acc: 0.90690 | v_loss: 0.48938 v_acc: 0.89714 |  iteration: 3010 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 524 loss: 0.25802 acc: 0.92611 | v_loss: 0.40317 v_acc: 0.90560 |  iteration: 3011 teacher: 1 stage: sketch lr: 0.000526\n",
      "batch 525 loss: 0.35078 acc: 0.91276 | v_loss: 0.29984 v_acc: 0.92188 |  iteration: 3012 teacher: 1 stage: sketch lr: 0.000526\n",
      "batch 526 loss: 0.29925 acc: 0.91634 | v_loss: 0.47186 v_acc: 0.90788 |  iteration: 3013 teacher: 1 stage: sketch lr: 0.000526\n",
      "batch 527 loss: 0.36995 acc: 0.90332 | v_loss: 0.52733 v_acc: 0.87858 |  iteration: 3014 teacher: 1 stage: sketch lr: 0.000527\n",
      "batch 528 loss: 0.28718 acc: 0.92188 | v_loss: 0.88540 v_acc: 0.83366 |  iteration: 3015 teacher: 1 stage: sketch lr: 0.000527\n",
      "batch 529 loss: 0.31438 acc: 0.90658 | v_loss: 0.54186 v_acc: 0.87923 |  iteration: 3016 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 530 loss: 0.32995 acc: 0.89551 | v_loss: 0.60700 v_acc: 0.87695 |  iteration: 3017 teacher: 1 stage: sketch lr: 0.000527\n",
      "batch 531 loss: 0.36971 acc: 0.90104 | v_loss: 0.42531 v_acc: 0.89909 |  iteration: 3018 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 532 loss: 0.30798 acc: 0.91276 | v_loss: 0.53648 v_acc: 0.88411 |  iteration: 3019 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 533 loss: 0.24768 acc: 0.92936 | v_loss: 0.79951 v_acc: 0.84310 |  iteration: 3020 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 534 loss: 0.34787 acc: 0.90527 | v_loss: 0.55253 v_acc: 0.89290 |  iteration: 3021 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 535 loss: 0.30231 acc: 0.91895 | v_loss: 0.56225 v_acc: 0.89062 |  iteration: 3022 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 536 loss: 0.24751 acc: 0.92773 | v_loss: 0.53817 v_acc: 0.88770 |  iteration: 3023 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 537 loss: 0.32722 acc: 0.91471 | v_loss: 0.44069 v_acc: 0.90495 |  iteration: 3024 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 538 loss: 0.37027 acc: 0.90104 | v_loss: 0.49632 v_acc: 0.90495 |  iteration: 3025 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 539 loss: 0.26599 acc: 0.92383 | v_loss: 0.61492 v_acc: 0.86947 |  iteration: 3026 teacher: 0 stage: sketch lr: 0.000529\n",
      "batch 540 loss: 0.32279 acc: 0.91309 | v_loss: 0.39649 v_acc: 0.91764 |  iteration: 3027 teacher: 0 stage: sketch lr: 0.000529\n",
      "batch 541 loss: 0.30014 acc: 0.91667 | v_loss: 0.96593 v_acc: 0.82845 |  iteration: 3028 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 542 loss: 0.34911 acc: 0.90039 | v_loss: 0.64493 v_acc: 0.87598 |  iteration: 3029 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 543 loss: 0.31331 acc: 0.90430 | v_loss: 0.67669 v_acc: 0.86361 |  iteration: 3030 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 544 loss: 0.41544 acc: 0.88444 | v_loss: 0.54997 v_acc: 0.89095 |  iteration: 3031 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 545 loss: 0.34545 acc: 0.90365 | v_loss: 0.50161 v_acc: 0.88900 |  iteration: 3032 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 546 loss: 0.34724 acc: 0.90007 | v_loss: 0.57548 v_acc: 0.88639 |  iteration: 3033 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 547 loss: 0.29676 acc: 0.91699 | v_loss: 0.51948 v_acc: 0.88932 |  iteration: 3034 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 548 loss: 0.22763 acc: 0.92871 | v_loss: 0.56023 v_acc: 0.87500 |  iteration: 3035 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 549 loss: 0.29909 acc: 0.91081 | v_loss: 0.49973 v_acc: 0.90234 |  iteration: 3036 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 550 loss: 0.36619 acc: 0.90104 | v_loss: 0.45602 v_acc: 0.89779 |  iteration: 3037 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 551 loss: 0.27711 acc: 0.91471 | v_loss: 0.36302 v_acc: 0.92057 |  iteration: 3038 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 552 loss: 0.28173 acc: 0.91992 | v_loss: 0.61734 v_acc: 0.86556 |  iteration: 3039 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 553 loss: 0.32786 acc: 0.90267 | v_loss: 0.56997 v_acc: 0.85742 |  iteration: 3040 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 554 loss: 0.27461 acc: 0.92415 | v_loss: 0.63191 v_acc: 0.86198 |  iteration: 3041 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 555 loss: 0.35287 acc: 0.90072 | v_loss: 0.85842 v_acc: 0.84733 |  iteration: 3042 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 556 loss: 0.35313 acc: 0.91016 | v_loss: 0.43289 v_acc: 0.90527 |  iteration: 3043 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 557 loss: 0.30826 acc: 0.91569 | v_loss: 0.62161 v_acc: 0.87598 |  iteration: 3044 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 558 loss: 0.23194 acc: 0.93327 | v_loss: 0.60680 v_acc: 0.88379 |  iteration: 3045 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 559 loss: 0.40015 acc: 0.89714 | v_loss: 0.37510 v_acc: 0.90983 |  iteration: 3046 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 560 loss: 0.26671 acc: 0.92122 | v_loss: 1.12875 v_acc: 0.80176 |  iteration: 3047 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 561 loss: 0.31602 acc: 0.91211 | v_loss: 0.37936 v_acc: 0.90820 |  iteration: 3048 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 562 loss: 0.28695 acc: 0.91667 | v_loss: 0.58789 v_acc: 0.87663 |  iteration: 3049 teacher: 0 stage: sketch lr: 0.000533\n",
      "batch 563 loss: 0.30287 acc: 0.90625 | v_loss: 0.52277 v_acc: 0.88900 |  iteration: 3050 teacher: 0 stage: sketch lr: 0.000533\n",
      "batch 564 loss: 0.34858 acc: 0.89941 | v_loss: 0.42197 v_acc: 0.90462 |  iteration: 3051 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 565 loss: 0.31570 acc: 0.90918 | v_loss: 0.52451 v_acc: 0.89062 |  iteration: 3052 teacher: 0 stage: sketch lr: 0.000533\n",
      "batch 566 loss: 0.38508 acc: 0.88867 | v_loss: 0.58234 v_acc: 0.87630 |  iteration: 3053 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 567 loss: 0.25383 acc: 0.92383 | v_loss: 0.45641 v_acc: 0.90462 |  iteration: 3054 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 568 loss: 0.32141 acc: 0.91081 | v_loss: 0.66709 v_acc: 0.86296 |  iteration: 3055 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 569 loss: 0.27880 acc: 0.92806 | v_loss: 0.40348 v_acc: 0.90560 |  iteration: 3056 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 570 loss: 0.31313 acc: 0.91113 | v_loss: 0.99779 v_acc: 0.82357 |  iteration: 3057 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 571 loss: 0.27775 acc: 0.92578 | v_loss: 0.57210 v_acc: 0.89323 |  iteration: 3058 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 572 loss: 0.32841 acc: 0.90267 | v_loss: 0.67030 v_acc: 0.86816 |  iteration: 3059 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 573 loss: 0.30417 acc: 0.91243 | v_loss: 0.44281 v_acc: 0.89583 |  iteration: 3060 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 574 loss: 0.31782 acc: 0.90951 | v_loss: 0.64886 v_acc: 0.85449 |  iteration: 3061 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 575 loss: 0.23422 acc: 0.93717 | v_loss: 0.48755 v_acc: 0.88477 |  iteration: 3062 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 576 loss: 0.29019 acc: 0.92057 | v_loss: 0.46612 v_acc: 0.88639 |  iteration: 3063 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 577 loss: 0.36035 acc: 0.89486 | v_loss: 0.43725 v_acc: 0.89551 |  iteration: 3064 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 578 loss: 0.22123 acc: 0.93978 | v_loss: 0.73357 v_acc: 0.86230 |  iteration: 3065 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 579 loss: 0.32648 acc: 0.91634 | v_loss: 0.53327 v_acc: 0.89225 |  iteration: 3066 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 580 loss: 0.34547 acc: 0.90820 | v_loss: 0.54382 v_acc: 0.88151 |  iteration: 3067 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 581 loss: 0.31824 acc: 0.90853 | v_loss: 0.67091 v_acc: 0.85352 |  iteration: 3068 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 582 loss: 0.31635 acc: 0.91016 | v_loss: 0.45704 v_acc: 0.88835 |  iteration: 3069 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 583 loss: 0.34413 acc: 0.90885 | v_loss: 0.56048 v_acc: 0.86556 |  iteration: 3070 teacher: 0 stage: sketch lr: 0.000536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 584 loss: 0.33499 acc: 0.89616 | v_loss: 0.57978 v_acc: 0.86068 |  iteration: 3071 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 585 loss: 0.28709 acc: 0.91374 | v_loss: 0.74611 v_acc: 0.85254 |  iteration: 3072 teacher: 1 stage: sketch lr: 0.000537\n",
      "batch 586 loss: 0.32442 acc: 0.90267 | v_loss: 0.53750 v_acc: 0.89095 |  iteration: 3073 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 587 loss: 0.27135 acc: 0.92318 | v_loss: 0.59807 v_acc: 0.87956 |  iteration: 3074 teacher: 1 stage: sketch lr: 0.000537\n",
      "batch 588 loss: 0.26271 acc: 0.92057 | v_loss: 0.66508 v_acc: 0.88281 |  iteration: 3075 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 589 loss: 0.26321 acc: 0.92871 | v_loss: 0.58629 v_acc: 0.86458 |  iteration: 3076 teacher: 1 stage: sketch lr: 0.000537\n",
      "batch 590 loss: 0.40721 acc: 0.89095 | v_loss: 0.43217 v_acc: 0.90495 |  iteration: 3077 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 591 loss: 0.25163 acc: 0.92708 | v_loss: 0.83566 v_acc: 0.83984 |  iteration: 3078 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 592 loss: 0.30922 acc: 0.91309 | v_loss: 0.58308 v_acc: 0.88249 |  iteration: 3079 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 593 loss: 0.33419 acc: 0.90397 | v_loss: 0.56850 v_acc: 0.87272 |  iteration: 3080 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 594 loss: 0.23589 acc: 0.92741 | v_loss: 0.54913 v_acc: 0.87695 |  iteration: 3081 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 595 loss: 0.31939 acc: 0.91309 | v_loss: 0.44783 v_acc: 0.89225 |  iteration: 3082 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 596 loss: 0.42191 acc: 0.89453 | v_loss: 0.47059 v_acc: 0.90104 |  iteration: 3083 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 597 loss: 0.26551 acc: 0.91895 | v_loss: 0.53660 v_acc: 0.87891 |  iteration: 3084 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 598 loss: 0.20037 acc: 0.94108 | v_loss: 0.65057 v_acc: 0.85482 |  iteration: 3085 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 599 loss: 0.21604 acc: 0.93327 | v_loss: 0.61779 v_acc: 0.88021 |  iteration: 3086 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 600 loss: 0.28817 acc: 0.91895 | v_loss: 0.61998 v_acc: 0.88444 |  iteration: 3087 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 601 loss: 0.32667 acc: 0.90072 | v_loss: 0.38462 v_acc: 0.91048 |  iteration: 3088 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 602 loss: 0.32803 acc: 0.90755 | v_loss: 0.53149 v_acc: 0.88704 |  iteration: 3089 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 603 loss: 0.21636 acc: 0.94043 | v_loss: 0.52108 v_acc: 0.87891 |  iteration: 3090 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 604 loss: 0.23234 acc: 0.93034 | v_loss: 0.83405 v_acc: 0.83496 |  iteration: 3091 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 605 loss: 0.29524 acc: 0.91797 | v_loss: 0.41658 v_acc: 0.90462 |  iteration: 3092 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 606 loss: 0.33642 acc: 0.90234 | v_loss: 0.32072 v_acc: 0.92480 |  iteration: 3093 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 607 loss: 0.33944 acc: 0.90299 | v_loss: 0.55662 v_acc: 0.89062 |  iteration: 3094 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 608 loss: 0.25312 acc: 0.92643 | v_loss: 0.56100 v_acc: 0.88444 |  iteration: 3095 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 609 loss: 0.29439 acc: 0.91634 | v_loss: 0.69476 v_acc: 0.85840 |  iteration: 3096 teacher: 1 stage: sketch lr: 0.000541\n",
      "batch 610 loss: 0.27373 acc: 0.92220 | v_loss: 0.42167 v_acc: 0.90690 |  iteration: 3097 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 611 loss: 0.34366 acc: 0.90299 | v_loss: 0.50285 v_acc: 0.88184 |  iteration: 3098 teacher: 1 stage: sketch lr: 0.000541\n",
      "batch 612 loss: 0.33172 acc: 0.91211 | v_loss: 0.59409 v_acc: 0.86426 |  iteration: 3099 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 613 loss: 0.31903 acc: 0.91048 | v_loss: 0.66056 v_acc: 0.84701 |  iteration: 3100 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 614 loss: 0.18916 acc: 0.94303 | v_loss: 0.50854 v_acc: 0.88542 |  iteration: 3101 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 615 loss: 0.31798 acc: 0.90007 | v_loss: 0.37962 v_acc: 0.90202 |  iteration: 3102 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 616 loss: 0.25278 acc: 0.92773 | v_loss: 0.27969 v_acc: 0.92318 |  iteration: 3103 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 617 loss: 0.27474 acc: 0.92057 | v_loss: 0.46475 v_acc: 0.89160 |  iteration: 3104 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 618 loss: 0.34533 acc: 0.89909 | v_loss: 0.50036 v_acc: 0.88607 |  iteration: 3105 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 619 loss: 0.20328 acc: 0.93424 | v_loss: 0.82843 v_acc: 0.86263 |  iteration: 3106 teacher: 0 stage: sketch lr: 0.000543\n",
      "batch 620 loss: 0.21956 acc: 0.93685 | v_loss: 0.57956 v_acc: 0.88053 |  iteration: 3107 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 621 loss: 0.34318 acc: 0.91439 | v_loss: 0.74177 v_acc: 0.86816 |  iteration: 3108 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 622 loss: 0.36325 acc: 0.89974 | v_loss: 0.40221 v_acc: 0.90658 |  iteration: 3109 teacher: 0 stage: sketch lr: 0.000543\n",
      "batch 623 loss: 0.29326 acc: 0.91569 | v_loss: 0.52131 v_acc: 0.88737 |  iteration: 3110 teacher: 0 stage: sketch lr: 0.000543\n",
      "batch 624 loss: 0.27856 acc: 0.92285 | v_loss: 0.75675 v_acc: 0.84961 |  iteration: 3111 teacher: 0 stage: sketch lr: 0.000543\n",
      "batch 625 loss: 0.26885 acc: 0.92676 | v_loss: 0.53827 v_acc: 0.89355 |  iteration: 3112 teacher: 0 stage: sketch lr: 0.000544\n",
      "batch 626 loss: 0.32210 acc: 0.91471 | v_loss: 0.54272 v_acc: 0.88965 |  iteration: 3113 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 627 loss: 0.38939 acc: 0.89453 | v_loss: 0.48483 v_acc: 0.88997 |  iteration: 3114 teacher: 0 stage: sketch lr: 0.000544\n",
      "batch 628 loss: 0.38485 acc: 0.89811 | v_loss: 0.42830 v_acc: 0.90234 |  iteration: 3115 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 629 loss: 0.28568 acc: 0.91439 | v_loss: 0.44691 v_acc: 0.90267 |  iteration: 3116 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 630 loss: 0.30354 acc: 0.90625 | v_loss: 0.56392 v_acc: 0.86947 |  iteration: 3117 teacher: 0 stage: sketch lr: 0.000545\n",
      "batch 631 loss: 0.28601 acc: 0.91634 | v_loss: 0.37354 v_acc: 0.91829 |  iteration: 3118 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 632 loss: 0.32560 acc: 0.90983 | v_loss: 0.93435 v_acc: 0.82975 |  iteration: 3119 teacher: 0 stage: sketch lr: 0.000545\n",
      "batch 633 loss: 0.32754 acc: 0.90039 | v_loss: 0.60207 v_acc: 0.87793 |  iteration: 3120 teacher: 0 stage: sketch lr: 0.000545\n",
      "batch 634 loss: 0.35559 acc: 0.90462 | v_loss: 0.67486 v_acc: 0.86393 |  iteration: 3121 teacher: 0 stage: sketch lr: 0.000545\n",
      "batch 635 loss: 0.29345 acc: 0.91634 | v_loss: 0.52334 v_acc: 0.89193 |  iteration: 3122 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 636 loss: 0.31418 acc: 0.90495 | v_loss: 0.48726 v_acc: 0.89746 |  iteration: 3123 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 637 loss: 0.19910 acc: 0.94434 | v_loss: 0.62119 v_acc: 0.88053 |  iteration: 3124 teacher: 1 stage: sketch lr: 0.000546\n",
      "batch 638 loss: 0.31611 acc: 0.91178 | v_loss: 0.55323 v_acc: 0.88867 |  iteration: 3125 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 639 loss: 0.32487 acc: 0.90658 | v_loss: 0.51215 v_acc: 0.88477 |  iteration: 3126 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 640 loss: 0.34072 acc: 0.90918 | v_loss: 0.49199 v_acc: 0.90267 |  iteration: 3127 teacher: 1 stage: sketch lr: 0.000546\n",
      "batch 641 loss: 0.23833 acc: 0.92969 | v_loss: 0.44821 v_acc: 0.90137 |  iteration: 3128 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 642 loss: 0.31031 acc: 0.90885 | v_loss: 0.35097 v_acc: 0.91569 |  iteration: 3129 teacher: 1 stage: sketch lr: 0.000547\n",
      "batch 643 loss: 0.24030 acc: 0.93359 | v_loss: 0.67164 v_acc: 0.86035 |  iteration: 3130 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 644 loss: 0.23879 acc: 0.93132 | v_loss: 0.56339 v_acc: 0.86882 |  iteration: 3131 teacher: 1 stage: sketch lr: 0.000547\n",
      "batch 645 loss: 0.23351 acc: 0.93229 | v_loss: 0.62909 v_acc: 0.86589 |  iteration: 3132 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 646 loss: 0.23780 acc: 0.93164 | v_loss: 0.81056 v_acc: 0.84733 |  iteration: 3133 teacher: 1 stage: sketch lr: 0.000547\n",
      "batch 647 loss: 0.25320 acc: 0.92350 | v_loss: 0.41371 v_acc: 0.91667 |  iteration: 3134 teacher: 1 stage: sketch lr: 0.000547\n",
      "batch 648 loss: 0.20633 acc: 0.93913 | v_loss: 0.59246 v_acc: 0.88411 |  iteration: 3135 teacher: 1 stage: sketch lr: 0.000548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 649 loss: 0.32156 acc: 0.90755 | v_loss: 0.55199 v_acc: 0.89486 |  iteration: 3136 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 650 loss: 0.28622 acc: 0.92415 | v_loss: 0.44416 v_acc: 0.91178 |  iteration: 3137 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 651 loss: 0.24865 acc: 0.93229 | v_loss: 1.19059 v_acc: 0.79850 |  iteration: 3138 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 652 loss: 0.28754 acc: 0.91862 | v_loss: 0.40330 v_acc: 0.91243 |  iteration: 3139 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 653 loss: 0.22799 acc: 0.93750 | v_loss: 0.58206 v_acc: 0.87500 |  iteration: 3140 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 654 loss: 0.27657 acc: 0.92480 | v_loss: 0.51716 v_acc: 0.88574 |  iteration: 3141 teacher: 1 stage: sketch lr: 0.000549\n",
      "batch 655 loss: 0.30323 acc: 0.91439 | v_loss: 0.41455 v_acc: 0.90365 |  iteration: 3142 teacher: 1 stage: sketch lr: 0.000549\n",
      "batch 656 loss: 0.35625 acc: 0.89128 | v_loss: 0.47504 v_acc: 0.89193 |  iteration: 3143 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 657 loss: 0.26461 acc: 0.92188 | v_loss: 0.56400 v_acc: 0.87435 |  iteration: 3144 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 658 loss: 0.26490 acc: 0.92676 | v_loss: 0.42815 v_acc: 0.90918 |  iteration: 3145 teacher: 1 stage: sketch lr: 0.000549\n",
      "batch 659 loss: 0.26347 acc: 0.92122 | v_loss: 0.65238 v_acc: 0.86979 |  iteration: 3146 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 660 loss: 0.26086 acc: 0.92415 | v_loss: 0.41323 v_acc: 0.90430 |  iteration: 3147 teacher: 0 stage: sketch lr: 0.000550\n",
      "batch 661 loss: 0.26564 acc: 0.92155 | v_loss: 0.99867 v_acc: 0.82422 |  iteration: 3148 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 662 loss: 0.26371 acc: 0.92057 | v_loss: 0.54526 v_acc: 0.89258 |  iteration: 3149 teacher: 0 stage: sketch lr: 0.000550\n",
      "batch 663 loss: 0.25235 acc: 0.93001 | v_loss: 0.65883 v_acc: 0.87630 |  iteration: 3150 teacher: 0 stage: sketch lr: 0.000550\n",
      "batch 664 loss: 0.21240 acc: 0.93815 | v_loss: 0.41543 v_acc: 0.89681 |  iteration: 3151 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 665 loss: 0.27946 acc: 0.91895 | v_loss: 0.65258 v_acc: 0.85384 |  iteration: 3152 teacher: 0 stage: sketch lr: 0.000551\n",
      "batch 666 loss: 0.33454 acc: 0.90592 | v_loss: 0.44906 v_acc: 0.89388 |  iteration: 3153 teacher: 0 stage: sketch lr: 0.000551\n",
      "batch 667 loss: 0.28072 acc: 0.92643 | v_loss: 0.47598 v_acc: 0.88900 |  iteration: 3154 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 668 loss: 0.29588 acc: 0.91146 | v_loss: 0.47524 v_acc: 0.88835 |  iteration: 3155 teacher: 0 stage: sketch lr: 0.000551\n",
      "batch 669 loss: 0.34114 acc: 0.90462 | v_loss: 0.75664 v_acc: 0.85286 |  iteration: 3156 teacher: 0 stage: sketch lr: 0.000551\n",
      "batch 670 loss: 0.27887 acc: 0.92643 | v_loss: 0.53770 v_acc: 0.89062 |  iteration: 3157 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 671 loss: 0.19668 acc: 0.94629 | v_loss: 0.53244 v_acc: 0.88607 |  iteration: 3158 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 672 loss: 0.26313 acc: 0.92057 | v_loss: 0.67788 v_acc: 0.85449 |  iteration: 3159 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 673 loss: 0.23355 acc: 0.92871 | v_loss: 0.45041 v_acc: 0.89453 |  iteration: 3160 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 674 loss: 0.20852 acc: 0.93783 | v_loss: 0.52759 v_acc: 0.87142 |  iteration: 3161 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 675 loss: 0.29262 acc: 0.92611 | v_loss: 0.55243 v_acc: 0.88053 |  iteration: 3162 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 676 loss: 0.26347 acc: 0.92090 | v_loss: 0.77146 v_acc: 0.85319 |  iteration: 3163 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 677 loss: 0.39417 acc: 0.89128 | v_loss: 0.57731 v_acc: 0.88216 |  iteration: 3164 teacher: 0 stage: sketch lr: 0.000553\n",
      "batch 678 loss: 0.37482 acc: 0.89225 | v_loss: 0.60258 v_acc: 0.87272 |  iteration: 3165 teacher: 0 stage: sketch lr: 0.000553\n",
      "batch 679 loss: 0.22403 acc: 0.93880 | v_loss: 0.62646 v_acc: 0.87500 |  iteration: 3166 teacher: 0 stage: sketch lr: 0.000553\n",
      "batch 680 loss: 0.24011 acc: 0.93490 | v_loss: 0.58566 v_acc: 0.85742 |  iteration: 3167 teacher: 0 stage: sketch lr: 0.000553\n",
      "batch 681 loss: 0.21644 acc: 0.93815 | v_loss: 0.46502 v_acc: 0.89811 |  iteration: 3168 teacher: 0 stage: sketch lr: 0.000553\n",
      "batch 682 loss: 0.37575 acc: 0.89453 | v_loss: 0.80497 v_acc: 0.83952 |  iteration: 3169 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 683 loss: 0.27871 acc: 0.92253 | v_loss: 0.58931 v_acc: 0.87142 |  iteration: 3170 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 684 loss: 0.28803 acc: 0.91211 | v_loss: 0.50950 v_acc: 0.87500 |  iteration: 3171 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 685 loss: 0.25626 acc: 0.91960 | v_loss: 0.55727 v_acc: 0.88184 |  iteration: 3172 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 686 loss: 0.25924 acc: 0.92057 | v_loss: 0.49089 v_acc: 0.89355 |  iteration: 3173 teacher: 0 stage: sketch lr: 0.000554\n",
      "batch 687 loss: 0.33434 acc: 0.91960 | v_loss: 0.48323 v_acc: 0.89714 |  iteration: 3174 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 688 loss: 0.24698 acc: 0.92318 | v_loss: 0.57015 v_acc: 0.88346 |  iteration: 3175 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 689 loss: 0.32613 acc: 0.90885 | v_loss: 0.64684 v_acc: 0.84896 |  iteration: 3176 teacher: 1 stage: sketch lr: 0.000555\n",
      "batch 690 loss: 0.30099 acc: 0.91895 | v_loss: 0.62478 v_acc: 0.88802 |  iteration: 3177 teacher: 1 stage: sketch lr: 0.000555\n",
      "batch 691 loss: 0.28151 acc: 0.92611 | v_loss: 0.64708 v_acc: 0.88574 |  iteration: 3178 teacher: 1 stage: sketch lr: 0.000555\n",
      "batch 692 loss: 0.28596 acc: 0.91895 | v_loss: 0.36092 v_acc: 0.91341 |  iteration: 3179 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 693 loss: 0.32632 acc: 0.90625 | v_loss: 0.56226 v_acc: 0.88607 |  iteration: 3180 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 694 loss: 0.30378 acc: 0.91536 | v_loss: 0.45550 v_acc: 0.89030 |  iteration: 3181 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 695 loss: 0.42621 acc: 0.88542 | v_loss: 0.85465 v_acc: 0.82650 |  iteration: 3182 teacher: 1 stage: sketch lr: 0.000556\n",
      "batch 696 loss: 0.23692 acc: 0.92936 | v_loss: 0.36327 v_acc: 0.91016 |  iteration: 3183 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 697 loss: 0.29666 acc: 0.91309 | v_loss: 0.32586 v_acc: 0.91895 |  iteration: 3184 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 698 loss: 0.28178 acc: 0.91699 | v_loss: 0.53787 v_acc: 0.88737 |  iteration: 3185 teacher: 1 stage: sketch lr: 0.000556\n",
      "batch 699 loss: 0.27574 acc: 0.91895 | v_loss: 0.58594 v_acc: 0.88477 |  iteration: 3186 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 700 loss: 0.19721 acc: 0.94076 | v_loss: 0.73664 v_acc: 0.84798 |  iteration: 3187 teacher: 1 stage: sketch lr: 0.000557\n",
      "batch 701 loss: 0.32820 acc: 0.90592 | v_loss: 0.42203 v_acc: 0.90299 |  iteration: 3188 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 702 loss: 0.28194 acc: 0.91113 | v_loss: 0.58386 v_acc: 0.86198 |  iteration: 3189 teacher: 1 stage: sketch lr: 0.000557\n",
      "batch 703 loss: 0.24313 acc: 0.92936 | v_loss: 0.58734 v_acc: 0.87467 |  iteration: 3190 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 704 loss: 0.25681 acc: 0.92415 | v_loss: 0.64269 v_acc: 0.85156 |  iteration: 3191 teacher: 1 stage: sketch lr: 0.000557\n",
      "batch 705 loss: 0.26430 acc: 0.92057 | v_loss: 0.45861 v_acc: 0.90202 |  iteration: 3192 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 706 loss: 0.25479 acc: 0.92513 | v_loss: 0.38132 v_acc: 0.90299 |  iteration: 3193 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 707 loss: 0.23560 acc: 0.92741 | v_loss: 0.31797 v_acc: 0.92057 |  iteration: 3194 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 708 loss: 0.31794 acc: 0.91667 | v_loss: 0.46744 v_acc: 0.89941 |  iteration: 3195 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 709 loss: 0.24719 acc: 0.93392 | v_loss: 0.49711 v_acc: 0.89355 |  iteration: 3196 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 710 loss: 0.30027 acc: 0.91602 | v_loss: 0.79984 v_acc: 0.85482 |  iteration: 3197 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 711 loss: 0.22180 acc: 0.93229 | v_loss: 0.51560 v_acc: 0.88053 |  iteration: 3198 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 712 loss: 0.32367 acc: 0.90658 | v_loss: 0.63180 v_acc: 0.86426 |  iteration: 3199 teacher: 1 stage: sketch lr: 0.000559\n",
      "batch 713 loss: 0.27048 acc: 0.91829 | v_loss: 0.41635 v_acc: 0.89779 |  iteration: 3200 teacher: 0 stage: sketch lr: 0.000559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 714 loss: 0.30463 acc: 0.90951 | v_loss: 0.55708 v_acc: 0.87891 |  iteration: 3201 teacher: 1 stage: sketch lr: 0.000559\n",
      "batch 715 loss: 0.27575 acc: 0.92318 | v_loss: 0.73054 v_acc: 0.85254 |  iteration: 3202 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 716 loss: 0.28547 acc: 0.91927 | v_loss: 0.51090 v_acc: 0.88835 |  iteration: 3203 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 717 loss: 0.27021 acc: 0.92611 | v_loss: 0.50033 v_acc: 0.89193 |  iteration: 3204 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 718 loss: 0.36940 acc: 0.90169 | v_loss: 0.47690 v_acc: 0.88639 |  iteration: 3205 teacher: 0 stage: sketch lr: 0.000560\n",
      "batch 719 loss: 0.34242 acc: 0.90332 | v_loss: 0.43648 v_acc: 0.90332 |  iteration: 3206 teacher: 0 stage: sketch lr: 0.000560\n",
      "batch 720 loss: 0.28512 acc: 0.92969 | v_loss: 0.47525 v_acc: 0.89551 |  iteration: 3207 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 721 loss: 0.27151 acc: 0.91471 | v_loss: 0.58724 v_acc: 0.86784 |  iteration: 3208 teacher: 0 stage: sketch lr: 0.000560\n",
      "batch 722 loss: 0.22606 acc: 0.93522 | v_loss: 0.35317 v_acc: 0.92220 |  iteration: 3209 teacher: 0 stage: sketch lr: 0.000561\n",
      "batch 723 loss: 0.25994 acc: 0.93034 | v_loss: 0.92613 v_acc: 0.83073 |  iteration: 3210 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 724 loss: 0.30183 acc: 0.90788 | v_loss: 0.61141 v_acc: 0.87728 |  iteration: 3211 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 725 loss: 0.25521 acc: 0.92676 | v_loss: 0.67872 v_acc: 0.87109 |  iteration: 3212 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 726 loss: 0.26883 acc: 0.92643 | v_loss: 0.57387 v_acc: 0.89290 |  iteration: 3213 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 727 loss: 0.32173 acc: 0.90527 | v_loss: 0.50065 v_acc: 0.89290 |  iteration: 3214 teacher: 0 stage: sketch lr: 0.000561\n",
      "batch 728 loss: 0.27251 acc: 0.92122 | v_loss: 0.61227 v_acc: 0.88444 |  iteration: 3215 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 729 loss: 0.24573 acc: 0.93164 | v_loss: 0.56728 v_acc: 0.88607 |  iteration: 3216 teacher: 1 stage: sketch lr: 0.000562\n",
      "batch 730 loss: 0.26668 acc: 0.92253 | v_loss: 0.51368 v_acc: 0.89486 |  iteration: 3217 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 731 loss: 0.26973 acc: 0.92676 | v_loss: 0.49440 v_acc: 0.90332 |  iteration: 3218 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 732 loss: 0.32282 acc: 0.90885 | v_loss: 0.46400 v_acc: 0.89746 |  iteration: 3219 teacher: 1 stage: sketch lr: 0.000562\n",
      "batch 733 loss: 0.32247 acc: 0.91146 | v_loss: 0.34589 v_acc: 0.92155 |  iteration: 3220 teacher: 0 stage: sketch lr: 0.000563\n",
      "batch 734 loss: 0.32021 acc: 0.91406 | v_loss: 0.61431 v_acc: 0.86491 |  iteration: 3221 teacher: 0 stage: sketch lr: 0.000563\n",
      "batch 735 loss: 0.30337 acc: 0.91309 | v_loss: 0.58180 v_acc: 0.85840 |  iteration: 3222 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 736 loss: 0.19689 acc: 0.93978 | v_loss: 0.58974 v_acc: 0.85807 |  iteration: 3223 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 737 loss: 0.30402 acc: 0.91081 | v_loss: 0.84095 v_acc: 0.83887 |  iteration: 3224 teacher: 0 stage: sketch lr: 0.000563\n",
      "batch 738 loss: 0.21676 acc: 0.93783 | v_loss: 0.38312 v_acc: 0.91504 |  iteration: 3225 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 739 loss: 0.24265 acc: 0.93001 | v_loss: 0.58707 v_acc: 0.87109 |  iteration: 3226 teacher: 1 stage: sketch lr: 0.000564\n",
      "batch 740 loss: 0.25819 acc: 0.92741 | v_loss: 0.54738 v_acc: 0.88965 |  iteration: 3227 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 741 loss: 0.21903 acc: 0.93750 | v_loss: 0.40571 v_acc: 0.91081 |  iteration: 3228 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 742 loss: 0.27952 acc: 0.92253 | v_loss: 1.13124 v_acc: 0.80371 |  iteration: 3229 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 743 loss: 0.38537 acc: 0.88965 | v_loss: 0.40320 v_acc: 0.91081 |  iteration: 3230 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 744 loss: 0.27267 acc: 0.92057 | v_loss: 0.61797 v_acc: 0.87337 |  iteration: 3231 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 745 loss: 0.34140 acc: 0.90495 | v_loss: 0.52896 v_acc: 0.88770 |  iteration: 3232 teacher: 1 stage: sketch lr: 0.000565\n",
      "batch 746 loss: 0.27020 acc: 0.92122 | v_loss: 0.41772 v_acc: 0.90430 |  iteration: 3233 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 747 loss: 0.27610 acc: 0.92188 | v_loss: 0.49927 v_acc: 0.89583 |  iteration: 3234 teacher: 1 stage: sketch lr: 0.000565\n",
      "batch 748 loss: 0.31846 acc: 0.89714 | v_loss: 0.61962 v_acc: 0.87467 |  iteration: 3235 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 749 loss: 0.27764 acc: 0.92480 | v_loss: 0.45259 v_acc: 0.90332 |  iteration: 3236 teacher: 1 stage: sketch lr: 0.000565\n",
      "batch 750 loss: 0.30694 acc: 0.92090 | v_loss: 0.61480 v_acc: 0.87630 |  iteration: 3237 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 751 loss: 0.32838 acc: 0.91536 | v_loss: 0.40616 v_acc: 0.91211 |  iteration: 3238 teacher: 0 stage: sketch lr: 0.000566\n",
      "batch 752 loss: 0.34687 acc: 0.90527 | v_loss: 0.99722 v_acc: 0.83496 |  iteration: 3239 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 753 loss: 0.26681 acc: 0.92383 | v_loss: 0.57040 v_acc: 0.87988 |  iteration: 3240 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 754 loss: 0.18527 acc: 0.94922 | v_loss: 0.65804 v_acc: 0.86393 |  iteration: 3241 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 755 loss: 0.35834 acc: 0.89518 | v_loss: 0.42673 v_acc: 0.89779 |  iteration: 3242 teacher: 0 stage: sketch lr: 0.000566\n",
      "batch 756 loss: 0.40102 acc: 0.89355 | v_loss: 0.64477 v_acc: 0.86426 |  iteration: 3243 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 757 loss: 0.31467 acc: 0.91211 | v_loss: 0.44873 v_acc: 0.89811 |  iteration: 3244 teacher: 1 stage: sketch lr: 0.000567\n",
      "batch 758 loss: 0.23040 acc: 0.93034 | v_loss: 0.44474 v_acc: 0.89421 |  iteration: 3245 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 759 loss: 0.28210 acc: 0.91992 | v_loss: 0.42579 v_acc: 0.89681 |  iteration: 3246 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 760 loss: 0.23617 acc: 0.92773 | v_loss: 0.73027 v_acc: 0.85612 |  iteration: 3247 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 761 loss: 0.25002 acc: 0.92318 | v_loss: 0.51104 v_acc: 0.90234 |  iteration: 3248 teacher: 1 stage: sketch lr: 0.000567\n",
      "batch 762 loss: 0.29229 acc: 0.91667 | v_loss: 0.53330 v_acc: 0.88346 |  iteration: 3249 teacher: 0 stage: sketch lr: 0.000568\n",
      "batch 763 loss: 0.27658 acc: 0.92578 | v_loss: 0.66010 v_acc: 0.85872 |  iteration: 3250 teacher: 0 stage: sketch lr: 0.000568\n",
      "batch 764 loss: 0.30147 acc: 0.91178 | v_loss: 0.48251 v_acc: 0.89225 |  iteration: 3251 teacher: 0 stage: sketch lr: 0.000568\n",
      "batch 765 loss: 0.26666 acc: 0.92383 | v_loss: 0.54141 v_acc: 0.86621 |  iteration: 3252 teacher: 1 stage: sketch lr: 0.000568\n",
      "batch 766 loss: 0.28103 acc: 0.91341 | v_loss: 0.53189 v_acc: 0.87305 |  iteration: 3253 teacher: 0 stage: sketch lr: 0.000568\n",
      "batch 767 loss: 0.24035 acc: 0.92578 | v_loss: 0.70481 v_acc: 0.85645 |  iteration: 3254 teacher: 1 stage: sketch lr: 0.000568\n",
      "batch 768 loss: 0.25069 acc: 0.92155 | v_loss: 0.55236 v_acc: 0.88770 |  iteration: 3255 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 769 loss: 0.34067 acc: 0.91309 | v_loss: 0.58530 v_acc: 0.87988 |  iteration: 3256 teacher: 1 stage: sketch lr: 0.000569\n",
      "batch 770 loss: 0.25239 acc: 0.92969 | v_loss: 0.63008 v_acc: 0.87663 |  iteration: 3257 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 771 loss: 0.30520 acc: 0.91146 | v_loss: 0.56455 v_acc: 0.86133 |  iteration: 3258 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 772 loss: 0.26307 acc: 0.91862 | v_loss: 0.39076 v_acc: 0.90983 |  iteration: 3259 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 773 loss: 0.27604 acc: 0.92025 | v_loss: 0.81667 v_acc: 0.83789 |  iteration: 3260 teacher: 1 stage: sketch lr: 0.000569\n",
      "batch 774 loss: 0.26800 acc: 0.92285 | v_loss: 0.57420 v_acc: 0.88184 |  iteration: 3261 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 775 loss: 0.29658 acc: 0.91081 | v_loss: 0.56996 v_acc: 0.87728 |  iteration: 3262 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 776 loss: 0.29438 acc: 0.91927 | v_loss: 0.56128 v_acc: 0.88216 |  iteration: 3263 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 777 loss: 0.28908 acc: 0.91992 | v_loss: 0.44695 v_acc: 0.90658 |  iteration: 3264 teacher: 0 stage: sketch lr: 0.000570\n",
      "batch 778 loss: 0.32293 acc: 0.90332 | v_loss: 0.43387 v_acc: 0.89811 |  iteration: 3265 teacher: 0 stage: sketch lr: 0.000570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 779 loss: 0.33733 acc: 0.91081 | v_loss: 0.52486 v_acc: 0.89030 |  iteration: 3266 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 780 loss: 0.26601 acc: 0.91764 | v_loss: 0.63433 v_acc: 0.85254 |  iteration: 3267 teacher: 0 stage: sketch lr: 0.000571\n",
      "batch 781 loss: 0.29695 acc: 0.91504 | v_loss: 0.56921 v_acc: 0.88802 |  iteration: 3268 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 782 loss: 0.23866 acc: 0.92871 | v_loss: 0.62181 v_acc: 0.87793 |  iteration: 3269 teacher: 0 stage: sketch lr: 0.000571\n",
      "batch 783 loss: 0.21482 acc: 0.93913 | v_loss: 0.40401 v_acc: 0.90951 |  iteration: 3270 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 784 loss: 0.32002 acc: 0.91113 | v_loss: 0.52183 v_acc: 0.89160 |  iteration: 3271 teacher: 0 stage: sketch lr: 0.000571\n",
      "batch 785 loss: 0.33400 acc: 0.91276 | v_loss: 0.52869 v_acc: 0.88086 |  iteration: 3272 teacher: 0 stage: sketch lr: 0.000572\n",
      "batch 786 loss: 0.32658 acc: 0.90853 | v_loss: 0.89914 v_acc: 0.82650 |  iteration: 3273 teacher: 1 stage: sketch lr: 0.000572\n",
      "batch 787 loss: 0.23650 acc: 0.93587 | v_loss: 0.39794 v_acc: 0.91211 |  iteration: 3274 teacher: 1 stage: sketch lr: 0.000572\n",
      "batch 788 loss: 0.21791 acc: 0.93815 | v_loss: 0.34146 v_acc: 0.92025 |  iteration: 3275 teacher: 1 stage: sketch lr: 0.000572\n",
      "batch 789 loss: 0.21060 acc: 0.93783 | v_loss: 0.59056 v_acc: 0.89128 |  iteration: 3276 teacher: 0 stage: sketch lr: 0.000572\n",
      "batch 790 loss: 0.28655 acc: 0.91536 | v_loss: 0.60304 v_acc: 0.88607 |  iteration: 3277 teacher: 1 stage: sketch lr: 0.000572\n",
      "batch 791 loss: 0.35282 acc: 0.90788 | v_loss: 0.71722 v_acc: 0.86361 |  iteration: 3278 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 792 loss: 0.31957 acc: 0.91341 | v_loss: 0.43945 v_acc: 0.90527 |  iteration: 3279 teacher: 1 stage: sketch lr: 0.000573\n",
      "batch 793 loss: 0.24344 acc: 0.93522 | v_loss: 0.55525 v_acc: 0.87467 |  iteration: 3280 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 794 loss: 0.27836 acc: 0.92057 | v_loss: 0.65026 v_acc: 0.86393 |  iteration: 3281 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 795 loss: 0.32675 acc: 0.91146 | v_loss: 0.68503 v_acc: 0.84831 |  iteration: 3282 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 796 loss: 0.29157 acc: 0.91829 | v_loss: 0.50928 v_acc: 0.89258 |  iteration: 3283 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 797 loss: 0.20856 acc: 0.94043 | v_loss: 0.37452 v_acc: 0.89941 |  iteration: 3284 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 798 loss: 0.23166 acc: 0.92839 | v_loss: 0.31446 v_acc: 0.91732 |  iteration: 3285 teacher: 0 stage: sketch lr: 0.000574\n",
      "batch 799 loss: 0.32509 acc: 0.90788 | v_loss: 0.43581 v_acc: 0.90397 |  iteration: 3286 teacher: 0 stage: sketch lr: 0.000574\n",
      "batch 800 loss: 0.28967 acc: 0.91309 | v_loss: 0.50010 v_acc: 0.88444 |  iteration: 3287 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 801 loss: 0.29038 acc: 0.91634 | v_loss: 0.84575 v_acc: 0.85319 |  iteration: 3288 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 802 loss: 0.31008 acc: 0.90983 | v_loss: 0.56706 v_acc: 0.88314 |  iteration: 3289 teacher: 0 stage: sketch lr: 0.000575\n",
      "batch 803 loss: 0.35294 acc: 0.90397 | v_loss: 0.68854 v_acc: 0.86556 |  iteration: 3290 teacher: 0 stage: sketch lr: 0.000575\n",
      "batch 804 loss: 0.27441 acc: 0.91829 | v_loss: 0.42583 v_acc: 0.89746 |  iteration: 3291 teacher: 1 stage: sketch lr: 0.000575\n",
      "batch 805 loss: 0.29321 acc: 0.91309 | v_loss: 0.56073 v_acc: 0.87663 |  iteration: 3292 teacher: 1 stage: sketch lr: 0.000575\n",
      "batch 806 loss: 0.25167 acc: 0.92480 | v_loss: 0.75381 v_acc: 0.84668 |  iteration: 3293 teacher: 0 stage: sketch lr: 0.000575\n",
      "batch 807 loss: 0.28999 acc: 0.91243 | v_loss: 0.51615 v_acc: 0.88835 |  iteration: 3294 teacher: 1 stage: sketch lr: 0.000575\n",
      "batch 808 loss: 0.27399 acc: 0.90918 | v_loss: 0.55253 v_acc: 0.88932 |  iteration: 3295 teacher: 0 stage: sketch lr: 0.000576\n",
      "batch 809 loss: 0.26223 acc: 0.93620 | v_loss: 0.48884 v_acc: 0.89160 |  iteration: 3296 teacher: 1 stage: sketch lr: 0.000576\n",
      "batch 810 loss: 0.29851 acc: 0.91276 | v_loss: 0.44013 v_acc: 0.90430 |  iteration: 3297 teacher: 0 stage: sketch lr: 0.000576\n",
      "batch 811 loss: 0.23988 acc: 0.92839 | v_loss: 0.47674 v_acc: 0.90332 |  iteration: 3298 teacher: 1 stage: sketch lr: 0.000576\n",
      "batch 812 loss: 0.21013 acc: 0.94108 | v_loss: 0.61859 v_acc: 0.86882 |  iteration: 3299 teacher: 0 stage: sketch lr: 0.000576\n",
      "batch 813 loss: 0.35197 acc: 0.90299 | v_loss: 0.36954 v_acc: 0.92383 |  iteration: 3300 teacher: 1 stage: sketch lr: 0.000576\n",
      "batch 814 loss: 0.25736 acc: 0.93099 | v_loss: 0.96205 v_acc: 0.82878 |  iteration: 3301 teacher: 1 stage: sketch lr: 0.000577\n",
      "batch 815 loss: 0.31592 acc: 0.91764 | v_loss: 0.61848 v_acc: 0.88184 |  iteration: 3302 teacher: 1 stage: sketch lr: 0.000577\n",
      "batch 816 loss: 0.33540 acc: 0.90267 | v_loss: 0.68174 v_acc: 0.85612 |  iteration: 3303 teacher: 0 stage: sketch lr: 0.000577\n",
      "batch 817 loss: 0.26823 acc: 0.92090 | v_loss: 0.53342 v_acc: 0.89486 |  iteration: 3304 teacher: 1 stage: sketch lr: 0.000577\n",
      "batch 818 loss: 0.35970 acc: 0.89323 | v_loss: 0.48665 v_acc: 0.89518 |  iteration: 3305 teacher: 0 stage: sketch lr: 0.000577\n",
      "batch 819 loss: 0.20925 acc: 0.93978 | v_loss: 0.59283 v_acc: 0.88607 |  iteration: 3306 teacher: 1 stage: sketch lr: 0.000578\n",
      "batch 820 loss: 0.23664 acc: 0.93522 | v_loss: 0.55189 v_acc: 0.89193 |  iteration: 3307 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 821 loss: 0.31896 acc: 0.91309 | v_loss: 0.54766 v_acc: 0.89355 |  iteration: 3308 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 822 loss: 0.32965 acc: 0.91146 | v_loss: 0.51446 v_acc: 0.90853 |  iteration: 3309 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 823 loss: 0.21861 acc: 0.93392 | v_loss: 0.47054 v_acc: 0.90169 |  iteration: 3310 teacher: 1 stage: sketch lr: 0.000578\n",
      "batch 824 loss: 0.32720 acc: 0.91211 | v_loss: 0.35534 v_acc: 0.91667 |  iteration: 3311 teacher: 1 stage: sketch lr: 0.000578\n",
      "batch 825 loss: 0.32570 acc: 0.91016 | v_loss: 0.65569 v_acc: 0.87272 |  iteration: 3312 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 826 loss: 0.30688 acc: 0.91732 | v_loss: 0.58555 v_acc: 0.86328 |  iteration: 3313 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 827 loss: 0.32235 acc: 0.91048 | v_loss: 0.55256 v_acc: 0.87663 |  iteration: 3314 teacher: 0 stage: sketch lr: 0.000579\n",
      "batch 828 loss: 0.26436 acc: 0.91536 | v_loss: 0.83833 v_acc: 0.83724 |  iteration: 3315 teacher: 0 stage: sketch lr: 0.000579\n",
      "batch 829 loss: 0.24702 acc: 0.92513 | v_loss: 0.41414 v_acc: 0.90983 |  iteration: 3316 teacher: 0 stage: sketch lr: 0.000579\n",
      "batch 830 loss: 0.25523 acc: 0.93197 | v_loss: 0.56321 v_acc: 0.88118 |  iteration: 3317 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 831 loss: 0.28552 acc: 0.91895 | v_loss: 0.54006 v_acc: 0.89095 |  iteration: 3318 teacher: 0 stage: sketch lr: 0.000580\n",
      "batch 832 loss: 0.23238 acc: 0.93099 | v_loss: 0.41172 v_acc: 0.90885 |  iteration: 3319 teacher: 1 stage: sketch lr: 0.000580\n",
      "batch 833 loss: 0.33104 acc: 0.90365 | v_loss: 1.09321 v_acc: 0.81087 |  iteration: 3320 teacher: 0 stage: sketch lr: 0.000580\n",
      "batch 834 loss: 0.20969 acc: 0.93522 | v_loss: 0.40024 v_acc: 0.91276 |  iteration: 3321 teacher: 0 stage: sketch lr: 0.000580\n",
      "batch 835 loss: 0.26080 acc: 0.91992 | v_loss: 0.58164 v_acc: 0.87695 |  iteration: 3322 teacher: 0 stage: sketch lr: 0.000580\n",
      "batch 836 loss: 0.27597 acc: 0.91862 | v_loss: 0.48855 v_acc: 0.89583 |  iteration: 3323 teacher: 1 stage: sketch lr: 0.000581\n",
      "batch 837 loss: 0.33902 acc: 0.89648 | v_loss: 0.40727 v_acc: 0.91146 |  iteration: 3324 teacher: 1 stage: sketch lr: 0.000581\n",
      "batch 838 loss: 0.25880 acc: 0.92611 | v_loss: 0.53085 v_acc: 0.88249 |  iteration: 3325 teacher: 1 stage: sketch lr: 0.000581\n",
      "batch 839 loss: 0.31494 acc: 0.91667 | v_loss: 0.58664 v_acc: 0.88184 |  iteration: 3326 teacher: 1 stage: sketch lr: 0.000581\n",
      "batch 840 loss: 0.27851 acc: 0.92188 | v_loss: 0.43769 v_acc: 0.90983 |  iteration: 3327 teacher: 1 stage: sketch lr: 0.000581\n",
      "batch 841 loss: 0.25638 acc: 0.92546 | v_loss: 0.60127 v_acc: 0.88086 |  iteration: 3328 teacher: 1 stage: sketch lr: 0.000581\n",
      "batch 842 loss: 0.32358 acc: 0.91341 | v_loss: 0.40908 v_acc: 0.90267 |  iteration: 3329 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 843 loss: 0.27017 acc: 0.93001 | v_loss: 0.96201 v_acc: 0.82227 |  iteration: 3330 teacher: 0 stage: sketch lr: 0.000582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 844 loss: 0.32624 acc: 0.90397 | v_loss: 0.53033 v_acc: 0.88835 |  iteration: 3331 teacher: 0 stage: sketch lr: 0.000582\n",
      "batch 845 loss: 0.31491 acc: 0.90560 | v_loss: 0.65073 v_acc: 0.86751 |  iteration: 3332 teacher: 0 stage: sketch lr: 0.000582\n",
      "batch 846 loss: 0.27675 acc: 0.91829 | v_loss: 0.41342 v_acc: 0.89290 |  iteration: 3333 teacher: 0 stage: sketch lr: 0.000582\n",
      "batch 847 loss: 0.34691 acc: 0.90365 | v_loss: 0.64761 v_acc: 0.85579 |  iteration: 3334 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 848 loss: 0.31126 acc: 0.90788 | v_loss: 0.42502 v_acc: 0.90202 |  iteration: 3335 teacher: 0 stage: sketch lr: 0.000583\n",
      "batch 849 loss: 0.29528 acc: 0.91667 | v_loss: 0.47263 v_acc: 0.88574 |  iteration: 3336 teacher: 0 stage: sketch lr: 0.000583\n",
      "batch 850 loss: 0.27562 acc: 0.92546 | v_loss: 0.41858 v_acc: 0.89486 |  iteration: 3337 teacher: 0 stage: sketch lr: 0.000583\n",
      "batch 851 loss: 0.24401 acc: 0.92936 | v_loss: 0.74132 v_acc: 0.85091 |  iteration: 3338 teacher: 0 stage: sketch lr: 0.000583\n",
      "batch 852 loss: 0.30396 acc: 0.91927 | v_loss: 0.55552 v_acc: 0.89551 |  iteration: 3339 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 853 loss: 0.33857 acc: 0.90723 | v_loss: 0.55222 v_acc: 0.88151 |  iteration: 3340 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 854 loss: 0.27378 acc: 0.92415 | v_loss: 0.68648 v_acc: 0.85189 |  iteration: 3341 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 855 loss: 0.30986 acc: 0.91732 | v_loss: 0.46495 v_acc: 0.89258 |  iteration: 3342 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 856 loss: 0.30436 acc: 0.91309 | v_loss: 0.51507 v_acc: 0.86914 |  iteration: 3343 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 857 loss: 0.32492 acc: 0.90723 | v_loss: 0.54598 v_acc: 0.87207 |  iteration: 3344 teacher: 1 stage: sketch lr: 0.000584\n",
      "batch 858 loss: 0.31126 acc: 0.90658 | v_loss: 0.69199 v_acc: 0.85352 |  iteration: 3345 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 859 loss: 0.33159 acc: 0.89518 | v_loss: 0.54994 v_acc: 0.88607 |  iteration: 3346 teacher: 0 stage: sketch lr: 0.000585\n",
      "batch 860 loss: 0.38185 acc: 0.88997 | v_loss: 0.57434 v_acc: 0.87435 |  iteration: 3347 teacher: 0 stage: sketch lr: 0.000585\n",
      "batch 861 loss: 0.24543 acc: 0.92741 | v_loss: 0.60000 v_acc: 0.88411 |  iteration: 3348 teacher: 1 stage: sketch lr: 0.000585\n",
      "batch 862 loss: 0.29851 acc: 0.91341 | v_loss: 0.58838 v_acc: 0.86133 |  iteration: 3349 teacher: 1 stage: sketch lr: 0.000585\n",
      "batch 863 loss: 0.16411 acc: 0.95020 | v_loss: 0.46812 v_acc: 0.89714 |  iteration: 3350 teacher: 0 stage: sketch lr: 0.000585\n",
      "batch 864 loss: 0.28959 acc: 0.91764 | v_loss: 0.82938 v_acc: 0.83952 |  iteration: 3351 teacher: 1 stage: sketch lr: 0.000585\n",
      "batch 865 loss: 0.24824 acc: 0.92546 | v_loss: 0.60533 v_acc: 0.88542 |  iteration: 3352 teacher: 1 stage: sketch lr: 0.000586\n",
      "batch 866 loss: 0.25984 acc: 0.93132 | v_loss: 0.55312 v_acc: 0.87500 |  iteration: 3353 teacher: 1 stage: sketch lr: 0.000586\n",
      "batch 867 loss: 0.25731 acc: 0.92839 | v_loss: 0.56312 v_acc: 0.88216 |  iteration: 3354 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 868 loss: 0.25369 acc: 0.93001 | v_loss: 0.46431 v_acc: 0.89551 |  iteration: 3355 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 869 loss: 0.25592 acc: 0.91764 | v_loss: 0.45623 v_acc: 0.89583 |  iteration: 3356 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 870 loss: 0.27039 acc: 0.91406 | v_loss: 0.49863 v_acc: 0.88542 |  iteration: 3357 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 871 loss: 0.19846 acc: 0.93978 | v_loss: 0.60815 v_acc: 0.85417 |  iteration: 3358 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 872 loss: 0.32241 acc: 0.89714 | v_loss: 0.59076 v_acc: 0.88477 |  iteration: 3359 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 873 loss: 0.30487 acc: 0.90788 | v_loss: 0.60477 v_acc: 0.88477 |  iteration: 3360 teacher: 1 stage: sketch lr: 0.000587\n",
      "batch 874 loss: 0.23522 acc: 0.92643 | v_loss: 0.36524 v_acc: 0.91081 |  iteration: 3361 teacher: 1 stage: sketch lr: 0.000587\n",
      "batch 875 loss: 0.30363 acc: 0.91471 | v_loss: 0.55993 v_acc: 0.88151 |  iteration: 3362 teacher: 1 stage: sketch lr: 0.000587\n",
      "batch 876 loss: 0.23804 acc: 0.93001 | v_loss: 0.52833 v_acc: 0.88542 |  iteration: 3363 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 877 loss: 0.32173 acc: 0.91439 | v_loss: 0.93628 v_acc: 0.82194 |  iteration: 3364 teacher: 1 stage: sketch lr: 0.000588\n",
      "batch 878 loss: 0.21837 acc: 0.93685 | v_loss: 0.40395 v_acc: 0.90365 |  iteration: 3365 teacher: 1 stage: sketch lr: 0.000588\n",
      "batch 879 loss: 0.29568 acc: 0.91439 | v_loss: 0.33448 v_acc: 0.92741 |  iteration: 3366 teacher: 1 stage: sketch lr: 0.000588\n",
      "batch 880 loss: 0.26610 acc: 0.91504 | v_loss: 0.60617 v_acc: 0.88346 |  iteration: 3367 teacher: 0 stage: sketch lr: 0.000588\n",
      "batch 881 loss: 0.24032 acc: 0.93034 | v_loss: 0.60118 v_acc: 0.88151 |  iteration: 3368 teacher: 0 stage: sketch lr: 0.000588\n",
      "batch 882 loss: 0.23568 acc: 0.92936 | v_loss: 0.68129 v_acc: 0.86458 |  iteration: 3369 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 883 loss: 0.27581 acc: 0.92350 | v_loss: 0.46013 v_acc: 0.90039 |  iteration: 3370 teacher: 1 stage: sketch lr: 0.000589\n",
      "batch 884 loss: 0.27763 acc: 0.92090 | v_loss: 0.52817 v_acc: 0.87533 |  iteration: 3371 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 885 loss: 0.25165 acc: 0.93164 | v_loss: 0.60532 v_acc: 0.86686 |  iteration: 3372 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 886 loss: 0.23051 acc: 0.93717 | v_loss: 0.64723 v_acc: 0.85547 |  iteration: 3373 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 887 loss: 0.33038 acc: 0.91341 | v_loss: 0.49494 v_acc: 0.89811 |  iteration: 3374 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 888 loss: 0.27299 acc: 0.92676 | v_loss: 0.35614 v_acc: 0.91243 |  iteration: 3375 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 889 loss: 0.25463 acc: 0.92643 | v_loss: 0.28327 v_acc: 0.92057 |  iteration: 3376 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 890 loss: 0.23606 acc: 0.92839 | v_loss: 0.47832 v_acc: 0.89583 |  iteration: 3377 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 891 loss: 0.27016 acc: 0.91732 | v_loss: 0.51323 v_acc: 0.88672 |  iteration: 3378 teacher: 0 stage: sketch lr: 0.000590\n",
      "batch 892 loss: 0.29963 acc: 0.91406 | v_loss: 0.80090 v_acc: 0.85612 |  iteration: 3379 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 893 loss: 0.27507 acc: 0.92546 | v_loss: 0.57129 v_acc: 0.88314 |  iteration: 3380 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 894 loss: 0.33811 acc: 0.90658 | v_loss: 0.68005 v_acc: 0.87077 |  iteration: 3381 teacher: 1 stage: sketch lr: 0.000591\n",
      "batch 895 loss: 0.23251 acc: 0.92839 | v_loss: 0.44053 v_acc: 0.90039 |  iteration: 3382 teacher: 1 stage: sketch lr: 0.000591\n",
      "batch 896 loss: 0.27631 acc: 0.92839 | v_loss: 0.56556 v_acc: 0.88346 |  iteration: 3383 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 897 loss: 0.31643 acc: 0.92253 | v_loss: 0.79281 v_acc: 0.84342 |  iteration: 3384 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 898 loss: 0.27198 acc: 0.91960 | v_loss: 0.51608 v_acc: 0.88509 |  iteration: 3385 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 899 loss: 0.36530 acc: 0.90137 | v_loss: 0.51974 v_acc: 0.88704 |  iteration: 3386 teacher: 0 stage: sketch lr: 0.000592\n",
      "batch 900 loss: 0.25509 acc: 0.92708 | v_loss: 0.50626 v_acc: 0.88737 |  iteration: 3387 teacher: 1 stage: sketch lr: 0.000592\n",
      "batch 901 loss: 0.21824 acc: 0.93620 | v_loss: 0.44475 v_acc: 0.89941 |  iteration: 3388 teacher: 1 stage: sketch lr: 0.000592\n",
      "batch 902 loss: 0.39982 acc: 0.89746 | v_loss: 0.50025 v_acc: 0.89453 |  iteration: 3389 teacher: 1 stage: sketch lr: 0.000592\n",
      "batch 903 loss: 0.26865 acc: 0.91699 | v_loss: 0.57589 v_acc: 0.86361 |  iteration: 3390 teacher: 0 stage: sketch lr: 0.000592\n",
      "batch 904 loss: 0.30608 acc: 0.91048 | v_loss: 0.37601 v_acc: 0.91536 |  iteration: 3391 teacher: 0 stage: sketch lr: 0.000592\n",
      "batch 905 loss: 0.30499 acc: 0.91081 | v_loss: 0.92730 v_acc: 0.82161 |  iteration: 3392 teacher: 0 stage: sketch lr: 0.000593\n",
      "batch 906 loss: 0.20459 acc: 0.93099 | v_loss: 0.64545 v_acc: 0.87240 |  iteration: 3393 teacher: 1 stage: sketch lr: 0.000593\n",
      "batch 907 loss: 0.27524 acc: 0.91992 | v_loss: 0.75428 v_acc: 0.85482 |  iteration: 3394 teacher: 1 stage: sketch lr: 0.000593\n",
      "batch 908 loss: 0.27612 acc: 0.92383 | v_loss: 0.55482 v_acc: 0.89323 |  iteration: 3395 teacher: 1 stage: sketch lr: 0.000593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 909 loss: 0.23153 acc: 0.93229 | v_loss: 0.50365 v_acc: 0.89876 |  iteration: 3396 teacher: 1 stage: sketch lr: 0.000593\n",
      "batch 910 loss: 0.27747 acc: 0.91895 | v_loss: 0.61199 v_acc: 0.88932 |  iteration: 3397 teacher: 1 stage: sketch lr: 0.000593\n",
      "batch 911 loss: 0.26202 acc: 0.92611 | v_loss: 0.52440 v_acc: 0.89355 |  iteration: 3398 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 912 loss: 0.27956 acc: 0.92513 | v_loss: 0.49123 v_acc: 0.89681 |  iteration: 3399 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 913 loss: 0.35323 acc: 0.90527 | v_loss: 0.51158 v_acc: 0.89974 |  iteration: 3400 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 914 loss: 0.27578 acc: 0.92285 | v_loss: 0.42613 v_acc: 0.90267 |  iteration: 3401 teacher: 0 stage: sketch lr: 0.000594\n",
      "batch 915 loss: 0.27309 acc: 0.92253 | v_loss: 0.34399 v_acc: 0.92318 |  iteration: 3402 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 916 loss: 0.22345 acc: 0.93164 | v_loss: 0.63107 v_acc: 0.86816 |  iteration: 3403 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 917 loss: 0.25597 acc: 0.92806 | v_loss: 0.57029 v_acc: 0.86523 |  iteration: 3404 teacher: 1 stage: sketch lr: 0.000595\n",
      "batch 918 loss: 0.30610 acc: 0.91113 | v_loss: 0.63693 v_acc: 0.86654 |  iteration: 3405 teacher: 1 stage: sketch lr: 0.000595\n",
      "batch 919 loss: 0.27214 acc: 0.92318 | v_loss: 0.82553 v_acc: 0.84212 |  iteration: 3406 teacher: 0 stage: sketch lr: 0.000595\n",
      "batch 920 loss: 0.23300 acc: 0.93262 | v_loss: 0.50838 v_acc: 0.89941 |  iteration: 3407 teacher: 1 stage: sketch lr: 0.000595\n",
      "batch 921 loss: 0.33302 acc: 0.90234 | v_loss: 0.57711 v_acc: 0.87988 |  iteration: 3408 teacher: 1 stage: sketch lr: 0.000595\n",
      "batch 922 loss: 0.30142 acc: 0.91439 | v_loss: 0.55067 v_acc: 0.88965 |  iteration: 3409 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 923 loss: 0.19098 acc: 0.94173 | v_loss: 0.42684 v_acc: 0.91178 |  iteration: 3410 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 924 loss: 0.29493 acc: 0.91406 | v_loss: 1.20777 v_acc: 0.80436 |  iteration: 3411 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 925 loss: 0.23283 acc: 0.93001 | v_loss: 0.36615 v_acc: 0.92057 |  iteration: 3412 teacher: 0 stage: sketch lr: 0.000596\n",
      "batch 926 loss: 0.26450 acc: 0.92578 | v_loss: 0.61453 v_acc: 0.87988 |  iteration: 3413 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 927 loss: 0.30857 acc: 0.91374 | v_loss: 0.57377 v_acc: 0.88411 |  iteration: 3414 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 928 loss: 0.25002 acc: 0.93392 | v_loss: 0.44564 v_acc: 0.90169 |  iteration: 3415 teacher: 1 stage: sketch lr: 0.000597\n",
      "batch 929 loss: 0.37135 acc: 0.90202 | v_loss: 0.52917 v_acc: 0.88477 |  iteration: 3416 teacher: 1 stage: sketch lr: 0.000597\n",
      "batch 930 loss: 0.22871 acc: 0.93392 | v_loss: 0.58597 v_acc: 0.87044 |  iteration: 3417 teacher: 1 stage: sketch lr: 0.000597\n",
      "batch 931 loss: 0.24899 acc: 0.92155 | v_loss: 0.45212 v_acc: 0.89974 |  iteration: 3418 teacher: 1 stage: sketch lr: 0.000597\n",
      "batch 932 loss: 0.38403 acc: 0.89062 | v_loss: 0.64362 v_acc: 0.86523 |  iteration: 3419 teacher: 1 stage: sketch lr: 0.000597\n",
      "batch 933 loss: 0.26086 acc: 0.92643 | v_loss: 0.41598 v_acc: 0.90234 |  iteration: 3420 teacher: 1 stage: sketch lr: 0.000597\n",
      "batch 934 loss: 0.37094 acc: 0.89583 | v_loss: 0.98454 v_acc: 0.83073 |  iteration: 3421 teacher: 1 stage: sketch lr: 0.000598\n",
      "batch 935 loss: 0.30586 acc: 0.90853 | v_loss: 0.57316 v_acc: 0.88802 |  iteration: 3422 teacher: 1 stage: sketch lr: 0.000598\n",
      "batch 936 loss: 0.25942 acc: 0.92839 | v_loss: 0.67475 v_acc: 0.86654 |  iteration: 3423 teacher: 1 stage: sketch lr: 0.000598\n",
      "batch 937 loss: 0.29068 acc: 0.92611 | v_loss: 0.42335 v_acc: 0.90202 |  iteration: 3424 teacher: 0 stage: sketch lr: 0.000598\n",
      "batch 938 loss: 0.34496 acc: 0.90690 | v_loss: 0.67871 v_acc: 0.85286 |  iteration: 3425 teacher: 0 stage: sketch lr: 0.000598\n",
      "batch 939 loss: 0.31583 acc: 0.91471 | v_loss: 0.44590 v_acc: 0.89518 |  iteration: 3426 teacher: 0 stage: sketch lr: 0.000598\n",
      "batch 940 loss: 0.26293 acc: 0.91829 | v_loss: 0.44948 v_acc: 0.89518 |  iteration: 3427 teacher: 0 stage: sketch lr: 0.000599\n",
      "batch 941 loss: 0.28426 acc: 0.91178 | v_loss: 0.42740 v_acc: 0.89974 |  iteration: 3428 teacher: 0 stage: sketch lr: 0.000599\n",
      "batch 942 loss: 0.33491 acc: 0.90430 | v_loss: 0.70859 v_acc: 0.86165 |  iteration: 3429 teacher: 0 stage: sketch lr: 0.000599\n",
      "batch 943 loss: 0.32155 acc: 0.90625 | v_loss: 0.49780 v_acc: 0.90299 |  iteration: 3430 teacher: 0 stage: sketch lr: 0.000599\n",
      "batch 944 loss: 0.37454 acc: 0.89551 | v_loss: 0.51421 v_acc: 0.88249 |  iteration: 3431 teacher: 0 stage: sketch lr: 0.000599\n",
      "batch 945 loss: 0.27846 acc: 0.91602 | v_loss: 0.64818 v_acc: 0.86035 |  iteration: 3432 teacher: 0 stage: sketch lr: 0.000600\n",
      "batch 946 loss: 0.29431 acc: 0.91211 | v_loss: 0.44846 v_acc: 0.89551 |  iteration: 3433 teacher: 0 stage: sketch lr: 0.000600\n",
      "batch 947 loss: 0.35563 acc: 0.90039 | v_loss: 0.51739 v_acc: 0.87337 |  iteration: 3434 teacher: 1 stage: sketch lr: 0.000600\n",
      "batch 948 loss: 0.30422 acc: 0.91504 | v_loss: 0.56311 v_acc: 0.87402 |  iteration: 3435 teacher: 1 stage: sketch lr: 0.000600\n",
      "batch 949 loss: 0.38194 acc: 0.90039 | v_loss: 0.78720 v_acc: 0.86133 |  iteration: 3436 teacher: 1 stage: sketch lr: 0.000600\n",
      "batch 950 loss: 0.28487 acc: 0.91569 | v_loss: 0.53753 v_acc: 0.89160 |  iteration: 3437 teacher: 0 stage: sketch lr: 0.000600\n",
      "batch 951 loss: 0.28658 acc: 0.91960 | v_loss: 0.57914 v_acc: 0.88509 |  iteration: 3438 teacher: 0 stage: sketch lr: 0.000601\n",
      "batch 952 loss: 0.33094 acc: 0.90690 | v_loss: 0.62008 v_acc: 0.88281 |  iteration: 3439 teacher: 0 stage: sketch lr: 0.000601\n",
      "batch 953 loss: 0.21538 acc: 0.93359 | v_loss: 0.61180 v_acc: 0.85482 |  iteration: 3440 teacher: 0 stage: sketch lr: 0.000601\n",
      "batch 954 loss: 0.27689 acc: 0.91569 | v_loss: 0.43156 v_acc: 0.90788 |  iteration: 3441 teacher: 0 stage: sketch lr: 0.000601\n",
      "batch 955 loss: 0.29231 acc: 0.91569 | v_loss: 0.73351 v_acc: 0.84766 |  iteration: 3442 teacher: 0 stage: sketch lr: 0.000601\n",
      "batch 956 loss: 0.27884 acc: 0.92057 | v_loss: 0.58290 v_acc: 0.87630 |  iteration: 3443 teacher: 0 stage: sketch lr: 0.000601\n",
      "batch 957 loss: 0.36894 acc: 0.89844 | v_loss: 0.57986 v_acc: 0.87858 |  iteration: 3444 teacher: 1 stage: sketch lr: 0.000602\n",
      "batch 958 loss: 0.34306 acc: 0.89974 | v_loss: 0.57019 v_acc: 0.87272 |  iteration: 3445 teacher: 1 stage: sketch lr: 0.000602\n",
      "batch 959 loss: 0.23616 acc: 0.93066 | v_loss: 0.46943 v_acc: 0.89941 |  iteration: 3446 teacher: 0 stage: sketch lr: 0.000602\n",
      "batch 960 loss: 0.23457 acc: 0.93294 | v_loss: 0.48406 v_acc: 0.89518 |  iteration: 3447 teacher: 0 stage: sketch lr: 0.000602\n",
      "batch 961 loss: 0.25038 acc: 0.92513 | v_loss: 0.51794 v_acc: 0.89388 |  iteration: 3448 teacher: 0 stage: sketch lr: 0.000602\n",
      "batch 962 loss: 0.27328 acc: 0.92415 | v_loss: 0.65692 v_acc: 0.85156 |  iteration: 3449 teacher: 0 stage: sketch lr: 0.000603\n",
      "batch 963 loss: 0.25395 acc: 0.92383 | v_loss: 0.54231 v_acc: 0.88932 |  iteration: 3450 teacher: 0 stage: sketch lr: 0.000603\n",
      "batch 964 loss: 0.29506 acc: 0.91276 | v_loss: 0.61250 v_acc: 0.87923 |  iteration: 3451 teacher: 1 stage: sketch lr: 0.000603\n",
      "batch 965 loss: 0.21751 acc: 0.93424 | v_loss: 0.38058 v_acc: 0.90625 |  iteration: 3452 teacher: 1 stage: sketch lr: 0.000603\n",
      "batch 966 loss: 0.21245 acc: 0.93197 | v_loss: 0.51206 v_acc: 0.88379 |  iteration: 3453 teacher: 1 stage: sketch lr: 0.000603\n",
      "batch 967 loss: 0.33462 acc: 0.91211 | v_loss: 0.53931 v_acc: 0.86816 |  iteration: 3454 teacher: 1 stage: sketch lr: 0.000603\n",
      "batch 968 loss: 0.26650 acc: 0.92090 | v_loss: 0.89266 v_acc: 0.82357 |  iteration: 3455 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 969 loss: 0.35669 acc: 0.90104 | v_loss: 0.38322 v_acc: 0.90397 |  iteration: 3456 teacher: 1 stage: sketch lr: 0.000604\n",
      "batch 970 loss: 0.24269 acc: 0.92448 | v_loss: 0.31084 v_acc: 0.92676 |  iteration: 3457 teacher: 1 stage: sketch lr: 0.000604\n",
      "batch 971 loss: 0.30496 acc: 0.91178 | v_loss: 0.60907 v_acc: 0.88021 |  iteration: 3458 teacher: 1 stage: sketch lr: 0.000604\n",
      "batch 972 loss: 0.32233 acc: 0.91016 | v_loss: 0.60012 v_acc: 0.88151 |  iteration: 3459 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 973 loss: 0.20013 acc: 0.93783 | v_loss: 0.68818 v_acc: 0.85482 |  iteration: 3460 teacher: 0 stage: sketch lr: 0.000604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 974 loss: 0.34477 acc: 0.89876 | v_loss: 0.41821 v_acc: 0.90397 |  iteration: 3461 teacher: 0 stage: sketch lr: 0.000605\n",
      "batch 975 loss: 0.25187 acc: 0.92546 | v_loss: 0.54970 v_acc: 0.87370 |  iteration: 3462 teacher: 0 stage: sketch lr: 0.000605\n",
      "batch 976 loss: 0.27795 acc: 0.92188 | v_loss: 0.60102 v_acc: 0.86947 |  iteration: 3463 teacher: 0 stage: sketch lr: 0.000605\n",
      "batch 977 loss: 0.23447 acc: 0.92904 | v_loss: 0.69268 v_acc: 0.85026 |  iteration: 3464 teacher: 0 stage: sketch lr: 0.000605\n",
      "batch 978 loss: 0.32514 acc: 0.90918 | v_loss: 0.51097 v_acc: 0.89193 |  iteration: 3465 teacher: 0 stage: sketch lr: 0.000605\n",
      "batch 979 loss: 0.28680 acc: 0.91699 | v_loss: 0.38748 v_acc: 0.90755 |  iteration: 3466 teacher: 1 stage: sketch lr: 0.000605\n",
      "batch 980 loss: 0.32433 acc: 0.90592 | v_loss: 0.31063 v_acc: 0.91764 |  iteration: 3467 teacher: 0 stage: sketch lr: 0.000606\n",
      "batch 981 loss: 0.33419 acc: 0.90723 | v_loss: 0.46862 v_acc: 0.89876 |  iteration: 3468 teacher: 1 stage: sketch lr: 0.000606\n",
      "batch 982 loss: 0.27356 acc: 0.92025 | v_loss: 0.55144 v_acc: 0.87598 |  iteration: 3469 teacher: 1 stage: sketch lr: 0.000606\n",
      "batch 983 loss: 0.30696 acc: 0.91797 | v_loss: 0.83418 v_acc: 0.84831 |  iteration: 3470 teacher: 1 stage: sketch lr: 0.000606\n",
      "batch 984 loss: 0.23210 acc: 0.93327 | v_loss: 0.54852 v_acc: 0.87370 |  iteration: 3471 teacher: 1 stage: sketch lr: 0.000606\n",
      "batch 985 loss: 0.24711 acc: 0.92643 | v_loss: 0.66420 v_acc: 0.86686 |  iteration: 3472 teacher: 1 stage: sketch lr: 0.000607\n",
      "batch 986 loss: 0.33551 acc: 0.91243 | v_loss: 0.43951 v_acc: 0.89323 |  iteration: 3473 teacher: 1 stage: sketch lr: 0.000607\n",
      "batch 987 loss: 0.35757 acc: 0.89909 | v_loss: 0.52558 v_acc: 0.88086 |  iteration: 3474 teacher: 0 stage: sketch lr: 0.000607\n",
      "batch 988 loss: 0.32541 acc: 0.90755 | v_loss: 0.87281 v_acc: 0.82129 |  iteration: 3475 teacher: 1 stage: sketch lr: 0.000607\n",
      "batch 989 loss: 0.24580 acc: 0.93132 | v_loss: 0.51429 v_acc: 0.88411 |  iteration: 3476 teacher: 0 stage: sketch lr: 0.000607\n",
      "batch 990 loss: 0.37469 acc: 0.90039 | v_loss: 0.53855 v_acc: 0.88770 |  iteration: 3477 teacher: 1 stage: sketch lr: 0.000607\n",
      "batch 991 loss: 0.26740 acc: 0.91764 | v_loss: 0.49227 v_acc: 0.87956 |  iteration: 3478 teacher: 1 stage: sketch lr: 0.000608\n",
      "batch 992 loss: 0.26285 acc: 0.93359 | v_loss: 0.44822 v_acc: 0.90104 |  iteration: 3479 teacher: 1 stage: sketch lr: 0.000608\n",
      "batch 993 loss: 0.27001 acc: 0.91699 | v_loss: 0.48500 v_acc: 0.89779 |  iteration: 3480 teacher: 1 stage: sketch lr: 0.000608\n",
      "batch 994 loss: 0.26950 acc: 0.92188 | v_loss: 0.62656 v_acc: 0.86133 |  iteration: 3481 teacher: 1 stage: sketch lr: 0.000608\n",
      "batch 995 loss: 0.34413 acc: 0.89551 | v_loss: 0.39286 v_acc: 0.91667 |  iteration: 3482 teacher: 0 stage: sketch lr: 0.000608\n",
      "batch 996 loss: 0.31443 acc: 0.90755 | v_loss: 0.97085 v_acc: 0.82617 |  iteration: 3483 teacher: 0 stage: sketch lr: 0.000608\n",
      "batch 997 loss: 0.24681 acc: 0.92741 | v_loss: 0.65639 v_acc: 0.87109 |  iteration: 3484 teacher: 0 stage: sketch lr: 0.000609\n",
      "batch 998 loss: 0.38350 acc: 0.89421 | v_loss: 0.65961 v_acc: 0.86523 |  iteration: 3485 teacher: 1 stage: sketch lr: 0.000609\n",
      "batch 999 loss: 0.25815 acc: 0.92871 | v_loss: 0.55141 v_acc: 0.88802 |  iteration: 3486 teacher: 1 stage: sketch lr: 0.000609\n",
      "batch 1000 loss: 0.28440 acc: 0.91471 | v_loss: 0.50624 v_acc: 0.89193 |  iteration: 3487 teacher: 1 stage: sketch lr: 0.000609\n",
      "batch 1001 loss: 0.21985 acc: 0.93652 | v_loss: 0.57153 v_acc: 0.87956 |  iteration: 3488 teacher: 1 stage: sketch lr: 0.000609\n",
      "batch 1002 loss: 0.26647 acc: 0.91895 | v_loss: 0.53614 v_acc: 0.88607 |  iteration: 3489 teacher: 1 stage: sketch lr: 0.000610\n",
      "batch 1003 loss: 0.30344 acc: 0.90365 | v_loss: 0.48835 v_acc: 0.89160 |  iteration: 3490 teacher: 1 stage: sketch lr: 0.000610\n",
      "batch 1004 loss: 0.25154 acc: 0.92643 | v_loss: 0.49755 v_acc: 0.90039 |  iteration: 3491 teacher: 0 stage: sketch lr: 0.000610\n",
      "batch 1005 loss: 0.37047 acc: 0.89681 | v_loss: 0.45878 v_acc: 0.89681 |  iteration: 3492 teacher: 1 stage: sketch lr: 0.000610\n",
      "batch 1006 loss: 0.28256 acc: 0.92318 | v_loss: 0.35915 v_acc: 0.92188 |  iteration: 3493 teacher: 1 stage: sketch lr: 0.000610\n",
      "batch 1007 loss: 0.29195 acc: 0.92350 | v_loss: 0.65092 v_acc: 0.86198 |  iteration: 3494 teacher: 0 stage: sketch lr: 0.000610\n",
      "batch 1008 loss: 0.32909 acc: 0.90137 | v_loss: 0.56087 v_acc: 0.86361 |  iteration: 3495 teacher: 0 stage: sketch lr: 0.000611\n",
      "batch 1009 loss: 0.23434 acc: 0.93652 | v_loss: 0.60518 v_acc: 0.85775 |  iteration: 3496 teacher: 1 stage: sketch lr: 0.000611\n",
      "batch 1010 loss: 0.36785 acc: 0.90202 | v_loss: 0.83386 v_acc: 0.84180 |  iteration: 3497 teacher: 1 stage: sketch lr: 0.000611\n",
      "batch 1011 loss: 0.27518 acc: 0.91862 | v_loss: 0.41632 v_acc: 0.90430 |  iteration: 3498 teacher: 0 stage: sketch lr: 0.000611\n",
      "batch 1012 loss: 0.21768 acc: 0.93392 | v_loss: 0.53925 v_acc: 0.87207 |  iteration: 3499 teacher: 1 stage: sketch lr: 0.000611\n",
      "batch 1013 loss: 0.41709 acc: 0.87858 | v_loss: 0.54577 v_acc: 0.89193 |  iteration: 3500 teacher: 1 stage: sketch lr: 0.000611\n",
      "batch 1014 loss: 0.27790 acc: 0.91341 | v_loss: 0.40138 v_acc: 0.91178 |  iteration: 3501 teacher: 1 stage: sketch lr: 0.000612\n",
      "batch 1015 loss: 0.32160 acc: 0.91374 | v_loss: 1.20918 v_acc: 0.81608 |  iteration: 3502 teacher: 1 stage: sketch lr: 0.000612\n",
      "batch 1016 loss: 0.27987 acc: 0.92448 | v_loss: 0.39047 v_acc: 0.92090 |  iteration: 3503 teacher: 0 stage: sketch lr: 0.000612\n",
      "batch 1017 loss: 0.30397 acc: 0.92318 | v_loss: 0.62305 v_acc: 0.87467 |  iteration: 3504 teacher: 0 stage: sketch lr: 0.000612\n",
      "batch 1018 loss: 0.31392 acc: 0.91895 | v_loss: 0.55021 v_acc: 0.89486 |  iteration: 3505 teacher: 0 stage: sketch lr: 0.000612\n",
      "batch 1019 loss: 0.26521 acc: 0.92708 | v_loss: 0.41688 v_acc: 0.90723 |  iteration: 3506 teacher: 1 stage: sketch lr: 0.000612\n",
      "batch 1020 loss: 0.29691 acc: 0.91895 | v_loss: 0.51367 v_acc: 0.88607 |  iteration: 3507 teacher: 1 stage: sketch lr: 0.000613\n",
      "batch 1021 loss: 0.25135 acc: 0.93001 | v_loss: 0.57082 v_acc: 0.88086 |  iteration: 3508 teacher: 0 stage: sketch lr: 0.000613\n",
      "batch 1022 loss: 0.33960 acc: 0.90723 | v_loss: 0.41685 v_acc: 0.90853 |  iteration: 3509 teacher: 1 stage: sketch lr: 0.000613\n",
      "batch 1023 loss: 0.29904 acc: 0.90885 | v_loss: 0.62604 v_acc: 0.87467 |  iteration: 3510 teacher: 1 stage: sketch lr: 0.000613\n",
      "batch 1024 loss: 0.23958 acc: 0.93164 | v_loss: 0.39651 v_acc: 0.90430 |  iteration: 3511 teacher: 1 stage: sketch lr: 0.000613\n",
      "batch 1025 loss: 0.30696 acc: 0.90918 | v_loss: 1.02356 v_acc: 0.83366 |  iteration: 3512 teacher: 0 stage: sketch lr: 0.000614\n",
      "batch 1026 loss: 0.18876 acc: 0.94401 | v_loss: 0.58596 v_acc: 0.88835 |  iteration: 3513 teacher: 1 stage: sketch lr: 0.000614\n",
      "batch 1027 loss: 0.26683 acc: 0.92546 | v_loss: 0.65555 v_acc: 0.87500 |  iteration: 3514 teacher: 1 stage: sketch lr: 0.000614\n",
      "batch 1028 loss: 0.31603 acc: 0.90397 | v_loss: 0.43984 v_acc: 0.90007 |  iteration: 3515 teacher: 1 stage: sketch lr: 0.000614\n",
      "batch 1029 loss: 0.24049 acc: 0.93164 | v_loss: 0.70220 v_acc: 0.84408 |  iteration: 3516 teacher: 1 stage: sketch lr: 0.000614\n",
      "batch 1030 loss: 0.30613 acc: 0.91048 | v_loss: 0.46336 v_acc: 0.88542 |  iteration: 3517 teacher: 0 stage: sketch lr: 0.000614\n",
      "batch 1031 loss: 0.32132 acc: 0.90690 | v_loss: 0.46325 v_acc: 0.88249 |  iteration: 3518 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 1032 loss: 0.39716 acc: 0.88704 | v_loss: 0.43163 v_acc: 0.88639 |  iteration: 3519 teacher: 0 stage: sketch lr: 0.000615\n",
      "batch 1033 loss: 0.26996 acc: 0.91829 | v_loss: 0.74572 v_acc: 0.84603 |  iteration: 3520 teacher: 0 stage: sketch lr: 0.000615\n",
      "batch 1034 loss: 0.34449 acc: 0.90853 | v_loss: 0.48696 v_acc: 0.90104 |  iteration: 3521 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 1035 loss: 0.30634 acc: 0.91504 | v_loss: 0.56567 v_acc: 0.88704 |  iteration: 3522 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 1036 loss: 0.34033 acc: 0.90820 | v_loss: 0.65577 v_acc: 0.85970 |  iteration: 3523 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 1037 loss: 0.32611 acc: 0.90560 | v_loss: 0.43418 v_acc: 0.90299 |  iteration: 3524 teacher: 0 stage: sketch lr: 0.000616\n",
      "batch 1038 loss: 0.29277 acc: 0.92220 | v_loss: 0.52474 v_acc: 0.86849 |  iteration: 3525 teacher: 0 stage: sketch lr: 0.000616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1039 loss: 0.27397 acc: 0.92350 | v_loss: 0.55685 v_acc: 0.86751 |  iteration: 3526 teacher: 0 stage: sketch lr: 0.000616\n",
      "batch 1040 loss: 0.27463 acc: 0.92155 | v_loss: 0.77255 v_acc: 0.84733 |  iteration: 3527 teacher: 0 stage: sketch lr: 0.000616\n",
      "batch 1041 loss: 0.28268 acc: 0.91569 | v_loss: 0.59494 v_acc: 0.88314 |  iteration: 3528 teacher: 1 stage: sketch lr: 0.000616\n",
      "batch 1042 loss: 0.31770 acc: 0.90951 | v_loss: 0.59203 v_acc: 0.88118 |  iteration: 3529 teacher: 0 stage: sketch lr: 0.000616\n",
      "batch 1043 loss: 0.28924 acc: 0.91927 | v_loss: 0.66956 v_acc: 0.87402 |  iteration: 3530 teacher: 1 stage: sketch lr: 0.000617\n",
      "batch 1044 loss: 0.30099 acc: 0.90625 | v_loss: 0.62483 v_acc: 0.85645 |  iteration: 3531 teacher: 0 stage: sketch lr: 0.000617\n",
      "batch 1045 loss: 0.32709 acc: 0.90202 | v_loss: 0.49533 v_acc: 0.89648 |  iteration: 3532 teacher: 0 stage: sketch lr: 0.000617\n",
      "batch 1046 loss: 0.30966 acc: 0.90853 | v_loss: 0.80642 v_acc: 0.83301 |  iteration: 3533 teacher: 0 stage: sketch lr: 0.000617\n",
      "batch 1047 loss: 0.28539 acc: 0.91341 | v_loss: 0.55937 v_acc: 0.87695 |  iteration: 3534 teacher: 0 stage: sketch lr: 0.000617\n",
      "batch 1048 loss: 0.18999 acc: 0.94076 | v_loss: 0.60993 v_acc: 0.87142 |  iteration: 3535 teacher: 1 stage: sketch lr: 0.000618\n",
      "batch 1049 loss: 0.34627 acc: 0.90625 | v_loss: 0.53785 v_acc: 0.87565 |  iteration: 3536 teacher: 0 stage: sketch lr: 0.000618\n",
      "batch 1050 loss: 0.32785 acc: 0.90658 | v_loss: 0.48102 v_acc: 0.89974 |  iteration: 3537 teacher: 0 stage: sketch lr: 0.000618\n",
      "batch 1051 loss: 0.33422 acc: 0.90234 | v_loss: 0.46993 v_acc: 0.89583 |  iteration: 3538 teacher: 0 stage: sketch lr: 0.000618\n",
      "batch 1052 loss: 0.24229 acc: 0.93652 | v_loss: 0.51667 v_acc: 0.88802 |  iteration: 3539 teacher: 1 stage: sketch lr: 0.000618\n",
      "batch 1053 loss: 0.32808 acc: 0.90755 | v_loss: 0.62000 v_acc: 0.85710 |  iteration: 3540 teacher: 0 stage: sketch lr: 0.000618\n",
      "batch 1054 loss: 0.33347 acc: 0.90495 | v_loss: 0.55941 v_acc: 0.88900 |  iteration: 3541 teacher: 0 stage: sketch lr: 0.000619\n",
      "batch 1055 loss: 0.31750 acc: 0.90788 | v_loss: 0.58405 v_acc: 0.87598 |  iteration: 3542 teacher: 1 stage: sketch lr: 0.000619\n",
      "batch 1056 loss: 0.27153 acc: 0.91764 | v_loss: 0.37731 v_acc: 0.90755 |  iteration: 3543 teacher: 0 stage: sketch lr: 0.000619\n",
      "batch 1057 loss: 0.21133 acc: 0.94108 | v_loss: 0.56964 v_acc: 0.88249 |  iteration: 3544 teacher: 1 stage: sketch lr: 0.000619\n",
      "batch 1058 loss: 0.28238 acc: 0.92480 | v_loss: 0.52323 v_acc: 0.88444 |  iteration: 3545 teacher: 1 stage: sketch lr: 0.000619\n",
      "batch 1059 loss: 0.38682 acc: 0.89258 | v_loss: 0.93560 v_acc: 0.82520 |  iteration: 3546 teacher: 1 stage: sketch lr: 0.000619\n",
      "batch 1060 loss: 0.26811 acc: 0.91634 | v_loss: 0.40692 v_acc: 0.89811 |  iteration: 3547 teacher: 0 stage: sketch lr: 0.000620\n",
      "batch 1061 loss: 0.31986 acc: 0.90039 | v_loss: 0.33368 v_acc: 0.92708 |  iteration: 3548 teacher: 0 stage: sketch lr: 0.000620\n",
      "batch 1062 loss: 0.27024 acc: 0.92448 | v_loss: 0.61261 v_acc: 0.87663 |  iteration: 3549 teacher: 0 stage: sketch lr: 0.000620\n",
      "batch 1063 loss: 0.28050 acc: 0.92188 | v_loss: 0.57183 v_acc: 0.88151 |  iteration: 3550 teacher: 1 stage: sketch lr: 0.000620\n",
      "batch 1064 loss: 0.27650 acc: 0.92904 | v_loss: 0.76324 v_acc: 0.84570 |  iteration: 3551 teacher: 1 stage: sketch lr: 0.000620\n",
      "batch 1065 loss: 0.33634 acc: 0.90234 | v_loss: 0.46821 v_acc: 0.89844 |  iteration: 3552 teacher: 1 stage: sketch lr: 0.000621\n",
      "batch 1066 loss: 0.37205 acc: 0.89909 | v_loss: 0.52485 v_acc: 0.88053 |  iteration: 3553 teacher: 1 stage: sketch lr: 0.000621\n",
      "batch 1067 loss: 0.33907 acc: 0.90755 | v_loss: 0.59407 v_acc: 0.86816 |  iteration: 3554 teacher: 1 stage: sketch lr: 0.000621\n",
      "batch 1068 loss: 0.35835 acc: 0.90039 | v_loss: 0.68744 v_acc: 0.84342 |  iteration: 3555 teacher: 1 stage: sketch lr: 0.000621\n",
      "batch 1069 loss: 0.23507 acc: 0.93197 | v_loss: 0.49650 v_acc: 0.89160 |  iteration: 3556 teacher: 1 stage: sketch lr: 0.000621\n",
      "batch 1070 loss: 0.30676 acc: 0.91243 | v_loss: 0.39989 v_acc: 0.89811 |  iteration: 3557 teacher: 1 stage: sketch lr: 0.000621\n",
      "batch 1071 loss: 0.31854 acc: 0.91081 | v_loss: 0.36127 v_acc: 0.90820 |  iteration: 3558 teacher: 0 stage: sketch lr: 0.000622\n",
      "batch 1072 loss: 0.32042 acc: 0.90430 | v_loss: 0.44875 v_acc: 0.89616 |  iteration: 3559 teacher: 1 stage: sketch lr: 0.000622\n",
      "batch 1073 loss: 0.32184 acc: 0.90267 | v_loss: 0.48215 v_acc: 0.88932 |  iteration: 3560 teacher: 0 stage: sketch lr: 0.000622\n",
      "batch 1074 loss: 0.30630 acc: 0.90658 | v_loss: 0.82850 v_acc: 0.85449 |  iteration: 3561 teacher: 1 stage: sketch lr: 0.000622\n",
      "batch 1075 loss: 0.27457 acc: 0.91829 | v_loss: 0.61586 v_acc: 0.87174 |  iteration: 3562 teacher: 0 stage: sketch lr: 0.000622\n",
      "batch 1076 loss: 0.32950 acc: 0.91016 | v_loss: 0.69100 v_acc: 0.86849 |  iteration: 3563 teacher: 1 stage: sketch lr: 0.000622\n",
      "batch 1077 loss: 0.36717 acc: 0.90332 | v_loss: 0.43212 v_acc: 0.90039 |  iteration: 3564 teacher: 1 stage: sketch lr: 0.000623\n",
      "batch 1078 loss: 0.33758 acc: 0.90723 | v_loss: 0.55348 v_acc: 0.88346 |  iteration: 3565 teacher: 1 stage: sketch lr: 0.000623\n",
      "batch 1079 loss: 0.30666 acc: 0.91667 | v_loss: 0.77431 v_acc: 0.83984 |  iteration: 3566 teacher: 0 stage: sketch lr: 0.000623\n",
      "batch 1080 loss: 0.31418 acc: 0.90560 | v_loss: 0.52233 v_acc: 0.88574 |  iteration: 3567 teacher: 0 stage: sketch lr: 0.000623\n",
      "batch 1081 loss: 0.28029 acc: 0.92741 | v_loss: 0.55276 v_acc: 0.87923 |  iteration: 3568 teacher: 1 stage: sketch lr: 0.000623\n",
      "batch 1082 loss: 0.34352 acc: 0.89779 | v_loss: 0.51382 v_acc: 0.87565 |  iteration: 3569 teacher: 0 stage: sketch lr: 0.000623\n",
      "batch 1083 loss: 0.32800 acc: 0.90983 | v_loss: 0.41187 v_acc: 0.90430 |  iteration: 3570 teacher: 1 stage: sketch lr: 0.000624\n",
      "batch 1084 loss: 0.26793 acc: 0.92188 | v_loss: 0.45287 v_acc: 0.89551 |  iteration: 3571 teacher: 1 stage: sketch lr: 0.000624\n",
      "batch 1085 loss: 0.25754 acc: 0.92448 | v_loss: 0.58934 v_acc: 0.86686 |  iteration: 3572 teacher: 1 stage: sketch lr: 0.000624\n",
      "batch 1086 loss: 0.23429 acc: 0.93717 | v_loss: 0.36166 v_acc: 0.91243 |  iteration: 3573 teacher: 1 stage: sketch lr: 0.000624\n",
      "batch 1087 loss: 0.22800 acc: 0.93132 | v_loss: 0.91495 v_acc: 0.83171 |  iteration: 3574 teacher: 0 stage: sketch lr: 0.000624\n",
      "batch 1088 loss: 0.20673 acc: 0.94238 | v_loss: 0.62543 v_acc: 0.87956 |  iteration: 3575 teacher: 1 stage: sketch lr: 0.000625\n",
      "batch 1089 loss: 0.36436 acc: 0.89323 | v_loss: 0.67471 v_acc: 0.87044 |  iteration: 3576 teacher: 0 stage: sketch lr: 0.000625\n",
      "batch 1090 loss: 0.26580 acc: 0.92415 | v_loss: 0.53961 v_acc: 0.89290 |  iteration: 3577 teacher: 0 stage: sketch lr: 0.000625\n",
      "batch 1091 loss: 0.30347 acc: 0.91406 | v_loss: 0.50530 v_acc: 0.89583 |  iteration: 3578 teacher: 0 stage: sketch lr: 0.000625\n",
      "batch 1092 loss: 0.29865 acc: 0.91536 | v_loss: 0.59173 v_acc: 0.87728 |  iteration: 3579 teacher: 1 stage: sketch lr: 0.000625\n",
      "batch 1093 loss: 0.23127 acc: 0.93294 | v_loss: 0.56173 v_acc: 0.88444 |  iteration: 3580 teacher: 1 stage: sketch lr: 0.000625\n",
      "batch 1094 loss: 0.34170 acc: 0.90885 | v_loss: 0.50612 v_acc: 0.88672 |  iteration: 3581 teacher: 1 stage: sketch lr: 0.000626\n",
      "batch 1095 loss: 0.20699 acc: 0.93620 | v_loss: 0.52076 v_acc: 0.89583 |  iteration: 3582 teacher: 1 stage: sketch lr: 0.000626\n",
      "batch 1096 loss: 0.30663 acc: 0.90592 | v_loss: 0.49116 v_acc: 0.88542 |  iteration: 3583 teacher: 1 stage: sketch lr: 0.000626\n",
      "batch 1097 loss: 0.35691 acc: 0.90755 | v_loss: 0.34357 v_acc: 0.90983 |  iteration: 3584 teacher: 1 stage: sketch lr: 0.000626\n",
      "batch 1098 loss: 0.25828 acc: 0.92546 | v_loss: 0.62859 v_acc: 0.85872 |  iteration: 3585 teacher: 1 stage: sketch lr: 0.000626\n",
      "batch 1099 loss: 0.27613 acc: 0.92090 | v_loss: 0.58434 v_acc: 0.85482 |  iteration: 3586 teacher: 0 stage: sketch lr: 0.000626\n",
      "batch 1100 loss: 0.33011 acc: 0.90299 | v_loss: 0.61985 v_acc: 0.86361 |  iteration: 3587 teacher: 1 stage: sketch lr: 0.000627\n",
      "batch 1101 loss: 0.24847 acc: 0.92546 | v_loss: 0.79401 v_acc: 0.85417 |  iteration: 3588 teacher: 1 stage: sketch lr: 0.000627\n",
      "batch 1102 loss: 0.33854 acc: 0.89616 | v_loss: 0.43920 v_acc: 0.90755 |  iteration: 3589 teacher: 0 stage: sketch lr: 0.000627\n",
      "batch 1103 loss: 0.22099 acc: 0.93132 | v_loss: 0.64810 v_acc: 0.86947 |  iteration: 3590 teacher: 0 stage: sketch lr: 0.000627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1104 loss: 0.28930 acc: 0.91341 | v_loss: 0.59002 v_acc: 0.89225 |  iteration: 3591 teacher: 0 stage: sketch lr: 0.000627\n",
      "batch 1105 loss: 0.28520 acc: 0.91569 | v_loss: 0.40778 v_acc: 0.91569 |  iteration: 3592 teacher: 0 stage: sketch lr: 0.000627\n",
      "batch 1106 loss: 0.33847 acc: 0.90234 | v_loss: 1.31748 v_acc: 0.80990 |  iteration: 3593 teacher: 1 stage: sketch lr: 0.000628\n",
      "batch 1107 loss: 0.35548 acc: 0.90332 | v_loss: 0.39800 v_acc: 0.92253 |  iteration: 3594 teacher: 0 stage: sketch lr: 0.000628\n",
      "batch 1108 loss: 0.22543 acc: 0.93913 | v_loss: 0.61576 v_acc: 0.88086 |  iteration: 3595 teacher: 0 stage: sketch lr: 0.000628\n",
      "batch 1109 loss: 0.20353 acc: 0.94010 | v_loss: 0.54455 v_acc: 0.89095 |  iteration: 3596 teacher: 0 stage: sketch lr: 0.000628\n",
      "batch 1110 loss: 0.28863 acc: 0.92318 | v_loss: 0.41994 v_acc: 0.90007 |  iteration: 3597 teacher: 0 stage: sketch lr: 0.000628\n",
      "batch 1111 loss: 0.24657 acc: 0.91797 | v_loss: 0.51373 v_acc: 0.88346 |  iteration: 3598 teacher: 0 stage: sketch lr: 0.000629\n",
      "batch 1112 loss: 0.27342 acc: 0.91276 | v_loss: 0.58200 v_acc: 0.88281 |  iteration: 3599 teacher: 0 stage: sketch lr: 0.000629\n",
      "batch 1113 loss: 0.29628 acc: 0.90951 | v_loss: 0.40005 v_acc: 0.91081 |  iteration: 3600 teacher: 0 stage: sketch lr: 0.000629\n",
      "batch 1114 loss: 0.34239 acc: 0.90104 | v_loss: 0.60066 v_acc: 0.86979 |  iteration: 3601 teacher: 1 stage: sketch lr: 0.000629\n",
      "batch 1115 loss: 0.25977 acc: 0.92057 | v_loss: 0.40119 v_acc: 0.89844 |  iteration: 3602 teacher: 0 stage: sketch lr: 0.000629\n",
      "batch 1116 loss: 0.36558 acc: 0.90234 | v_loss: 1.05069 v_acc: 0.81868 |  iteration: 3603 teacher: 1 stage: sketch lr: 0.000629\n",
      "batch 1117 loss: 0.26863 acc: 0.92448 | v_loss: 0.58473 v_acc: 0.88542 |  iteration: 3604 teacher: 1 stage: sketch lr: 0.000630\n",
      "batch 1118 loss: 0.32343 acc: 0.91113 | v_loss: 0.68555 v_acc: 0.87044 |  iteration: 3605 teacher: 1 stage: sketch lr: 0.000630\n",
      "batch 1119 loss: 0.33543 acc: 0.91016 | v_loss: 0.40719 v_acc: 0.89844 |  iteration: 3606 teacher: 1 stage: sketch lr: 0.000630\n",
      "batch 1120 loss: 0.40653 acc: 0.89779 | v_loss: 0.70010 v_acc: 0.85221 |  iteration: 3607 teacher: 1 stage: sketch lr: 0.000630\n",
      "batch 1121 loss: 0.25201 acc: 0.92480 | v_loss: 0.44479 v_acc: 0.89779 |  iteration: 3608 teacher: 1 stage: sketch lr: 0.000630\n",
      "batch 1122 loss: 0.25354 acc: 0.92220 | v_loss: 0.46192 v_acc: 0.88900 |  iteration: 3609 teacher: 0 stage: sketch lr: 0.000630\n",
      "batch 1123 loss: 0.35540 acc: 0.89160 | v_loss: 0.44989 v_acc: 0.89062 |  iteration: 3610 teacher: 0 stage: sketch lr: 0.000631\n",
      "batch 1124 loss: 0.28372 acc: 0.91504 | v_loss: 0.74159 v_acc: 0.84635 |  iteration: 3611 teacher: 0 stage: sketch lr: 0.000631\n",
      "batch 1125 loss: 0.29562 acc: 0.91504 | v_loss: 0.52690 v_acc: 0.88997 |  iteration: 3612 teacher: 0 stage: sketch lr: 0.000631\n",
      "batch 1126 loss: 0.30790 acc: 0.91211 | v_loss: 0.59414 v_acc: 0.86882 |  iteration: 3613 teacher: 0 stage: sketch lr: 0.000631\n",
      "batch 1127 loss: 0.27883 acc: 0.91992 | v_loss: 0.69793 v_acc: 0.84798 |  iteration: 3614 teacher: 1 stage: sketch lr: 0.000631\n",
      "batch 1128 loss: 0.33847 acc: 0.90104 | v_loss: 0.47953 v_acc: 0.88509 |  iteration: 3615 teacher: 1 stage: sketch lr: 0.000632\n",
      "batch 1129 loss: 0.30216 acc: 0.91178 | v_loss: 0.55786 v_acc: 0.86589 |  iteration: 3616 teacher: 0 stage: sketch lr: 0.000632\n",
      "batch 1130 loss: 0.38824 acc: 0.89128 | v_loss: 0.53564 v_acc: 0.87663 |  iteration: 3617 teacher: 1 stage: sketch lr: 0.000632\n",
      "batch 1131 loss: 0.24152 acc: 0.93457 | v_loss: 0.74923 v_acc: 0.84733 |  iteration: 3618 teacher: 0 stage: sketch lr: 0.000632\n",
      "batch 1132 loss: 0.27548 acc: 0.91927 | v_loss: 0.53956 v_acc: 0.88411 |  iteration: 3619 teacher: 0 stage: sketch lr: 0.000632\n",
      "batch 1133 loss: 0.27390 acc: 0.91927 | v_loss: 0.55850 v_acc: 0.87760 |  iteration: 3620 teacher: 1 stage: sketch lr: 0.000632\n",
      "batch 1134 loss: 0.32638 acc: 0.90365 | v_loss: 0.64870 v_acc: 0.87370 |  iteration: 3621 teacher: 0 stage: sketch lr: 0.000633\n",
      "batch 1135 loss: 0.33054 acc: 0.90202 | v_loss: 0.65471 v_acc: 0.84473 |  iteration: 3622 teacher: 1 stage: sketch lr: 0.000633\n",
      "batch 1136 loss: 0.37720 acc: 0.88672 | v_loss: 0.43882 v_acc: 0.89974 |  iteration: 3623 teacher: 0 stage: sketch lr: 0.000633\n",
      "batch 1137 loss: 0.34051 acc: 0.90462 | v_loss: 0.81389 v_acc: 0.83919 |  iteration: 3624 teacher: 1 stage: sketch lr: 0.000633\n",
      "batch 1138 loss: 0.31858 acc: 0.91276 | v_loss: 0.60259 v_acc: 0.88835 |  iteration: 3625 teacher: 1 stage: sketch lr: 0.000633\n",
      "batch 1139 loss: 0.27460 acc: 0.91927 | v_loss: 0.54355 v_acc: 0.87402 |  iteration: 3626 teacher: 1 stage: sketch lr: 0.000633\n",
      "batch 1140 loss: 0.33681 acc: 0.90072 | v_loss: 0.50896 v_acc: 0.88086 |  iteration: 3627 teacher: 0 stage: sketch lr: 0.000634\n",
      "batch 1141 loss: 0.35749 acc: 0.89746 | v_loss: 0.46862 v_acc: 0.89258 |  iteration: 3628 teacher: 0 stage: sketch lr: 0.000634\n",
      "batch 1142 loss: 0.34837 acc: 0.90202 | v_loss: 0.47346 v_acc: 0.88379 |  iteration: 3629 teacher: 1 stage: sketch lr: 0.000634\n",
      "batch 1143 loss: 0.21859 acc: 0.93620 | v_loss: 0.53236 v_acc: 0.88509 |  iteration: 3630 teacher: 1 stage: sketch lr: 0.000634\n",
      "batch 1144 loss: 0.23443 acc: 0.93392 | v_loss: 0.62371 v_acc: 0.84635 |  iteration: 3631 teacher: 0 stage: sketch lr: 0.000634\n",
      "batch 1145 loss: 0.32042 acc: 0.90853 | v_loss: 0.59735 v_acc: 0.88411 |  iteration: 3632 teacher: 0 stage: sketch lr: 0.000634\n",
      "batch 1146 loss: 0.31148 acc: 0.90918 | v_loss: 0.61342 v_acc: 0.87598 |  iteration: 3633 teacher: 1 stage: sketch lr: 0.000635\n",
      "batch 1147 loss: 0.33301 acc: 0.89811 | v_loss: 0.35372 v_acc: 0.91276 |  iteration: 3634 teacher: 0 stage: sketch lr: 0.000635\n",
      "batch 1148 loss: 0.30553 acc: 0.91276 | v_loss: 0.54378 v_acc: 0.88444 |  iteration: 3635 teacher: 0 stage: sketch lr: 0.000635\n",
      "batch 1149 loss: 0.22103 acc: 0.93815 | v_loss: 0.53619 v_acc: 0.87533 |  iteration: 3636 teacher: 1 stage: sketch lr: 0.000635\n",
      "batch 1150 loss: 0.30358 acc: 0.91113 | v_loss: 0.81172 v_acc: 0.84049 |  iteration: 3637 teacher: 0 stage: sketch lr: 0.000635\n",
      "batch 1151 loss: 0.29188 acc: 0.91862 | v_loss: 0.38102 v_acc: 0.90951 |  iteration: 3638 teacher: 0 stage: sketch lr: 0.000636\n",
      "batch 1152 loss: 0.30080 acc: 0.91113 | v_loss: 0.32768 v_acc: 0.92611 |  iteration: 3639 teacher: 0 stage: sketch lr: 0.000636\n",
      "batch 1153 loss: 0.22231 acc: 0.93685 | v_loss: 0.56198 v_acc: 0.88965 |  iteration: 3640 teacher: 1 stage: sketch lr: 0.000636\n",
      "batch 1154 loss: 0.29253 acc: 0.91211 | v_loss: 0.55063 v_acc: 0.88672 |  iteration: 3641 teacher: 0 stage: sketch lr: 0.000636\n",
      "batch 1155 loss: 0.39736 acc: 0.90755 | v_loss: 0.66419 v_acc: 0.86328 |  iteration: 3642 teacher: 1 stage: sketch lr: 0.000636\n",
      "batch 1156 loss: 0.25939 acc: 0.92350 | v_loss: 0.44076 v_acc: 0.89388 |  iteration: 3643 teacher: 0 stage: sketch lr: 0.000636\n",
      "batch 1157 loss: 0.26814 acc: 0.92253 | v_loss: 0.60165 v_acc: 0.85905 |  iteration: 3644 teacher: 1 stage: sketch lr: 0.000637\n",
      "batch 1158 loss: 0.33811 acc: 0.89779 | v_loss: 0.61742 v_acc: 0.85775 |  iteration: 3645 teacher: 0 stage: sketch lr: 0.000637\n",
      "batch 1159 loss: 0.32566 acc: 0.91374 | v_loss: 0.65703 v_acc: 0.85319 |  iteration: 3646 teacher: 0 stage: sketch lr: 0.000637\n",
      "batch 1160 loss: 0.23388 acc: 0.93262 | v_loss: 0.51579 v_acc: 0.89388 |  iteration: 3647 teacher: 0 stage: sketch lr: 0.000637\n",
      "batch 1161 loss: 0.28251 acc: 0.91374 | v_loss: 0.39188 v_acc: 0.90202 |  iteration: 3648 teacher: 1 stage: sketch lr: 0.000637\n",
      "batch 1162 loss: 0.23519 acc: 0.92806 | v_loss: 0.28777 v_acc: 0.92383 |  iteration: 3649 teacher: 0 stage: sketch lr: 0.000637\n",
      "batch 1163 loss: 0.30804 acc: 0.90625 | v_loss: 0.47739 v_acc: 0.90169 |  iteration: 3650 teacher: 0 stage: sketch lr: 0.000638\n",
      "batch 1164 loss: 0.34159 acc: 0.90527 | v_loss: 0.54126 v_acc: 0.87923 |  iteration: 3651 teacher: 0 stage: sketch lr: 0.000638\n",
      "batch 1165 loss: 0.26920 acc: 0.92480 | v_loss: 0.83445 v_acc: 0.85840 |  iteration: 3652 teacher: 0 stage: sketch lr: 0.000638\n",
      "batch 1166 loss: 0.37186 acc: 0.90104 | v_loss: 0.56174 v_acc: 0.87598 |  iteration: 3653 teacher: 0 stage: sketch lr: 0.000638\n",
      "batch 1167 loss: 0.27588 acc: 0.92415 | v_loss: 0.67714 v_acc: 0.86719 |  iteration: 3654 teacher: 0 stage: sketch lr: 0.000638\n",
      "batch 1168 loss: 0.21949 acc: 0.93359 | v_loss: 0.41117 v_acc: 0.90430 |  iteration: 3655 teacher: 1 stage: sketch lr: 0.000639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1169 loss: 0.31644 acc: 0.91211 | v_loss: 0.56057 v_acc: 0.88477 |  iteration: 3656 teacher: 1 stage: sketch lr: 0.000639\n",
      "batch 1170 loss: 0.30082 acc: 0.91113 | v_loss: 0.76735 v_acc: 0.84017 |  iteration: 3657 teacher: 1 stage: sketch lr: 0.000639\n",
      "batch 1171 loss: 0.33394 acc: 0.90690 | v_loss: 0.51727 v_acc: 0.90104 |  iteration: 3658 teacher: 0 stage: sketch lr: 0.000639\n",
      "batch 1172 loss: 0.28772 acc: 0.91569 | v_loss: 0.53503 v_acc: 0.88542 |  iteration: 3659 teacher: 0 stage: sketch lr: 0.000639\n",
      "batch 1173 loss: 0.22989 acc: 0.93066 | v_loss: 0.52409 v_acc: 0.88444 |  iteration: 3660 teacher: 0 stage: sketch lr: 0.000639\n",
      "batch 1174 loss: 0.28115 acc: 0.92253 | v_loss: 0.44309 v_acc: 0.90332 |  iteration: 3661 teacher: 1 stage: sketch lr: 0.000640\n",
      "batch 1175 loss: 0.36769 acc: 0.90007 | v_loss: 0.51179 v_acc: 0.89648 |  iteration: 3662 teacher: 1 stage: sketch lr: 0.000640\n",
      "batch 1176 loss: 0.31208 acc: 0.90853 | v_loss: 0.57351 v_acc: 0.86230 |  iteration: 3663 teacher: 0 stage: sketch lr: 0.000640\n",
      "batch 1177 loss: 0.28111 acc: 0.91634 | v_loss: 0.36462 v_acc: 0.92188 |  iteration: 3664 teacher: 0 stage: sketch lr: 0.000640\n",
      "batch 1178 loss: 0.29018 acc: 0.91992 | v_loss: 0.95163 v_acc: 0.83138 |  iteration: 3665 teacher: 1 stage: sketch lr: 0.000640\n",
      "batch 1179 loss: 0.28876 acc: 0.91764 | v_loss: 0.66733 v_acc: 0.86621 |  iteration: 3666 teacher: 1 stage: sketch lr: 0.000640\n",
      "batch 1180 loss: 0.29774 acc: 0.91276 | v_loss: 0.65583 v_acc: 0.86035 |  iteration: 3667 teacher: 0 stage: sketch lr: 0.000641\n",
      "batch 1181 loss: 0.34531 acc: 0.89551 | v_loss: 0.56744 v_acc: 0.88542 |  iteration: 3668 teacher: 0 stage: sketch lr: 0.000641\n",
      "batch 1182 loss: 0.34954 acc: 0.90169 | v_loss: 0.46039 v_acc: 0.89453 |  iteration: 3669 teacher: 0 stage: sketch lr: 0.000641\n",
      "batch 1183 loss: 0.18572 acc: 0.94922 | v_loss: 0.61726 v_acc: 0.88249 |  iteration: 3670 teacher: 1 stage: sketch lr: 0.000641\n",
      "batch 1184 loss: 0.27354 acc: 0.92513 | v_loss: 0.56929 v_acc: 0.88737 |  iteration: 3671 teacher: 1 stage: sketch lr: 0.000641\n",
      "batch 1185 loss: 0.25444 acc: 0.93392 | v_loss: 0.56224 v_acc: 0.87826 |  iteration: 3672 teacher: 1 stage: sketch lr: 0.000641\n",
      "batch 1186 loss: 0.22836 acc: 0.93848 | v_loss: 0.53535 v_acc: 0.89323 |  iteration: 3673 teacher: 1 stage: sketch lr: 0.000642\n",
      "batch 1187 loss: 0.30520 acc: 0.91048 | v_loss: 0.45192 v_acc: 0.89518 |  iteration: 3674 teacher: 0 stage: sketch lr: 0.000642\n",
      "batch 1188 loss: 0.22365 acc: 0.93490 | v_loss: 0.37082 v_acc: 0.91569 |  iteration: 3675 teacher: 1 stage: sketch lr: 0.000642\n",
      "batch 1189 loss: 0.33072 acc: 0.90625 | v_loss: 0.63716 v_acc: 0.86719 |  iteration: 3676 teacher: 1 stage: sketch lr: 0.000642\n",
      "batch 1190 loss: 0.28678 acc: 0.91895 | v_loss: 0.54349 v_acc: 0.86035 |  iteration: 3677 teacher: 0 stage: sketch lr: 0.000642\n",
      "batch 1191 loss: 0.29008 acc: 0.92090 | v_loss: 0.57566 v_acc: 0.86621 |  iteration: 3678 teacher: 1 stage: sketch lr: 0.000643\n",
      "batch 1192 loss: 0.24784 acc: 0.92741 | v_loss: 0.80527 v_acc: 0.84961 |  iteration: 3679 teacher: 1 stage: sketch lr: 0.000643\n",
      "batch 1193 loss: 0.29539 acc: 0.91960 | v_loss: 0.42615 v_acc: 0.90658 |  iteration: 3680 teacher: 0 stage: sketch lr: 0.000643\n",
      "batch 1194 loss: 0.34708 acc: 0.90462 | v_loss: 0.56131 v_acc: 0.87240 |  iteration: 3681 teacher: 0 stage: sketch lr: 0.000643\n",
      "batch 1195 loss: 0.26066 acc: 0.92220 | v_loss: 0.52791 v_acc: 0.88477 |  iteration: 3682 teacher: 0 stage: sketch lr: 0.000643\n",
      "batch 1196 loss: 0.33409 acc: 0.90169 | v_loss: 0.38373 v_acc: 0.90853 |  iteration: 3683 teacher: 0 stage: sketch lr: 0.000643\n",
      "batch 1197 loss: 0.27918 acc: 0.92122 | v_loss: 1.04143 v_acc: 0.80599 |  iteration: 3684 teacher: 1 stage: sketch lr: 0.000644\n",
      "batch 1198 loss: 0.30526 acc: 0.90690 | v_loss: 0.39461 v_acc: 0.91081 |  iteration: 3685 teacher: 0 stage: sketch lr: 0.000644\n",
      "batch 1199 loss: 0.32074 acc: 0.91113 | v_loss: 0.62225 v_acc: 0.87858 |  iteration: 3686 teacher: 1 stage: sketch lr: 0.000644\n",
      "batch 1200 loss: 0.28115 acc: 0.92188 | v_loss: 0.54513 v_acc: 0.88704 |  iteration: 3687 teacher: 0 stage: sketch lr: 0.000644\n",
      "batch 1201 loss: 0.25161 acc: 0.93001 | v_loss: 0.46824 v_acc: 0.90365 |  iteration: 3688 teacher: 1 stage: sketch lr: 0.000644\n",
      "batch 1202 loss: 0.26475 acc: 0.92806 | v_loss: 0.51540 v_acc: 0.89421 |  iteration: 3689 teacher: 1 stage: sketch lr: 0.000644\n",
      "batch 1203 loss: 0.36936 acc: 0.89095 | v_loss: 0.59244 v_acc: 0.87370 |  iteration: 3690 teacher: 0 stage: sketch lr: 0.000645\n",
      "batch 1204 loss: 0.28478 acc: 0.92057 | v_loss: 0.41721 v_acc: 0.90853 |  iteration: 3691 teacher: 0 stage: sketch lr: 0.000645\n",
      "batch 1205 loss: 0.24145 acc: 0.92513 | v_loss: 0.65328 v_acc: 0.86784 |  iteration: 3692 teacher: 0 stage: sketch lr: 0.000645\n",
      "batch 1206 loss: 0.36246 acc: 0.89746 | v_loss: 0.40377 v_acc: 0.89941 |  iteration: 3693 teacher: 0 stage: sketch lr: 0.000645\n",
      "batch 1207 loss: 0.29302 acc: 0.91764 | v_loss: 0.95209 v_acc: 0.82227 |  iteration: 3694 teacher: 0 stage: sketch lr: 0.000645\n",
      "batch 1208 loss: 0.30635 acc: 0.90495 | v_loss: 0.56723 v_acc: 0.88021 |  iteration: 3695 teacher: 0 stage: sketch lr: 0.000645\n",
      "batch 1209 loss: 0.33529 acc: 0.90658 | v_loss: 0.70067 v_acc: 0.86133 |  iteration: 3696 teacher: 1 stage: sketch lr: 0.000646\n",
      "batch 1210 loss: 0.34305 acc: 0.90560 | v_loss: 0.43836 v_acc: 0.90723 |  iteration: 3697 teacher: 1 stage: sketch lr: 0.000646\n",
      "batch 1211 loss: 0.37067 acc: 0.90202 | v_loss: 0.71813 v_acc: 0.85938 |  iteration: 3698 teacher: 0 stage: sketch lr: 0.000646\n",
      "batch 1212 loss: 0.38586 acc: 0.88900 | v_loss: 0.43238 v_acc: 0.89779 |  iteration: 3699 teacher: 0 stage: sketch lr: 0.000646\n",
      "batch 1213 loss: 0.30350 acc: 0.91732 | v_loss: 0.52818 v_acc: 0.87891 |  iteration: 3700 teacher: 1 stage: sketch lr: 0.000646\n",
      "batch 1214 loss: 0.29799 acc: 0.91439 | v_loss: 0.43528 v_acc: 0.88835 |  iteration: 3701 teacher: 1 stage: sketch lr: 0.000647\n",
      "batch 1215 loss: 0.43744 acc: 0.88151 | v_loss: 0.73326 v_acc: 0.84766 |  iteration: 3702 teacher: 0 stage: sketch lr: 0.000647\n",
      "batch 1216 loss: 0.30570 acc: 0.91309 | v_loss: 0.53472 v_acc: 0.88639 |  iteration: 3703 teacher: 1 stage: sketch lr: 0.000647\n",
      "batch 1217 loss: 0.27433 acc: 0.91667 | v_loss: 0.53816 v_acc: 0.87760 |  iteration: 3704 teacher: 1 stage: sketch lr: 0.000647\n",
      "batch 1218 loss: 0.36893 acc: 0.90332 | v_loss: 0.71477 v_acc: 0.84147 |  iteration: 3705 teacher: 1 stage: sketch lr: 0.000647\n",
      "batch 1219 loss: 0.27355 acc: 0.91862 | v_loss: 0.51271 v_acc: 0.88574 |  iteration: 3706 teacher: 1 stage: sketch lr: 0.000647\n",
      "batch 1220 loss: 0.29460 acc: 0.91536 | v_loss: 0.56556 v_acc: 0.86068 |  iteration: 3707 teacher: 0 stage: sketch lr: 0.000648\n",
      "batch 1221 loss: 0.31220 acc: 0.91927 | v_loss: 0.55107 v_acc: 0.87305 |  iteration: 3708 teacher: 1 stage: sketch lr: 0.000648\n",
      "batch 1222 loss: 0.28574 acc: 0.92057 | v_loss: 0.76848 v_acc: 0.84928 |  iteration: 3709 teacher: 1 stage: sketch lr: 0.000648\n",
      "batch 1223 loss: 0.32035 acc: 0.91797 | v_loss: 0.59050 v_acc: 0.87435 |  iteration: 3710 teacher: 1 stage: sketch lr: 0.000648\n",
      "batch 1224 loss: 0.37441 acc: 0.89323 | v_loss: 0.60219 v_acc: 0.87793 |  iteration: 3711 teacher: 1 stage: sketch lr: 0.000648\n",
      "batch 1225 loss: 0.29234 acc: 0.91602 | v_loss: 0.67441 v_acc: 0.87402 |  iteration: 3712 teacher: 1 stage: sketch lr: 0.000648\n",
      "batch 1226 loss: 0.32222 acc: 0.90885 | v_loss: 0.67795 v_acc: 0.84603 |  iteration: 3713 teacher: 1 stage: sketch lr: 0.000649\n",
      "batch 1227 loss: 0.29479 acc: 0.91764 | v_loss: 0.40090 v_acc: 0.90918 |  iteration: 3714 teacher: 1 stage: sketch lr: 0.000649\n",
      "batch 1228 loss: 0.30558 acc: 0.91895 | v_loss: 0.76367 v_acc: 0.85124 |  iteration: 3715 teacher: 1 stage: sketch lr: 0.000649\n",
      "batch 1229 loss: 0.36786 acc: 0.90007 | v_loss: 0.57345 v_acc: 0.88574 |  iteration: 3716 teacher: 0 stage: sketch lr: 0.000649\n",
      "batch 1230 loss: 0.23674 acc: 0.92676 | v_loss: 0.56550 v_acc: 0.87402 |  iteration: 3717 teacher: 0 stage: sketch lr: 0.000649\n",
      "batch 1231 loss: 0.25441 acc: 0.92546 | v_loss: 0.58067 v_acc: 0.87858 |  iteration: 3718 teacher: 1 stage: sketch lr: 0.000650\n",
      "batch 1232 loss: 0.30841 acc: 0.91797 | v_loss: 0.49831 v_acc: 0.88411 |  iteration: 3719 teacher: 1 stage: sketch lr: 0.000650\n",
      "batch 1233 loss: 0.34837 acc: 0.90430 | v_loss: 0.50165 v_acc: 0.88770 |  iteration: 3720 teacher: 0 stage: sketch lr: 0.000650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1234 loss: 0.29881 acc: 0.91536 | v_loss: 0.57767 v_acc: 0.86686 |  iteration: 3721 teacher: 0 stage: sketch lr: 0.000650\n",
      "batch 1235 loss: 0.35050 acc: 0.89518 | v_loss: 0.63205 v_acc: 0.84668 |  iteration: 3722 teacher: 0 stage: sketch lr: 0.000650\n",
      "batch 1236 loss: 0.30532 acc: 0.91146 | v_loss: 0.63047 v_acc: 0.87565 |  iteration: 3723 teacher: 0 stage: sketch lr: 0.000650\n",
      "batch 1237 loss: 0.30596 acc: 0.91146 | v_loss: 0.56226 v_acc: 0.88867 |  iteration: 3724 teacher: 1 stage: sketch lr: 0.000651\n",
      "batch 1238 loss: 0.39366 acc: 0.89225 | v_loss: 0.40287 v_acc: 0.90951 |  iteration: 3725 teacher: 1 stage: sketch lr: 0.000651\n",
      "batch 1239 loss: 0.39402 acc: 0.88965 | v_loss: 0.54798 v_acc: 0.88444 |  iteration: 3726 teacher: 0 stage: sketch lr: 0.000651\n",
      "batch 1240 loss: 0.35545 acc: 0.90592 | v_loss: 0.52228 v_acc: 0.88021 |  iteration: 3727 teacher: 0 stage: sketch lr: 0.000651\n",
      "batch 1241 loss: 0.36155 acc: 0.89648 | v_loss: 0.82566 v_acc: 0.82943 |  iteration: 3728 teacher: 0 stage: sketch lr: 0.000651\n",
      "batch 1242 loss: 0.24864 acc: 0.92871 | v_loss: 0.39276 v_acc: 0.90332 |  iteration: 3729 teacher: 1 stage: sketch lr: 0.000651\n",
      "epoch 2 loss: 0.29890 acc: 0.91491 | v_loss: 0.56822 v_acc: 0.88011 \n",
      "epoch: 3\n",
      "__________________________________________\n",
      "batch 0 loss: 0.37511 acc: 0.90202 | v_loss: 0.62353 v_acc: 0.87565 |  iteration: 3730 teacher: 0 stage: sketch lr: 0.000652\n",
      "batch 1 loss: 0.37029 acc: 0.89160 | v_loss: 0.55283 v_acc: 0.88867 |  iteration: 3731 teacher: 0 stage: sketch lr: 0.000652\n",
      "batch 2 loss: 0.25956 acc: 0.92546 | v_loss: 0.52337 v_acc: 0.88997 |  iteration: 3732 teacher: 0 stage: sketch lr: 0.000652\n",
      "batch 3 loss: 0.24250 acc: 0.93132 | v_loss: 0.50787 v_acc: 0.90104 |  iteration: 3733 teacher: 1 stage: sketch lr: 0.000652\n",
      "batch 4 loss: 0.32231 acc: 0.91243 | v_loss: 0.50603 v_acc: 0.89062 |  iteration: 3734 teacher: 1 stage: sketch lr: 0.000652\n",
      "batch 5 loss: 0.23818 acc: 0.93392 | v_loss: 0.41472 v_acc: 0.91081 |  iteration: 3735 teacher: 1 stage: sketch lr: 0.000652\n",
      "batch 6 loss: 0.28618 acc: 0.92676 | v_loss: 0.66788 v_acc: 0.86361 |  iteration: 3736 teacher: 1 stage: sketch lr: 0.000653\n",
      "batch 7 loss: 0.32296 acc: 0.91211 | v_loss: 0.57739 v_acc: 0.87142 |  iteration: 3737 teacher: 0 stage: sketch lr: 0.000653\n",
      "batch 8 loss: 0.23541 acc: 0.93164 | v_loss: 0.63104 v_acc: 0.86751 |  iteration: 3738 teacher: 0 stage: sketch lr: 0.000653\n",
      "batch 9 loss: 0.26273 acc: 0.92611 | v_loss: 0.84518 v_acc: 0.84147 |  iteration: 3739 teacher: 0 stage: sketch lr: 0.000653\n",
      "batch 10 loss: 0.25053 acc: 0.93197 | v_loss: 0.42657 v_acc: 0.90723 |  iteration: 3740 teacher: 1 stage: sketch lr: 0.000653\n",
      "batch 11 loss: 0.35955 acc: 0.89844 | v_loss: 0.59247 v_acc: 0.86198 |  iteration: 3741 teacher: 0 stage: sketch lr: 0.000654\n",
      "batch 12 loss: 0.36244 acc: 0.89160 | v_loss: 0.51702 v_acc: 0.88542 |  iteration: 3742 teacher: 1 stage: sketch lr: 0.000654\n",
      "batch 13 loss: 0.31453 acc: 0.90658 | v_loss: 0.41463 v_acc: 0.89974 |  iteration: 3743 teacher: 0 stage: sketch lr: 0.000654\n",
      "batch 14 loss: 0.25366 acc: 0.92643 | v_loss: 1.11748 v_acc: 0.80176 |  iteration: 3744 teacher: 0 stage: sketch lr: 0.000654\n",
      "batch 15 loss: 0.38414 acc: 0.89128 | v_loss: 0.41652 v_acc: 0.91797 |  iteration: 3745 teacher: 1 stage: sketch lr: 0.000654\n",
      "batch 16 loss: 0.21574 acc: 0.93587 | v_loss: 0.68247 v_acc: 0.87467 |  iteration: 3746 teacher: 0 stage: sketch lr: 0.000654\n",
      "batch 17 loss: 0.33821 acc: 0.90820 | v_loss: 0.57392 v_acc: 0.89486 |  iteration: 3747 teacher: 0 stage: sketch lr: 0.000655\n",
      "batch 18 loss: 0.36882 acc: 0.89193 | v_loss: 0.44556 v_acc: 0.91211 |  iteration: 3748 teacher: 0 stage: sketch lr: 0.000655\n",
      "batch 19 loss: 0.32024 acc: 0.90918 | v_loss: 0.54707 v_acc: 0.89421 |  iteration: 3749 teacher: 0 stage: sketch lr: 0.000655\n",
      "batch 20 loss: 0.33731 acc: 0.91048 | v_loss: 0.63161 v_acc: 0.86523 |  iteration: 3750 teacher: 1 stage: sketch lr: 0.000655\n",
      "batch 21 loss: 0.29795 acc: 0.91699 | v_loss: 0.45297 v_acc: 0.90462 |  iteration: 3751 teacher: 0 stage: sketch lr: 0.000655\n",
      "batch 22 loss: 0.34223 acc: 0.90169 | v_loss: 0.62413 v_acc: 0.87272 |  iteration: 3752 teacher: 0 stage: sketch lr: 0.000655\n",
      "batch 23 loss: 0.27416 acc: 0.92611 | v_loss: 0.38459 v_acc: 0.90430 |  iteration: 3753 teacher: 0 stage: sketch lr: 0.000656\n",
      "batch 24 loss: 0.34356 acc: 0.89909 | v_loss: 0.89880 v_acc: 0.82324 |  iteration: 3754 teacher: 0 stage: sketch lr: 0.000656\n",
      "batch 25 loss: 0.32807 acc: 0.90951 | v_loss: 0.54183 v_acc: 0.88411 |  iteration: 3755 teacher: 1 stage: sketch lr: 0.000656\n",
      "batch 26 loss: 0.29202 acc: 0.91146 | v_loss: 0.63514 v_acc: 0.88281 |  iteration: 3756 teacher: 0 stage: sketch lr: 0.000656\n",
      "batch 27 loss: 0.32485 acc: 0.91243 | v_loss: 0.42860 v_acc: 0.90202 |  iteration: 3757 teacher: 1 stage: sketch lr: 0.000656\n",
      "batch 28 loss: 0.48433 acc: 0.87728 | v_loss: 0.65708 v_acc: 0.85482 |  iteration: 3758 teacher: 1 stage: sketch lr: 0.000656\n",
      "batch 29 loss: 0.27563 acc: 0.93066 | v_loss: 0.45939 v_acc: 0.89388 |  iteration: 3759 teacher: 1 stage: sketch lr: 0.000657\n",
      "batch 30 loss: 0.38839 acc: 0.88281 | v_loss: 0.49965 v_acc: 0.87467 |  iteration: 3760 teacher: 0 stage: sketch lr: 0.000657\n",
      "batch 31 loss: 0.41904 acc: 0.88314 | v_loss: 0.42391 v_acc: 0.88672 |  iteration: 3761 teacher: 0 stage: sketch lr: 0.000657\n",
      "batch 32 loss: 0.26709 acc: 0.92839 | v_loss: 0.71967 v_acc: 0.84342 |  iteration: 3762 teacher: 1 stage: sketch lr: 0.000657\n",
      "batch 33 loss: 0.35425 acc: 0.89909 | v_loss: 0.49827 v_acc: 0.88997 |  iteration: 3763 teacher: 1 stage: sketch lr: 0.000657\n",
      "batch 34 loss: 0.42783 acc: 0.88249 | v_loss: 0.55876 v_acc: 0.88118 |  iteration: 3764 teacher: 0 stage: sketch lr: 0.000658\n",
      "batch 35 loss: 0.26835 acc: 0.92253 | v_loss: 0.69822 v_acc: 0.84798 |  iteration: 3765 teacher: 1 stage: sketch lr: 0.000658\n",
      "batch 36 loss: 0.26998 acc: 0.92122 | v_loss: 0.47526 v_acc: 0.89355 |  iteration: 3766 teacher: 0 stage: sketch lr: 0.000658\n",
      "batch 37 loss: 0.29814 acc: 0.91341 | v_loss: 0.52695 v_acc: 0.87077 |  iteration: 3767 teacher: 0 stage: sketch lr: 0.000658\n",
      "batch 38 loss: 0.30768 acc: 0.90495 | v_loss: 0.57755 v_acc: 0.87337 |  iteration: 3768 teacher: 0 stage: sketch lr: 0.000658\n",
      "batch 39 loss: 0.35944 acc: 0.90430 | v_loss: 0.76041 v_acc: 0.85091 |  iteration: 3769 teacher: 0 stage: sketch lr: 0.000658\n",
      "batch 40 loss: 0.36768 acc: 0.90332 | v_loss: 0.57814 v_acc: 0.87598 |  iteration: 3770 teacher: 1 stage: sketch lr: 0.000659\n",
      "batch 41 loss: 0.24150 acc: 0.92773 | v_loss: 0.58289 v_acc: 0.88021 |  iteration: 3771 teacher: 1 stage: sketch lr: 0.000659\n",
      "batch 42 loss: 0.28041 acc: 0.91667 | v_loss: 0.65975 v_acc: 0.86816 |  iteration: 3772 teacher: 0 stage: sketch lr: 0.000659\n",
      "batch 43 loss: 0.35130 acc: 0.90039 | v_loss: 0.56497 v_acc: 0.85352 |  iteration: 3773 teacher: 1 stage: sketch lr: 0.000659\n",
      "batch 44 loss: 0.33245 acc: 0.90462 | v_loss: 0.45473 v_acc: 0.90137 |  iteration: 3774 teacher: 0 stage: sketch lr: 0.000659\n",
      "batch 45 loss: 0.35232 acc: 0.90397 | v_loss: 0.79179 v_acc: 0.84570 |  iteration: 3775 teacher: 1 stage: sketch lr: 0.000659\n",
      "batch 46 loss: 0.25441 acc: 0.92350 | v_loss: 0.64535 v_acc: 0.86686 |  iteration: 3776 teacher: 0 stage: sketch lr: 0.000660\n",
      "batch 47 loss: 0.32897 acc: 0.90820 | v_loss: 0.56719 v_acc: 0.87337 |  iteration: 3777 teacher: 1 stage: sketch lr: 0.000660\n",
      "batch 48 loss: 0.30118 acc: 0.91243 | v_loss: 0.54390 v_acc: 0.88477 |  iteration: 3778 teacher: 0 stage: sketch lr: 0.000660\n",
      "batch 49 loss: 0.30604 acc: 0.91211 | v_loss: 0.51079 v_acc: 0.89193 |  iteration: 3779 teacher: 1 stage: sketch lr: 0.000660\n",
      "batch 50 loss: 0.28506 acc: 0.91406 | v_loss: 0.49264 v_acc: 0.88770 |  iteration: 3780 teacher: 0 stage: sketch lr: 0.000660\n",
      "batch 51 loss: 0.32113 acc: 0.90820 | v_loss: 0.57099 v_acc: 0.88151 |  iteration: 3781 teacher: 0 stage: sketch lr: 0.000661\n",
      "batch 52 loss: 0.32293 acc: 0.91341 | v_loss: 0.62788 v_acc: 0.85221 |  iteration: 3782 teacher: 1 stage: sketch lr: 0.000661\n",
      "batch 53 loss: 0.30209 acc: 0.91732 | v_loss: 0.59109 v_acc: 0.88216 |  iteration: 3783 teacher: 1 stage: sketch lr: 0.000661\n",
      "batch 54 loss: 0.31942 acc: 0.91667 | v_loss: 0.65796 v_acc: 0.87240 |  iteration: 3784 teacher: 1 stage: sketch lr: 0.000661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 55 loss: 0.29536 acc: 0.92122 | v_loss: 0.40508 v_acc: 0.90983 |  iteration: 3785 teacher: 1 stage: sketch lr: 0.000661\n",
      "batch 56 loss: 0.27539 acc: 0.91862 | v_loss: 0.58775 v_acc: 0.88770 |  iteration: 3786 teacher: 0 stage: sketch lr: 0.000661\n",
      "batch 57 loss: 0.28089 acc: 0.91862 | v_loss: 0.47089 v_acc: 0.89258 |  iteration: 3787 teacher: 0 stage: sketch lr: 0.000662\n",
      "batch 58 loss: 0.31454 acc: 0.90918 | v_loss: 0.92383 v_acc: 0.83398 |  iteration: 3788 teacher: 0 stage: sketch lr: 0.000662\n",
      "batch 59 loss: 0.29112 acc: 0.91634 | v_loss: 0.41548 v_acc: 0.90560 |  iteration: 3789 teacher: 1 stage: sketch lr: 0.000662\n",
      "batch 60 loss: 0.29281 acc: 0.91243 | v_loss: 0.35287 v_acc: 0.92676 |  iteration: 3790 teacher: 0 stage: sketch lr: 0.000662\n",
      "batch 61 loss: 0.31661 acc: 0.90951 | v_loss: 0.57292 v_acc: 0.88118 |  iteration: 3791 teacher: 0 stage: sketch lr: 0.000662\n",
      "batch 62 loss: 0.29479 acc: 0.91764 | v_loss: 0.60923 v_acc: 0.88314 |  iteration: 3792 teacher: 0 stage: sketch lr: 0.000662\n",
      "batch 63 loss: 0.26048 acc: 0.92773 | v_loss: 0.71507 v_acc: 0.85026 |  iteration: 3793 teacher: 1 stage: sketch lr: 0.000663\n",
      "batch 64 loss: 0.35629 acc: 0.90137 | v_loss: 0.42475 v_acc: 0.90430 |  iteration: 3794 teacher: 1 stage: sketch lr: 0.000663\n",
      "batch 65 loss: 0.27311 acc: 0.92448 | v_loss: 0.54157 v_acc: 0.87435 |  iteration: 3795 teacher: 1 stage: sketch lr: 0.000663\n",
      "batch 66 loss: 0.36172 acc: 0.90137 | v_loss: 0.58120 v_acc: 0.86165 |  iteration: 3796 teacher: 1 stage: sketch lr: 0.000663\n",
      "batch 67 loss: 0.30453 acc: 0.90820 | v_loss: 0.63632 v_acc: 0.84896 |  iteration: 3797 teacher: 0 stage: sketch lr: 0.000663\n",
      "batch 68 loss: 0.30310 acc: 0.90853 | v_loss: 0.54354 v_acc: 0.88379 |  iteration: 3798 teacher: 0 stage: sketch lr: 0.000663\n",
      "batch 69 loss: 0.27041 acc: 0.92057 | v_loss: 0.41756 v_acc: 0.90039 |  iteration: 3799 teacher: 1 stage: sketch lr: 0.000664\n",
      "batch 70 loss: 0.45869 acc: 0.87467 | v_loss: 0.30199 v_acc: 0.92090 |  iteration: 3800 teacher: 1 stage: sketch lr: 0.000664\n",
      "batch 71 loss: 0.24547 acc: 0.92839 | v_loss: 0.48539 v_acc: 0.89551 |  iteration: 3801 teacher: 0 stage: sketch lr: 0.000664\n",
      "batch 72 loss: 0.28215 acc: 0.91895 | v_loss: 0.59258 v_acc: 0.87728 |  iteration: 3802 teacher: 0 stage: sketch lr: 0.000664\n",
      "batch 73 loss: 0.35504 acc: 0.89746 | v_loss: 0.85291 v_acc: 0.85384 |  iteration: 3803 teacher: 1 stage: sketch lr: 0.000664\n",
      "batch 74 loss: 0.30683 acc: 0.90853 | v_loss: 0.56381 v_acc: 0.87695 |  iteration: 3804 teacher: 1 stage: sketch lr: 0.000665\n",
      "batch 75 loss: 0.22384 acc: 0.93424 | v_loss: 0.70655 v_acc: 0.85384 |  iteration: 3805 teacher: 0 stage: sketch lr: 0.000665\n",
      "batch 76 loss: 0.25646 acc: 0.92513 | v_loss: 0.44953 v_acc: 0.89355 |  iteration: 3806 teacher: 0 stage: sketch lr: 0.000665\n",
      "batch 77 loss: 0.40157 acc: 0.88965 | v_loss: 0.54441 v_acc: 0.87305 |  iteration: 3807 teacher: 0 stage: sketch lr: 0.000665\n",
      "batch 78 loss: 0.31714 acc: 0.90885 | v_loss: 0.73779 v_acc: 0.84733 |  iteration: 3808 teacher: 0 stage: sketch lr: 0.000665\n",
      "batch 79 loss: 0.26336 acc: 0.92578 | v_loss: 0.53559 v_acc: 0.88151 |  iteration: 3809 teacher: 1 stage: sketch lr: 0.000665\n",
      "batch 80 loss: 0.32375 acc: 0.90625 | v_loss: 0.52220 v_acc: 0.89648 |  iteration: 3810 teacher: 1 stage: sketch lr: 0.000666\n",
      "batch 81 loss: 0.31177 acc: 0.91048 | v_loss: 0.50381 v_acc: 0.88379 |  iteration: 3811 teacher: 1 stage: sketch lr: 0.000666\n",
      "batch 82 loss: 0.30096 acc: 0.91536 | v_loss: 0.43604 v_acc: 0.89844 |  iteration: 3812 teacher: 1 stage: sketch lr: 0.000666\n",
      "batch 83 loss: 0.51079 acc: 0.87012 | v_loss: 0.48427 v_acc: 0.89486 |  iteration: 3813 teacher: 1 stage: sketch lr: 0.000666\n",
      "batch 84 loss: 0.31547 acc: 0.90983 | v_loss: 0.60215 v_acc: 0.87044 |  iteration: 3814 teacher: 0 stage: sketch lr: 0.000666\n",
      "batch 85 loss: 0.22489 acc: 0.93197 | v_loss: 0.36922 v_acc: 0.91732 |  iteration: 3815 teacher: 0 stage: sketch lr: 0.000666\n",
      "batch 86 loss: 0.19595 acc: 0.93880 | v_loss: 0.90046 v_acc: 0.82845 |  iteration: 3816 teacher: 0 stage: sketch lr: 0.000667\n",
      "batch 87 loss: 0.29516 acc: 0.91341 | v_loss: 0.64190 v_acc: 0.87695 |  iteration: 3817 teacher: 1 stage: sketch lr: 0.000667\n",
      "batch 88 loss: 0.24137 acc: 0.92220 | v_loss: 0.69562 v_acc: 0.86849 |  iteration: 3818 teacher: 0 stage: sketch lr: 0.000667\n",
      "batch 89 loss: 0.28312 acc: 0.91992 | v_loss: 0.49737 v_acc: 0.89844 |  iteration: 3819 teacher: 0 stage: sketch lr: 0.000667\n",
      "batch 90 loss: 0.27656 acc: 0.92057 | v_loss: 0.47142 v_acc: 0.88900 |  iteration: 3820 teacher: 1 stage: sketch lr: 0.000667\n",
      "batch 91 loss: 0.21983 acc: 0.94043 | v_loss: 0.62447 v_acc: 0.88086 |  iteration: 3821 teacher: 1 stage: sketch lr: 0.000668\n",
      "batch 92 loss: 0.27593 acc: 0.91341 | v_loss: 0.52148 v_acc: 0.89551 |  iteration: 3822 teacher: 0 stage: sketch lr: 0.000668\n",
      "batch 93 loss: 0.35255 acc: 0.89844 | v_loss: 0.48737 v_acc: 0.89551 |  iteration: 3823 teacher: 0 stage: sketch lr: 0.000668\n",
      "batch 94 loss: 0.23164 acc: 0.92936 | v_loss: 0.50207 v_acc: 0.89648 |  iteration: 3824 teacher: 0 stage: sketch lr: 0.000668\n",
      "batch 95 loss: 0.26455 acc: 0.92415 | v_loss: 0.44157 v_acc: 0.89714 |  iteration: 3825 teacher: 0 stage: sketch lr: 0.000668\n",
      "batch 96 loss: 0.29890 acc: 0.91634 | v_loss: 0.33637 v_acc: 0.91471 |  iteration: 3826 teacher: 0 stage: sketch lr: 0.000668\n",
      "batch 97 loss: 0.29630 acc: 0.91439 | v_loss: 0.64468 v_acc: 0.86198 |  iteration: 3827 teacher: 0 stage: sketch lr: 0.000669\n",
      "batch 98 loss: 0.30614 acc: 0.91309 | v_loss: 0.60249 v_acc: 0.86589 |  iteration: 3828 teacher: 1 stage: sketch lr: 0.000669\n",
      "batch 99 loss: 0.28172 acc: 0.92025 | v_loss: 0.63887 v_acc: 0.86686 |  iteration: 3829 teacher: 1 stage: sketch lr: 0.000669\n",
      "batch 100 loss: 0.35508 acc: 0.90430 | v_loss: 0.81844 v_acc: 0.84798 |  iteration: 3830 teacher: 0 stage: sketch lr: 0.000669\n",
      "batch 101 loss: 0.37587 acc: 0.90104 | v_loss: 0.41665 v_acc: 0.90658 |  iteration: 3831 teacher: 0 stage: sketch lr: 0.000669\n",
      "batch 102 loss: 0.29631 acc: 0.91602 | v_loss: 0.56975 v_acc: 0.87044 |  iteration: 3832 teacher: 0 stage: sketch lr: 0.000669\n",
      "batch 103 loss: 0.23299 acc: 0.93262 | v_loss: 0.54224 v_acc: 0.88704 |  iteration: 3833 teacher: 0 stage: sketch lr: 0.000670\n",
      "batch 104 loss: 0.29819 acc: 0.91016 | v_loss: 0.40484 v_acc: 0.90462 |  iteration: 3834 teacher: 0 stage: sketch lr: 0.000670\n",
      "batch 105 loss: 0.26435 acc: 0.91667 | v_loss: 1.06340 v_acc: 0.81250 |  iteration: 3835 teacher: 0 stage: sketch lr: 0.000670\n",
      "batch 106 loss: 0.22528 acc: 0.93327 | v_loss: 0.39996 v_acc: 0.91536 |  iteration: 3836 teacher: 1 stage: sketch lr: 0.000670\n",
      "batch 107 loss: 0.22959 acc: 0.93099 | v_loss: 0.62273 v_acc: 0.88672 |  iteration: 3837 teacher: 0 stage: sketch lr: 0.000670\n",
      "batch 108 loss: 0.31376 acc: 0.91048 | v_loss: 0.53578 v_acc: 0.89746 |  iteration: 3838 teacher: 0 stage: sketch lr: 0.000670\n",
      "batch 109 loss: 0.30100 acc: 0.91699 | v_loss: 0.43001 v_acc: 0.90853 |  iteration: 3839 teacher: 0 stage: sketch lr: 0.000671\n",
      "batch 110 loss: 0.27972 acc: 0.91992 | v_loss: 0.52647 v_acc: 0.88997 |  iteration: 3840 teacher: 0 stage: sketch lr: 0.000671\n",
      "batch 111 loss: 0.32524 acc: 0.92122 | v_loss: 0.60355 v_acc: 0.87044 |  iteration: 3841 teacher: 1 stage: sketch lr: 0.000671\n",
      "batch 112 loss: 0.36361 acc: 0.91602 | v_loss: 0.45378 v_acc: 0.89258 |  iteration: 3842 teacher: 1 stage: sketch lr: 0.000671\n",
      "batch 113 loss: 0.26100 acc: 0.92708 | v_loss: 0.61141 v_acc: 0.85872 |  iteration: 3843 teacher: 1 stage: sketch lr: 0.000671\n",
      "batch 114 loss: 0.18541 acc: 0.94564 | v_loss: 0.43392 v_acc: 0.88639 |  iteration: 3844 teacher: 1 stage: sketch lr: 0.000672\n",
      "batch 115 loss: 0.25303 acc: 0.92122 | v_loss: 0.90912 v_acc: 0.81999 |  iteration: 3845 teacher: 1 stage: sketch lr: 0.000672\n",
      "batch 116 loss: 0.33898 acc: 0.91113 | v_loss: 0.59357 v_acc: 0.87467 |  iteration: 3846 teacher: 1 stage: sketch lr: 0.000672\n",
      "batch 117 loss: 0.27162 acc: 0.91504 | v_loss: 0.64278 v_acc: 0.87467 |  iteration: 3847 teacher: 0 stage: sketch lr: 0.000672\n",
      "batch 118 loss: 0.24555 acc: 0.92611 | v_loss: 0.42827 v_acc: 0.89941 |  iteration: 3848 teacher: 0 stage: sketch lr: 0.000672\n",
      "batch 119 loss: 0.37709 acc: 0.90462 | v_loss: 0.68103 v_acc: 0.85514 |  iteration: 3849 teacher: 1 stage: sketch lr: 0.000672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 120 loss: 0.32068 acc: 0.91569 | v_loss: 0.44080 v_acc: 0.89681 |  iteration: 3850 teacher: 1 stage: sketch lr: 0.000673\n",
      "batch 121 loss: 0.29202 acc: 0.91536 | v_loss: 0.46216 v_acc: 0.88965 |  iteration: 3851 teacher: 0 stage: sketch lr: 0.000673\n",
      "batch 122 loss: 0.34198 acc: 0.90007 | v_loss: 0.43586 v_acc: 0.88997 |  iteration: 3852 teacher: 0 stage: sketch lr: 0.000673\n",
      "batch 123 loss: 0.25776 acc: 0.92220 | v_loss: 0.72142 v_acc: 0.85449 |  iteration: 3853 teacher: 1 stage: sketch lr: 0.000673\n",
      "batch 124 loss: 0.26216 acc: 0.92415 | v_loss: 0.50499 v_acc: 0.89941 |  iteration: 3854 teacher: 0 stage: sketch lr: 0.000673\n",
      "batch 125 loss: 0.29786 acc: 0.91309 | v_loss: 0.54392 v_acc: 0.88639 |  iteration: 3855 teacher: 0 stage: sketch lr: 0.000673\n",
      "batch 126 loss: 0.26377 acc: 0.92546 | v_loss: 0.68637 v_acc: 0.85872 |  iteration: 3856 teacher: 1 stage: sketch lr: 0.000674\n",
      "batch 127 loss: 0.33964 acc: 0.90820 | v_loss: 0.46810 v_acc: 0.89714 |  iteration: 3857 teacher: 0 stage: sketch lr: 0.000674\n",
      "batch 128 loss: 0.21367 acc: 0.93620 | v_loss: 0.55075 v_acc: 0.86458 |  iteration: 3858 teacher: 0 stage: sketch lr: 0.000674\n",
      "batch 129 loss: 0.26854 acc: 0.92578 | v_loss: 0.59628 v_acc: 0.86751 |  iteration: 3859 teacher: 1 stage: sketch lr: 0.000674\n",
      "batch 130 loss: 0.30165 acc: 0.91406 | v_loss: 0.83020 v_acc: 0.84408 |  iteration: 3860 teacher: 1 stage: sketch lr: 0.000674\n",
      "batch 131 loss: 0.29141 acc: 0.92188 | v_loss: 0.56710 v_acc: 0.88444 |  iteration: 3861 teacher: 0 stage: sketch lr: 0.000674\n",
      "batch 132 loss: 0.24151 acc: 0.92773 | v_loss: 0.57885 v_acc: 0.88704 |  iteration: 3862 teacher: 1 stage: sketch lr: 0.000675\n",
      "batch 133 loss: 0.28129 acc: 0.92090 | v_loss: 0.61699 v_acc: 0.87760 |  iteration: 3863 teacher: 0 stage: sketch lr: 0.000675\n",
      "batch 134 loss: 0.28735 acc: 0.91960 | v_loss: 0.58241 v_acc: 0.86133 |  iteration: 3864 teacher: 0 stage: sketch lr: 0.000675\n",
      "batch 135 loss: 0.27201 acc: 0.91960 | v_loss: 0.45649 v_acc: 0.89909 |  iteration: 3865 teacher: 0 stage: sketch lr: 0.000675\n",
      "batch 136 loss: 0.32346 acc: 0.90885 | v_loss: 0.80420 v_acc: 0.83757 |  iteration: 3866 teacher: 1 stage: sketch lr: 0.000675\n",
      "batch 137 loss: 0.33276 acc: 0.90658 | v_loss: 0.60763 v_acc: 0.86914 |  iteration: 3867 teacher: 1 stage: sketch lr: 0.000676\n",
      "batch 138 loss: 0.29819 acc: 0.91048 | v_loss: 0.57785 v_acc: 0.87500 |  iteration: 3868 teacher: 1 stage: sketch lr: 0.000676\n",
      "batch 139 loss: 0.38207 acc: 0.90007 | v_loss: 0.54952 v_acc: 0.87598 |  iteration: 3869 teacher: 0 stage: sketch lr: 0.000676\n",
      "batch 140 loss: 0.30215 acc: 0.91602 | v_loss: 0.48337 v_acc: 0.89714 |  iteration: 3870 teacher: 0 stage: sketch lr: 0.000676\n",
      "batch 141 loss: 0.20869 acc: 0.93490 | v_loss: 0.47412 v_acc: 0.89551 |  iteration: 3871 teacher: 1 stage: sketch lr: 0.000676\n",
      "batch 142 loss: 0.27755 acc: 0.91829 | v_loss: 0.56402 v_acc: 0.86979 |  iteration: 3872 teacher: 1 stage: sketch lr: 0.000676\n",
      "batch 143 loss: 0.34084 acc: 0.90332 | v_loss: 0.66982 v_acc: 0.85156 |  iteration: 3873 teacher: 1 stage: sketch lr: 0.000677\n",
      "batch 144 loss: 0.20584 acc: 0.93490 | v_loss: 0.61284 v_acc: 0.87956 |  iteration: 3874 teacher: 0 stage: sketch lr: 0.000677\n",
      "batch 145 loss: 0.26113 acc: 0.92415 | v_loss: 0.56857 v_acc: 0.88216 |  iteration: 3875 teacher: 0 stage: sketch lr: 0.000677\n",
      "batch 146 loss: 0.29885 acc: 0.91569 | v_loss: 0.38455 v_acc: 0.90690 |  iteration: 3876 teacher: 0 stage: sketch lr: 0.000677\n",
      "batch 147 loss: 0.27956 acc: 0.92480 | v_loss: 0.57999 v_acc: 0.88118 |  iteration: 3877 teacher: 0 stage: sketch lr: 0.000677\n",
      "batch 148 loss: 0.33982 acc: 0.90625 | v_loss: 0.53364 v_acc: 0.88021 |  iteration: 3878 teacher: 1 stage: sketch lr: 0.000677\n",
      "batch 149 loss: 0.29887 acc: 0.90853 | v_loss: 0.90646 v_acc: 0.82780 |  iteration: 3879 teacher: 0 stage: sketch lr: 0.000678\n",
      "batch 150 loss: 0.27011 acc: 0.91732 | v_loss: 0.38501 v_acc: 0.90267 |  iteration: 3880 teacher: 0 stage: sketch lr: 0.000678\n",
      "batch 151 loss: 0.31529 acc: 0.90755 | v_loss: 0.32993 v_acc: 0.92611 |  iteration: 3881 teacher: 0 stage: sketch lr: 0.000678\n",
      "batch 152 loss: 0.31902 acc: 0.90723 | v_loss: 0.60342 v_acc: 0.87370 |  iteration: 3882 teacher: 1 stage: sketch lr: 0.000678\n",
      "batch 153 loss: 0.27219 acc: 0.92611 | v_loss: 0.55505 v_acc: 0.88411 |  iteration: 3883 teacher: 1 stage: sketch lr: 0.000678\n",
      "batch 154 loss: 0.22857 acc: 0.93327 | v_loss: 0.70263 v_acc: 0.85514 |  iteration: 3884 teacher: 1 stage: sketch lr: 0.000679\n",
      "batch 155 loss: 0.33374 acc: 0.90560 | v_loss: 0.46689 v_acc: 0.89681 |  iteration: 3885 teacher: 0 stage: sketch lr: 0.000679\n",
      "batch 156 loss: 0.35875 acc: 0.89388 | v_loss: 0.49083 v_acc: 0.87923 |  iteration: 3886 teacher: 0 stage: sketch lr: 0.000679\n",
      "batch 157 loss: 0.32927 acc: 0.90658 | v_loss: 0.60120 v_acc: 0.86947 |  iteration: 3887 teacher: 0 stage: sketch lr: 0.000679\n",
      "batch 158 loss: 0.31764 acc: 0.91667 | v_loss: 0.68517 v_acc: 0.84342 |  iteration: 3888 teacher: 1 stage: sketch lr: 0.000679\n",
      "batch 159 loss: 0.31726 acc: 0.91699 | v_loss: 0.50872 v_acc: 0.89518 |  iteration: 3889 teacher: 0 stage: sketch lr: 0.000679\n",
      "batch 160 loss: 0.27302 acc: 0.92448 | v_loss: 0.41217 v_acc: 0.89941 |  iteration: 3890 teacher: 0 stage: sketch lr: 0.000680\n",
      "batch 161 loss: 0.30722 acc: 0.90788 | v_loss: 0.29819 v_acc: 0.92122 |  iteration: 3891 teacher: 0 stage: sketch lr: 0.000680\n",
      "batch 162 loss: 0.30690 acc: 0.91406 | v_loss: 0.46107 v_acc: 0.90137 |  iteration: 3892 teacher: 1 stage: sketch lr: 0.000680\n",
      "batch 163 loss: 0.27958 acc: 0.91504 | v_loss: 0.54041 v_acc: 0.88574 |  iteration: 3893 teacher: 0 stage: sketch lr: 0.000680\n",
      "batch 164 loss: 0.34895 acc: 0.90007 | v_loss: 0.85659 v_acc: 0.85384 |  iteration: 3894 teacher: 1 stage: sketch lr: 0.000680\n",
      "batch 165 loss: 0.32021 acc: 0.91732 | v_loss: 0.58153 v_acc: 0.86979 |  iteration: 3895 teacher: 1 stage: sketch lr: 0.000680\n",
      "batch 166 loss: 0.22960 acc: 0.93555 | v_loss: 0.64776 v_acc: 0.87012 |  iteration: 3896 teacher: 0 stage: sketch lr: 0.000681\n",
      "batch 167 loss: 0.26359 acc: 0.91862 | v_loss: 0.43641 v_acc: 0.89811 |  iteration: 3897 teacher: 0 stage: sketch lr: 0.000681\n",
      "batch 168 loss: 0.31918 acc: 0.90755 | v_loss: 0.57954 v_acc: 0.87565 |  iteration: 3898 teacher: 0 stage: sketch lr: 0.000681\n",
      "batch 169 loss: 0.33655 acc: 0.90072 | v_loss: 0.76761 v_acc: 0.84408 |  iteration: 3899 teacher: 0 stage: sketch lr: 0.000681\n",
      "batch 170 loss: 0.30072 acc: 0.91276 | v_loss: 0.60092 v_acc: 0.88477 |  iteration: 3900 teacher: 1 stage: sketch lr: 0.000681\n",
      "batch 171 loss: 0.31093 acc: 0.91211 | v_loss: 0.52693 v_acc: 0.88835 |  iteration: 3901 teacher: 1 stage: sketch lr: 0.000681\n",
      "batch 172 loss: 0.34507 acc: 0.90983 | v_loss: 0.51557 v_acc: 0.87988 |  iteration: 3902 teacher: 1 stage: sketch lr: 0.000682\n",
      "batch 173 loss: 0.30122 acc: 0.91406 | v_loss: 0.40929 v_acc: 0.90723 |  iteration: 3903 teacher: 0 stage: sketch lr: 0.000682\n",
      "batch 174 loss: 0.30150 acc: 0.91341 | v_loss: 0.49886 v_acc: 0.89583 |  iteration: 3904 teacher: 0 stage: sketch lr: 0.000682\n",
      "batch 175 loss: 0.37525 acc: 0.89290 | v_loss: 0.61623 v_acc: 0.86751 |  iteration: 3905 teacher: 0 stage: sketch lr: 0.000682\n",
      "batch 176 loss: 0.23867 acc: 0.93132 | v_loss: 0.38267 v_acc: 0.92220 |  iteration: 3906 teacher: 0 stage: sketch lr: 0.000682\n",
      "batch 177 loss: 0.29720 acc: 0.92122 | v_loss: 1.04870 v_acc: 0.82161 |  iteration: 3907 teacher: 1 stage: sketch lr: 0.000683\n",
      "batch 178 loss: 0.28818 acc: 0.91895 | v_loss: 0.65005 v_acc: 0.88509 |  iteration: 3908 teacher: 0 stage: sketch lr: 0.000683\n",
      "batch 179 loss: 0.29679 acc: 0.92285 | v_loss: 0.70862 v_acc: 0.85938 |  iteration: 3909 teacher: 1 stage: sketch lr: 0.000683\n",
      "batch 180 loss: 0.34359 acc: 0.90007 | v_loss: 0.59638 v_acc: 0.88151 |  iteration: 3910 teacher: 0 stage: sketch lr: 0.000683\n",
      "batch 181 loss: 0.28327 acc: 0.91732 | v_loss: 0.50922 v_acc: 0.89225 |  iteration: 3911 teacher: 0 stage: sketch lr: 0.000683\n",
      "batch 182 loss: 0.29344 acc: 0.91862 | v_loss: 0.59897 v_acc: 0.88346 |  iteration: 3912 teacher: 1 stage: sketch lr: 0.000683\n",
      "batch 183 loss: 0.24046 acc: 0.92708 | v_loss: 0.53205 v_acc: 0.88249 |  iteration: 3913 teacher: 1 stage: sketch lr: 0.000684\n",
      "batch 184 loss: 0.28011 acc: 0.91764 | v_loss: 0.51983 v_acc: 0.87760 |  iteration: 3914 teacher: 0 stage: sketch lr: 0.000684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 185 loss: 0.22493 acc: 0.93229 | v_loss: 0.51025 v_acc: 0.89323 |  iteration: 3915 teacher: 1 stage: sketch lr: 0.000684\n",
      "batch 186 loss: 0.29042 acc: 0.91243 | v_loss: 0.46723 v_acc: 0.89290 |  iteration: 3916 teacher: 1 stage: sketch lr: 0.000684\n",
      "batch 187 loss: 0.28586 acc: 0.91276 | v_loss: 0.35529 v_acc: 0.91243 |  iteration: 3917 teacher: 0 stage: sketch lr: 0.000684\n",
      "batch 188 loss: 0.35797 acc: 0.90234 | v_loss: 0.67411 v_acc: 0.85677 |  iteration: 3918 teacher: 0 stage: sketch lr: 0.000684\n",
      "batch 189 loss: 0.36388 acc: 0.89518 | v_loss: 0.57707 v_acc: 0.86068 |  iteration: 3919 teacher: 0 stage: sketch lr: 0.000685\n",
      "batch 190 loss: 0.35681 acc: 0.90527 | v_loss: 0.60498 v_acc: 0.86784 |  iteration: 3920 teacher: 1 stage: sketch lr: 0.000685\n",
      "batch 191 loss: 0.28021 acc: 0.91536 | v_loss: 0.85000 v_acc: 0.83919 |  iteration: 3921 teacher: 1 stage: sketch lr: 0.000685\n",
      "batch 192 loss: 0.34284 acc: 0.89486 | v_loss: 0.44960 v_acc: 0.90267 |  iteration: 3922 teacher: 0 stage: sketch lr: 0.000685\n",
      "batch 193 loss: 0.25096 acc: 0.92188 | v_loss: 0.55796 v_acc: 0.87956 |  iteration: 3923 teacher: 0 stage: sketch lr: 0.000685\n",
      "batch 194 loss: 0.34576 acc: 0.90462 | v_loss: 0.55040 v_acc: 0.89030 |  iteration: 3924 teacher: 0 stage: sketch lr: 0.000685\n",
      "batch 195 loss: 0.35392 acc: 0.89909 | v_loss: 0.38814 v_acc: 0.91048 |  iteration: 3925 teacher: 1 stage: sketch lr: 0.000686\n",
      "batch 196 loss: 0.29586 acc: 0.91309 | v_loss: 1.08525 v_acc: 0.80534 |  iteration: 3926 teacher: 1 stage: sketch lr: 0.000686\n",
      "batch 197 loss: 0.32381 acc: 0.90430 | v_loss: 0.39379 v_acc: 0.91569 |  iteration: 3927 teacher: 1 stage: sketch lr: 0.000686\n",
      "batch 198 loss: 0.26068 acc: 0.92839 | v_loss: 0.62919 v_acc: 0.87240 |  iteration: 3928 teacher: 1 stage: sketch lr: 0.000686\n",
      "batch 199 loss: 0.32780 acc: 0.90234 | v_loss: 0.54277 v_acc: 0.88932 |  iteration: 3929 teacher: 1 stage: sketch lr: 0.000686\n",
      "batch 200 loss: 0.30656 acc: 0.92285 | v_loss: 0.44840 v_acc: 0.90267 |  iteration: 3930 teacher: 1 stage: sketch lr: 0.000687\n",
      "batch 201 loss: 0.38248 acc: 0.89811 | v_loss: 0.53906 v_acc: 0.88639 |  iteration: 3931 teacher: 0 stage: sketch lr: 0.000687\n",
      "batch 202 loss: 0.25169 acc: 0.92904 | v_loss: 0.60389 v_acc: 0.86621 |  iteration: 3932 teacher: 1 stage: sketch lr: 0.000687\n",
      "batch 203 loss: 0.34034 acc: 0.89941 | v_loss: 0.43023 v_acc: 0.90104 |  iteration: 3933 teacher: 0 stage: sketch lr: 0.000687\n",
      "batch 204 loss: 0.39420 acc: 0.89128 | v_loss: 0.59684 v_acc: 0.86654 |  iteration: 3934 teacher: 1 stage: sketch lr: 0.000687\n",
      "batch 205 loss: 0.35661 acc: 0.90039 | v_loss: 0.39093 v_acc: 0.90104 |  iteration: 3935 teacher: 1 stage: sketch lr: 0.000687\n",
      "batch 206 loss: 0.24690 acc: 0.92415 | v_loss: 0.99170 v_acc: 0.80729 |  iteration: 3936 teacher: 0 stage: sketch lr: 0.000688\n",
      "batch 207 loss: 0.31152 acc: 0.90820 | v_loss: 0.56709 v_acc: 0.88249 |  iteration: 3937 teacher: 0 stage: sketch lr: 0.000688\n",
      "batch 208 loss: 0.25782 acc: 0.92708 | v_loss: 0.71317 v_acc: 0.85124 |  iteration: 3938 teacher: 1 stage: sketch lr: 0.000688\n",
      "batch 209 loss: 0.22394 acc: 0.93229 | v_loss: 0.40324 v_acc: 0.90625 |  iteration: 3939 teacher: 1 stage: sketch lr: 0.000688\n",
      "batch 210 loss: 0.22703 acc: 0.92708 | v_loss: 0.68653 v_acc: 0.85286 |  iteration: 3940 teacher: 0 stage: sketch lr: 0.000688\n",
      "batch 211 loss: 0.24178 acc: 0.92350 | v_loss: 0.43980 v_acc: 0.89648 |  iteration: 3941 teacher: 1 stage: sketch lr: 0.000688\n",
      "batch 212 loss: 0.26011 acc: 0.93132 | v_loss: 0.50612 v_acc: 0.88086 |  iteration: 3942 teacher: 1 stage: sketch lr: 0.000689\n",
      "batch 213 loss: 0.25784 acc: 0.92415 | v_loss: 0.44713 v_acc: 0.89648 |  iteration: 3943 teacher: 0 stage: sketch lr: 0.000689\n",
      "batch 214 loss: 0.24948 acc: 0.93327 | v_loss: 0.73285 v_acc: 0.85938 |  iteration: 3944 teacher: 0 stage: sketch lr: 0.000689\n",
      "batch 215 loss: 0.31322 acc: 0.91602 | v_loss: 0.52215 v_acc: 0.90169 |  iteration: 3945 teacher: 0 stage: sketch lr: 0.000689\n",
      "batch 216 loss: 0.21235 acc: 0.93555 | v_loss: 0.57131 v_acc: 0.88086 |  iteration: 3946 teacher: 1 stage: sketch lr: 0.000689\n",
      "batch 217 loss: 0.29749 acc: 0.92578 | v_loss: 0.74380 v_acc: 0.85026 |  iteration: 3947 teacher: 1 stage: sketch lr: 0.000690\n",
      "batch 218 loss: 0.23598 acc: 0.93620 | v_loss: 0.44730 v_acc: 0.89974 |  iteration: 3948 teacher: 1 stage: sketch lr: 0.000690\n",
      "batch 219 loss: 0.27613 acc: 0.92155 | v_loss: 0.53044 v_acc: 0.87077 |  iteration: 3949 teacher: 1 stage: sketch lr: 0.000690\n",
      "batch 220 loss: 0.21510 acc: 0.93685 | v_loss: 0.57849 v_acc: 0.87012 |  iteration: 3950 teacher: 1 stage: sketch lr: 0.000690\n",
      "batch 221 loss: 0.35063 acc: 0.90332 | v_loss: 0.77517 v_acc: 0.84733 |  iteration: 3951 teacher: 0 stage: sketch lr: 0.000690\n",
      "batch 222 loss: 0.36789 acc: 0.89876 | v_loss: 0.57927 v_acc: 0.88021 |  iteration: 3952 teacher: 1 stage: sketch lr: 0.000690\n",
      "batch 223 loss: 0.37370 acc: 0.89290 | v_loss: 0.61042 v_acc: 0.88314 |  iteration: 3953 teacher: 0 stage: sketch lr: 0.000691\n",
      "batch 224 loss: 0.28854 acc: 0.92578 | v_loss: 0.66380 v_acc: 0.87174 |  iteration: 3954 teacher: 1 stage: sketch lr: 0.000691\n",
      "batch 225 loss: 0.23088 acc: 0.93066 | v_loss: 0.59322 v_acc: 0.85807 |  iteration: 3955 teacher: 1 stage: sketch lr: 0.000691\n",
      "batch 226 loss: 0.35703 acc: 0.88216 | v_loss: 0.45026 v_acc: 0.89583 |  iteration: 3956 teacher: 0 stage: sketch lr: 0.000691\n",
      "batch 227 loss: 0.35522 acc: 0.89941 | v_loss: 0.81521 v_acc: 0.84473 |  iteration: 3957 teacher: 1 stage: sketch lr: 0.000691\n",
      "batch 228 loss: 0.32549 acc: 0.90527 | v_loss: 0.61163 v_acc: 0.86784 |  iteration: 3958 teacher: 0 stage: sketch lr: 0.000691\n",
      "batch 229 loss: 0.27132 acc: 0.91992 | v_loss: 0.53875 v_acc: 0.87174 |  iteration: 3959 teacher: 1 stage: sketch lr: 0.000692\n",
      "batch 230 loss: 0.44224 acc: 0.88770 | v_loss: 0.55159 v_acc: 0.87142 |  iteration: 3960 teacher: 1 stage: sketch lr: 0.000692\n",
      "batch 231 loss: 0.34120 acc: 0.90039 | v_loss: 0.47115 v_acc: 0.88932 |  iteration: 3961 teacher: 0 stage: sketch lr: 0.000692\n",
      "batch 232 loss: 0.28424 acc: 0.91536 | v_loss: 0.47232 v_acc: 0.88867 |  iteration: 3962 teacher: 1 stage: sketch lr: 0.000692\n",
      "batch 233 loss: 0.26516 acc: 0.92448 | v_loss: 0.52354 v_acc: 0.88314 |  iteration: 3963 teacher: 0 stage: sketch lr: 0.000692\n",
      "batch 234 loss: 0.42188 acc: 0.88737 | v_loss: 0.62730 v_acc: 0.84896 |  iteration: 3964 teacher: 1 stage: sketch lr: 0.000692\n",
      "batch 235 loss: 0.24854 acc: 0.92676 | v_loss: 0.57969 v_acc: 0.88346 |  iteration: 3965 teacher: 1 stage: sketch lr: 0.000693\n",
      "batch 236 loss: 0.31996 acc: 0.90983 | v_loss: 0.65894 v_acc: 0.87467 |  iteration: 3966 teacher: 1 stage: sketch lr: 0.000693\n",
      "batch 237 loss: 0.34055 acc: 0.90723 | v_loss: 0.39248 v_acc: 0.90495 |  iteration: 3967 teacher: 1 stage: sketch lr: 0.000693\n",
      "batch 238 loss: 0.25745 acc: 0.92448 | v_loss: 0.58079 v_acc: 0.88216 |  iteration: 3968 teacher: 1 stage: sketch lr: 0.000693\n",
      "batch 239 loss: 0.33606 acc: 0.89290 | v_loss: 0.52475 v_acc: 0.87533 |  iteration: 3969 teacher: 0 stage: sketch lr: 0.000693\n",
      "batch 240 loss: 0.21695 acc: 0.93197 | v_loss: 0.88456 v_acc: 0.82585 |  iteration: 3970 teacher: 0 stage: sketch lr: 0.000694\n",
      "batch 241 loss: 0.28062 acc: 0.92220 | v_loss: 0.38494 v_acc: 0.90690 |  iteration: 3971 teacher: 1 stage: sketch lr: 0.000694\n",
      "batch 242 loss: 0.23180 acc: 0.92871 | v_loss: 0.31360 v_acc: 0.92773 |  iteration: 3972 teacher: 0 stage: sketch lr: 0.000694\n",
      "batch 243 loss: 0.28626 acc: 0.91927 | v_loss: 0.57385 v_acc: 0.88281 |  iteration: 3973 teacher: 1 stage: sketch lr: 0.000694\n",
      "batch 244 loss: 0.35489 acc: 0.89551 | v_loss: 0.58281 v_acc: 0.88965 |  iteration: 3974 teacher: 1 stage: sketch lr: 0.000694\n",
      "batch 245 loss: 0.31166 acc: 0.91276 | v_loss: 0.66879 v_acc: 0.86165 |  iteration: 3975 teacher: 0 stage: sketch lr: 0.000694\n",
      "batch 246 loss: 0.21024 acc: 0.93652 | v_loss: 0.42973 v_acc: 0.90267 |  iteration: 3976 teacher: 1 stage: sketch lr: 0.000695\n",
      "batch 247 loss: 0.31313 acc: 0.91309 | v_loss: 0.49090 v_acc: 0.87858 |  iteration: 3977 teacher: 1 stage: sketch lr: 0.000695\n",
      "batch 248 loss: 0.28896 acc: 0.91211 | v_loss: 0.61982 v_acc: 0.86035 |  iteration: 3978 teacher: 1 stage: sketch lr: 0.000695\n",
      "batch 249 loss: 0.30576 acc: 0.90625 | v_loss: 0.69965 v_acc: 0.84310 |  iteration: 3979 teacher: 0 stage: sketch lr: 0.000695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 250 loss: 0.34257 acc: 0.90332 | v_loss: 0.50343 v_acc: 0.90039 |  iteration: 3980 teacher: 1 stage: sketch lr: 0.000695\n",
      "batch 251 loss: 0.31472 acc: 0.91081 | v_loss: 0.41766 v_acc: 0.90365 |  iteration: 3981 teacher: 1 stage: sketch lr: 0.000695\n",
      "batch 252 loss: 0.26739 acc: 0.92513 | v_loss: 0.28475 v_acc: 0.92643 |  iteration: 3982 teacher: 0 stage: sketch lr: 0.000696\n",
      "batch 253 loss: 0.27893 acc: 0.92188 | v_loss: 0.46634 v_acc: 0.89909 |  iteration: 3983 teacher: 1 stage: sketch lr: 0.000696\n",
      "batch 254 loss: 0.23524 acc: 0.93555 | v_loss: 0.50950 v_acc: 0.88477 |  iteration: 3984 teacher: 1 stage: sketch lr: 0.000696\n",
      "batch 255 loss: 0.24528 acc: 0.92318 | v_loss: 0.82887 v_acc: 0.85840 |  iteration: 3985 teacher: 0 stage: sketch lr: 0.000696\n",
      "batch 256 loss: 0.26797 acc: 0.91699 | v_loss: 0.54149 v_acc: 0.88704 |  iteration: 3986 teacher: 1 stage: sketch lr: 0.000696\n",
      "batch 257 loss: 0.31626 acc: 0.90885 | v_loss: 0.67064 v_acc: 0.86816 |  iteration: 3987 teacher: 0 stage: sketch lr: 0.000697\n",
      "batch 258 loss: 0.26006 acc: 0.93132 | v_loss: 0.41462 v_acc: 0.90202 |  iteration: 3988 teacher: 1 stage: sketch lr: 0.000697\n",
      "batch 259 loss: 0.31371 acc: 0.91113 | v_loss: 0.54609 v_acc: 0.88118 |  iteration: 3989 teacher: 1 stage: sketch lr: 0.000697\n",
      "batch 260 loss: 0.29800 acc: 0.91536 | v_loss: 0.72278 v_acc: 0.84375 |  iteration: 3990 teacher: 0 stage: sketch lr: 0.000697\n",
      "batch 261 loss: 0.23903 acc: 0.93359 | v_loss: 0.51749 v_acc: 0.89062 |  iteration: 3991 teacher: 1 stage: sketch lr: 0.000697\n",
      "batch 262 loss: 0.29487 acc: 0.91960 | v_loss: 0.54177 v_acc: 0.88184 |  iteration: 3992 teacher: 0 stage: sketch lr: 0.000697\n",
      "batch 263 loss: 0.32636 acc: 0.89453 | v_loss: 0.46581 v_acc: 0.89128 |  iteration: 3993 teacher: 0 stage: sketch lr: 0.000698\n",
      "batch 264 loss: 0.29881 acc: 0.91829 | v_loss: 0.42522 v_acc: 0.90430 |  iteration: 3994 teacher: 0 stage: sketch lr: 0.000698\n",
      "batch 265 loss: 0.19724 acc: 0.94303 | v_loss: 0.48768 v_acc: 0.89616 |  iteration: 3995 teacher: 0 stage: sketch lr: 0.000698\n",
      "batch 266 loss: 0.23573 acc: 0.93001 | v_loss: 0.57326 v_acc: 0.87663 |  iteration: 3996 teacher: 1 stage: sketch lr: 0.000698\n",
      "batch 267 loss: 0.27622 acc: 0.92383 | v_loss: 0.36440 v_acc: 0.92155 |  iteration: 3997 teacher: 1 stage: sketch lr: 0.000698\n",
      "batch 268 loss: 0.25562 acc: 0.93099 | v_loss: 0.94062 v_acc: 0.82031 |  iteration: 3998 teacher: 1 stage: sketch lr: 0.000698\n",
      "batch 269 loss: 0.26343 acc: 0.92676 | v_loss: 0.61193 v_acc: 0.87533 |  iteration: 3999 teacher: 0 stage: sketch lr: 0.000699\n",
      "batch 270 loss: 0.42097 acc: 0.87858 | v_loss: 0.62300 v_acc: 0.86133 |  iteration: 4000 teacher: 1 stage: sketch lr: 0.000699\n",
      "batch 271 loss: 0.39058 acc: 0.88379 | v_loss: 0.50837 v_acc: 0.89193 |  iteration: 4001 teacher: 0 stage: sketch lr: 0.000699\n",
      "batch 272 loss: 0.36137 acc: 0.90169 | v_loss: 0.50411 v_acc: 0.88737 |  iteration: 4002 teacher: 1 stage: sketch lr: 0.000699\n",
      "batch 273 loss: 0.28337 acc: 0.91862 | v_loss: 0.64966 v_acc: 0.87272 |  iteration: 4003 teacher: 0 stage: sketch lr: 0.000699\n",
      "batch 274 loss: 0.33663 acc: 0.90853 | v_loss: 0.52286 v_acc: 0.89062 |  iteration: 4004 teacher: 1 stage: sketch lr: 0.000698\n",
      "batch 275 loss: 0.32992 acc: 0.90951 | v_loss: 0.48943 v_acc: 0.88737 |  iteration: 4005 teacher: 1 stage: sketch lr: 0.000698\n",
      "batch 276 loss: 0.32998 acc: 0.90658 | v_loss: 0.49425 v_acc: 0.89714 |  iteration: 4006 teacher: 1 stage: sketch lr: 0.000698\n",
      "batch 277 loss: 0.27190 acc: 0.91992 | v_loss: 0.46980 v_acc: 0.89714 |  iteration: 4007 teacher: 0 stage: sketch lr: 0.000698\n",
      "batch 278 loss: 0.27591 acc: 0.92220 | v_loss: 0.34889 v_acc: 0.91536 |  iteration: 4008 teacher: 0 stage: sketch lr: 0.000698\n",
      "batch 279 loss: 0.34619 acc: 0.89779 | v_loss: 0.61404 v_acc: 0.86458 |  iteration: 4009 teacher: 1 stage: sketch lr: 0.000698\n",
      "batch 280 loss: 0.24231 acc: 0.92708 | v_loss: 0.55209 v_acc: 0.87370 |  iteration: 4010 teacher: 0 stage: sketch lr: 0.000698\n",
      "batch 281 loss: 0.21672 acc: 0.94206 | v_loss: 0.66640 v_acc: 0.86100 |  iteration: 4011 teacher: 1 stage: sketch lr: 0.000698\n",
      "batch 282 loss: 0.37074 acc: 0.90430 | v_loss: 0.93418 v_acc: 0.84049 |  iteration: 4012 teacher: 1 stage: sketch lr: 0.000698\n",
      "batch 283 loss: 0.30661 acc: 0.90853 | v_loss: 0.48566 v_acc: 0.90267 |  iteration: 4013 teacher: 0 stage: sketch lr: 0.000698\n",
      "batch 284 loss: 0.27865 acc: 0.92285 | v_loss: 0.61043 v_acc: 0.88151 |  iteration: 4014 teacher: 0 stage: sketch lr: 0.000698\n",
      "batch 285 loss: 0.27712 acc: 0.92155 | v_loss: 0.54644 v_acc: 0.89323 |  iteration: 4015 teacher: 1 stage: sketch lr: 0.000697\n",
      "batch 286 loss: 0.32378 acc: 0.90658 | v_loss: 0.41331 v_acc: 0.90690 |  iteration: 4016 teacher: 0 stage: sketch lr: 0.000697\n",
      "batch 287 loss: 0.31037 acc: 0.90658 | v_loss: 1.10942 v_acc: 0.79688 |  iteration: 4017 teacher: 0 stage: sketch lr: 0.000697\n",
      "batch 288 loss: 0.31625 acc: 0.90397 | v_loss: 0.39473 v_acc: 0.90918 |  iteration: 4018 teacher: 0 stage: sketch lr: 0.000697\n",
      "batch 289 loss: 0.28737 acc: 0.91667 | v_loss: 0.59487 v_acc: 0.87207 |  iteration: 4019 teacher: 1 stage: sketch lr: 0.000697\n",
      "batch 290 loss: 0.27532 acc: 0.92350 | v_loss: 0.51254 v_acc: 0.89388 |  iteration: 4020 teacher: 1 stage: sketch lr: 0.000697\n",
      "batch 291 loss: 0.35676 acc: 0.89583 | v_loss: 0.45465 v_acc: 0.89681 |  iteration: 4021 teacher: 0 stage: sketch lr: 0.000697\n",
      "batch 292 loss: 0.30987 acc: 0.91732 | v_loss: 0.54124 v_acc: 0.88444 |  iteration: 4022 teacher: 0 stage: sketch lr: 0.000697\n",
      "batch 293 loss: 0.31299 acc: 0.90918 | v_loss: 0.58021 v_acc: 0.87598 |  iteration: 4023 teacher: 0 stage: sketch lr: 0.000697\n",
      "batch 294 loss: 0.28258 acc: 0.91569 | v_loss: 0.46914 v_acc: 0.90527 |  iteration: 4024 teacher: 1 stage: sketch lr: 0.000697\n",
      "batch 295 loss: 0.24678 acc: 0.92383 | v_loss: 0.63752 v_acc: 0.86523 |  iteration: 4025 teacher: 0 stage: sketch lr: 0.000697\n",
      "batch 296 loss: 0.23592 acc: 0.92839 | v_loss: 0.41371 v_acc: 0.89811 |  iteration: 4026 teacher: 0 stage: sketch lr: 0.000697\n",
      "batch 297 loss: 0.31627 acc: 0.91536 | v_loss: 1.01354 v_acc: 0.81445 |  iteration: 4027 teacher: 1 stage: sketch lr: 0.000696\n",
      "batch 298 loss: 0.34355 acc: 0.90918 | v_loss: 0.61339 v_acc: 0.88314 |  iteration: 4028 teacher: 0 stage: sketch lr: 0.000696\n",
      "batch 299 loss: 0.29894 acc: 0.91341 | v_loss: 0.71272 v_acc: 0.86523 |  iteration: 4029 teacher: 0 stage: sketch lr: 0.000696\n",
      "batch 300 loss: 0.31016 acc: 0.91602 | v_loss: 0.42478 v_acc: 0.90072 |  iteration: 4030 teacher: 0 stage: sketch lr: 0.000696\n",
      "batch 301 loss: 0.27214 acc: 0.91927 | v_loss: 0.65349 v_acc: 0.86589 |  iteration: 4031 teacher: 1 stage: sketch lr: 0.000696\n",
      "batch 302 loss: 0.29836 acc: 0.91569 | v_loss: 0.46160 v_acc: 0.88932 |  iteration: 4032 teacher: 0 stage: sketch lr: 0.000696\n",
      "batch 303 loss: 0.30158 acc: 0.90788 | v_loss: 0.49474 v_acc: 0.88444 |  iteration: 4033 teacher: 1 stage: sketch lr: 0.000696\n",
      "batch 304 loss: 0.37336 acc: 0.90397 | v_loss: 0.43627 v_acc: 0.88574 |  iteration: 4034 teacher: 0 stage: sketch lr: 0.000696\n",
      "batch 305 loss: 0.38880 acc: 0.89258 | v_loss: 0.69934 v_acc: 0.84896 |  iteration: 4035 teacher: 0 stage: sketch lr: 0.000696\n",
      "batch 306 loss: 0.28826 acc: 0.92122 | v_loss: 0.49619 v_acc: 0.89128 |  iteration: 4036 teacher: 1 stage: sketch lr: 0.000696\n",
      "batch 307 loss: 0.26782 acc: 0.91569 | v_loss: 0.51895 v_acc: 0.87858 |  iteration: 4037 teacher: 0 stage: sketch lr: 0.000696\n",
      "batch 308 loss: 0.25736 acc: 0.92546 | v_loss: 0.68663 v_acc: 0.84310 |  iteration: 4038 teacher: 0 stage: sketch lr: 0.000695\n",
      "batch 309 loss: 0.29018 acc: 0.91113 | v_loss: 0.43957 v_acc: 0.89453 |  iteration: 4039 teacher: 0 stage: sketch lr: 0.000695\n",
      "batch 310 loss: 0.31457 acc: 0.90658 | v_loss: 0.53991 v_acc: 0.86979 |  iteration: 4040 teacher: 0 stage: sketch lr: 0.000695\n",
      "batch 311 loss: 0.30895 acc: 0.90560 | v_loss: 0.55517 v_acc: 0.86979 |  iteration: 4041 teacher: 1 stage: sketch lr: 0.000695\n",
      "batch 312 loss: 0.30136 acc: 0.91504 | v_loss: 0.75111 v_acc: 0.85514 |  iteration: 4042 teacher: 1 stage: sketch lr: 0.000695\n",
      "batch 313 loss: 0.25132 acc: 0.92383 | v_loss: 0.55557 v_acc: 0.89421 |  iteration: 4043 teacher: 0 stage: sketch lr: 0.000695\n",
      "batch 314 loss: 0.28526 acc: 0.91764 | v_loss: 0.57034 v_acc: 0.89486 |  iteration: 4044 teacher: 1 stage: sketch lr: 0.000695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 315 loss: 0.31654 acc: 0.91960 | v_loss: 0.67173 v_acc: 0.87533 |  iteration: 4045 teacher: 0 stage: sketch lr: 0.000695\n",
      "batch 316 loss: 0.22299 acc: 0.93717 | v_loss: 0.57743 v_acc: 0.86393 |  iteration: 4046 teacher: 0 stage: sketch lr: 0.000695\n",
      "batch 317 loss: 0.18744 acc: 0.94010 | v_loss: 0.44721 v_acc: 0.90299 |  iteration: 4047 teacher: 0 stage: sketch lr: 0.000695\n",
      "batch 318 loss: 0.21309 acc: 0.93392 | v_loss: 0.77553 v_acc: 0.83561 |  iteration: 4048 teacher: 1 stage: sketch lr: 0.000695\n",
      "batch 319 loss: 0.31415 acc: 0.90430 | v_loss: 0.58258 v_acc: 0.87891 |  iteration: 4049 teacher: 0 stage: sketch lr: 0.000695\n",
      "batch 320 loss: 0.31317 acc: 0.90430 | v_loss: 0.54696 v_acc: 0.87858 |  iteration: 4050 teacher: 1 stage: sketch lr: 0.000694\n",
      "batch 321 loss: 0.26633 acc: 0.92155 | v_loss: 0.53124 v_acc: 0.87467 |  iteration: 4051 teacher: 0 stage: sketch lr: 0.000694\n",
      "batch 322 loss: 0.30192 acc: 0.91471 | v_loss: 0.49145 v_acc: 0.89453 |  iteration: 4052 teacher: 0 stage: sketch lr: 0.000694\n",
      "batch 323 loss: 0.25840 acc: 0.92090 | v_loss: 0.45535 v_acc: 0.89648 |  iteration: 4053 teacher: 1 stage: sketch lr: 0.000694\n",
      "batch 324 loss: 0.30074 acc: 0.91341 | v_loss: 0.52658 v_acc: 0.88184 |  iteration: 4054 teacher: 1 stage: sketch lr: 0.000694\n",
      "batch 325 loss: 0.28511 acc: 0.91243 | v_loss: 0.63203 v_acc: 0.85189 |  iteration: 4055 teacher: 0 stage: sketch lr: 0.000694\n",
      "batch 326 loss: 0.29507 acc: 0.91569 | v_loss: 0.57861 v_acc: 0.88314 |  iteration: 4056 teacher: 1 stage: sketch lr: 0.000694\n",
      "batch 327 loss: 0.24654 acc: 0.93066 | v_loss: 0.60392 v_acc: 0.87240 |  iteration: 4057 teacher: 0 stage: sketch lr: 0.000694\n",
      "batch 328 loss: 0.26480 acc: 0.92253 | v_loss: 0.39796 v_acc: 0.90397 |  iteration: 4058 teacher: 1 stage: sketch lr: 0.000694\n",
      "batch 329 loss: 0.31826 acc: 0.90365 | v_loss: 0.54462 v_acc: 0.88737 |  iteration: 4059 teacher: 0 stage: sketch lr: 0.000694\n",
      "batch 330 loss: 0.30097 acc: 0.91895 | v_loss: 0.48183 v_acc: 0.88509 |  iteration: 4060 teacher: 1 stage: sketch lr: 0.000694\n",
      "batch 331 loss: 0.29776 acc: 0.90885 | v_loss: 0.84728 v_acc: 0.82487 |  iteration: 4061 teacher: 0 stage: sketch lr: 0.000694\n",
      "batch 332 loss: 0.23944 acc: 0.93327 | v_loss: 0.37348 v_acc: 0.90788 |  iteration: 4062 teacher: 1 stage: sketch lr: 0.000693\n",
      "batch 333 loss: 0.39004 acc: 0.89290 | v_loss: 0.30330 v_acc: 0.92546 |  iteration: 4063 teacher: 0 stage: sketch lr: 0.000693\n",
      "batch 334 loss: 0.19703 acc: 0.94661 | v_loss: 0.60257 v_acc: 0.87760 |  iteration: 4064 teacher: 1 stage: sketch lr: 0.000693\n",
      "batch 335 loss: 0.25037 acc: 0.92415 | v_loss: 0.58619 v_acc: 0.87598 |  iteration: 4065 teacher: 0 stage: sketch lr: 0.000693\n",
      "batch 336 loss: 0.26505 acc: 0.91960 | v_loss: 0.65526 v_acc: 0.86751 |  iteration: 4066 teacher: 0 stage: sketch lr: 0.000693\n",
      "batch 337 loss: 0.21401 acc: 0.93587 | v_loss: 0.46445 v_acc: 0.89388 |  iteration: 4067 teacher: 1 stage: sketch lr: 0.000693\n",
      "batch 338 loss: 0.36905 acc: 0.89062 | v_loss: 0.54857 v_acc: 0.87956 |  iteration: 4068 teacher: 0 stage: sketch lr: 0.000693\n",
      "batch 339 loss: 0.32783 acc: 0.90495 | v_loss: 0.62337 v_acc: 0.86816 |  iteration: 4069 teacher: 1 stage: sketch lr: 0.000693\n",
      "batch 340 loss: 0.27031 acc: 0.92383 | v_loss: 0.66775 v_acc: 0.84408 |  iteration: 4070 teacher: 0 stage: sketch lr: 0.000693\n",
      "batch 341 loss: 0.27742 acc: 0.91960 | v_loss: 0.54238 v_acc: 0.88672 |  iteration: 4071 teacher: 1 stage: sketch lr: 0.000693\n",
      "batch 342 loss: 0.30292 acc: 0.90918 | v_loss: 0.40513 v_acc: 0.90755 |  iteration: 4072 teacher: 0 stage: sketch lr: 0.000693\n",
      "batch 343 loss: 0.32476 acc: 0.91276 | v_loss: 0.34843 v_acc: 0.91797 |  iteration: 4073 teacher: 1 stage: sketch lr: 0.000692\n",
      "batch 344 loss: 0.24691 acc: 0.92318 | v_loss: 0.50023 v_acc: 0.89681 |  iteration: 4074 teacher: 0 stage: sketch lr: 0.000692\n",
      "batch 345 loss: 0.36991 acc: 0.89876 | v_loss: 0.47284 v_acc: 0.89095 |  iteration: 4075 teacher: 1 stage: sketch lr: 0.000692\n",
      "batch 346 loss: 0.30341 acc: 0.91699 | v_loss: 0.81419 v_acc: 0.85579 |  iteration: 4076 teacher: 0 stage: sketch lr: 0.000692\n",
      "batch 347 loss: 0.27689 acc: 0.91960 | v_loss: 0.56759 v_acc: 0.87598 |  iteration: 4077 teacher: 1 stage: sketch lr: 0.000692\n",
      "batch 348 loss: 0.27655 acc: 0.92448 | v_loss: 0.63696 v_acc: 0.86979 |  iteration: 4078 teacher: 0 stage: sketch lr: 0.000692\n",
      "batch 349 loss: 0.35272 acc: 0.89388 | v_loss: 0.41972 v_acc: 0.90267 |  iteration: 4079 teacher: 0 stage: sketch lr: 0.000692\n",
      "batch 350 loss: 0.29597 acc: 0.91211 | v_loss: 0.56613 v_acc: 0.87826 |  iteration: 4080 teacher: 0 stage: sketch lr: 0.000692\n",
      "batch 351 loss: 0.33566 acc: 0.90951 | v_loss: 0.78595 v_acc: 0.83073 |  iteration: 4081 teacher: 0 stage: sketch lr: 0.000692\n",
      "batch 352 loss: 0.29161 acc: 0.91439 | v_loss: 0.54944 v_acc: 0.88346 |  iteration: 4082 teacher: 0 stage: sketch lr: 0.000692\n",
      "batch 353 loss: 0.24948 acc: 0.92318 | v_loss: 0.53157 v_acc: 0.88184 |  iteration: 4083 teacher: 1 stage: sketch lr: 0.000692\n",
      "batch 354 loss: 0.23145 acc: 0.93262 | v_loss: 0.50505 v_acc: 0.88249 |  iteration: 4084 teacher: 0 stage: sketch lr: 0.000692\n",
      "batch 355 loss: 0.37604 acc: 0.89844 | v_loss: 0.41655 v_acc: 0.90072 |  iteration: 4085 teacher: 1 stage: sketch lr: 0.000691\n",
      "batch 356 loss: 0.31685 acc: 0.90560 | v_loss: 0.47156 v_acc: 0.90104 |  iteration: 4086 teacher: 1 stage: sketch lr: 0.000691\n",
      "batch 357 loss: 0.23762 acc: 0.93392 | v_loss: 0.57655 v_acc: 0.86947 |  iteration: 4087 teacher: 1 stage: sketch lr: 0.000691\n",
      "batch 358 loss: 0.40763 acc: 0.88900 | v_loss: 0.35645 v_acc: 0.91927 |  iteration: 4088 teacher: 1 stage: sketch lr: 0.000691\n",
      "batch 359 loss: 0.31953 acc: 0.90625 | v_loss: 0.94716 v_acc: 0.82064 |  iteration: 4089 teacher: 1 stage: sketch lr: 0.000691\n",
      "batch 360 loss: 0.34089 acc: 0.90234 | v_loss: 0.64811 v_acc: 0.86947 |  iteration: 4090 teacher: 1 stage: sketch lr: 0.000691\n",
      "batch 361 loss: 0.32981 acc: 0.90592 | v_loss: 0.64668 v_acc: 0.85775 |  iteration: 4091 teacher: 0 stage: sketch lr: 0.000691\n",
      "batch 362 loss: 0.26846 acc: 0.91732 | v_loss: 0.54127 v_acc: 0.89193 |  iteration: 4092 teacher: 0 stage: sketch lr: 0.000691\n",
      "batch 363 loss: 0.26957 acc: 0.92253 | v_loss: 0.55091 v_acc: 0.88574 |  iteration: 4093 teacher: 0 stage: sketch lr: 0.000691\n",
      "batch 364 loss: 0.28238 acc: 0.92122 | v_loss: 0.59181 v_acc: 0.88639 |  iteration: 4094 teacher: 1 stage: sketch lr: 0.000691\n",
      "batch 365 loss: 0.27300 acc: 0.92741 | v_loss: 0.55102 v_acc: 0.88607 |  iteration: 4095 teacher: 0 stage: sketch lr: 0.000691\n",
      "batch 366 loss: 0.29808 acc: 0.91895 | v_loss: 0.49953 v_acc: 0.88704 |  iteration: 4096 teacher: 0 stage: sketch lr: 0.000691\n",
      "batch 367 loss: 0.28926 acc: 0.91895 | v_loss: 0.48125 v_acc: 0.89941 |  iteration: 4097 teacher: 1 stage: sketch lr: 0.000690\n",
      "batch 368 loss: 0.20246 acc: 0.94108 | v_loss: 0.47200 v_acc: 0.88932 |  iteration: 4098 teacher: 1 stage: sketch lr: 0.000690\n",
      "batch 369 loss: 0.28442 acc: 0.91243 | v_loss: 0.33633 v_acc: 0.91374 |  iteration: 4099 teacher: 1 stage: sketch lr: 0.000690\n",
      "batch 370 loss: 0.31388 acc: 0.91276 | v_loss: 0.58755 v_acc: 0.86491 |  iteration: 4100 teacher: 1 stage: sketch lr: 0.000690\n",
      "batch 371 loss: 0.25828 acc: 0.91895 | v_loss: 0.54770 v_acc: 0.86458 |  iteration: 4101 teacher: 1 stage: sketch lr: 0.000690\n",
      "batch 372 loss: 0.38037 acc: 0.88835 | v_loss: 0.58462 v_acc: 0.86816 |  iteration: 4102 teacher: 0 stage: sketch lr: 0.000690\n",
      "batch 373 loss: 0.26336 acc: 0.93164 | v_loss: 0.76716 v_acc: 0.84668 |  iteration: 4103 teacher: 1 stage: sketch lr: 0.000690\n",
      "batch 374 loss: 0.31894 acc: 0.90885 | v_loss: 0.37722 v_acc: 0.91764 |  iteration: 4104 teacher: 1 stage: sketch lr: 0.000690\n",
      "batch 375 loss: 0.29966 acc: 0.91927 | v_loss: 0.54186 v_acc: 0.87793 |  iteration: 4105 teacher: 0 stage: sketch lr: 0.000690\n",
      "batch 376 loss: 0.29917 acc: 0.91536 | v_loss: 0.53266 v_acc: 0.88900 |  iteration: 4106 teacher: 0 stage: sketch lr: 0.000690\n",
      "batch 377 loss: 0.20870 acc: 0.93652 | v_loss: 0.42073 v_acc: 0.90267 |  iteration: 4107 teacher: 1 stage: sketch lr: 0.000690\n",
      "batch 378 loss: 0.28920 acc: 0.92025 | v_loss: 1.14046 v_acc: 0.80078 |  iteration: 4108 teacher: 0 stage: sketch lr: 0.000690\n",
      "batch 379 loss: 0.27836 acc: 0.91048 | v_loss: 0.39689 v_acc: 0.91797 |  iteration: 4109 teacher: 0 stage: sketch lr: 0.000689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 380 loss: 0.26098 acc: 0.92676 | v_loss: 0.63295 v_acc: 0.88053 |  iteration: 4110 teacher: 0 stage: sketch lr: 0.000689\n",
      "batch 381 loss: 0.27520 acc: 0.93001 | v_loss: 0.50951 v_acc: 0.89811 |  iteration: 4111 teacher: 0 stage: sketch lr: 0.000689\n",
      "batch 382 loss: 0.24697 acc: 0.93685 | v_loss: 0.41982 v_acc: 0.90820 |  iteration: 4112 teacher: 0 stage: sketch lr: 0.000689\n",
      "batch 383 loss: 0.26750 acc: 0.93001 | v_loss: 0.52890 v_acc: 0.88574 |  iteration: 4113 teacher: 1 stage: sketch lr: 0.000689\n",
      "batch 384 loss: 0.31957 acc: 0.90397 | v_loss: 0.60369 v_acc: 0.86784 |  iteration: 4114 teacher: 1 stage: sketch lr: 0.000689\n",
      "batch 385 loss: 0.23158 acc: 0.93164 | v_loss: 0.44058 v_acc: 0.89746 |  iteration: 4115 teacher: 0 stage: sketch lr: 0.000689\n",
      "batch 386 loss: 0.31827 acc: 0.91341 | v_loss: 0.60823 v_acc: 0.86035 |  iteration: 4116 teacher: 1 stage: sketch lr: 0.000689\n",
      "batch 387 loss: 0.30228 acc: 0.91536 | v_loss: 0.38797 v_acc: 0.90039 |  iteration: 4117 teacher: 1 stage: sketch lr: 0.000689\n",
      "batch 388 loss: 0.30287 acc: 0.91569 | v_loss: 0.94913 v_acc: 0.80957 |  iteration: 4118 teacher: 1 stage: sketch lr: 0.000689\n",
      "batch 389 loss: 0.26047 acc: 0.92513 | v_loss: 0.59794 v_acc: 0.86979 |  iteration: 4119 teacher: 1 stage: sketch lr: 0.000689\n",
      "batch 390 loss: 0.31467 acc: 0.90430 | v_loss: 0.69369 v_acc: 0.86165 |  iteration: 4120 teacher: 1 stage: sketch lr: 0.000689\n",
      "batch 391 loss: 0.31802 acc: 0.91764 | v_loss: 0.39959 v_acc: 0.90267 |  iteration: 4121 teacher: 1 stage: sketch lr: 0.000688\n",
      "batch 392 loss: 0.21692 acc: 0.93490 | v_loss: 0.67289 v_acc: 0.84766 |  iteration: 4122 teacher: 1 stage: sketch lr: 0.000688\n",
      "batch 393 loss: 0.30355 acc: 0.90755 | v_loss: 0.43871 v_acc: 0.89648 |  iteration: 4123 teacher: 1 stage: sketch lr: 0.000688\n",
      "batch 394 loss: 0.34124 acc: 0.89518 | v_loss: 0.47252 v_acc: 0.88867 |  iteration: 4124 teacher: 0 stage: sketch lr: 0.000688\n",
      "batch 395 loss: 0.29436 acc: 0.90885 | v_loss: 0.42704 v_acc: 0.89811 |  iteration: 4125 teacher: 1 stage: sketch lr: 0.000688\n",
      "batch 396 loss: 0.30736 acc: 0.91602 | v_loss: 0.71309 v_acc: 0.85775 |  iteration: 4126 teacher: 0 stage: sketch lr: 0.000688\n",
      "batch 397 loss: 0.24512 acc: 0.93620 | v_loss: 0.49327 v_acc: 0.90332 |  iteration: 4127 teacher: 1 stage: sketch lr: 0.000688\n",
      "batch 398 loss: 0.31422 acc: 0.91178 | v_loss: 0.51726 v_acc: 0.88118 |  iteration: 4128 teacher: 1 stage: sketch lr: 0.000688\n",
      "batch 399 loss: 0.33502 acc: 0.91243 | v_loss: 0.66957 v_acc: 0.84831 |  iteration: 4129 teacher: 1 stage: sketch lr: 0.000688\n",
      "batch 400 loss: 0.24454 acc: 0.92676 | v_loss: 0.41767 v_acc: 0.89648 |  iteration: 4130 teacher: 0 stage: sketch lr: 0.000688\n",
      "batch 401 loss: 0.23051 acc: 0.93685 | v_loss: 0.49252 v_acc: 0.87467 |  iteration: 4131 teacher: 0 stage: sketch lr: 0.000688\n",
      "batch 402 loss: 0.25899 acc: 0.92220 | v_loss: 0.53229 v_acc: 0.87337 |  iteration: 4132 teacher: 0 stage: sketch lr: 0.000688\n",
      "batch 403 loss: 0.33560 acc: 0.90104 | v_loss: 0.70546 v_acc: 0.85970 |  iteration: 4133 teacher: 0 stage: sketch lr: 0.000687\n",
      "batch 404 loss: 0.36691 acc: 0.89909 | v_loss: 0.57276 v_acc: 0.88737 |  iteration: 4134 teacher: 0 stage: sketch lr: 0.000687\n",
      "batch 405 loss: 0.26847 acc: 0.91602 | v_loss: 0.55553 v_acc: 0.89062 |  iteration: 4135 teacher: 1 stage: sketch lr: 0.000687\n",
      "batch 406 loss: 0.27907 acc: 0.91960 | v_loss: 0.64148 v_acc: 0.88021 |  iteration: 4136 teacher: 0 stage: sketch lr: 0.000687\n",
      "batch 407 loss: 0.25787 acc: 0.92220 | v_loss: 0.62410 v_acc: 0.85905 |  iteration: 4137 teacher: 1 stage: sketch lr: 0.000687\n",
      "batch 408 loss: 0.27943 acc: 0.92025 | v_loss: 0.48700 v_acc: 0.89779 |  iteration: 4138 teacher: 1 stage: sketch lr: 0.000687\n",
      "batch 409 loss: 0.34219 acc: 0.89811 | v_loss: 0.80504 v_acc: 0.83659 |  iteration: 4139 teacher: 0 stage: sketch lr: 0.000687\n",
      "batch 410 loss: 0.24991 acc: 0.93066 | v_loss: 0.59015 v_acc: 0.87695 |  iteration: 4140 teacher: 1 stage: sketch lr: 0.000687\n",
      "batch 411 loss: 0.30586 acc: 0.91146 | v_loss: 0.55983 v_acc: 0.86947 |  iteration: 4141 teacher: 0 stage: sketch lr: 0.000687\n",
      "batch 412 loss: 0.26909 acc: 0.92253 | v_loss: 0.50899 v_acc: 0.88249 |  iteration: 4142 teacher: 0 stage: sketch lr: 0.000687\n",
      "batch 413 loss: 0.32785 acc: 0.90918 | v_loss: 0.48924 v_acc: 0.88932 |  iteration: 4143 teacher: 1 stage: sketch lr: 0.000687\n",
      "batch 414 loss: 0.29295 acc: 0.91243 | v_loss: 0.46531 v_acc: 0.88672 |  iteration: 4144 teacher: 1 stage: sketch lr: 0.000687\n",
      "batch 415 loss: 0.29144 acc: 0.90332 | v_loss: 0.49999 v_acc: 0.88574 |  iteration: 4145 teacher: 0 stage: sketch lr: 0.000686\n",
      "batch 416 loss: 0.30280 acc: 0.91309 | v_loss: 0.63932 v_acc: 0.84766 |  iteration: 4146 teacher: 0 stage: sketch lr: 0.000686\n",
      "batch 417 loss: 0.25073 acc: 0.92904 | v_loss: 0.56326 v_acc: 0.88086 |  iteration: 4147 teacher: 0 stage: sketch lr: 0.000686\n",
      "batch 418 loss: 0.28064 acc: 0.91764 | v_loss: 0.58839 v_acc: 0.88607 |  iteration: 4148 teacher: 0 stage: sketch lr: 0.000686\n",
      "batch 419 loss: 0.36447 acc: 0.89909 | v_loss: 0.39483 v_acc: 0.91146 |  iteration: 4149 teacher: 1 stage: sketch lr: 0.000686\n",
      "batch 420 loss: 0.23703 acc: 0.93555 | v_loss: 0.52677 v_acc: 0.88509 |  iteration: 4150 teacher: 0 stage: sketch lr: 0.000686\n",
      "batch 421 loss: 0.40505 acc: 0.88737 | v_loss: 0.50904 v_acc: 0.87760 |  iteration: 4151 teacher: 0 stage: sketch lr: 0.000686\n",
      "batch 422 loss: 0.31687 acc: 0.91406 | v_loss: 0.84181 v_acc: 0.82845 |  iteration: 4152 teacher: 1 stage: sketch lr: 0.000686\n",
      "batch 423 loss: 0.30066 acc: 0.90723 | v_loss: 0.35461 v_acc: 0.91081 |  iteration: 4153 teacher: 1 stage: sketch lr: 0.000686\n",
      "batch 424 loss: 0.30849 acc: 0.90853 | v_loss: 0.32463 v_acc: 0.92513 |  iteration: 4154 teacher: 0 stage: sketch lr: 0.000686\n",
      "batch 425 loss: 0.29058 acc: 0.90853 | v_loss: 0.54888 v_acc: 0.88184 |  iteration: 4155 teacher: 0 stage: sketch lr: 0.000686\n",
      "batch 426 loss: 0.27037 acc: 0.92546 | v_loss: 0.55042 v_acc: 0.88900 |  iteration: 4156 teacher: 1 stage: sketch lr: 0.000686\n",
      "batch 427 loss: 0.20114 acc: 0.94336 | v_loss: 0.65273 v_acc: 0.86068 |  iteration: 4157 teacher: 1 stage: sketch lr: 0.000685\n",
      "batch 428 loss: 0.30309 acc: 0.91243 | v_loss: 0.41108 v_acc: 0.90365 |  iteration: 4158 teacher: 0 stage: sketch lr: 0.000685\n",
      "batch 429 loss: 0.20286 acc: 0.93685 | v_loss: 0.51683 v_acc: 0.87207 |  iteration: 4159 teacher: 0 stage: sketch lr: 0.000685\n",
      "batch 430 loss: 0.23761 acc: 0.93132 | v_loss: 0.62097 v_acc: 0.85938 |  iteration: 4160 teacher: 1 stage: sketch lr: 0.000685\n",
      "batch 431 loss: 0.34971 acc: 0.89974 | v_loss: 0.63832 v_acc: 0.85449 |  iteration: 4161 teacher: 0 stage: sketch lr: 0.000685\n",
      "batch 432 loss: 0.29064 acc: 0.92188 | v_loss: 0.49021 v_acc: 0.88542 |  iteration: 4162 teacher: 1 stage: sketch lr: 0.000685\n",
      "batch 433 loss: 0.25848 acc: 0.92383 | v_loss: 0.39433 v_acc: 0.90267 |  iteration: 4163 teacher: 0 stage: sketch lr: 0.000685\n",
      "batch 434 loss: 0.35983 acc: 0.89876 | v_loss: 0.31004 v_acc: 0.91536 |  iteration: 4164 teacher: 0 stage: sketch lr: 0.000685\n",
      "batch 435 loss: 0.28179 acc: 0.91699 | v_loss: 0.47397 v_acc: 0.90007 |  iteration: 4165 teacher: 0 stage: sketch lr: 0.000685\n",
      "batch 436 loss: 0.30017 acc: 0.91764 | v_loss: 0.50714 v_acc: 0.88770 |  iteration: 4166 teacher: 0 stage: sketch lr: 0.000685\n",
      "batch 437 loss: 0.26996 acc: 0.92578 | v_loss: 0.81759 v_acc: 0.85319 |  iteration: 4167 teacher: 1 stage: sketch lr: 0.000685\n",
      "batch 438 loss: 0.35766 acc: 0.89746 | v_loss: 0.55928 v_acc: 0.88021 |  iteration: 4168 teacher: 0 stage: sketch lr: 0.000685\n",
      "batch 439 loss: 0.36289 acc: 0.89941 | v_loss: 0.64438 v_acc: 0.87174 |  iteration: 4169 teacher: 0 stage: sketch lr: 0.000684\n",
      "batch 440 loss: 0.32706 acc: 0.91178 | v_loss: 0.40505 v_acc: 0.90462 |  iteration: 4170 teacher: 1 stage: sketch lr: 0.000684\n",
      "batch 441 loss: 0.34904 acc: 0.89844 | v_loss: 0.56197 v_acc: 0.88542 |  iteration: 4171 teacher: 0 stage: sketch lr: 0.000684\n",
      "batch 442 loss: 0.33800 acc: 0.90299 | v_loss: 0.78124 v_acc: 0.84473 |  iteration: 4172 teacher: 0 stage: sketch lr: 0.000684\n",
      "batch 443 loss: 0.28129 acc: 0.92122 | v_loss: 0.54876 v_acc: 0.88444 |  iteration: 4173 teacher: 0 stage: sketch lr: 0.000684\n",
      "batch 444 loss: 0.28981 acc: 0.91992 | v_loss: 0.52651 v_acc: 0.88770 |  iteration: 4174 teacher: 0 stage: sketch lr: 0.000684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 445 loss: 0.29535 acc: 0.91634 | v_loss: 0.49833 v_acc: 0.88477 |  iteration: 4175 teacher: 0 stage: sketch lr: 0.000684\n",
      "batch 446 loss: 0.31388 acc: 0.91146 | v_loss: 0.41190 v_acc: 0.90039 |  iteration: 4176 teacher: 0 stage: sketch lr: 0.000684\n",
      "batch 447 loss: 0.25517 acc: 0.92806 | v_loss: 0.45753 v_acc: 0.90430 |  iteration: 4177 teacher: 1 stage: sketch lr: 0.000684\n",
      "batch 448 loss: 0.27202 acc: 0.92383 | v_loss: 0.60311 v_acc: 0.87077 |  iteration: 4178 teacher: 1 stage: sketch lr: 0.000684\n",
      "batch 449 loss: 0.23233 acc: 0.93066 | v_loss: 0.37788 v_acc: 0.91960 |  iteration: 4179 teacher: 1 stage: sketch lr: 0.000684\n",
      "batch 450 loss: 0.24281 acc: 0.92871 | v_loss: 0.87699 v_acc: 0.82389 |  iteration: 4180 teacher: 1 stage: sketch lr: 0.000684\n",
      "batch 451 loss: 0.32508 acc: 0.90853 | v_loss: 0.61009 v_acc: 0.87760 |  iteration: 4181 teacher: 1 stage: sketch lr: 0.000683\n",
      "batch 452 loss: 0.33209 acc: 0.90560 | v_loss: 0.70101 v_acc: 0.86426 |  iteration: 4182 teacher: 1 stage: sketch lr: 0.000683\n",
      "batch 453 loss: 0.20973 acc: 0.94108 | v_loss: 0.53352 v_acc: 0.89258 |  iteration: 4183 teacher: 1 stage: sketch lr: 0.000683\n",
      "batch 454 loss: 0.30121 acc: 0.91699 | v_loss: 0.48314 v_acc: 0.89062 |  iteration: 4184 teacher: 0 stage: sketch lr: 0.000683\n",
      "batch 455 loss: 0.31433 acc: 0.91178 | v_loss: 0.55906 v_acc: 0.89128 |  iteration: 4185 teacher: 1 stage: sketch lr: 0.000683\n",
      "batch 456 loss: 0.29327 acc: 0.91406 | v_loss: 0.52118 v_acc: 0.89030 |  iteration: 4186 teacher: 0 stage: sketch lr: 0.000683\n",
      "batch 457 loss: 0.30969 acc: 0.90332 | v_loss: 0.49504 v_acc: 0.88249 |  iteration: 4187 teacher: 0 stage: sketch lr: 0.000683\n",
      "batch 458 loss: 0.20281 acc: 0.93848 | v_loss: 0.49050 v_acc: 0.90007 |  iteration: 4188 teacher: 1 stage: sketch lr: 0.000683\n",
      "batch 459 loss: 0.33654 acc: 0.90495 | v_loss: 0.43687 v_acc: 0.90169 |  iteration: 4189 teacher: 1 stage: sketch lr: 0.000683\n",
      "batch 460 loss: 0.28167 acc: 0.91667 | v_loss: 0.40591 v_acc: 0.91243 |  iteration: 4190 teacher: 1 stage: sketch lr: 0.000683\n",
      "batch 461 loss: 0.22453 acc: 0.94173 | v_loss: 0.67053 v_acc: 0.85352 |  iteration: 4191 teacher: 1 stage: sketch lr: 0.000683\n",
      "batch 462 loss: 0.45660 acc: 0.87858 | v_loss: 0.56543 v_acc: 0.87012 |  iteration: 4192 teacher: 0 stage: sketch lr: 0.000683\n",
      "batch 463 loss: 0.29295 acc: 0.91895 | v_loss: 0.65557 v_acc: 0.85905 |  iteration: 4193 teacher: 1 stage: sketch lr: 0.000682\n",
      "batch 464 loss: 0.28898 acc: 0.91634 | v_loss: 0.88487 v_acc: 0.83822 |  iteration: 4194 teacher: 0 stage: sketch lr: 0.000682\n",
      "batch 465 loss: 0.28721 acc: 0.92350 | v_loss: 0.48262 v_acc: 0.89421 |  iteration: 4195 teacher: 1 stage: sketch lr: 0.000682\n",
      "batch 466 loss: 0.30859 acc: 0.91374 | v_loss: 0.61024 v_acc: 0.87663 |  iteration: 4196 teacher: 1 stage: sketch lr: 0.000682\n",
      "batch 467 loss: 0.33189 acc: 0.91471 | v_loss: 0.56157 v_acc: 0.88509 |  iteration: 4197 teacher: 0 stage: sketch lr: 0.000682\n",
      "batch 468 loss: 0.41968 acc: 0.89095 | v_loss: 0.44622 v_acc: 0.90788 |  iteration: 4198 teacher: 1 stage: sketch lr: 0.000682\n",
      "batch 469 loss: 0.29690 acc: 0.91569 | v_loss: 1.16810 v_acc: 0.79753 |  iteration: 4199 teacher: 0 stage: sketch lr: 0.000682\n",
      "batch 470 loss: 0.31646 acc: 0.90885 | v_loss: 0.41157 v_acc: 0.90690 |  iteration: 4200 teacher: 0 stage: sketch lr: 0.000682\n",
      "batch 471 loss: 0.26200 acc: 0.92350 | v_loss: 0.59539 v_acc: 0.86523 |  iteration: 4201 teacher: 0 stage: sketch lr: 0.000682\n",
      "batch 472 loss: 0.35917 acc: 0.89062 | v_loss: 0.50769 v_acc: 0.88932 |  iteration: 4202 teacher: 0 stage: sketch lr: 0.000682\n",
      "batch 473 loss: 0.25431 acc: 0.91602 | v_loss: 0.43501 v_acc: 0.89909 |  iteration: 4203 teacher: 1 stage: sketch lr: 0.000682\n",
      "batch 474 loss: 0.28537 acc: 0.91667 | v_loss: 0.53358 v_acc: 0.88086 |  iteration: 4204 teacher: 1 stage: sketch lr: 0.000682\n",
      "batch 475 loss: 0.34562 acc: 0.89681 | v_loss: 0.56914 v_acc: 0.87793 |  iteration: 4205 teacher: 0 stage: sketch lr: 0.000682\n",
      "batch 476 loss: 0.26304 acc: 0.92285 | v_loss: 0.44996 v_acc: 0.90527 |  iteration: 4206 teacher: 1 stage: sketch lr: 0.000681\n",
      "batch 477 loss: 0.29556 acc: 0.91406 | v_loss: 0.63544 v_acc: 0.86979 |  iteration: 4207 teacher: 1 stage: sketch lr: 0.000681\n",
      "batch 478 loss: 0.31429 acc: 0.91602 | v_loss: 0.42061 v_acc: 0.90625 |  iteration: 4208 teacher: 0 stage: sketch lr: 0.000681\n",
      "batch 479 loss: 0.23681 acc: 0.92871 | v_loss: 1.08394 v_acc: 0.81966 |  iteration: 4209 teacher: 1 stage: sketch lr: 0.000681\n",
      "batch 480 loss: 0.28443 acc: 0.92253 | v_loss: 0.55959 v_acc: 0.89095 |  iteration: 4210 teacher: 0 stage: sketch lr: 0.000681\n",
      "batch 481 loss: 0.32644 acc: 0.91471 | v_loss: 0.63752 v_acc: 0.86914 |  iteration: 4211 teacher: 1 stage: sketch lr: 0.000681\n",
      "batch 482 loss: 0.26770 acc: 0.92253 | v_loss: 0.42705 v_acc: 0.89811 |  iteration: 4212 teacher: 0 stage: sketch lr: 0.000681\n",
      "batch 483 loss: 0.21899 acc: 0.93978 | v_loss: 0.61484 v_acc: 0.86035 |  iteration: 4213 teacher: 1 stage: sketch lr: 0.000681\n",
      "batch 484 loss: 0.37602 acc: 0.89941 | v_loss: 0.44522 v_acc: 0.89323 |  iteration: 4214 teacher: 1 stage: sketch lr: 0.000681\n",
      "batch 485 loss: 0.38212 acc: 0.90072 | v_loss: 0.45675 v_acc: 0.89486 |  iteration: 4215 teacher: 1 stage: sketch lr: 0.000681\n",
      "batch 486 loss: 0.31920 acc: 0.90592 | v_loss: 0.40276 v_acc: 0.89486 |  iteration: 4216 teacher: 0 stage: sketch lr: 0.000681\n",
      "batch 487 loss: 0.34021 acc: 0.90365 | v_loss: 0.69216 v_acc: 0.85710 |  iteration: 4217 teacher: 0 stage: sketch lr: 0.000681\n",
      "batch 488 loss: 0.27554 acc: 0.92090 | v_loss: 0.49249 v_acc: 0.89583 |  iteration: 4218 teacher: 0 stage: sketch lr: 0.000680\n",
      "batch 489 loss: 0.25494 acc: 0.92350 | v_loss: 0.54919 v_acc: 0.87402 |  iteration: 4219 teacher: 0 stage: sketch lr: 0.000680\n",
      "batch 490 loss: 0.33865 acc: 0.90560 | v_loss: 0.65853 v_acc: 0.85514 |  iteration: 4220 teacher: 0 stage: sketch lr: 0.000680\n",
      "batch 491 loss: 0.22477 acc: 0.93066 | v_loss: 0.47194 v_acc: 0.88607 |  iteration: 4221 teacher: 0 stage: sketch lr: 0.000680\n",
      "batch 492 loss: 0.38383 acc: 0.88737 | v_loss: 0.49459 v_acc: 0.87142 |  iteration: 4222 teacher: 0 stage: sketch lr: 0.000680\n",
      "batch 493 loss: 0.29174 acc: 0.91960 | v_loss: 0.56160 v_acc: 0.86491 |  iteration: 4223 teacher: 0 stage: sketch lr: 0.000680\n",
      "batch 494 loss: 0.22910 acc: 0.92448 | v_loss: 0.78919 v_acc: 0.84375 |  iteration: 4224 teacher: 0 stage: sketch lr: 0.000680\n",
      "batch 495 loss: 0.20806 acc: 0.93066 | v_loss: 0.55757 v_acc: 0.88867 |  iteration: 4225 teacher: 0 stage: sketch lr: 0.000680\n",
      "batch 496 loss: 0.21914 acc: 0.93359 | v_loss: 0.56045 v_acc: 0.89095 |  iteration: 4226 teacher: 0 stage: sketch lr: 0.000680\n",
      "batch 497 loss: 0.25873 acc: 0.92643 | v_loss: 0.66461 v_acc: 0.88509 |  iteration: 4227 teacher: 0 stage: sketch lr: 0.000680\n",
      "batch 498 loss: 0.25662 acc: 0.93001 | v_loss: 0.61902 v_acc: 0.86165 |  iteration: 4228 teacher: 1 stage: sketch lr: 0.000680\n",
      "batch 499 loss: 0.34968 acc: 0.90495 | v_loss: 0.47966 v_acc: 0.90007 |  iteration: 4229 teacher: 0 stage: sketch lr: 0.000680\n",
      "batch 500 loss: 0.27343 acc: 0.92285 | v_loss: 0.83860 v_acc: 0.83398 |  iteration: 4230 teacher: 1 stage: sketch lr: 0.000680\n",
      "batch 501 loss: 0.38083 acc: 0.89453 | v_loss: 0.61446 v_acc: 0.87272 |  iteration: 4231 teacher: 1 stage: sketch lr: 0.000679\n",
      "batch 502 loss: 0.43630 acc: 0.87533 | v_loss: 0.57905 v_acc: 0.85970 |  iteration: 4232 teacher: 1 stage: sketch lr: 0.000679\n",
      "batch 503 loss: 0.29840 acc: 0.90723 | v_loss: 0.53495 v_acc: 0.88118 |  iteration: 4233 teacher: 0 stage: sketch lr: 0.000679\n",
      "batch 504 loss: 0.29878 acc: 0.90755 | v_loss: 0.48817 v_acc: 0.88932 |  iteration: 4234 teacher: 0 stage: sketch lr: 0.000679\n",
      "batch 505 loss: 0.26500 acc: 0.91634 | v_loss: 0.48702 v_acc: 0.89193 |  iteration: 4235 teacher: 0 stage: sketch lr: 0.000679\n",
      "batch 506 loss: 0.28827 acc: 0.92122 | v_loss: 0.57154 v_acc: 0.88574 |  iteration: 4236 teacher: 1 stage: sketch lr: 0.000679\n",
      "batch 507 loss: 0.41511 acc: 0.89290 | v_loss: 0.69291 v_acc: 0.84993 |  iteration: 4237 teacher: 1 stage: sketch lr: 0.000679\n",
      "batch 508 loss: 0.24736 acc: 0.92806 | v_loss: 0.60923 v_acc: 0.88672 |  iteration: 4238 teacher: 0 stage: sketch lr: 0.000679\n",
      "batch 509 loss: 0.28489 acc: 0.91960 | v_loss: 0.61094 v_acc: 0.87565 |  iteration: 4239 teacher: 0 stage: sketch lr: 0.000679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 510 loss: 0.36176 acc: 0.90007 | v_loss: 0.41661 v_acc: 0.89746 |  iteration: 4240 teacher: 0 stage: sketch lr: 0.000679\n",
      "batch 511 loss: 0.32093 acc: 0.90430 | v_loss: 0.60450 v_acc: 0.86393 |  iteration: 4241 teacher: 1 stage: sketch lr: 0.000679\n",
      "batch 512 loss: 0.34974 acc: 0.90397 | v_loss: 0.50507 v_acc: 0.87728 |  iteration: 4242 teacher: 1 stage: sketch lr: 0.000679\n",
      "batch 513 loss: 0.34304 acc: 0.90104 | v_loss: 0.89332 v_acc: 0.81934 |  iteration: 4243 teacher: 0 stage: sketch lr: 0.000678\n",
      "batch 514 loss: 0.50256 acc: 0.86686 | v_loss: 0.38113 v_acc: 0.89746 |  iteration: 4244 teacher: 1 stage: sketch lr: 0.000678\n",
      "batch 515 loss: 0.38722 acc: 0.89388 | v_loss: 0.29714 v_acc: 0.92350 |  iteration: 4245 teacher: 0 stage: sketch lr: 0.000678\n",
      "batch 516 loss: 0.23534 acc: 0.92741 | v_loss: 0.53631 v_acc: 0.88346 |  iteration: 4246 teacher: 0 stage: sketch lr: 0.000678\n",
      "batch 517 loss: 0.30107 acc: 0.91243 | v_loss: 0.56778 v_acc: 0.87891 |  iteration: 4247 teacher: 0 stage: sketch lr: 0.000678\n",
      "batch 518 loss: 0.35891 acc: 0.90430 | v_loss: 0.63455 v_acc: 0.86230 |  iteration: 4248 teacher: 1 stage: sketch lr: 0.000678\n",
      "batch 519 loss: 0.34364 acc: 0.89811 | v_loss: 0.41619 v_acc: 0.89844 |  iteration: 4249 teacher: 0 stage: sketch lr: 0.000678\n",
      "batch 520 loss: 0.33110 acc: 0.91016 | v_loss: 0.54716 v_acc: 0.86947 |  iteration: 4250 teacher: 1 stage: sketch lr: 0.000678\n",
      "batch 521 loss: 0.29598 acc: 0.91211 | v_loss: 0.62186 v_acc: 0.86361 |  iteration: 4251 teacher: 1 stage: sketch lr: 0.000678\n",
      "batch 522 loss: 0.28611 acc: 0.91439 | v_loss: 0.71775 v_acc: 0.83496 |  iteration: 4252 teacher: 1 stage: sketch lr: 0.000678\n",
      "batch 523 loss: 0.33762 acc: 0.90853 | v_loss: 0.50586 v_acc: 0.89388 |  iteration: 4253 teacher: 1 stage: sketch lr: 0.000678\n",
      "batch 524 loss: 0.33886 acc: 0.90495 | v_loss: 0.38485 v_acc: 0.90365 |  iteration: 4254 teacher: 1 stage: sketch lr: 0.000678\n",
      "batch 525 loss: 0.26144 acc: 0.92090 | v_loss: 0.31549 v_acc: 0.91895 |  iteration: 4255 teacher: 0 stage: sketch lr: 0.000678\n",
      "batch 526 loss: 0.32945 acc: 0.90365 | v_loss: 0.45301 v_acc: 0.89648 |  iteration: 4256 teacher: 0 stage: sketch lr: 0.000677\n",
      "batch 527 loss: 0.31485 acc: 0.90495 | v_loss: 0.50523 v_acc: 0.87826 |  iteration: 4257 teacher: 1 stage: sketch lr: 0.000677\n",
      "batch 528 loss: 0.27190 acc: 0.91699 | v_loss: 0.78480 v_acc: 0.85807 |  iteration: 4258 teacher: 0 stage: sketch lr: 0.000677\n",
      "batch 529 loss: 0.37083 acc: 0.89746 | v_loss: 0.52681 v_acc: 0.87728 |  iteration: 4259 teacher: 0 stage: sketch lr: 0.000677\n",
      "batch 530 loss: 0.28372 acc: 0.91732 | v_loss: 0.64312 v_acc: 0.86491 |  iteration: 4260 teacher: 0 stage: sketch lr: 0.000677\n",
      "batch 531 loss: 0.29143 acc: 0.91471 | v_loss: 0.42108 v_acc: 0.89388 |  iteration: 4261 teacher: 0 stage: sketch lr: 0.000677\n",
      "batch 532 loss: 0.34659 acc: 0.90951 | v_loss: 0.55686 v_acc: 0.87858 |  iteration: 4262 teacher: 1 stage: sketch lr: 0.000677\n",
      "batch 533 loss: 0.24933 acc: 0.92448 | v_loss: 0.72253 v_acc: 0.85091 |  iteration: 4263 teacher: 0 stage: sketch lr: 0.000677\n",
      "batch 534 loss: 0.33375 acc: 0.90072 | v_loss: 0.49950 v_acc: 0.88021 |  iteration: 4264 teacher: 0 stage: sketch lr: 0.000677\n",
      "batch 535 loss: 0.40901 acc: 0.88867 | v_loss: 0.51040 v_acc: 0.88574 |  iteration: 4265 teacher: 1 stage: sketch lr: 0.000677\n",
      "batch 536 loss: 0.33321 acc: 0.90592 | v_loss: 0.52505 v_acc: 0.87370 |  iteration: 4266 teacher: 1 stage: sketch lr: 0.000677\n",
      "batch 537 loss: 0.26242 acc: 0.92611 | v_loss: 0.45411 v_acc: 0.89258 |  iteration: 4267 teacher: 1 stage: sketch lr: 0.000677\n",
      "batch 538 loss: 0.37370 acc: 0.90234 | v_loss: 0.49384 v_acc: 0.89616 |  iteration: 4268 teacher: 0 stage: sketch lr: 0.000676\n",
      "batch 539 loss: 0.33815 acc: 0.90462 | v_loss: 0.59987 v_acc: 0.86491 |  iteration: 4269 teacher: 0 stage: sketch lr: 0.000676\n",
      "batch 540 loss: 0.26962 acc: 0.91960 | v_loss: 0.40544 v_acc: 0.91829 |  iteration: 4270 teacher: 0 stage: sketch lr: 0.000676\n",
      "batch 541 loss: 0.30500 acc: 0.91243 | v_loss: 0.93542 v_acc: 0.82943 |  iteration: 4271 teacher: 1 stage: sketch lr: 0.000676\n",
      "batch 542 loss: 0.31435 acc: 0.91309 | v_loss: 0.66640 v_acc: 0.87077 |  iteration: 4272 teacher: 1 stage: sketch lr: 0.000676\n",
      "batch 543 loss: 0.31213 acc: 0.90951 | v_loss: 0.67281 v_acc: 0.86003 |  iteration: 4273 teacher: 1 stage: sketch lr: 0.000676\n",
      "batch 544 loss: 0.26782 acc: 0.92285 | v_loss: 0.55044 v_acc: 0.89323 |  iteration: 4274 teacher: 0 stage: sketch lr: 0.000676\n",
      "batch 545 loss: 0.25409 acc: 0.92318 | v_loss: 0.52212 v_acc: 0.88607 |  iteration: 4275 teacher: 1 stage: sketch lr: 0.000676\n",
      "batch 546 loss: 0.37625 acc: 0.88574 | v_loss: 0.58945 v_acc: 0.88118 |  iteration: 4276 teacher: 1 stage: sketch lr: 0.000676\n",
      "batch 547 loss: 0.33493 acc: 0.90690 | v_loss: 0.49092 v_acc: 0.89193 |  iteration: 4277 teacher: 1 stage: sketch lr: 0.000676\n",
      "batch 548 loss: 0.24931 acc: 0.93359 | v_loss: 0.54754 v_acc: 0.87760 |  iteration: 4278 teacher: 1 stage: sketch lr: 0.000676\n",
      "batch 549 loss: 0.23783 acc: 0.92806 | v_loss: 0.49470 v_acc: 0.89941 |  iteration: 4279 teacher: 1 stage: sketch lr: 0.000676\n",
      "batch 550 loss: 0.38852 acc: 0.89095 | v_loss: 0.47286 v_acc: 0.89876 |  iteration: 4280 teacher: 0 stage: sketch lr: 0.000676\n",
      "batch 551 loss: 0.31549 acc: 0.90332 | v_loss: 0.35717 v_acc: 0.91992 |  iteration: 4281 teacher: 0 stage: sketch lr: 0.000675\n",
      "batch 552 loss: 0.37238 acc: 0.90462 | v_loss: 0.63506 v_acc: 0.86882 |  iteration: 4282 teacher: 1 stage: sketch lr: 0.000675\n",
      "batch 553 loss: 0.28339 acc: 0.92090 | v_loss: 0.57899 v_acc: 0.86361 |  iteration: 4283 teacher: 1 stage: sketch lr: 0.000675\n",
      "batch 554 loss: 0.37622 acc: 0.89648 | v_loss: 0.62961 v_acc: 0.87044 |  iteration: 4284 teacher: 0 stage: sketch lr: 0.000675\n",
      "batch 555 loss: 0.29241 acc: 0.92188 | v_loss: 0.85166 v_acc: 0.84440 |  iteration: 4285 teacher: 1 stage: sketch lr: 0.000675\n",
      "batch 556 loss: 0.31356 acc: 0.91471 | v_loss: 0.45451 v_acc: 0.90137 |  iteration: 4286 teacher: 1 stage: sketch lr: 0.000675\n",
      "batch 557 loss: 0.28777 acc: 0.91634 | v_loss: 0.57307 v_acc: 0.86719 |  iteration: 4287 teacher: 1 stage: sketch lr: 0.000675\n",
      "batch 558 loss: 0.39375 acc: 0.88704 | v_loss: 0.55069 v_acc: 0.88607 |  iteration: 4288 teacher: 1 stage: sketch lr: 0.000675\n",
      "batch 559 loss: 0.29737 acc: 0.91862 | v_loss: 0.40301 v_acc: 0.90723 |  iteration: 4289 teacher: 1 stage: sketch lr: 0.000675\n",
      "batch 560 loss: 0.24375 acc: 0.92513 | v_loss: 1.16852 v_acc: 0.80208 |  iteration: 4290 teacher: 1 stage: sketch lr: 0.000675\n",
      "batch 561 loss: 0.31168 acc: 0.91569 | v_loss: 0.40825 v_acc: 0.90853 |  iteration: 4291 teacher: 1 stage: sketch lr: 0.000675\n",
      "batch 562 loss: 0.27280 acc: 0.91862 | v_loss: 0.61354 v_acc: 0.88086 |  iteration: 4292 teacher: 0 stage: sketch lr: 0.000675\n",
      "batch 563 loss: 0.41159 acc: 0.88574 | v_loss: 0.52077 v_acc: 0.89616 |  iteration: 4293 teacher: 1 stage: sketch lr: 0.000675\n",
      "batch 564 loss: 0.29694 acc: 0.91243 | v_loss: 0.43981 v_acc: 0.90625 |  iteration: 4294 teacher: 1 stage: sketch lr: 0.000674\n",
      "batch 565 loss: 0.32403 acc: 0.90951 | v_loss: 0.51124 v_acc: 0.89551 |  iteration: 4295 teacher: 0 stage: sketch lr: 0.000674\n",
      "batch 566 loss: 0.20064 acc: 0.93685 | v_loss: 0.62160 v_acc: 0.87695 |  iteration: 4296 teacher: 0 stage: sketch lr: 0.000674\n",
      "batch 567 loss: 0.30948 acc: 0.91016 | v_loss: 0.43430 v_acc: 0.90495 |  iteration: 4297 teacher: 1 stage: sketch lr: 0.000674\n",
      "batch 568 loss: 0.32687 acc: 0.90755 | v_loss: 0.61288 v_acc: 0.86816 |  iteration: 4298 teacher: 1 stage: sketch lr: 0.000674\n",
      "batch 569 loss: 0.29375 acc: 0.91569 | v_loss: 0.38605 v_acc: 0.90690 |  iteration: 4299 teacher: 1 stage: sketch lr: 0.000674\n",
      "batch 570 loss: 0.29412 acc: 0.91211 | v_loss: 1.03847 v_acc: 0.81087 |  iteration: 4300 teacher: 0 stage: sketch lr: 0.000674\n",
      "batch 571 loss: 0.29551 acc: 0.91797 | v_loss: 0.59794 v_acc: 0.88802 |  iteration: 4301 teacher: 0 stage: sketch lr: 0.000674\n",
      "batch 572 loss: 0.26680 acc: 0.91634 | v_loss: 0.68073 v_acc: 0.86654 |  iteration: 4302 teacher: 1 stage: sketch lr: 0.000674\n",
      "batch 573 loss: 0.36794 acc: 0.90462 | v_loss: 0.39454 v_acc: 0.90397 |  iteration: 4303 teacher: 1 stage: sketch lr: 0.000674\n",
      "batch 574 loss: 0.23260 acc: 0.93913 | v_loss: 0.65408 v_acc: 0.85254 |  iteration: 4304 teacher: 1 stage: sketch lr: 0.000674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 575 loss: 0.31324 acc: 0.90755 | v_loss: 0.45692 v_acc: 0.89290 |  iteration: 4305 teacher: 0 stage: sketch lr: 0.000674\n",
      "batch 576 loss: 0.44133 acc: 0.87988 | v_loss: 0.44223 v_acc: 0.88672 |  iteration: 4306 teacher: 1 stage: sketch lr: 0.000673\n",
      "batch 577 loss: 0.21292 acc: 0.93327 | v_loss: 0.43093 v_acc: 0.89290 |  iteration: 4307 teacher: 0 stage: sketch lr: 0.000673\n",
      "batch 578 loss: 0.26582 acc: 0.91634 | v_loss: 0.74394 v_acc: 0.84049 |  iteration: 4308 teacher: 0 stage: sketch lr: 0.000673\n",
      "batch 579 loss: 0.31522 acc: 0.90495 | v_loss: 0.50521 v_acc: 0.88965 |  iteration: 4309 teacher: 1 stage: sketch lr: 0.000673\n",
      "batch 580 loss: 0.28628 acc: 0.91960 | v_loss: 0.53614 v_acc: 0.88021 |  iteration: 4310 teacher: 1 stage: sketch lr: 0.000673\n",
      "batch 581 loss: 0.32595 acc: 0.91309 | v_loss: 0.68185 v_acc: 0.85612 |  iteration: 4311 teacher: 0 stage: sketch lr: 0.000673\n",
      "batch 582 loss: 0.21729 acc: 0.93783 | v_loss: 0.46220 v_acc: 0.89876 |  iteration: 4312 teacher: 1 stage: sketch lr: 0.000673\n",
      "batch 583 loss: 0.22899 acc: 0.93783 | v_loss: 0.55070 v_acc: 0.86458 |  iteration: 4313 teacher: 1 stage: sketch lr: 0.000673\n",
      "batch 584 loss: 0.32342 acc: 0.90690 | v_loss: 0.56091 v_acc: 0.87240 |  iteration: 4314 teacher: 0 stage: sketch lr: 0.000673\n",
      "batch 585 loss: 0.29705 acc: 0.92448 | v_loss: 0.72324 v_acc: 0.85840 |  iteration: 4315 teacher: 1 stage: sketch lr: 0.000673\n",
      "batch 586 loss: 0.25216 acc: 0.92188 | v_loss: 0.58903 v_acc: 0.87467 |  iteration: 4316 teacher: 1 stage: sketch lr: 0.000673\n",
      "batch 587 loss: 0.25615 acc: 0.92839 | v_loss: 0.61936 v_acc: 0.87077 |  iteration: 4317 teacher: 0 stage: sketch lr: 0.000673\n",
      "batch 588 loss: 0.30489 acc: 0.90755 | v_loss: 0.64226 v_acc: 0.86523 |  iteration: 4318 teacher: 1 stage: sketch lr: 0.000673\n",
      "batch 589 loss: 0.31214 acc: 0.90234 | v_loss: 0.62159 v_acc: 0.85514 |  iteration: 4319 teacher: 0 stage: sketch lr: 0.000672\n",
      "batch 590 loss: 0.22327 acc: 0.93652 | v_loss: 0.42895 v_acc: 0.90560 |  iteration: 4320 teacher: 1 stage: sketch lr: 0.000672\n",
      "batch 591 loss: 0.18825 acc: 0.94857 | v_loss: 0.77695 v_acc: 0.84603 |  iteration: 4321 teacher: 1 stage: sketch lr: 0.000672\n",
      "batch 592 loss: 0.23489 acc: 0.93229 | v_loss: 0.61370 v_acc: 0.87858 |  iteration: 4322 teacher: 1 stage: sketch lr: 0.000672\n",
      "batch 593 loss: 0.34437 acc: 0.89974 | v_loss: 0.57414 v_acc: 0.86979 |  iteration: 4323 teacher: 0 stage: sketch lr: 0.000672\n",
      "batch 594 loss: 0.32073 acc: 0.91081 | v_loss: 0.56552 v_acc: 0.87793 |  iteration: 4324 teacher: 1 stage: sketch lr: 0.000672\n",
      "batch 595 loss: 0.31372 acc: 0.90885 | v_loss: 0.46376 v_acc: 0.89453 |  iteration: 4325 teacher: 0 stage: sketch lr: 0.000672\n",
      "batch 596 loss: 0.37374 acc: 0.90430 | v_loss: 0.46544 v_acc: 0.89193 |  iteration: 4326 teacher: 1 stage: sketch lr: 0.000672\n",
      "batch 597 loss: 0.29117 acc: 0.92057 | v_loss: 0.56074 v_acc: 0.88574 |  iteration: 4327 teacher: 1 stage: sketch lr: 0.000672\n",
      "batch 598 loss: 0.28891 acc: 0.91471 | v_loss: 0.60584 v_acc: 0.85547 |  iteration: 4328 teacher: 1 stage: sketch lr: 0.000672\n",
      "batch 599 loss: 0.26474 acc: 0.92415 | v_loss: 0.61364 v_acc: 0.87793 |  iteration: 4329 teacher: 1 stage: sketch lr: 0.000672\n",
      "batch 600 loss: 0.37372 acc: 0.89714 | v_loss: 0.59250 v_acc: 0.87956 |  iteration: 4330 teacher: 0 stage: sketch lr: 0.000672\n",
      "batch 601 loss: 0.27009 acc: 0.92285 | v_loss: 0.40576 v_acc: 0.90723 |  iteration: 4331 teacher: 1 stage: sketch lr: 0.000672\n",
      "batch 602 loss: 0.25751 acc: 0.92611 | v_loss: 0.58415 v_acc: 0.87891 |  iteration: 4332 teacher: 0 stage: sketch lr: 0.000671\n",
      "batch 603 loss: 0.29214 acc: 0.91732 | v_loss: 0.52746 v_acc: 0.87858 |  iteration: 4333 teacher: 1 stage: sketch lr: 0.000671\n",
      "batch 604 loss: 0.26955 acc: 0.92090 | v_loss: 0.86667 v_acc: 0.82422 |  iteration: 4334 teacher: 0 stage: sketch lr: 0.000671\n",
      "batch 605 loss: 0.35946 acc: 0.89681 | v_loss: 0.36636 v_acc: 0.90495 |  iteration: 4335 teacher: 0 stage: sketch lr: 0.000671\n",
      "batch 606 loss: 0.34364 acc: 0.90527 | v_loss: 0.29825 v_acc: 0.92773 |  iteration: 4336 teacher: 0 stage: sketch lr: 0.000671\n",
      "batch 607 loss: 0.43010 acc: 0.88151 | v_loss: 0.58869 v_acc: 0.87793 |  iteration: 4337 teacher: 1 stage: sketch lr: 0.000671\n",
      "batch 608 loss: 0.29642 acc: 0.91081 | v_loss: 0.57498 v_acc: 0.88281 |  iteration: 4338 teacher: 0 stage: sketch lr: 0.000671\n",
      "batch 609 loss: 0.34018 acc: 0.90072 | v_loss: 0.62815 v_acc: 0.86035 |  iteration: 4339 teacher: 0 stage: sketch lr: 0.000671\n",
      "batch 610 loss: 0.33468 acc: 0.90202 | v_loss: 0.40750 v_acc: 0.90430 |  iteration: 4340 teacher: 0 stage: sketch lr: 0.000671\n",
      "batch 611 loss: 0.25675 acc: 0.92448 | v_loss: 0.50712 v_acc: 0.87402 |  iteration: 4341 teacher: 1 stage: sketch lr: 0.000671\n",
      "batch 612 loss: 0.29135 acc: 0.91439 | v_loss: 0.58087 v_acc: 0.86556 |  iteration: 4342 teacher: 0 stage: sketch lr: 0.000671\n",
      "batch 613 loss: 0.20529 acc: 0.93620 | v_loss: 0.64093 v_acc: 0.85449 |  iteration: 4343 teacher: 0 stage: sketch lr: 0.000671\n",
      "batch 614 loss: 0.32837 acc: 0.90755 | v_loss: 0.53013 v_acc: 0.89323 |  iteration: 4344 teacher: 1 stage: sketch lr: 0.000671\n",
      "batch 615 loss: 0.37673 acc: 0.88379 | v_loss: 0.39939 v_acc: 0.90723 |  iteration: 4345 teacher: 0 stage: sketch lr: 0.000670\n",
      "batch 616 loss: 0.29215 acc: 0.91667 | v_loss: 0.33014 v_acc: 0.92480 |  iteration: 4346 teacher: 0 stage: sketch lr: 0.000670\n",
      "batch 617 loss: 0.34665 acc: 0.90853 | v_loss: 0.51151 v_acc: 0.89616 |  iteration: 4347 teacher: 0 stage: sketch lr: 0.000670\n",
      "batch 618 loss: 0.26793 acc: 0.92513 | v_loss: 0.49378 v_acc: 0.89355 |  iteration: 4348 teacher: 0 stage: sketch lr: 0.000670\n",
      "batch 619 loss: 0.35060 acc: 0.90039 | v_loss: 0.82101 v_acc: 0.85547 |  iteration: 4349 teacher: 1 stage: sketch lr: 0.000670\n",
      "batch 620 loss: 0.33571 acc: 0.90592 | v_loss: 0.55221 v_acc: 0.86751 |  iteration: 4350 teacher: 1 stage: sketch lr: 0.000670\n",
      "batch 621 loss: 0.28435 acc: 0.92025 | v_loss: 0.63957 v_acc: 0.86947 |  iteration: 4351 teacher: 1 stage: sketch lr: 0.000670\n",
      "batch 622 loss: 0.29971 acc: 0.90885 | v_loss: 0.42267 v_acc: 0.89616 |  iteration: 4352 teacher: 0 stage: sketch lr: 0.000670\n",
      "batch 623 loss: 0.24352 acc: 0.92448 | v_loss: 0.52489 v_acc: 0.88249 |  iteration: 4353 teacher: 1 stage: sketch lr: 0.000670\n",
      "batch 624 loss: 0.26690 acc: 0.92188 | v_loss: 0.77230 v_acc: 0.84863 |  iteration: 4354 teacher: 1 stage: sketch lr: 0.000670\n",
      "batch 625 loss: 0.28221 acc: 0.92318 | v_loss: 0.54398 v_acc: 0.88607 |  iteration: 4355 teacher: 1 stage: sketch lr: 0.000670\n",
      "batch 626 loss: 0.37223 acc: 0.89714 | v_loss: 0.54670 v_acc: 0.88574 |  iteration: 4356 teacher: 1 stage: sketch lr: 0.000670\n",
      "batch 627 loss: 0.31932 acc: 0.91048 | v_loss: 0.51112 v_acc: 0.88477 |  iteration: 4357 teacher: 0 stage: sketch lr: 0.000670\n",
      "batch 628 loss: 0.25419 acc: 0.92839 | v_loss: 0.43948 v_acc: 0.89974 |  iteration: 4358 teacher: 0 stage: sketch lr: 0.000669\n",
      "batch 629 loss: 0.28408 acc: 0.91895 | v_loss: 0.49506 v_acc: 0.89746 |  iteration: 4359 teacher: 0 stage: sketch lr: 0.000669\n",
      "batch 630 loss: 0.27133 acc: 0.92578 | v_loss: 0.60949 v_acc: 0.86426 |  iteration: 4360 teacher: 0 stage: sketch lr: 0.000669\n",
      "batch 631 loss: 0.30257 acc: 0.90332 | v_loss: 0.37814 v_acc: 0.91732 |  iteration: 4361 teacher: 0 stage: sketch lr: 0.000669\n",
      "batch 632 loss: 0.26481 acc: 0.92383 | v_loss: 0.98828 v_acc: 0.82812 |  iteration: 4362 teacher: 1 stage: sketch lr: 0.000669\n",
      "batch 633 loss: 0.22098 acc: 0.93880 | v_loss: 0.64844 v_acc: 0.87663 |  iteration: 4363 teacher: 1 stage: sketch lr: 0.000669\n",
      "batch 634 loss: 0.29869 acc: 0.91504 | v_loss: 0.69673 v_acc: 0.86947 |  iteration: 4364 teacher: 1 stage: sketch lr: 0.000669\n",
      "batch 635 loss: 0.23740 acc: 0.93717 | v_loss: 0.61390 v_acc: 0.88249 |  iteration: 4365 teacher: 1 stage: sketch lr: 0.000669\n",
      "batch 636 loss: 0.29001 acc: 0.92122 | v_loss: 0.53563 v_acc: 0.88704 |  iteration: 4366 teacher: 1 stage: sketch lr: 0.000669\n",
      "batch 637 loss: 0.36533 acc: 0.90299 | v_loss: 0.59337 v_acc: 0.87565 |  iteration: 4367 teacher: 0 stage: sketch lr: 0.000669\n",
      "batch 638 loss: 0.32781 acc: 0.90560 | v_loss: 0.52191 v_acc: 0.88053 |  iteration: 4368 teacher: 0 stage: sketch lr: 0.000669\n",
      "batch 639 loss: 0.24048 acc: 0.93490 | v_loss: 0.48675 v_acc: 0.88704 |  iteration: 4369 teacher: 1 stage: sketch lr: 0.000669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 640 loss: 0.36834 acc: 0.90007 | v_loss: 0.50078 v_acc: 0.88737 |  iteration: 4370 teacher: 1 stage: sketch lr: 0.000669\n",
      "batch 641 loss: 0.32474 acc: 0.90560 | v_loss: 0.43673 v_acc: 0.88835 |  iteration: 4371 teacher: 0 stage: sketch lr: 0.000668\n",
      "batch 642 loss: 0.32686 acc: 0.90299 | v_loss: 0.39053 v_acc: 0.90820 |  iteration: 4372 teacher: 0 stage: sketch lr: 0.000668\n",
      "batch 643 loss: 0.23114 acc: 0.93620 | v_loss: 0.60557 v_acc: 0.87142 |  iteration: 4373 teacher: 1 stage: sketch lr: 0.000668\n",
      "batch 644 loss: 0.29347 acc: 0.91016 | v_loss: 0.54784 v_acc: 0.87240 |  iteration: 4374 teacher: 0 stage: sketch lr: 0.000668\n",
      "batch 645 loss: 0.29503 acc: 0.91764 | v_loss: 0.60267 v_acc: 0.86458 |  iteration: 4375 teacher: 0 stage: sketch lr: 0.000668\n",
      "batch 646 loss: 0.24892 acc: 0.93197 | v_loss: 0.79166 v_acc: 0.84961 |  iteration: 4376 teacher: 0 stage: sketch lr: 0.000668\n",
      "batch 647 loss: 0.26766 acc: 0.92448 | v_loss: 0.42756 v_acc: 0.90658 |  iteration: 4377 teacher: 0 stage: sketch lr: 0.000668\n",
      "batch 648 loss: 0.26801 acc: 0.91992 | v_loss: 0.58928 v_acc: 0.86719 |  iteration: 4378 teacher: 0 stage: sketch lr: 0.000668\n",
      "batch 649 loss: 0.26810 acc: 0.92122 | v_loss: 0.56720 v_acc: 0.88867 |  iteration: 4379 teacher: 0 stage: sketch lr: 0.000668\n",
      "batch 650 loss: 0.29869 acc: 0.91406 | v_loss: 0.45638 v_acc: 0.90072 |  iteration: 4380 teacher: 1 stage: sketch lr: 0.000668\n",
      "batch 651 loss: 0.35110 acc: 0.91016 | v_loss: 1.07811 v_acc: 0.80697 |  iteration: 4381 teacher: 1 stage: sketch lr: 0.000668\n",
      "batch 652 loss: 0.20325 acc: 0.93945 | v_loss: 0.38936 v_acc: 0.91504 |  iteration: 4382 teacher: 1 stage: sketch lr: 0.000668\n",
      "batch 653 loss: 0.26659 acc: 0.91895 | v_loss: 0.60637 v_acc: 0.88118 |  iteration: 4383 teacher: 0 stage: sketch lr: 0.000668\n",
      "batch 654 loss: 0.28503 acc: 0.91276 | v_loss: 0.49574 v_acc: 0.89648 |  iteration: 4384 teacher: 1 stage: sketch lr: 0.000667\n",
      "batch 655 loss: 0.27304 acc: 0.92448 | v_loss: 0.38545 v_acc: 0.91797 |  iteration: 4385 teacher: 0 stage: sketch lr: 0.000667\n",
      "batch 656 loss: 0.31886 acc: 0.91178 | v_loss: 0.52225 v_acc: 0.89681 |  iteration: 4386 teacher: 0 stage: sketch lr: 0.000667\n",
      "batch 657 loss: 0.28755 acc: 0.91829 | v_loss: 0.60331 v_acc: 0.87760 |  iteration: 4387 teacher: 0 stage: sketch lr: 0.000667\n",
      "batch 658 loss: 0.29517 acc: 0.91309 | v_loss: 0.43084 v_acc: 0.90755 |  iteration: 4388 teacher: 0 stage: sketch lr: 0.000667\n",
      "batch 659 loss: 0.21931 acc: 0.93132 | v_loss: 0.61651 v_acc: 0.86556 |  iteration: 4389 teacher: 0 stage: sketch lr: 0.000667\n",
      "batch 660 loss: 0.24612 acc: 0.92773 | v_loss: 0.40180 v_acc: 0.89453 |  iteration: 4390 teacher: 1 stage: sketch lr: 0.000667\n",
      "batch 661 loss: 0.23405 acc: 0.92448 | v_loss: 0.94758 v_acc: 0.81673 |  iteration: 4391 teacher: 0 stage: sketch lr: 0.000667\n",
      "batch 662 loss: 0.34220 acc: 0.90397 | v_loss: 0.55990 v_acc: 0.88704 |  iteration: 4392 teacher: 1 stage: sketch lr: 0.000667\n",
      "batch 663 loss: 0.29004 acc: 0.91895 | v_loss: 0.77392 v_acc: 0.86068 |  iteration: 4393 teacher: 1 stage: sketch lr: 0.000667\n",
      "batch 664 loss: 0.27669 acc: 0.92350 | v_loss: 0.43786 v_acc: 0.90430 |  iteration: 4394 teacher: 0 stage: sketch lr: 0.000667\n",
      "batch 665 loss: 0.21955 acc: 0.93717 | v_loss: 0.65262 v_acc: 0.86784 |  iteration: 4395 teacher: 1 stage: sketch lr: 0.000667\n",
      "batch 666 loss: 0.23541 acc: 0.93262 | v_loss: 0.44892 v_acc: 0.89746 |  iteration: 4396 teacher: 1 stage: sketch lr: 0.000667\n",
      "batch 667 loss: 0.25589 acc: 0.93392 | v_loss: 0.47400 v_acc: 0.88835 |  iteration: 4397 teacher: 1 stage: sketch lr: 0.000666\n",
      "batch 668 loss: 0.26807 acc: 0.91829 | v_loss: 0.47525 v_acc: 0.88867 |  iteration: 4398 teacher: 1 stage: sketch lr: 0.000666\n",
      "batch 669 loss: 0.29088 acc: 0.91569 | v_loss: 0.78551 v_acc: 0.84603 |  iteration: 4399 teacher: 0 stage: sketch lr: 0.000666\n",
      "batch 670 loss: 0.19282 acc: 0.94368 | v_loss: 0.51432 v_acc: 0.89714 |  iteration: 4400 teacher: 0 stage: sketch lr: 0.000666\n",
      "batch 671 loss: 0.29034 acc: 0.91602 | v_loss: 0.49361 v_acc: 0.88444 |  iteration: 4401 teacher: 0 stage: sketch lr: 0.000666\n",
      "batch 672 loss: 0.33380 acc: 0.90560 | v_loss: 0.66165 v_acc: 0.85319 |  iteration: 4402 teacher: 1 stage: sketch lr: 0.000666\n",
      "batch 673 loss: 0.24051 acc: 0.92773 | v_loss: 0.45020 v_acc: 0.89355 |  iteration: 4403 teacher: 1 stage: sketch lr: 0.000666\n",
      "batch 674 loss: 0.23696 acc: 0.92708 | v_loss: 0.49834 v_acc: 0.88151 |  iteration: 4404 teacher: 0 stage: sketch lr: 0.000666\n",
      "batch 675 loss: 0.28597 acc: 0.91764 | v_loss: 0.55306 v_acc: 0.87500 |  iteration: 4405 teacher: 0 stage: sketch lr: 0.000666\n",
      "batch 676 loss: 0.23247 acc: 0.92741 | v_loss: 0.76431 v_acc: 0.85091 |  iteration: 4406 teacher: 1 stage: sketch lr: 0.000666\n",
      "batch 677 loss: 0.28801 acc: 0.92188 | v_loss: 0.57703 v_acc: 0.88737 |  iteration: 4407 teacher: 1 stage: sketch lr: 0.000666\n",
      "batch 678 loss: 0.29699 acc: 0.91536 | v_loss: 0.57609 v_acc: 0.88574 |  iteration: 4408 teacher: 0 stage: sketch lr: 0.000666\n",
      "batch 679 loss: 0.31849 acc: 0.91829 | v_loss: 0.65277 v_acc: 0.87500 |  iteration: 4409 teacher: 1 stage: sketch lr: 0.000666\n",
      "batch 680 loss: 0.28716 acc: 0.91504 | v_loss: 0.57291 v_acc: 0.86003 |  iteration: 4410 teacher: 0 stage: sketch lr: 0.000665\n",
      "batch 681 loss: 0.35419 acc: 0.89876 | v_loss: 0.42610 v_acc: 0.89909 |  iteration: 4411 teacher: 0 stage: sketch lr: 0.000665\n",
      "batch 682 loss: 0.28212 acc: 0.90885 | v_loss: 0.73248 v_acc: 0.84538 |  iteration: 4412 teacher: 1 stage: sketch lr: 0.000665\n",
      "batch 683 loss: 0.28652 acc: 0.91113 | v_loss: 0.57614 v_acc: 0.87500 |  iteration: 4413 teacher: 0 stage: sketch lr: 0.000665\n",
      "batch 684 loss: 0.21846 acc: 0.93197 | v_loss: 0.57586 v_acc: 0.86393 |  iteration: 4414 teacher: 1 stage: sketch lr: 0.000665\n",
      "batch 685 loss: 0.34347 acc: 0.90592 | v_loss: 0.55342 v_acc: 0.87272 |  iteration: 4415 teacher: 1 stage: sketch lr: 0.000665\n",
      "batch 686 loss: 0.27393 acc: 0.92383 | v_loss: 0.48917 v_acc: 0.89355 |  iteration: 4416 teacher: 0 stage: sketch lr: 0.000665\n",
      "batch 687 loss: 0.32808 acc: 0.90755 | v_loss: 0.45657 v_acc: 0.89779 |  iteration: 4417 teacher: 1 stage: sketch lr: 0.000665\n",
      "batch 688 loss: 0.33005 acc: 0.90755 | v_loss: 0.54391 v_acc: 0.88574 |  iteration: 4418 teacher: 1 stage: sketch lr: 0.000665\n",
      "batch 689 loss: 0.31526 acc: 0.90951 | v_loss: 0.64317 v_acc: 0.85384 |  iteration: 4419 teacher: 1 stage: sketch lr: 0.000665\n",
      "batch 690 loss: 0.18649 acc: 0.94206 | v_loss: 0.57045 v_acc: 0.88672 |  iteration: 4420 teacher: 1 stage: sketch lr: 0.000665\n",
      "batch 691 loss: 0.27149 acc: 0.92415 | v_loss: 0.61046 v_acc: 0.88184 |  iteration: 4421 teacher: 0 stage: sketch lr: 0.000665\n",
      "batch 692 loss: 0.18656 acc: 0.94727 | v_loss: 0.39351 v_acc: 0.90592 |  iteration: 4422 teacher: 0 stage: sketch lr: 0.000665\n",
      "batch 693 loss: 0.25987 acc: 0.92253 | v_loss: 0.54006 v_acc: 0.87923 |  iteration: 4423 teacher: 0 stage: sketch lr: 0.000665\n",
      "batch 694 loss: 0.32866 acc: 0.90365 | v_loss: 0.47683 v_acc: 0.88184 |  iteration: 4424 teacher: 0 stage: sketch lr: 0.000664\n",
      "batch 695 loss: 0.23747 acc: 0.92676 | v_loss: 0.80694 v_acc: 0.82812 |  iteration: 4425 teacher: 0 stage: sketch lr: 0.000664\n",
      "batch 696 loss: 0.30160 acc: 0.90983 | v_loss: 0.36083 v_acc: 0.90397 |  iteration: 4426 teacher: 0 stage: sketch lr: 0.000664\n",
      "batch 697 loss: 0.25732 acc: 0.92383 | v_loss: 0.31030 v_acc: 0.93229 |  iteration: 4427 teacher: 0 stage: sketch lr: 0.000664\n",
      "batch 698 loss: 0.27271 acc: 0.92643 | v_loss: 0.58082 v_acc: 0.88444 |  iteration: 4428 teacher: 0 stage: sketch lr: 0.000664\n",
      "batch 699 loss: 0.26352 acc: 0.92220 | v_loss: 0.58472 v_acc: 0.87988 |  iteration: 4429 teacher: 1 stage: sketch lr: 0.000664\n",
      "batch 700 loss: 0.26348 acc: 0.92122 | v_loss: 0.66893 v_acc: 0.86068 |  iteration: 4430 teacher: 0 stage: sketch lr: 0.000664\n",
      "batch 701 loss: 0.23780 acc: 0.93424 | v_loss: 0.43182 v_acc: 0.90267 |  iteration: 4431 teacher: 0 stage: sketch lr: 0.000664\n",
      "batch 702 loss: 0.23357 acc: 0.93001 | v_loss: 0.53481 v_acc: 0.86523 |  iteration: 4432 teacher: 0 stage: sketch lr: 0.000664\n",
      "batch 703 loss: 0.46697 acc: 0.87663 | v_loss: 0.56069 v_acc: 0.87533 |  iteration: 4433 teacher: 1 stage: sketch lr: 0.000664\n",
      "batch 704 loss: 0.30036 acc: 0.91602 | v_loss: 0.61462 v_acc: 0.85254 |  iteration: 4434 teacher: 1 stage: sketch lr: 0.000664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 705 loss: 0.23700 acc: 0.93424 | v_loss: 0.52397 v_acc: 0.88900 |  iteration: 4435 teacher: 0 stage: sketch lr: 0.000664\n",
      "batch 706 loss: 0.18132 acc: 0.94434 | v_loss: 0.38426 v_acc: 0.90495 |  iteration: 4436 teacher: 1 stage: sketch lr: 0.000664\n",
      "batch 707 loss: 0.31950 acc: 0.91569 | v_loss: 0.31354 v_acc: 0.92741 |  iteration: 4437 teacher: 0 stage: sketch lr: 0.000663\n",
      "batch 708 loss: 0.35815 acc: 0.90625 | v_loss: 0.46009 v_acc: 0.90234 |  iteration: 4438 teacher: 0 stage: sketch lr: 0.000663\n",
      "batch 709 loss: 0.39735 acc: 0.89160 | v_loss: 0.48277 v_acc: 0.89258 |  iteration: 4439 teacher: 1 stage: sketch lr: 0.000663\n",
      "batch 710 loss: 0.36739 acc: 0.90495 | v_loss: 0.82033 v_acc: 0.85579 |  iteration: 4440 teacher: 1 stage: sketch lr: 0.000663\n",
      "batch 711 loss: 0.29226 acc: 0.91146 | v_loss: 0.55767 v_acc: 0.87923 |  iteration: 4441 teacher: 0 stage: sketch lr: 0.000663\n",
      "batch 712 loss: 0.28588 acc: 0.91764 | v_loss: 0.65955 v_acc: 0.86100 |  iteration: 4442 teacher: 0 stage: sketch lr: 0.000663\n",
      "batch 713 loss: 0.32980 acc: 0.90462 | v_loss: 0.41806 v_acc: 0.89486 |  iteration: 4443 teacher: 1 stage: sketch lr: 0.000663\n",
      "batch 714 loss: 0.28978 acc: 0.91895 | v_loss: 0.55725 v_acc: 0.88053 |  iteration: 4444 teacher: 0 stage: sketch lr: 0.000663\n",
      "batch 715 loss: 0.27575 acc: 0.92122 | v_loss: 0.77245 v_acc: 0.83268 |  iteration: 4445 teacher: 0 stage: sketch lr: 0.000663\n",
      "batch 716 loss: 0.26652 acc: 0.91927 | v_loss: 0.52415 v_acc: 0.88379 |  iteration: 4446 teacher: 1 stage: sketch lr: 0.000663\n",
      "batch 717 loss: 0.29066 acc: 0.91276 | v_loss: 0.51362 v_acc: 0.88932 |  iteration: 4447 teacher: 0 stage: sketch lr: 0.000663\n",
      "batch 718 loss: 0.34535 acc: 0.90755 | v_loss: 0.48945 v_acc: 0.88314 |  iteration: 4448 teacher: 1 stage: sketch lr: 0.000663\n",
      "batch 719 loss: 0.35724 acc: 0.89844 | v_loss: 0.41207 v_acc: 0.90202 |  iteration: 4449 teacher: 0 stage: sketch lr: 0.000663\n",
      "batch 720 loss: 0.27289 acc: 0.92220 | v_loss: 0.47806 v_acc: 0.89681 |  iteration: 4450 teacher: 1 stage: sketch lr: 0.000662\n",
      "batch 721 loss: 0.18716 acc: 0.94499 | v_loss: 0.62636 v_acc: 0.85807 |  iteration: 4451 teacher: 0 stage: sketch lr: 0.000662\n",
      "batch 722 loss: 0.24798 acc: 0.92448 | v_loss: 0.34770 v_acc: 0.92513 |  iteration: 4452 teacher: 0 stage: sketch lr: 0.000662\n",
      "batch 723 loss: 0.22070 acc: 0.93001 | v_loss: 0.95396 v_acc: 0.82357 |  iteration: 4453 teacher: 0 stage: sketch lr: 0.000662\n",
      "batch 724 loss: 0.31879 acc: 0.91048 | v_loss: 0.62138 v_acc: 0.87044 |  iteration: 4454 teacher: 1 stage: sketch lr: 0.000662\n",
      "batch 725 loss: 0.25842 acc: 0.92676 | v_loss: 0.66662 v_acc: 0.87077 |  iteration: 4455 teacher: 0 stage: sketch lr: 0.000662\n",
      "batch 726 loss: 0.32742 acc: 0.90625 | v_loss: 0.49544 v_acc: 0.90039 |  iteration: 4456 teacher: 0 stage: sketch lr: 0.000662\n",
      "batch 727 loss: 0.32010 acc: 0.90983 | v_loss: 0.44874 v_acc: 0.89941 |  iteration: 4457 teacher: 1 stage: sketch lr: 0.000662\n",
      "batch 728 loss: 0.26066 acc: 0.92318 | v_loss: 0.58155 v_acc: 0.88542 |  iteration: 4458 teacher: 0 stage: sketch lr: 0.000662\n",
      "batch 729 loss: 0.27899 acc: 0.91406 | v_loss: 0.49378 v_acc: 0.89648 |  iteration: 4459 teacher: 0 stage: sketch lr: 0.000662\n",
      "batch 730 loss: 0.27917 acc: 0.91536 | v_loss: 0.50137 v_acc: 0.88639 |  iteration: 4460 teacher: 1 stage: sketch lr: 0.000662\n",
      "batch 731 loss: 0.18501 acc: 0.94661 | v_loss: 0.48412 v_acc: 0.90039 |  iteration: 4461 teacher: 0 stage: sketch lr: 0.000662\n",
      "batch 732 loss: 0.25647 acc: 0.92773 | v_loss: 0.47500 v_acc: 0.89486 |  iteration: 4462 teacher: 1 stage: sketch lr: 0.000662\n",
      "batch 733 loss: 0.33055 acc: 0.90853 | v_loss: 0.33883 v_acc: 0.92350 |  iteration: 4463 teacher: 0 stage: sketch lr: 0.000662\n",
      "batch 734 loss: 0.34266 acc: 0.90462 | v_loss: 0.64196 v_acc: 0.86523 |  iteration: 4464 teacher: 1 stage: sketch lr: 0.000661\n",
      "batch 735 loss: 0.26588 acc: 0.92090 | v_loss: 0.56322 v_acc: 0.86426 |  iteration: 4465 teacher: 1 stage: sketch lr: 0.000661\n",
      "batch 736 loss: 0.25530 acc: 0.91960 | v_loss: 0.64327 v_acc: 0.85710 |  iteration: 4466 teacher: 1 stage: sketch lr: 0.000661\n",
      "batch 737 loss: 0.29685 acc: 0.91569 | v_loss: 0.85945 v_acc: 0.83984 |  iteration: 4467 teacher: 0 stage: sketch lr: 0.000661\n",
      "batch 738 loss: 0.23775 acc: 0.93294 | v_loss: 0.47434 v_acc: 0.89583 |  iteration: 4468 teacher: 1 stage: sketch lr: 0.000661\n",
      "batch 739 loss: 0.33018 acc: 0.90397 | v_loss: 0.56772 v_acc: 0.87630 |  iteration: 4469 teacher: 1 stage: sketch lr: 0.000661\n",
      "batch 740 loss: 0.28553 acc: 0.91602 | v_loss: 0.52154 v_acc: 0.89128 |  iteration: 4470 teacher: 1 stage: sketch lr: 0.000661\n",
      "batch 741 loss: 0.27558 acc: 0.91764 | v_loss: 0.43663 v_acc: 0.90495 |  iteration: 4471 teacher: 1 stage: sketch lr: 0.000661\n",
      "batch 742 loss: 0.34394 acc: 0.89844 | v_loss: 1.16348 v_acc: 0.80827 |  iteration: 4472 teacher: 0 stage: sketch lr: 0.000661\n",
      "batch 743 loss: 0.29400 acc: 0.91927 | v_loss: 0.41063 v_acc: 0.90951 |  iteration: 4473 teacher: 0 stage: sketch lr: 0.000661\n",
      "batch 744 loss: 0.33717 acc: 0.90788 | v_loss: 0.57881 v_acc: 0.87858 |  iteration: 4474 teacher: 0 stage: sketch lr: 0.000661\n",
      "batch 745 loss: 0.25576 acc: 0.92480 | v_loss: 0.48158 v_acc: 0.89030 |  iteration: 4475 teacher: 0 stage: sketch lr: 0.000661\n",
      "batch 746 loss: 0.25865 acc: 0.92155 | v_loss: 0.40849 v_acc: 0.90658 |  iteration: 4476 teacher: 0 stage: sketch lr: 0.000661\n",
      "batch 747 loss: 0.39358 acc: 0.89648 | v_loss: 0.52609 v_acc: 0.89095 |  iteration: 4477 teacher: 1 stage: sketch lr: 0.000660\n",
      "batch 748 loss: 0.28611 acc: 0.92318 | v_loss: 0.55539 v_acc: 0.87793 |  iteration: 4478 teacher: 0 stage: sketch lr: 0.000660\n",
      "batch 749 loss: 0.34405 acc: 0.90658 | v_loss: 0.46473 v_acc: 0.90788 |  iteration: 4479 teacher: 1 stage: sketch lr: 0.000660\n",
      "batch 750 loss: 0.35076 acc: 0.89941 | v_loss: 0.59950 v_acc: 0.87402 |  iteration: 4480 teacher: 1 stage: sketch lr: 0.000660\n",
      "batch 751 loss: 0.25924 acc: 0.92090 | v_loss: 0.45877 v_acc: 0.88704 |  iteration: 4481 teacher: 1 stage: sketch lr: 0.000660\n",
      "batch 752 loss: 0.32198 acc: 0.90560 | v_loss: 0.93008 v_acc: 0.82747 |  iteration: 4482 teacher: 0 stage: sketch lr: 0.000660\n",
      "batch 753 loss: 0.33414 acc: 0.90137 | v_loss: 0.59117 v_acc: 0.88249 |  iteration: 4483 teacher: 0 stage: sketch lr: 0.000660\n",
      "batch 754 loss: 0.30334 acc: 0.90332 | v_loss: 0.69167 v_acc: 0.86491 |  iteration: 4484 teacher: 0 stage: sketch lr: 0.000660\n",
      "batch 755 loss: 0.22429 acc: 0.93652 | v_loss: 0.45810 v_acc: 0.89551 |  iteration: 4485 teacher: 0 stage: sketch lr: 0.000660\n",
      "batch 756 loss: 0.28477 acc: 0.92513 | v_loss: 0.69016 v_acc: 0.86426 |  iteration: 4486 teacher: 0 stage: sketch lr: 0.000660\n",
      "batch 757 loss: 0.20602 acc: 0.94206 | v_loss: 0.44866 v_acc: 0.89844 |  iteration: 4487 teacher: 1 stage: sketch lr: 0.000660\n",
      "batch 758 loss: 0.18405 acc: 0.94336 | v_loss: 0.49052 v_acc: 0.89746 |  iteration: 4488 teacher: 1 stage: sketch lr: 0.000660\n",
      "batch 759 loss: 0.35547 acc: 0.90104 | v_loss: 0.45611 v_acc: 0.89779 |  iteration: 4489 teacher: 1 stage: sketch lr: 0.000660\n",
      "batch 760 loss: 0.33008 acc: 0.91178 | v_loss: 0.76523 v_acc: 0.85026 |  iteration: 4490 teacher: 0 stage: sketch lr: 0.000660\n",
      "batch 761 loss: 0.24944 acc: 0.92578 | v_loss: 0.49480 v_acc: 0.90007 |  iteration: 4491 teacher: 0 stage: sketch lr: 0.000659\n",
      "batch 762 loss: 0.34407 acc: 0.89583 | v_loss: 0.50489 v_acc: 0.88607 |  iteration: 4492 teacher: 0 stage: sketch lr: 0.000659\n",
      "batch 763 loss: 0.36244 acc: 0.89844 | v_loss: 0.65824 v_acc: 0.85710 |  iteration: 4493 teacher: 0 stage: sketch lr: 0.000659\n",
      "batch 764 loss: 0.28729 acc: 0.91341 | v_loss: 0.44397 v_acc: 0.90104 |  iteration: 4494 teacher: 0 stage: sketch lr: 0.000659\n",
      "batch 765 loss: 0.24370 acc: 0.92480 | v_loss: 0.51895 v_acc: 0.87370 |  iteration: 4495 teacher: 1 stage: sketch lr: 0.000659\n",
      "batch 766 loss: 0.24817 acc: 0.92578 | v_loss: 0.51902 v_acc: 0.87858 |  iteration: 4496 teacher: 0 stage: sketch lr: 0.000659\n",
      "batch 767 loss: 0.30895 acc: 0.91178 | v_loss: 0.70374 v_acc: 0.86100 |  iteration: 4497 teacher: 0 stage: sketch lr: 0.000659\n",
      "batch 768 loss: 0.28250 acc: 0.91960 | v_loss: 0.53803 v_acc: 0.89486 |  iteration: 4498 teacher: 0 stage: sketch lr: 0.000659\n",
      "batch 769 loss: 0.36422 acc: 0.89811 | v_loss: 0.53388 v_acc: 0.88802 |  iteration: 4499 teacher: 1 stage: sketch lr: 0.000659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 770 loss: 0.34061 acc: 0.90202 | v_loss: 0.64404 v_acc: 0.87923 |  iteration: 4500 teacher: 0 stage: sketch lr: 0.000659\n",
      "batch 771 loss: 0.30034 acc: 0.91113 | v_loss: 0.56134 v_acc: 0.86426 |  iteration: 4501 teacher: 1 stage: sketch lr: 0.000659\n",
      "batch 772 loss: 0.19656 acc: 0.93848 | v_loss: 0.44929 v_acc: 0.90495 |  iteration: 4502 teacher: 0 stage: sketch lr: 0.000659\n",
      "batch 773 loss: 0.36396 acc: 0.90072 | v_loss: 0.78133 v_acc: 0.84440 |  iteration: 4503 teacher: 1 stage: sketch lr: 0.000659\n",
      "batch 774 loss: 0.26560 acc: 0.92513 | v_loss: 0.57040 v_acc: 0.88737 |  iteration: 4504 teacher: 1 stage: sketch lr: 0.000659\n",
      "batch 775 loss: 0.26623 acc: 0.92025 | v_loss: 0.56323 v_acc: 0.87402 |  iteration: 4505 teacher: 0 stage: sketch lr: 0.000658\n",
      "batch 776 loss: 0.30652 acc: 0.91536 | v_loss: 0.52872 v_acc: 0.88672 |  iteration: 4506 teacher: 0 stage: sketch lr: 0.000658\n",
      "batch 777 loss: 0.29076 acc: 0.91862 | v_loss: 0.49309 v_acc: 0.88802 |  iteration: 4507 teacher: 0 stage: sketch lr: 0.000658\n",
      "batch 778 loss: 0.25534 acc: 0.92773 | v_loss: 0.47824 v_acc: 0.89258 |  iteration: 4508 teacher: 1 stage: sketch lr: 0.000658\n",
      "batch 779 loss: 0.35508 acc: 0.89746 | v_loss: 0.52694 v_acc: 0.88932 |  iteration: 4509 teacher: 0 stage: sketch lr: 0.000658\n",
      "batch 780 loss: 0.38386 acc: 0.88835 | v_loss: 0.58843 v_acc: 0.85775 |  iteration: 4510 teacher: 0 stage: sketch lr: 0.000658\n",
      "batch 781 loss: 0.31097 acc: 0.90527 | v_loss: 0.58490 v_acc: 0.88118 |  iteration: 4511 teacher: 1 stage: sketch lr: 0.000658\n",
      "batch 782 loss: 0.25715 acc: 0.92318 | v_loss: 0.60840 v_acc: 0.88053 |  iteration: 4512 teacher: 0 stage: sketch lr: 0.000658\n",
      "batch 783 loss: 0.28146 acc: 0.92057 | v_loss: 0.38183 v_acc: 0.90951 |  iteration: 4513 teacher: 1 stage: sketch lr: 0.000658\n",
      "batch 784 loss: 0.26136 acc: 0.92578 | v_loss: 0.54012 v_acc: 0.88249 |  iteration: 4514 teacher: 0 stage: sketch lr: 0.000658\n",
      "batch 785 loss: 0.20762 acc: 0.94173 | v_loss: 0.46658 v_acc: 0.88477 |  iteration: 4515 teacher: 1 stage: sketch lr: 0.000658\n",
      "batch 786 loss: 0.30320 acc: 0.90690 | v_loss: 0.88242 v_acc: 0.83594 |  iteration: 4516 teacher: 0 stage: sketch lr: 0.000658\n",
      "batch 787 loss: 0.23034 acc: 0.93034 | v_loss: 0.33029 v_acc: 0.91569 |  iteration: 4517 teacher: 1 stage: sketch lr: 0.000658\n",
      "batch 788 loss: 0.27769 acc: 0.91862 | v_loss: 0.30549 v_acc: 0.92839 |  iteration: 4518 teacher: 0 stage: sketch lr: 0.000657\n",
      "batch 789 loss: 0.25407 acc: 0.92350 | v_loss: 0.54914 v_acc: 0.88151 |  iteration: 4519 teacher: 1 stage: sketch lr: 0.000657\n",
      "batch 790 loss: 0.20306 acc: 0.93620 | v_loss: 0.51067 v_acc: 0.88835 |  iteration: 4520 teacher: 1 stage: sketch lr: 0.000657\n",
      "batch 791 loss: 0.24849 acc: 0.92285 | v_loss: 0.63294 v_acc: 0.86784 |  iteration: 4521 teacher: 0 stage: sketch lr: 0.000657\n",
      "batch 792 loss: 0.22310 acc: 0.93555 | v_loss: 0.42405 v_acc: 0.90104 |  iteration: 4522 teacher: 1 stage: sketch lr: 0.000657\n",
      "batch 793 loss: 0.27761 acc: 0.92057 | v_loss: 0.49523 v_acc: 0.87533 |  iteration: 4523 teacher: 0 stage: sketch lr: 0.000657\n",
      "batch 794 loss: 0.28695 acc: 0.91764 | v_loss: 0.54973 v_acc: 0.88021 |  iteration: 4524 teacher: 0 stage: sketch lr: 0.000657\n",
      "batch 795 loss: 0.25700 acc: 0.92513 | v_loss: 0.65021 v_acc: 0.85221 |  iteration: 4525 teacher: 1 stage: sketch lr: 0.000657\n",
      "batch 796 loss: 0.22301 acc: 0.93750 | v_loss: 0.50071 v_acc: 0.89876 |  iteration: 4526 teacher: 0 stage: sketch lr: 0.000657\n",
      "batch 797 loss: 0.36922 acc: 0.88965 | v_loss: 0.38310 v_acc: 0.90820 |  iteration: 4527 teacher: 0 stage: sketch lr: 0.000657\n",
      "batch 798 loss: 0.21743 acc: 0.93978 | v_loss: 0.30882 v_acc: 0.92383 |  iteration: 4528 teacher: 1 stage: sketch lr: 0.000657\n",
      "batch 799 loss: 0.23636 acc: 0.93229 | v_loss: 0.46872 v_acc: 0.90365 |  iteration: 4529 teacher: 1 stage: sketch lr: 0.000657\n",
      "batch 800 loss: 0.20968 acc: 0.93652 | v_loss: 0.49861 v_acc: 0.89355 |  iteration: 4530 teacher: 1 stage: sketch lr: 0.000657\n",
      "batch 801 loss: 0.24101 acc: 0.92676 | v_loss: 0.87746 v_acc: 0.85417 |  iteration: 4531 teacher: 0 stage: sketch lr: 0.000657\n",
      "batch 802 loss: 0.28311 acc: 0.92806 | v_loss: 0.62573 v_acc: 0.87207 |  iteration: 4532 teacher: 1 stage: sketch lr: 0.000656\n",
      "batch 803 loss: 0.23751 acc: 0.92936 | v_loss: 0.68378 v_acc: 0.86133 |  iteration: 4533 teacher: 1 stage: sketch lr: 0.000656\n",
      "batch 804 loss: 0.30343 acc: 0.90951 | v_loss: 0.40039 v_acc: 0.90788 |  iteration: 4534 teacher: 0 stage: sketch lr: 0.000656\n",
      "batch 805 loss: 0.30265 acc: 0.91732 | v_loss: 0.52578 v_acc: 0.88477 |  iteration: 4535 teacher: 1 stage: sketch lr: 0.000656\n",
      "batch 806 loss: 0.39062 acc: 0.88965 | v_loss: 0.74721 v_acc: 0.84180 |  iteration: 4536 teacher: 0 stage: sketch lr: 0.000656\n",
      "batch 807 loss: 0.31825 acc: 0.91048 | v_loss: 0.48678 v_acc: 0.88346 |  iteration: 4537 teacher: 1 stage: sketch lr: 0.000656\n",
      "batch 808 loss: 0.26927 acc: 0.92090 | v_loss: 0.49652 v_acc: 0.88216 |  iteration: 4538 teacher: 0 stage: sketch lr: 0.000656\n",
      "batch 809 loss: 0.32420 acc: 0.91016 | v_loss: 0.52561 v_acc: 0.87500 |  iteration: 4539 teacher: 1 stage: sketch lr: 0.000656\n",
      "batch 810 loss: 0.31445 acc: 0.90527 | v_loss: 0.47822 v_acc: 0.89648 |  iteration: 4540 teacher: 0 stage: sketch lr: 0.000656\n",
      "batch 811 loss: 0.31073 acc: 0.91081 | v_loss: 0.47971 v_acc: 0.89030 |  iteration: 4541 teacher: 0 stage: sketch lr: 0.000656\n",
      "batch 812 loss: 0.33483 acc: 0.90137 | v_loss: 0.58321 v_acc: 0.87402 |  iteration: 4542 teacher: 0 stage: sketch lr: 0.000656\n",
      "batch 813 loss: 0.28162 acc: 0.91732 | v_loss: 0.42724 v_acc: 0.91699 |  iteration: 4543 teacher: 1 stage: sketch lr: 0.000656\n",
      "batch 814 loss: 0.28047 acc: 0.92188 | v_loss: 0.96558 v_acc: 0.82975 |  iteration: 4544 teacher: 1 stage: sketch lr: 0.000656\n",
      "batch 815 loss: 0.30382 acc: 0.90918 | v_loss: 0.65029 v_acc: 0.87663 |  iteration: 4545 teacher: 1 stage: sketch lr: 0.000656\n",
      "batch 816 loss: 0.26627 acc: 0.92057 | v_loss: 0.70934 v_acc: 0.86068 |  iteration: 4546 teacher: 1 stage: sketch lr: 0.000655\n",
      "batch 817 loss: 0.34552 acc: 0.91016 | v_loss: 0.56040 v_acc: 0.89355 |  iteration: 4547 teacher: 1 stage: sketch lr: 0.000655\n",
      "batch 818 loss: 0.35123 acc: 0.90560 | v_loss: 0.54076 v_acc: 0.88574 |  iteration: 4548 teacher: 0 stage: sketch lr: 0.000655\n",
      "batch 819 loss: 0.36916 acc: 0.89225 | v_loss: 0.62177 v_acc: 0.87826 |  iteration: 4549 teacher: 0 stage: sketch lr: 0.000655\n",
      "batch 820 loss: 0.26393 acc: 0.92415 | v_loss: 0.57044 v_acc: 0.88053 |  iteration: 4550 teacher: 0 stage: sketch lr: 0.000655\n",
      "batch 821 loss: 0.30986 acc: 0.91178 | v_loss: 0.52877 v_acc: 0.88574 |  iteration: 4551 teacher: 0 stage: sketch lr: 0.000655\n",
      "batch 822 loss: 0.30023 acc: 0.91829 | v_loss: 0.50415 v_acc: 0.89551 |  iteration: 4552 teacher: 1 stage: sketch lr: 0.000655\n",
      "batch 823 loss: 0.33100 acc: 0.90690 | v_loss: 0.48417 v_acc: 0.88932 |  iteration: 4553 teacher: 0 stage: sketch lr: 0.000655\n",
      "batch 824 loss: 0.31821 acc: 0.91113 | v_loss: 0.38221 v_acc: 0.91146 |  iteration: 4554 teacher: 1 stage: sketch lr: 0.000655\n",
      "batch 825 loss: 0.30553 acc: 0.90853 | v_loss: 0.67366 v_acc: 0.85775 |  iteration: 4555 teacher: 0 stage: sketch lr: 0.000655\n",
      "batch 826 loss: 0.30313 acc: 0.90820 | v_loss: 0.56654 v_acc: 0.86686 |  iteration: 4556 teacher: 0 stage: sketch lr: 0.000655\n",
      "batch 827 loss: 0.30972 acc: 0.90885 | v_loss: 0.65689 v_acc: 0.86068 |  iteration: 4557 teacher: 1 stage: sketch lr: 0.000655\n",
      "batch 828 loss: 0.31793 acc: 0.91439 | v_loss: 0.84469 v_acc: 0.83659 |  iteration: 4558 teacher: 1 stage: sketch lr: 0.000655\n",
      "batch 829 loss: 0.30213 acc: 0.91309 | v_loss: 0.43252 v_acc: 0.90430 |  iteration: 4559 teacher: 0 stage: sketch lr: 0.000655\n",
      "batch 830 loss: 0.28168 acc: 0.91764 | v_loss: 0.58743 v_acc: 0.86654 |  iteration: 4560 teacher: 1 stage: sketch lr: 0.000654\n",
      "batch 831 loss: 0.28032 acc: 0.91504 | v_loss: 0.51975 v_acc: 0.89421 |  iteration: 4561 teacher: 0 stage: sketch lr: 0.000654\n",
      "batch 832 loss: 0.29979 acc: 0.91536 | v_loss: 0.40219 v_acc: 0.90723 |  iteration: 4562 teacher: 1 stage: sketch lr: 0.000654\n",
      "batch 833 loss: 0.36849 acc: 0.89746 | v_loss: 1.18760 v_acc: 0.79395 |  iteration: 4563 teacher: 1 stage: sketch lr: 0.000654\n",
      "batch 834 loss: 0.29728 acc: 0.90853 | v_loss: 0.40046 v_acc: 0.91211 |  iteration: 4564 teacher: 0 stage: sketch lr: 0.000654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 835 loss: 0.27454 acc: 0.92285 | v_loss: 0.63190 v_acc: 0.87435 |  iteration: 4565 teacher: 0 stage: sketch lr: 0.000654\n",
      "batch 836 loss: 0.25326 acc: 0.92643 | v_loss: 0.55834 v_acc: 0.88965 |  iteration: 4566 teacher: 1 stage: sketch lr: 0.000654\n",
      "batch 837 loss: 0.32172 acc: 0.91504 | v_loss: 0.41406 v_acc: 0.90918 |  iteration: 4567 teacher: 1 stage: sketch lr: 0.000654\n",
      "batch 838 loss: 0.26702 acc: 0.92122 | v_loss: 0.51396 v_acc: 0.88542 |  iteration: 4568 teacher: 0 stage: sketch lr: 0.000654\n",
      "batch 839 loss: 0.26469 acc: 0.91602 | v_loss: 0.57514 v_acc: 0.87598 |  iteration: 4569 teacher: 1 stage: sketch lr: 0.000654\n",
      "batch 840 loss: 0.37842 acc: 0.89746 | v_loss: 0.45803 v_acc: 0.90104 |  iteration: 4570 teacher: 1 stage: sketch lr: 0.000654\n",
      "batch 841 loss: 0.23060 acc: 0.92741 | v_loss: 0.62584 v_acc: 0.87142 |  iteration: 4571 teacher: 1 stage: sketch lr: 0.000654\n",
      "batch 842 loss: 0.28275 acc: 0.92546 | v_loss: 0.40563 v_acc: 0.90625 |  iteration: 4572 teacher: 0 stage: sketch lr: 0.000654\n",
      "batch 843 loss: 0.25117 acc: 0.93132 | v_loss: 1.03578 v_acc: 0.81771 |  iteration: 4573 teacher: 1 stage: sketch lr: 0.000654\n",
      "batch 844 loss: 0.38640 acc: 0.90527 | v_loss: 0.60482 v_acc: 0.87533 |  iteration: 4574 teacher: 1 stage: sketch lr: 0.000653\n",
      "batch 845 loss: 0.24818 acc: 0.92611 | v_loss: 0.65380 v_acc: 0.87207 |  iteration: 4575 teacher: 1 stage: sketch lr: 0.000653\n",
      "batch 846 loss: 0.26073 acc: 0.93001 | v_loss: 0.41667 v_acc: 0.89941 |  iteration: 4576 teacher: 0 stage: sketch lr: 0.000653\n",
      "batch 847 loss: 0.33504 acc: 0.90397 | v_loss: 0.62734 v_acc: 0.86491 |  iteration: 4577 teacher: 1 stage: sketch lr: 0.000653\n",
      "batch 848 loss: 0.24336 acc: 0.92839 | v_loss: 0.48946 v_acc: 0.89128 |  iteration: 4578 teacher: 1 stage: sketch lr: 0.000653\n",
      "batch 849 loss: 0.32631 acc: 0.91243 | v_loss: 0.48340 v_acc: 0.88509 |  iteration: 4579 teacher: 1 stage: sketch lr: 0.000653\n",
      "batch 850 loss: 0.26664 acc: 0.91764 | v_loss: 0.46139 v_acc: 0.89062 |  iteration: 4580 teacher: 0 stage: sketch lr: 0.000653\n",
      "batch 851 loss: 0.31769 acc: 0.91113 | v_loss: 0.71576 v_acc: 0.84993 |  iteration: 4581 teacher: 0 stage: sketch lr: 0.000653\n",
      "batch 852 loss: 0.27487 acc: 0.91992 | v_loss: 0.53767 v_acc: 0.89453 |  iteration: 4582 teacher: 0 stage: sketch lr: 0.000653\n",
      "batch 853 loss: 0.35697 acc: 0.90267 | v_loss: 0.55009 v_acc: 0.87533 |  iteration: 4583 teacher: 1 stage: sketch lr: 0.000653\n",
      "batch 854 loss: 0.31446 acc: 0.91146 | v_loss: 0.66735 v_acc: 0.84961 |  iteration: 4584 teacher: 0 stage: sketch lr: 0.000653\n",
      "batch 855 loss: 0.25838 acc: 0.92318 | v_loss: 0.41222 v_acc: 0.90202 |  iteration: 4585 teacher: 1 stage: sketch lr: 0.000653\n",
      "batch 856 loss: 0.28263 acc: 0.91406 | v_loss: 0.49269 v_acc: 0.87435 |  iteration: 4586 teacher: 0 stage: sketch lr: 0.000653\n",
      "batch 857 loss: 0.30540 acc: 0.90397 | v_loss: 0.52137 v_acc: 0.87858 |  iteration: 4587 teacher: 0 stage: sketch lr: 0.000653\n",
      "batch 858 loss: 0.16525 acc: 0.94564 | v_loss: 0.76587 v_acc: 0.84766 |  iteration: 4588 teacher: 1 stage: sketch lr: 0.000652\n",
      "batch 859 loss: 0.22189 acc: 0.93587 | v_loss: 0.53472 v_acc: 0.88965 |  iteration: 4589 teacher: 1 stage: sketch lr: 0.000652\n",
      "batch 860 loss: 0.29019 acc: 0.92220 | v_loss: 0.56943 v_acc: 0.88639 |  iteration: 4590 teacher: 1 stage: sketch lr: 0.000652\n",
      "batch 861 loss: 0.41189 acc: 0.89453 | v_loss: 0.64322 v_acc: 0.87956 |  iteration: 4591 teacher: 1 stage: sketch lr: 0.000652\n",
      "batch 862 loss: 0.30851 acc: 0.90918 | v_loss: 0.58327 v_acc: 0.87207 |  iteration: 4592 teacher: 0 stage: sketch lr: 0.000652\n",
      "batch 863 loss: 0.28267 acc: 0.92480 | v_loss: 0.43676 v_acc: 0.90788 |  iteration: 4593 teacher: 1 stage: sketch lr: 0.000652\n",
      "batch 864 loss: 0.22572 acc: 0.93490 | v_loss: 0.77684 v_acc: 0.84082 |  iteration: 4594 teacher: 1 stage: sketch lr: 0.000652\n",
      "batch 865 loss: 0.30514 acc: 0.91536 | v_loss: 0.53487 v_acc: 0.88444 |  iteration: 4595 teacher: 1 stage: sketch lr: 0.000652\n",
      "batch 866 loss: 0.27650 acc: 0.91895 | v_loss: 0.54515 v_acc: 0.87044 |  iteration: 4596 teacher: 0 stage: sketch lr: 0.000652\n",
      "batch 867 loss: 0.40788 acc: 0.88477 | v_loss: 0.51976 v_acc: 0.87695 |  iteration: 4597 teacher: 0 stage: sketch lr: 0.000652\n",
      "batch 868 loss: 0.23043 acc: 0.93001 | v_loss: 0.46430 v_acc: 0.89290 |  iteration: 4598 teacher: 0 stage: sketch lr: 0.000652\n",
      "batch 869 loss: 0.23485 acc: 0.92839 | v_loss: 0.43293 v_acc: 0.89844 |  iteration: 4599 teacher: 0 stage: sketch lr: 0.000652\n",
      "batch 870 loss: 0.30222 acc: 0.91309 | v_loss: 0.51992 v_acc: 0.89062 |  iteration: 4600 teacher: 0 stage: sketch lr: 0.000652\n",
      "batch 871 loss: 0.31524 acc: 0.91927 | v_loss: 0.61456 v_acc: 0.85938 |  iteration: 4601 teacher: 1 stage: sketch lr: 0.000652\n",
      "batch 872 loss: 0.28469 acc: 0.92578 | v_loss: 0.62334 v_acc: 0.88086 |  iteration: 4602 teacher: 0 stage: sketch lr: 0.000651\n",
      "batch 873 loss: 0.33377 acc: 0.90234 | v_loss: 0.60025 v_acc: 0.88411 |  iteration: 4603 teacher: 1 stage: sketch lr: 0.000651\n",
      "batch 874 loss: 0.37194 acc: 0.89290 | v_loss: 0.37553 v_acc: 0.90658 |  iteration: 4604 teacher: 0 stage: sketch lr: 0.000651\n",
      "batch 875 loss: 0.27984 acc: 0.91504 | v_loss: 0.52607 v_acc: 0.88021 |  iteration: 4605 teacher: 0 stage: sketch lr: 0.000651\n",
      "batch 876 loss: 0.32417 acc: 0.90495 | v_loss: 0.47556 v_acc: 0.88542 |  iteration: 4606 teacher: 0 stage: sketch lr: 0.000651\n",
      "batch 877 loss: 0.31809 acc: 0.90267 | v_loss: 0.81878 v_acc: 0.82715 |  iteration: 4607 teacher: 0 stage: sketch lr: 0.000651\n",
      "batch 878 loss: 0.27269 acc: 0.93132 | v_loss: 0.36646 v_acc: 0.90658 |  iteration: 4608 teacher: 1 stage: sketch lr: 0.000651\n",
      "batch 879 loss: 0.28150 acc: 0.92025 | v_loss: 0.31302 v_acc: 0.93034 |  iteration: 4609 teacher: 0 stage: sketch lr: 0.000651\n",
      "batch 880 loss: 0.34810 acc: 0.90592 | v_loss: 0.51531 v_acc: 0.88672 |  iteration: 4610 teacher: 1 stage: sketch lr: 0.000651\n",
      "batch 881 loss: 0.27710 acc: 0.92057 | v_loss: 0.55972 v_acc: 0.88737 |  iteration: 4611 teacher: 1 stage: sketch lr: 0.000651\n",
      "batch 882 loss: 0.24404 acc: 0.93197 | v_loss: 0.65539 v_acc: 0.85579 |  iteration: 4612 teacher: 1 stage: sketch lr: 0.000651\n",
      "batch 883 loss: 0.36193 acc: 0.89844 | v_loss: 0.42604 v_acc: 0.89746 |  iteration: 4613 teacher: 1 stage: sketch lr: 0.000651\n",
      "batch 884 loss: 0.24048 acc: 0.92513 | v_loss: 0.49909 v_acc: 0.86816 |  iteration: 4614 teacher: 1 stage: sketch lr: 0.000651\n",
      "batch 885 loss: 0.20134 acc: 0.93880 | v_loss: 0.58638 v_acc: 0.86556 |  iteration: 4615 teacher: 1 stage: sketch lr: 0.000651\n",
      "batch 886 loss: 0.24091 acc: 0.92871 | v_loss: 0.68243 v_acc: 0.84831 |  iteration: 4616 teacher: 1 stage: sketch lr: 0.000650\n",
      "batch 887 loss: 0.26729 acc: 0.92936 | v_loss: 0.51593 v_acc: 0.89225 |  iteration: 4617 teacher: 1 stage: sketch lr: 0.000650\n",
      "batch 888 loss: 0.35486 acc: 0.90788 | v_loss: 0.39191 v_acc: 0.90495 |  iteration: 4618 teacher: 1 stage: sketch lr: 0.000650\n",
      "batch 889 loss: 0.23169 acc: 0.93359 | v_loss: 0.28232 v_acc: 0.92155 |  iteration: 4619 teacher: 1 stage: sketch lr: 0.000650\n",
      "batch 890 loss: 0.26603 acc: 0.92188 | v_loss: 0.44377 v_acc: 0.90365 |  iteration: 4620 teacher: 0 stage: sketch lr: 0.000650\n",
      "batch 891 loss: 0.36392 acc: 0.89421 | v_loss: 0.47641 v_acc: 0.88444 |  iteration: 4621 teacher: 1 stage: sketch lr: 0.000650\n",
      "batch 892 loss: 0.26566 acc: 0.91732 | v_loss: 0.79420 v_acc: 0.86035 |  iteration: 4622 teacher: 0 stage: sketch lr: 0.000650\n",
      "batch 893 loss: 0.23279 acc: 0.92415 | v_loss: 0.55137 v_acc: 0.88249 |  iteration: 4623 teacher: 0 stage: sketch lr: 0.000650\n",
      "batch 894 loss: 0.22399 acc: 0.94499 | v_loss: 0.63193 v_acc: 0.86816 |  iteration: 4624 teacher: 0 stage: sketch lr: 0.000650\n",
      "batch 895 loss: 0.29351 acc: 0.91732 | v_loss: 0.41913 v_acc: 0.89876 |  iteration: 4625 teacher: 1 stage: sketch lr: 0.000650\n",
      "batch 896 loss: 0.31581 acc: 0.90788 | v_loss: 0.52311 v_acc: 0.88574 |  iteration: 4626 teacher: 0 stage: sketch lr: 0.000650\n",
      "batch 897 loss: 0.21371 acc: 0.93848 | v_loss: 0.81459 v_acc: 0.84831 |  iteration: 4627 teacher: 1 stage: sketch lr: 0.000650\n",
      "batch 898 loss: 0.23377 acc: 0.92839 | v_loss: 0.50151 v_acc: 0.89225 |  iteration: 4628 teacher: 1 stage: sketch lr: 0.000650\n",
      "batch 899 loss: 0.24678 acc: 0.93229 | v_loss: 0.52672 v_acc: 0.89128 |  iteration: 4629 teacher: 1 stage: sketch lr: 0.000650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 900 loss: 0.29014 acc: 0.91634 | v_loss: 0.48744 v_acc: 0.89355 |  iteration: 4630 teacher: 0 stage: sketch lr: 0.000649\n",
      "batch 901 loss: 0.22915 acc: 0.93457 | v_loss: 0.44423 v_acc: 0.90853 |  iteration: 4631 teacher: 1 stage: sketch lr: 0.000649\n",
      "batch 902 loss: 0.23388 acc: 0.93229 | v_loss: 0.45898 v_acc: 0.90332 |  iteration: 4632 teacher: 1 stage: sketch lr: 0.000649\n",
      "batch 903 loss: 0.20643 acc: 0.93587 | v_loss: 0.61730 v_acc: 0.86816 |  iteration: 4633 teacher: 1 stage: sketch lr: 0.000649\n",
      "batch 904 loss: 0.29030 acc: 0.91146 | v_loss: 0.35462 v_acc: 0.92253 |  iteration: 4634 teacher: 1 stage: sketch lr: 0.000649\n",
      "batch 905 loss: 0.26009 acc: 0.92741 | v_loss: 0.99606 v_acc: 0.83171 |  iteration: 4635 teacher: 1 stage: sketch lr: 0.000649\n",
      "batch 906 loss: 0.23206 acc: 0.92773 | v_loss: 0.64871 v_acc: 0.87500 |  iteration: 4636 teacher: 0 stage: sketch lr: 0.000649\n",
      "batch 907 loss: 0.25271 acc: 0.93262 | v_loss: 0.72989 v_acc: 0.86328 |  iteration: 4637 teacher: 1 stage: sketch lr: 0.000649\n",
      "batch 908 loss: 0.24318 acc: 0.93034 | v_loss: 0.53742 v_acc: 0.89486 |  iteration: 4638 teacher: 0 stage: sketch lr: 0.000649\n",
      "batch 909 loss: 0.27069 acc: 0.92708 | v_loss: 0.52792 v_acc: 0.88607 |  iteration: 4639 teacher: 0 stage: sketch lr: 0.000649\n",
      "batch 910 loss: 0.28681 acc: 0.92122 | v_loss: 0.58903 v_acc: 0.88053 |  iteration: 4640 teacher: 1 stage: sketch lr: 0.000649\n",
      "batch 911 loss: 0.26366 acc: 0.92448 | v_loss: 0.49518 v_acc: 0.88216 |  iteration: 4641 teacher: 1 stage: sketch lr: 0.000649\n",
      "batch 912 loss: 0.28165 acc: 0.91927 | v_loss: 0.50300 v_acc: 0.87793 |  iteration: 4642 teacher: 1 stage: sketch lr: 0.000649\n",
      "batch 913 loss: 0.37487 acc: 0.88542 | v_loss: 0.47403 v_acc: 0.89714 |  iteration: 4643 teacher: 1 stage: sketch lr: 0.000649\n",
      "batch 914 loss: 0.28740 acc: 0.91081 | v_loss: 0.43732 v_acc: 0.89258 |  iteration: 4644 teacher: 1 stage: sketch lr: 0.000649\n",
      "batch 915 loss: 0.37230 acc: 0.89779 | v_loss: 0.32969 v_acc: 0.91667 |  iteration: 4645 teacher: 0 stage: sketch lr: 0.000648\n",
      "batch 916 loss: 0.34106 acc: 0.90169 | v_loss: 0.65351 v_acc: 0.86263 |  iteration: 4646 teacher: 0 stage: sketch lr: 0.000648\n",
      "batch 917 loss: 0.27094 acc: 0.92155 | v_loss: 0.54868 v_acc: 0.87109 |  iteration: 4647 teacher: 1 stage: sketch lr: 0.000648\n",
      "batch 918 loss: 0.21307 acc: 0.93717 | v_loss: 0.61871 v_acc: 0.86751 |  iteration: 4648 teacher: 1 stage: sketch lr: 0.000648\n",
      "batch 919 loss: 0.21733 acc: 0.93424 | v_loss: 0.85272 v_acc: 0.84277 |  iteration: 4649 teacher: 1 stage: sketch lr: 0.000648\n",
      "batch 920 loss: 0.37534 acc: 0.89746 | v_loss: 0.42976 v_acc: 0.90592 |  iteration: 4650 teacher: 0 stage: sketch lr: 0.000648\n",
      "batch 921 loss: 0.26368 acc: 0.92546 | v_loss: 0.58964 v_acc: 0.87598 |  iteration: 4651 teacher: 1 stage: sketch lr: 0.000648\n",
      "batch 922 loss: 0.26168 acc: 0.92383 | v_loss: 0.52732 v_acc: 0.88932 |  iteration: 4652 teacher: 0 stage: sketch lr: 0.000648\n",
      "batch 923 loss: 0.28970 acc: 0.91211 | v_loss: 0.43691 v_acc: 0.89974 |  iteration: 4653 teacher: 1 stage: sketch lr: 0.000648\n",
      "batch 924 loss: 0.28897 acc: 0.91439 | v_loss: 1.11047 v_acc: 0.79785 |  iteration: 4654 teacher: 1 stage: sketch lr: 0.000648\n",
      "batch 925 loss: 0.22996 acc: 0.93132 | v_loss: 0.35895 v_acc: 0.91927 |  iteration: 4655 teacher: 1 stage: sketch lr: 0.000648\n",
      "batch 926 loss: 0.24473 acc: 0.92611 | v_loss: 0.59521 v_acc: 0.87891 |  iteration: 4656 teacher: 0 stage: sketch lr: 0.000648\n",
      "batch 927 loss: 0.27528 acc: 0.91634 | v_loss: 0.51724 v_acc: 0.88997 |  iteration: 4657 teacher: 0 stage: sketch lr: 0.000648\n",
      "batch 928 loss: 0.21642 acc: 0.93717 | v_loss: 0.40575 v_acc: 0.90885 |  iteration: 4658 teacher: 1 stage: sketch lr: 0.000648\n",
      "batch 929 loss: 0.30498 acc: 0.91341 | v_loss: 0.51393 v_acc: 0.89160 |  iteration: 4659 teacher: 0 stage: sketch lr: 0.000647\n",
      "batch 930 loss: 0.30950 acc: 0.91178 | v_loss: 0.59100 v_acc: 0.87012 |  iteration: 4660 teacher: 0 stage: sketch lr: 0.000647\n",
      "batch 931 loss: 0.19682 acc: 0.93945 | v_loss: 0.42094 v_acc: 0.90169 |  iteration: 4661 teacher: 0 stage: sketch lr: 0.000647\n",
      "batch 932 loss: 0.17385 acc: 0.94759 | v_loss: 0.62581 v_acc: 0.86914 |  iteration: 4662 teacher: 1 stage: sketch lr: 0.000647\n",
      "batch 933 loss: 0.21491 acc: 0.94141 | v_loss: 0.38066 v_acc: 0.90495 |  iteration: 4663 teacher: 1 stage: sketch lr: 0.000647\n",
      "batch 934 loss: 0.33864 acc: 0.89779 | v_loss: 0.98658 v_acc: 0.81445 |  iteration: 4664 teacher: 0 stage: sketch lr: 0.000647\n",
      "batch 935 loss: 0.29767 acc: 0.92090 | v_loss: 0.58575 v_acc: 0.88639 |  iteration: 4665 teacher: 1 stage: sketch lr: 0.000647\n",
      "batch 936 loss: 0.28743 acc: 0.92513 | v_loss: 0.69100 v_acc: 0.86133 |  iteration: 4666 teacher: 1 stage: sketch lr: 0.000647\n",
      "batch 937 loss: 0.23033 acc: 0.93066 | v_loss: 0.42235 v_acc: 0.90430 |  iteration: 4667 teacher: 0 stage: sketch lr: 0.000647\n",
      "batch 938 loss: 0.27207 acc: 0.92871 | v_loss: 0.66734 v_acc: 0.85938 |  iteration: 4668 teacher: 1 stage: sketch lr: 0.000647\n",
      "batch 939 loss: 0.27445 acc: 0.91732 | v_loss: 0.43802 v_acc: 0.89193 |  iteration: 4669 teacher: 0 stage: sketch lr: 0.000647\n",
      "batch 940 loss: 0.24487 acc: 0.93197 | v_loss: 0.47496 v_acc: 0.89193 |  iteration: 4670 teacher: 1 stage: sketch lr: 0.000647\n",
      "batch 941 loss: 0.35012 acc: 0.90592 | v_loss: 0.45259 v_acc: 0.89551 |  iteration: 4671 teacher: 1 stage: sketch lr: 0.000647\n",
      "batch 942 loss: 0.33140 acc: 0.91374 | v_loss: 0.74321 v_acc: 0.85059 |  iteration: 4672 teacher: 1 stage: sketch lr: 0.000647\n",
      "batch 943 loss: 0.16759 acc: 0.94857 | v_loss: 0.50715 v_acc: 0.89258 |  iteration: 4673 teacher: 1 stage: sketch lr: 0.000646\n",
      "batch 944 loss: 0.23725 acc: 0.92839 | v_loss: 0.53071 v_acc: 0.88021 |  iteration: 4674 teacher: 1 stage: sketch lr: 0.000646\n",
      "batch 945 loss: 0.35694 acc: 0.90625 | v_loss: 0.65318 v_acc: 0.85612 |  iteration: 4675 teacher: 1 stage: sketch lr: 0.000646\n",
      "batch 946 loss: 0.20705 acc: 0.93978 | v_loss: 0.44981 v_acc: 0.88965 |  iteration: 4676 teacher: 1 stage: sketch lr: 0.000646\n",
      "batch 947 loss: 0.24188 acc: 0.92839 | v_loss: 0.51398 v_acc: 0.86719 |  iteration: 4677 teacher: 0 stage: sketch lr: 0.000646\n",
      "batch 948 loss: 0.27031 acc: 0.92415 | v_loss: 0.54610 v_acc: 0.86751 |  iteration: 4678 teacher: 1 stage: sketch lr: 0.000646\n",
      "batch 949 loss: 0.21947 acc: 0.93783 | v_loss: 0.74716 v_acc: 0.84668 |  iteration: 4679 teacher: 1 stage: sketch lr: 0.000646\n",
      "batch 950 loss: 0.25959 acc: 0.92611 | v_loss: 0.51860 v_acc: 0.88965 |  iteration: 4680 teacher: 1 stage: sketch lr: 0.000646\n",
      "batch 951 loss: 0.25681 acc: 0.92969 | v_loss: 0.57286 v_acc: 0.88509 |  iteration: 4681 teacher: 1 stage: sketch lr: 0.000646\n",
      "batch 952 loss: 0.19969 acc: 0.94238 | v_loss: 0.65352 v_acc: 0.88151 |  iteration: 4682 teacher: 0 stage: sketch lr: 0.000646\n",
      "batch 953 loss: 0.28026 acc: 0.91634 | v_loss: 0.58645 v_acc: 0.86263 |  iteration: 4683 teacher: 0 stage: sketch lr: 0.000646\n",
      "batch 954 loss: 0.25751 acc: 0.92904 | v_loss: 0.45751 v_acc: 0.89844 |  iteration: 4684 teacher: 1 stage: sketch lr: 0.000646\n",
      "batch 955 loss: 0.24685 acc: 0.93262 | v_loss: 0.80376 v_acc: 0.84147 |  iteration: 4685 teacher: 0 stage: sketch lr: 0.000646\n",
      "batch 956 loss: 0.28170 acc: 0.91797 | v_loss: 0.61285 v_acc: 0.88379 |  iteration: 4686 teacher: 0 stage: sketch lr: 0.000646\n",
      "batch 957 loss: 0.29725 acc: 0.90755 | v_loss: 0.53451 v_acc: 0.87598 |  iteration: 4687 teacher: 0 stage: sketch lr: 0.000646\n",
      "batch 958 loss: 0.22397 acc: 0.93945 | v_loss: 0.53749 v_acc: 0.88151 |  iteration: 4688 teacher: 1 stage: sketch lr: 0.000645\n",
      "batch 959 loss: 0.25438 acc: 0.92415 | v_loss: 0.46605 v_acc: 0.89486 |  iteration: 4689 teacher: 1 stage: sketch lr: 0.000645\n",
      "batch 960 loss: 0.24197 acc: 0.92904 | v_loss: 0.47241 v_acc: 0.89290 |  iteration: 4690 teacher: 0 stage: sketch lr: 0.000645\n",
      "batch 961 loss: 0.24699 acc: 0.92253 | v_loss: 0.52206 v_acc: 0.89323 |  iteration: 4691 teacher: 1 stage: sketch lr: 0.000645\n",
      "batch 962 loss: 0.37404 acc: 0.90397 | v_loss: 0.61681 v_acc: 0.85970 |  iteration: 4692 teacher: 1 stage: sketch lr: 0.000645\n",
      "batch 963 loss: 0.34487 acc: 0.90299 | v_loss: 0.59697 v_acc: 0.88281 |  iteration: 4693 teacher: 0 stage: sketch lr: 0.000645\n",
      "batch 964 loss: 0.25560 acc: 0.92383 | v_loss: 0.58296 v_acc: 0.88737 |  iteration: 4694 teacher: 0 stage: sketch lr: 0.000645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 965 loss: 0.28449 acc: 0.91895 | v_loss: 0.39110 v_acc: 0.90918 |  iteration: 4695 teacher: 0 stage: sketch lr: 0.000645\n",
      "batch 966 loss: 0.34544 acc: 0.90527 | v_loss: 0.54885 v_acc: 0.88184 |  iteration: 4696 teacher: 0 stage: sketch lr: 0.000645\n",
      "batch 967 loss: 0.28878 acc: 0.92448 | v_loss: 0.49211 v_acc: 0.87663 |  iteration: 4697 teacher: 1 stage: sketch lr: 0.000645\n",
      "batch 968 loss: 0.27891 acc: 0.92253 | v_loss: 0.81658 v_acc: 0.82878 |  iteration: 4698 teacher: 1 stage: sketch lr: 0.000645\n",
      "batch 969 loss: 0.28855 acc: 0.90430 | v_loss: 0.37197 v_acc: 0.90853 |  iteration: 4699 teacher: 0 stage: sketch lr: 0.000645\n",
      "batch 970 loss: 0.22363 acc: 0.93392 | v_loss: 0.33115 v_acc: 0.92025 |  iteration: 4700 teacher: 1 stage: sketch lr: 0.000645\n",
      "batch 971 loss: 0.23074 acc: 0.93424 | v_loss: 0.57264 v_acc: 0.87923 |  iteration: 4701 teacher: 1 stage: sketch lr: 0.000645\n",
      "batch 972 loss: 0.32885 acc: 0.90267 | v_loss: 0.57867 v_acc: 0.87923 |  iteration: 4702 teacher: 0 stage: sketch lr: 0.000645\n",
      "batch 973 loss: 0.27573 acc: 0.92676 | v_loss: 0.65865 v_acc: 0.85189 |  iteration: 4703 teacher: 0 stage: sketch lr: 0.000644\n",
      "batch 974 loss: 0.27604 acc: 0.91992 | v_loss: 0.40630 v_acc: 0.90234 |  iteration: 4704 teacher: 0 stage: sketch lr: 0.000644\n",
      "batch 975 loss: 0.24951 acc: 0.93359 | v_loss: 0.56154 v_acc: 0.86719 |  iteration: 4705 teacher: 1 stage: sketch lr: 0.000644\n",
      "batch 976 loss: 0.33611 acc: 0.90723 | v_loss: 0.60944 v_acc: 0.86979 |  iteration: 4706 teacher: 1 stage: sketch lr: 0.000644\n",
      "batch 977 loss: 0.23323 acc: 0.93164 | v_loss: 0.64547 v_acc: 0.85384 |  iteration: 4707 teacher: 0 stage: sketch lr: 0.000644\n",
      "batch 978 loss: 0.29384 acc: 0.91699 | v_loss: 0.47022 v_acc: 0.89258 |  iteration: 4708 teacher: 0 stage: sketch lr: 0.000644\n",
      "batch 979 loss: 0.35507 acc: 0.90527 | v_loss: 0.36696 v_acc: 0.90690 |  iteration: 4709 teacher: 1 stage: sketch lr: 0.000644\n",
      "batch 980 loss: 0.27769 acc: 0.91895 | v_loss: 0.28760 v_acc: 0.92350 |  iteration: 4710 teacher: 0 stage: sketch lr: 0.000644\n",
      "batch 981 loss: 0.25175 acc: 0.93164 | v_loss: 0.47171 v_acc: 0.90299 |  iteration: 4711 teacher: 0 stage: sketch lr: 0.000644\n",
      "batch 982 loss: 0.28294 acc: 0.92057 | v_loss: 0.53873 v_acc: 0.89193 |  iteration: 4712 teacher: 1 stage: sketch lr: 0.000644\n",
      "batch 983 loss: 0.32395 acc: 0.91178 | v_loss: 0.86400 v_acc: 0.84863 |  iteration: 4713 teacher: 1 stage: sketch lr: 0.000644\n",
      "batch 984 loss: 0.34351 acc: 0.91439 | v_loss: 0.56556 v_acc: 0.87240 |  iteration: 4714 teacher: 1 stage: sketch lr: 0.000644\n",
      "batch 985 loss: 0.24052 acc: 0.92676 | v_loss: 0.66913 v_acc: 0.86849 |  iteration: 4715 teacher: 0 stage: sketch lr: 0.000644\n",
      "batch 986 loss: 0.33104 acc: 0.90755 | v_loss: 0.43534 v_acc: 0.89714 |  iteration: 4716 teacher: 1 stage: sketch lr: 0.000644\n",
      "batch 987 loss: 0.33283 acc: 0.90202 | v_loss: 0.55352 v_acc: 0.88184 |  iteration: 4717 teacher: 0 stage: sketch lr: 0.000643\n",
      "batch 988 loss: 0.22808 acc: 0.93132 | v_loss: 0.76517 v_acc: 0.84147 |  iteration: 4718 teacher: 0 stage: sketch lr: 0.000643\n",
      "batch 989 loss: 0.26818 acc: 0.92936 | v_loss: 0.51681 v_acc: 0.89290 |  iteration: 4719 teacher: 1 stage: sketch lr: 0.000643\n",
      "batch 990 loss: 0.29858 acc: 0.91667 | v_loss: 0.56570 v_acc: 0.88118 |  iteration: 4720 teacher: 1 stage: sketch lr: 0.000643\n",
      "batch 991 loss: 0.32022 acc: 0.90853 | v_loss: 0.48445 v_acc: 0.88737 |  iteration: 4721 teacher: 0 stage: sketch lr: 0.000643\n",
      "batch 992 loss: 0.29386 acc: 0.91602 | v_loss: 0.41028 v_acc: 0.90788 |  iteration: 4722 teacher: 0 stage: sketch lr: 0.000643\n",
      "batch 993 loss: 0.25401 acc: 0.92708 | v_loss: 0.51281 v_acc: 0.89095 |  iteration: 4723 teacher: 1 stage: sketch lr: 0.000643\n",
      "batch 994 loss: 0.27662 acc: 0.91764 | v_loss: 0.59364 v_acc: 0.86686 |  iteration: 4724 teacher: 0 stage: sketch lr: 0.000643\n",
      "batch 995 loss: 0.35606 acc: 0.90007 | v_loss: 0.38064 v_acc: 0.91862 |  iteration: 4725 teacher: 1 stage: sketch lr: 0.000643\n",
      "batch 996 loss: 0.26895 acc: 0.91569 | v_loss: 0.91659 v_acc: 0.82910 |  iteration: 4726 teacher: 1 stage: sketch lr: 0.000643\n",
      "batch 997 loss: 0.22810 acc: 0.93132 | v_loss: 0.65372 v_acc: 0.87435 |  iteration: 4727 teacher: 1 stage: sketch lr: 0.000643\n",
      "batch 998 loss: 0.28705 acc: 0.91504 | v_loss: 0.68426 v_acc: 0.86719 |  iteration: 4728 teacher: 0 stage: sketch lr: 0.000643\n",
      "batch 999 loss: 0.29931 acc: 0.91178 | v_loss: 0.55184 v_acc: 0.89518 |  iteration: 4729 teacher: 0 stage: sketch lr: 0.000643\n",
      "batch 1000 loss: 0.27074 acc: 0.92285 | v_loss: 0.44524 v_acc: 0.89909 |  iteration: 4730 teacher: 0 stage: sketch lr: 0.000643\n",
      "batch 1001 loss: 0.25884 acc: 0.92546 | v_loss: 0.56558 v_acc: 0.88802 |  iteration: 4731 teacher: 0 stage: sketch lr: 0.000643\n",
      "batch 1002 loss: 0.28293 acc: 0.91276 | v_loss: 0.53694 v_acc: 0.89030 |  iteration: 4732 teacher: 0 stage: sketch lr: 0.000642\n",
      "batch 1003 loss: 0.19428 acc: 0.94141 | v_loss: 0.51258 v_acc: 0.88249 |  iteration: 4733 teacher: 1 stage: sketch lr: 0.000642\n",
      "batch 1004 loss: 0.34289 acc: 0.90853 | v_loss: 0.51857 v_acc: 0.89551 |  iteration: 4734 teacher: 1 stage: sketch lr: 0.000642\n",
      "batch 1005 loss: 0.29361 acc: 0.91471 | v_loss: 0.46809 v_acc: 0.89779 |  iteration: 4735 teacher: 0 stage: sketch lr: 0.000642\n",
      "batch 1006 loss: 0.29851 acc: 0.91504 | v_loss: 0.34848 v_acc: 0.92448 |  iteration: 4736 teacher: 0 stage: sketch lr: 0.000642\n",
      "batch 1007 loss: 0.27380 acc: 0.91862 | v_loss: 0.58737 v_acc: 0.86523 |  iteration: 4737 teacher: 1 stage: sketch lr: 0.000642\n",
      "batch 1008 loss: 0.25960 acc: 0.92480 | v_loss: 0.51466 v_acc: 0.86621 |  iteration: 4738 teacher: 0 stage: sketch lr: 0.000642\n",
      "batch 1009 loss: 0.32826 acc: 0.90397 | v_loss: 0.60116 v_acc: 0.86621 |  iteration: 4739 teacher: 0 stage: sketch lr: 0.000642\n",
      "batch 1010 loss: 0.29055 acc: 0.91895 | v_loss: 0.80764 v_acc: 0.84766 |  iteration: 4740 teacher: 1 stage: sketch lr: 0.000642\n",
      "batch 1011 loss: 0.26791 acc: 0.91862 | v_loss: 0.42528 v_acc: 0.90723 |  iteration: 4741 teacher: 0 stage: sketch lr: 0.000642\n",
      "batch 1012 loss: 0.26195 acc: 0.92741 | v_loss: 0.59069 v_acc: 0.87793 |  iteration: 4742 teacher: 0 stage: sketch lr: 0.000642\n",
      "batch 1013 loss: 0.20753 acc: 0.93620 | v_loss: 0.56052 v_acc: 0.88835 |  iteration: 4743 teacher: 0 stage: sketch lr: 0.000642\n",
      "batch 1014 loss: 0.26952 acc: 0.92122 | v_loss: 0.44055 v_acc: 0.91048 |  iteration: 4744 teacher: 1 stage: sketch lr: 0.000642\n",
      "batch 1015 loss: 0.25780 acc: 0.92741 | v_loss: 1.18184 v_acc: 0.80762 |  iteration: 4745 teacher: 1 stage: sketch lr: 0.000642\n",
      "batch 1016 loss: 0.24768 acc: 0.92383 | v_loss: 0.38816 v_acc: 0.91732 |  iteration: 4746 teacher: 0 stage: sketch lr: 0.000642\n",
      "batch 1017 loss: 0.22869 acc: 0.93034 | v_loss: 0.62120 v_acc: 0.88151 |  iteration: 4747 teacher: 1 stage: sketch lr: 0.000641\n",
      "batch 1018 loss: 0.26136 acc: 0.91829 | v_loss: 0.52781 v_acc: 0.89486 |  iteration: 4748 teacher: 1 stage: sketch lr: 0.000641\n",
      "batch 1019 loss: 0.28220 acc: 0.91146 | v_loss: 0.41334 v_acc: 0.91016 |  iteration: 4749 teacher: 0 stage: sketch lr: 0.000641\n",
      "batch 1020 loss: 0.21149 acc: 0.93978 | v_loss: 0.51130 v_acc: 0.89225 |  iteration: 4750 teacher: 1 stage: sketch lr: 0.000641\n",
      "batch 1021 loss: 0.30021 acc: 0.91992 | v_loss: 0.59064 v_acc: 0.87337 |  iteration: 4751 teacher: 1 stage: sketch lr: 0.000641\n",
      "batch 1022 loss: 0.30064 acc: 0.91243 | v_loss: 0.42893 v_acc: 0.90430 |  iteration: 4752 teacher: 0 stage: sketch lr: 0.000641\n",
      "batch 1023 loss: 0.30865 acc: 0.90527 | v_loss: 0.62131 v_acc: 0.86426 |  iteration: 4753 teacher: 0 stage: sketch lr: 0.000641\n",
      "batch 1024 loss: 0.32304 acc: 0.91016 | v_loss: 0.38606 v_acc: 0.90658 |  iteration: 4754 teacher: 1 stage: sketch lr: 0.000641\n",
      "batch 1025 loss: 0.32229 acc: 0.90690 | v_loss: 0.95873 v_acc: 0.81738 |  iteration: 4755 teacher: 1 stage: sketch lr: 0.000641\n",
      "batch 1026 loss: 0.27470 acc: 0.91341 | v_loss: 0.58495 v_acc: 0.88118 |  iteration: 4756 teacher: 0 stage: sketch lr: 0.000641\n",
      "batch 1027 loss: 0.24419 acc: 0.93164 | v_loss: 0.67199 v_acc: 0.86882 |  iteration: 4757 teacher: 0 stage: sketch lr: 0.000641\n",
      "batch 1028 loss: 0.27429 acc: 0.91764 | v_loss: 0.42651 v_acc: 0.90202 |  iteration: 4758 teacher: 0 stage: sketch lr: 0.000641\n",
      "batch 1029 loss: 0.25623 acc: 0.92383 | v_loss: 0.66046 v_acc: 0.85905 |  iteration: 4759 teacher: 0 stage: sketch lr: 0.000641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1030 loss: 0.25591 acc: 0.91960 | v_loss: 0.43741 v_acc: 0.89876 |  iteration: 4760 teacher: 1 stage: sketch lr: 0.000641\n",
      "batch 1031 loss: 0.28520 acc: 0.92318 | v_loss: 0.46771 v_acc: 0.89388 |  iteration: 4761 teacher: 0 stage: sketch lr: 0.000640\n",
      "batch 1032 loss: 0.33450 acc: 0.90267 | v_loss: 0.41668 v_acc: 0.90072 |  iteration: 4762 teacher: 0 stage: sketch lr: 0.000640\n",
      "batch 1033 loss: 0.29962 acc: 0.91341 | v_loss: 0.73855 v_acc: 0.85482 |  iteration: 4763 teacher: 0 stage: sketch lr: 0.000640\n",
      "batch 1034 loss: 0.27593 acc: 0.91178 | v_loss: 0.53004 v_acc: 0.89518 |  iteration: 4764 teacher: 0 stage: sketch lr: 0.000640\n",
      "batch 1035 loss: 0.32367 acc: 0.90690 | v_loss: 0.56148 v_acc: 0.88346 |  iteration: 4765 teacher: 0 stage: sketch lr: 0.000640\n",
      "batch 1036 loss: 0.20942 acc: 0.93490 | v_loss: 0.65989 v_acc: 0.85514 |  iteration: 4766 teacher: 0 stage: sketch lr: 0.000640\n",
      "batch 1037 loss: 0.25734 acc: 0.92546 | v_loss: 0.45379 v_acc: 0.89388 |  iteration: 4767 teacher: 0 stage: sketch lr: 0.000640\n",
      "batch 1038 loss: 0.27229 acc: 0.92904 | v_loss: 0.51497 v_acc: 0.87923 |  iteration: 4768 teacher: 1 stage: sketch lr: 0.000640\n",
      "batch 1039 loss: 0.25937 acc: 0.92708 | v_loss: 0.55794 v_acc: 0.86719 |  iteration: 4769 teacher: 0 stage: sketch lr: 0.000640\n",
      "batch 1040 loss: 0.30196 acc: 0.90755 | v_loss: 0.73065 v_acc: 0.85482 |  iteration: 4770 teacher: 0 stage: sketch lr: 0.000640\n",
      "batch 1041 loss: 0.28907 acc: 0.92318 | v_loss: 0.52322 v_acc: 0.88770 |  iteration: 4771 teacher: 0 stage: sketch lr: 0.000640\n",
      "batch 1042 loss: 0.22436 acc: 0.92904 | v_loss: 0.53811 v_acc: 0.89160 |  iteration: 4772 teacher: 1 stage: sketch lr: 0.000640\n",
      "batch 1043 loss: 0.24984 acc: 0.92513 | v_loss: 0.64081 v_acc: 0.87793 |  iteration: 4773 teacher: 0 stage: sketch lr: 0.000640\n",
      "batch 1044 loss: 0.37433 acc: 0.89681 | v_loss: 0.56618 v_acc: 0.86133 |  iteration: 4774 teacher: 0 stage: sketch lr: 0.000640\n",
      "batch 1045 loss: 0.34509 acc: 0.90202 | v_loss: 0.45522 v_acc: 0.89616 |  iteration: 4775 teacher: 0 stage: sketch lr: 0.000640\n",
      "batch 1046 loss: 0.20341 acc: 0.93685 | v_loss: 0.84773 v_acc: 0.83757 |  iteration: 4776 teacher: 1 stage: sketch lr: 0.000639\n",
      "batch 1047 loss: 0.39475 acc: 0.89518 | v_loss: 0.59274 v_acc: 0.87695 |  iteration: 4777 teacher: 1 stage: sketch lr: 0.000639\n",
      "batch 1048 loss: 0.17927 acc: 0.94954 | v_loss: 0.60088 v_acc: 0.87630 |  iteration: 4778 teacher: 1 stage: sketch lr: 0.000639\n",
      "batch 1049 loss: 0.28990 acc: 0.91699 | v_loss: 0.58004 v_acc: 0.87240 |  iteration: 4779 teacher: 0 stage: sketch lr: 0.000639\n",
      "batch 1050 loss: 0.27447 acc: 0.91960 | v_loss: 0.51543 v_acc: 0.88151 |  iteration: 4780 teacher: 0 stage: sketch lr: 0.000639\n",
      "batch 1051 loss: 0.30500 acc: 0.90723 | v_loss: 0.46894 v_acc: 0.88835 |  iteration: 4781 teacher: 0 stage: sketch lr: 0.000639\n",
      "batch 1052 loss: 0.26726 acc: 0.92546 | v_loss: 0.51073 v_acc: 0.89030 |  iteration: 4782 teacher: 1 stage: sketch lr: 0.000639\n",
      "batch 1053 loss: 0.47945 acc: 0.86523 | v_loss: 0.60969 v_acc: 0.85384 |  iteration: 4783 teacher: 1 stage: sketch lr: 0.000639\n",
      "batch 1054 loss: 0.28529 acc: 0.92025 | v_loss: 0.59845 v_acc: 0.87533 |  iteration: 4784 teacher: 1 stage: sketch lr: 0.000639\n",
      "batch 1055 loss: 0.28426 acc: 0.91829 | v_loss: 0.64157 v_acc: 0.87858 |  iteration: 4785 teacher: 0 stage: sketch lr: 0.000639\n",
      "batch 1056 loss: 0.32397 acc: 0.90690 | v_loss: 0.37429 v_acc: 0.90690 |  iteration: 4786 teacher: 0 stage: sketch lr: 0.000639\n",
      "batch 1057 loss: 0.22887 acc: 0.93034 | v_loss: 0.53049 v_acc: 0.88477 |  iteration: 4787 teacher: 0 stage: sketch lr: 0.000639\n",
      "batch 1058 loss: 0.28241 acc: 0.92871 | v_loss: 0.47927 v_acc: 0.88704 |  iteration: 4788 teacher: 1 stage: sketch lr: 0.000639\n",
      "batch 1059 loss: 0.26589 acc: 0.91927 | v_loss: 0.79643 v_acc: 0.82975 |  iteration: 4789 teacher: 1 stage: sketch lr: 0.000639\n",
      "batch 1060 loss: 0.30067 acc: 0.91374 | v_loss: 0.37242 v_acc: 0.90690 |  iteration: 4790 teacher: 1 stage: sketch lr: 0.000639\n",
      "batch 1061 loss: 0.31820 acc: 0.90625 | v_loss: 0.33766 v_acc: 0.91862 |  iteration: 4791 teacher: 1 stage: sketch lr: 0.000638\n",
      "batch 1062 loss: 0.27657 acc: 0.92480 | v_loss: 0.54419 v_acc: 0.88411 |  iteration: 4792 teacher: 1 stage: sketch lr: 0.000638\n",
      "batch 1063 loss: 0.21478 acc: 0.93750 | v_loss: 0.55737 v_acc: 0.88444 |  iteration: 4793 teacher: 1 stage: sketch lr: 0.000638\n",
      "batch 1064 loss: 0.30738 acc: 0.90951 | v_loss: 0.66968 v_acc: 0.85807 |  iteration: 4794 teacher: 1 stage: sketch lr: 0.000638\n",
      "batch 1065 loss: 0.35443 acc: 0.89714 | v_loss: 0.44650 v_acc: 0.89355 |  iteration: 4795 teacher: 1 stage: sketch lr: 0.000638\n",
      "batch 1066 loss: 0.33913 acc: 0.90430 | v_loss: 0.50730 v_acc: 0.87598 |  iteration: 4796 teacher: 0 stage: sketch lr: 0.000638\n",
      "batch 1067 loss: 0.23835 acc: 0.92318 | v_loss: 0.60739 v_acc: 0.86491 |  iteration: 4797 teacher: 0 stage: sketch lr: 0.000638\n",
      "batch 1068 loss: 0.31859 acc: 0.91699 | v_loss: 0.65564 v_acc: 0.84766 |  iteration: 4798 teacher: 1 stage: sketch lr: 0.000638\n",
      "batch 1069 loss: 0.34228 acc: 0.90560 | v_loss: 0.51650 v_acc: 0.88900 |  iteration: 4799 teacher: 0 stage: sketch lr: 0.000638\n",
      "batch 1070 loss: 0.37461 acc: 0.90234 | v_loss: 0.38487 v_acc: 0.90592 |  iteration: 4800 teacher: 0 stage: sketch lr: 0.000638\n",
      "batch 1071 loss: 0.30439 acc: 0.91211 | v_loss: 0.31859 v_acc: 0.92122 |  iteration: 4801 teacher: 1 stage: sketch lr: 0.000638\n",
      "batch 1072 loss: 0.39118 acc: 0.88151 | v_loss: 0.46739 v_acc: 0.90462 |  iteration: 4802 teacher: 0 stage: sketch lr: 0.000638\n",
      "batch 1073 loss: 0.30959 acc: 0.91178 | v_loss: 0.52264 v_acc: 0.88444 |  iteration: 4803 teacher: 0 stage: sketch lr: 0.000638\n",
      "batch 1074 loss: 0.22687 acc: 0.93522 | v_loss: 0.83016 v_acc: 0.85417 |  iteration: 4804 teacher: 0 stage: sketch lr: 0.000638\n",
      "batch 1075 loss: 0.32531 acc: 0.90592 | v_loss: 0.55729 v_acc: 0.87565 |  iteration: 4805 teacher: 1 stage: sketch lr: 0.000638\n",
      "batch 1076 loss: 0.31411 acc: 0.90560 | v_loss: 0.66960 v_acc: 0.86686 |  iteration: 4806 teacher: 1 stage: sketch lr: 0.000637\n",
      "batch 1077 loss: 0.29303 acc: 0.91732 | v_loss: 0.39893 v_acc: 0.89811 |  iteration: 4807 teacher: 1 stage: sketch lr: 0.000637\n",
      "batch 1078 loss: 0.36664 acc: 0.89160 | v_loss: 0.52047 v_acc: 0.88086 |  iteration: 4808 teacher: 0 stage: sketch lr: 0.000637\n",
      "batch 1079 loss: 0.26805 acc: 0.92415 | v_loss: 0.69855 v_acc: 0.84961 |  iteration: 4809 teacher: 1 stage: sketch lr: 0.000637\n",
      "batch 1080 loss: 0.31604 acc: 0.90462 | v_loss: 0.52375 v_acc: 0.89225 |  iteration: 4810 teacher: 0 stage: sketch lr: 0.000637\n",
      "batch 1081 loss: 0.30092 acc: 0.91471 | v_loss: 0.52556 v_acc: 0.88835 |  iteration: 4811 teacher: 1 stage: sketch lr: 0.000637\n",
      "batch 1082 loss: 0.27957 acc: 0.91797 | v_loss: 0.46196 v_acc: 0.89128 |  iteration: 4812 teacher: 0 stage: sketch lr: 0.000637\n",
      "batch 1083 loss: 0.32086 acc: 0.90658 | v_loss: 0.45253 v_acc: 0.90137 |  iteration: 4813 teacher: 0 stage: sketch lr: 0.000637\n",
      "batch 1084 loss: 0.22068 acc: 0.93522 | v_loss: 0.48047 v_acc: 0.89486 |  iteration: 4814 teacher: 1 stage: sketch lr: 0.000637\n",
      "batch 1085 loss: 0.28579 acc: 0.91829 | v_loss: 0.57147 v_acc: 0.87077 |  iteration: 4815 teacher: 1 stage: sketch lr: 0.000637\n",
      "batch 1086 loss: 0.28542 acc: 0.91829 | v_loss: 0.36844 v_acc: 0.91895 |  iteration: 4816 teacher: 0 stage: sketch lr: 0.000637\n",
      "batch 1087 loss: 0.31840 acc: 0.91016 | v_loss: 0.95035 v_acc: 0.82715 |  iteration: 4817 teacher: 0 stage: sketch lr: 0.000637\n",
      "batch 1088 loss: 0.39118 acc: 0.89453 | v_loss: 0.59154 v_acc: 0.88314 |  iteration: 4818 teacher: 0 stage: sketch lr: 0.000637\n",
      "batch 1089 loss: 0.26725 acc: 0.91992 | v_loss: 0.69069 v_acc: 0.86361 |  iteration: 4819 teacher: 1 stage: sketch lr: 0.000637\n",
      "batch 1090 loss: 0.25428 acc: 0.93132 | v_loss: 0.53418 v_acc: 0.88932 |  iteration: 4820 teacher: 0 stage: sketch lr: 0.000637\n",
      "batch 1091 loss: 0.25916 acc: 0.92513 | v_loss: 0.48204 v_acc: 0.89290 |  iteration: 4821 teacher: 0 stage: sketch lr: 0.000636\n",
      "batch 1092 loss: 0.27549 acc: 0.91276 | v_loss: 0.56755 v_acc: 0.88607 |  iteration: 4822 teacher: 0 stage: sketch lr: 0.000636\n",
      "batch 1093 loss: 0.33864 acc: 0.90723 | v_loss: 0.50603 v_acc: 0.89225 |  iteration: 4823 teacher: 1 stage: sketch lr: 0.000636\n",
      "batch 1094 loss: 0.21570 acc: 0.93197 | v_loss: 0.48924 v_acc: 0.89648 |  iteration: 4824 teacher: 1 stage: sketch lr: 0.000636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1095 loss: 0.21613 acc: 0.93359 | v_loss: 0.46253 v_acc: 0.90658 |  iteration: 4825 teacher: 1 stage: sketch lr: 0.000636\n",
      "batch 1096 loss: 0.26785 acc: 0.92057 | v_loss: 0.45770 v_acc: 0.89616 |  iteration: 4826 teacher: 1 stage: sketch lr: 0.000636\n",
      "batch 1097 loss: 0.23824 acc: 0.92969 | v_loss: 0.33349 v_acc: 0.92090 |  iteration: 4827 teacher: 0 stage: sketch lr: 0.000636\n",
      "batch 1098 loss: 0.24984 acc: 0.92708 | v_loss: 0.58163 v_acc: 0.86849 |  iteration: 4828 teacher: 1 stage: sketch lr: 0.000636\n",
      "batch 1099 loss: 0.20793 acc: 0.94141 | v_loss: 0.52003 v_acc: 0.86589 |  iteration: 4829 teacher: 1 stage: sketch lr: 0.000636\n",
      "batch 1100 loss: 0.33100 acc: 0.90625 | v_loss: 0.57757 v_acc: 0.85905 |  iteration: 4830 teacher: 0 stage: sketch lr: 0.000636\n",
      "batch 1101 loss: 0.27560 acc: 0.92318 | v_loss: 0.81047 v_acc: 0.84375 |  iteration: 4831 teacher: 0 stage: sketch lr: 0.000636\n",
      "batch 1102 loss: 0.42126 acc: 0.88021 | v_loss: 0.44835 v_acc: 0.91016 |  iteration: 4832 teacher: 0 stage: sketch lr: 0.000636\n",
      "batch 1103 loss: 0.26339 acc: 0.92546 | v_loss: 0.62218 v_acc: 0.86654 |  iteration: 4833 teacher: 1 stage: sketch lr: 0.000636\n",
      "batch 1104 loss: 0.24106 acc: 0.92839 | v_loss: 0.55792 v_acc: 0.88704 |  iteration: 4834 teacher: 0 stage: sketch lr: 0.000636\n",
      "batch 1105 loss: 0.26330 acc: 0.92741 | v_loss: 0.40250 v_acc: 0.91439 |  iteration: 4835 teacher: 0 stage: sketch lr: 0.000636\n",
      "batch 1106 loss: 0.35325 acc: 0.90690 | v_loss: 1.18321 v_acc: 0.80176 |  iteration: 4836 teacher: 1 stage: sketch lr: 0.000636\n",
      "batch 1107 loss: 0.25558 acc: 0.92383 | v_loss: 0.41412 v_acc: 0.91406 |  iteration: 4837 teacher: 1 stage: sketch lr: 0.000635\n",
      "batch 1108 loss: 0.39914 acc: 0.89551 | v_loss: 0.62351 v_acc: 0.88184 |  iteration: 4838 teacher: 1 stage: sketch lr: 0.000635\n",
      "batch 1109 loss: 0.29745 acc: 0.91829 | v_loss: 0.54432 v_acc: 0.88704 |  iteration: 4839 teacher: 1 stage: sketch lr: 0.000635\n",
      "batch 1110 loss: 0.36236 acc: 0.89779 | v_loss: 0.43588 v_acc: 0.90007 |  iteration: 4840 teacher: 0 stage: sketch lr: 0.000635\n",
      "batch 1111 loss: 0.20937 acc: 0.93783 | v_loss: 0.52562 v_acc: 0.88086 |  iteration: 4841 teacher: 1 stage: sketch lr: 0.000635\n",
      "batch 1112 loss: 0.27662 acc: 0.92415 | v_loss: 0.57845 v_acc: 0.87174 |  iteration: 4842 teacher: 1 stage: sketch lr: 0.000635\n",
      "batch 1113 loss: 0.34473 acc: 0.90007 | v_loss: 0.42305 v_acc: 0.90397 |  iteration: 4843 teacher: 0 stage: sketch lr: 0.000635\n",
      "batch 1114 loss: 0.27812 acc: 0.91634 | v_loss: 0.60791 v_acc: 0.87012 |  iteration: 4844 teacher: 0 stage: sketch lr: 0.000635\n",
      "batch 1115 loss: 0.26089 acc: 0.92025 | v_loss: 0.38346 v_acc: 0.90853 |  iteration: 4845 teacher: 0 stage: sketch lr: 0.000635\n",
      "batch 1116 loss: 0.28131 acc: 0.92285 | v_loss: 0.95060 v_acc: 0.82812 |  iteration: 4846 teacher: 1 stage: sketch lr: 0.000635\n",
      "batch 1117 loss: 0.28650 acc: 0.91536 | v_loss: 0.55320 v_acc: 0.88509 |  iteration: 4847 teacher: 1 stage: sketch lr: 0.000635\n",
      "batch 1118 loss: 0.25646 acc: 0.92122 | v_loss: 0.70386 v_acc: 0.86816 |  iteration: 4848 teacher: 0 stage: sketch lr: 0.000635\n",
      "batch 1119 loss: 0.28514 acc: 0.92122 | v_loss: 0.40708 v_acc: 0.90397 |  iteration: 4849 teacher: 1 stage: sketch lr: 0.000635\n",
      "batch 1120 loss: 0.20131 acc: 0.94401 | v_loss: 0.66770 v_acc: 0.84863 |  iteration: 4850 teacher: 1 stage: sketch lr: 0.000635\n",
      "batch 1121 loss: 0.28873 acc: 0.91081 | v_loss: 0.42797 v_acc: 0.89681 |  iteration: 4851 teacher: 0 stage: sketch lr: 0.000635\n",
      "batch 1122 loss: 0.31071 acc: 0.90755 | v_loss: 0.47056 v_acc: 0.89388 |  iteration: 4852 teacher: 0 stage: sketch lr: 0.000634\n",
      "batch 1123 loss: 0.22758 acc: 0.92936 | v_loss: 0.47815 v_acc: 0.88965 |  iteration: 4853 teacher: 1 stage: sketch lr: 0.000634\n",
      "batch 1124 loss: 0.24827 acc: 0.93034 | v_loss: 0.70646 v_acc: 0.87174 |  iteration: 4854 teacher: 1 stage: sketch lr: 0.000634\n",
      "batch 1125 loss: 0.40684 acc: 0.89616 | v_loss: 0.53526 v_acc: 0.89486 |  iteration: 4855 teacher: 1 stage: sketch lr: 0.000634\n",
      "batch 1126 loss: 0.29774 acc: 0.91178 | v_loss: 0.53395 v_acc: 0.87923 |  iteration: 4856 teacher: 0 stage: sketch lr: 0.000634\n",
      "batch 1127 loss: 0.19852 acc: 0.93978 | v_loss: 0.62728 v_acc: 0.86230 |  iteration: 4857 teacher: 0 stage: sketch lr: 0.000634\n",
      "batch 1128 loss: 0.23112 acc: 0.93717 | v_loss: 0.44018 v_acc: 0.89518 |  iteration: 4858 teacher: 1 stage: sketch lr: 0.000634\n",
      "batch 1129 loss: 0.23749 acc: 0.92871 | v_loss: 0.51690 v_acc: 0.87207 |  iteration: 4859 teacher: 1 stage: sketch lr: 0.000634\n",
      "batch 1130 loss: 0.29699 acc: 0.91471 | v_loss: 0.53995 v_acc: 0.87077 |  iteration: 4860 teacher: 1 stage: sketch lr: 0.000634\n",
      "batch 1131 loss: 0.28987 acc: 0.91406 | v_loss: 0.77026 v_acc: 0.84212 |  iteration: 4861 teacher: 0 stage: sketch lr: 0.000634\n",
      "batch 1132 loss: 0.25914 acc: 0.91862 | v_loss: 0.56078 v_acc: 0.88346 |  iteration: 4862 teacher: 0 stage: sketch lr: 0.000634\n",
      "batch 1133 loss: 0.23470 acc: 0.93099 | v_loss: 0.60452 v_acc: 0.88281 |  iteration: 4863 teacher: 1 stage: sketch lr: 0.000634\n",
      "batch 1134 loss: 0.29969 acc: 0.91211 | v_loss: 0.67707 v_acc: 0.87793 |  iteration: 4864 teacher: 1 stage: sketch lr: 0.000634\n",
      "batch 1135 loss: 0.29090 acc: 0.92155 | v_loss: 0.56385 v_acc: 0.86751 |  iteration: 4865 teacher: 0 stage: sketch lr: 0.000634\n",
      "batch 1136 loss: 0.23654 acc: 0.92969 | v_loss: 0.42471 v_acc: 0.90560 |  iteration: 4866 teacher: 1 stage: sketch lr: 0.000634\n",
      "batch 1137 loss: 0.25967 acc: 0.92741 | v_loss: 0.79332 v_acc: 0.83464 |  iteration: 4867 teacher: 0 stage: sketch lr: 0.000633\n",
      "batch 1138 loss: 0.28561 acc: 0.91602 | v_loss: 0.57338 v_acc: 0.87695 |  iteration: 4868 teacher: 0 stage: sketch lr: 0.000633\n",
      "batch 1139 loss: 0.36947 acc: 0.89648 | v_loss: 0.53935 v_acc: 0.87467 |  iteration: 4869 teacher: 0 stage: sketch lr: 0.000633\n",
      "batch 1140 loss: 0.31523 acc: 0.90983 | v_loss: 0.52900 v_acc: 0.87695 |  iteration: 4870 teacher: 1 stage: sketch lr: 0.000633\n",
      "batch 1141 loss: 0.26800 acc: 0.92122 | v_loss: 0.47681 v_acc: 0.89648 |  iteration: 4871 teacher: 0 stage: sketch lr: 0.000633\n",
      "batch 1142 loss: 0.31432 acc: 0.91178 | v_loss: 0.47378 v_acc: 0.89225 |  iteration: 4872 teacher: 0 stage: sketch lr: 0.000633\n",
      "batch 1143 loss: 0.23362 acc: 0.93197 | v_loss: 0.54111 v_acc: 0.88802 |  iteration: 4873 teacher: 1 stage: sketch lr: 0.000633\n",
      "batch 1144 loss: 0.37850 acc: 0.89681 | v_loss: 0.64738 v_acc: 0.85254 |  iteration: 4874 teacher: 1 stage: sketch lr: 0.000633\n",
      "batch 1145 loss: 0.25964 acc: 0.92513 | v_loss: 0.60671 v_acc: 0.88249 |  iteration: 4875 teacher: 0 stage: sketch lr: 0.000633\n",
      "batch 1146 loss: 0.25228 acc: 0.92611 | v_loss: 0.60614 v_acc: 0.88477 |  iteration: 4876 teacher: 1 stage: sketch lr: 0.000633\n",
      "batch 1147 loss: 0.21979 acc: 0.93197 | v_loss: 0.39020 v_acc: 0.90462 |  iteration: 4877 teacher: 1 stage: sketch lr: 0.000633\n",
      "batch 1148 loss: 0.24177 acc: 0.93359 | v_loss: 0.54172 v_acc: 0.88086 |  iteration: 4878 teacher: 0 stage: sketch lr: 0.000633\n",
      "batch 1149 loss: 0.28901 acc: 0.91732 | v_loss: 0.53211 v_acc: 0.87500 |  iteration: 4879 teacher: 1 stage: sketch lr: 0.000633\n",
      "batch 1150 loss: 0.23279 acc: 0.93262 | v_loss: 0.88502 v_acc: 0.82812 |  iteration: 4880 teacher: 1 stage: sketch lr: 0.000633\n",
      "batch 1151 loss: 0.32581 acc: 0.90918 | v_loss: 0.39302 v_acc: 0.90267 |  iteration: 4881 teacher: 0 stage: sketch lr: 0.000633\n",
      "batch 1152 loss: 0.24664 acc: 0.92220 | v_loss: 0.30122 v_acc: 0.92904 |  iteration: 4882 teacher: 1 stage: sketch lr: 0.000633\n",
      "batch 1153 loss: 0.25951 acc: 0.92285 | v_loss: 0.57489 v_acc: 0.88770 |  iteration: 4883 teacher: 1 stage: sketch lr: 0.000632\n",
      "batch 1154 loss: 0.30188 acc: 0.91276 | v_loss: 0.57167 v_acc: 0.88411 |  iteration: 4884 teacher: 0 stage: sketch lr: 0.000632\n",
      "batch 1155 loss: 0.31089 acc: 0.91536 | v_loss: 0.68272 v_acc: 0.85938 |  iteration: 4885 teacher: 1 stage: sketch lr: 0.000632\n",
      "batch 1156 loss: 0.19299 acc: 0.94661 | v_loss: 0.41833 v_acc: 0.89681 |  iteration: 4886 teacher: 1 stage: sketch lr: 0.000632\n",
      "batch 1157 loss: 0.22348 acc: 0.93783 | v_loss: 0.50343 v_acc: 0.86751 |  iteration: 4887 teacher: 1 stage: sketch lr: 0.000632\n",
      "batch 1158 loss: 0.26307 acc: 0.92350 | v_loss: 0.59422 v_acc: 0.86230 |  iteration: 4888 teacher: 0 stage: sketch lr: 0.000632\n",
      "batch 1159 loss: 0.23607 acc: 0.92318 | v_loss: 0.65911 v_acc: 0.84017 |  iteration: 4889 teacher: 0 stage: sketch lr: 0.000632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1160 loss: 0.35854 acc: 0.89258 | v_loss: 0.48118 v_acc: 0.89421 |  iteration: 4890 teacher: 0 stage: sketch lr: 0.000632\n",
      "batch 1161 loss: 0.25951 acc: 0.92643 | v_loss: 0.37228 v_acc: 0.91374 |  iteration: 4891 teacher: 0 stage: sketch lr: 0.000632\n",
      "batch 1162 loss: 0.23950 acc: 0.92383 | v_loss: 0.31869 v_acc: 0.92155 |  iteration: 4892 teacher: 0 stage: sketch lr: 0.000632\n",
      "batch 1163 loss: 0.24159 acc: 0.92546 | v_loss: 0.50734 v_acc: 0.90625 |  iteration: 4893 teacher: 0 stage: sketch lr: 0.000632\n",
      "batch 1164 loss: 0.25033 acc: 0.93229 | v_loss: 0.54474 v_acc: 0.88802 |  iteration: 4894 teacher: 0 stage: sketch lr: 0.000632\n",
      "batch 1165 loss: 0.24312 acc: 0.93132 | v_loss: 0.84754 v_acc: 0.86165 |  iteration: 4895 teacher: 1 stage: sketch lr: 0.000632\n",
      "batch 1166 loss: 0.30642 acc: 0.91406 | v_loss: 0.54332 v_acc: 0.88379 |  iteration: 4896 teacher: 1 stage: sketch lr: 0.000632\n",
      "batch 1167 loss: 0.26435 acc: 0.92480 | v_loss: 0.66864 v_acc: 0.86589 |  iteration: 4897 teacher: 1 stage: sketch lr: 0.000632\n",
      "batch 1168 loss: 0.22156 acc: 0.92936 | v_loss: 0.44393 v_acc: 0.89551 |  iteration: 4898 teacher: 1 stage: sketch lr: 0.000631\n",
      "batch 1169 loss: 0.29442 acc: 0.91243 | v_loss: 0.52094 v_acc: 0.88509 |  iteration: 4899 teacher: 0 stage: sketch lr: 0.000631\n",
      "batch 1170 loss: 0.27244 acc: 0.92415 | v_loss: 0.75987 v_acc: 0.84635 |  iteration: 4900 teacher: 0 stage: sketch lr: 0.000631\n",
      "batch 1171 loss: 0.25931 acc: 0.91829 | v_loss: 0.49305 v_acc: 0.88932 |  iteration: 4901 teacher: 0 stage: sketch lr: 0.000631\n",
      "batch 1172 loss: 0.28292 acc: 0.91992 | v_loss: 0.50432 v_acc: 0.88737 |  iteration: 4902 teacher: 0 stage: sketch lr: 0.000631\n",
      "batch 1173 loss: 0.26101 acc: 0.93132 | v_loss: 0.45336 v_acc: 0.89421 |  iteration: 4903 teacher: 1 stage: sketch lr: 0.000631\n",
      "batch 1174 loss: 0.24588 acc: 0.92871 | v_loss: 0.44131 v_acc: 0.89909 |  iteration: 4904 teacher: 1 stage: sketch lr: 0.000631\n",
      "batch 1175 loss: 0.25629 acc: 0.91667 | v_loss: 0.45234 v_acc: 0.90853 |  iteration: 4905 teacher: 0 stage: sketch lr: 0.000631\n",
      "batch 1176 loss: 0.23276 acc: 0.92904 | v_loss: 0.56154 v_acc: 0.87598 |  iteration: 4906 teacher: 0 stage: sketch lr: 0.000631\n",
      "batch 1177 loss: 0.24123 acc: 0.92448 | v_loss: 0.36678 v_acc: 0.91862 |  iteration: 4907 teacher: 0 stage: sketch lr: 0.000631\n",
      "batch 1178 loss: 0.34313 acc: 0.91406 | v_loss: 0.93552 v_acc: 0.82780 |  iteration: 4908 teacher: 1 stage: sketch lr: 0.000631\n",
      "batch 1179 loss: 0.27529 acc: 0.92253 | v_loss: 0.63735 v_acc: 0.87207 |  iteration: 4909 teacher: 0 stage: sketch lr: 0.000631\n",
      "batch 1180 loss: 0.23454 acc: 0.93522 | v_loss: 0.68257 v_acc: 0.86068 |  iteration: 4910 teacher: 1 stage: sketch lr: 0.000631\n",
      "batch 1181 loss: 0.23130 acc: 0.92871 | v_loss: 0.51370 v_acc: 0.89160 |  iteration: 4911 teacher: 1 stage: sketch lr: 0.000631\n",
      "batch 1182 loss: 0.33989 acc: 0.90202 | v_loss: 0.54364 v_acc: 0.88118 |  iteration: 4912 teacher: 1 stage: sketch lr: 0.000631\n",
      "batch 1183 loss: 0.37105 acc: 0.89811 | v_loss: 0.57698 v_acc: 0.88249 |  iteration: 4913 teacher: 0 stage: sketch lr: 0.000631\n",
      "batch 1184 loss: 0.22624 acc: 0.93424 | v_loss: 0.50153 v_acc: 0.89095 |  iteration: 4914 teacher: 1 stage: sketch lr: 0.000630\n",
      "batch 1185 loss: 0.26171 acc: 0.92155 | v_loss: 0.53133 v_acc: 0.88704 |  iteration: 4915 teacher: 1 stage: sketch lr: 0.000630\n",
      "batch 1186 loss: 0.25272 acc: 0.92806 | v_loss: 0.51621 v_acc: 0.89486 |  iteration: 4916 teacher: 1 stage: sketch lr: 0.000630\n",
      "batch 1187 loss: 0.26532 acc: 0.92513 | v_loss: 0.47891 v_acc: 0.89290 |  iteration: 4917 teacher: 1 stage: sketch lr: 0.000630\n",
      "batch 1188 loss: 0.26921 acc: 0.92676 | v_loss: 0.37051 v_acc: 0.91699 |  iteration: 4918 teacher: 1 stage: sketch lr: 0.000630\n",
      "batch 1189 loss: 0.28884 acc: 0.92025 | v_loss: 0.64538 v_acc: 0.86751 |  iteration: 4919 teacher: 1 stage: sketch lr: 0.000630\n",
      "batch 1190 loss: 0.26567 acc: 0.92904 | v_loss: 0.55791 v_acc: 0.86914 |  iteration: 4920 teacher: 1 stage: sketch lr: 0.000630\n",
      "batch 1191 loss: 0.23889 acc: 0.93327 | v_loss: 0.61607 v_acc: 0.86426 |  iteration: 4921 teacher: 1 stage: sketch lr: 0.000630\n",
      "batch 1192 loss: 0.24846 acc: 0.92578 | v_loss: 0.80218 v_acc: 0.85645 |  iteration: 4922 teacher: 0 stage: sketch lr: 0.000630\n",
      "batch 1193 loss: 0.27386 acc: 0.91797 | v_loss: 0.40271 v_acc: 0.91406 |  iteration: 4923 teacher: 0 stage: sketch lr: 0.000630\n",
      "batch 1194 loss: 0.18582 acc: 0.94336 | v_loss: 0.59091 v_acc: 0.87240 |  iteration: 4924 teacher: 0 stage: sketch lr: 0.000630\n",
      "batch 1195 loss: 0.25226 acc: 0.92480 | v_loss: 0.51598 v_acc: 0.88639 |  iteration: 4925 teacher: 0 stage: sketch lr: 0.000630\n",
      "batch 1196 loss: 0.28998 acc: 0.92220 | v_loss: 0.39979 v_acc: 0.90658 |  iteration: 4926 teacher: 1 stage: sketch lr: 0.000630\n",
      "batch 1197 loss: 0.24827 acc: 0.93652 | v_loss: 1.20292 v_acc: 0.80111 |  iteration: 4927 teacher: 1 stage: sketch lr: 0.000630\n",
      "batch 1198 loss: 0.26954 acc: 0.92448 | v_loss: 0.38102 v_acc: 0.91471 |  iteration: 4928 teacher: 0 stage: sketch lr: 0.000630\n",
      "batch 1199 loss: 0.24105 acc: 0.93457 | v_loss: 0.56293 v_acc: 0.88281 |  iteration: 4929 teacher: 1 stage: sketch lr: 0.000629\n",
      "batch 1200 loss: 0.26410 acc: 0.92025 | v_loss: 0.46704 v_acc: 0.89453 |  iteration: 4930 teacher: 0 stage: sketch lr: 0.000629\n",
      "batch 1201 loss: 0.37612 acc: 0.89225 | v_loss: 0.38192 v_acc: 0.90560 |  iteration: 4931 teacher: 1 stage: sketch lr: 0.000629\n",
      "batch 1202 loss: 0.25745 acc: 0.92546 | v_loss: 0.48079 v_acc: 0.88900 |  iteration: 4932 teacher: 1 stage: sketch lr: 0.000629\n",
      "batch 1203 loss: 0.27866 acc: 0.91895 | v_loss: 0.57355 v_acc: 0.86914 |  iteration: 4933 teacher: 0 stage: sketch lr: 0.000629\n",
      "batch 1204 loss: 0.32433 acc: 0.90039 | v_loss: 0.39122 v_acc: 0.90853 |  iteration: 4934 teacher: 0 stage: sketch lr: 0.000629\n",
      "batch 1205 loss: 0.30787 acc: 0.91243 | v_loss: 0.60959 v_acc: 0.86719 |  iteration: 4935 teacher: 0 stage: sketch lr: 0.000629\n",
      "batch 1206 loss: 0.38708 acc: 0.88932 | v_loss: 0.39600 v_acc: 0.90202 |  iteration: 4936 teacher: 0 stage: sketch lr: 0.000629\n",
      "batch 1207 loss: 0.37428 acc: 0.89811 | v_loss: 1.04366 v_acc: 0.82585 |  iteration: 4937 teacher: 1 stage: sketch lr: 0.000629\n",
      "batch 1208 loss: 0.28497 acc: 0.91699 | v_loss: 0.59818 v_acc: 0.88607 |  iteration: 4938 teacher: 0 stage: sketch lr: 0.000629\n",
      "batch 1209 loss: 0.26781 acc: 0.93001 | v_loss: 0.68135 v_acc: 0.86296 |  iteration: 4939 teacher: 1 stage: sketch lr: 0.000629\n",
      "batch 1210 loss: 0.23352 acc: 0.93880 | v_loss: 0.43514 v_acc: 0.90169 |  iteration: 4940 teacher: 0 stage: sketch lr: 0.000629\n",
      "batch 1211 loss: 0.29110 acc: 0.91862 | v_loss: 0.65607 v_acc: 0.86393 |  iteration: 4941 teacher: 1 stage: sketch lr: 0.000629\n",
      "batch 1212 loss: 0.24719 acc: 0.91829 | v_loss: 0.42578 v_acc: 0.89876 |  iteration: 4942 teacher: 0 stage: sketch lr: 0.000629\n",
      "batch 1213 loss: 0.30854 acc: 0.91797 | v_loss: 0.46572 v_acc: 0.88672 |  iteration: 4943 teacher: 0 stage: sketch lr: 0.000629\n",
      "batch 1214 loss: 0.33613 acc: 0.90885 | v_loss: 0.45781 v_acc: 0.88997 |  iteration: 4944 teacher: 1 stage: sketch lr: 0.000629\n",
      "batch 1215 loss: 0.26839 acc: 0.92025 | v_loss: 0.73926 v_acc: 0.84668 |  iteration: 4945 teacher: 0 stage: sketch lr: 0.000628\n",
      "batch 1216 loss: 0.30384 acc: 0.91732 | v_loss: 0.53356 v_acc: 0.89030 |  iteration: 4946 teacher: 1 stage: sketch lr: 0.000628\n",
      "batch 1217 loss: 0.30401 acc: 0.91243 | v_loss: 0.50991 v_acc: 0.88704 |  iteration: 4947 teacher: 0 stage: sketch lr: 0.000628\n",
      "batch 1218 loss: 0.30768 acc: 0.91276 | v_loss: 0.67701 v_acc: 0.85384 |  iteration: 4948 teacher: 0 stage: sketch lr: 0.000628\n",
      "batch 1219 loss: 0.23153 acc: 0.93457 | v_loss: 0.44861 v_acc: 0.89616 |  iteration: 4949 teacher: 1 stage: sketch lr: 0.000628\n",
      "batch 1220 loss: 0.39533 acc: 0.89941 | v_loss: 0.54532 v_acc: 0.87012 |  iteration: 4950 teacher: 1 stage: sketch lr: 0.000628\n",
      "batch 1221 loss: 0.37224 acc: 0.90234 | v_loss: 0.54126 v_acc: 0.86979 |  iteration: 4951 teacher: 0 stage: sketch lr: 0.000628\n",
      "batch 1222 loss: 0.35272 acc: 0.90820 | v_loss: 0.76475 v_acc: 0.85059 |  iteration: 4952 teacher: 1 stage: sketch lr: 0.000628\n",
      "batch 1223 loss: 0.26884 acc: 0.91829 | v_loss: 0.52915 v_acc: 0.89355 |  iteration: 4953 teacher: 1 stage: sketch lr: 0.000628\n",
      "batch 1224 loss: 0.23030 acc: 0.93066 | v_loss: 0.55771 v_acc: 0.87923 |  iteration: 4954 teacher: 0 stage: sketch lr: 0.000628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1225 loss: 0.24214 acc: 0.92448 | v_loss: 0.62933 v_acc: 0.88086 |  iteration: 4955 teacher: 0 stage: sketch lr: 0.000628\n",
      "batch 1226 loss: 0.20120 acc: 0.94206 | v_loss: 0.56898 v_acc: 0.86426 |  iteration: 4956 teacher: 1 stage: sketch lr: 0.000628\n",
      "batch 1227 loss: 0.24898 acc: 0.92708 | v_loss: 0.42519 v_acc: 0.90592 |  iteration: 4957 teacher: 0 stage: sketch lr: 0.000628\n",
      "batch 1228 loss: 0.23826 acc: 0.92480 | v_loss: 0.78206 v_acc: 0.84896 |  iteration: 4958 teacher: 0 stage: sketch lr: 0.000628\n",
      "batch 1229 loss: 0.26447 acc: 0.92285 | v_loss: 0.56080 v_acc: 0.89160 |  iteration: 4959 teacher: 1 stage: sketch lr: 0.000628\n",
      "batch 1230 loss: 0.25910 acc: 0.92090 | v_loss: 0.59308 v_acc: 0.87500 |  iteration: 4960 teacher: 1 stage: sketch lr: 0.000628\n",
      "batch 1231 loss: 0.24352 acc: 0.93099 | v_loss: 0.52395 v_acc: 0.88509 |  iteration: 4961 teacher: 0 stage: sketch lr: 0.000627\n",
      "batch 1232 loss: 0.24308 acc: 0.92643 | v_loss: 0.42604 v_acc: 0.89844 |  iteration: 4962 teacher: 1 stage: sketch lr: 0.000627\n",
      "batch 1233 loss: 0.22119 acc: 0.93262 | v_loss: 0.46929 v_acc: 0.89779 |  iteration: 4963 teacher: 1 stage: sketch lr: 0.000627\n",
      "batch 1234 loss: 0.31219 acc: 0.91634 | v_loss: 0.56087 v_acc: 0.88639 |  iteration: 4964 teacher: 1 stage: sketch lr: 0.000627\n",
      "batch 1235 loss: 0.29489 acc: 0.91699 | v_loss: 0.60589 v_acc: 0.85579 |  iteration: 4965 teacher: 0 stage: sketch lr: 0.000627\n",
      "batch 1236 loss: 0.30031 acc: 0.91113 | v_loss: 0.54881 v_acc: 0.88997 |  iteration: 4966 teacher: 0 stage: sketch lr: 0.000627\n",
      "batch 1237 loss: 0.26873 acc: 0.92253 | v_loss: 0.55531 v_acc: 0.87826 |  iteration: 4967 teacher: 0 stage: sketch lr: 0.000627\n",
      "batch 1238 loss: 0.23445 acc: 0.92904 | v_loss: 0.37258 v_acc: 0.90885 |  iteration: 4968 teacher: 1 stage: sketch lr: 0.000627\n",
      "batch 1239 loss: 0.25619 acc: 0.93359 | v_loss: 0.51139 v_acc: 0.88574 |  iteration: 4969 teacher: 1 stage: sketch lr: 0.000627\n",
      "batch 1240 loss: 0.27987 acc: 0.91439 | v_loss: 0.48626 v_acc: 0.88086 |  iteration: 4970 teacher: 0 stage: sketch lr: 0.000627\n",
      "batch 1241 loss: 0.31056 acc: 0.91309 | v_loss: 0.86588 v_acc: 0.83301 |  iteration: 4971 teacher: 0 stage: sketch lr: 0.000627\n",
      "batch 1242 loss: 0.23738 acc: 0.93815 | v_loss: 0.36608 v_acc: 0.91439 |  iteration: 4972 teacher: 1 stage: sketch lr: 0.000627\n",
      "epoch 3 loss: 0.29106 acc: 0.91670 | v_loss: 0.56088 v_acc: 0.88029 \n",
      "epoch: 4\n",
      "__________________________________________\n",
      "batch 0 loss: 0.15461 acc: 0.95150 | v_loss: 0.55815 v_acc: 0.88151 |  iteration: 4973 teacher: 1 stage: sketch lr: 0.000627\n",
      "batch 1 loss: 0.26739 acc: 0.92350 | v_loss: 0.51289 v_acc: 0.89290 |  iteration: 4974 teacher: 0 stage: sketch lr: 0.000627\n",
      "batch 2 loss: 0.30527 acc: 0.91536 | v_loss: 0.50232 v_acc: 0.89062 |  iteration: 4975 teacher: 0 stage: sketch lr: 0.000627\n",
      "batch 3 loss: 0.26183 acc: 0.91927 | v_loss: 0.50492 v_acc: 0.90658 |  iteration: 4976 teacher: 1 stage: sketch lr: 0.000627\n",
      "batch 4 loss: 0.21619 acc: 0.93522 | v_loss: 0.45750 v_acc: 0.89518 |  iteration: 4977 teacher: 0 stage: sketch lr: 0.000626\n",
      "batch 5 loss: 0.24311 acc: 0.92350 | v_loss: 0.37250 v_acc: 0.91146 |  iteration: 4978 teacher: 0 stage: sketch lr: 0.000626\n",
      "batch 6 loss: 0.29320 acc: 0.91829 | v_loss: 0.61546 v_acc: 0.86751 |  iteration: 4979 teacher: 0 stage: sketch lr: 0.000626\n",
      "batch 7 loss: 0.25810 acc: 0.92741 | v_loss: 0.59127 v_acc: 0.86719 |  iteration: 4980 teacher: 0 stage: sketch lr: 0.000626\n",
      "batch 8 loss: 0.19817 acc: 0.93945 | v_loss: 0.66409 v_acc: 0.85807 |  iteration: 4981 teacher: 1 stage: sketch lr: 0.000626\n",
      "batch 9 loss: 0.28840 acc: 0.92188 | v_loss: 0.81028 v_acc: 0.84863 |  iteration: 4982 teacher: 0 stage: sketch lr: 0.000626\n",
      "batch 10 loss: 0.36068 acc: 0.90267 | v_loss: 0.40955 v_acc: 0.91439 |  iteration: 4983 teacher: 1 stage: sketch lr: 0.000626\n",
      "batch 11 loss: 0.31689 acc: 0.91439 | v_loss: 0.56492 v_acc: 0.87337 |  iteration: 4984 teacher: 1 stage: sketch lr: 0.000626\n",
      "batch 12 loss: 0.29997 acc: 0.91536 | v_loss: 0.51500 v_acc: 0.89128 |  iteration: 4985 teacher: 0 stage: sketch lr: 0.000626\n",
      "batch 13 loss: 0.24197 acc: 0.93034 | v_loss: 0.38473 v_acc: 0.91048 |  iteration: 4986 teacher: 1 stage: sketch lr: 0.000626\n",
      "batch 14 loss: 0.26312 acc: 0.92806 | v_loss: 1.10672 v_acc: 0.80306 |  iteration: 4987 teacher: 1 stage: sketch lr: 0.000626\n",
      "batch 15 loss: 0.27427 acc: 0.91732 | v_loss: 0.38250 v_acc: 0.91113 |  iteration: 4988 teacher: 0 stage: sketch lr: 0.000626\n",
      "batch 16 loss: 0.26953 acc: 0.91309 | v_loss: 0.58203 v_acc: 0.87012 |  iteration: 4989 teacher: 0 stage: sketch lr: 0.000626\n",
      "batch 17 loss: 0.28926 acc: 0.91536 | v_loss: 0.50170 v_acc: 0.89551 |  iteration: 4990 teacher: 0 stage: sketch lr: 0.000626\n",
      "batch 18 loss: 0.31854 acc: 0.90495 | v_loss: 0.41350 v_acc: 0.89974 |  iteration: 4991 teacher: 0 stage: sketch lr: 0.000626\n",
      "batch 19 loss: 0.34083 acc: 0.91504 | v_loss: 0.49219 v_acc: 0.89648 |  iteration: 4992 teacher: 1 stage: sketch lr: 0.000626\n",
      "batch 20 loss: 0.33898 acc: 0.90397 | v_loss: 0.62593 v_acc: 0.87598 |  iteration: 4993 teacher: 1 stage: sketch lr: 0.000625\n",
      "batch 21 loss: 0.24611 acc: 0.93164 | v_loss: 0.46339 v_acc: 0.90299 |  iteration: 4994 teacher: 1 stage: sketch lr: 0.000625\n",
      "batch 22 loss: 0.37021 acc: 0.89779 | v_loss: 0.62646 v_acc: 0.87044 |  iteration: 4995 teacher: 1 stage: sketch lr: 0.000625\n",
      "batch 23 loss: 0.31488 acc: 0.91276 | v_loss: 0.38648 v_acc: 0.90625 |  iteration: 4996 teacher: 0 stage: sketch lr: 0.000625\n",
      "batch 24 loss: 0.24731 acc: 0.92513 | v_loss: 1.05176 v_acc: 0.81803 |  iteration: 4997 teacher: 0 stage: sketch lr: 0.000625\n",
      "batch 25 loss: 0.38305 acc: 0.89876 | v_loss: 0.60941 v_acc: 0.88835 |  iteration: 4998 teacher: 1 stage: sketch lr: 0.000625\n",
      "batch 26 loss: 0.32377 acc: 0.90430 | v_loss: 0.68360 v_acc: 0.86589 |  iteration: 4999 teacher: 0 stage: sketch lr: 0.000625\n",
      "batch 27 loss: 0.28095 acc: 0.91927 | v_loss: 0.42800 v_acc: 0.90365 |  iteration: 5000 teacher: 0 stage: sketch lr: 0.000625\n",
      "batch 28 loss: 0.24558 acc: 0.92350 | v_loss: 0.65969 v_acc: 0.85775 |  iteration: 5001 teacher: 1 stage: sketch lr: 0.000625\n",
      "batch 29 loss: 0.30394 acc: 0.90820 | v_loss: 0.48487 v_acc: 0.88802 |  iteration: 5002 teacher: 0 stage: sketch lr: 0.000625\n",
      "batch 30 loss: 0.41688 acc: 0.88444 | v_loss: 0.49637 v_acc: 0.88704 |  iteration: 5003 teacher: 1 stage: sketch lr: 0.000625\n",
      "batch 31 loss: 0.28761 acc: 0.91374 | v_loss: 0.46436 v_acc: 0.89128 |  iteration: 5004 teacher: 0 stage: sketch lr: 0.000625\n",
      "batch 32 loss: 0.28498 acc: 0.91732 | v_loss: 0.74739 v_acc: 0.83952 |  iteration: 5005 teacher: 0 stage: sketch lr: 0.000625\n",
      "batch 33 loss: 0.30932 acc: 0.90560 | v_loss: 0.50814 v_acc: 0.89453 |  iteration: 5006 teacher: 1 stage: sketch lr: 0.000625\n",
      "batch 34 loss: 0.26190 acc: 0.93262 | v_loss: 0.54983 v_acc: 0.86458 |  iteration: 5007 teacher: 1 stage: sketch lr: 0.000625\n",
      "batch 35 loss: 0.31703 acc: 0.91048 | v_loss: 0.66451 v_acc: 0.84993 |  iteration: 5008 teacher: 1 stage: sketch lr: 0.000625\n",
      "batch 36 loss: 0.27311 acc: 0.92188 | v_loss: 0.46619 v_acc: 0.88411 |  iteration: 5009 teacher: 1 stage: sketch lr: 0.000624\n",
      "batch 37 loss: 0.31837 acc: 0.89909 | v_loss: 0.51199 v_acc: 0.86784 |  iteration: 5010 teacher: 0 stage: sketch lr: 0.000624\n",
      "batch 38 loss: 0.31725 acc: 0.90625 | v_loss: 0.54036 v_acc: 0.87012 |  iteration: 5011 teacher: 0 stage: sketch lr: 0.000624\n",
      "batch 39 loss: 0.33207 acc: 0.90332 | v_loss: 0.71382 v_acc: 0.85384 |  iteration: 5012 teacher: 0 stage: sketch lr: 0.000624\n",
      "batch 40 loss: 0.37080 acc: 0.89714 | v_loss: 0.51005 v_acc: 0.88574 |  iteration: 5013 teacher: 1 stage: sketch lr: 0.000624\n",
      "batch 41 loss: 0.25945 acc: 0.92350 | v_loss: 0.54112 v_acc: 0.88607 |  iteration: 5014 teacher: 0 stage: sketch lr: 0.000624\n",
      "batch 42 loss: 0.25115 acc: 0.92350 | v_loss: 0.64913 v_acc: 0.87988 |  iteration: 5015 teacher: 0 stage: sketch lr: 0.000624\n",
      "batch 43 loss: 0.28282 acc: 0.91699 | v_loss: 0.66746 v_acc: 0.84701 |  iteration: 5016 teacher: 0 stage: sketch lr: 0.000624\n",
      "batch 44 loss: 0.30698 acc: 0.90755 | v_loss: 0.43571 v_acc: 0.90723 |  iteration: 5017 teacher: 0 stage: sketch lr: 0.000624\n",
      "batch 45 loss: 0.34875 acc: 0.90104 | v_loss: 0.80694 v_acc: 0.84570 |  iteration: 5018 teacher: 1 stage: sketch lr: 0.000624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 46 loss: 0.22728 acc: 0.92741 | v_loss: 0.59685 v_acc: 0.88249 |  iteration: 5019 teacher: 0 stage: sketch lr: 0.000624\n",
      "batch 47 loss: 0.21854 acc: 0.93945 | v_loss: 0.51678 v_acc: 0.88574 |  iteration: 5020 teacher: 0 stage: sketch lr: 0.000624\n",
      "batch 48 loss: 0.29833 acc: 0.91764 | v_loss: 0.52070 v_acc: 0.88184 |  iteration: 5021 teacher: 0 stage: sketch lr: 0.000624\n",
      "batch 49 loss: 0.25332 acc: 0.93262 | v_loss: 0.46383 v_acc: 0.89290 |  iteration: 5022 teacher: 1 stage: sketch lr: 0.000624\n",
      "batch 50 loss: 0.24833 acc: 0.92936 | v_loss: 0.46022 v_acc: 0.89779 |  iteration: 5023 teacher: 1 stage: sketch lr: 0.000624\n",
      "batch 51 loss: 0.25437 acc: 0.92285 | v_loss: 0.51749 v_acc: 0.89095 |  iteration: 5024 teacher: 0 stage: sketch lr: 0.000624\n",
      "batch 52 loss: 0.23053 acc: 0.92904 | v_loss: 0.62956 v_acc: 0.85677 |  iteration: 5025 teacher: 1 stage: sketch lr: 0.000623\n",
      "batch 53 loss: 0.22000 acc: 0.93164 | v_loss: 0.55391 v_acc: 0.89160 |  iteration: 5026 teacher: 1 stage: sketch lr: 0.000623\n",
      "batch 54 loss: 0.23686 acc: 0.92708 | v_loss: 0.56389 v_acc: 0.88835 |  iteration: 5027 teacher: 1 stage: sketch lr: 0.000623\n",
      "batch 55 loss: 0.31833 acc: 0.91439 | v_loss: 0.36364 v_acc: 0.91504 |  iteration: 5028 teacher: 0 stage: sketch lr: 0.000623\n",
      "batch 56 loss: 0.30129 acc: 0.91797 | v_loss: 0.54371 v_acc: 0.88151 |  iteration: 5029 teacher: 0 stage: sketch lr: 0.000623\n",
      "batch 57 loss: 0.28065 acc: 0.92318 | v_loss: 0.47020 v_acc: 0.88281 |  iteration: 5030 teacher: 1 stage: sketch lr: 0.000623\n",
      "batch 58 loss: 0.27083 acc: 0.91764 | v_loss: 0.79323 v_acc: 0.83919 |  iteration: 5031 teacher: 0 stage: sketch lr: 0.000623\n",
      "batch 59 loss: 0.26831 acc: 0.92415 | v_loss: 0.35248 v_acc: 0.91374 |  iteration: 5032 teacher: 1 stage: sketch lr: 0.000623\n",
      "batch 60 loss: 0.30382 acc: 0.90723 | v_loss: 0.31811 v_acc: 0.92122 |  iteration: 5033 teacher: 0 stage: sketch lr: 0.000623\n",
      "batch 61 loss: 0.22811 acc: 0.92969 | v_loss: 0.55531 v_acc: 0.87663 |  iteration: 5034 teacher: 0 stage: sketch lr: 0.000623\n",
      "batch 62 loss: 0.27780 acc: 0.90853 | v_loss: 0.52511 v_acc: 0.88411 |  iteration: 5035 teacher: 0 stage: sketch lr: 0.000623\n",
      "batch 63 loss: 0.22116 acc: 0.93359 | v_loss: 0.64597 v_acc: 0.86165 |  iteration: 5036 teacher: 1 stage: sketch lr: 0.000623\n",
      "batch 64 loss: 0.25483 acc: 0.92611 | v_loss: 0.42832 v_acc: 0.90137 |  iteration: 5037 teacher: 1 stage: sketch lr: 0.000623\n",
      "batch 65 loss: 0.26573 acc: 0.91471 | v_loss: 0.51974 v_acc: 0.86914 |  iteration: 5038 teacher: 0 stage: sketch lr: 0.000623\n",
      "batch 66 loss: 0.36043 acc: 0.89453 | v_loss: 0.56038 v_acc: 0.86816 |  iteration: 5039 teacher: 0 stage: sketch lr: 0.000623\n",
      "batch 67 loss: 0.30193 acc: 0.91504 | v_loss: 0.64309 v_acc: 0.84961 |  iteration: 5040 teacher: 0 stage: sketch lr: 0.000623\n",
      "batch 68 loss: 0.30043 acc: 0.91569 | v_loss: 0.47661 v_acc: 0.89421 |  iteration: 5041 teacher: 0 stage: sketch lr: 0.000622\n",
      "batch 69 loss: 0.27287 acc: 0.91895 | v_loss: 0.39227 v_acc: 0.90397 |  iteration: 5042 teacher: 0 stage: sketch lr: 0.000622\n",
      "batch 70 loss: 0.26073 acc: 0.91829 | v_loss: 0.28779 v_acc: 0.92057 |  iteration: 5043 teacher: 1 stage: sketch lr: 0.000622\n",
      "batch 71 loss: 0.28933 acc: 0.91439 | v_loss: 0.43555 v_acc: 0.90332 |  iteration: 5044 teacher: 1 stage: sketch lr: 0.000622\n",
      "batch 72 loss: 0.24466 acc: 0.93164 | v_loss: 0.49244 v_acc: 0.88509 |  iteration: 5045 teacher: 1 stage: sketch lr: 0.000622\n",
      "batch 73 loss: 0.24514 acc: 0.92676 | v_loss: 0.85253 v_acc: 0.85286 |  iteration: 5046 teacher: 1 stage: sketch lr: 0.000622\n",
      "batch 74 loss: 0.24927 acc: 0.92936 | v_loss: 0.57773 v_acc: 0.87240 |  iteration: 5047 teacher: 0 stage: sketch lr: 0.000622\n",
      "batch 75 loss: 0.25991 acc: 0.92708 | v_loss: 0.67814 v_acc: 0.86751 |  iteration: 5048 teacher: 1 stage: sketch lr: 0.000622\n",
      "batch 76 loss: 0.29986 acc: 0.91862 | v_loss: 0.43999 v_acc: 0.90169 |  iteration: 5049 teacher: 0 stage: sketch lr: 0.000622\n",
      "batch 77 loss: 0.25603 acc: 0.92513 | v_loss: 0.56799 v_acc: 0.88411 |  iteration: 5050 teacher: 0 stage: sketch lr: 0.000622\n",
      "batch 78 loss: 0.23516 acc: 0.93262 | v_loss: 0.77872 v_acc: 0.84408 |  iteration: 5051 teacher: 1 stage: sketch lr: 0.000622\n",
      "batch 79 loss: 0.33857 acc: 0.90560 | v_loss: 0.50272 v_acc: 0.89193 |  iteration: 5052 teacher: 0 stage: sketch lr: 0.000622\n",
      "batch 80 loss: 0.25614 acc: 0.92188 | v_loss: 0.50947 v_acc: 0.88932 |  iteration: 5053 teacher: 0 stage: sketch lr: 0.000622\n",
      "batch 81 loss: 0.28733 acc: 0.91667 | v_loss: 0.49052 v_acc: 0.88477 |  iteration: 5054 teacher: 0 stage: sketch lr: 0.000622\n",
      "batch 82 loss: 0.30245 acc: 0.91406 | v_loss: 0.47286 v_acc: 0.89974 |  iteration: 5055 teacher: 1 stage: sketch lr: 0.000622\n",
      "batch 83 loss: 0.25388 acc: 0.92090 | v_loss: 0.46062 v_acc: 0.90560 |  iteration: 5056 teacher: 0 stage: sketch lr: 0.000622\n",
      "batch 84 loss: 0.26652 acc: 0.92090 | v_loss: 0.59015 v_acc: 0.86882 |  iteration: 5057 teacher: 1 stage: sketch lr: 0.000621\n",
      "batch 85 loss: 0.22196 acc: 0.93587 | v_loss: 0.36737 v_acc: 0.91829 |  iteration: 5058 teacher: 0 stage: sketch lr: 0.000621\n",
      "batch 86 loss: 0.26301 acc: 0.92155 | v_loss: 0.94044 v_acc: 0.81738 |  iteration: 5059 teacher: 1 stage: sketch lr: 0.000621\n",
      "batch 87 loss: 0.28417 acc: 0.91374 | v_loss: 0.64825 v_acc: 0.87044 |  iteration: 5060 teacher: 0 stage: sketch lr: 0.000621\n",
      "batch 88 loss: 0.28401 acc: 0.91081 | v_loss: 0.65047 v_acc: 0.86654 |  iteration: 5061 teacher: 0 stage: sketch lr: 0.000621\n",
      "batch 89 loss: 0.23049 acc: 0.92741 | v_loss: 0.54921 v_acc: 0.89811 |  iteration: 5062 teacher: 0 stage: sketch lr: 0.000621\n",
      "batch 90 loss: 0.23768 acc: 0.92871 | v_loss: 0.49295 v_acc: 0.90234 |  iteration: 5063 teacher: 1 stage: sketch lr: 0.000621\n",
      "batch 91 loss: 0.19953 acc: 0.94141 | v_loss: 0.62704 v_acc: 0.88477 |  iteration: 5064 teacher: 0 stage: sketch lr: 0.000621\n",
      "batch 92 loss: 0.33305 acc: 0.90853 | v_loss: 0.54316 v_acc: 0.89095 |  iteration: 5065 teacher: 0 stage: sketch lr: 0.000621\n",
      "batch 93 loss: 0.24640 acc: 0.92448 | v_loss: 0.50013 v_acc: 0.89290 |  iteration: 5066 teacher: 0 stage: sketch lr: 0.000621\n",
      "batch 94 loss: 0.26870 acc: 0.92415 | v_loss: 0.54525 v_acc: 0.88802 |  iteration: 5067 teacher: 1 stage: sketch lr: 0.000621\n",
      "batch 95 loss: 0.38322 acc: 0.89518 | v_loss: 0.45157 v_acc: 0.89518 |  iteration: 5068 teacher: 1 stage: sketch lr: 0.000621\n",
      "batch 96 loss: 0.32839 acc: 0.90430 | v_loss: 0.34930 v_acc: 0.91276 |  iteration: 5069 teacher: 0 stage: sketch lr: 0.000621\n",
      "batch 97 loss: 0.25883 acc: 0.92220 | v_loss: 0.62139 v_acc: 0.85514 |  iteration: 5070 teacher: 0 stage: sketch lr: 0.000621\n",
      "batch 98 loss: 0.31422 acc: 0.90983 | v_loss: 0.55250 v_acc: 0.86816 |  iteration: 5071 teacher: 1 stage: sketch lr: 0.000621\n",
      "batch 99 loss: 0.26473 acc: 0.92188 | v_loss: 0.62237 v_acc: 0.85938 |  iteration: 5072 teacher: 0 stage: sketch lr: 0.000621\n",
      "batch 100 loss: 0.23721 acc: 0.93132 | v_loss: 0.80909 v_acc: 0.84733 |  iteration: 5073 teacher: 1 stage: sketch lr: 0.000620\n",
      "batch 101 loss: 0.30251 acc: 0.91341 | v_loss: 0.41060 v_acc: 0.90788 |  iteration: 5074 teacher: 1 stage: sketch lr: 0.000620\n",
      "batch 102 loss: 0.29517 acc: 0.91797 | v_loss: 0.58176 v_acc: 0.87402 |  iteration: 5075 teacher: 0 stage: sketch lr: 0.000620\n",
      "batch 103 loss: 0.29775 acc: 0.91406 | v_loss: 0.53867 v_acc: 0.88672 |  iteration: 5076 teacher: 0 stage: sketch lr: 0.000620\n",
      "batch 104 loss: 0.23980 acc: 0.93262 | v_loss: 0.42470 v_acc: 0.90299 |  iteration: 5077 teacher: 0 stage: sketch lr: 0.000620\n",
      "batch 105 loss: 0.26208 acc: 0.92383 | v_loss: 1.18117 v_acc: 0.81868 |  iteration: 5078 teacher: 0 stage: sketch lr: 0.000620\n",
      "batch 106 loss: 0.28821 acc: 0.91374 | v_loss: 0.40831 v_acc: 0.91602 |  iteration: 5079 teacher: 0 stage: sketch lr: 0.000620\n",
      "batch 107 loss: 0.29899 acc: 0.91634 | v_loss: 0.62932 v_acc: 0.87240 |  iteration: 5080 teacher: 0 stage: sketch lr: 0.000620\n",
      "batch 108 loss: 0.30015 acc: 0.92025 | v_loss: 0.56131 v_acc: 0.89290 |  iteration: 5081 teacher: 0 stage: sketch lr: 0.000620\n",
      "batch 109 loss: 0.33516 acc: 0.90299 | v_loss: 0.41368 v_acc: 0.91439 |  iteration: 5082 teacher: 1 stage: sketch lr: 0.000620\n",
      "batch 110 loss: 0.20998 acc: 0.94010 | v_loss: 0.53792 v_acc: 0.88672 |  iteration: 5083 teacher: 1 stage: sketch lr: 0.000620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 111 loss: 0.22727 acc: 0.92871 | v_loss: 0.59739 v_acc: 0.87663 |  iteration: 5084 teacher: 1 stage: sketch lr: 0.000620\n",
      "batch 112 loss: 0.25917 acc: 0.92188 | v_loss: 0.43255 v_acc: 0.90169 |  iteration: 5085 teacher: 1 stage: sketch lr: 0.000620\n",
      "batch 113 loss: 0.34714 acc: 0.90169 | v_loss: 0.62873 v_acc: 0.86849 |  iteration: 5086 teacher: 0 stage: sketch lr: 0.000620\n",
      "batch 114 loss: 0.28015 acc: 0.91471 | v_loss: 0.38168 v_acc: 0.90430 |  iteration: 5087 teacher: 1 stage: sketch lr: 0.000620\n",
      "batch 115 loss: 0.32431 acc: 0.90690 | v_loss: 0.98889 v_acc: 0.80924 |  iteration: 5088 teacher: 0 stage: sketch lr: 0.000620\n",
      "batch 116 loss: 0.30599 acc: 0.91113 | v_loss: 0.59513 v_acc: 0.87858 |  iteration: 5089 teacher: 0 stage: sketch lr: 0.000620\n",
      "batch 117 loss: 0.26344 acc: 0.93164 | v_loss: 0.71875 v_acc: 0.85938 |  iteration: 5090 teacher: 1 stage: sketch lr: 0.000619\n",
      "batch 118 loss: 0.29545 acc: 0.91081 | v_loss: 0.44497 v_acc: 0.89844 |  iteration: 5091 teacher: 1 stage: sketch lr: 0.000619\n",
      "batch 119 loss: 0.33671 acc: 0.90365 | v_loss: 0.63605 v_acc: 0.86621 |  iteration: 5092 teacher: 1 stage: sketch lr: 0.000619\n",
      "batch 120 loss: 0.30458 acc: 0.91536 | v_loss: 0.44699 v_acc: 0.89453 |  iteration: 5093 teacher: 1 stage: sketch lr: 0.000619\n",
      "batch 121 loss: 0.26367 acc: 0.92448 | v_loss: 0.46037 v_acc: 0.88607 |  iteration: 5094 teacher: 1 stage: sketch lr: 0.000619\n",
      "batch 122 loss: 0.24690 acc: 0.92188 | v_loss: 0.47425 v_acc: 0.88867 |  iteration: 5095 teacher: 0 stage: sketch lr: 0.000619\n",
      "batch 123 loss: 0.27617 acc: 0.92546 | v_loss: 0.71915 v_acc: 0.85905 |  iteration: 5096 teacher: 1 stage: sketch lr: 0.000619\n",
      "batch 124 loss: 0.20192 acc: 0.94173 | v_loss: 0.48923 v_acc: 0.90527 |  iteration: 5097 teacher: 0 stage: sketch lr: 0.000619\n",
      "batch 125 loss: 0.21881 acc: 0.94173 | v_loss: 0.55709 v_acc: 0.87598 |  iteration: 5098 teacher: 1 stage: sketch lr: 0.000619\n",
      "batch 126 loss: 0.30759 acc: 0.91276 | v_loss: 0.68783 v_acc: 0.85384 |  iteration: 5099 teacher: 1 stage: sketch lr: 0.000619\n",
      "batch 127 loss: 0.21317 acc: 0.92936 | v_loss: 0.43778 v_acc: 0.89616 |  iteration: 5100 teacher: 0 stage: sketch lr: 0.000619\n",
      "batch 128 loss: 0.40317 acc: 0.89648 | v_loss: 0.55890 v_acc: 0.86621 |  iteration: 5101 teacher: 1 stage: sketch lr: 0.000619\n",
      "batch 129 loss: 0.31799 acc: 0.91602 | v_loss: 0.55725 v_acc: 0.86491 |  iteration: 5102 teacher: 0 stage: sketch lr: 0.000619\n",
      "batch 130 loss: 0.25720 acc: 0.92708 | v_loss: 0.74017 v_acc: 0.84440 |  iteration: 5103 teacher: 0 stage: sketch lr: 0.000619\n",
      "batch 131 loss: 0.26740 acc: 0.92220 | v_loss: 0.55834 v_acc: 0.87793 |  iteration: 5104 teacher: 0 stage: sketch lr: 0.000619\n",
      "batch 132 loss: 0.25247 acc: 0.93717 | v_loss: 0.55497 v_acc: 0.87435 |  iteration: 5105 teacher: 1 stage: sketch lr: 0.000619\n",
      "batch 133 loss: 0.21564 acc: 0.93685 | v_loss: 0.61239 v_acc: 0.86491 |  iteration: 5106 teacher: 1 stage: sketch lr: 0.000618\n",
      "batch 134 loss: 0.20755 acc: 0.94499 | v_loss: 0.59394 v_acc: 0.85221 |  iteration: 5107 teacher: 1 stage: sketch lr: 0.000618\n",
      "batch 135 loss: 0.33234 acc: 0.90234 | v_loss: 0.42813 v_acc: 0.90104 |  iteration: 5108 teacher: 1 stage: sketch lr: 0.000618\n",
      "batch 136 loss: 0.28624 acc: 0.91895 | v_loss: 0.78420 v_acc: 0.82878 |  iteration: 5109 teacher: 0 stage: sketch lr: 0.000618\n",
      "batch 137 loss: 0.29591 acc: 0.91471 | v_loss: 0.55135 v_acc: 0.87760 |  iteration: 5110 teacher: 1 stage: sketch lr: 0.000618\n",
      "batch 138 loss: 0.28219 acc: 0.91992 | v_loss: 0.57013 v_acc: 0.86654 |  iteration: 5111 teacher: 1 stage: sketch lr: 0.000618\n",
      "batch 139 loss: 0.27880 acc: 0.92122 | v_loss: 0.52651 v_acc: 0.87760 |  iteration: 5112 teacher: 1 stage: sketch lr: 0.000618\n",
      "batch 140 loss: 0.29496 acc: 0.90820 | v_loss: 0.49247 v_acc: 0.89648 |  iteration: 5113 teacher: 0 stage: sketch lr: 0.000618\n",
      "batch 141 loss: 0.23719 acc: 0.93620 | v_loss: 0.46469 v_acc: 0.89388 |  iteration: 5114 teacher: 1 stage: sketch lr: 0.000618\n",
      "batch 142 loss: 0.25699 acc: 0.92708 | v_loss: 0.54286 v_acc: 0.88021 |  iteration: 5115 teacher: 1 stage: sketch lr: 0.000618\n",
      "batch 143 loss: 0.28013 acc: 0.92285 | v_loss: 0.61860 v_acc: 0.84766 |  iteration: 5116 teacher: 0 stage: sketch lr: 0.000618\n",
      "batch 144 loss: 0.24196 acc: 0.93066 | v_loss: 0.58070 v_acc: 0.88542 |  iteration: 5117 teacher: 0 stage: sketch lr: 0.000618\n",
      "batch 145 loss: 0.26344 acc: 0.91829 | v_loss: 0.57389 v_acc: 0.88672 |  iteration: 5118 teacher: 0 stage: sketch lr: 0.000618\n",
      "batch 146 loss: 0.29321 acc: 0.91048 | v_loss: 0.38420 v_acc: 0.90951 |  iteration: 5119 teacher: 0 stage: sketch lr: 0.000618\n",
      "batch 147 loss: 0.24503 acc: 0.92741 | v_loss: 0.55934 v_acc: 0.88639 |  iteration: 5120 teacher: 0 stage: sketch lr: 0.000618\n",
      "batch 148 loss: 0.24093 acc: 0.92741 | v_loss: 0.50406 v_acc: 0.88379 |  iteration: 5121 teacher: 1 stage: sketch lr: 0.000618\n",
      "batch 149 loss: 0.40688 acc: 0.89388 | v_loss: 0.93327 v_acc: 0.82975 |  iteration: 5122 teacher: 1 stage: sketch lr: 0.000618\n",
      "batch 150 loss: 0.28799 acc: 0.91374 | v_loss: 0.35420 v_acc: 0.91048 |  iteration: 5123 teacher: 0 stage: sketch lr: 0.000617\n",
      "batch 151 loss: 0.22516 acc: 0.93392 | v_loss: 0.30506 v_acc: 0.92871 |  iteration: 5124 teacher: 1 stage: sketch lr: 0.000617\n",
      "batch 152 loss: 0.28735 acc: 0.92057 | v_loss: 0.58199 v_acc: 0.88249 |  iteration: 5125 teacher: 0 stage: sketch lr: 0.000617\n",
      "batch 153 loss: 0.26131 acc: 0.92350 | v_loss: 0.54639 v_acc: 0.88379 |  iteration: 5126 teacher: 0 stage: sketch lr: 0.000617\n",
      "batch 154 loss: 0.30387 acc: 0.90202 | v_loss: 0.65483 v_acc: 0.86361 |  iteration: 5127 teacher: 1 stage: sketch lr: 0.000617\n",
      "batch 155 loss: 0.26301 acc: 0.91764 | v_loss: 0.41257 v_acc: 0.90788 |  iteration: 5128 teacher: 0 stage: sketch lr: 0.000617\n",
      "batch 156 loss: 0.31329 acc: 0.90658 | v_loss: 0.48355 v_acc: 0.87858 |  iteration: 5129 teacher: 0 stage: sketch lr: 0.000617\n",
      "batch 157 loss: 0.22120 acc: 0.93457 | v_loss: 0.60454 v_acc: 0.87012 |  iteration: 5130 teacher: 1 stage: sketch lr: 0.000617\n",
      "batch 158 loss: 0.23623 acc: 0.93750 | v_loss: 0.68487 v_acc: 0.84993 |  iteration: 5131 teacher: 1 stage: sketch lr: 0.000617\n",
      "batch 159 loss: 0.20088 acc: 0.94108 | v_loss: 0.50882 v_acc: 0.89128 |  iteration: 5132 teacher: 1 stage: sketch lr: 0.000617\n",
      "batch 160 loss: 0.23598 acc: 0.93197 | v_loss: 0.41356 v_acc: 0.90169 |  iteration: 5133 teacher: 0 stage: sketch lr: 0.000617\n",
      "batch 161 loss: 0.33435 acc: 0.91016 | v_loss: 0.35951 v_acc: 0.91374 |  iteration: 5134 teacher: 1 stage: sketch lr: 0.000617\n",
      "batch 162 loss: 0.26137 acc: 0.92318 | v_loss: 0.47362 v_acc: 0.89746 |  iteration: 5135 teacher: 0 stage: sketch lr: 0.000617\n",
      "batch 163 loss: 0.22871 acc: 0.93229 | v_loss: 0.48354 v_acc: 0.88346 |  iteration: 5136 teacher: 1 stage: sketch lr: 0.000617\n",
      "batch 164 loss: 0.28961 acc: 0.91439 | v_loss: 0.77406 v_acc: 0.85221 |  iteration: 5137 teacher: 0 stage: sketch lr: 0.000617\n",
      "batch 165 loss: 0.23098 acc: 0.93132 | v_loss: 0.54982 v_acc: 0.87240 |  iteration: 5138 teacher: 0 stage: sketch lr: 0.000617\n",
      "batch 166 loss: 0.22277 acc: 0.93001 | v_loss: 0.67901 v_acc: 0.86654 |  iteration: 5139 teacher: 1 stage: sketch lr: 0.000616\n",
      "batch 167 loss: 0.26295 acc: 0.91764 | v_loss: 0.42279 v_acc: 0.90202 |  iteration: 5140 teacher: 1 stage: sketch lr: 0.000616\n",
      "batch 168 loss: 0.28340 acc: 0.91602 | v_loss: 0.54430 v_acc: 0.88704 |  iteration: 5141 teacher: 1 stage: sketch lr: 0.000616\n",
      "batch 169 loss: 0.23304 acc: 0.93945 | v_loss: 0.79179 v_acc: 0.84928 |  iteration: 5142 teacher: 0 stage: sketch lr: 0.000616\n",
      "batch 170 loss: 0.33431 acc: 0.90430 | v_loss: 0.48162 v_acc: 0.89974 |  iteration: 5143 teacher: 0 stage: sketch lr: 0.000616\n",
      "batch 171 loss: 0.17148 acc: 0.95215 | v_loss: 0.50362 v_acc: 0.89290 |  iteration: 5144 teacher: 1 stage: sketch lr: 0.000616\n",
      "batch 172 loss: 0.28339 acc: 0.91862 | v_loss: 0.49788 v_acc: 0.88542 |  iteration: 5145 teacher: 0 stage: sketch lr: 0.000616\n",
      "batch 173 loss: 0.26318 acc: 0.92155 | v_loss: 0.43135 v_acc: 0.90527 |  iteration: 5146 teacher: 1 stage: sketch lr: 0.000616\n",
      "batch 174 loss: 0.22081 acc: 0.93880 | v_loss: 0.48737 v_acc: 0.89844 |  iteration: 5147 teacher: 1 stage: sketch lr: 0.000616\n",
      "batch 175 loss: 0.27189 acc: 0.92025 | v_loss: 0.59441 v_acc: 0.86003 |  iteration: 5148 teacher: 0 stage: sketch lr: 0.000616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 176 loss: 0.24390 acc: 0.93294 | v_loss: 0.37300 v_acc: 0.91764 |  iteration: 5149 teacher: 1 stage: sketch lr: 0.000616\n",
      "batch 177 loss: 0.22020 acc: 0.93392 | v_loss: 0.95036 v_acc: 0.83008 |  iteration: 5150 teacher: 0 stage: sketch lr: 0.000616\n",
      "batch 178 loss: 0.28904 acc: 0.91829 | v_loss: 0.66424 v_acc: 0.87793 |  iteration: 5151 teacher: 1 stage: sketch lr: 0.000616\n",
      "batch 179 loss: 0.27939 acc: 0.92285 | v_loss: 0.70892 v_acc: 0.86361 |  iteration: 5152 teacher: 0 stage: sketch lr: 0.000616\n",
      "batch 180 loss: 0.26850 acc: 0.92415 | v_loss: 0.51947 v_acc: 0.89062 |  iteration: 5153 teacher: 1 stage: sketch lr: 0.000616\n",
      "batch 181 loss: 0.26113 acc: 0.92513 | v_loss: 0.49152 v_acc: 0.88802 |  iteration: 5154 teacher: 1 stage: sketch lr: 0.000616\n",
      "batch 182 loss: 0.24252 acc: 0.92057 | v_loss: 0.56226 v_acc: 0.88835 |  iteration: 5155 teacher: 0 stage: sketch lr: 0.000616\n",
      "batch 183 loss: 0.27646 acc: 0.91797 | v_loss: 0.50726 v_acc: 0.89681 |  iteration: 5156 teacher: 0 stage: sketch lr: 0.000615\n",
      "batch 184 loss: 0.28563 acc: 0.91276 | v_loss: 0.53343 v_acc: 0.89128 |  iteration: 5157 teacher: 0 stage: sketch lr: 0.000615\n",
      "batch 185 loss: 0.26617 acc: 0.91634 | v_loss: 0.47516 v_acc: 0.90495 |  iteration: 5158 teacher: 0 stage: sketch lr: 0.000615\n",
      "batch 186 loss: 0.31260 acc: 0.90853 | v_loss: 0.46635 v_acc: 0.89323 |  iteration: 5159 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 187 loss: 0.30834 acc: 0.91276 | v_loss: 0.33906 v_acc: 0.91667 |  iteration: 5160 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 188 loss: 0.22050 acc: 0.93945 | v_loss: 0.66871 v_acc: 0.85091 |  iteration: 5161 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 189 loss: 0.24461 acc: 0.93132 | v_loss: 0.58652 v_acc: 0.85645 |  iteration: 5162 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 190 loss: 0.26795 acc: 0.91504 | v_loss: 0.59074 v_acc: 0.86719 |  iteration: 5163 teacher: 0 stage: sketch lr: 0.000615\n",
      "batch 191 loss: 0.31114 acc: 0.91634 | v_loss: 0.81377 v_acc: 0.84668 |  iteration: 5164 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 192 loss: 0.23538 acc: 0.92904 | v_loss: 0.45433 v_acc: 0.90365 |  iteration: 5165 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 193 loss: 0.27126 acc: 0.92773 | v_loss: 0.59429 v_acc: 0.87565 |  iteration: 5166 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 194 loss: 0.26624 acc: 0.92318 | v_loss: 0.55290 v_acc: 0.89388 |  iteration: 5167 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 195 loss: 0.17158 acc: 0.94889 | v_loss: 0.45337 v_acc: 0.90104 |  iteration: 5168 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 196 loss: 0.18246 acc: 0.94954 | v_loss: 1.16726 v_acc: 0.80957 |  iteration: 5169 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 197 loss: 0.19970 acc: 0.94141 | v_loss: 0.40179 v_acc: 0.91146 |  iteration: 5170 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 198 loss: 0.42672 acc: 0.88835 | v_loss: 0.59479 v_acc: 0.87858 |  iteration: 5171 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 199 loss: 0.33862 acc: 0.90592 | v_loss: 0.51060 v_acc: 0.89128 |  iteration: 5172 teacher: 0 stage: sketch lr: 0.000615\n",
      "batch 200 loss: 0.21919 acc: 0.93229 | v_loss: 0.40329 v_acc: 0.90592 |  iteration: 5173 teacher: 0 stage: sketch lr: 0.000614\n",
      "batch 201 loss: 0.30163 acc: 0.91211 | v_loss: 0.48910 v_acc: 0.88900 |  iteration: 5174 teacher: 1 stage: sketch lr: 0.000614\n",
      "batch 202 loss: 0.28970 acc: 0.91699 | v_loss: 0.59000 v_acc: 0.86849 |  iteration: 5175 teacher: 1 stage: sketch lr: 0.000614\n",
      "batch 203 loss: 0.26607 acc: 0.92188 | v_loss: 0.38913 v_acc: 0.90885 |  iteration: 5176 teacher: 1 stage: sketch lr: 0.000614\n",
      "batch 204 loss: 0.21950 acc: 0.93164 | v_loss: 0.56873 v_acc: 0.86979 |  iteration: 5177 teacher: 1 stage: sketch lr: 0.000614\n",
      "batch 205 loss: 0.27235 acc: 0.91927 | v_loss: 0.36514 v_acc: 0.90658 |  iteration: 5178 teacher: 1 stage: sketch lr: 0.000614\n",
      "batch 206 loss: 0.24977 acc: 0.92741 | v_loss: 0.91472 v_acc: 0.81315 |  iteration: 5179 teacher: 1 stage: sketch lr: 0.000614\n",
      "batch 207 loss: 0.22142 acc: 0.93750 | v_loss: 0.54305 v_acc: 0.88672 |  iteration: 5180 teacher: 1 stage: sketch lr: 0.000614\n",
      "batch 208 loss: 0.24232 acc: 0.92871 | v_loss: 0.63593 v_acc: 0.86198 |  iteration: 5181 teacher: 0 stage: sketch lr: 0.000614\n",
      "batch 209 loss: 0.29305 acc: 0.91374 | v_loss: 0.42677 v_acc: 0.90234 |  iteration: 5182 teacher: 0 stage: sketch lr: 0.000614\n",
      "batch 210 loss: 0.30647 acc: 0.90267 | v_loss: 0.63805 v_acc: 0.85677 |  iteration: 5183 teacher: 0 stage: sketch lr: 0.000614\n",
      "batch 211 loss: 0.28677 acc: 0.91927 | v_loss: 0.45134 v_acc: 0.89453 |  iteration: 5184 teacher: 1 stage: sketch lr: 0.000614\n",
      "batch 212 loss: 0.36182 acc: 0.88835 | v_loss: 0.45262 v_acc: 0.89128 |  iteration: 5185 teacher: 0 stage: sketch lr: 0.000614\n",
      "batch 213 loss: 0.25637 acc: 0.92708 | v_loss: 0.44231 v_acc: 0.88770 |  iteration: 5186 teacher: 0 stage: sketch lr: 0.000614\n",
      "batch 214 loss: 0.22869 acc: 0.93587 | v_loss: 0.73255 v_acc: 0.85905 |  iteration: 5187 teacher: 1 stage: sketch lr: 0.000614\n",
      "batch 215 loss: 0.30477 acc: 0.91016 | v_loss: 0.55296 v_acc: 0.89323 |  iteration: 5188 teacher: 0 stage: sketch lr: 0.000614\n",
      "batch 216 loss: 0.29515 acc: 0.91927 | v_loss: 0.55031 v_acc: 0.88021 |  iteration: 5189 teacher: 0 stage: sketch lr: 0.000614\n",
      "batch 217 loss: 0.37267 acc: 0.90299 | v_loss: 0.68175 v_acc: 0.84798 |  iteration: 5190 teacher: 1 stage: sketch lr: 0.000613\n",
      "batch 218 loss: 0.29971 acc: 0.91146 | v_loss: 0.46656 v_acc: 0.88379 |  iteration: 5191 teacher: 0 stage: sketch lr: 0.000613\n",
      "batch 219 loss: 0.19019 acc: 0.94173 | v_loss: 0.50863 v_acc: 0.87272 |  iteration: 5192 teacher: 1 stage: sketch lr: 0.000613\n",
      "batch 220 loss: 0.23880 acc: 0.92904 | v_loss: 0.57912 v_acc: 0.86491 |  iteration: 5193 teacher: 1 stage: sketch lr: 0.000613\n",
      "batch 221 loss: 0.35043 acc: 0.89779 | v_loss: 0.73626 v_acc: 0.84310 |  iteration: 5194 teacher: 0 stage: sketch lr: 0.000613\n",
      "batch 222 loss: 0.32688 acc: 0.90788 | v_loss: 0.58485 v_acc: 0.87109 |  iteration: 5195 teacher: 1 stage: sketch lr: 0.000613\n",
      "batch 223 loss: 0.26175 acc: 0.92155 | v_loss: 0.57272 v_acc: 0.88672 |  iteration: 5196 teacher: 1 stage: sketch lr: 0.000613\n",
      "batch 224 loss: 0.23997 acc: 0.93587 | v_loss: 0.70535 v_acc: 0.86589 |  iteration: 5197 teacher: 1 stage: sketch lr: 0.000613\n",
      "batch 225 loss: 0.22154 acc: 0.93424 | v_loss: 0.56683 v_acc: 0.86849 |  iteration: 5198 teacher: 0 stage: sketch lr: 0.000613\n",
      "batch 226 loss: 0.31800 acc: 0.91113 | v_loss: 0.45554 v_acc: 0.90104 |  iteration: 5199 teacher: 1 stage: sketch lr: 0.000613\n",
      "batch 227 loss: 0.20436 acc: 0.94499 | v_loss: 0.81947 v_acc: 0.84310 |  iteration: 5200 teacher: 1 stage: sketch lr: 0.000613\n",
      "batch 228 loss: 0.20126 acc: 0.93880 | v_loss: 0.62271 v_acc: 0.87956 |  iteration: 5201 teacher: 0 stage: sketch lr: 0.000613\n",
      "batch 229 loss: 0.23794 acc: 0.92904 | v_loss: 0.59944 v_acc: 0.87533 |  iteration: 5202 teacher: 1 stage: sketch lr: 0.000613\n",
      "batch 230 loss: 0.33088 acc: 0.91439 | v_loss: 0.54588 v_acc: 0.88281 |  iteration: 5203 teacher: 1 stage: sketch lr: 0.000613\n",
      "batch 231 loss: 0.32406 acc: 0.91048 | v_loss: 0.48128 v_acc: 0.90169 |  iteration: 5204 teacher: 0 stage: sketch lr: 0.000613\n",
      "batch 232 loss: 0.31389 acc: 0.91048 | v_loss: 0.45777 v_acc: 0.89518 |  iteration: 5205 teacher: 0 stage: sketch lr: 0.000613\n",
      "batch 233 loss: 0.34532 acc: 0.90202 | v_loss: 0.55292 v_acc: 0.88118 |  iteration: 5206 teacher: 1 stage: sketch lr: 0.000613\n",
      "batch 234 loss: 0.28743 acc: 0.91471 | v_loss: 0.58890 v_acc: 0.85221 |  iteration: 5207 teacher: 0 stage: sketch lr: 0.000612\n",
      "batch 235 loss: 0.18935 acc: 0.94596 | v_loss: 0.57370 v_acc: 0.88542 |  iteration: 5208 teacher: 1 stage: sketch lr: 0.000612\n",
      "batch 236 loss: 0.27101 acc: 0.91504 | v_loss: 0.57924 v_acc: 0.87826 |  iteration: 5209 teacher: 1 stage: sketch lr: 0.000612\n",
      "batch 237 loss: 0.30164 acc: 0.91341 | v_loss: 0.38862 v_acc: 0.90495 |  iteration: 5210 teacher: 0 stage: sketch lr: 0.000612\n",
      "batch 238 loss: 0.17978 acc: 0.94368 | v_loss: 0.50110 v_acc: 0.88900 |  iteration: 5211 teacher: 0 stage: sketch lr: 0.000612\n",
      "batch 239 loss: 0.26340 acc: 0.92676 | v_loss: 0.50562 v_acc: 0.88021 |  iteration: 5212 teacher: 0 stage: sketch lr: 0.000612\n",
      "batch 240 loss: 0.27255 acc: 0.92025 | v_loss: 0.84415 v_acc: 0.83724 |  iteration: 5213 teacher: 0 stage: sketch lr: 0.000612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 241 loss: 0.28752 acc: 0.91536 | v_loss: 0.36721 v_acc: 0.90625 |  iteration: 5214 teacher: 0 stage: sketch lr: 0.000612\n",
      "batch 242 loss: 0.29826 acc: 0.91764 | v_loss: 0.30956 v_acc: 0.93001 |  iteration: 5215 teacher: 1 stage: sketch lr: 0.000612\n",
      "batch 243 loss: 0.33889 acc: 0.90365 | v_loss: 0.61967 v_acc: 0.87858 |  iteration: 5216 teacher: 0 stage: sketch lr: 0.000612\n",
      "batch 244 loss: 0.30793 acc: 0.90885 | v_loss: 0.55285 v_acc: 0.88118 |  iteration: 5217 teacher: 0 stage: sketch lr: 0.000612\n",
      "batch 245 loss: 0.35522 acc: 0.89290 | v_loss: 0.67157 v_acc: 0.85579 |  iteration: 5218 teacher: 1 stage: sketch lr: 0.000612\n",
      "batch 246 loss: 0.25952 acc: 0.92285 | v_loss: 0.44416 v_acc: 0.89193 |  iteration: 5219 teacher: 1 stage: sketch lr: 0.000612\n",
      "batch 247 loss: 0.21175 acc: 0.94238 | v_loss: 0.54401 v_acc: 0.86589 |  iteration: 5220 teacher: 1 stage: sketch lr: 0.000612\n",
      "batch 248 loss: 0.31938 acc: 0.90658 | v_loss: 0.64426 v_acc: 0.85482 |  iteration: 5221 teacher: 0 stage: sketch lr: 0.000612\n",
      "batch 249 loss: 0.24755 acc: 0.93164 | v_loss: 0.68500 v_acc: 0.83984 |  iteration: 5222 teacher: 1 stage: sketch lr: 0.000612\n",
      "batch 250 loss: 0.35871 acc: 0.89323 | v_loss: 0.49715 v_acc: 0.90039 |  iteration: 5223 teacher: 0 stage: sketch lr: 0.000612\n",
      "batch 251 loss: 0.34971 acc: 0.90104 | v_loss: 0.40849 v_acc: 0.90560 |  iteration: 5224 teacher: 1 stage: sketch lr: 0.000611\n",
      "batch 252 loss: 0.23254 acc: 0.92969 | v_loss: 0.30932 v_acc: 0.91699 |  iteration: 5225 teacher: 1 stage: sketch lr: 0.000611\n",
      "batch 253 loss: 0.31097 acc: 0.91602 | v_loss: 0.49715 v_acc: 0.89095 |  iteration: 5226 teacher: 0 stage: sketch lr: 0.000611\n",
      "batch 254 loss: 0.29928 acc: 0.90723 | v_loss: 0.52232 v_acc: 0.87467 |  iteration: 5227 teacher: 0 stage: sketch lr: 0.000611\n",
      "batch 255 loss: 0.31042 acc: 0.89714 | v_loss: 0.81395 v_acc: 0.84147 |  iteration: 5228 teacher: 0 stage: sketch lr: 0.000611\n",
      "batch 256 loss: 0.30380 acc: 0.90658 | v_loss: 0.59581 v_acc: 0.86621 |  iteration: 5229 teacher: 0 stage: sketch lr: 0.000611\n",
      "batch 257 loss: 0.27549 acc: 0.91862 | v_loss: 0.61485 v_acc: 0.87109 |  iteration: 5230 teacher: 1 stage: sketch lr: 0.000611\n",
      "batch 258 loss: 0.36479 acc: 0.91113 | v_loss: 0.46702 v_acc: 0.88997 |  iteration: 5231 teacher: 1 stage: sketch lr: 0.000611\n",
      "batch 259 loss: 0.26913 acc: 0.92415 | v_loss: 0.55769 v_acc: 0.88151 |  iteration: 5232 teacher: 1 stage: sketch lr: 0.000611\n",
      "batch 260 loss: 0.29293 acc: 0.91374 | v_loss: 0.80158 v_acc: 0.83887 |  iteration: 5233 teacher: 0 stage: sketch lr: 0.000611\n",
      "batch 261 loss: 0.26514 acc: 0.92350 | v_loss: 0.53596 v_acc: 0.88574 |  iteration: 5234 teacher: 0 stage: sketch lr: 0.000611\n",
      "batch 262 loss: 0.30347 acc: 0.91243 | v_loss: 0.52237 v_acc: 0.88346 |  iteration: 5235 teacher: 0 stage: sketch lr: 0.000611\n",
      "batch 263 loss: 0.35846 acc: 0.90332 | v_loss: 0.47646 v_acc: 0.88639 |  iteration: 5236 teacher: 1 stage: sketch lr: 0.000611\n",
      "batch 264 loss: 0.31980 acc: 0.90788 | v_loss: 0.42392 v_acc: 0.90007 |  iteration: 5237 teacher: 1 stage: sketch lr: 0.000611\n",
      "batch 265 loss: 0.18280 acc: 0.94401 | v_loss: 0.44707 v_acc: 0.89648 |  iteration: 5238 teacher: 1 stage: sketch lr: 0.000611\n",
      "batch 266 loss: 0.22452 acc: 0.93001 | v_loss: 0.65958 v_acc: 0.85221 |  iteration: 5239 teacher: 1 stage: sketch lr: 0.000611\n",
      "batch 267 loss: 0.26772 acc: 0.91732 | v_loss: 0.37520 v_acc: 0.91439 |  iteration: 5240 teacher: 0 stage: sketch lr: 0.000611\n",
      "batch 268 loss: 0.15351 acc: 0.95475 | v_loss: 0.94736 v_acc: 0.82780 |  iteration: 5241 teacher: 1 stage: sketch lr: 0.000610\n",
      "batch 269 loss: 0.29242 acc: 0.91602 | v_loss: 0.66353 v_acc: 0.86947 |  iteration: 5242 teacher: 0 stage: sketch lr: 0.000610\n",
      "batch 270 loss: 0.25217 acc: 0.93066 | v_loss: 0.68006 v_acc: 0.86296 |  iteration: 5243 teacher: 1 stage: sketch lr: 0.000610\n",
      "batch 271 loss: 0.29693 acc: 0.92155 | v_loss: 0.54998 v_acc: 0.89355 |  iteration: 5244 teacher: 1 stage: sketch lr: 0.000610\n",
      "batch 272 loss: 0.30701 acc: 0.91048 | v_loss: 0.48434 v_acc: 0.89616 |  iteration: 5245 teacher: 0 stage: sketch lr: 0.000610\n",
      "batch 273 loss: 0.27072 acc: 0.91732 | v_loss: 0.57300 v_acc: 0.89225 |  iteration: 5246 teacher: 0 stage: sketch lr: 0.000610\n",
      "batch 274 loss: 0.22904 acc: 0.93555 | v_loss: 0.50758 v_acc: 0.89225 |  iteration: 5247 teacher: 1 stage: sketch lr: 0.000610\n",
      "batch 275 loss: 0.28802 acc: 0.91178 | v_loss: 0.51553 v_acc: 0.88932 |  iteration: 5248 teacher: 0 stage: sketch lr: 0.000610\n",
      "batch 276 loss: 0.37746 acc: 0.90625 | v_loss: 0.48145 v_acc: 0.90202 |  iteration: 5249 teacher: 1 stage: sketch lr: 0.000610\n",
      "batch 277 loss: 0.23530 acc: 0.92904 | v_loss: 0.45662 v_acc: 0.88997 |  iteration: 5250 teacher: 0 stage: sketch lr: 0.000610\n",
      "batch 278 loss: 0.30517 acc: 0.90820 | v_loss: 0.32631 v_acc: 0.91536 |  iteration: 5251 teacher: 1 stage: sketch lr: 0.000610\n",
      "batch 279 loss: 0.25315 acc: 0.92904 | v_loss: 0.62226 v_acc: 0.86068 |  iteration: 5252 teacher: 1 stage: sketch lr: 0.000610\n",
      "batch 280 loss: 0.19877 acc: 0.94336 | v_loss: 0.57530 v_acc: 0.86328 |  iteration: 5253 teacher: 1 stage: sketch lr: 0.000610\n",
      "batch 281 loss: 0.30306 acc: 0.90885 | v_loss: 0.58222 v_acc: 0.85775 |  iteration: 5254 teacher: 1 stage: sketch lr: 0.000610\n",
      "batch 282 loss: 0.31527 acc: 0.91602 | v_loss: 0.80997 v_acc: 0.84180 |  iteration: 5255 teacher: 1 stage: sketch lr: 0.000610\n",
      "batch 283 loss: 0.30148 acc: 0.91406 | v_loss: 0.42864 v_acc: 0.90202 |  iteration: 5256 teacher: 0 stage: sketch lr: 0.000610\n",
      "batch 284 loss: 0.33313 acc: 0.91048 | v_loss: 0.56042 v_acc: 0.87467 |  iteration: 5257 teacher: 1 stage: sketch lr: 0.000610\n",
      "batch 285 loss: 0.28423 acc: 0.91862 | v_loss: 0.53152 v_acc: 0.88249 |  iteration: 5258 teacher: 1 stage: sketch lr: 0.000609\n",
      "batch 286 loss: 0.31862 acc: 0.90918 | v_loss: 0.45052 v_acc: 0.89486 |  iteration: 5259 teacher: 1 stage: sketch lr: 0.000609\n",
      "batch 287 loss: 0.28608 acc: 0.92090 | v_loss: 1.17312 v_acc: 0.80664 |  iteration: 5260 teacher: 0 stage: sketch lr: 0.000609\n",
      "batch 288 loss: 0.25640 acc: 0.92220 | v_loss: 0.34991 v_acc: 0.92057 |  iteration: 5261 teacher: 0 stage: sketch lr: 0.000609\n",
      "batch 289 loss: 0.28127 acc: 0.92643 | v_loss: 0.57477 v_acc: 0.87305 |  iteration: 5262 teacher: 1 stage: sketch lr: 0.000609\n",
      "batch 290 loss: 0.32376 acc: 0.90983 | v_loss: 0.47981 v_acc: 0.89453 |  iteration: 5263 teacher: 1 stage: sketch lr: 0.000609\n",
      "batch 291 loss: 0.34270 acc: 0.89746 | v_loss: 0.41127 v_acc: 0.90625 |  iteration: 5264 teacher: 0 stage: sketch lr: 0.000609\n",
      "batch 292 loss: 0.28822 acc: 0.91699 | v_loss: 0.53910 v_acc: 0.89095 |  iteration: 5265 teacher: 0 stage: sketch lr: 0.000609\n",
      "batch 293 loss: 0.28694 acc: 0.91732 | v_loss: 0.60552 v_acc: 0.87598 |  iteration: 5266 teacher: 1 stage: sketch lr: 0.000609\n",
      "batch 294 loss: 0.34803 acc: 0.90527 | v_loss: 0.44352 v_acc: 0.90560 |  iteration: 5267 teacher: 0 stage: sketch lr: 0.000609\n",
      "batch 295 loss: 0.24791 acc: 0.93685 | v_loss: 0.60512 v_acc: 0.87565 |  iteration: 5268 teacher: 1 stage: sketch lr: 0.000609\n",
      "batch 296 loss: 0.30407 acc: 0.91504 | v_loss: 0.38433 v_acc: 0.90755 |  iteration: 5269 teacher: 0 stage: sketch lr: 0.000609\n",
      "batch 297 loss: 0.32491 acc: 0.91048 | v_loss: 0.97726 v_acc: 0.81543 |  iteration: 5270 teacher: 1 stage: sketch lr: 0.000609\n",
      "batch 298 loss: 0.34379 acc: 0.89746 | v_loss: 0.60793 v_acc: 0.87630 |  iteration: 5271 teacher: 0 stage: sketch lr: 0.000609\n",
      "batch 299 loss: 0.37298 acc: 0.88639 | v_loss: 0.61786 v_acc: 0.88216 |  iteration: 5272 teacher: 0 stage: sketch lr: 0.000609\n",
      "batch 300 loss: 0.35491 acc: 0.90690 | v_loss: 0.44951 v_acc: 0.89388 |  iteration: 5273 teacher: 1 stage: sketch lr: 0.000609\n",
      "batch 301 loss: 0.28404 acc: 0.91927 | v_loss: 0.65996 v_acc: 0.85905 |  iteration: 5274 teacher: 0 stage: sketch lr: 0.000609\n",
      "batch 302 loss: 0.24474 acc: 0.93001 | v_loss: 0.43924 v_acc: 0.89290 |  iteration: 5275 teacher: 0 stage: sketch lr: 0.000608\n",
      "batch 303 loss: 0.28351 acc: 0.91699 | v_loss: 0.43954 v_acc: 0.89714 |  iteration: 5276 teacher: 1 stage: sketch lr: 0.000608\n",
      "batch 304 loss: 0.27403 acc: 0.91699 | v_loss: 0.44336 v_acc: 0.88770 |  iteration: 5277 teacher: 1 stage: sketch lr: 0.000608\n",
      "batch 305 loss: 0.27384 acc: 0.91895 | v_loss: 0.71269 v_acc: 0.86165 |  iteration: 5278 teacher: 0 stage: sketch lr: 0.000608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 306 loss: 0.28893 acc: 0.91536 | v_loss: 0.54810 v_acc: 0.89290 |  iteration: 5279 teacher: 1 stage: sketch lr: 0.000608\n",
      "batch 307 loss: 0.26864 acc: 0.92220 | v_loss: 0.57269 v_acc: 0.87207 |  iteration: 5280 teacher: 1 stage: sketch lr: 0.000608\n",
      "batch 308 loss: 0.24832 acc: 0.92773 | v_loss: 0.67265 v_acc: 0.85059 |  iteration: 5281 teacher: 1 stage: sketch lr: 0.000608\n",
      "batch 309 loss: 0.25051 acc: 0.92936 | v_loss: 0.44986 v_acc: 0.89583 |  iteration: 5282 teacher: 1 stage: sketch lr: 0.000608\n",
      "batch 310 loss: 0.31990 acc: 0.90918 | v_loss: 0.52814 v_acc: 0.86816 |  iteration: 5283 teacher: 0 stage: sketch lr: 0.000608\n",
      "batch 311 loss: 0.24987 acc: 0.92936 | v_loss: 0.52370 v_acc: 0.87565 |  iteration: 5284 teacher: 0 stage: sketch lr: 0.000608\n",
      "batch 312 loss: 0.24658 acc: 0.92546 | v_loss: 0.81166 v_acc: 0.84733 |  iteration: 5285 teacher: 1 stage: sketch lr: 0.000608\n",
      "batch 313 loss: 0.25237 acc: 0.92839 | v_loss: 0.58248 v_acc: 0.88249 |  iteration: 5286 teacher: 0 stage: sketch lr: 0.000608\n",
      "batch 314 loss: 0.24450 acc: 0.92546 | v_loss: 0.58951 v_acc: 0.88639 |  iteration: 5287 teacher: 0 stage: sketch lr: 0.000608\n",
      "batch 315 loss: 0.31632 acc: 0.91243 | v_loss: 0.63570 v_acc: 0.87630 |  iteration: 5288 teacher: 1 stage: sketch lr: 0.000608\n",
      "batch 316 loss: 0.32211 acc: 0.90853 | v_loss: 0.55732 v_acc: 0.86784 |  iteration: 5289 teacher: 1 stage: sketch lr: 0.000608\n",
      "batch 317 loss: 0.26739 acc: 0.92285 | v_loss: 0.43449 v_acc: 0.90788 |  iteration: 5290 teacher: 0 stage: sketch lr: 0.000608\n",
      "batch 318 loss: 0.31104 acc: 0.92057 | v_loss: 0.78266 v_acc: 0.83919 |  iteration: 5291 teacher: 1 stage: sketch lr: 0.000608\n",
      "batch 319 loss: 0.29263 acc: 0.91211 | v_loss: 0.59261 v_acc: 0.87663 |  iteration: 5292 teacher: 0 stage: sketch lr: 0.000608\n",
      "batch 320 loss: 0.26341 acc: 0.92643 | v_loss: 0.53051 v_acc: 0.87174 |  iteration: 5293 teacher: 0 stage: sketch lr: 0.000607\n",
      "batch 321 loss: 0.28263 acc: 0.91113 | v_loss: 0.51132 v_acc: 0.87435 |  iteration: 5294 teacher: 0 stage: sketch lr: 0.000607\n",
      "batch 322 loss: 0.29662 acc: 0.90983 | v_loss: 0.46438 v_acc: 0.88281 |  iteration: 5295 teacher: 0 stage: sketch lr: 0.000607\n",
      "batch 323 loss: 0.26071 acc: 0.92448 | v_loss: 0.45158 v_acc: 0.89225 |  iteration: 5296 teacher: 0 stage: sketch lr: 0.000607\n",
      "batch 324 loss: 0.30947 acc: 0.90527 | v_loss: 0.51342 v_acc: 0.88867 |  iteration: 5297 teacher: 0 stage: sketch lr: 0.000607\n",
      "batch 325 loss: 0.31126 acc: 0.91309 | v_loss: 0.58062 v_acc: 0.85775 |  iteration: 5298 teacher: 1 stage: sketch lr: 0.000607\n",
      "batch 326 loss: 0.26749 acc: 0.92611 | v_loss: 0.54994 v_acc: 0.89388 |  iteration: 5299 teacher: 0 stage: sketch lr: 0.000607\n",
      "batch 327 loss: 0.29978 acc: 0.91341 | v_loss: 0.60819 v_acc: 0.88672 |  iteration: 5300 teacher: 1 stage: sketch lr: 0.000607\n",
      "batch 328 loss: 0.22674 acc: 0.93490 | v_loss: 0.36479 v_acc: 0.91732 |  iteration: 5301 teacher: 1 stage: sketch lr: 0.000607\n",
      "batch 329 loss: 0.31780 acc: 0.90820 | v_loss: 0.51012 v_acc: 0.88639 |  iteration: 5302 teacher: 1 stage: sketch lr: 0.000607\n",
      "batch 330 loss: 0.28240 acc: 0.91504 | v_loss: 0.48654 v_acc: 0.87793 |  iteration: 5303 teacher: 0 stage: sketch lr: 0.000607\n",
      "batch 331 loss: 0.20759 acc: 0.93913 | v_loss: 0.85959 v_acc: 0.82910 |  iteration: 5304 teacher: 0 stage: sketch lr: 0.000607\n",
      "batch 332 loss: 0.19562 acc: 0.93620 | v_loss: 0.37304 v_acc: 0.91146 |  iteration: 5305 teacher: 1 stage: sketch lr: 0.000607\n",
      "batch 333 loss: 0.28623 acc: 0.91862 | v_loss: 0.30888 v_acc: 0.93099 |  iteration: 5306 teacher: 0 stage: sketch lr: 0.000607\n",
      "batch 334 loss: 0.28642 acc: 0.91895 | v_loss: 0.60065 v_acc: 0.88281 |  iteration: 5307 teacher: 1 stage: sketch lr: 0.000607\n",
      "batch 335 loss: 0.21876 acc: 0.93652 | v_loss: 0.51601 v_acc: 0.89258 |  iteration: 5308 teacher: 1 stage: sketch lr: 0.000607\n",
      "batch 336 loss: 0.31952 acc: 0.91146 | v_loss: 0.62009 v_acc: 0.86068 |  iteration: 5309 teacher: 0 stage: sketch lr: 0.000607\n",
      "batch 337 loss: 0.20504 acc: 0.92904 | v_loss: 0.40902 v_acc: 0.90365 |  iteration: 5310 teacher: 0 stage: sketch lr: 0.000606\n",
      "batch 338 loss: 0.28304 acc: 0.91960 | v_loss: 0.47035 v_acc: 0.87728 |  iteration: 5311 teacher: 1 stage: sketch lr: 0.000606\n",
      "batch 339 loss: 0.25664 acc: 0.93197 | v_loss: 0.62816 v_acc: 0.85872 |  iteration: 5312 teacher: 0 stage: sketch lr: 0.000606\n",
      "batch 340 loss: 0.20036 acc: 0.93717 | v_loss: 0.65027 v_acc: 0.84668 |  iteration: 5313 teacher: 0 stage: sketch lr: 0.000606\n",
      "batch 341 loss: 0.23662 acc: 0.92904 | v_loss: 0.46568 v_acc: 0.89486 |  iteration: 5314 teacher: 0 stage: sketch lr: 0.000606\n",
      "batch 342 loss: 0.26295 acc: 0.92871 | v_loss: 0.38515 v_acc: 0.90137 |  iteration: 5315 teacher: 1 stage: sketch lr: 0.000606\n",
      "batch 343 loss: 0.30787 acc: 0.91243 | v_loss: 0.31145 v_acc: 0.92025 |  iteration: 5316 teacher: 1 stage: sketch lr: 0.000606\n",
      "batch 344 loss: 0.29363 acc: 0.91211 | v_loss: 0.49040 v_acc: 0.89616 |  iteration: 5317 teacher: 1 stage: sketch lr: 0.000606\n",
      "batch 345 loss: 0.25512 acc: 0.92188 | v_loss: 0.55824 v_acc: 0.88542 |  iteration: 5318 teacher: 0 stage: sketch lr: 0.000606\n",
      "batch 346 loss: 0.26943 acc: 0.92220 | v_loss: 0.80490 v_acc: 0.85579 |  iteration: 5319 teacher: 1 stage: sketch lr: 0.000606\n",
      "batch 347 loss: 0.21060 acc: 0.93164 | v_loss: 0.58059 v_acc: 0.87370 |  iteration: 5320 teacher: 0 stage: sketch lr: 0.000606\n",
      "batch 348 loss: 0.26713 acc: 0.92773 | v_loss: 0.64805 v_acc: 0.85905 |  iteration: 5321 teacher: 1 stage: sketch lr: 0.000606\n",
      "batch 349 loss: 0.31301 acc: 0.90658 | v_loss: 0.40759 v_acc: 0.90723 |  iteration: 5322 teacher: 0 stage: sketch lr: 0.000606\n",
      "batch 350 loss: 0.23973 acc: 0.92806 | v_loss: 0.52642 v_acc: 0.88835 |  iteration: 5323 teacher: 1 stage: sketch lr: 0.000606\n",
      "batch 351 loss: 0.25860 acc: 0.92643 | v_loss: 0.76650 v_acc: 0.84831 |  iteration: 5324 teacher: 1 stage: sketch lr: 0.000606\n",
      "batch 352 loss: 0.36431 acc: 0.90592 | v_loss: 0.52109 v_acc: 0.89486 |  iteration: 5325 teacher: 1 stage: sketch lr: 0.000606\n",
      "batch 353 loss: 0.29155 acc: 0.91862 | v_loss: 0.53085 v_acc: 0.88737 |  iteration: 5326 teacher: 0 stage: sketch lr: 0.000606\n",
      "batch 354 loss: 0.23595 acc: 0.93164 | v_loss: 0.51345 v_acc: 0.88639 |  iteration: 5327 teacher: 1 stage: sketch lr: 0.000606\n",
      "batch 355 loss: 0.19060 acc: 0.94336 | v_loss: 0.42377 v_acc: 0.90592 |  iteration: 5328 teacher: 1 stage: sketch lr: 0.000605\n",
      "batch 356 loss: 0.25363 acc: 0.93099 | v_loss: 0.45403 v_acc: 0.90820 |  iteration: 5329 teacher: 1 stage: sketch lr: 0.000605\n",
      "batch 357 loss: 0.22023 acc: 0.93815 | v_loss: 0.57244 v_acc: 0.87305 |  iteration: 5330 teacher: 0 stage: sketch lr: 0.000605\n",
      "batch 358 loss: 0.32412 acc: 0.90592 | v_loss: 0.36701 v_acc: 0.91992 |  iteration: 5331 teacher: 0 stage: sketch lr: 0.000605\n",
      "batch 359 loss: 0.29925 acc: 0.91178 | v_loss: 0.94554 v_acc: 0.82682 |  iteration: 5332 teacher: 0 stage: sketch lr: 0.000605\n",
      "batch 360 loss: 0.23185 acc: 0.92871 | v_loss: 0.63365 v_acc: 0.87435 |  iteration: 5333 teacher: 0 stage: sketch lr: 0.000605\n",
      "batch 361 loss: 0.36089 acc: 0.89648 | v_loss: 0.68304 v_acc: 0.86458 |  iteration: 5334 teacher: 0 stage: sketch lr: 0.000605\n",
      "batch 362 loss: 0.26651 acc: 0.92676 | v_loss: 0.55711 v_acc: 0.88184 |  iteration: 5335 teacher: 1 stage: sketch lr: 0.000605\n",
      "batch 363 loss: 0.24445 acc: 0.93164 | v_loss: 0.48248 v_acc: 0.89551 |  iteration: 5336 teacher: 0 stage: sketch lr: 0.000605\n",
      "batch 364 loss: 0.28605 acc: 0.92611 | v_loss: 0.60436 v_acc: 0.87956 |  iteration: 5337 teacher: 1 stage: sketch lr: 0.000605\n",
      "batch 365 loss: 0.35143 acc: 0.90723 | v_loss: 0.50982 v_acc: 0.89583 |  iteration: 5338 teacher: 0 stage: sketch lr: 0.000605\n",
      "batch 366 loss: 0.20565 acc: 0.94010 | v_loss: 0.48976 v_acc: 0.88997 |  iteration: 5339 teacher: 0 stage: sketch lr: 0.000605\n",
      "batch 367 loss: 0.21549 acc: 0.93652 | v_loss: 0.49747 v_acc: 0.89551 |  iteration: 5340 teacher: 0 stage: sketch lr: 0.000605\n",
      "batch 368 loss: 0.24365 acc: 0.92188 | v_loss: 0.43526 v_acc: 0.90104 |  iteration: 5341 teacher: 0 stage: sketch lr: 0.000605\n",
      "batch 369 loss: 0.38504 acc: 0.88835 | v_loss: 0.33578 v_acc: 0.91992 |  iteration: 5342 teacher: 0 stage: sketch lr: 0.000605\n",
      "batch 370 loss: 0.34275 acc: 0.90234 | v_loss: 0.62316 v_acc: 0.86133 |  iteration: 5343 teacher: 1 stage: sketch lr: 0.000605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 371 loss: 0.21765 acc: 0.93164 | v_loss: 0.56113 v_acc: 0.86100 |  iteration: 5344 teacher: 0 stage: sketch lr: 0.000605\n",
      "batch 372 loss: 0.26915 acc: 0.92220 | v_loss: 0.59535 v_acc: 0.87044 |  iteration: 5345 teacher: 1 stage: sketch lr: 0.000604\n",
      "batch 373 loss: 0.28678 acc: 0.91797 | v_loss: 0.85749 v_acc: 0.84408 |  iteration: 5346 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 374 loss: 0.22218 acc: 0.94271 | v_loss: 0.43468 v_acc: 0.90788 |  iteration: 5347 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 375 loss: 0.33715 acc: 0.90755 | v_loss: 0.59784 v_acc: 0.88281 |  iteration: 5348 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 376 loss: 0.22943 acc: 0.93099 | v_loss: 0.56873 v_acc: 0.89128 |  iteration: 5349 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 377 loss: 0.24864 acc: 0.92969 | v_loss: 0.42505 v_acc: 0.90560 |  iteration: 5350 teacher: 1 stage: sketch lr: 0.000604\n",
      "batch 378 loss: 0.29832 acc: 0.91016 | v_loss: 1.16211 v_acc: 0.80078 |  iteration: 5351 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 379 loss: 0.36410 acc: 0.89876 | v_loss: 0.40361 v_acc: 0.91374 |  iteration: 5352 teacher: 1 stage: sketch lr: 0.000604\n",
      "batch 380 loss: 0.28357 acc: 0.91667 | v_loss: 0.57440 v_acc: 0.88021 |  iteration: 5353 teacher: 1 stage: sketch lr: 0.000604\n",
      "batch 381 loss: 0.39789 acc: 0.88216 | v_loss: 0.49104 v_acc: 0.88737 |  iteration: 5354 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 382 loss: 0.26037 acc: 0.92513 | v_loss: 0.40434 v_acc: 0.90560 |  iteration: 5355 teacher: 1 stage: sketch lr: 0.000604\n",
      "batch 383 loss: 0.19223 acc: 0.93783 | v_loss: 0.50003 v_acc: 0.89225 |  iteration: 5356 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 384 loss: 0.32617 acc: 0.91016 | v_loss: 0.59052 v_acc: 0.87109 |  iteration: 5357 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 385 loss: 0.29032 acc: 0.91732 | v_loss: 0.45340 v_acc: 0.90560 |  iteration: 5358 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 386 loss: 0.24640 acc: 0.92220 | v_loss: 0.61443 v_acc: 0.87337 |  iteration: 5359 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 387 loss: 0.22396 acc: 0.93457 | v_loss: 0.37358 v_acc: 0.91309 |  iteration: 5360 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 388 loss: 0.24459 acc: 0.92773 | v_loss: 0.99370 v_acc: 0.82780 |  iteration: 5361 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 389 loss: 0.25755 acc: 0.92383 | v_loss: 0.57676 v_acc: 0.88314 |  iteration: 5362 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 390 loss: 0.28884 acc: 0.91895 | v_loss: 0.70515 v_acc: 0.86068 |  iteration: 5363 teacher: 1 stage: sketch lr: 0.000603\n",
      "batch 391 loss: 0.28377 acc: 0.91634 | v_loss: 0.40040 v_acc: 0.90137 |  iteration: 5364 teacher: 1 stage: sketch lr: 0.000603\n",
      "batch 392 loss: 0.22662 acc: 0.93132 | v_loss: 0.63796 v_acc: 0.86784 |  iteration: 5365 teacher: 0 stage: sketch lr: 0.000603\n",
      "batch 393 loss: 0.26105 acc: 0.92773 | v_loss: 0.40709 v_acc: 0.90332 |  iteration: 5366 teacher: 0 stage: sketch lr: 0.000603\n",
      "batch 394 loss: 0.28842 acc: 0.91146 | v_loss: 0.42175 v_acc: 0.89128 |  iteration: 5367 teacher: 0 stage: sketch lr: 0.000603\n",
      "batch 395 loss: 0.28315 acc: 0.91374 | v_loss: 0.39988 v_acc: 0.89453 |  iteration: 5368 teacher: 1 stage: sketch lr: 0.000603\n",
      "batch 396 loss: 0.26548 acc: 0.92611 | v_loss: 0.67583 v_acc: 0.85775 |  iteration: 5369 teacher: 1 stage: sketch lr: 0.000603\n",
      "batch 397 loss: 0.24970 acc: 0.92122 | v_loss: 0.49258 v_acc: 0.90104 |  iteration: 5370 teacher: 0 stage: sketch lr: 0.000603\n",
      "batch 398 loss: 0.23695 acc: 0.93197 | v_loss: 0.53556 v_acc: 0.88151 |  iteration: 5371 teacher: 1 stage: sketch lr: 0.000603\n",
      "batch 399 loss: 0.31321 acc: 0.91471 | v_loss: 0.62678 v_acc: 0.85938 |  iteration: 5372 teacher: 1 stage: sketch lr: 0.000603\n",
      "batch 400 loss: 0.26896 acc: 0.90951 | v_loss: 0.44288 v_acc: 0.89518 |  iteration: 5373 teacher: 0 stage: sketch lr: 0.000603\n",
      "batch 401 loss: 0.20882 acc: 0.94238 | v_loss: 0.51443 v_acc: 0.87598 |  iteration: 5374 teacher: 1 stage: sketch lr: 0.000603\n",
      "batch 402 loss: 0.23688 acc: 0.92806 | v_loss: 0.57816 v_acc: 0.86816 |  iteration: 5375 teacher: 0 stage: sketch lr: 0.000603\n",
      "batch 403 loss: 0.28536 acc: 0.91602 | v_loss: 0.73104 v_acc: 0.85482 |  iteration: 5376 teacher: 0 stage: sketch lr: 0.000603\n",
      "batch 404 loss: 0.28918 acc: 0.92025 | v_loss: 0.59213 v_acc: 0.88574 |  iteration: 5377 teacher: 1 stage: sketch lr: 0.000603\n",
      "batch 405 loss: 0.33166 acc: 0.90430 | v_loss: 0.56178 v_acc: 0.89583 |  iteration: 5378 teacher: 0 stage: sketch lr: 0.000603\n",
      "batch 406 loss: 0.30427 acc: 0.91309 | v_loss: 0.67979 v_acc: 0.87630 |  iteration: 5379 teacher: 0 stage: sketch lr: 0.000603\n",
      "batch 407 loss: 0.22914 acc: 0.93099 | v_loss: 0.58148 v_acc: 0.86816 |  iteration: 5380 teacher: 0 stage: sketch lr: 0.000603\n",
      "batch 408 loss: 0.25355 acc: 0.92578 | v_loss: 0.43198 v_acc: 0.90267 |  iteration: 5381 teacher: 1 stage: sketch lr: 0.000602\n",
      "batch 409 loss: 0.21243 acc: 0.93913 | v_loss: 0.77370 v_acc: 0.83952 |  iteration: 5382 teacher: 1 stage: sketch lr: 0.000602\n",
      "batch 410 loss: 0.26256 acc: 0.92643 | v_loss: 0.57030 v_acc: 0.87793 |  iteration: 5383 teacher: 1 stage: sketch lr: 0.000602\n",
      "batch 411 loss: 0.22449 acc: 0.93685 | v_loss: 0.54638 v_acc: 0.86979 |  iteration: 5384 teacher: 1 stage: sketch lr: 0.000602\n",
      "batch 412 loss: 0.29564 acc: 0.92318 | v_loss: 0.54245 v_acc: 0.87012 |  iteration: 5385 teacher: 1 stage: sketch lr: 0.000602\n",
      "batch 413 loss: 0.24794 acc: 0.92155 | v_loss: 0.45518 v_acc: 0.89388 |  iteration: 5386 teacher: 1 stage: sketch lr: 0.000602\n",
      "batch 414 loss: 0.25738 acc: 0.92090 | v_loss: 0.44246 v_acc: 0.89681 |  iteration: 5387 teacher: 0 stage: sketch lr: 0.000602\n",
      "batch 415 loss: 0.28145 acc: 0.91960 | v_loss: 0.50974 v_acc: 0.88770 |  iteration: 5388 teacher: 1 stage: sketch lr: 0.000602\n",
      "batch 416 loss: 0.27320 acc: 0.91602 | v_loss: 0.59325 v_acc: 0.86230 |  iteration: 5389 teacher: 1 stage: sketch lr: 0.000602\n",
      "batch 417 loss: 0.28517 acc: 0.91374 | v_loss: 0.54991 v_acc: 0.89355 |  iteration: 5390 teacher: 0 stage: sketch lr: 0.000602\n",
      "batch 418 loss: 0.26041 acc: 0.92611 | v_loss: 0.57107 v_acc: 0.88444 |  iteration: 5391 teacher: 1 stage: sketch lr: 0.000602\n",
      "batch 419 loss: 0.27741 acc: 0.91829 | v_loss: 0.37776 v_acc: 0.91341 |  iteration: 5392 teacher: 0 stage: sketch lr: 0.000602\n",
      "batch 420 loss: 0.20993 acc: 0.93685 | v_loss: 0.52199 v_acc: 0.88770 |  iteration: 5393 teacher: 1 stage: sketch lr: 0.000602\n",
      "batch 421 loss: 0.31142 acc: 0.90592 | v_loss: 0.50061 v_acc: 0.88379 |  iteration: 5394 teacher: 0 stage: sketch lr: 0.000602\n",
      "batch 422 loss: 0.22532 acc: 0.93490 | v_loss: 0.90764 v_acc: 0.83171 |  iteration: 5395 teacher: 1 stage: sketch lr: 0.000602\n",
      "batch 423 loss: 0.29797 acc: 0.91960 | v_loss: 0.35990 v_acc: 0.90983 |  iteration: 5396 teacher: 0 stage: sketch lr: 0.000602\n",
      "batch 424 loss: 0.23196 acc: 0.92546 | v_loss: 0.30347 v_acc: 0.92741 |  iteration: 5397 teacher: 0 stage: sketch lr: 0.000602\n",
      "batch 425 loss: 0.27687 acc: 0.92318 | v_loss: 0.60094 v_acc: 0.88118 |  iteration: 5398 teacher: 1 stage: sketch lr: 0.000602\n",
      "batch 426 loss: 0.20908 acc: 0.93685 | v_loss: 0.57414 v_acc: 0.87988 |  iteration: 5399 teacher: 0 stage: sketch lr: 0.000601\n",
      "batch 427 loss: 0.34018 acc: 0.90592 | v_loss: 0.64594 v_acc: 0.86719 |  iteration: 5400 teacher: 0 stage: sketch lr: 0.000601\n",
      "batch 428 loss: 0.30884 acc: 0.91471 | v_loss: 0.44969 v_acc: 0.90137 |  iteration: 5401 teacher: 1 stage: sketch lr: 0.000601\n",
      "batch 429 loss: 0.24002 acc: 0.93294 | v_loss: 0.50671 v_acc: 0.87174 |  iteration: 5402 teacher: 1 stage: sketch lr: 0.000601\n",
      "batch 430 loss: 0.37002 acc: 0.89811 | v_loss: 0.60783 v_acc: 0.85938 |  iteration: 5403 teacher: 0 stage: sketch lr: 0.000601\n",
      "batch 431 loss: 0.36388 acc: 0.89453 | v_loss: 0.61856 v_acc: 0.85807 |  iteration: 5404 teacher: 0 stage: sketch lr: 0.000601\n",
      "batch 432 loss: 0.31854 acc: 0.91146 | v_loss: 0.45558 v_acc: 0.89974 |  iteration: 5405 teacher: 0 stage: sketch lr: 0.000601\n",
      "batch 433 loss: 0.32727 acc: 0.90755 | v_loss: 0.37919 v_acc: 0.90072 |  iteration: 5406 teacher: 1 stage: sketch lr: 0.000601\n",
      "batch 434 loss: 0.23465 acc: 0.93327 | v_loss: 0.30031 v_acc: 0.91992 |  iteration: 5407 teacher: 1 stage: sketch lr: 0.000601\n",
      "batch 435 loss: 0.25589 acc: 0.92708 | v_loss: 0.44231 v_acc: 0.90202 |  iteration: 5408 teacher: 1 stage: sketch lr: 0.000601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 436 loss: 0.31716 acc: 0.91276 | v_loss: 0.51832 v_acc: 0.88118 |  iteration: 5409 teacher: 1 stage: sketch lr: 0.000601\n",
      "batch 437 loss: 0.26641 acc: 0.92611 | v_loss: 0.79679 v_acc: 0.86100 |  iteration: 5410 teacher: 1 stage: sketch lr: 0.000601\n",
      "batch 438 loss: 0.26955 acc: 0.92188 | v_loss: 0.51167 v_acc: 0.88672 |  iteration: 5411 teacher: 1 stage: sketch lr: 0.000601\n",
      "batch 439 loss: 0.23775 acc: 0.92480 | v_loss: 0.68300 v_acc: 0.86458 |  iteration: 5412 teacher: 0 stage: sketch lr: 0.000601\n",
      "batch 440 loss: 0.26543 acc: 0.92448 | v_loss: 0.44764 v_acc: 0.89779 |  iteration: 5413 teacher: 0 stage: sketch lr: 0.000601\n",
      "batch 441 loss: 0.21321 acc: 0.93717 | v_loss: 0.57717 v_acc: 0.88346 |  iteration: 5414 teacher: 1 stage: sketch lr: 0.000601\n",
      "batch 442 loss: 0.28954 acc: 0.92057 | v_loss: 0.79674 v_acc: 0.84115 |  iteration: 5415 teacher: 1 stage: sketch lr: 0.000601\n",
      "batch 443 loss: 0.30297 acc: 0.91667 | v_loss: 0.54249 v_acc: 0.89290 |  iteration: 5416 teacher: 1 stage: sketch lr: 0.000601\n",
      "batch 444 loss: 0.23944 acc: 0.93392 | v_loss: 0.51495 v_acc: 0.88477 |  iteration: 5417 teacher: 0 stage: sketch lr: 0.000600\n",
      "batch 445 loss: 0.24640 acc: 0.92741 | v_loss: 0.52362 v_acc: 0.88118 |  iteration: 5418 teacher: 0 stage: sketch lr: 0.000600\n",
      "batch 446 loss: 0.29195 acc: 0.91634 | v_loss: 0.41140 v_acc: 0.90397 |  iteration: 5419 teacher: 0 stage: sketch lr: 0.000600\n",
      "batch 447 loss: 0.23186 acc: 0.92806 | v_loss: 0.47643 v_acc: 0.89583 |  iteration: 5420 teacher: 0 stage: sketch lr: 0.000600\n",
      "batch 448 loss: 0.25325 acc: 0.92480 | v_loss: 0.62445 v_acc: 0.86328 |  iteration: 5421 teacher: 0 stage: sketch lr: 0.000600\n",
      "batch 449 loss: 0.28953 acc: 0.91048 | v_loss: 0.37007 v_acc: 0.91699 |  iteration: 5422 teacher: 0 stage: sketch lr: 0.000600\n",
      "batch 450 loss: 0.24614 acc: 0.92513 | v_loss: 0.96154 v_acc: 0.82129 |  iteration: 5423 teacher: 1 stage: sketch lr: 0.000600\n",
      "batch 451 loss: 0.22361 acc: 0.93587 | v_loss: 0.63795 v_acc: 0.87435 |  iteration: 5424 teacher: 0 stage: sketch lr: 0.000600\n",
      "batch 452 loss: 0.26559 acc: 0.91764 | v_loss: 0.70921 v_acc: 0.85742 |  iteration: 5425 teacher: 0 stage: sketch lr: 0.000600\n",
      "batch 453 loss: 0.26887 acc: 0.92090 | v_loss: 0.53160 v_acc: 0.89095 |  iteration: 5426 teacher: 0 stage: sketch lr: 0.000600\n",
      "batch 454 loss: 0.28697 acc: 0.91699 | v_loss: 0.49203 v_acc: 0.89453 |  iteration: 5427 teacher: 0 stage: sketch lr: 0.000600\n",
      "batch 455 loss: 0.28837 acc: 0.91048 | v_loss: 0.57845 v_acc: 0.88965 |  iteration: 5428 teacher: 0 stage: sketch lr: 0.000600\n",
      "batch 456 loss: 0.36256 acc: 0.89486 | v_loss: 0.53151 v_acc: 0.89160 |  iteration: 5429 teacher: 1 stage: sketch lr: 0.000600\n",
      "batch 457 loss: 0.19029 acc: 0.94303 | v_loss: 0.51188 v_acc: 0.89225 |  iteration: 5430 teacher: 1 stage: sketch lr: 0.000600\n",
      "batch 458 loss: 0.23194 acc: 0.93490 | v_loss: 0.50774 v_acc: 0.90104 |  iteration: 5431 teacher: 0 stage: sketch lr: 0.000600\n",
      "batch 459 loss: 0.35773 acc: 0.89974 | v_loss: 0.46033 v_acc: 0.89974 |  iteration: 5432 teacher: 1 stage: sketch lr: 0.000600\n",
      "batch 460 loss: 0.25333 acc: 0.92806 | v_loss: 0.33157 v_acc: 0.92090 |  iteration: 5433 teacher: 0 stage: sketch lr: 0.000600\n",
      "batch 461 loss: 0.31030 acc: 0.91406 | v_loss: 0.61286 v_acc: 0.86133 |  iteration: 5434 teacher: 1 stage: sketch lr: 0.000600\n",
      "batch 462 loss: 0.32790 acc: 0.91862 | v_loss: 0.53720 v_acc: 0.87012 |  iteration: 5435 teacher: 1 stage: sketch lr: 0.000599\n",
      "batch 463 loss: 0.32039 acc: 0.90234 | v_loss: 0.57325 v_acc: 0.86784 |  iteration: 5436 teacher: 0 stage: sketch lr: 0.000599\n",
      "batch 464 loss: 0.22932 acc: 0.93034 | v_loss: 0.79584 v_acc: 0.83822 |  iteration: 5437 teacher: 0 stage: sketch lr: 0.000599\n",
      "batch 465 loss: 0.22856 acc: 0.93197 | v_loss: 0.39859 v_acc: 0.90951 |  iteration: 5438 teacher: 1 stage: sketch lr: 0.000599\n",
      "batch 466 loss: 0.26413 acc: 0.91927 | v_loss: 0.54651 v_acc: 0.87402 |  iteration: 5439 teacher: 0 stage: sketch lr: 0.000599\n",
      "batch 467 loss: 0.27387 acc: 0.92122 | v_loss: 0.50914 v_acc: 0.89746 |  iteration: 5440 teacher: 0 stage: sketch lr: 0.000599\n",
      "batch 468 loss: 0.24976 acc: 0.92220 | v_loss: 0.43703 v_acc: 0.90527 |  iteration: 5441 teacher: 0 stage: sketch lr: 0.000599\n",
      "batch 469 loss: 0.24877 acc: 0.93197 | v_loss: 1.18079 v_acc: 0.81120 |  iteration: 5442 teacher: 1 stage: sketch lr: 0.000599\n",
      "batch 470 loss: 0.19739 acc: 0.93848 | v_loss: 0.37847 v_acc: 0.91732 |  iteration: 5443 teacher: 1 stage: sketch lr: 0.000599\n",
      "batch 471 loss: 0.33085 acc: 0.90592 | v_loss: 0.57684 v_acc: 0.87793 |  iteration: 5444 teacher: 0 stage: sketch lr: 0.000599\n",
      "batch 472 loss: 0.25219 acc: 0.93132 | v_loss: 0.53967 v_acc: 0.89941 |  iteration: 5445 teacher: 1 stage: sketch lr: 0.000599\n",
      "batch 473 loss: 0.25371 acc: 0.92773 | v_loss: 0.43101 v_acc: 0.90365 |  iteration: 5446 teacher: 1 stage: sketch lr: 0.000599\n",
      "batch 474 loss: 0.20794 acc: 0.94043 | v_loss: 0.48455 v_acc: 0.89290 |  iteration: 5447 teacher: 0 stage: sketch lr: 0.000599\n",
      "batch 475 loss: 0.25368 acc: 0.92741 | v_loss: 0.56852 v_acc: 0.87467 |  iteration: 5448 teacher: 0 stage: sketch lr: 0.000599\n",
      "batch 476 loss: 0.19719 acc: 0.93652 | v_loss: 0.45214 v_acc: 0.90885 |  iteration: 5449 teacher: 0 stage: sketch lr: 0.000599\n",
      "batch 477 loss: 0.38254 acc: 0.89583 | v_loss: 0.63690 v_acc: 0.86589 |  iteration: 5450 teacher: 1 stage: sketch lr: 0.000599\n",
      "batch 478 loss: 0.25927 acc: 0.92383 | v_loss: 0.39497 v_acc: 0.90820 |  iteration: 5451 teacher: 1 stage: sketch lr: 0.000599\n",
      "batch 479 loss: 0.23761 acc: 0.93294 | v_loss: 0.97637 v_acc: 0.82454 |  iteration: 5452 teacher: 0 stage: sketch lr: 0.000599\n",
      "batch 480 loss: 0.25570 acc: 0.92546 | v_loss: 0.60597 v_acc: 0.88672 |  iteration: 5453 teacher: 1 stage: sketch lr: 0.000598\n",
      "batch 481 loss: 0.25630 acc: 0.92708 | v_loss: 0.66473 v_acc: 0.86458 |  iteration: 5454 teacher: 1 stage: sketch lr: 0.000598\n",
      "batch 482 loss: 0.24219 acc: 0.92513 | v_loss: 0.43103 v_acc: 0.90202 |  iteration: 5455 teacher: 1 stage: sketch lr: 0.000598\n",
      "batch 483 loss: 0.31779 acc: 0.91178 | v_loss: 0.67436 v_acc: 0.85775 |  iteration: 5456 teacher: 0 stage: sketch lr: 0.000598\n",
      "batch 484 loss: 0.35074 acc: 0.91797 | v_loss: 0.46817 v_acc: 0.90267 |  iteration: 5457 teacher: 1 stage: sketch lr: 0.000598\n",
      "batch 485 loss: 0.32741 acc: 0.90690 | v_loss: 0.46735 v_acc: 0.90104 |  iteration: 5458 teacher: 1 stage: sketch lr: 0.000598\n",
      "batch 486 loss: 0.27151 acc: 0.91764 | v_loss: 0.45671 v_acc: 0.89421 |  iteration: 5459 teacher: 1 stage: sketch lr: 0.000598\n",
      "batch 487 loss: 0.26649 acc: 0.92708 | v_loss: 0.73666 v_acc: 0.86296 |  iteration: 5460 teacher: 1 stage: sketch lr: 0.000598\n",
      "batch 488 loss: 0.30695 acc: 0.92057 | v_loss: 0.53034 v_acc: 0.89225 |  iteration: 5461 teacher: 1 stage: sketch lr: 0.000598\n",
      "batch 489 loss: 0.29057 acc: 0.91471 | v_loss: 0.49116 v_acc: 0.88932 |  iteration: 5462 teacher: 1 stage: sketch lr: 0.000598\n",
      "batch 490 loss: 0.24563 acc: 0.93294 | v_loss: 0.62717 v_acc: 0.86686 |  iteration: 5463 teacher: 1 stage: sketch lr: 0.000598\n",
      "batch 491 loss: 0.26341 acc: 0.91406 | v_loss: 0.46933 v_acc: 0.89095 |  iteration: 5464 teacher: 1 stage: sketch lr: 0.000598\n",
      "batch 492 loss: 0.32377 acc: 0.90885 | v_loss: 0.51334 v_acc: 0.86979 |  iteration: 5465 teacher: 0 stage: sketch lr: 0.000598\n",
      "batch 493 loss: 0.20124 acc: 0.94173 | v_loss: 0.54190 v_acc: 0.86784 |  iteration: 5466 teacher: 1 stage: sketch lr: 0.000598\n",
      "batch 494 loss: 0.28241 acc: 0.91895 | v_loss: 0.69231 v_acc: 0.85352 |  iteration: 5467 teacher: 1 stage: sketch lr: 0.000598\n",
      "batch 495 loss: 0.31478 acc: 0.90788 | v_loss: 0.55799 v_acc: 0.87663 |  iteration: 5468 teacher: 1 stage: sketch lr: 0.000598\n",
      "batch 496 loss: 0.30552 acc: 0.91178 | v_loss: 0.60348 v_acc: 0.88118 |  iteration: 5469 teacher: 0 stage: sketch lr: 0.000598\n",
      "batch 497 loss: 0.22834 acc: 0.93424 | v_loss: 0.66834 v_acc: 0.87728 |  iteration: 5470 teacher: 1 stage: sketch lr: 0.000598\n",
      "batch 498 loss: 0.23669 acc: 0.93164 | v_loss: 0.57185 v_acc: 0.86491 |  iteration: 5471 teacher: 0 stage: sketch lr: 0.000597\n",
      "batch 499 loss: 0.25562 acc: 0.91569 | v_loss: 0.41110 v_acc: 0.90853 |  iteration: 5472 teacher: 0 stage: sketch lr: 0.000597\n",
      "batch 500 loss: 0.26313 acc: 0.92448 | v_loss: 0.80424 v_acc: 0.83887 |  iteration: 5473 teacher: 1 stage: sketch lr: 0.000597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 501 loss: 0.25997 acc: 0.93359 | v_loss: 0.62605 v_acc: 0.88477 |  iteration: 5474 teacher: 1 stage: sketch lr: 0.000597\n",
      "batch 502 loss: 0.37509 acc: 0.89290 | v_loss: 0.57015 v_acc: 0.87467 |  iteration: 5475 teacher: 0 stage: sketch lr: 0.000597\n",
      "batch 503 loss: 0.26568 acc: 0.93066 | v_loss: 0.57587 v_acc: 0.87826 |  iteration: 5476 teacher: 0 stage: sketch lr: 0.000597\n",
      "batch 504 loss: 0.23718 acc: 0.93783 | v_loss: 0.49301 v_acc: 0.88867 |  iteration: 5477 teacher: 1 stage: sketch lr: 0.000597\n",
      "batch 505 loss: 0.30520 acc: 0.92090 | v_loss: 0.46309 v_acc: 0.89258 |  iteration: 5478 teacher: 1 stage: sketch lr: 0.000597\n",
      "batch 506 loss: 0.33166 acc: 0.90983 | v_loss: 0.49621 v_acc: 0.88574 |  iteration: 5479 teacher: 0 stage: sketch lr: 0.000597\n",
      "batch 507 loss: 0.22321 acc: 0.92578 | v_loss: 0.57042 v_acc: 0.85938 |  iteration: 5480 teacher: 0 stage: sketch lr: 0.000597\n",
      "batch 508 loss: 0.31113 acc: 0.91113 | v_loss: 0.53423 v_acc: 0.88997 |  iteration: 5481 teacher: 0 stage: sketch lr: 0.000597\n",
      "batch 509 loss: 0.34412 acc: 0.89844 | v_loss: 0.57064 v_acc: 0.87956 |  iteration: 5482 teacher: 1 stage: sketch lr: 0.000597\n",
      "batch 510 loss: 0.22222 acc: 0.92415 | v_loss: 0.40138 v_acc: 0.89844 |  iteration: 5483 teacher: 1 stage: sketch lr: 0.000597\n",
      "batch 511 loss: 0.28172 acc: 0.91797 | v_loss: 0.57487 v_acc: 0.88053 |  iteration: 5484 teacher: 0 stage: sketch lr: 0.000597\n",
      "batch 512 loss: 0.28418 acc: 0.91471 | v_loss: 0.44494 v_acc: 0.89486 |  iteration: 5485 teacher: 0 stage: sketch lr: 0.000597\n",
      "batch 513 loss: 0.38536 acc: 0.89583 | v_loss: 0.88476 v_acc: 0.83301 |  iteration: 5486 teacher: 1 stage: sketch lr: 0.000597\n",
      "batch 514 loss: 0.26476 acc: 0.92448 | v_loss: 0.38775 v_acc: 0.90951 |  iteration: 5487 teacher: 0 stage: sketch lr: 0.000597\n",
      "batch 515 loss: 0.32071 acc: 0.90462 | v_loss: 0.32244 v_acc: 0.91862 |  iteration: 5488 teacher: 1 stage: sketch lr: 0.000597\n",
      "batch 516 loss: 0.33725 acc: 0.90983 | v_loss: 0.57974 v_acc: 0.88314 |  iteration: 5489 teacher: 1 stage: sketch lr: 0.000597\n",
      "batch 517 loss: 0.17668 acc: 0.95378 | v_loss: 0.54561 v_acc: 0.88639 |  iteration: 5490 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 518 loss: 0.29618 acc: 0.91927 | v_loss: 0.65471 v_acc: 0.85840 |  iteration: 5491 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 519 loss: 0.31026 acc: 0.91341 | v_loss: 0.39522 v_acc: 0.90755 |  iteration: 5492 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 520 loss: 0.35044 acc: 0.90039 | v_loss: 0.49457 v_acc: 0.87695 |  iteration: 5493 teacher: 0 stage: sketch lr: 0.000596\n",
      "batch 521 loss: 0.32653 acc: 0.89876 | v_loss: 0.61245 v_acc: 0.86654 |  iteration: 5494 teacher: 0 stage: sketch lr: 0.000596\n",
      "batch 522 loss: 0.25769 acc: 0.92253 | v_loss: 0.65682 v_acc: 0.84668 |  iteration: 5495 teacher: 0 stage: sketch lr: 0.000596\n",
      "batch 523 loss: 0.29860 acc: 0.91211 | v_loss: 0.46712 v_acc: 0.89355 |  iteration: 5496 teacher: 0 stage: sketch lr: 0.000596\n",
      "batch 524 loss: 0.28912 acc: 0.91536 | v_loss: 0.36590 v_acc: 0.90951 |  iteration: 5497 teacher: 0 stage: sketch lr: 0.000596\n",
      "batch 525 loss: 0.32334 acc: 0.90462 | v_loss: 0.33073 v_acc: 0.91764 |  iteration: 5498 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 526 loss: 0.29622 acc: 0.91471 | v_loss: 0.46508 v_acc: 0.90202 |  iteration: 5499 teacher: 0 stage: sketch lr: 0.000596\n",
      "batch 527 loss: 0.24400 acc: 0.92383 | v_loss: 0.50310 v_acc: 0.88574 |  iteration: 5500 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 528 loss: 0.34782 acc: 0.90462 | v_loss: 0.89269 v_acc: 0.85254 |  iteration: 5501 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 529 loss: 0.25749 acc: 0.93262 | v_loss: 0.59160 v_acc: 0.87174 |  iteration: 5502 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 530 loss: 0.23125 acc: 0.93034 | v_loss: 0.69856 v_acc: 0.86882 |  iteration: 5503 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 531 loss: 0.23716 acc: 0.93229 | v_loss: 0.41436 v_acc: 0.90267 |  iteration: 5504 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 532 loss: 0.20529 acc: 0.93685 | v_loss: 0.58801 v_acc: 0.87565 |  iteration: 5505 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 533 loss: 0.31654 acc: 0.91113 | v_loss: 0.78196 v_acc: 0.83854 |  iteration: 5506 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 534 loss: 0.29054 acc: 0.91309 | v_loss: 0.51183 v_acc: 0.89160 |  iteration: 5507 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 535 loss: 0.25350 acc: 0.93262 | v_loss: 0.50365 v_acc: 0.88802 |  iteration: 5508 teacher: 1 stage: sketch lr: 0.000595\n",
      "batch 536 loss: 0.30650 acc: 0.90788 | v_loss: 0.48564 v_acc: 0.88639 |  iteration: 5509 teacher: 0 stage: sketch lr: 0.000595\n",
      "batch 537 loss: 0.20576 acc: 0.93717 | v_loss: 0.41335 v_acc: 0.90397 |  iteration: 5510 teacher: 0 stage: sketch lr: 0.000595\n",
      "batch 538 loss: 0.37487 acc: 0.89714 | v_loss: 0.47733 v_acc: 0.90137 |  iteration: 5511 teacher: 1 stage: sketch lr: 0.000595\n",
      "batch 539 loss: 0.25120 acc: 0.92578 | v_loss: 0.53530 v_acc: 0.87793 |  iteration: 5512 teacher: 0 stage: sketch lr: 0.000595\n",
      "batch 540 loss: 0.25594 acc: 0.93034 | v_loss: 0.36334 v_acc: 0.92057 |  iteration: 5513 teacher: 1 stage: sketch lr: 0.000595\n",
      "batch 541 loss: 0.21984 acc: 0.93815 | v_loss: 0.94455 v_acc: 0.82324 |  iteration: 5514 teacher: 0 stage: sketch lr: 0.000595\n",
      "batch 542 loss: 0.33108 acc: 0.90267 | v_loss: 0.66434 v_acc: 0.87174 |  iteration: 5515 teacher: 0 stage: sketch lr: 0.000595\n",
      "batch 543 loss: 0.31681 acc: 0.90365 | v_loss: 0.67588 v_acc: 0.86556 |  iteration: 5516 teacher: 0 stage: sketch lr: 0.000595\n",
      "batch 544 loss: 0.26412 acc: 0.92122 | v_loss: 0.52145 v_acc: 0.89421 |  iteration: 5517 teacher: 0 stage: sketch lr: 0.000595\n",
      "batch 545 loss: 0.25426 acc: 0.91992 | v_loss: 0.47789 v_acc: 0.89421 |  iteration: 5518 teacher: 0 stage: sketch lr: 0.000595\n",
      "batch 546 loss: 0.18647 acc: 0.94043 | v_loss: 0.60454 v_acc: 0.89258 |  iteration: 5519 teacher: 1 stage: sketch lr: 0.000595\n",
      "batch 547 loss: 0.21632 acc: 0.93652 | v_loss: 0.51928 v_acc: 0.89681 |  iteration: 5520 teacher: 0 stage: sketch lr: 0.000595\n",
      "batch 548 loss: 0.31138 acc: 0.91243 | v_loss: 0.50069 v_acc: 0.89355 |  iteration: 5521 teacher: 1 stage: sketch lr: 0.000595\n",
      "batch 549 loss: 0.29716 acc: 0.91341 | v_loss: 0.49759 v_acc: 0.90007 |  iteration: 5522 teacher: 0 stage: sketch lr: 0.000595\n",
      "batch 550 loss: 0.27938 acc: 0.92448 | v_loss: 0.47638 v_acc: 0.89290 |  iteration: 5523 teacher: 1 stage: sketch lr: 0.000595\n",
      "batch 551 loss: 0.26381 acc: 0.92383 | v_loss: 0.40069 v_acc: 0.90885 |  iteration: 5524 teacher: 0 stage: sketch lr: 0.000595\n",
      "batch 552 loss: 0.26088 acc: 0.92871 | v_loss: 0.60545 v_acc: 0.85775 |  iteration: 5525 teacher: 1 stage: sketch lr: 0.000595\n",
      "batch 553 loss: 0.33056 acc: 0.90495 | v_loss: 0.53946 v_acc: 0.86361 |  iteration: 5526 teacher: 1 stage: sketch lr: 0.000595\n",
      "batch 554 loss: 0.27078 acc: 0.91504 | v_loss: 0.58172 v_acc: 0.86035 |  iteration: 5527 teacher: 0 stage: sketch lr: 0.000594\n",
      "batch 555 loss: 0.25600 acc: 0.92936 | v_loss: 0.80354 v_acc: 0.83724 |  iteration: 5528 teacher: 0 stage: sketch lr: 0.000594\n",
      "batch 556 loss: 0.27039 acc: 0.91211 | v_loss: 0.39500 v_acc: 0.90658 |  iteration: 5529 teacher: 0 stage: sketch lr: 0.000594\n",
      "batch 557 loss: 0.25223 acc: 0.92155 | v_loss: 0.57548 v_acc: 0.87956 |  iteration: 5530 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 558 loss: 0.29731 acc: 0.91439 | v_loss: 0.53737 v_acc: 0.89290 |  iteration: 5531 teacher: 0 stage: sketch lr: 0.000594\n",
      "batch 559 loss: 0.30246 acc: 0.91634 | v_loss: 0.43803 v_acc: 0.90658 |  iteration: 5532 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 560 loss: 0.20114 acc: 0.93685 | v_loss: 1.14441 v_acc: 0.81348 |  iteration: 5533 teacher: 0 stage: sketch lr: 0.000594\n",
      "batch 561 loss: 0.23802 acc: 0.93229 | v_loss: 0.40547 v_acc: 0.91243 |  iteration: 5534 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 562 loss: 0.24244 acc: 0.93327 | v_loss: 0.61767 v_acc: 0.87272 |  iteration: 5535 teacher: 0 stage: sketch lr: 0.000594\n",
      "batch 563 loss: 0.30554 acc: 0.91536 | v_loss: 0.53642 v_acc: 0.89323 |  iteration: 5536 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 564 loss: 0.22235 acc: 0.93587 | v_loss: 0.43733 v_acc: 0.90625 |  iteration: 5537 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 565 loss: 0.29037 acc: 0.91992 | v_loss: 0.52362 v_acc: 0.89290 |  iteration: 5538 teacher: 0 stage: sketch lr: 0.000594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 566 loss: 0.37335 acc: 0.89160 | v_loss: 0.60357 v_acc: 0.87467 |  iteration: 5539 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 567 loss: 0.22273 acc: 0.93490 | v_loss: 0.42876 v_acc: 0.90820 |  iteration: 5540 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 568 loss: 0.26998 acc: 0.91732 | v_loss: 0.63532 v_acc: 0.87142 |  iteration: 5541 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 569 loss: 0.27384 acc: 0.91536 | v_loss: 0.37001 v_acc: 0.90332 |  iteration: 5542 teacher: 0 stage: sketch lr: 0.000594\n",
      "batch 570 loss: 0.31069 acc: 0.90365 | v_loss: 0.99485 v_acc: 0.81348 |  iteration: 5543 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 571 loss: 0.24590 acc: 0.92155 | v_loss: 0.54764 v_acc: 0.88346 |  iteration: 5544 teacher: 0 stage: sketch lr: 0.000594\n",
      "batch 572 loss: 0.25684 acc: 0.93132 | v_loss: 0.69781 v_acc: 0.86003 |  iteration: 5545 teacher: 1 stage: sketch lr: 0.000593\n",
      "batch 573 loss: 0.31373 acc: 0.90885 | v_loss: 0.44094 v_acc: 0.89583 |  iteration: 5546 teacher: 0 stage: sketch lr: 0.000593\n",
      "batch 574 loss: 0.25563 acc: 0.92155 | v_loss: 0.63582 v_acc: 0.85417 |  iteration: 5547 teacher: 0 stage: sketch lr: 0.000593\n",
      "batch 575 loss: 0.22070 acc: 0.93490 | v_loss: 0.45997 v_acc: 0.89583 |  iteration: 5548 teacher: 1 stage: sketch lr: 0.000593\n",
      "batch 576 loss: 0.30913 acc: 0.90755 | v_loss: 0.47267 v_acc: 0.88835 |  iteration: 5549 teacher: 0 stage: sketch lr: 0.000593\n",
      "batch 577 loss: 0.35137 acc: 0.90527 | v_loss: 0.44176 v_acc: 0.88509 |  iteration: 5550 teacher: 1 stage: sketch lr: 0.000593\n",
      "batch 578 loss: 0.26384 acc: 0.92350 | v_loss: 0.77167 v_acc: 0.84603 |  iteration: 5551 teacher: 0 stage: sketch lr: 0.000593\n",
      "batch 579 loss: 0.40453 acc: 0.88704 | v_loss: 0.53878 v_acc: 0.89355 |  iteration: 5552 teacher: 0 stage: sketch lr: 0.000593\n",
      "batch 580 loss: 0.27954 acc: 0.92155 | v_loss: 0.51313 v_acc: 0.88053 |  iteration: 5553 teacher: 0 stage: sketch lr: 0.000593\n",
      "batch 581 loss: 0.25423 acc: 0.92904 | v_loss: 0.63946 v_acc: 0.86230 |  iteration: 5554 teacher: 0 stage: sketch lr: 0.000593\n",
      "batch 582 loss: 0.36394 acc: 0.90299 | v_loss: 0.43358 v_acc: 0.89616 |  iteration: 5555 teacher: 0 stage: sketch lr: 0.000593\n",
      "batch 583 loss: 0.32103 acc: 0.90755 | v_loss: 0.49180 v_acc: 0.87663 |  iteration: 5556 teacher: 0 stage: sketch lr: 0.000593\n",
      "batch 584 loss: 0.25971 acc: 0.92904 | v_loss: 0.55489 v_acc: 0.87174 |  iteration: 5557 teacher: 1 stage: sketch lr: 0.000593\n",
      "batch 585 loss: 0.27008 acc: 0.92057 | v_loss: 0.71284 v_acc: 0.85514 |  iteration: 5558 teacher: 0 stage: sketch lr: 0.000593\n",
      "batch 586 loss: 0.27047 acc: 0.92448 | v_loss: 0.60010 v_acc: 0.88184 |  iteration: 5559 teacher: 0 stage: sketch lr: 0.000593\n",
      "batch 587 loss: 0.29531 acc: 0.90332 | v_loss: 0.58190 v_acc: 0.88216 |  iteration: 5560 teacher: 0 stage: sketch lr: 0.000593\n",
      "batch 588 loss: 0.26557 acc: 0.92350 | v_loss: 0.65161 v_acc: 0.87207 |  iteration: 5561 teacher: 1 stage: sketch lr: 0.000593\n",
      "batch 589 loss: 0.30006 acc: 0.91439 | v_loss: 0.59272 v_acc: 0.86361 |  iteration: 5562 teacher: 1 stage: sketch lr: 0.000593\n",
      "batch 590 loss: 0.41316 acc: 0.88021 | v_loss: 0.46115 v_acc: 0.89551 |  iteration: 5563 teacher: 1 stage: sketch lr: 0.000593\n",
      "batch 591 loss: 0.34195 acc: 0.89551 | v_loss: 0.78071 v_acc: 0.84570 |  iteration: 5564 teacher: 0 stage: sketch lr: 0.000592\n",
      "batch 592 loss: 0.29918 acc: 0.91439 | v_loss: 0.57623 v_acc: 0.87891 |  iteration: 5565 teacher: 0 stage: sketch lr: 0.000592\n",
      "batch 593 loss: 0.31397 acc: 0.90690 | v_loss: 0.57639 v_acc: 0.86849 |  iteration: 5566 teacher: 1 stage: sketch lr: 0.000592\n",
      "batch 594 loss: 0.30370 acc: 0.92090 | v_loss: 0.58602 v_acc: 0.87663 |  iteration: 5567 teacher: 1 stage: sketch lr: 0.000592\n",
      "batch 595 loss: 0.25682 acc: 0.92546 | v_loss: 0.46405 v_acc: 0.89551 |  iteration: 5568 teacher: 0 stage: sketch lr: 0.000592\n",
      "batch 596 loss: 0.28866 acc: 0.91992 | v_loss: 0.47116 v_acc: 0.89421 |  iteration: 5569 teacher: 1 stage: sketch lr: 0.000592\n",
      "batch 597 loss: 0.23735 acc: 0.92220 | v_loss: 0.55339 v_acc: 0.87695 |  iteration: 5570 teacher: 1 stage: sketch lr: 0.000592\n",
      "batch 598 loss: 0.19624 acc: 0.94206 | v_loss: 0.62203 v_acc: 0.84961 |  iteration: 5571 teacher: 1 stage: sketch lr: 0.000592\n",
      "batch 599 loss: 0.34895 acc: 0.89844 | v_loss: 0.57146 v_acc: 0.88542 |  iteration: 5572 teacher: 0 stage: sketch lr: 0.000592\n",
      "batch 600 loss: 0.27344 acc: 0.92122 | v_loss: 0.59134 v_acc: 0.88184 |  iteration: 5573 teacher: 1 stage: sketch lr: 0.000592\n",
      "batch 601 loss: 0.30015 acc: 0.91211 | v_loss: 0.36521 v_acc: 0.91634 |  iteration: 5574 teacher: 0 stage: sketch lr: 0.000592\n",
      "batch 602 loss: 0.23632 acc: 0.92806 | v_loss: 0.53042 v_acc: 0.88249 |  iteration: 5575 teacher: 1 stage: sketch lr: 0.000592\n",
      "batch 603 loss: 0.25422 acc: 0.91667 | v_loss: 0.50282 v_acc: 0.88965 |  iteration: 5576 teacher: 0 stage: sketch lr: 0.000592\n",
      "batch 604 loss: 0.25048 acc: 0.92448 | v_loss: 0.84718 v_acc: 0.82845 |  iteration: 5577 teacher: 1 stage: sketch lr: 0.000592\n",
      "batch 605 loss: 0.24448 acc: 0.92839 | v_loss: 0.34491 v_acc: 0.91178 |  iteration: 5578 teacher: 0 stage: sketch lr: 0.000592\n",
      "batch 606 loss: 0.27489 acc: 0.91895 | v_loss: 0.33263 v_acc: 0.92090 |  iteration: 5579 teacher: 0 stage: sketch lr: 0.000592\n",
      "batch 607 loss: 0.29455 acc: 0.91146 | v_loss: 0.57809 v_acc: 0.88184 |  iteration: 5580 teacher: 0 stage: sketch lr: 0.000592\n",
      "batch 608 loss: 0.25288 acc: 0.93587 | v_loss: 0.55330 v_acc: 0.89551 |  iteration: 5581 teacher: 1 stage: sketch lr: 0.000592\n",
      "batch 609 loss: 0.27967 acc: 0.92122 | v_loss: 0.65225 v_acc: 0.86654 |  iteration: 5582 teacher: 1 stage: sketch lr: 0.000592\n",
      "batch 610 loss: 0.23023 acc: 0.93490 | v_loss: 0.41336 v_acc: 0.90332 |  iteration: 5583 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 611 loss: 0.27401 acc: 0.91309 | v_loss: 0.50206 v_acc: 0.86979 |  iteration: 5584 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 612 loss: 0.27940 acc: 0.92253 | v_loss: 0.60913 v_acc: 0.86849 |  iteration: 5585 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 613 loss: 0.35546 acc: 0.89941 | v_loss: 0.64145 v_acc: 0.84766 |  iteration: 5586 teacher: 1 stage: sketch lr: 0.000591\n",
      "batch 614 loss: 0.21894 acc: 0.93522 | v_loss: 0.49456 v_acc: 0.89779 |  iteration: 5587 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 615 loss: 0.32198 acc: 0.90365 | v_loss: 0.36344 v_acc: 0.91146 |  iteration: 5588 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 616 loss: 0.19360 acc: 0.94857 | v_loss: 0.33871 v_acc: 0.91602 |  iteration: 5589 teacher: 1 stage: sketch lr: 0.000591\n",
      "batch 617 loss: 0.27824 acc: 0.92122 | v_loss: 0.46167 v_acc: 0.90332 |  iteration: 5590 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 618 loss: 0.42247 acc: 0.88379 | v_loss: 0.54443 v_acc: 0.88021 |  iteration: 5591 teacher: 1 stage: sketch lr: 0.000591\n",
      "batch 619 loss: 0.19835 acc: 0.93652 | v_loss: 0.83866 v_acc: 0.84993 |  iteration: 5592 teacher: 1 stage: sketch lr: 0.000591\n",
      "batch 620 loss: 0.24051 acc: 0.92415 | v_loss: 0.51118 v_acc: 0.88867 |  iteration: 5593 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 621 loss: 0.23469 acc: 0.93001 | v_loss: 0.65383 v_acc: 0.87012 |  iteration: 5594 teacher: 1 stage: sketch lr: 0.000591\n",
      "batch 622 loss: 0.23470 acc: 0.93197 | v_loss: 0.42333 v_acc: 0.90592 |  iteration: 5595 teacher: 1 stage: sketch lr: 0.000591\n",
      "batch 623 loss: 0.27000 acc: 0.92513 | v_loss: 0.52037 v_acc: 0.88509 |  iteration: 5596 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 624 loss: 0.26391 acc: 0.91992 | v_loss: 0.75904 v_acc: 0.84798 |  iteration: 5597 teacher: 1 stage: sketch lr: 0.000591\n",
      "batch 625 loss: 0.30728 acc: 0.91602 | v_loss: 0.52585 v_acc: 0.88542 |  iteration: 5598 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 626 loss: 0.32010 acc: 0.90430 | v_loss: 0.51962 v_acc: 0.89030 |  iteration: 5599 teacher: 1 stage: sketch lr: 0.000591\n",
      "batch 627 loss: 0.25949 acc: 0.92155 | v_loss: 0.49844 v_acc: 0.88184 |  iteration: 5600 teacher: 1 stage: sketch lr: 0.000591\n",
      "batch 628 loss: 0.16301 acc: 0.94954 | v_loss: 0.42607 v_acc: 0.90820 |  iteration: 5601 teacher: 1 stage: sketch lr: 0.000591\n",
      "batch 629 loss: 0.26469 acc: 0.92253 | v_loss: 0.44243 v_acc: 0.90918 |  iteration: 5602 teacher: 0 stage: sketch lr: 0.000590\n",
      "batch 630 loss: 0.21253 acc: 0.94173 | v_loss: 0.60361 v_acc: 0.86003 |  iteration: 5603 teacher: 1 stage: sketch lr: 0.000590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 631 loss: 0.16185 acc: 0.94889 | v_loss: 0.36198 v_acc: 0.91732 |  iteration: 5604 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 632 loss: 0.34143 acc: 0.90625 | v_loss: 0.93441 v_acc: 0.83040 |  iteration: 5605 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 633 loss: 0.20471 acc: 0.93848 | v_loss: 0.59896 v_acc: 0.87923 |  iteration: 5606 teacher: 0 stage: sketch lr: 0.000590\n",
      "batch 634 loss: 0.32543 acc: 0.90365 | v_loss: 0.70277 v_acc: 0.86068 |  iteration: 5607 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 635 loss: 0.19885 acc: 0.93978 | v_loss: 0.52928 v_acc: 0.88411 |  iteration: 5608 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 636 loss: 0.27822 acc: 0.92155 | v_loss: 0.52292 v_acc: 0.88346 |  iteration: 5609 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 637 loss: 0.22985 acc: 0.93066 | v_loss: 0.61447 v_acc: 0.87858 |  iteration: 5610 teacher: 0 stage: sketch lr: 0.000590\n",
      "batch 638 loss: 0.28193 acc: 0.92090 | v_loss: 0.51797 v_acc: 0.88509 |  iteration: 5611 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 639 loss: 0.28525 acc: 0.91178 | v_loss: 0.52325 v_acc: 0.87956 |  iteration: 5612 teacher: 0 stage: sketch lr: 0.000590\n",
      "batch 640 loss: 0.24582 acc: 0.93262 | v_loss: 0.53297 v_acc: 0.89225 |  iteration: 5613 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 641 loss: 0.32178 acc: 0.90527 | v_loss: 0.47268 v_acc: 0.89681 |  iteration: 5614 teacher: 0 stage: sketch lr: 0.000590\n",
      "batch 642 loss: 0.20352 acc: 0.93392 | v_loss: 0.33196 v_acc: 0.91667 |  iteration: 5615 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 643 loss: 0.22877 acc: 0.92969 | v_loss: 0.66801 v_acc: 0.85645 |  iteration: 5616 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 644 loss: 0.26270 acc: 0.92741 | v_loss: 0.56935 v_acc: 0.86816 |  iteration: 5617 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 645 loss: 0.35284 acc: 0.91146 | v_loss: 0.63354 v_acc: 0.86068 |  iteration: 5618 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 646 loss: 0.24339 acc: 0.92676 | v_loss: 0.82986 v_acc: 0.84310 |  iteration: 5619 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 647 loss: 0.22746 acc: 0.93750 | v_loss: 0.39699 v_acc: 0.90723 |  iteration: 5620 teacher: 0 stage: sketch lr: 0.000590\n",
      "batch 648 loss: 0.36234 acc: 0.90430 | v_loss: 0.55785 v_acc: 0.87956 |  iteration: 5621 teacher: 1 stage: sketch lr: 0.000589\n",
      "batch 649 loss: 0.24901 acc: 0.93392 | v_loss: 0.51416 v_acc: 0.88379 |  iteration: 5622 teacher: 1 stage: sketch lr: 0.000589\n",
      "batch 650 loss: 0.22603 acc: 0.93327 | v_loss: 0.40841 v_acc: 0.90723 |  iteration: 5623 teacher: 1 stage: sketch lr: 0.000589\n",
      "batch 651 loss: 0.26430 acc: 0.92513 | v_loss: 1.13815 v_acc: 0.80371 |  iteration: 5624 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 652 loss: 0.31271 acc: 0.91276 | v_loss: 0.37964 v_acc: 0.91439 |  iteration: 5625 teacher: 1 stage: sketch lr: 0.000589\n",
      "batch 653 loss: 0.31519 acc: 0.90755 | v_loss: 0.59098 v_acc: 0.87663 |  iteration: 5626 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 654 loss: 0.22221 acc: 0.92969 | v_loss: 0.51125 v_acc: 0.88867 |  iteration: 5627 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 655 loss: 0.29113 acc: 0.91146 | v_loss: 0.41776 v_acc: 0.90397 |  iteration: 5628 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 656 loss: 0.20151 acc: 0.93652 | v_loss: 0.47162 v_acc: 0.89941 |  iteration: 5629 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 657 loss: 0.25360 acc: 0.92350 | v_loss: 0.58186 v_acc: 0.87533 |  iteration: 5630 teacher: 1 stage: sketch lr: 0.000589\n",
      "batch 658 loss: 0.31892 acc: 0.90267 | v_loss: 0.42084 v_acc: 0.90658 |  iteration: 5631 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 659 loss: 0.24499 acc: 0.92415 | v_loss: 0.60989 v_acc: 0.87467 |  iteration: 5632 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 660 loss: 0.28202 acc: 0.91829 | v_loss: 0.39652 v_acc: 0.90788 |  iteration: 5633 teacher: 1 stage: sketch lr: 0.000589\n",
      "batch 661 loss: 0.27464 acc: 0.91699 | v_loss: 0.97837 v_acc: 0.82031 |  iteration: 5634 teacher: 1 stage: sketch lr: 0.000589\n",
      "batch 662 loss: 0.26537 acc: 0.92611 | v_loss: 0.62015 v_acc: 0.87793 |  iteration: 5635 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 663 loss: 0.29637 acc: 0.90625 | v_loss: 0.74087 v_acc: 0.86816 |  iteration: 5636 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 664 loss: 0.27177 acc: 0.92188 | v_loss: 0.43242 v_acc: 0.90072 |  iteration: 5637 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 665 loss: 0.27135 acc: 0.92025 | v_loss: 0.60831 v_acc: 0.87240 |  iteration: 5638 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 666 loss: 0.36449 acc: 0.89648 | v_loss: 0.44301 v_acc: 0.90169 |  iteration: 5639 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 667 loss: 0.21849 acc: 0.93945 | v_loss: 0.45408 v_acc: 0.89128 |  iteration: 5640 teacher: 0 stage: sketch lr: 0.000588\n",
      "batch 668 loss: 0.25678 acc: 0.92415 | v_loss: 0.44115 v_acc: 0.89355 |  iteration: 5641 teacher: 0 stage: sketch lr: 0.000588\n",
      "batch 669 loss: 0.27588 acc: 0.91602 | v_loss: 0.74365 v_acc: 0.84342 |  iteration: 5642 teacher: 0 stage: sketch lr: 0.000588\n",
      "batch 670 loss: 0.25180 acc: 0.92285 | v_loss: 0.47271 v_acc: 0.90202 |  iteration: 5643 teacher: 0 stage: sketch lr: 0.000588\n",
      "batch 671 loss: 0.23494 acc: 0.93066 | v_loss: 0.52647 v_acc: 0.88118 |  iteration: 5644 teacher: 1 stage: sketch lr: 0.000588\n",
      "batch 672 loss: 0.26063 acc: 0.92415 | v_loss: 0.63140 v_acc: 0.85807 |  iteration: 5645 teacher: 0 stage: sketch lr: 0.000588\n",
      "batch 673 loss: 0.23329 acc: 0.93848 | v_loss: 0.48027 v_acc: 0.88835 |  iteration: 5646 teacher: 1 stage: sketch lr: 0.000588\n",
      "batch 674 loss: 0.32632 acc: 0.91276 | v_loss: 0.52728 v_acc: 0.87207 |  iteration: 5647 teacher: 1 stage: sketch lr: 0.000588\n",
      "batch 675 loss: 0.26887 acc: 0.91569 | v_loss: 0.52269 v_acc: 0.86719 |  iteration: 5648 teacher: 1 stage: sketch lr: 0.000588\n",
      "batch 676 loss: 0.26838 acc: 0.92643 | v_loss: 0.72337 v_acc: 0.84993 |  iteration: 5649 teacher: 0 stage: sketch lr: 0.000588\n",
      "batch 677 loss: 0.21578 acc: 0.93262 | v_loss: 0.52106 v_acc: 0.88542 |  iteration: 5650 teacher: 1 stage: sketch lr: 0.000588\n",
      "batch 678 loss: 0.23788 acc: 0.93229 | v_loss: 0.57869 v_acc: 0.88086 |  iteration: 5651 teacher: 1 stage: sketch lr: 0.000588\n",
      "batch 679 loss: 0.26154 acc: 0.92448 | v_loss: 0.60766 v_acc: 0.87858 |  iteration: 5652 teacher: 0 stage: sketch lr: 0.000588\n",
      "batch 680 loss: 0.25379 acc: 0.92122 | v_loss: 0.59014 v_acc: 0.86003 |  iteration: 5653 teacher: 0 stage: sketch lr: 0.000588\n",
      "batch 681 loss: 0.23004 acc: 0.92839 | v_loss: 0.43527 v_acc: 0.90788 |  iteration: 5654 teacher: 0 stage: sketch lr: 0.000588\n",
      "batch 682 loss: 0.32040 acc: 0.91569 | v_loss: 0.75998 v_acc: 0.85547 |  iteration: 5655 teacher: 1 stage: sketch lr: 0.000588\n",
      "batch 683 loss: 0.28179 acc: 0.92253 | v_loss: 0.61761 v_acc: 0.87435 |  iteration: 5656 teacher: 1 stage: sketch lr: 0.000588\n",
      "batch 684 loss: 0.21462 acc: 0.93815 | v_loss: 0.60143 v_acc: 0.87044 |  iteration: 5657 teacher: 1 stage: sketch lr: 0.000588\n",
      "batch 685 loss: 0.38342 acc: 0.89648 | v_loss: 0.53544 v_acc: 0.87370 |  iteration: 5658 teacher: 0 stage: sketch lr: 0.000588\n",
      "batch 686 loss: 0.33476 acc: 0.90072 | v_loss: 0.46069 v_acc: 0.89616 |  iteration: 5659 teacher: 1 stage: sketch lr: 0.000587\n",
      "batch 687 loss: 0.26126 acc: 0.92188 | v_loss: 0.45280 v_acc: 0.89323 |  iteration: 5660 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 688 loss: 0.24505 acc: 0.93034 | v_loss: 0.50380 v_acc: 0.88477 |  iteration: 5661 teacher: 1 stage: sketch lr: 0.000587\n",
      "batch 689 loss: 0.27055 acc: 0.92025 | v_loss: 0.64200 v_acc: 0.84993 |  iteration: 5662 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 690 loss: 0.32568 acc: 0.90983 | v_loss: 0.60801 v_acc: 0.87760 |  iteration: 5663 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 691 loss: 0.25259 acc: 0.92806 | v_loss: 0.59019 v_acc: 0.88737 |  iteration: 5664 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 692 loss: 0.27436 acc: 0.91927 | v_loss: 0.37425 v_acc: 0.90234 |  iteration: 5665 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 693 loss: 0.29158 acc: 0.92025 | v_loss: 0.60004 v_acc: 0.87142 |  iteration: 5666 teacher: 1 stage: sketch lr: 0.000587\n",
      "batch 694 loss: 0.33725 acc: 0.90202 | v_loss: 0.50104 v_acc: 0.87630 |  iteration: 5667 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 695 loss: 0.30742 acc: 0.90723 | v_loss: 0.84971 v_acc: 0.82292 |  iteration: 5668 teacher: 0 stage: sketch lr: 0.000587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 696 loss: 0.30152 acc: 0.91569 | v_loss: 0.34612 v_acc: 0.90723 |  iteration: 5669 teacher: 1 stage: sketch lr: 0.000587\n",
      "batch 697 loss: 0.30736 acc: 0.91471 | v_loss: 0.31698 v_acc: 0.92350 |  iteration: 5670 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 698 loss: 0.29970 acc: 0.91927 | v_loss: 0.56243 v_acc: 0.88053 |  iteration: 5671 teacher: 1 stage: sketch lr: 0.000587\n",
      "batch 699 loss: 0.24749 acc: 0.92122 | v_loss: 0.56121 v_acc: 0.88672 |  iteration: 5672 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 700 loss: 0.28182 acc: 0.92611 | v_loss: 0.68992 v_acc: 0.85026 |  iteration: 5673 teacher: 1 stage: sketch lr: 0.000587\n",
      "batch 701 loss: 0.24259 acc: 0.92936 | v_loss: 0.46003 v_acc: 0.89648 |  iteration: 5674 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 702 loss: 0.44239 acc: 0.87240 | v_loss: 0.48502 v_acc: 0.87891 |  iteration: 5675 teacher: 1 stage: sketch lr: 0.000587\n",
      "batch 703 loss: 0.37400 acc: 0.89974 | v_loss: 0.56646 v_acc: 0.86947 |  iteration: 5676 teacher: 1 stage: sketch lr: 0.000587\n",
      "batch 704 loss: 0.22392 acc: 0.93620 | v_loss: 0.62752 v_acc: 0.85286 |  iteration: 5677 teacher: 1 stage: sketch lr: 0.000587\n",
      "batch 705 loss: 0.21801 acc: 0.93392 | v_loss: 0.50993 v_acc: 0.88965 |  iteration: 5678 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 706 loss: 0.25292 acc: 0.92871 | v_loss: 0.35785 v_acc: 0.91504 |  iteration: 5679 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 707 loss: 0.18144 acc: 0.95150 | v_loss: 0.28987 v_acc: 0.92188 |  iteration: 5680 teacher: 1 stage: sketch lr: 0.000586\n",
      "batch 708 loss: 0.32847 acc: 0.90820 | v_loss: 0.43144 v_acc: 0.90169 |  iteration: 5681 teacher: 1 stage: sketch lr: 0.000586\n",
      "batch 709 loss: 0.30119 acc: 0.91146 | v_loss: 0.49967 v_acc: 0.88216 |  iteration: 5682 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 710 loss: 0.27572 acc: 0.92546 | v_loss: 0.80268 v_acc: 0.86263 |  iteration: 5683 teacher: 1 stage: sketch lr: 0.000586\n",
      "batch 711 loss: 0.24880 acc: 0.92611 | v_loss: 0.50679 v_acc: 0.88444 |  iteration: 5684 teacher: 1 stage: sketch lr: 0.000586\n",
      "batch 712 loss: 0.19071 acc: 0.94303 | v_loss: 0.65397 v_acc: 0.87142 |  iteration: 5685 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 713 loss: 0.28181 acc: 0.91862 | v_loss: 0.43771 v_acc: 0.89876 |  iteration: 5686 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 714 loss: 0.33964 acc: 0.89876 | v_loss: 0.54183 v_acc: 0.88477 |  iteration: 5687 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 715 loss: 0.25101 acc: 0.93034 | v_loss: 0.71357 v_acc: 0.85449 |  iteration: 5688 teacher: 1 stage: sketch lr: 0.000586\n",
      "batch 716 loss: 0.22179 acc: 0.93848 | v_loss: 0.51531 v_acc: 0.89258 |  iteration: 5689 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 717 loss: 0.31888 acc: 0.90723 | v_loss: 0.49786 v_acc: 0.89030 |  iteration: 5690 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 718 loss: 0.23698 acc: 0.93294 | v_loss: 0.48726 v_acc: 0.87988 |  iteration: 5691 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 719 loss: 0.35836 acc: 0.89486 | v_loss: 0.44263 v_acc: 0.90365 |  iteration: 5692 teacher: 1 stage: sketch lr: 0.000586\n",
      "batch 720 loss: 0.23935 acc: 0.92806 | v_loss: 0.46724 v_acc: 0.90169 |  iteration: 5693 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 721 loss: 0.28844 acc: 0.91309 | v_loss: 0.60604 v_acc: 0.86393 |  iteration: 5694 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 722 loss: 0.29734 acc: 0.91146 | v_loss: 0.34106 v_acc: 0.92155 |  iteration: 5695 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 723 loss: 0.29301 acc: 0.91699 | v_loss: 0.93630 v_acc: 0.82194 |  iteration: 5696 teacher: 1 stage: sketch lr: 0.000586\n",
      "batch 724 loss: 0.23212 acc: 0.93587 | v_loss: 0.65518 v_acc: 0.87533 |  iteration: 5697 teacher: 1 stage: sketch lr: 0.000586\n",
      "batch 725 loss: 0.30293 acc: 0.91341 | v_loss: 0.68891 v_acc: 0.85840 |  iteration: 5698 teacher: 1 stage: sketch lr: 0.000585\n",
      "batch 726 loss: 0.24620 acc: 0.92708 | v_loss: 0.52129 v_acc: 0.89583 |  iteration: 5699 teacher: 1 stage: sketch lr: 0.000585\n",
      "batch 727 loss: 0.23246 acc: 0.93555 | v_loss: 0.48634 v_acc: 0.88574 |  iteration: 5700 teacher: 1 stage: sketch lr: 0.000585\n",
      "batch 728 loss: 0.29272 acc: 0.91439 | v_loss: 0.59848 v_acc: 0.87826 |  iteration: 5701 teacher: 0 stage: sketch lr: 0.000585\n",
      "batch 729 loss: 0.28469 acc: 0.92025 | v_loss: 0.49712 v_acc: 0.89030 |  iteration: 5702 teacher: 1 stage: sketch lr: 0.000585\n",
      "batch 730 loss: 0.36586 acc: 0.89876 | v_loss: 0.50978 v_acc: 0.89486 |  iteration: 5703 teacher: 1 stage: sketch lr: 0.000585\n",
      "batch 731 loss: 0.28755 acc: 0.91895 | v_loss: 0.50413 v_acc: 0.89583 |  iteration: 5704 teacher: 1 stage: sketch lr: 0.000585\n",
      "batch 732 loss: 0.38242 acc: 0.88509 | v_loss: 0.45804 v_acc: 0.88997 |  iteration: 5705 teacher: 1 stage: sketch lr: 0.000585\n",
      "batch 733 loss: 0.25548 acc: 0.92611 | v_loss: 0.35848 v_acc: 0.91439 |  iteration: 5706 teacher: 1 stage: sketch lr: 0.000585\n",
      "batch 734 loss: 0.20082 acc: 0.93815 | v_loss: 0.62855 v_acc: 0.86882 |  iteration: 5707 teacher: 0 stage: sketch lr: 0.000585\n",
      "batch 735 loss: 0.33630 acc: 0.90625 | v_loss: 0.58052 v_acc: 0.86589 |  iteration: 5708 teacher: 0 stage: sketch lr: 0.000585\n",
      "batch 736 loss: 0.29692 acc: 0.91699 | v_loss: 0.67491 v_acc: 0.86621 |  iteration: 5709 teacher: 1 stage: sketch lr: 0.000585\n",
      "batch 737 loss: 0.32297 acc: 0.91113 | v_loss: 0.86794 v_acc: 0.84668 |  iteration: 5710 teacher: 1 stage: sketch lr: 0.000585\n",
      "batch 738 loss: 0.28441 acc: 0.92708 | v_loss: 0.42386 v_acc: 0.91113 |  iteration: 5711 teacher: 1 stage: sketch lr: 0.000585\n",
      "batch 739 loss: 0.33707 acc: 0.91146 | v_loss: 0.54171 v_acc: 0.87988 |  iteration: 5712 teacher: 1 stage: sketch lr: 0.000585\n",
      "batch 740 loss: 0.29834 acc: 0.90853 | v_loss: 0.50349 v_acc: 0.88737 |  iteration: 5713 teacher: 0 stage: sketch lr: 0.000585\n",
      "batch 741 loss: 0.33205 acc: 0.89844 | v_loss: 0.44091 v_acc: 0.90430 |  iteration: 5714 teacher: 0 stage: sketch lr: 0.000585\n",
      "batch 742 loss: 0.25873 acc: 0.92253 | v_loss: 1.06172 v_acc: 0.79850 |  iteration: 5715 teacher: 0 stage: sketch lr: 0.000585\n",
      "batch 743 loss: 0.31135 acc: 0.90983 | v_loss: 0.37791 v_acc: 0.91439 |  iteration: 5716 teacher: 0 stage: sketch lr: 0.000585\n",
      "batch 744 loss: 0.24688 acc: 0.92773 | v_loss: 0.56231 v_acc: 0.87207 |  iteration: 5717 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 745 loss: 0.24593 acc: 0.93099 | v_loss: 0.49750 v_acc: 0.89128 |  iteration: 5718 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 746 loss: 0.23249 acc: 0.93066 | v_loss: 0.37457 v_acc: 0.91504 |  iteration: 5719 teacher: 1 stage: sketch lr: 0.000584\n",
      "batch 747 loss: 0.24703 acc: 0.92936 | v_loss: 0.47779 v_acc: 0.90072 |  iteration: 5720 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 748 loss: 0.27673 acc: 0.92057 | v_loss: 0.59318 v_acc: 0.87533 |  iteration: 5721 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 749 loss: 0.30289 acc: 0.91699 | v_loss: 0.42853 v_acc: 0.90820 |  iteration: 5722 teacher: 1 stage: sketch lr: 0.000584\n",
      "batch 750 loss: 0.29712 acc: 0.91960 | v_loss: 0.63607 v_acc: 0.87435 |  iteration: 5723 teacher: 1 stage: sketch lr: 0.000584\n",
      "batch 751 loss: 0.29088 acc: 0.92122 | v_loss: 0.38040 v_acc: 0.90332 |  iteration: 5724 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 752 loss: 0.31153 acc: 0.90690 | v_loss: 0.94824 v_acc: 0.81673 |  iteration: 5725 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 753 loss: 0.29767 acc: 0.92188 | v_loss: 0.56505 v_acc: 0.87760 |  iteration: 5726 teacher: 1 stage: sketch lr: 0.000584\n",
      "batch 754 loss: 0.27277 acc: 0.91439 | v_loss: 0.63031 v_acc: 0.86914 |  iteration: 5727 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 755 loss: 0.25082 acc: 0.92188 | v_loss: 0.41987 v_acc: 0.89811 |  iteration: 5728 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 756 loss: 0.29516 acc: 0.91211 | v_loss: 0.64659 v_acc: 0.86263 |  iteration: 5729 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 757 loss: 0.21867 acc: 0.93717 | v_loss: 0.42397 v_acc: 0.90267 |  iteration: 5730 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 758 loss: 0.29646 acc: 0.91406 | v_loss: 0.46788 v_acc: 0.89128 |  iteration: 5731 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 759 loss: 0.24942 acc: 0.92611 | v_loss: 0.43828 v_acc: 0.89583 |  iteration: 5732 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 760 loss: 0.31913 acc: 0.90658 | v_loss: 0.70168 v_acc: 0.86589 |  iteration: 5733 teacher: 0 stage: sketch lr: 0.000584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 761 loss: 0.25394 acc: 0.92643 | v_loss: 0.52052 v_acc: 0.89583 |  iteration: 5734 teacher: 1 stage: sketch lr: 0.000584\n",
      "batch 762 loss: 0.39374 acc: 0.88835 | v_loss: 0.50656 v_acc: 0.88770 |  iteration: 5735 teacher: 1 stage: sketch lr: 0.000584\n",
      "batch 763 loss: 0.25933 acc: 0.92448 | v_loss: 0.65953 v_acc: 0.86230 |  iteration: 5736 teacher: 1 stage: sketch lr: 0.000584\n",
      "batch 764 loss: 0.37274 acc: 0.89909 | v_loss: 0.44919 v_acc: 0.89648 |  iteration: 5737 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 765 loss: 0.22725 acc: 0.93164 | v_loss: 0.50331 v_acc: 0.87337 |  iteration: 5738 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 766 loss: 0.24386 acc: 0.92546 | v_loss: 0.51767 v_acc: 0.88118 |  iteration: 5739 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 767 loss: 0.27251 acc: 0.92057 | v_loss: 0.75950 v_acc: 0.85710 |  iteration: 5740 teacher: 0 stage: sketch lr: 0.000583\n",
      "batch 768 loss: 0.21724 acc: 0.93620 | v_loss: 0.53308 v_acc: 0.88704 |  iteration: 5741 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 769 loss: 0.26653 acc: 0.91829 | v_loss: 0.56810 v_acc: 0.89551 |  iteration: 5742 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 770 loss: 0.27135 acc: 0.92025 | v_loss: 0.61655 v_acc: 0.87891 |  iteration: 5743 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 771 loss: 0.20569 acc: 0.94141 | v_loss: 0.54448 v_acc: 0.86523 |  iteration: 5744 teacher: 0 stage: sketch lr: 0.000583\n",
      "batch 772 loss: 0.22967 acc: 0.93392 | v_loss: 0.41351 v_acc: 0.90658 |  iteration: 5745 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 773 loss: 0.24566 acc: 0.92253 | v_loss: 0.75548 v_acc: 0.84310 |  iteration: 5746 teacher: 0 stage: sketch lr: 0.000583\n",
      "batch 774 loss: 0.26953 acc: 0.92025 | v_loss: 0.54433 v_acc: 0.88704 |  iteration: 5747 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 775 loss: 0.26217 acc: 0.92057 | v_loss: 0.58487 v_acc: 0.86816 |  iteration: 5748 teacher: 0 stage: sketch lr: 0.000583\n",
      "batch 776 loss: 0.24482 acc: 0.92188 | v_loss: 0.52280 v_acc: 0.89030 |  iteration: 5749 teacher: 0 stage: sketch lr: 0.000583\n",
      "batch 777 loss: 0.29374 acc: 0.92155 | v_loss: 0.51209 v_acc: 0.89453 |  iteration: 5750 teacher: 0 stage: sketch lr: 0.000583\n",
      "batch 778 loss: 0.27038 acc: 0.91927 | v_loss: 0.45699 v_acc: 0.89909 |  iteration: 5751 teacher: 0 stage: sketch lr: 0.000583\n",
      "batch 779 loss: 0.28591 acc: 0.92578 | v_loss: 0.56004 v_acc: 0.88411 |  iteration: 5752 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 780 loss: 0.33557 acc: 0.91048 | v_loss: 0.61576 v_acc: 0.84733 |  iteration: 5753 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 781 loss: 0.29032 acc: 0.91732 | v_loss: 0.53730 v_acc: 0.88932 |  iteration: 5754 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 782 loss: 0.24375 acc: 0.93262 | v_loss: 0.59729 v_acc: 0.87435 |  iteration: 5755 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 783 loss: 0.28701 acc: 0.91667 | v_loss: 0.37272 v_acc: 0.91243 |  iteration: 5756 teacher: 0 stage: sketch lr: 0.000583\n",
      "batch 784 loss: 0.23313 acc: 0.93197 | v_loss: 0.57371 v_acc: 0.88574 |  iteration: 5757 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 785 loss: 0.26136 acc: 0.92643 | v_loss: 0.47822 v_acc: 0.88509 |  iteration: 5758 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 786 loss: 0.31794 acc: 0.90560 | v_loss: 0.91285 v_acc: 0.82943 |  iteration: 5759 teacher: 0 stage: sketch lr: 0.000582\n",
      "batch 787 loss: 0.23837 acc: 0.93359 | v_loss: 0.35887 v_acc: 0.91048 |  iteration: 5760 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 788 loss: 0.28827 acc: 0.92122 | v_loss: 0.30914 v_acc: 0.92513 |  iteration: 5761 teacher: 0 stage: sketch lr: 0.000582\n",
      "batch 789 loss: 0.34334 acc: 0.90137 | v_loss: 0.55837 v_acc: 0.88249 |  iteration: 5762 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 790 loss: 0.34742 acc: 0.89909 | v_loss: 0.52419 v_acc: 0.88346 |  iteration: 5763 teacher: 0 stage: sketch lr: 0.000582\n",
      "batch 791 loss: 0.18061 acc: 0.94661 | v_loss: 0.62423 v_acc: 0.85970 |  iteration: 5764 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 792 loss: 0.25670 acc: 0.91895 | v_loss: 0.43238 v_acc: 0.88477 |  iteration: 5765 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 793 loss: 0.34431 acc: 0.89681 | v_loss: 0.52686 v_acc: 0.86523 |  iteration: 5766 teacher: 0 stage: sketch lr: 0.000582\n",
      "batch 794 loss: 0.27700 acc: 0.91634 | v_loss: 0.56265 v_acc: 0.86979 |  iteration: 5767 teacher: 0 stage: sketch lr: 0.000582\n",
      "batch 795 loss: 0.25961 acc: 0.92350 | v_loss: 0.63914 v_acc: 0.85059 |  iteration: 5768 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 796 loss: 0.32736 acc: 0.89941 | v_loss: 0.49422 v_acc: 0.89095 |  iteration: 5769 teacher: 0 stage: sketch lr: 0.000582\n",
      "batch 797 loss: 0.31108 acc: 0.91341 | v_loss: 0.41670 v_acc: 0.89876 |  iteration: 5770 teacher: 0 stage: sketch lr: 0.000582\n",
      "batch 798 loss: 0.34321 acc: 0.90202 | v_loss: 0.28440 v_acc: 0.92773 |  iteration: 5771 teacher: 0 stage: sketch lr: 0.000582\n",
      "batch 799 loss: 0.23492 acc: 0.93848 | v_loss: 0.49723 v_acc: 0.90495 |  iteration: 5772 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 800 loss: 0.33849 acc: 0.90202 | v_loss: 0.58855 v_acc: 0.87598 |  iteration: 5773 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 801 loss: 0.30383 acc: 0.91634 | v_loss: 0.86498 v_acc: 0.84863 |  iteration: 5774 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 802 loss: 0.30432 acc: 0.91504 | v_loss: 0.53557 v_acc: 0.87207 |  iteration: 5775 teacher: 0 stage: sketch lr: 0.000582\n",
      "batch 803 loss: 0.28881 acc: 0.91829 | v_loss: 0.63876 v_acc: 0.87337 |  iteration: 5776 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 804 loss: 0.25104 acc: 0.92806 | v_loss: 0.40257 v_acc: 0.90723 |  iteration: 5777 teacher: 0 stage: sketch lr: 0.000581\n",
      "batch 805 loss: 0.30612 acc: 0.90918 | v_loss: 0.58184 v_acc: 0.87174 |  iteration: 5778 teacher: 0 stage: sketch lr: 0.000581\n",
      "batch 806 loss: 0.31245 acc: 0.90169 | v_loss: 0.74296 v_acc: 0.84538 |  iteration: 5779 teacher: 0 stage: sketch lr: 0.000581\n",
      "batch 807 loss: 0.25190 acc: 0.92383 | v_loss: 0.55716 v_acc: 0.88672 |  iteration: 5780 teacher: 0 stage: sketch lr: 0.000581\n",
      "batch 808 loss: 0.30519 acc: 0.91504 | v_loss: 0.50806 v_acc: 0.89453 |  iteration: 5781 teacher: 0 stage: sketch lr: 0.000581\n",
      "batch 809 loss: 0.27932 acc: 0.92383 | v_loss: 0.49631 v_acc: 0.88542 |  iteration: 5782 teacher: 1 stage: sketch lr: 0.000581\n",
      "batch 810 loss: 0.24812 acc: 0.92578 | v_loss: 0.40614 v_acc: 0.90658 |  iteration: 5783 teacher: 0 stage: sketch lr: 0.000581\n",
      "batch 811 loss: 0.28818 acc: 0.91927 | v_loss: 0.47786 v_acc: 0.89909 |  iteration: 5784 teacher: 1 stage: sketch lr: 0.000581\n",
      "batch 812 loss: 0.31016 acc: 0.91341 | v_loss: 0.56501 v_acc: 0.86979 |  iteration: 5785 teacher: 1 stage: sketch lr: 0.000581\n",
      "batch 813 loss: 0.28935 acc: 0.91146 | v_loss: 0.37935 v_acc: 0.91406 |  iteration: 5786 teacher: 1 stage: sketch lr: 0.000581\n",
      "batch 814 loss: 0.27552 acc: 0.92350 | v_loss: 0.92544 v_acc: 0.82812 |  iteration: 5787 teacher: 1 stage: sketch lr: 0.000581\n",
      "batch 815 loss: 0.27185 acc: 0.91374 | v_loss: 0.62595 v_acc: 0.87793 |  iteration: 5788 teacher: 0 stage: sketch lr: 0.000581\n",
      "batch 816 loss: 0.26768 acc: 0.92318 | v_loss: 0.69278 v_acc: 0.86426 |  iteration: 5789 teacher: 0 stage: sketch lr: 0.000581\n",
      "batch 817 loss: 0.24721 acc: 0.92578 | v_loss: 0.50558 v_acc: 0.90169 |  iteration: 5790 teacher: 0 stage: sketch lr: 0.000581\n",
      "batch 818 loss: 0.22734 acc: 0.93880 | v_loss: 0.50051 v_acc: 0.88997 |  iteration: 5791 teacher: 1 stage: sketch lr: 0.000581\n",
      "batch 819 loss: 0.26235 acc: 0.93164 | v_loss: 0.58134 v_acc: 0.88346 |  iteration: 5792 teacher: 1 stage: sketch lr: 0.000581\n",
      "batch 820 loss: 0.30593 acc: 0.91113 | v_loss: 0.48399 v_acc: 0.89974 |  iteration: 5793 teacher: 0 stage: sketch lr: 0.000581\n",
      "batch 821 loss: 0.30058 acc: 0.91178 | v_loss: 0.53267 v_acc: 0.88411 |  iteration: 5794 teacher: 1 stage: sketch lr: 0.000581\n",
      "batch 822 loss: 0.26088 acc: 0.92839 | v_loss: 0.51491 v_acc: 0.89844 |  iteration: 5795 teacher: 0 stage: sketch lr: 0.000581\n",
      "batch 823 loss: 0.31260 acc: 0.90527 | v_loss: 0.45791 v_acc: 0.89225 |  iteration: 5796 teacher: 0 stage: sketch lr: 0.000580\n",
      "batch 824 loss: 0.27321 acc: 0.91960 | v_loss: 0.33575 v_acc: 0.92285 |  iteration: 5797 teacher: 1 stage: sketch lr: 0.000580\n",
      "batch 825 loss: 0.19607 acc: 0.93978 | v_loss: 0.60330 v_acc: 0.86979 |  iteration: 5798 teacher: 0 stage: sketch lr: 0.000580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 826 loss: 0.23652 acc: 0.92708 | v_loss: 0.57081 v_acc: 0.86523 |  iteration: 5799 teacher: 0 stage: sketch lr: 0.000580\n",
      "batch 827 loss: 0.26702 acc: 0.91667 | v_loss: 0.62371 v_acc: 0.86523 |  iteration: 5800 teacher: 0 stage: sketch lr: 0.000580\n",
      "batch 828 loss: 0.23801 acc: 0.92285 | v_loss: 0.78666 v_acc: 0.84701 |  iteration: 5801 teacher: 0 stage: sketch lr: 0.000580\n",
      "batch 829 loss: 0.26886 acc: 0.92741 | v_loss: 0.39484 v_acc: 0.91081 |  iteration: 5802 teacher: 1 stage: sketch lr: 0.000580\n",
      "batch 830 loss: 0.24125 acc: 0.92350 | v_loss: 0.57098 v_acc: 0.87630 |  iteration: 5803 teacher: 0 stage: sketch lr: 0.000580\n",
      "batch 831 loss: 0.25423 acc: 0.92415 | v_loss: 0.47894 v_acc: 0.89518 |  iteration: 5804 teacher: 1 stage: sketch lr: 0.000580\n",
      "batch 832 loss: 0.19676 acc: 0.94271 | v_loss: 0.43023 v_acc: 0.90267 |  iteration: 5805 teacher: 0 stage: sketch lr: 0.000580\n",
      "batch 833 loss: 0.22273 acc: 0.93359 | v_loss: 1.16193 v_acc: 0.80859 |  iteration: 5806 teacher: 0 stage: sketch lr: 0.000580\n",
      "batch 834 loss: 0.35090 acc: 0.90495 | v_loss: 0.39057 v_acc: 0.91504 |  iteration: 5807 teacher: 1 stage: sketch lr: 0.000580\n",
      "batch 835 loss: 0.25717 acc: 0.92122 | v_loss: 0.60167 v_acc: 0.87793 |  iteration: 5808 teacher: 0 stage: sketch lr: 0.000580\n",
      "batch 836 loss: 0.24887 acc: 0.92839 | v_loss: 0.51228 v_acc: 0.89779 |  iteration: 5809 teacher: 0 stage: sketch lr: 0.000580\n",
      "batch 837 loss: 0.28468 acc: 0.91992 | v_loss: 0.43996 v_acc: 0.90039 |  iteration: 5810 teacher: 1 stage: sketch lr: 0.000580\n",
      "batch 838 loss: 0.25950 acc: 0.91960 | v_loss: 0.46247 v_acc: 0.89518 |  iteration: 5811 teacher: 1 stage: sketch lr: 0.000580\n",
      "batch 839 loss: 0.20031 acc: 0.93913 | v_loss: 0.55589 v_acc: 0.87435 |  iteration: 5812 teacher: 1 stage: sketch lr: 0.000580\n",
      "batch 840 loss: 0.26069 acc: 0.92904 | v_loss: 0.40226 v_acc: 0.91178 |  iteration: 5813 teacher: 0 stage: sketch lr: 0.000580\n",
      "batch 841 loss: 0.27331 acc: 0.91960 | v_loss: 0.65670 v_acc: 0.86914 |  iteration: 5814 teacher: 0 stage: sketch lr: 0.000580\n",
      "batch 842 loss: 0.26687 acc: 0.92513 | v_loss: 0.34724 v_acc: 0.91797 |  iteration: 5815 teacher: 1 stage: sketch lr: 0.000580\n",
      "batch 843 loss: 0.32629 acc: 0.90462 | v_loss: 0.98190 v_acc: 0.82454 |  iteration: 5816 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 844 loss: 0.32600 acc: 0.91406 | v_loss: 0.58127 v_acc: 0.88249 |  iteration: 5817 teacher: 0 stage: sketch lr: 0.000579\n",
      "batch 845 loss: 0.22205 acc: 0.93099 | v_loss: 0.67014 v_acc: 0.86719 |  iteration: 5818 teacher: 0 stage: sketch lr: 0.000579\n",
      "batch 846 loss: 0.24923 acc: 0.93164 | v_loss: 0.40694 v_acc: 0.90625 |  iteration: 5819 teacher: 0 stage: sketch lr: 0.000579\n",
      "batch 847 loss: 0.26175 acc: 0.91960 | v_loss: 0.65220 v_acc: 0.85514 |  iteration: 5820 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 848 loss: 0.34031 acc: 0.91992 | v_loss: 0.43978 v_acc: 0.89453 |  iteration: 5821 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 849 loss: 0.33002 acc: 0.90365 | v_loss: 0.46676 v_acc: 0.88867 |  iteration: 5822 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 850 loss: 0.27616 acc: 0.92188 | v_loss: 0.44742 v_acc: 0.89225 |  iteration: 5823 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 851 loss: 0.22448 acc: 0.93262 | v_loss: 0.69796 v_acc: 0.85221 |  iteration: 5824 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 852 loss: 0.26071 acc: 0.92741 | v_loss: 0.51337 v_acc: 0.89844 |  iteration: 5825 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 853 loss: 0.32429 acc: 0.90332 | v_loss: 0.52785 v_acc: 0.88184 |  iteration: 5826 teacher: 0 stage: sketch lr: 0.000579\n",
      "batch 854 loss: 0.23408 acc: 0.93490 | v_loss: 0.63810 v_acc: 0.86198 |  iteration: 5827 teacher: 0 stage: sketch lr: 0.000579\n",
      "batch 855 loss: 0.32883 acc: 0.90788 | v_loss: 0.47434 v_acc: 0.89160 |  iteration: 5828 teacher: 0 stage: sketch lr: 0.000579\n",
      "batch 856 loss: 0.28035 acc: 0.91862 | v_loss: 0.55574 v_acc: 0.86100 |  iteration: 5829 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 857 loss: 0.26580 acc: 0.92546 | v_loss: 0.54041 v_acc: 0.87435 |  iteration: 5830 teacher: 0 stage: sketch lr: 0.000579\n",
      "batch 858 loss: 0.30467 acc: 0.91374 | v_loss: 0.72336 v_acc: 0.85384 |  iteration: 5831 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 859 loss: 0.31171 acc: 0.91374 | v_loss: 0.56205 v_acc: 0.88477 |  iteration: 5832 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 860 loss: 0.24999 acc: 0.92969 | v_loss: 0.57444 v_acc: 0.88770 |  iteration: 5833 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 861 loss: 0.24034 acc: 0.93099 | v_loss: 0.69004 v_acc: 0.87370 |  iteration: 5834 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 862 loss: 0.28456 acc: 0.91536 | v_loss: 0.55083 v_acc: 0.87240 |  iteration: 5835 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 863 loss: 0.18647 acc: 0.94076 | v_loss: 0.46063 v_acc: 0.89746 |  iteration: 5836 teacher: 0 stage: sketch lr: 0.000579\n",
      "batch 864 loss: 0.24933 acc: 0.92676 | v_loss: 0.75474 v_acc: 0.84245 |  iteration: 5837 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 865 loss: 0.33528 acc: 0.90462 | v_loss: 0.54125 v_acc: 0.88314 |  iteration: 5838 teacher: 1 stage: sketch lr: 0.000578\n",
      "batch 866 loss: 0.24263 acc: 0.92708 | v_loss: 0.56000 v_acc: 0.87109 |  iteration: 5839 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 867 loss: 0.28202 acc: 0.91113 | v_loss: 0.52808 v_acc: 0.87500 |  iteration: 5840 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 868 loss: 0.27073 acc: 0.91927 | v_loss: 0.50660 v_acc: 0.88932 |  iteration: 5841 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 869 loss: 0.29250 acc: 0.92220 | v_loss: 0.45174 v_acc: 0.89648 |  iteration: 5842 teacher: 1 stage: sketch lr: 0.000578\n",
      "batch 870 loss: 0.28411 acc: 0.92318 | v_loss: 0.57645 v_acc: 0.88184 |  iteration: 5843 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 871 loss: 0.24266 acc: 0.92969 | v_loss: 0.58842 v_acc: 0.86068 |  iteration: 5844 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 872 loss: 0.26637 acc: 0.92904 | v_loss: 0.60264 v_acc: 0.88867 |  iteration: 5845 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 873 loss: 0.33616 acc: 0.90104 | v_loss: 0.58721 v_acc: 0.88249 |  iteration: 5846 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 874 loss: 0.31966 acc: 0.91146 | v_loss: 0.35501 v_acc: 0.91081 |  iteration: 5847 teacher: 1 stage: sketch lr: 0.000578\n",
      "batch 875 loss: 0.27589 acc: 0.92090 | v_loss: 0.53966 v_acc: 0.88216 |  iteration: 5848 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 876 loss: 0.25917 acc: 0.91732 | v_loss: 0.48513 v_acc: 0.87956 |  iteration: 5849 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 877 loss: 0.29548 acc: 0.91211 | v_loss: 0.86582 v_acc: 0.82487 |  iteration: 5850 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 878 loss: 0.28583 acc: 0.91341 | v_loss: 0.35053 v_acc: 0.91048 |  iteration: 5851 teacher: 1 stage: sketch lr: 0.000578\n",
      "batch 879 loss: 0.26656 acc: 0.92448 | v_loss: 0.27005 v_acc: 0.93457 |  iteration: 5852 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 880 loss: 0.27859 acc: 0.91960 | v_loss: 0.56311 v_acc: 0.88086 |  iteration: 5853 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 881 loss: 0.28942 acc: 0.91536 | v_loss: 0.53923 v_acc: 0.88607 |  iteration: 5854 teacher: 1 stage: sketch lr: 0.000578\n",
      "batch 882 loss: 0.31193 acc: 0.91146 | v_loss: 0.63267 v_acc: 0.86426 |  iteration: 5855 teacher: 1 stage: sketch lr: 0.000578\n",
      "batch 883 loss: 0.32594 acc: 0.90885 | v_loss: 0.42644 v_acc: 0.90560 |  iteration: 5856 teacher: 1 stage: sketch lr: 0.000578\n",
      "batch 884 loss: 0.22208 acc: 0.93783 | v_loss: 0.52381 v_acc: 0.87109 |  iteration: 5857 teacher: 1 stage: sketch lr: 0.000577\n",
      "batch 885 loss: 0.30198 acc: 0.91178 | v_loss: 0.59396 v_acc: 0.86979 |  iteration: 5858 teacher: 0 stage: sketch lr: 0.000577\n",
      "batch 886 loss: 0.26512 acc: 0.92546 | v_loss: 0.60793 v_acc: 0.84831 |  iteration: 5859 teacher: 1 stage: sketch lr: 0.000577\n",
      "batch 887 loss: 0.36755 acc: 0.88900 | v_loss: 0.45620 v_acc: 0.90234 |  iteration: 5860 teacher: 0 stage: sketch lr: 0.000577\n",
      "batch 888 loss: 0.29579 acc: 0.91406 | v_loss: 0.40329 v_acc: 0.89876 |  iteration: 5861 teacher: 1 stage: sketch lr: 0.000577\n",
      "batch 889 loss: 0.28442 acc: 0.91374 | v_loss: 0.30547 v_acc: 0.92090 |  iteration: 5862 teacher: 0 stage: sketch lr: 0.000577\n",
      "batch 890 loss: 0.28553 acc: 0.91374 | v_loss: 0.43453 v_acc: 0.90332 |  iteration: 5863 teacher: 0 stage: sketch lr: 0.000577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 891 loss: 0.23673 acc: 0.92448 | v_loss: 0.44951 v_acc: 0.89811 |  iteration: 5864 teacher: 0 stage: sketch lr: 0.000577\n",
      "batch 892 loss: 0.25141 acc: 0.92448 | v_loss: 0.77395 v_acc: 0.85807 |  iteration: 5865 teacher: 0 stage: sketch lr: 0.000577\n",
      "batch 893 loss: 0.26646 acc: 0.91992 | v_loss: 0.53307 v_acc: 0.88346 |  iteration: 5866 teacher: 0 stage: sketch lr: 0.000577\n",
      "batch 894 loss: 0.23281 acc: 0.92676 | v_loss: 0.61337 v_acc: 0.87207 |  iteration: 5867 teacher: 1 stage: sketch lr: 0.000577\n",
      "batch 895 loss: 0.19767 acc: 0.93815 | v_loss: 0.42265 v_acc: 0.89779 |  iteration: 5868 teacher: 1 stage: sketch lr: 0.000577\n",
      "batch 896 loss: 0.35865 acc: 0.90234 | v_loss: 0.54889 v_acc: 0.88281 |  iteration: 5869 teacher: 0 stage: sketch lr: 0.000577\n",
      "batch 897 loss: 0.32131 acc: 0.90918 | v_loss: 0.79354 v_acc: 0.83984 |  iteration: 5870 teacher: 0 stage: sketch lr: 0.000577\n",
      "batch 898 loss: 0.26256 acc: 0.91960 | v_loss: 0.53496 v_acc: 0.89030 |  iteration: 5871 teacher: 0 stage: sketch lr: 0.000577\n",
      "batch 899 loss: 0.19296 acc: 0.95182 | v_loss: 0.54722 v_acc: 0.88281 |  iteration: 5872 teacher: 0 stage: sketch lr: 0.000577\n",
      "batch 900 loss: 0.22225 acc: 0.93717 | v_loss: 0.51865 v_acc: 0.88672 |  iteration: 5873 teacher: 0 stage: sketch lr: 0.000577\n",
      "batch 901 loss: 0.36491 acc: 0.91081 | v_loss: 0.41320 v_acc: 0.90495 |  iteration: 5874 teacher: 1 stage: sketch lr: 0.000577\n",
      "batch 902 loss: 0.22979 acc: 0.93652 | v_loss: 0.45005 v_acc: 0.90365 |  iteration: 5875 teacher: 1 stage: sketch lr: 0.000577\n",
      "batch 903 loss: 0.23407 acc: 0.93066 | v_loss: 0.58691 v_acc: 0.87435 |  iteration: 5876 teacher: 1 stage: sketch lr: 0.000577\n",
      "batch 904 loss: 0.27969 acc: 0.92025 | v_loss: 0.33979 v_acc: 0.92480 |  iteration: 5877 teacher: 0 stage: sketch lr: 0.000576\n",
      "batch 905 loss: 0.25737 acc: 0.91667 | v_loss: 0.89968 v_acc: 0.83073 |  iteration: 5878 teacher: 0 stage: sketch lr: 0.000576\n",
      "batch 906 loss: 0.24106 acc: 0.92318 | v_loss: 0.64586 v_acc: 0.87598 |  iteration: 5879 teacher: 1 stage: sketch lr: 0.000576\n",
      "batch 907 loss: 0.32176 acc: 0.91829 | v_loss: 0.70275 v_acc: 0.85677 |  iteration: 5880 teacher: 1 stage: sketch lr: 0.000576\n",
      "batch 908 loss: 0.33489 acc: 0.90495 | v_loss: 0.52807 v_acc: 0.89583 |  iteration: 5881 teacher: 1 stage: sketch lr: 0.000576\n",
      "batch 909 loss: 0.34038 acc: 0.90983 | v_loss: 0.51683 v_acc: 0.88932 |  iteration: 5882 teacher: 1 stage: sketch lr: 0.000576\n",
      "batch 910 loss: 0.31495 acc: 0.91471 | v_loss: 0.56290 v_acc: 0.88216 |  iteration: 5883 teacher: 1 stage: sketch lr: 0.000576\n",
      "batch 911 loss: 0.27508 acc: 0.91276 | v_loss: 0.51854 v_acc: 0.89095 |  iteration: 5884 teacher: 0 stage: sketch lr: 0.000576\n",
      "batch 912 loss: 0.28319 acc: 0.91829 | v_loss: 0.45492 v_acc: 0.89779 |  iteration: 5885 teacher: 1 stage: sketch lr: 0.000576\n",
      "batch 913 loss: 0.25977 acc: 0.92546 | v_loss: 0.47686 v_acc: 0.90820 |  iteration: 5886 teacher: 1 stage: sketch lr: 0.000576\n",
      "batch 914 loss: 0.28270 acc: 0.92513 | v_loss: 0.42380 v_acc: 0.89746 |  iteration: 5887 teacher: 1 stage: sketch lr: 0.000576\n",
      "batch 915 loss: 0.20671 acc: 0.93457 | v_loss: 0.35238 v_acc: 0.91374 |  iteration: 5888 teacher: 1 stage: sketch lr: 0.000576\n",
      "batch 916 loss: 0.29228 acc: 0.90918 | v_loss: 0.62348 v_acc: 0.86328 |  iteration: 5889 teacher: 0 stage: sketch lr: 0.000576\n",
      "batch 917 loss: 0.26926 acc: 0.92383 | v_loss: 0.55457 v_acc: 0.86947 |  iteration: 5890 teacher: 1 stage: sketch lr: 0.000576\n",
      "batch 918 loss: 0.30259 acc: 0.91439 | v_loss: 0.63892 v_acc: 0.86426 |  iteration: 5891 teacher: 0 stage: sketch lr: 0.000576\n",
      "batch 919 loss: 0.18383 acc: 0.94238 | v_loss: 0.82701 v_acc: 0.84440 |  iteration: 5892 teacher: 1 stage: sketch lr: 0.000576\n",
      "batch 920 loss: 0.25817 acc: 0.92155 | v_loss: 0.41109 v_acc: 0.91178 |  iteration: 5893 teacher: 0 stage: sketch lr: 0.000576\n",
      "batch 921 loss: 0.30226 acc: 0.90462 | v_loss: 0.55349 v_acc: 0.88249 |  iteration: 5894 teacher: 0 stage: sketch lr: 0.000576\n",
      "batch 922 loss: 0.24948 acc: 0.92318 | v_loss: 0.58485 v_acc: 0.88118 |  iteration: 5895 teacher: 1 stage: sketch lr: 0.000576\n",
      "batch 923 loss: 0.31734 acc: 0.91374 | v_loss: 0.41230 v_acc: 0.90495 |  iteration: 5896 teacher: 0 stage: sketch lr: 0.000576\n",
      "batch 924 loss: 0.34579 acc: 0.89779 | v_loss: 1.16047 v_acc: 0.79688 |  iteration: 5897 teacher: 0 stage: sketch lr: 0.000576\n",
      "batch 925 loss: 0.27826 acc: 0.92220 | v_loss: 0.35770 v_acc: 0.92155 |  iteration: 5898 teacher: 0 stage: sketch lr: 0.000575\n",
      "batch 926 loss: 0.21133 acc: 0.93685 | v_loss: 0.59166 v_acc: 0.87728 |  iteration: 5899 teacher: 1 stage: sketch lr: 0.000575\n",
      "batch 927 loss: 0.28549 acc: 0.91471 | v_loss: 0.52091 v_acc: 0.88835 |  iteration: 5900 teacher: 0 stage: sketch lr: 0.000575\n",
      "batch 928 loss: 0.19351 acc: 0.94303 | v_loss: 0.43249 v_acc: 0.89779 |  iteration: 5901 teacher: 1 stage: sketch lr: 0.000575\n",
      "batch 929 loss: 0.30548 acc: 0.91016 | v_loss: 0.49764 v_acc: 0.89128 |  iteration: 5902 teacher: 1 stage: sketch lr: 0.000575\n",
      "batch 930 loss: 0.29216 acc: 0.91634 | v_loss: 0.57572 v_acc: 0.87630 |  iteration: 5903 teacher: 0 stage: sketch lr: 0.000575\n",
      "batch 931 loss: 0.28658 acc: 0.91569 | v_loss: 0.41158 v_acc: 0.90885 |  iteration: 5904 teacher: 0 stage: sketch lr: 0.000575\n",
      "batch 932 loss: 0.30870 acc: 0.90267 | v_loss: 0.61071 v_acc: 0.86686 |  iteration: 5905 teacher: 1 stage: sketch lr: 0.000575\n",
      "batch 933 loss: 0.28272 acc: 0.91895 | v_loss: 0.39589 v_acc: 0.90560 |  iteration: 5906 teacher: 0 stage: sketch lr: 0.000575\n",
      "batch 934 loss: 0.27141 acc: 0.91699 | v_loss: 0.97801 v_acc: 0.82161 |  iteration: 5907 teacher: 1 stage: sketch lr: 0.000575\n",
      "batch 935 loss: 0.29041 acc: 0.91732 | v_loss: 0.55734 v_acc: 0.89193 |  iteration: 5908 teacher: 0 stage: sketch lr: 0.000575\n",
      "batch 936 loss: 0.33818 acc: 0.89388 | v_loss: 0.66588 v_acc: 0.86947 |  iteration: 5909 teacher: 1 stage: sketch lr: 0.000575\n",
      "batch 937 loss: 0.28993 acc: 0.91178 | v_loss: 0.42859 v_acc: 0.89648 |  iteration: 5910 teacher: 0 stage: sketch lr: 0.000575\n",
      "batch 938 loss: 0.26099 acc: 0.92025 | v_loss: 0.65667 v_acc: 0.86263 |  iteration: 5911 teacher: 1 stage: sketch lr: 0.000575\n",
      "batch 939 loss: 0.39229 acc: 0.89518 | v_loss: 0.43060 v_acc: 0.89616 |  iteration: 5912 teacher: 0 stage: sketch lr: 0.000575\n",
      "batch 940 loss: 0.24183 acc: 0.92546 | v_loss: 0.44839 v_acc: 0.89290 |  iteration: 5913 teacher: 0 stage: sketch lr: 0.000575\n",
      "batch 941 loss: 0.26604 acc: 0.92220 | v_loss: 0.45240 v_acc: 0.88932 |  iteration: 5914 teacher: 1 stage: sketch lr: 0.000575\n",
      "batch 942 loss: 0.29351 acc: 0.91243 | v_loss: 0.73763 v_acc: 0.84082 |  iteration: 5915 teacher: 1 stage: sketch lr: 0.000575\n",
      "batch 943 loss: 0.30648 acc: 0.91016 | v_loss: 0.50606 v_acc: 0.90072 |  iteration: 5916 teacher: 0 stage: sketch lr: 0.000575\n",
      "batch 944 loss: 0.27665 acc: 0.91797 | v_loss: 0.54131 v_acc: 0.87174 |  iteration: 5917 teacher: 0 stage: sketch lr: 0.000575\n",
      "batch 945 loss: 0.31618 acc: 0.90788 | v_loss: 0.67547 v_acc: 0.84896 |  iteration: 5918 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 946 loss: 0.23911 acc: 0.92839 | v_loss: 0.45923 v_acc: 0.89160 |  iteration: 5919 teacher: 0 stage: sketch lr: 0.000574\n",
      "batch 947 loss: 0.32056 acc: 0.91146 | v_loss: 0.52147 v_acc: 0.86882 |  iteration: 5920 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 948 loss: 0.26669 acc: 0.93294 | v_loss: 0.57605 v_acc: 0.86458 |  iteration: 5921 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 949 loss: 0.24089 acc: 0.92806 | v_loss: 0.77603 v_acc: 0.85156 |  iteration: 5922 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 950 loss: 0.21061 acc: 0.93815 | v_loss: 0.59320 v_acc: 0.88086 |  iteration: 5923 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 951 loss: 0.26603 acc: 0.91634 | v_loss: 0.57016 v_acc: 0.89290 |  iteration: 5924 teacher: 0 stage: sketch lr: 0.000574\n",
      "batch 952 loss: 0.30755 acc: 0.91113 | v_loss: 0.67891 v_acc: 0.87565 |  iteration: 5925 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 953 loss: 0.32863 acc: 0.90885 | v_loss: 0.59541 v_acc: 0.86393 |  iteration: 5926 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 954 loss: 0.31092 acc: 0.90690 | v_loss: 0.48549 v_acc: 0.90072 |  iteration: 5927 teacher: 0 stage: sketch lr: 0.000574\n",
      "batch 955 loss: 0.26704 acc: 0.92122 | v_loss: 0.79449 v_acc: 0.84147 |  iteration: 5928 teacher: 0 stage: sketch lr: 0.000574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 956 loss: 0.30826 acc: 0.91374 | v_loss: 0.58440 v_acc: 0.87891 |  iteration: 5929 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 957 loss: 0.22949 acc: 0.92578 | v_loss: 0.56262 v_acc: 0.87500 |  iteration: 5930 teacher: 0 stage: sketch lr: 0.000574\n",
      "batch 958 loss: 0.28413 acc: 0.91895 | v_loss: 0.54834 v_acc: 0.87663 |  iteration: 5931 teacher: 0 stage: sketch lr: 0.000574\n",
      "batch 959 loss: 0.28647 acc: 0.91699 | v_loss: 0.45743 v_acc: 0.89681 |  iteration: 5932 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 960 loss: 0.21554 acc: 0.93392 | v_loss: 0.46960 v_acc: 0.89421 |  iteration: 5933 teacher: 0 stage: sketch lr: 0.000574\n",
      "batch 961 loss: 0.23363 acc: 0.93229 | v_loss: 0.54932 v_acc: 0.88118 |  iteration: 5934 teacher: 0 stage: sketch lr: 0.000574\n",
      "batch 962 loss: 0.32359 acc: 0.90397 | v_loss: 0.58516 v_acc: 0.85677 |  iteration: 5935 teacher: 0 stage: sketch lr: 0.000574\n",
      "batch 963 loss: 0.29777 acc: 0.91146 | v_loss: 0.58340 v_acc: 0.88411 |  iteration: 5936 teacher: 0 stage: sketch lr: 0.000574\n",
      "batch 964 loss: 0.28860 acc: 0.91667 | v_loss: 0.58627 v_acc: 0.88379 |  iteration: 5937 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 965 loss: 0.30361 acc: 0.91309 | v_loss: 0.38972 v_acc: 0.90234 |  iteration: 5938 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 966 loss: 0.30451 acc: 0.91309 | v_loss: 0.56703 v_acc: 0.87891 |  iteration: 5939 teacher: 1 stage: sketch lr: 0.000573\n",
      "batch 967 loss: 0.23809 acc: 0.92546 | v_loss: 0.49593 v_acc: 0.88086 |  iteration: 5940 teacher: 1 stage: sketch lr: 0.000573\n",
      "batch 968 loss: 0.25446 acc: 0.91764 | v_loss: 0.82880 v_acc: 0.82747 |  iteration: 5941 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 969 loss: 0.32876 acc: 0.90723 | v_loss: 0.35404 v_acc: 0.90983 |  iteration: 5942 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 970 loss: 0.27221 acc: 0.91797 | v_loss: 0.31510 v_acc: 0.92188 |  iteration: 5943 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 971 loss: 0.26345 acc: 0.92090 | v_loss: 0.60353 v_acc: 0.87858 |  iteration: 5944 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 972 loss: 0.33084 acc: 0.90365 | v_loss: 0.54127 v_acc: 0.88770 |  iteration: 5945 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 973 loss: 0.34213 acc: 0.89551 | v_loss: 0.63239 v_acc: 0.86458 |  iteration: 5946 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 974 loss: 0.25566 acc: 0.92741 | v_loss: 0.43032 v_acc: 0.89583 |  iteration: 5947 teacher: 1 stage: sketch lr: 0.000573\n",
      "batch 975 loss: 0.34430 acc: 0.90072 | v_loss: 0.51140 v_acc: 0.86979 |  iteration: 5948 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 976 loss: 0.26685 acc: 0.91992 | v_loss: 0.61987 v_acc: 0.85807 |  iteration: 5949 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 977 loss: 0.31860 acc: 0.90885 | v_loss: 0.63287 v_acc: 0.84603 |  iteration: 5950 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 978 loss: 0.26244 acc: 0.91732 | v_loss: 0.47661 v_acc: 0.89160 |  iteration: 5951 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 979 loss: 0.31160 acc: 0.91309 | v_loss: 0.39949 v_acc: 0.90723 |  iteration: 5952 teacher: 1 stage: sketch lr: 0.000573\n",
      "batch 980 loss: 0.24787 acc: 0.92546 | v_loss: 0.28707 v_acc: 0.92643 |  iteration: 5953 teacher: 1 stage: sketch lr: 0.000573\n",
      "batch 981 loss: 0.30370 acc: 0.91211 | v_loss: 0.43516 v_acc: 0.91113 |  iteration: 5954 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 982 loss: 0.28585 acc: 0.92122 | v_loss: 0.56702 v_acc: 0.87891 |  iteration: 5955 teacher: 1 stage: sketch lr: 0.000573\n",
      "batch 983 loss: 0.28587 acc: 0.92220 | v_loss: 0.89046 v_acc: 0.84408 |  iteration: 5956 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 984 loss: 0.25848 acc: 0.92448 | v_loss: 0.57404 v_acc: 0.87272 |  iteration: 5957 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 985 loss: 0.20984 acc: 0.94238 | v_loss: 0.66530 v_acc: 0.86589 |  iteration: 5958 teacher: 1 stage: sketch lr: 0.000573\n",
      "batch 986 loss: 0.30915 acc: 0.92220 | v_loss: 0.43429 v_acc: 0.89876 |  iteration: 5959 teacher: 1 stage: sketch lr: 0.000573\n",
      "batch 987 loss: 0.26472 acc: 0.92057 | v_loss: 0.51963 v_acc: 0.88477 |  iteration: 5960 teacher: 0 stage: sketch lr: 0.000572\n",
      "batch 988 loss: 0.34146 acc: 0.90560 | v_loss: 0.75470 v_acc: 0.84082 |  iteration: 5961 teacher: 1 stage: sketch lr: 0.000572\n",
      "batch 989 loss: 0.30348 acc: 0.91536 | v_loss: 0.51638 v_acc: 0.89193 |  iteration: 5962 teacher: 1 stage: sketch lr: 0.000572\n",
      "batch 990 loss: 0.26610 acc: 0.92350 | v_loss: 0.52284 v_acc: 0.88444 |  iteration: 5963 teacher: 0 stage: sketch lr: 0.000572\n",
      "batch 991 loss: 0.22692 acc: 0.93099 | v_loss: 0.49394 v_acc: 0.89323 |  iteration: 5964 teacher: 1 stage: sketch lr: 0.000572\n",
      "batch 992 loss: 0.17283 acc: 0.94499 | v_loss: 0.42602 v_acc: 0.90820 |  iteration: 5965 teacher: 0 stage: sketch lr: 0.000572\n",
      "batch 993 loss: 0.37099 acc: 0.90299 | v_loss: 0.46289 v_acc: 0.90039 |  iteration: 5966 teacher: 1 stage: sketch lr: 0.000572\n",
      "batch 994 loss: 0.27408 acc: 0.92253 | v_loss: 0.59920 v_acc: 0.86491 |  iteration: 5967 teacher: 1 stage: sketch lr: 0.000572\n",
      "batch 995 loss: 0.27149 acc: 0.91862 | v_loss: 0.36738 v_acc: 0.91992 |  iteration: 5968 teacher: 1 stage: sketch lr: 0.000572\n",
      "batch 996 loss: 0.34615 acc: 0.90690 | v_loss: 0.93198 v_acc: 0.82650 |  iteration: 5969 teacher: 1 stage: sketch lr: 0.000572\n",
      "batch 997 loss: 0.26211 acc: 0.92318 | v_loss: 0.65364 v_acc: 0.86133 |  iteration: 5970 teacher: 1 stage: sketch lr: 0.000572\n",
      "batch 998 loss: 0.23307 acc: 0.93359 | v_loss: 0.70880 v_acc: 0.85026 |  iteration: 5971 teacher: 0 stage: sketch lr: 0.000572\n",
      "batch 999 loss: 0.32104 acc: 0.90299 | v_loss: 0.47380 v_acc: 0.89844 |  iteration: 5972 teacher: 0 stage: sketch lr: 0.000572\n",
      "batch 1000 loss: 0.26745 acc: 0.91178 | v_loss: 0.49035 v_acc: 0.88542 |  iteration: 5973 teacher: 1 stage: sketch lr: 0.000572\n",
      "batch 1001 loss: 0.37255 acc: 0.88444 | v_loss: 0.57086 v_acc: 0.88346 |  iteration: 5974 teacher: 0 stage: sketch lr: 0.000572\n",
      "batch 1002 loss: 0.23300 acc: 0.93490 | v_loss: 0.51115 v_acc: 0.89030 |  iteration: 5975 teacher: 0 stage: sketch lr: 0.000572\n",
      "batch 1003 loss: 0.20879 acc: 0.93685 | v_loss: 0.51056 v_acc: 0.88932 |  iteration: 5976 teacher: 0 stage: sketch lr: 0.000572\n",
      "batch 1004 loss: 0.26506 acc: 0.93197 | v_loss: 0.49780 v_acc: 0.90592 |  iteration: 5977 teacher: 0 stage: sketch lr: 0.000572\n",
      "batch 1005 loss: 0.28854 acc: 0.92383 | v_loss: 0.44305 v_acc: 0.89616 |  iteration: 5978 teacher: 0 stage: sketch lr: 0.000572\n",
      "batch 1006 loss: 0.30262 acc: 0.92285 | v_loss: 0.35507 v_acc: 0.91471 |  iteration: 5979 teacher: 0 stage: sketch lr: 0.000572\n",
      "batch 1007 loss: 0.29145 acc: 0.91764 | v_loss: 0.62089 v_acc: 0.85677 |  iteration: 5980 teacher: 0 stage: sketch lr: 0.000571\n",
      "batch 1008 loss: 0.33697 acc: 0.90560 | v_loss: 0.57082 v_acc: 0.85970 |  iteration: 5981 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 1009 loss: 0.30625 acc: 0.91374 | v_loss: 0.58791 v_acc: 0.85807 |  iteration: 5982 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 1010 loss: 0.17020 acc: 0.94108 | v_loss: 0.81016 v_acc: 0.83984 |  iteration: 5983 teacher: 0 stage: sketch lr: 0.000571\n",
      "batch 1011 loss: 0.33548 acc: 0.90299 | v_loss: 0.43783 v_acc: 0.90234 |  iteration: 5984 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 1012 loss: 0.29479 acc: 0.91667 | v_loss: 0.59051 v_acc: 0.86882 |  iteration: 5985 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 1013 loss: 0.25838 acc: 0.92578 | v_loss: 0.54303 v_acc: 0.88607 |  iteration: 5986 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 1014 loss: 0.26171 acc: 0.92578 | v_loss: 0.39311 v_acc: 0.90755 |  iteration: 5987 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 1015 loss: 0.34743 acc: 0.90267 | v_loss: 1.08166 v_acc: 0.81380 |  iteration: 5988 teacher: 0 stage: sketch lr: 0.000571\n",
      "batch 1016 loss: 0.23349 acc: 0.93132 | v_loss: 0.35846 v_acc: 0.91895 |  iteration: 5989 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 1017 loss: 0.29324 acc: 0.91406 | v_loss: 0.51839 v_acc: 0.88314 |  iteration: 5990 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 1018 loss: 0.32304 acc: 0.90332 | v_loss: 0.50450 v_acc: 0.88346 |  iteration: 5991 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 1019 loss: 0.22107 acc: 0.92448 | v_loss: 0.42790 v_acc: 0.90007 |  iteration: 5992 teacher: 0 stage: sketch lr: 0.000571\n",
      "batch 1020 loss: 0.34699 acc: 0.89876 | v_loss: 0.51804 v_acc: 0.88704 |  iteration: 5993 teacher: 1 stage: sketch lr: 0.000571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1021 loss: 0.33653 acc: 0.89648 | v_loss: 0.60091 v_acc: 0.86882 |  iteration: 5994 teacher: 0 stage: sketch lr: 0.000571\n",
      "batch 1022 loss: 0.25442 acc: 0.91829 | v_loss: 0.42257 v_acc: 0.90885 |  iteration: 5995 teacher: 0 stage: sketch lr: 0.000571\n",
      "batch 1023 loss: 0.28680 acc: 0.92025 | v_loss: 0.63408 v_acc: 0.87012 |  iteration: 5996 teacher: 0 stage: sketch lr: 0.000571\n",
      "batch 1024 loss: 0.27204 acc: 0.93229 | v_loss: 0.36485 v_acc: 0.91113 |  iteration: 5997 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 1025 loss: 0.34887 acc: 0.90234 | v_loss: 0.98205 v_acc: 0.82357 |  iteration: 5998 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 1026 loss: 0.22785 acc: 0.93457 | v_loss: 0.57157 v_acc: 0.88216 |  iteration: 5999 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 1027 loss: 0.23453 acc: 0.93294 | v_loss: 0.69295 v_acc: 0.86426 |  iteration: 6000 teacher: 0 stage: sketch lr: 0.000571\n",
      "batch 1028 loss: 0.27531 acc: 0.91634 | v_loss: 0.40901 v_acc: 0.90885 |  iteration: 6001 teacher: 0 stage: sketch lr: 0.000570\n",
      "batch 1029 loss: 0.26923 acc: 0.92090 | v_loss: 0.66827 v_acc: 0.85938 |  iteration: 6002 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 1030 loss: 0.28630 acc: 0.91927 | v_loss: 0.43830 v_acc: 0.89909 |  iteration: 6003 teacher: 0 stage: sketch lr: 0.000570\n",
      "batch 1031 loss: 0.22750 acc: 0.92513 | v_loss: 0.51349 v_acc: 0.88411 |  iteration: 6004 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 1032 loss: 0.20441 acc: 0.93457 | v_loss: 0.40896 v_acc: 0.89909 |  iteration: 6005 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 1033 loss: 0.25281 acc: 0.93294 | v_loss: 0.73041 v_acc: 0.85547 |  iteration: 6006 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 1034 loss: 0.27467 acc: 0.92448 | v_loss: 0.50840 v_acc: 0.90039 |  iteration: 6007 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 1035 loss: 0.24715 acc: 0.92741 | v_loss: 0.52565 v_acc: 0.87891 |  iteration: 6008 teacher: 0 stage: sketch lr: 0.000570\n",
      "batch 1036 loss: 0.29404 acc: 0.90788 | v_loss: 0.67693 v_acc: 0.84928 |  iteration: 6009 teacher: 0 stage: sketch lr: 0.000570\n",
      "batch 1037 loss: 0.32605 acc: 0.91081 | v_loss: 0.42082 v_acc: 0.89388 |  iteration: 6010 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 1038 loss: 0.26474 acc: 0.91895 | v_loss: 0.51447 v_acc: 0.86654 |  iteration: 6011 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 1039 loss: 0.26564 acc: 0.92350 | v_loss: 0.52851 v_acc: 0.86882 |  iteration: 6012 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 1040 loss: 0.41591 acc: 0.88932 | v_loss: 0.75192 v_acc: 0.84570 |  iteration: 6013 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 1041 loss: 0.22240 acc: 0.93522 | v_loss: 0.54327 v_acc: 0.87598 |  iteration: 6014 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 1042 loss: 0.27078 acc: 0.91797 | v_loss: 0.56208 v_acc: 0.88118 |  iteration: 6015 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 1043 loss: 0.30058 acc: 0.91406 | v_loss: 0.63298 v_acc: 0.88086 |  iteration: 6016 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 1044 loss: 0.38439 acc: 0.89062 | v_loss: 0.54309 v_acc: 0.87174 |  iteration: 6017 teacher: 0 stage: sketch lr: 0.000570\n",
      "batch 1045 loss: 0.29454 acc: 0.91016 | v_loss: 0.46344 v_acc: 0.89779 |  iteration: 6018 teacher: 0 stage: sketch lr: 0.000570\n",
      "batch 1046 loss: 0.36979 acc: 0.89486 | v_loss: 0.81629 v_acc: 0.84277 |  iteration: 6019 teacher: 0 stage: sketch lr: 0.000570\n",
      "batch 1047 loss: 0.34648 acc: 0.89876 | v_loss: 0.58156 v_acc: 0.87826 |  iteration: 6020 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 1048 loss: 0.31355 acc: 0.91862 | v_loss: 0.57385 v_acc: 0.86458 |  iteration: 6021 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 1049 loss: 0.34699 acc: 0.90104 | v_loss: 0.52946 v_acc: 0.87500 |  iteration: 6022 teacher: 0 stage: sketch lr: 0.000570\n",
      "batch 1050 loss: 0.32825 acc: 0.91829 | v_loss: 0.51278 v_acc: 0.88118 |  iteration: 6023 teacher: 1 stage: sketch lr: 0.000569\n",
      "batch 1051 loss: 0.27990 acc: 0.91797 | v_loss: 0.47196 v_acc: 0.88411 |  iteration: 6024 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 1052 loss: 0.27106 acc: 0.92122 | v_loss: 0.53283 v_acc: 0.88216 |  iteration: 6025 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 1053 loss: 0.24374 acc: 0.93490 | v_loss: 0.59906 v_acc: 0.85449 |  iteration: 6026 teacher: 1 stage: sketch lr: 0.000569\n",
      "batch 1054 loss: 0.24038 acc: 0.93424 | v_loss: 0.54921 v_acc: 0.89258 |  iteration: 6027 teacher: 1 stage: sketch lr: 0.000569\n",
      "batch 1055 loss: 0.28227 acc: 0.91374 | v_loss: 0.61227 v_acc: 0.87533 |  iteration: 6028 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 1056 loss: 0.22968 acc: 0.93783 | v_loss: 0.37165 v_acc: 0.90918 |  iteration: 6029 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 1057 loss: 0.32312 acc: 0.91048 | v_loss: 0.55445 v_acc: 0.88509 |  iteration: 6030 teacher: 1 stage: sketch lr: 0.000569\n",
      "batch 1058 loss: 0.23032 acc: 0.93620 | v_loss: 0.46944 v_acc: 0.88216 |  iteration: 6031 teacher: 1 stage: sketch lr: 0.000569\n",
      "batch 1059 loss: 0.24963 acc: 0.92025 | v_loss: 0.83319 v_acc: 0.83008 |  iteration: 6032 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 1060 loss: 0.19069 acc: 0.94727 | v_loss: 0.36728 v_acc: 0.90267 |  iteration: 6033 teacher: 1 stage: sketch lr: 0.000569\n",
      "batch 1061 loss: 0.28252 acc: 0.92383 | v_loss: 0.33106 v_acc: 0.92546 |  iteration: 6034 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 1062 loss: 0.27203 acc: 0.92057 | v_loss: 0.52734 v_acc: 0.88770 |  iteration: 6035 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 1063 loss: 0.19918 acc: 0.93750 | v_loss: 0.55500 v_acc: 0.88477 |  iteration: 6036 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 1064 loss: 0.24759 acc: 0.92676 | v_loss: 0.65922 v_acc: 0.86621 |  iteration: 6037 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 1065 loss: 0.35443 acc: 0.91178 | v_loss: 0.42139 v_acc: 0.90658 |  iteration: 6038 teacher: 1 stage: sketch lr: 0.000569\n",
      "batch 1066 loss: 0.31398 acc: 0.91113 | v_loss: 0.47002 v_acc: 0.87891 |  iteration: 6039 teacher: 1 stage: sketch lr: 0.000569\n",
      "batch 1067 loss: 0.30022 acc: 0.91309 | v_loss: 0.59468 v_acc: 0.86816 |  iteration: 6040 teacher: 1 stage: sketch lr: 0.000569\n",
      "batch 1068 loss: 0.29025 acc: 0.92025 | v_loss: 0.63187 v_acc: 0.84766 |  iteration: 6041 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 1069 loss: 0.33528 acc: 0.90104 | v_loss: 0.46700 v_acc: 0.89388 |  iteration: 6042 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 1070 loss: 0.25929 acc: 0.92676 | v_loss: 0.36314 v_acc: 0.90853 |  iteration: 6043 teacher: 1 stage: sketch lr: 0.000569\n",
      "batch 1071 loss: 0.29760 acc: 0.91602 | v_loss: 0.28185 v_acc: 0.92220 |  iteration: 6044 teacher: 0 stage: sketch lr: 0.000568\n",
      "batch 1072 loss: 0.26789 acc: 0.91504 | v_loss: 0.44461 v_acc: 0.90072 |  iteration: 6045 teacher: 0 stage: sketch lr: 0.000568\n",
      "batch 1073 loss: 0.28387 acc: 0.91667 | v_loss: 0.50528 v_acc: 0.88184 |  iteration: 6046 teacher: 1 stage: sketch lr: 0.000568\n",
      "batch 1074 loss: 0.26430 acc: 0.92220 | v_loss: 0.78601 v_acc: 0.85482 |  iteration: 6047 teacher: 1 stage: sketch lr: 0.000568\n",
      "batch 1075 loss: 0.33348 acc: 0.89714 | v_loss: 0.51418 v_acc: 0.87402 |  iteration: 6048 teacher: 0 stage: sketch lr: 0.000568\n",
      "batch 1076 loss: 0.32312 acc: 0.91081 | v_loss: 0.59411 v_acc: 0.87240 |  iteration: 6049 teacher: 1 stage: sketch lr: 0.000568\n",
      "batch 1077 loss: 0.30170 acc: 0.91276 | v_loss: 0.41577 v_acc: 0.89681 |  iteration: 6050 teacher: 0 stage: sketch lr: 0.000568\n",
      "batch 1078 loss: 0.25771 acc: 0.92318 | v_loss: 0.52714 v_acc: 0.87793 |  iteration: 6051 teacher: 1 stage: sketch lr: 0.000568\n",
      "batch 1079 loss: 0.31572 acc: 0.91146 | v_loss: 0.75291 v_acc: 0.83952 |  iteration: 6052 teacher: 1 stage: sketch lr: 0.000568\n",
      "batch 1080 loss: 0.33409 acc: 0.90299 | v_loss: 0.51085 v_acc: 0.89095 |  iteration: 6053 teacher: 1 stage: sketch lr: 0.000568\n",
      "batch 1081 loss: 0.22851 acc: 0.93620 | v_loss: 0.50702 v_acc: 0.88639 |  iteration: 6054 teacher: 0 stage: sketch lr: 0.000568\n",
      "batch 1082 loss: 0.27250 acc: 0.91927 | v_loss: 0.44779 v_acc: 0.89323 |  iteration: 6055 teacher: 1 stage: sketch lr: 0.000568\n",
      "batch 1083 loss: 0.25908 acc: 0.92350 | v_loss: 0.41410 v_acc: 0.90495 |  iteration: 6056 teacher: 1 stage: sketch lr: 0.000568\n",
      "batch 1084 loss: 0.20753 acc: 0.93783 | v_loss: 0.45690 v_acc: 0.89974 |  iteration: 6057 teacher: 1 stage: sketch lr: 0.000568\n",
      "batch 1085 loss: 0.18960 acc: 0.94010 | v_loss: 0.60477 v_acc: 0.86816 |  iteration: 6058 teacher: 1 stage: sketch lr: 0.000568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1086 loss: 0.27017 acc: 0.92057 | v_loss: 0.35697 v_acc: 0.92611 |  iteration: 6059 teacher: 0 stage: sketch lr: 0.000568\n",
      "batch 1087 loss: 0.27178 acc: 0.92773 | v_loss: 0.95188 v_acc: 0.82161 |  iteration: 6060 teacher: 1 stage: sketch lr: 0.000568\n",
      "batch 1088 loss: 0.30766 acc: 0.91439 | v_loss: 0.63334 v_acc: 0.87044 |  iteration: 6061 teacher: 1 stage: sketch lr: 0.000568\n",
      "batch 1089 loss: 0.30672 acc: 0.90495 | v_loss: 0.64841 v_acc: 0.86751 |  iteration: 6062 teacher: 0 stage: sketch lr: 0.000568\n",
      "batch 1090 loss: 0.26958 acc: 0.92057 | v_loss: 0.54217 v_acc: 0.89290 |  iteration: 6063 teacher: 0 stage: sketch lr: 0.000568\n",
      "batch 1091 loss: 0.23284 acc: 0.93132 | v_loss: 0.46896 v_acc: 0.89290 |  iteration: 6064 teacher: 0 stage: sketch lr: 0.000568\n",
      "batch 1092 loss: 0.25209 acc: 0.92741 | v_loss: 0.58336 v_acc: 0.88672 |  iteration: 6065 teacher: 1 stage: sketch lr: 0.000567\n",
      "batch 1093 loss: 0.31556 acc: 0.91211 | v_loss: 0.53235 v_acc: 0.89128 |  iteration: 6066 teacher: 1 stage: sketch lr: 0.000567\n",
      "batch 1094 loss: 0.24220 acc: 0.92415 | v_loss: 0.48560 v_acc: 0.89388 |  iteration: 6067 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 1095 loss: 0.29833 acc: 0.91309 | v_loss: 0.47571 v_acc: 0.89616 |  iteration: 6068 teacher: 1 stage: sketch lr: 0.000567\n",
      "batch 1096 loss: 0.23902 acc: 0.93424 | v_loss: 0.45371 v_acc: 0.90039 |  iteration: 6069 teacher: 1 stage: sketch lr: 0.000567\n",
      "batch 1097 loss: 0.28264 acc: 0.92546 | v_loss: 0.41676 v_acc: 0.90885 |  iteration: 6070 teacher: 1 stage: sketch lr: 0.000567\n",
      "batch 1098 loss: 0.31026 acc: 0.91016 | v_loss: 0.71374 v_acc: 0.85221 |  iteration: 6071 teacher: 1 stage: sketch lr: 0.000567\n",
      "batch 1099 loss: 0.34600 acc: 0.90625 | v_loss: 0.52261 v_acc: 0.86426 |  iteration: 6072 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 1100 loss: 0.34016 acc: 0.90397 | v_loss: 0.62144 v_acc: 0.85579 |  iteration: 6073 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 1101 loss: 0.25208 acc: 0.92578 | v_loss: 0.79237 v_acc: 0.84342 |  iteration: 6074 teacher: 1 stage: sketch lr: 0.000567\n",
      "batch 1102 loss: 0.23582 acc: 0.92513 | v_loss: 0.44492 v_acc: 0.90527 |  iteration: 6075 teacher: 1 stage: sketch lr: 0.000567\n",
      "batch 1103 loss: 0.27574 acc: 0.92871 | v_loss: 0.63573 v_acc: 0.86947 |  iteration: 6076 teacher: 1 stage: sketch lr: 0.000567\n",
      "batch 1104 loss: 0.35396 acc: 0.90299 | v_loss: 0.58649 v_acc: 0.88379 |  iteration: 6077 teacher: 1 stage: sketch lr: 0.000567\n",
      "batch 1105 loss: 0.32120 acc: 0.91178 | v_loss: 0.47479 v_acc: 0.89388 |  iteration: 6078 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 1106 loss: 0.27118 acc: 0.91276 | v_loss: 1.10637 v_acc: 0.80046 |  iteration: 6079 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 1107 loss: 0.29443 acc: 0.91732 | v_loss: 0.37329 v_acc: 0.91309 |  iteration: 6080 teacher: 1 stage: sketch lr: 0.000567\n",
      "batch 1108 loss: 0.32853 acc: 0.89844 | v_loss: 0.59911 v_acc: 0.87598 |  iteration: 6081 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 1109 loss: 0.24716 acc: 0.92285 | v_loss: 0.52626 v_acc: 0.88444 |  iteration: 6082 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 1110 loss: 0.32937 acc: 0.90202 | v_loss: 0.42369 v_acc: 0.90755 |  iteration: 6083 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 1111 loss: 0.22574 acc: 0.92611 | v_loss: 0.50819 v_acc: 0.89030 |  iteration: 6084 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 1112 loss: 0.30645 acc: 0.90658 | v_loss: 0.61725 v_acc: 0.87044 |  iteration: 6085 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 1113 loss: 0.33358 acc: 0.90462 | v_loss: 0.44988 v_acc: 0.89941 |  iteration: 6086 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 1114 loss: 0.29554 acc: 0.91667 | v_loss: 0.59749 v_acc: 0.87174 |  iteration: 6087 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 1115 loss: 0.19679 acc: 0.94368 | v_loss: 0.42337 v_acc: 0.89388 |  iteration: 6088 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 1116 loss: 0.28830 acc: 0.91146 | v_loss: 0.94166 v_acc: 0.80697 |  iteration: 6089 teacher: 0 stage: sketch lr: 0.000566\n",
      "batch 1117 loss: 0.31407 acc: 0.90462 | v_loss: 0.57463 v_acc: 0.87663 |  iteration: 6090 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 1118 loss: 0.33661 acc: 0.89909 | v_loss: 0.66517 v_acc: 0.86165 |  iteration: 6091 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 1119 loss: 0.28029 acc: 0.91536 | v_loss: 0.43481 v_acc: 0.89844 |  iteration: 6092 teacher: 0 stage: sketch lr: 0.000566\n",
      "batch 1120 loss: 0.32602 acc: 0.90592 | v_loss: 0.64239 v_acc: 0.86556 |  iteration: 6093 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 1121 loss: 0.20868 acc: 0.94238 | v_loss: 0.43230 v_acc: 0.90299 |  iteration: 6094 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 1122 loss: 0.27405 acc: 0.92057 | v_loss: 0.50996 v_acc: 0.88672 |  iteration: 6095 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 1123 loss: 0.37915 acc: 0.89290 | v_loss: 0.48709 v_acc: 0.88509 |  iteration: 6096 teacher: 0 stage: sketch lr: 0.000566\n",
      "batch 1124 loss: 0.32670 acc: 0.91764 | v_loss: 0.75663 v_acc: 0.85091 |  iteration: 6097 teacher: 0 stage: sketch lr: 0.000566\n",
      "batch 1125 loss: 0.36215 acc: 0.90397 | v_loss: 0.52321 v_acc: 0.89518 |  iteration: 6098 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 1126 loss: 0.22123 acc: 0.93457 | v_loss: 0.53088 v_acc: 0.87728 |  iteration: 6099 teacher: 0 stage: sketch lr: 0.000566\n",
      "batch 1127 loss: 0.31189 acc: 0.91602 | v_loss: 0.66258 v_acc: 0.85124 |  iteration: 6100 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 1128 loss: 0.25106 acc: 0.92318 | v_loss: 0.44947 v_acc: 0.88802 |  iteration: 6101 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 1129 loss: 0.31955 acc: 0.90495 | v_loss: 0.52024 v_acc: 0.86556 |  iteration: 6102 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 1130 loss: 0.27809 acc: 0.91732 | v_loss: 0.55550 v_acc: 0.87174 |  iteration: 6103 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 1131 loss: 0.33793 acc: 0.90495 | v_loss: 0.81611 v_acc: 0.83887 |  iteration: 6104 teacher: 0 stage: sketch lr: 0.000566\n",
      "batch 1132 loss: 0.31034 acc: 0.91211 | v_loss: 0.55553 v_acc: 0.88249 |  iteration: 6105 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 1133 loss: 0.26116 acc: 0.92383 | v_loss: 0.55496 v_acc: 0.88802 |  iteration: 6106 teacher: 0 stage: sketch lr: 0.000566\n",
      "batch 1134 loss: 0.29562 acc: 0.90918 | v_loss: 0.63515 v_acc: 0.88086 |  iteration: 6107 teacher: 0 stage: sketch lr: 0.000566\n",
      "batch 1135 loss: 0.29577 acc: 0.91211 | v_loss: 0.58742 v_acc: 0.85905 |  iteration: 6108 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 1136 loss: 0.29507 acc: 0.91862 | v_loss: 0.48794 v_acc: 0.89225 |  iteration: 6109 teacher: 1 stage: sketch lr: 0.000565\n",
      "batch 1137 loss: 0.30390 acc: 0.91374 | v_loss: 0.81910 v_acc: 0.83757 |  iteration: 6110 teacher: 1 stage: sketch lr: 0.000565\n",
      "batch 1138 loss: 0.25239 acc: 0.92741 | v_loss: 0.58915 v_acc: 0.87793 |  iteration: 6111 teacher: 1 stage: sketch lr: 0.000565\n",
      "batch 1139 loss: 0.21666 acc: 0.93457 | v_loss: 0.57094 v_acc: 0.86914 |  iteration: 6112 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 1140 loss: 0.33412 acc: 0.90007 | v_loss: 0.54723 v_acc: 0.87891 |  iteration: 6113 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 1141 loss: 0.25090 acc: 0.92708 | v_loss: 0.45733 v_acc: 0.89258 |  iteration: 6114 teacher: 1 stage: sketch lr: 0.000565\n",
      "batch 1142 loss: 0.28620 acc: 0.91764 | v_loss: 0.45479 v_acc: 0.89193 |  iteration: 6115 teacher: 1 stage: sketch lr: 0.000565\n",
      "batch 1143 loss: 0.34853 acc: 0.89844 | v_loss: 0.55718 v_acc: 0.87728 |  iteration: 6116 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 1144 loss: 0.30104 acc: 0.91374 | v_loss: 0.60889 v_acc: 0.84863 |  iteration: 6117 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 1145 loss: 0.28860 acc: 0.92188 | v_loss: 0.57888 v_acc: 0.87728 |  iteration: 6118 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 1146 loss: 0.32335 acc: 0.90202 | v_loss: 0.63843 v_acc: 0.87598 |  iteration: 6119 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 1147 loss: 0.29207 acc: 0.91634 | v_loss: 0.40347 v_acc: 0.90234 |  iteration: 6120 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 1148 loss: 0.28388 acc: 0.91797 | v_loss: 0.56250 v_acc: 0.87923 |  iteration: 6121 teacher: 1 stage: sketch lr: 0.000565\n",
      "batch 1149 loss: 0.33766 acc: 0.89681 | v_loss: 0.49077 v_acc: 0.88477 |  iteration: 6122 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 1150 loss: 0.34024 acc: 0.90332 | v_loss: 0.87728 v_acc: 0.83171 |  iteration: 6123 teacher: 1 stage: sketch lr: 0.000565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1151 loss: 0.27341 acc: 0.91927 | v_loss: 0.39056 v_acc: 0.90332 |  iteration: 6124 teacher: 1 stage: sketch lr: 0.000565\n",
      "batch 1152 loss: 0.25027 acc: 0.91829 | v_loss: 0.30098 v_acc: 0.92122 |  iteration: 6125 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 1153 loss: 0.24058 acc: 0.92676 | v_loss: 0.53639 v_acc: 0.88118 |  iteration: 6126 teacher: 1 stage: sketch lr: 0.000565\n",
      "batch 1154 loss: 0.34688 acc: 0.90983 | v_loss: 0.54728 v_acc: 0.89062 |  iteration: 6127 teacher: 1 stage: sketch lr: 0.000565\n",
      "batch 1155 loss: 0.33954 acc: 0.90625 | v_loss: 0.65088 v_acc: 0.86882 |  iteration: 6128 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 1156 loss: 0.24254 acc: 0.92806 | v_loss: 0.41996 v_acc: 0.90332 |  iteration: 6129 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 1157 loss: 0.21540 acc: 0.93555 | v_loss: 0.49833 v_acc: 0.87695 |  iteration: 6130 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 1158 loss: 0.29720 acc: 0.91732 | v_loss: 0.63047 v_acc: 0.86882 |  iteration: 6131 teacher: 1 stage: sketch lr: 0.000564\n",
      "batch 1159 loss: 0.32273 acc: 0.90983 | v_loss: 0.64563 v_acc: 0.85449 |  iteration: 6132 teacher: 1 stage: sketch lr: 0.000564\n",
      "batch 1160 loss: 0.23649 acc: 0.92448 | v_loss: 0.47382 v_acc: 0.89811 |  iteration: 6133 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 1161 loss: 0.26383 acc: 0.91829 | v_loss: 0.40877 v_acc: 0.90885 |  iteration: 6134 teacher: 1 stage: sketch lr: 0.000564\n",
      "batch 1162 loss: 0.26745 acc: 0.91732 | v_loss: 0.35396 v_acc: 0.91211 |  iteration: 6135 teacher: 1 stage: sketch lr: 0.000564\n",
      "batch 1163 loss: 0.30936 acc: 0.91243 | v_loss: 0.47014 v_acc: 0.90007 |  iteration: 6136 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 1164 loss: 0.36120 acc: 0.90332 | v_loss: 0.52037 v_acc: 0.87500 |  iteration: 6137 teacher: 1 stage: sketch lr: 0.000564\n",
      "batch 1165 loss: 0.27685 acc: 0.92611 | v_loss: 0.80990 v_acc: 0.85482 |  iteration: 6138 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 1166 loss: 0.25437 acc: 0.92969 | v_loss: 0.54198 v_acc: 0.87337 |  iteration: 6139 teacher: 1 stage: sketch lr: 0.000564\n",
      "batch 1167 loss: 0.26162 acc: 0.92220 | v_loss: 0.65440 v_acc: 0.86654 |  iteration: 6140 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 1168 loss: 0.25557 acc: 0.93034 | v_loss: 0.40748 v_acc: 0.89648 |  iteration: 6141 teacher: 1 stage: sketch lr: 0.000564\n",
      "batch 1169 loss: 0.28219 acc: 0.91602 | v_loss: 0.54651 v_acc: 0.87760 |  iteration: 6142 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 1170 loss: 0.29045 acc: 0.91732 | v_loss: 0.71191 v_acc: 0.85417 |  iteration: 6143 teacher: 1 stage: sketch lr: 0.000564\n",
      "batch 1171 loss: 0.25080 acc: 0.92676 | v_loss: 0.54686 v_acc: 0.88802 |  iteration: 6144 teacher: 1 stage: sketch lr: 0.000564\n",
      "batch 1172 loss: 0.41541 acc: 0.88704 | v_loss: 0.55087 v_acc: 0.88216 |  iteration: 6145 teacher: 1 stage: sketch lr: 0.000564\n",
      "batch 1173 loss: 0.23496 acc: 0.92839 | v_loss: 0.49076 v_acc: 0.88346 |  iteration: 6146 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 1174 loss: 0.30479 acc: 0.91406 | v_loss: 0.39385 v_acc: 0.90658 |  iteration: 6147 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 1175 loss: 0.29311 acc: 0.91276 | v_loss: 0.47280 v_acc: 0.89453 |  iteration: 6148 teacher: 1 stage: sketch lr: 0.000564\n",
      "batch 1176 loss: 0.26623 acc: 0.92253 | v_loss: 0.58277 v_acc: 0.86751 |  iteration: 6149 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 1177 loss: 0.25899 acc: 0.91862 | v_loss: 0.37346 v_acc: 0.91569 |  iteration: 6150 teacher: 1 stage: sketch lr: 0.000564\n",
      "batch 1178 loss: 0.21883 acc: 0.93620 | v_loss: 0.89808 v_acc: 0.82943 |  iteration: 6151 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 1179 loss: 0.21741 acc: 0.93164 | v_loss: 0.62882 v_acc: 0.87793 |  iteration: 6152 teacher: 0 stage: sketch lr: 0.000563\n",
      "batch 1180 loss: 0.27336 acc: 0.92285 | v_loss: 0.68418 v_acc: 0.86263 |  iteration: 6153 teacher: 0 stage: sketch lr: 0.000563\n",
      "batch 1181 loss: 0.30358 acc: 0.91927 | v_loss: 0.49597 v_acc: 0.89583 |  iteration: 6154 teacher: 0 stage: sketch lr: 0.000563\n",
      "batch 1182 loss: 0.27298 acc: 0.92025 | v_loss: 0.46961 v_acc: 0.89551 |  iteration: 6155 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 1183 loss: 0.32657 acc: 0.90592 | v_loss: 0.55027 v_acc: 0.88997 |  iteration: 6156 teacher: 0 stage: sketch lr: 0.000563\n",
      "batch 1184 loss: 0.27319 acc: 0.91764 | v_loss: 0.53310 v_acc: 0.88867 |  iteration: 6157 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 1185 loss: 0.31261 acc: 0.91602 | v_loss: 0.54683 v_acc: 0.87695 |  iteration: 6158 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 1186 loss: 0.28225 acc: 0.92448 | v_loss: 0.49120 v_acc: 0.89681 |  iteration: 6159 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 1187 loss: 0.31336 acc: 0.91764 | v_loss: 0.43081 v_acc: 0.90007 |  iteration: 6160 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 1188 loss: 0.23882 acc: 0.92871 | v_loss: 0.36425 v_acc: 0.91992 |  iteration: 6161 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 1189 loss: 0.22953 acc: 0.93359 | v_loss: 0.65705 v_acc: 0.85970 |  iteration: 6162 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 1190 loss: 0.30536 acc: 0.91341 | v_loss: 0.56400 v_acc: 0.86751 |  iteration: 6163 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 1191 loss: 0.22607 acc: 0.93294 | v_loss: 0.61728 v_acc: 0.86589 |  iteration: 6164 teacher: 0 stage: sketch lr: 0.000563\n",
      "batch 1192 loss: 0.30837 acc: 0.90918 | v_loss: 0.81699 v_acc: 0.84440 |  iteration: 6165 teacher: 0 stage: sketch lr: 0.000563\n",
      "batch 1193 loss: 0.27045 acc: 0.92480 | v_loss: 0.42954 v_acc: 0.89811 |  iteration: 6166 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 1194 loss: 0.28460 acc: 0.91895 | v_loss: 0.54583 v_acc: 0.87793 |  iteration: 6167 teacher: 0 stage: sketch lr: 0.000563\n",
      "batch 1195 loss: 0.32012 acc: 0.91048 | v_loss: 0.59523 v_acc: 0.88444 |  iteration: 6168 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 1196 loss: 0.22388 acc: 0.93457 | v_loss: 0.42910 v_acc: 0.90169 |  iteration: 6169 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 1197 loss: 0.27048 acc: 0.91406 | v_loss: 1.15474 v_acc: 0.80241 |  iteration: 6170 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 1198 loss: 0.24552 acc: 0.92773 | v_loss: 0.39579 v_acc: 0.90918 |  iteration: 6171 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 1199 loss: 0.27621 acc: 0.91960 | v_loss: 0.56577 v_acc: 0.88216 |  iteration: 6172 teacher: 0 stage: sketch lr: 0.000563\n",
      "batch 1200 loss: 0.33316 acc: 0.89876 | v_loss: 0.49191 v_acc: 0.89258 |  iteration: 6173 teacher: 1 stage: sketch lr: 0.000562\n",
      "batch 1201 loss: 0.26745 acc: 0.92155 | v_loss: 0.41365 v_acc: 0.89876 |  iteration: 6174 teacher: 1 stage: sketch lr: 0.000562\n",
      "batch 1202 loss: 0.38230 acc: 0.89453 | v_loss: 0.48154 v_acc: 0.88900 |  iteration: 6175 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 1203 loss: 0.33082 acc: 0.91471 | v_loss: 0.59361 v_acc: 0.86751 |  iteration: 6176 teacher: 1 stage: sketch lr: 0.000562\n",
      "batch 1204 loss: 0.28521 acc: 0.91309 | v_loss: 0.42193 v_acc: 0.90397 |  iteration: 6177 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 1205 loss: 0.25271 acc: 0.92415 | v_loss: 0.61293 v_acc: 0.86719 |  iteration: 6178 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 1206 loss: 0.28175 acc: 0.91797 | v_loss: 0.35901 v_acc: 0.90983 |  iteration: 6179 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 1207 loss: 0.30158 acc: 0.91113 | v_loss: 0.93167 v_acc: 0.82617 |  iteration: 6180 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 1208 loss: 0.17700 acc: 0.94922 | v_loss: 0.57044 v_acc: 0.88704 |  iteration: 6181 teacher: 1 stage: sketch lr: 0.000562\n",
      "batch 1209 loss: 0.35217 acc: 0.89583 | v_loss: 0.64869 v_acc: 0.87663 |  iteration: 6182 teacher: 1 stage: sketch lr: 0.000562\n",
      "batch 1210 loss: 0.33012 acc: 0.90690 | v_loss: 0.42414 v_acc: 0.90365 |  iteration: 6183 teacher: 1 stage: sketch lr: 0.000562\n",
      "batch 1211 loss: 0.27081 acc: 0.92188 | v_loss: 0.65423 v_acc: 0.85742 |  iteration: 6184 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 1212 loss: 0.32184 acc: 0.90299 | v_loss: 0.42024 v_acc: 0.89909 |  iteration: 6185 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 1213 loss: 0.27228 acc: 0.92480 | v_loss: 0.45920 v_acc: 0.89030 |  iteration: 6186 teacher: 1 stage: sketch lr: 0.000562\n",
      "batch 1214 loss: 0.28538 acc: 0.91374 | v_loss: 0.42588 v_acc: 0.89909 |  iteration: 6187 teacher: 1 stage: sketch lr: 0.000562\n",
      "batch 1215 loss: 0.27607 acc: 0.92448 | v_loss: 0.73464 v_acc: 0.85579 |  iteration: 6188 teacher: 1 stage: sketch lr: 0.000562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1216 loss: 0.23363 acc: 0.93197 | v_loss: 0.51960 v_acc: 0.89323 |  iteration: 6189 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 1217 loss: 0.24455 acc: 0.93001 | v_loss: 0.56705 v_acc: 0.87533 |  iteration: 6190 teacher: 1 stage: sketch lr: 0.000562\n",
      "batch 1218 loss: 0.20644 acc: 0.93359 | v_loss: 0.67401 v_acc: 0.85091 |  iteration: 6191 teacher: 1 stage: sketch lr: 0.000562\n",
      "batch 1219 loss: 0.27971 acc: 0.91699 | v_loss: 0.47292 v_acc: 0.89616 |  iteration: 6192 teacher: 1 stage: sketch lr: 0.000562\n",
      "batch 1220 loss: 0.27257 acc: 0.92350 | v_loss: 0.48918 v_acc: 0.87598 |  iteration: 6193 teacher: 1 stage: sketch lr: 0.000562\n",
      "batch 1221 loss: 0.27626 acc: 0.92188 | v_loss: 0.52170 v_acc: 0.87305 |  iteration: 6194 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 1222 loss: 0.42968 acc: 0.88118 | v_loss: 0.72909 v_acc: 0.85286 |  iteration: 6195 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 1223 loss: 0.29359 acc: 0.91667 | v_loss: 0.52178 v_acc: 0.88867 |  iteration: 6196 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 1224 loss: 0.31186 acc: 0.91309 | v_loss: 0.58834 v_acc: 0.87174 |  iteration: 6197 teacher: 0 stage: sketch lr: 0.000561\n",
      "batch 1225 loss: 0.26952 acc: 0.92480 | v_loss: 0.63437 v_acc: 0.88151 |  iteration: 6198 teacher: 0 stage: sketch lr: 0.000561\n",
      "batch 1226 loss: 0.24988 acc: 0.93001 | v_loss: 0.54263 v_acc: 0.86426 |  iteration: 6199 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 1227 loss: 0.32313 acc: 0.90397 | v_loss: 0.43383 v_acc: 0.89876 |  iteration: 6200 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 1228 loss: 0.45454 acc: 0.88835 | v_loss: 0.75280 v_acc: 0.84277 |  iteration: 6201 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 1229 loss: 0.35207 acc: 0.89421 | v_loss: 0.58335 v_acc: 0.87630 |  iteration: 6202 teacher: 0 stage: sketch lr: 0.000561\n",
      "batch 1230 loss: 0.31641 acc: 0.90983 | v_loss: 0.54786 v_acc: 0.87044 |  iteration: 6203 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 1231 loss: 0.27162 acc: 0.91699 | v_loss: 0.55045 v_acc: 0.87533 |  iteration: 6204 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 1232 loss: 0.29904 acc: 0.90885 | v_loss: 0.46786 v_acc: 0.88900 |  iteration: 6205 teacher: 0 stage: sketch lr: 0.000561\n",
      "batch 1233 loss: 0.36509 acc: 0.89844 | v_loss: 0.46575 v_acc: 0.88672 |  iteration: 6206 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 1234 loss: 0.25886 acc: 0.91829 | v_loss: 0.50834 v_acc: 0.88216 |  iteration: 6207 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 1235 loss: 0.25977 acc: 0.92057 | v_loss: 0.56271 v_acc: 0.86198 |  iteration: 6208 teacher: 0 stage: sketch lr: 0.000561\n",
      "batch 1236 loss: 0.27836 acc: 0.91829 | v_loss: 0.56081 v_acc: 0.88737 |  iteration: 6209 teacher: 0 stage: sketch lr: 0.000561\n",
      "batch 1237 loss: 0.21716 acc: 0.93294 | v_loss: 0.57344 v_acc: 0.88184 |  iteration: 6210 teacher: 0 stage: sketch lr: 0.000561\n",
      "batch 1238 loss: 0.28209 acc: 0.91569 | v_loss: 0.38236 v_acc: 0.90365 |  iteration: 6211 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 1239 loss: 0.21938 acc: 0.93457 | v_loss: 0.53468 v_acc: 0.87891 |  iteration: 6212 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 1240 loss: 0.24091 acc: 0.92936 | v_loss: 0.47373 v_acc: 0.88151 |  iteration: 6213 teacher: 0 stage: sketch lr: 0.000561\n",
      "batch 1241 loss: 0.27270 acc: 0.91732 | v_loss: 0.89929 v_acc: 0.82910 |  iteration: 6214 teacher: 0 stage: sketch lr: 0.000561\n",
      "batch 1242 loss: 0.27647 acc: 0.91634 | v_loss: 0.39327 v_acc: 0.90299 |  iteration: 6215 teacher: 0 stage: sketch lr: 0.000561\n",
      "epoch 4 loss: 0.27838 acc: 0.91950 | v_loss: 0.55429 v_acc: 0.88086 \n",
      "epoch: 5\n",
      "__________________________________________\n",
      "batch 0 loss: 0.21409 acc: 0.93848 | v_loss: 0.61656 v_acc: 0.87663 |  iteration: 6216 teacher: 0 stage: sketch lr: 0.000561\n",
      "batch 1 loss: 0.24526 acc: 0.92708 | v_loss: 0.54263 v_acc: 0.89128 |  iteration: 6217 teacher: 0 stage: sketch lr: 0.000560\n",
      "batch 2 loss: 0.31773 acc: 0.90788 | v_loss: 0.52583 v_acc: 0.89225 |  iteration: 6218 teacher: 0 stage: sketch lr: 0.000560\n",
      "batch 3 loss: 0.34259 acc: 0.90527 | v_loss: 0.49710 v_acc: 0.90104 |  iteration: 6219 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 4 loss: 0.27959 acc: 0.91732 | v_loss: 0.43730 v_acc: 0.88932 |  iteration: 6220 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 5 loss: 0.28605 acc: 0.91992 | v_loss: 0.34045 v_acc: 0.91797 |  iteration: 6221 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 6 loss: 0.34698 acc: 0.90495 | v_loss: 0.61955 v_acc: 0.85807 |  iteration: 6222 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 7 loss: 0.22868 acc: 0.93197 | v_loss: 0.53160 v_acc: 0.86556 |  iteration: 6223 teacher: 0 stage: sketch lr: 0.000560\n",
      "batch 8 loss: 0.25889 acc: 0.92546 | v_loss: 0.61425 v_acc: 0.86361 |  iteration: 6224 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 9 loss: 0.24943 acc: 0.91960 | v_loss: 0.81878 v_acc: 0.84180 |  iteration: 6225 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 10 loss: 0.30039 acc: 0.90495 | v_loss: 0.41765 v_acc: 0.90755 |  iteration: 6226 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 11 loss: 0.24678 acc: 0.92546 | v_loss: 0.54089 v_acc: 0.88151 |  iteration: 6227 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 12 loss: 0.29413 acc: 0.92188 | v_loss: 0.54960 v_acc: 0.89225 |  iteration: 6228 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 13 loss: 0.21974 acc: 0.93522 | v_loss: 0.45476 v_acc: 0.89616 |  iteration: 6229 teacher: 0 stage: sketch lr: 0.000560\n",
      "batch 14 loss: 0.25446 acc: 0.92480 | v_loss: 1.12688 v_acc: 0.81315 |  iteration: 6230 teacher: 0 stage: sketch lr: 0.000560\n",
      "batch 15 loss: 0.33902 acc: 0.90430 | v_loss: 0.42560 v_acc: 0.91178 |  iteration: 6231 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 16 loss: 0.22588 acc: 0.93001 | v_loss: 0.58943 v_acc: 0.87728 |  iteration: 6232 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 17 loss: 0.27689 acc: 0.91569 | v_loss: 0.56000 v_acc: 0.87956 |  iteration: 6233 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 18 loss: 0.31220 acc: 0.90625 | v_loss: 0.45394 v_acc: 0.90332 |  iteration: 6234 teacher: 0 stage: sketch lr: 0.000560\n",
      "batch 19 loss: 0.32364 acc: 0.90104 | v_loss: 0.48004 v_acc: 0.89388 |  iteration: 6235 teacher: 0 stage: sketch lr: 0.000560\n",
      "batch 20 loss: 0.36856 acc: 0.89453 | v_loss: 0.55858 v_acc: 0.87858 |  iteration: 6236 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 21 loss: 0.30396 acc: 0.90625 | v_loss: 0.44395 v_acc: 0.89941 |  iteration: 6237 teacher: 0 stage: sketch lr: 0.000560\n",
      "batch 22 loss: 0.32206 acc: 0.90462 | v_loss: 0.63682 v_acc: 0.86263 |  iteration: 6238 teacher: 0 stage: sketch lr: 0.000560\n",
      "batch 23 loss: 0.35977 acc: 0.89518 | v_loss: 0.37301 v_acc: 0.90365 |  iteration: 6239 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 24 loss: 0.22012 acc: 0.93652 | v_loss: 0.93315 v_acc: 0.82031 |  iteration: 6240 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 25 loss: 0.27125 acc: 0.91536 | v_loss: 0.56223 v_acc: 0.88802 |  iteration: 6241 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 26 loss: 0.25592 acc: 0.91960 | v_loss: 0.62875 v_acc: 0.86751 |  iteration: 6242 teacher: 1 stage: sketch lr: 0.000559\n",
      "batch 27 loss: 0.25062 acc: 0.92546 | v_loss: 0.41062 v_acc: 0.89648 |  iteration: 6243 teacher: 1 stage: sketch lr: 0.000559\n",
      "batch 28 loss: 0.30890 acc: 0.90885 | v_loss: 0.65642 v_acc: 0.85514 |  iteration: 6244 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 29 loss: 0.27278 acc: 0.91439 | v_loss: 0.41773 v_acc: 0.89844 |  iteration: 6245 teacher: 1 stage: sketch lr: 0.000559\n",
      "batch 30 loss: 0.21073 acc: 0.93783 | v_loss: 0.44996 v_acc: 0.88965 |  iteration: 6246 teacher: 1 stage: sketch lr: 0.000559\n",
      "batch 31 loss: 0.29130 acc: 0.91341 | v_loss: 0.43734 v_acc: 0.89355 |  iteration: 6247 teacher: 1 stage: sketch lr: 0.000559\n",
      "batch 32 loss: 0.28776 acc: 0.91081 | v_loss: 0.71129 v_acc: 0.86426 |  iteration: 6248 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 33 loss: 0.21784 acc: 0.93132 | v_loss: 0.50700 v_acc: 0.89290 |  iteration: 6249 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 34 loss: 0.25504 acc: 0.92904 | v_loss: 0.51983 v_acc: 0.87956 |  iteration: 6250 teacher: 1 stage: sketch lr: 0.000559\n",
      "batch 35 loss: 0.24445 acc: 0.92448 | v_loss: 0.66853 v_acc: 0.85547 |  iteration: 6251 teacher: 1 stage: sketch lr: 0.000559\n",
      "batch 36 loss: 0.26122 acc: 0.92253 | v_loss: 0.43893 v_acc: 0.89909 |  iteration: 6252 teacher: 0 stage: sketch lr: 0.000559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 37 loss: 0.29579 acc: 0.91374 | v_loss: 0.53537 v_acc: 0.87044 |  iteration: 6253 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 38 loss: 0.21346 acc: 0.93620 | v_loss: 0.57139 v_acc: 0.86719 |  iteration: 6254 teacher: 1 stage: sketch lr: 0.000559\n",
      "batch 39 loss: 0.26551 acc: 0.92773 | v_loss: 0.72605 v_acc: 0.85059 |  iteration: 6255 teacher: 1 stage: sketch lr: 0.000559\n",
      "batch 40 loss: 0.28815 acc: 0.91309 | v_loss: 0.55959 v_acc: 0.87956 |  iteration: 6256 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 41 loss: 0.33402 acc: 0.89844 | v_loss: 0.53129 v_acc: 0.88639 |  iteration: 6257 teacher: 1 stage: sketch lr: 0.000559\n",
      "batch 42 loss: 0.29147 acc: 0.91211 | v_loss: 0.63558 v_acc: 0.87240 |  iteration: 6258 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 43 loss: 0.35472 acc: 0.90169 | v_loss: 0.60105 v_acc: 0.85417 |  iteration: 6259 teacher: 1 stage: sketch lr: 0.000559\n",
      "batch 44 loss: 0.22380 acc: 0.93229 | v_loss: 0.45864 v_acc: 0.89323 |  iteration: 6260 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 45 loss: 0.28191 acc: 0.91504 | v_loss: 0.76906 v_acc: 0.84180 |  iteration: 6261 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 46 loss: 0.21211 acc: 0.93620 | v_loss: 0.54141 v_acc: 0.88086 |  iteration: 6262 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 47 loss: 0.23897 acc: 0.92871 | v_loss: 0.58289 v_acc: 0.87012 |  iteration: 6263 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 48 loss: 0.28936 acc: 0.91634 | v_loss: 0.52408 v_acc: 0.88249 |  iteration: 6264 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 49 loss: 0.23839 acc: 0.92155 | v_loss: 0.44198 v_acc: 0.89746 |  iteration: 6265 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 50 loss: 0.23292 acc: 0.93490 | v_loss: 0.45332 v_acc: 0.89583 |  iteration: 6266 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 51 loss: 0.32002 acc: 0.91178 | v_loss: 0.51327 v_acc: 0.88997 |  iteration: 6267 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 52 loss: 0.25551 acc: 0.92155 | v_loss: 0.63591 v_acc: 0.85319 |  iteration: 6268 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 53 loss: 0.30929 acc: 0.91243 | v_loss: 0.57490 v_acc: 0.88997 |  iteration: 6269 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 54 loss: 0.22650 acc: 0.93620 | v_loss: 0.64068 v_acc: 0.87891 |  iteration: 6270 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 55 loss: 0.28315 acc: 0.91927 | v_loss: 0.38766 v_acc: 0.90202 |  iteration: 6271 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 56 loss: 0.27450 acc: 0.91699 | v_loss: 0.52307 v_acc: 0.88997 |  iteration: 6272 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 57 loss: 0.30661 acc: 0.91439 | v_loss: 0.46684 v_acc: 0.87923 |  iteration: 6273 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 58 loss: 0.24049 acc: 0.92220 | v_loss: 0.85297 v_acc: 0.82780 |  iteration: 6274 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 59 loss: 0.30832 acc: 0.90853 | v_loss: 0.38856 v_acc: 0.89518 |  iteration: 6275 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 60 loss: 0.24655 acc: 0.91992 | v_loss: 0.32303 v_acc: 0.91829 |  iteration: 6276 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 61 loss: 0.27008 acc: 0.91667 | v_loss: 0.59237 v_acc: 0.87663 |  iteration: 6277 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 62 loss: 0.29433 acc: 0.91146 | v_loss: 0.58339 v_acc: 0.88444 |  iteration: 6278 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 63 loss: 0.31054 acc: 0.91211 | v_loss: 0.66248 v_acc: 0.85612 |  iteration: 6279 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 64 loss: 0.28432 acc: 0.90885 | v_loss: 0.41929 v_acc: 0.89974 |  iteration: 6280 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 65 loss: 0.23122 acc: 0.92806 | v_loss: 0.48736 v_acc: 0.87858 |  iteration: 6281 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 66 loss: 0.27760 acc: 0.92253 | v_loss: 0.57167 v_acc: 0.87370 |  iteration: 6282 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 67 loss: 0.26417 acc: 0.92188 | v_loss: 0.66411 v_acc: 0.85059 |  iteration: 6283 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 68 loss: 0.35817 acc: 0.89290 | v_loss: 0.53264 v_acc: 0.88639 |  iteration: 6284 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 69 loss: 0.33228 acc: 0.90918 | v_loss: 0.39877 v_acc: 0.90560 |  iteration: 6285 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 70 loss: 0.17905 acc: 0.94629 | v_loss: 0.27751 v_acc: 0.92578 |  iteration: 6286 teacher: 1 stage: sketch lr: 0.000557\n",
      "batch 71 loss: 0.21427 acc: 0.93652 | v_loss: 0.41958 v_acc: 0.90560 |  iteration: 6287 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 72 loss: 0.23854 acc: 0.93164 | v_loss: 0.51498 v_acc: 0.87826 |  iteration: 6288 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 73 loss: 0.35445 acc: 0.89779 | v_loss: 0.84677 v_acc: 0.85286 |  iteration: 6289 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 74 loss: 0.25299 acc: 0.92253 | v_loss: 0.52030 v_acc: 0.88216 |  iteration: 6290 teacher: 1 stage: sketch lr: 0.000557\n",
      "batch 75 loss: 0.25519 acc: 0.92253 | v_loss: 0.63122 v_acc: 0.87240 |  iteration: 6291 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 76 loss: 0.31345 acc: 0.91211 | v_loss: 0.41087 v_acc: 0.90234 |  iteration: 6292 teacher: 1 stage: sketch lr: 0.000557\n",
      "batch 77 loss: 0.38218 acc: 0.89453 | v_loss: 0.51985 v_acc: 0.88542 |  iteration: 6293 teacher: 1 stage: sketch lr: 0.000557\n",
      "batch 78 loss: 0.28896 acc: 0.91569 | v_loss: 0.75744 v_acc: 0.85156 |  iteration: 6294 teacher: 1 stage: sketch lr: 0.000557\n",
      "batch 79 loss: 0.30533 acc: 0.91211 | v_loss: 0.46878 v_acc: 0.89160 |  iteration: 6295 teacher: 1 stage: sketch lr: 0.000557\n",
      "batch 80 loss: 0.26063 acc: 0.92253 | v_loss: 0.50026 v_acc: 0.89258 |  iteration: 6296 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 81 loss: 0.23887 acc: 0.92806 | v_loss: 0.48107 v_acc: 0.88249 |  iteration: 6297 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 82 loss: 0.28230 acc: 0.92220 | v_loss: 0.43078 v_acc: 0.90202 |  iteration: 6298 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 83 loss: 0.20389 acc: 0.93717 | v_loss: 0.46231 v_acc: 0.90658 |  iteration: 6299 teacher: 1 stage: sketch lr: 0.000557\n",
      "batch 84 loss: 0.26601 acc: 0.91471 | v_loss: 0.62597 v_acc: 0.86914 |  iteration: 6300 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 85 loss: 0.28852 acc: 0.91439 | v_loss: 0.36376 v_acc: 0.92415 |  iteration: 6301 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 86 loss: 0.26061 acc: 0.92676 | v_loss: 0.96769 v_acc: 0.82878 |  iteration: 6302 teacher: 1 stage: sketch lr: 0.000557\n",
      "batch 87 loss: 0.30523 acc: 0.92090 | v_loss: 0.66422 v_acc: 0.87435 |  iteration: 6303 teacher: 1 stage: sketch lr: 0.000557\n",
      "batch 88 loss: 0.37830 acc: 0.89583 | v_loss: 0.73237 v_acc: 0.86133 |  iteration: 6304 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 89 loss: 0.21173 acc: 0.93848 | v_loss: 0.53845 v_acc: 0.88932 |  iteration: 6305 teacher: 1 stage: sketch lr: 0.000557\n",
      "batch 90 loss: 0.26277 acc: 0.92611 | v_loss: 0.50267 v_acc: 0.88672 |  iteration: 6306 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 91 loss: 0.30778 acc: 0.90885 | v_loss: 0.59140 v_acc: 0.87728 |  iteration: 6307 teacher: 1 stage: sketch lr: 0.000556\n",
      "batch 92 loss: 0.27472 acc: 0.91829 | v_loss: 0.51531 v_acc: 0.88737 |  iteration: 6308 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 93 loss: 0.26095 acc: 0.92253 | v_loss: 0.47402 v_acc: 0.88509 |  iteration: 6309 teacher: 1 stage: sketch lr: 0.000556\n",
      "batch 94 loss: 0.19533 acc: 0.93978 | v_loss: 0.49595 v_acc: 0.89551 |  iteration: 6310 teacher: 1 stage: sketch lr: 0.000556\n",
      "batch 95 loss: 0.33409 acc: 0.89844 | v_loss: 0.46188 v_acc: 0.89193 |  iteration: 6311 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 96 loss: 0.29567 acc: 0.90755 | v_loss: 0.35136 v_acc: 0.91634 |  iteration: 6312 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 97 loss: 0.25858 acc: 0.92611 | v_loss: 0.63795 v_acc: 0.85286 |  iteration: 6313 teacher: 1 stage: sketch lr: 0.000556\n",
      "batch 98 loss: 0.32966 acc: 0.90625 | v_loss: 0.54677 v_acc: 0.86100 |  iteration: 6314 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 99 loss: 0.32979 acc: 0.90365 | v_loss: 0.58632 v_acc: 0.86263 |  iteration: 6315 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 100 loss: 0.27218 acc: 0.91797 | v_loss: 0.79564 v_acc: 0.84017 |  iteration: 6316 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 101 loss: 0.26669 acc: 0.92773 | v_loss: 0.41999 v_acc: 0.90169 |  iteration: 6317 teacher: 1 stage: sketch lr: 0.000556\n",
      "batch 102 loss: 0.34969 acc: 0.89779 | v_loss: 0.58392 v_acc: 0.86979 |  iteration: 6318 teacher: 0 stage: sketch lr: 0.000556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 103 loss: 0.27738 acc: 0.92415 | v_loss: 0.52604 v_acc: 0.88965 |  iteration: 6319 teacher: 1 stage: sketch lr: 0.000556\n",
      "batch 104 loss: 0.19247 acc: 0.94434 | v_loss: 0.45754 v_acc: 0.89844 |  iteration: 6320 teacher: 1 stage: sketch lr: 0.000556\n",
      "batch 105 loss: 0.32079 acc: 0.91439 | v_loss: 1.11894 v_acc: 0.80697 |  iteration: 6321 teacher: 1 stage: sketch lr: 0.000556\n",
      "batch 106 loss: 0.39628 acc: 0.89453 | v_loss: 0.38842 v_acc: 0.91602 |  iteration: 6322 teacher: 1 stage: sketch lr: 0.000556\n",
      "batch 107 loss: 0.23218 acc: 0.93359 | v_loss: 0.60501 v_acc: 0.87012 |  iteration: 6323 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 108 loss: 0.36173 acc: 0.89551 | v_loss: 0.54608 v_acc: 0.88932 |  iteration: 6324 teacher: 1 stage: sketch lr: 0.000556\n",
      "batch 109 loss: 0.25730 acc: 0.93001 | v_loss: 0.42528 v_acc: 0.90234 |  iteration: 6325 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 110 loss: 0.29537 acc: 0.91634 | v_loss: 0.52840 v_acc: 0.89486 |  iteration: 6326 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 111 loss: 0.33796 acc: 0.91276 | v_loss: 0.58351 v_acc: 0.87728 |  iteration: 6327 teacher: 1 stage: sketch lr: 0.000556\n",
      "batch 112 loss: 0.24693 acc: 0.92904 | v_loss: 0.43551 v_acc: 0.90234 |  iteration: 6328 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 113 loss: 0.21240 acc: 0.93587 | v_loss: 0.64213 v_acc: 0.87337 |  iteration: 6329 teacher: 1 stage: sketch lr: 0.000556\n",
      "batch 114 loss: 0.31951 acc: 0.90723 | v_loss: 0.39008 v_acc: 0.90592 |  iteration: 6330 teacher: 1 stage: sketch lr: 0.000555\n",
      "batch 115 loss: 0.31229 acc: 0.91569 | v_loss: 0.94652 v_acc: 0.81608 |  iteration: 6331 teacher: 1 stage: sketch lr: 0.000555\n",
      "batch 116 loss: 0.27996 acc: 0.91406 | v_loss: 0.60950 v_acc: 0.88151 |  iteration: 6332 teacher: 1 stage: sketch lr: 0.000555\n",
      "batch 117 loss: 0.24395 acc: 0.92253 | v_loss: 0.65044 v_acc: 0.86947 |  iteration: 6333 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 118 loss: 0.20509 acc: 0.93750 | v_loss: 0.40004 v_acc: 0.90299 |  iteration: 6334 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 119 loss: 0.31763 acc: 0.91406 | v_loss: 0.64047 v_acc: 0.86719 |  iteration: 6335 teacher: 1 stage: sketch lr: 0.000555\n",
      "batch 120 loss: 0.30308 acc: 0.91309 | v_loss: 0.46270 v_acc: 0.89648 |  iteration: 6336 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 121 loss: 0.28018 acc: 0.91406 | v_loss: 0.45242 v_acc: 0.88867 |  iteration: 6337 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 122 loss: 0.25388 acc: 0.93262 | v_loss: 0.44392 v_acc: 0.88542 |  iteration: 6338 teacher: 1 stage: sketch lr: 0.000555\n",
      "batch 123 loss: 0.23277 acc: 0.93099 | v_loss: 0.75218 v_acc: 0.84277 |  iteration: 6339 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 124 loss: 0.24031 acc: 0.92904 | v_loss: 0.51179 v_acc: 0.89486 |  iteration: 6340 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 125 loss: 0.26269 acc: 0.92383 | v_loss: 0.53495 v_acc: 0.88118 |  iteration: 6341 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 126 loss: 0.27692 acc: 0.91439 | v_loss: 0.66053 v_acc: 0.85384 |  iteration: 6342 teacher: 1 stage: sketch lr: 0.000555\n",
      "batch 127 loss: 0.31545 acc: 0.90495 | v_loss: 0.45632 v_acc: 0.89290 |  iteration: 6343 teacher: 1 stage: sketch lr: 0.000555\n",
      "batch 128 loss: 0.34078 acc: 0.89876 | v_loss: 0.53058 v_acc: 0.86784 |  iteration: 6344 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 129 loss: 0.33076 acc: 0.90267 | v_loss: 0.48176 v_acc: 0.87533 |  iteration: 6345 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 130 loss: 0.25878 acc: 0.91895 | v_loss: 0.75408 v_acc: 0.85221 |  iteration: 6346 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 131 loss: 0.24386 acc: 0.92090 | v_loss: 0.55286 v_acc: 0.88184 |  iteration: 6347 teacher: 1 stage: sketch lr: 0.000555\n",
      "batch 132 loss: 0.25839 acc: 0.92025 | v_loss: 0.60605 v_acc: 0.87988 |  iteration: 6348 teacher: 1 stage: sketch lr: 0.000555\n",
      "batch 133 loss: 0.27296 acc: 0.91113 | v_loss: 0.61904 v_acc: 0.88249 |  iteration: 6349 teacher: 1 stage: sketch lr: 0.000555\n",
      "batch 134 loss: 0.30316 acc: 0.91146 | v_loss: 0.57848 v_acc: 0.86426 |  iteration: 6350 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 135 loss: 0.32746 acc: 0.91081 | v_loss: 0.49133 v_acc: 0.88965 |  iteration: 6351 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 136 loss: 0.26463 acc: 0.92415 | v_loss: 0.82677 v_acc: 0.83984 |  iteration: 6352 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 137 loss: 0.20770 acc: 0.93815 | v_loss: 0.57187 v_acc: 0.87435 |  iteration: 6353 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 138 loss: 0.30643 acc: 0.90788 | v_loss: 0.59436 v_acc: 0.86784 |  iteration: 6354 teacher: 0 stage: sketch lr: 0.000554\n",
      "batch 139 loss: 0.22924 acc: 0.92773 | v_loss: 0.56411 v_acc: 0.87956 |  iteration: 6355 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 140 loss: 0.35929 acc: 0.89714 | v_loss: 0.42646 v_acc: 0.89486 |  iteration: 6356 teacher: 0 stage: sketch lr: 0.000554\n",
      "batch 141 loss: 0.25226 acc: 0.92676 | v_loss: 0.44039 v_acc: 0.90039 |  iteration: 6357 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 142 loss: 0.34770 acc: 0.90039 | v_loss: 0.53787 v_acc: 0.88118 |  iteration: 6358 teacher: 0 stage: sketch lr: 0.000554\n",
      "batch 143 loss: 0.32555 acc: 0.90560 | v_loss: 0.57725 v_acc: 0.85970 |  iteration: 6359 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 144 loss: 0.29281 acc: 0.91536 | v_loss: 0.55773 v_acc: 0.88900 |  iteration: 6360 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 145 loss: 0.33141 acc: 0.90951 | v_loss: 0.58224 v_acc: 0.88184 |  iteration: 6361 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 146 loss: 0.25636 acc: 0.92285 | v_loss: 0.34961 v_acc: 0.91146 |  iteration: 6362 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 147 loss: 0.27455 acc: 0.92741 | v_loss: 0.54397 v_acc: 0.87858 |  iteration: 6363 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 148 loss: 0.22015 acc: 0.93652 | v_loss: 0.47460 v_acc: 0.88770 |  iteration: 6364 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 149 loss: 0.29740 acc: 0.91829 | v_loss: 0.83655 v_acc: 0.83236 |  iteration: 6365 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 150 loss: 0.25418 acc: 0.92285 | v_loss: 0.34711 v_acc: 0.90918 |  iteration: 6366 teacher: 0 stage: sketch lr: 0.000554\n",
      "batch 151 loss: 0.24018 acc: 0.92708 | v_loss: 0.29901 v_acc: 0.92578 |  iteration: 6367 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 152 loss: 0.22993 acc: 0.92676 | v_loss: 0.54345 v_acc: 0.88249 |  iteration: 6368 teacher: 0 stage: sketch lr: 0.000554\n",
      "batch 153 loss: 0.20074 acc: 0.93652 | v_loss: 0.50825 v_acc: 0.88965 |  iteration: 6369 teacher: 0 stage: sketch lr: 0.000554\n",
      "batch 154 loss: 0.28586 acc: 0.92155 | v_loss: 0.63180 v_acc: 0.87012 |  iteration: 6370 teacher: 0 stage: sketch lr: 0.000554\n",
      "batch 155 loss: 0.25752 acc: 0.92415 | v_loss: 0.39968 v_acc: 0.90430 |  iteration: 6371 teacher: 0 stage: sketch lr: 0.000554\n",
      "batch 156 loss: 0.23217 acc: 0.93132 | v_loss: 0.45591 v_acc: 0.88021 |  iteration: 6372 teacher: 0 stage: sketch lr: 0.000554\n",
      "batch 157 loss: 0.26985 acc: 0.92415 | v_loss: 0.55741 v_acc: 0.87207 |  iteration: 6373 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 158 loss: 0.35631 acc: 0.90072 | v_loss: 0.64759 v_acc: 0.85677 |  iteration: 6374 teacher: 0 stage: sketch lr: 0.000554\n",
      "batch 159 loss: 0.23849 acc: 0.92513 | v_loss: 0.46127 v_acc: 0.89258 |  iteration: 6375 teacher: 0 stage: sketch lr: 0.000554\n",
      "batch 160 loss: 0.27153 acc: 0.92480 | v_loss: 0.41054 v_acc: 0.90072 |  iteration: 6376 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 161 loss: 0.23184 acc: 0.92839 | v_loss: 0.29677 v_acc: 0.92122 |  iteration: 6377 teacher: 0 stage: sketch lr: 0.000553\n",
      "batch 162 loss: 0.25662 acc: 0.92188 | v_loss: 0.44246 v_acc: 0.89551 |  iteration: 6378 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 163 loss: 0.29988 acc: 0.91113 | v_loss: 0.47426 v_acc: 0.89128 |  iteration: 6379 teacher: 0 stage: sketch lr: 0.000553\n",
      "batch 164 loss: 0.27118 acc: 0.91829 | v_loss: 0.79969 v_acc: 0.85319 |  iteration: 6380 teacher: 0 stage: sketch lr: 0.000553\n",
      "batch 165 loss: 0.23539 acc: 0.92415 | v_loss: 0.59553 v_acc: 0.86589 |  iteration: 6381 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 166 loss: 0.34211 acc: 0.89844 | v_loss: 0.63936 v_acc: 0.86947 |  iteration: 6382 teacher: 0 stage: sketch lr: 0.000553\n",
      "batch 167 loss: 0.30411 acc: 0.91797 | v_loss: 0.43535 v_acc: 0.89714 |  iteration: 6383 teacher: 1 stage: sketch lr: 0.000553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 168 loss: 0.23753 acc: 0.92904 | v_loss: 0.53132 v_acc: 0.87760 |  iteration: 6384 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 169 loss: 0.34028 acc: 0.89583 | v_loss: 0.75671 v_acc: 0.85124 |  iteration: 6385 teacher: 0 stage: sketch lr: 0.000553\n",
      "batch 170 loss: 0.28223 acc: 0.91243 | v_loss: 0.51863 v_acc: 0.89128 |  iteration: 6386 teacher: 0 stage: sketch lr: 0.000553\n",
      "batch 171 loss: 0.22421 acc: 0.93099 | v_loss: 0.51067 v_acc: 0.88737 |  iteration: 6387 teacher: 0 stage: sketch lr: 0.000553\n",
      "batch 172 loss: 0.22808 acc: 0.93457 | v_loss: 0.53374 v_acc: 0.87760 |  iteration: 6388 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 173 loss: 0.29130 acc: 0.91634 | v_loss: 0.41852 v_acc: 0.91211 |  iteration: 6389 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 174 loss: 0.22442 acc: 0.93392 | v_loss: 0.48878 v_acc: 0.90462 |  iteration: 6390 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 175 loss: 0.29350 acc: 0.92090 | v_loss: 0.61856 v_acc: 0.86361 |  iteration: 6391 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 176 loss: 0.22834 acc: 0.93099 | v_loss: 0.40470 v_acc: 0.91602 |  iteration: 6392 teacher: 0 stage: sketch lr: 0.000553\n",
      "batch 177 loss: 0.30538 acc: 0.90560 | v_loss: 0.96879 v_acc: 0.82292 |  iteration: 6393 teacher: 0 stage: sketch lr: 0.000553\n",
      "batch 178 loss: 0.35954 acc: 0.89941 | v_loss: 0.63255 v_acc: 0.87109 |  iteration: 6394 teacher: 0 stage: sketch lr: 0.000553\n",
      "batch 179 loss: 0.26168 acc: 0.92188 | v_loss: 0.65794 v_acc: 0.86296 |  iteration: 6395 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 180 loss: 0.23978 acc: 0.92806 | v_loss: 0.50540 v_acc: 0.89258 |  iteration: 6396 teacher: 0 stage: sketch lr: 0.000553\n",
      "batch 181 loss: 0.25672 acc: 0.91960 | v_loss: 0.43662 v_acc: 0.89323 |  iteration: 6397 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 182 loss: 0.30950 acc: 0.91439 | v_loss: 0.54906 v_acc: 0.88737 |  iteration: 6398 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 183 loss: 0.24547 acc: 0.92318 | v_loss: 0.50172 v_acc: 0.88965 |  iteration: 6399 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 184 loss: 0.29978 acc: 0.91374 | v_loss: 0.49427 v_acc: 0.88770 |  iteration: 6400 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 185 loss: 0.29744 acc: 0.92220 | v_loss: 0.49307 v_acc: 0.90462 |  iteration: 6401 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 186 loss: 0.36180 acc: 0.90788 | v_loss: 0.44037 v_acc: 0.90072 |  iteration: 6402 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 187 loss: 0.26821 acc: 0.91504 | v_loss: 0.33051 v_acc: 0.92285 |  iteration: 6403 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 188 loss: 0.29303 acc: 0.91439 | v_loss: 0.59343 v_acc: 0.86523 |  iteration: 6404 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 189 loss: 0.29166 acc: 0.91471 | v_loss: 0.56324 v_acc: 0.86523 |  iteration: 6405 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 190 loss: 0.31985 acc: 0.90723 | v_loss: 0.64545 v_acc: 0.85645 |  iteration: 6406 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 191 loss: 0.30330 acc: 0.91471 | v_loss: 0.79853 v_acc: 0.85384 |  iteration: 6407 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 192 loss: 0.33754 acc: 0.90951 | v_loss: 0.43474 v_acc: 0.90658 |  iteration: 6408 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 193 loss: 0.22328 acc: 0.93262 | v_loss: 0.56868 v_acc: 0.87370 |  iteration: 6409 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 194 loss: 0.30577 acc: 0.91178 | v_loss: 0.54059 v_acc: 0.89030 |  iteration: 6410 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 195 loss: 0.32244 acc: 0.90397 | v_loss: 0.40654 v_acc: 0.90820 |  iteration: 6411 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 196 loss: 0.25073 acc: 0.92936 | v_loss: 1.05609 v_acc: 0.81510 |  iteration: 6412 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 197 loss: 0.30517 acc: 0.90625 | v_loss: 0.38413 v_acc: 0.91211 |  iteration: 6413 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 198 loss: 0.25809 acc: 0.92220 | v_loss: 0.57020 v_acc: 0.87240 |  iteration: 6414 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 199 loss: 0.26891 acc: 0.91960 | v_loss: 0.50158 v_acc: 0.89323 |  iteration: 6415 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 200 loss: 0.28518 acc: 0.91211 | v_loss: 0.40380 v_acc: 0.90592 |  iteration: 6416 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 201 loss: 0.25992 acc: 0.92318 | v_loss: 0.51027 v_acc: 0.88900 |  iteration: 6417 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 202 loss: 0.23465 acc: 0.92871 | v_loss: 0.57786 v_acc: 0.87109 |  iteration: 6418 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 203 loss: 0.32273 acc: 0.91016 | v_loss: 0.44002 v_acc: 0.90625 |  iteration: 6419 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 204 loss: 0.25808 acc: 0.92318 | v_loss: 0.62261 v_acc: 0.87240 |  iteration: 6420 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 205 loss: 0.37061 acc: 0.90299 | v_loss: 0.38574 v_acc: 0.90658 |  iteration: 6421 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 206 loss: 0.24784 acc: 0.92448 | v_loss: 0.97050 v_acc: 0.82617 |  iteration: 6422 teacher: 0 stage: sketch lr: 0.000551\n",
      "batch 207 loss: 0.21181 acc: 0.94076 | v_loss: 0.59307 v_acc: 0.88607 |  iteration: 6423 teacher: 0 stage: sketch lr: 0.000551\n",
      "batch 208 loss: 0.29401 acc: 0.92285 | v_loss: 0.65026 v_acc: 0.87174 |  iteration: 6424 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 209 loss: 0.28563 acc: 0.91374 | v_loss: 0.43186 v_acc: 0.89779 |  iteration: 6425 teacher: 0 stage: sketch lr: 0.000551\n",
      "batch 210 loss: 0.28627 acc: 0.91764 | v_loss: 0.63511 v_acc: 0.86816 |  iteration: 6426 teacher: 0 stage: sketch lr: 0.000551\n",
      "batch 211 loss: 0.36202 acc: 0.89714 | v_loss: 0.44457 v_acc: 0.89323 |  iteration: 6427 teacher: 0 stage: sketch lr: 0.000551\n",
      "batch 212 loss: 0.30439 acc: 0.91471 | v_loss: 0.48612 v_acc: 0.88379 |  iteration: 6428 teacher: 0 stage: sketch lr: 0.000551\n",
      "batch 213 loss: 0.29026 acc: 0.91276 | v_loss: 0.41568 v_acc: 0.89583 |  iteration: 6429 teacher: 0 stage: sketch lr: 0.000551\n",
      "batch 214 loss: 0.26770 acc: 0.91829 | v_loss: 0.70985 v_acc: 0.85677 |  iteration: 6430 teacher: 0 stage: sketch lr: 0.000551\n",
      "batch 215 loss: 0.22999 acc: 0.92871 | v_loss: 0.52285 v_acc: 0.89095 |  iteration: 6431 teacher: 0 stage: sketch lr: 0.000551\n",
      "batch 216 loss: 0.21580 acc: 0.93522 | v_loss: 0.51301 v_acc: 0.88118 |  iteration: 6432 teacher: 0 stage: sketch lr: 0.000551\n",
      "batch 217 loss: 0.28841 acc: 0.90853 | v_loss: 0.66621 v_acc: 0.85547 |  iteration: 6433 teacher: 0 stage: sketch lr: 0.000551\n",
      "batch 218 loss: 0.23399 acc: 0.93197 | v_loss: 0.43989 v_acc: 0.89290 |  iteration: 6434 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 219 loss: 0.20257 acc: 0.93880 | v_loss: 0.48283 v_acc: 0.87923 |  iteration: 6435 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 220 loss: 0.29276 acc: 0.91732 | v_loss: 0.49363 v_acc: 0.88379 |  iteration: 6436 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 221 loss: 0.35516 acc: 0.89681 | v_loss: 0.74810 v_acc: 0.85579 |  iteration: 6437 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 222 loss: 0.25752 acc: 0.93034 | v_loss: 0.54280 v_acc: 0.88932 |  iteration: 6438 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 223 loss: 0.31383 acc: 0.91374 | v_loss: 0.55381 v_acc: 0.88997 |  iteration: 6439 teacher: 0 stage: sketch lr: 0.000551\n",
      "batch 224 loss: 0.29369 acc: 0.91732 | v_loss: 0.62100 v_acc: 0.88184 |  iteration: 6440 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 225 loss: 0.26509 acc: 0.92025 | v_loss: 0.57405 v_acc: 0.86198 |  iteration: 6441 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 226 loss: 0.34050 acc: 0.90462 | v_loss: 0.45289 v_acc: 0.90202 |  iteration: 6442 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 227 loss: 0.17179 acc: 0.95312 | v_loss: 0.75199 v_acc: 0.83887 |  iteration: 6443 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 228 loss: 0.26671 acc: 0.91602 | v_loss: 0.63430 v_acc: 0.86589 |  iteration: 6444 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 229 loss: 0.26453 acc: 0.92285 | v_loss: 0.59427 v_acc: 0.86393 |  iteration: 6445 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 230 loss: 0.22777 acc: 0.93880 | v_loss: 0.52837 v_acc: 0.87793 |  iteration: 6446 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 231 loss: 0.26559 acc: 0.92285 | v_loss: 0.47356 v_acc: 0.88835 |  iteration: 6447 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 232 loss: 0.26382 acc: 0.92090 | v_loss: 0.43935 v_acc: 0.89681 |  iteration: 6448 teacher: 0 stage: sketch lr: 0.000550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 233 loss: 0.28489 acc: 0.91862 | v_loss: 0.52240 v_acc: 0.88216 |  iteration: 6449 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 234 loss: 0.27890 acc: 0.92546 | v_loss: 0.61612 v_acc: 0.84505 |  iteration: 6450 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 235 loss: 0.20110 acc: 0.93424 | v_loss: 0.54452 v_acc: 0.88835 |  iteration: 6451 teacher: 0 stage: sketch lr: 0.000550\n",
      "batch 236 loss: 0.33893 acc: 0.90690 | v_loss: 0.59311 v_acc: 0.87891 |  iteration: 6452 teacher: 0 stage: sketch lr: 0.000550\n",
      "batch 237 loss: 0.27791 acc: 0.92383 | v_loss: 0.35899 v_acc: 0.90983 |  iteration: 6453 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 238 loss: 0.27235 acc: 0.92415 | v_loss: 0.52703 v_acc: 0.88900 |  iteration: 6454 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 239 loss: 0.21834 acc: 0.93685 | v_loss: 0.50914 v_acc: 0.88184 |  iteration: 6455 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 240 loss: 0.26609 acc: 0.91341 | v_loss: 0.82385 v_acc: 0.83333 |  iteration: 6456 teacher: 0 stage: sketch lr: 0.000550\n",
      "batch 241 loss: 0.27172 acc: 0.92318 | v_loss: 0.36485 v_acc: 0.90462 |  iteration: 6457 teacher: 0 stage: sketch lr: 0.000550\n",
      "batch 242 loss: 0.32213 acc: 0.91211 | v_loss: 0.29994 v_acc: 0.92839 |  iteration: 6458 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 243 loss: 0.30303 acc: 0.91113 | v_loss: 0.59425 v_acc: 0.88672 |  iteration: 6459 teacher: 0 stage: sketch lr: 0.000550\n",
      "batch 244 loss: 0.21155 acc: 0.93945 | v_loss: 0.58480 v_acc: 0.88346 |  iteration: 6460 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 245 loss: 0.25114 acc: 0.92773 | v_loss: 0.68373 v_acc: 0.86068 |  iteration: 6461 teacher: 0 stage: sketch lr: 0.000550\n",
      "batch 246 loss: 0.24814 acc: 0.92188 | v_loss: 0.42680 v_acc: 0.89779 |  iteration: 6462 teacher: 0 stage: sketch lr: 0.000550\n",
      "batch 247 loss: 0.27730 acc: 0.91829 | v_loss: 0.48237 v_acc: 0.87728 |  iteration: 6463 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 248 loss: 0.28832 acc: 0.91471 | v_loss: 0.55478 v_acc: 0.86914 |  iteration: 6464 teacher: 0 stage: sketch lr: 0.000550\n",
      "batch 249 loss: 0.24558 acc: 0.93099 | v_loss: 0.64240 v_acc: 0.85221 |  iteration: 6465 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 250 loss: 0.26375 acc: 0.92513 | v_loss: 0.47456 v_acc: 0.89030 |  iteration: 6466 teacher: 0 stage: sketch lr: 0.000550\n",
      "batch 251 loss: 0.29884 acc: 0.91374 | v_loss: 0.35885 v_acc: 0.90885 |  iteration: 6467 teacher: 0 stage: sketch lr: 0.000550\n",
      "batch 252 loss: 0.32073 acc: 0.90658 | v_loss: 0.30031 v_acc: 0.92741 |  iteration: 6468 teacher: 0 stage: sketch lr: 0.000550\n",
      "batch 253 loss: 0.27631 acc: 0.91732 | v_loss: 0.47139 v_acc: 0.90072 |  iteration: 6469 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 254 loss: 0.22186 acc: 0.93164 | v_loss: 0.49291 v_acc: 0.88639 |  iteration: 6470 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 255 loss: 0.31591 acc: 0.90690 | v_loss: 0.78722 v_acc: 0.85775 |  iteration: 6471 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 256 loss: 0.24683 acc: 0.93620 | v_loss: 0.55924 v_acc: 0.87565 |  iteration: 6472 teacher: 1 stage: sketch lr: 0.000549\n",
      "batch 257 loss: 0.26946 acc: 0.92057 | v_loss: 0.64111 v_acc: 0.86979 |  iteration: 6473 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 258 loss: 0.29614 acc: 0.91178 | v_loss: 0.37775 v_acc: 0.90820 |  iteration: 6474 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 259 loss: 0.17977 acc: 0.94336 | v_loss: 0.52107 v_acc: 0.88249 |  iteration: 6475 teacher: 1 stage: sketch lr: 0.000549\n",
      "batch 260 loss: 0.29959 acc: 0.91536 | v_loss: 0.73986 v_acc: 0.84635 |  iteration: 6476 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 261 loss: 0.35116 acc: 0.90137 | v_loss: 0.50223 v_acc: 0.88770 |  iteration: 6477 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 262 loss: 0.27090 acc: 0.92415 | v_loss: 0.51511 v_acc: 0.89095 |  iteration: 6478 teacher: 1 stage: sketch lr: 0.000549\n",
      "batch 263 loss: 0.23071 acc: 0.93262 | v_loss: 0.47946 v_acc: 0.88249 |  iteration: 6479 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 264 loss: 0.27197 acc: 0.91634 | v_loss: 0.40461 v_acc: 0.91113 |  iteration: 6480 teacher: 1 stage: sketch lr: 0.000549\n",
      "batch 265 loss: 0.26566 acc: 0.92871 | v_loss: 0.46289 v_acc: 0.89811 |  iteration: 6481 teacher: 1 stage: sketch lr: 0.000549\n",
      "batch 266 loss: 0.29488 acc: 0.90951 | v_loss: 0.57952 v_acc: 0.86230 |  iteration: 6482 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 267 loss: 0.20782 acc: 0.94238 | v_loss: 0.38451 v_acc: 0.91406 |  iteration: 6483 teacher: 1 stage: sketch lr: 0.000549\n",
      "batch 268 loss: 0.27941 acc: 0.91016 | v_loss: 0.96798 v_acc: 0.82715 |  iteration: 6484 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 269 loss: 0.25943 acc: 0.92643 | v_loss: 0.63243 v_acc: 0.87533 |  iteration: 6485 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 270 loss: 0.24228 acc: 0.93001 | v_loss: 0.69673 v_acc: 0.85677 |  iteration: 6486 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 271 loss: 0.21502 acc: 0.93262 | v_loss: 0.52317 v_acc: 0.89258 |  iteration: 6487 teacher: 1 stage: sketch lr: 0.000549\n",
      "batch 272 loss: 0.27205 acc: 0.91634 | v_loss: 0.48395 v_acc: 0.88770 |  iteration: 6488 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 273 loss: 0.27849 acc: 0.91829 | v_loss: 0.56114 v_acc: 0.88932 |  iteration: 6489 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 274 loss: 0.23264 acc: 0.93522 | v_loss: 0.51781 v_acc: 0.88802 |  iteration: 6490 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 275 loss: 0.24703 acc: 0.92448 | v_loss: 0.47471 v_acc: 0.89258 |  iteration: 6491 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 276 loss: 0.35644 acc: 0.90007 | v_loss: 0.49893 v_acc: 0.90267 |  iteration: 6492 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 277 loss: 0.24688 acc: 0.92806 | v_loss: 0.42763 v_acc: 0.89648 |  iteration: 6493 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 278 loss: 0.30287 acc: 0.91276 | v_loss: 0.35432 v_acc: 0.91406 |  iteration: 6494 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 279 loss: 0.21717 acc: 0.94173 | v_loss: 0.65010 v_acc: 0.86263 |  iteration: 6495 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 280 loss: 0.28004 acc: 0.92090 | v_loss: 0.53168 v_acc: 0.86979 |  iteration: 6496 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 281 loss: 0.25926 acc: 0.92448 | v_loss: 0.61842 v_acc: 0.86198 |  iteration: 6497 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 282 loss: 0.36248 acc: 0.89811 | v_loss: 0.85124 v_acc: 0.84310 |  iteration: 6498 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 283 loss: 0.37146 acc: 0.90169 | v_loss: 0.45198 v_acc: 0.89779 |  iteration: 6499 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 284 loss: 0.25360 acc: 0.92513 | v_loss: 0.56412 v_acc: 0.87760 |  iteration: 6500 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 285 loss: 0.32169 acc: 0.90267 | v_loss: 0.53099 v_acc: 0.88737 |  iteration: 6501 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 286 loss: 0.23434 acc: 0.92871 | v_loss: 0.43958 v_acc: 0.89681 |  iteration: 6502 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 287 loss: 0.22454 acc: 0.93197 | v_loss: 1.09975 v_acc: 0.80794 |  iteration: 6503 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 288 loss: 0.35662 acc: 0.90072 | v_loss: 0.40153 v_acc: 0.90820 |  iteration: 6504 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 289 loss: 0.38119 acc: 0.89714 | v_loss: 0.58223 v_acc: 0.87207 |  iteration: 6505 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 290 loss: 0.32531 acc: 0.91243 | v_loss: 0.50911 v_acc: 0.88965 |  iteration: 6506 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 291 loss: 0.30574 acc: 0.90918 | v_loss: 0.41312 v_acc: 0.90430 |  iteration: 6507 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 292 loss: 0.27818 acc: 0.91471 | v_loss: 0.45579 v_acc: 0.89323 |  iteration: 6508 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 293 loss: 0.30922 acc: 0.91439 | v_loss: 0.55221 v_acc: 0.87500 |  iteration: 6509 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 294 loss: 0.24047 acc: 0.92122 | v_loss: 0.40191 v_acc: 0.90690 |  iteration: 6510 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 295 loss: 0.20471 acc: 0.93815 | v_loss: 0.62244 v_acc: 0.87337 |  iteration: 6511 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 296 loss: 0.22951 acc: 0.93262 | v_loss: 0.41741 v_acc: 0.89876 |  iteration: 6512 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 297 loss: 0.26650 acc: 0.92448 | v_loss: 1.02059 v_acc: 0.82454 |  iteration: 6513 teacher: 1 stage: sketch lr: 0.000548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 298 loss: 0.24164 acc: 0.92676 | v_loss: 0.61787 v_acc: 0.87858 |  iteration: 6514 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 299 loss: 0.27406 acc: 0.91504 | v_loss: 0.67250 v_acc: 0.87109 |  iteration: 6515 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 300 loss: 0.29931 acc: 0.91862 | v_loss: 0.42011 v_acc: 0.90527 |  iteration: 6516 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 301 loss: 0.20566 acc: 0.93978 | v_loss: 0.66826 v_acc: 0.85710 |  iteration: 6517 teacher: 1 stage: sketch lr: 0.000547\n",
      "batch 302 loss: 0.26173 acc: 0.91960 | v_loss: 0.43419 v_acc: 0.89453 |  iteration: 6518 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 303 loss: 0.26295 acc: 0.92708 | v_loss: 0.46867 v_acc: 0.88802 |  iteration: 6519 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 304 loss: 0.31773 acc: 0.90527 | v_loss: 0.43356 v_acc: 0.89290 |  iteration: 6520 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 305 loss: 0.29061 acc: 0.91374 | v_loss: 0.73376 v_acc: 0.85156 |  iteration: 6521 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 306 loss: 0.31398 acc: 0.90365 | v_loss: 0.46782 v_acc: 0.89616 |  iteration: 6522 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 307 loss: 0.29851 acc: 0.91113 | v_loss: 0.50096 v_acc: 0.88053 |  iteration: 6523 teacher: 1 stage: sketch lr: 0.000547\n",
      "batch 308 loss: 0.31926 acc: 0.90820 | v_loss: 0.65841 v_acc: 0.85840 |  iteration: 6524 teacher: 1 stage: sketch lr: 0.000547\n",
      "batch 309 loss: 0.19435 acc: 0.93783 | v_loss: 0.45581 v_acc: 0.89128 |  iteration: 6525 teacher: 1 stage: sketch lr: 0.000547\n",
      "batch 310 loss: 0.26637 acc: 0.92480 | v_loss: 0.49305 v_acc: 0.87435 |  iteration: 6526 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 311 loss: 0.25529 acc: 0.91992 | v_loss: 0.51957 v_acc: 0.87663 |  iteration: 6527 teacher: 1 stage: sketch lr: 0.000547\n",
      "batch 312 loss: 0.21669 acc: 0.93717 | v_loss: 0.71586 v_acc: 0.84896 |  iteration: 6528 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 313 loss: 0.28735 acc: 0.92188 | v_loss: 0.55123 v_acc: 0.87956 |  iteration: 6529 teacher: 1 stage: sketch lr: 0.000547\n",
      "batch 314 loss: 0.26367 acc: 0.91797 | v_loss: 0.57671 v_acc: 0.88249 |  iteration: 6530 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 315 loss: 0.29659 acc: 0.91178 | v_loss: 0.62999 v_acc: 0.88249 |  iteration: 6531 teacher: 1 stage: sketch lr: 0.000547\n",
      "batch 316 loss: 0.29065 acc: 0.91895 | v_loss: 0.54733 v_acc: 0.87240 |  iteration: 6532 teacher: 1 stage: sketch lr: 0.000547\n",
      "batch 317 loss: 0.31290 acc: 0.91016 | v_loss: 0.45044 v_acc: 0.89714 |  iteration: 6533 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 318 loss: 0.24376 acc: 0.92448 | v_loss: 0.83700 v_acc: 0.83529 |  iteration: 6534 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 319 loss: 0.23673 acc: 0.93392 | v_loss: 0.58191 v_acc: 0.88477 |  iteration: 6535 teacher: 1 stage: sketch lr: 0.000547\n",
      "batch 320 loss: 0.25695 acc: 0.92415 | v_loss: 0.57934 v_acc: 0.87467 |  iteration: 6536 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 321 loss: 0.28687 acc: 0.92122 | v_loss: 0.56081 v_acc: 0.87760 |  iteration: 6537 teacher: 1 stage: sketch lr: 0.000547\n",
      "batch 322 loss: 0.28494 acc: 0.91536 | v_loss: 0.46928 v_acc: 0.89909 |  iteration: 6538 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 323 loss: 0.19462 acc: 0.94303 | v_loss: 0.46549 v_acc: 0.89779 |  iteration: 6539 teacher: 1 stage: sketch lr: 0.000547\n",
      "batch 324 loss: 0.28032 acc: 0.91699 | v_loss: 0.53700 v_acc: 0.87891 |  iteration: 6540 teacher: 1 stage: sketch lr: 0.000546\n",
      "batch 325 loss: 0.26954 acc: 0.91602 | v_loss: 0.61334 v_acc: 0.85384 |  iteration: 6541 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 326 loss: 0.24882 acc: 0.92350 | v_loss: 0.57662 v_acc: 0.88444 |  iteration: 6542 teacher: 1 stage: sketch lr: 0.000546\n",
      "batch 327 loss: 0.27549 acc: 0.92220 | v_loss: 0.61081 v_acc: 0.88704 |  iteration: 6543 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 328 loss: 0.23853 acc: 0.92806 | v_loss: 0.39751 v_acc: 0.90267 |  iteration: 6544 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 329 loss: 0.20611 acc: 0.93587 | v_loss: 0.56319 v_acc: 0.87956 |  iteration: 6545 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 330 loss: 0.29796 acc: 0.91243 | v_loss: 0.49689 v_acc: 0.88835 |  iteration: 6546 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 331 loss: 0.27013 acc: 0.92708 | v_loss: 0.86812 v_acc: 0.83724 |  iteration: 6547 teacher: 1 stage: sketch lr: 0.000546\n",
      "batch 332 loss: 0.28061 acc: 0.91602 | v_loss: 0.38664 v_acc: 0.90951 |  iteration: 6548 teacher: 1 stage: sketch lr: 0.000546\n",
      "batch 333 loss: 0.29068 acc: 0.91667 | v_loss: 0.30337 v_acc: 0.93066 |  iteration: 6549 teacher: 1 stage: sketch lr: 0.000546\n",
      "batch 334 loss: 0.25180 acc: 0.92480 | v_loss: 0.53054 v_acc: 0.88639 |  iteration: 6550 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 335 loss: 0.15007 acc: 0.95540 | v_loss: 0.58445 v_acc: 0.88965 |  iteration: 6551 teacher: 1 stage: sketch lr: 0.000546\n",
      "batch 336 loss: 0.29204 acc: 0.91406 | v_loss: 0.69769 v_acc: 0.85514 |  iteration: 6552 teacher: 1 stage: sketch lr: 0.000546\n",
      "batch 337 loss: 0.30317 acc: 0.91178 | v_loss: 0.43273 v_acc: 0.90202 |  iteration: 6553 teacher: 1 stage: sketch lr: 0.000546\n",
      "batch 338 loss: 0.28163 acc: 0.91569 | v_loss: 0.47930 v_acc: 0.87891 |  iteration: 6554 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 339 loss: 0.26174 acc: 0.92448 | v_loss: 0.61591 v_acc: 0.86882 |  iteration: 6555 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 340 loss: 0.24910 acc: 0.92871 | v_loss: 0.61167 v_acc: 0.85286 |  iteration: 6556 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 341 loss: 0.17739 acc: 0.95052 | v_loss: 0.51603 v_acc: 0.89062 |  iteration: 6557 teacher: 1 stage: sketch lr: 0.000546\n",
      "batch 342 loss: 0.24091 acc: 0.93034 | v_loss: 0.37271 v_acc: 0.90690 |  iteration: 6558 teacher: 1 stage: sketch lr: 0.000546\n",
      "batch 343 loss: 0.26824 acc: 0.92708 | v_loss: 0.30919 v_acc: 0.92285 |  iteration: 6559 teacher: 1 stage: sketch lr: 0.000546\n",
      "batch 344 loss: 0.29761 acc: 0.91439 | v_loss: 0.46208 v_acc: 0.89583 |  iteration: 6560 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 345 loss: 0.26876 acc: 0.93164 | v_loss: 0.50896 v_acc: 0.89290 |  iteration: 6561 teacher: 1 stage: sketch lr: 0.000546\n",
      "batch 346 loss: 0.29635 acc: 0.91243 | v_loss: 0.87702 v_acc: 0.85189 |  iteration: 6562 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 347 loss: 0.40085 acc: 0.89128 | v_loss: 0.52420 v_acc: 0.88542 |  iteration: 6563 teacher: 1 stage: sketch lr: 0.000546\n",
      "batch 348 loss: 0.33286 acc: 0.90560 | v_loss: 0.64192 v_acc: 0.86491 |  iteration: 6564 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 349 loss: 0.28678 acc: 0.92643 | v_loss: 0.39536 v_acc: 0.90137 |  iteration: 6565 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 350 loss: 0.31520 acc: 0.90072 | v_loss: 0.52575 v_acc: 0.87728 |  iteration: 6566 teacher: 0 stage: sketch lr: 0.000545\n",
      "batch 351 loss: 0.25466 acc: 0.92578 | v_loss: 0.71145 v_acc: 0.84993 |  iteration: 6567 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 352 loss: 0.28829 acc: 0.91341 | v_loss: 0.48612 v_acc: 0.89030 |  iteration: 6568 teacher: 0 stage: sketch lr: 0.000545\n",
      "batch 353 loss: 0.31072 acc: 0.90885 | v_loss: 0.53624 v_acc: 0.88086 |  iteration: 6569 teacher: 0 stage: sketch lr: 0.000545\n",
      "batch 354 loss: 0.24663 acc: 0.92904 | v_loss: 0.48514 v_acc: 0.88509 |  iteration: 6570 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 355 loss: 0.29465 acc: 0.91309 | v_loss: 0.41086 v_acc: 0.90658 |  iteration: 6571 teacher: 0 stage: sketch lr: 0.000545\n",
      "batch 356 loss: 0.33086 acc: 0.91341 | v_loss: 0.42845 v_acc: 0.90169 |  iteration: 6572 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 357 loss: 0.31765 acc: 0.91016 | v_loss: 0.59056 v_acc: 0.86816 |  iteration: 6573 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 358 loss: 0.30091 acc: 0.91081 | v_loss: 0.39300 v_acc: 0.91602 |  iteration: 6574 teacher: 0 stage: sketch lr: 0.000545\n",
      "batch 359 loss: 0.20958 acc: 0.93587 | v_loss: 0.91776 v_acc: 0.82389 |  iteration: 6575 teacher: 0 stage: sketch lr: 0.000545\n",
      "batch 360 loss: 0.28109 acc: 0.91536 | v_loss: 0.59000 v_acc: 0.88477 |  iteration: 6576 teacher: 0 stage: sketch lr: 0.000545\n",
      "batch 361 loss: 0.24337 acc: 0.92220 | v_loss: 0.66179 v_acc: 0.86198 |  iteration: 6577 teacher: 0 stage: sketch lr: 0.000545\n",
      "batch 362 loss: 0.23840 acc: 0.92904 | v_loss: 0.52127 v_acc: 0.89290 |  iteration: 6578 teacher: 1 stage: sketch lr: 0.000545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 363 loss: 0.25433 acc: 0.92839 | v_loss: 0.45538 v_acc: 0.89193 |  iteration: 6579 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 364 loss: 0.27493 acc: 0.91699 | v_loss: 0.55922 v_acc: 0.88737 |  iteration: 6580 teacher: 0 stage: sketch lr: 0.000545\n",
      "batch 365 loss: 0.21197 acc: 0.93717 | v_loss: 0.52396 v_acc: 0.89583 |  iteration: 6581 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 366 loss: 0.28337 acc: 0.92090 | v_loss: 0.51060 v_acc: 0.88737 |  iteration: 6582 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 367 loss: 0.38707 acc: 0.89974 | v_loss: 0.50507 v_acc: 0.90007 |  iteration: 6583 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 368 loss: 0.26805 acc: 0.92220 | v_loss: 0.49832 v_acc: 0.88835 |  iteration: 6584 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 369 loss: 0.22928 acc: 0.92969 | v_loss: 0.36736 v_acc: 0.91732 |  iteration: 6585 teacher: 0 stage: sketch lr: 0.000545\n",
      "batch 370 loss: 0.25534 acc: 0.92741 | v_loss: 0.65514 v_acc: 0.85872 |  iteration: 6586 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 371 loss: 0.31169 acc: 0.90592 | v_loss: 0.53569 v_acc: 0.86784 |  iteration: 6587 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 372 loss: 0.22265 acc: 0.93652 | v_loss: 0.59791 v_acc: 0.86133 |  iteration: 6588 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 373 loss: 0.29045 acc: 0.91536 | v_loss: 0.79662 v_acc: 0.84570 |  iteration: 6589 teacher: 0 stage: sketch lr: 0.000544\n",
      "batch 374 loss: 0.24209 acc: 0.93066 | v_loss: 0.38415 v_acc: 0.90820 |  iteration: 6590 teacher: 0 stage: sketch lr: 0.000544\n",
      "batch 375 loss: 0.26124 acc: 0.91895 | v_loss: 0.55212 v_acc: 0.88053 |  iteration: 6591 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 376 loss: 0.25074 acc: 0.93034 | v_loss: 0.51922 v_acc: 0.88835 |  iteration: 6592 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 377 loss: 0.21610 acc: 0.93620 | v_loss: 0.43439 v_acc: 0.90039 |  iteration: 6593 teacher: 0 stage: sketch lr: 0.000544\n",
      "batch 378 loss: 0.25588 acc: 0.92448 | v_loss: 1.11148 v_acc: 0.81283 |  iteration: 6594 teacher: 0 stage: sketch lr: 0.000544\n",
      "batch 379 loss: 0.28800 acc: 0.90723 | v_loss: 0.39502 v_acc: 0.91862 |  iteration: 6595 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 380 loss: 0.19631 acc: 0.93848 | v_loss: 0.59449 v_acc: 0.87793 |  iteration: 6596 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 381 loss: 0.26611 acc: 0.92383 | v_loss: 0.51708 v_acc: 0.89388 |  iteration: 6597 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 382 loss: 0.26517 acc: 0.92415 | v_loss: 0.44184 v_acc: 0.90234 |  iteration: 6598 teacher: 0 stage: sketch lr: 0.000544\n",
      "batch 383 loss: 0.23181 acc: 0.92871 | v_loss: 0.51249 v_acc: 0.89290 |  iteration: 6599 teacher: 0 stage: sketch lr: 0.000544\n",
      "batch 384 loss: 0.18859 acc: 0.94076 | v_loss: 0.61760 v_acc: 0.87923 |  iteration: 6600 teacher: 0 stage: sketch lr: 0.000544\n",
      "batch 385 loss: 0.19144 acc: 0.94336 | v_loss: 0.45652 v_acc: 0.90365 |  iteration: 6601 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 386 loss: 0.27753 acc: 0.92057 | v_loss: 0.63388 v_acc: 0.87695 |  iteration: 6602 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 387 loss: 0.22783 acc: 0.92383 | v_loss: 0.41356 v_acc: 0.90072 |  iteration: 6603 teacher: 0 stage: sketch lr: 0.000544\n",
      "batch 388 loss: 0.24741 acc: 0.92546 | v_loss: 1.01328 v_acc: 0.81152 |  iteration: 6604 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 389 loss: 0.28717 acc: 0.91960 | v_loss: 0.60107 v_acc: 0.87760 |  iteration: 6605 teacher: 0 stage: sketch lr: 0.000544\n",
      "batch 390 loss: 0.26042 acc: 0.91276 | v_loss: 0.68426 v_acc: 0.86393 |  iteration: 6606 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 391 loss: 0.27856 acc: 0.92090 | v_loss: 0.43126 v_acc: 0.89681 |  iteration: 6607 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 392 loss: 0.28585 acc: 0.91113 | v_loss: 0.62288 v_acc: 0.86751 |  iteration: 6608 teacher: 0 stage: sketch lr: 0.000544\n",
      "batch 393 loss: 0.29290 acc: 0.92513 | v_loss: 0.40968 v_acc: 0.90495 |  iteration: 6609 teacher: 0 stage: sketch lr: 0.000544\n",
      "batch 394 loss: 0.28654 acc: 0.91764 | v_loss: 0.48741 v_acc: 0.88737 |  iteration: 6610 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 395 loss: 0.28628 acc: 0.90918 | v_loss: 0.41499 v_acc: 0.89583 |  iteration: 6611 teacher: 0 stage: sketch lr: 0.000544\n",
      "batch 396 loss: 0.27454 acc: 0.91732 | v_loss: 0.73190 v_acc: 0.85612 |  iteration: 6612 teacher: 0 stage: sketch lr: 0.000543\n",
      "batch 397 loss: 0.26269 acc: 0.92025 | v_loss: 0.46371 v_acc: 0.90299 |  iteration: 6613 teacher: 0 stage: sketch lr: 0.000543\n",
      "batch 398 loss: 0.29632 acc: 0.91927 | v_loss: 0.51553 v_acc: 0.88086 |  iteration: 6614 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 399 loss: 0.27288 acc: 0.92350 | v_loss: 0.68980 v_acc: 0.85091 |  iteration: 6615 teacher: 0 stage: sketch lr: 0.000543\n",
      "batch 400 loss: 0.24017 acc: 0.92643 | v_loss: 0.42090 v_acc: 0.90397 |  iteration: 6616 teacher: 0 stage: sketch lr: 0.000543\n",
      "batch 401 loss: 0.25230 acc: 0.92318 | v_loss: 0.48901 v_acc: 0.87695 |  iteration: 6617 teacher: 0 stage: sketch lr: 0.000543\n",
      "batch 402 loss: 0.24315 acc: 0.93262 | v_loss: 0.52704 v_acc: 0.87826 |  iteration: 6618 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 403 loss: 0.32782 acc: 0.90853 | v_loss: 0.72391 v_acc: 0.85156 |  iteration: 6619 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 404 loss: 0.26894 acc: 0.92220 | v_loss: 0.54927 v_acc: 0.88411 |  iteration: 6620 teacher: 0 stage: sketch lr: 0.000543\n",
      "batch 405 loss: 0.22384 acc: 0.93197 | v_loss: 0.52248 v_acc: 0.89160 |  iteration: 6621 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 406 loss: 0.27753 acc: 0.91699 | v_loss: 0.60839 v_acc: 0.88249 |  iteration: 6622 teacher: 0 stage: sketch lr: 0.000543\n",
      "batch 407 loss: 0.37416 acc: 0.89323 | v_loss: 0.55703 v_acc: 0.86523 |  iteration: 6623 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 408 loss: 0.24795 acc: 0.93001 | v_loss: 0.44451 v_acc: 0.89779 |  iteration: 6624 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 409 loss: 0.20406 acc: 0.93555 | v_loss: 0.76143 v_acc: 0.84115 |  iteration: 6625 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 410 loss: 0.29423 acc: 0.91211 | v_loss: 0.51518 v_acc: 0.88411 |  iteration: 6626 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 411 loss: 0.24235 acc: 0.92773 | v_loss: 0.52736 v_acc: 0.87012 |  iteration: 6627 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 412 loss: 0.26688 acc: 0.92155 | v_loss: 0.51490 v_acc: 0.88281 |  iteration: 6628 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 413 loss: 0.26614 acc: 0.92969 | v_loss: 0.48103 v_acc: 0.89486 |  iteration: 6629 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 414 loss: 0.18232 acc: 0.94596 | v_loss: 0.44814 v_acc: 0.89551 |  iteration: 6630 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 415 loss: 0.30362 acc: 0.91243 | v_loss: 0.53786 v_acc: 0.88118 |  iteration: 6631 teacher: 0 stage: sketch lr: 0.000543\n",
      "batch 416 loss: 0.26159 acc: 0.92611 | v_loss: 0.60521 v_acc: 0.85677 |  iteration: 6632 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 417 loss: 0.28017 acc: 0.91439 | v_loss: 0.57404 v_acc: 0.88932 |  iteration: 6633 teacher: 0 stage: sketch lr: 0.000543\n",
      "batch 418 loss: 0.26301 acc: 0.92220 | v_loss: 0.64348 v_acc: 0.87467 |  iteration: 6634 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 419 loss: 0.22479 acc: 0.93717 | v_loss: 0.38202 v_acc: 0.90560 |  iteration: 6635 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 420 loss: 0.21623 acc: 0.93229 | v_loss: 0.53618 v_acc: 0.88477 |  iteration: 6636 teacher: 0 stage: sketch lr: 0.000543\n",
      "batch 421 loss: 0.21564 acc: 0.93913 | v_loss: 0.48728 v_acc: 0.88184 |  iteration: 6637 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 422 loss: 0.24475 acc: 0.92871 | v_loss: 0.86803 v_acc: 0.83301 |  iteration: 6638 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 423 loss: 0.20201 acc: 0.93750 | v_loss: 0.37655 v_acc: 0.90755 |  iteration: 6639 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 424 loss: 0.30390 acc: 0.91667 | v_loss: 0.32224 v_acc: 0.93001 |  iteration: 6640 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 425 loss: 0.38657 acc: 0.89583 | v_loss: 0.57529 v_acc: 0.88444 |  iteration: 6641 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 426 loss: 0.39152 acc: 0.88379 | v_loss: 0.57381 v_acc: 0.88249 |  iteration: 6642 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 427 loss: 0.24340 acc: 0.93132 | v_loss: 0.61382 v_acc: 0.86328 |  iteration: 6643 teacher: 0 stage: sketch lr: 0.000542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 428 loss: 0.23877 acc: 0.93099 | v_loss: 0.41972 v_acc: 0.89583 |  iteration: 6644 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 429 loss: 0.23523 acc: 0.93066 | v_loss: 0.46866 v_acc: 0.87695 |  iteration: 6645 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 430 loss: 0.26821 acc: 0.92025 | v_loss: 0.58252 v_acc: 0.87109 |  iteration: 6646 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 431 loss: 0.28500 acc: 0.91667 | v_loss: 0.65837 v_acc: 0.85059 |  iteration: 6647 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 432 loss: 0.23557 acc: 0.93620 | v_loss: 0.47763 v_acc: 0.89779 |  iteration: 6648 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 433 loss: 0.24182 acc: 0.92318 | v_loss: 0.38747 v_acc: 0.90267 |  iteration: 6649 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 434 loss: 0.27530 acc: 0.91862 | v_loss: 0.34198 v_acc: 0.91569 |  iteration: 6650 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 435 loss: 0.29625 acc: 0.91797 | v_loss: 0.43008 v_acc: 0.90104 |  iteration: 6651 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 436 loss: 0.37737 acc: 0.90267 | v_loss: 0.49142 v_acc: 0.88542 |  iteration: 6652 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 437 loss: 0.25962 acc: 0.92513 | v_loss: 0.80436 v_acc: 0.84961 |  iteration: 6653 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 438 loss: 0.25503 acc: 0.92415 | v_loss: 0.54499 v_acc: 0.87142 |  iteration: 6654 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 439 loss: 0.28323 acc: 0.91341 | v_loss: 0.59529 v_acc: 0.86784 |  iteration: 6655 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 440 loss: 0.27866 acc: 0.92415 | v_loss: 0.41773 v_acc: 0.90072 |  iteration: 6656 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 441 loss: 0.27904 acc: 0.91536 | v_loss: 0.50539 v_acc: 0.88704 |  iteration: 6657 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 442 loss: 0.29323 acc: 0.91081 | v_loss: 0.72087 v_acc: 0.84570 |  iteration: 6658 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 443 loss: 0.23836 acc: 0.92806 | v_loss: 0.54956 v_acc: 0.88835 |  iteration: 6659 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 444 loss: 0.24978 acc: 0.92969 | v_loss: 0.49689 v_acc: 0.88965 |  iteration: 6660 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 445 loss: 0.27417 acc: 0.91829 | v_loss: 0.43967 v_acc: 0.89128 |  iteration: 6661 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 446 loss: 0.33468 acc: 0.90625 | v_loss: 0.41753 v_acc: 0.90299 |  iteration: 6662 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 447 loss: 0.27030 acc: 0.91895 | v_loss: 0.44992 v_acc: 0.90365 |  iteration: 6663 teacher: 1 stage: sketch lr: 0.000541\n",
      "batch 448 loss: 0.20593 acc: 0.93815 | v_loss: 0.55027 v_acc: 0.86491 |  iteration: 6664 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 449 loss: 0.26897 acc: 0.91927 | v_loss: 0.38251 v_acc: 0.91569 |  iteration: 6665 teacher: 1 stage: sketch lr: 0.000541\n",
      "batch 450 loss: 0.29149 acc: 0.91569 | v_loss: 0.94357 v_acc: 0.82194 |  iteration: 6666 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 451 loss: 0.25576 acc: 0.93262 | v_loss: 0.62298 v_acc: 0.87305 |  iteration: 6667 teacher: 1 stage: sketch lr: 0.000541\n",
      "batch 452 loss: 0.22354 acc: 0.93587 | v_loss: 0.68582 v_acc: 0.85579 |  iteration: 6668 teacher: 1 stage: sketch lr: 0.000541\n",
      "batch 453 loss: 0.25665 acc: 0.92839 | v_loss: 0.51608 v_acc: 0.89193 |  iteration: 6669 teacher: 1 stage: sketch lr: 0.000541\n",
      "batch 454 loss: 0.22628 acc: 0.93066 | v_loss: 0.52861 v_acc: 0.87793 |  iteration: 6670 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 455 loss: 0.29099 acc: 0.90951 | v_loss: 0.55739 v_acc: 0.88574 |  iteration: 6671 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 456 loss: 0.27551 acc: 0.91276 | v_loss: 0.54845 v_acc: 0.88965 |  iteration: 6672 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 457 loss: 0.25191 acc: 0.92057 | v_loss: 0.48686 v_acc: 0.88932 |  iteration: 6673 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 458 loss: 0.28990 acc: 0.91960 | v_loss: 0.51788 v_acc: 0.90007 |  iteration: 6674 teacher: 1 stage: sketch lr: 0.000541\n",
      "batch 459 loss: 0.27341 acc: 0.91439 | v_loss: 0.43830 v_acc: 0.89290 |  iteration: 6675 teacher: 1 stage: sketch lr: 0.000541\n",
      "batch 460 loss: 0.32310 acc: 0.90495 | v_loss: 0.37216 v_acc: 0.91374 |  iteration: 6676 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 461 loss: 0.34950 acc: 0.89974 | v_loss: 0.67022 v_acc: 0.85938 |  iteration: 6677 teacher: 1 stage: sketch lr: 0.000541\n",
      "batch 462 loss: 0.30243 acc: 0.91016 | v_loss: 0.51541 v_acc: 0.87044 |  iteration: 6678 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 463 loss: 0.32356 acc: 0.90788 | v_loss: 0.64172 v_acc: 0.86133 |  iteration: 6679 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 464 loss: 0.26785 acc: 0.91797 | v_loss: 0.79494 v_acc: 0.84147 |  iteration: 6680 teacher: 1 stage: sketch lr: 0.000541\n",
      "batch 465 loss: 0.35670 acc: 0.90104 | v_loss: 0.43724 v_acc: 0.90039 |  iteration: 6681 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 466 loss: 0.25871 acc: 0.91276 | v_loss: 0.55069 v_acc: 0.86849 |  iteration: 6682 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 467 loss: 0.33949 acc: 0.90202 | v_loss: 0.51265 v_acc: 0.88770 |  iteration: 6683 teacher: 1 stage: sketch lr: 0.000541\n",
      "batch 468 loss: 0.25640 acc: 0.92253 | v_loss: 0.45531 v_acc: 0.89648 |  iteration: 6684 teacher: 1 stage: sketch lr: 0.000541\n",
      "batch 469 loss: 0.34667 acc: 0.89714 | v_loss: 1.13179 v_acc: 0.79590 |  iteration: 6685 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 470 loss: 0.35288 acc: 0.88900 | v_loss: 0.35217 v_acc: 0.91862 |  iteration: 6686 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 471 loss: 0.32550 acc: 0.90462 | v_loss: 0.59997 v_acc: 0.87207 |  iteration: 6687 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 472 loss: 0.30075 acc: 0.92025 | v_loss: 0.54751 v_acc: 0.88737 |  iteration: 6688 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 473 loss: 0.30063 acc: 0.91309 | v_loss: 0.44161 v_acc: 0.90039 |  iteration: 6689 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 474 loss: 0.34213 acc: 0.89974 | v_loss: 0.50879 v_acc: 0.89518 |  iteration: 6690 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 475 loss: 0.31579 acc: 0.90560 | v_loss: 0.63585 v_acc: 0.87533 |  iteration: 6691 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 476 loss: 0.31127 acc: 0.90820 | v_loss: 0.42668 v_acc: 0.90592 |  iteration: 6692 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 477 loss: 0.29755 acc: 0.91862 | v_loss: 0.64086 v_acc: 0.87077 |  iteration: 6693 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 478 loss: 0.28524 acc: 0.91439 | v_loss: 0.37839 v_acc: 0.90072 |  iteration: 6694 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 479 loss: 0.26483 acc: 0.92578 | v_loss: 0.93790 v_acc: 0.81934 |  iteration: 6695 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 480 loss: 0.28856 acc: 0.91862 | v_loss: 0.54928 v_acc: 0.88379 |  iteration: 6696 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 481 loss: 0.27408 acc: 0.91439 | v_loss: 0.63745 v_acc: 0.86882 |  iteration: 6697 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 482 loss: 0.30388 acc: 0.90918 | v_loss: 0.43167 v_acc: 0.89909 |  iteration: 6698 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 483 loss: 0.22961 acc: 0.93197 | v_loss: 0.67382 v_acc: 0.86068 |  iteration: 6699 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 484 loss: 0.27731 acc: 0.92480 | v_loss: 0.42731 v_acc: 0.89518 |  iteration: 6700 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 485 loss: 0.32761 acc: 0.90625 | v_loss: 0.47171 v_acc: 0.88770 |  iteration: 6701 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 486 loss: 0.30514 acc: 0.91764 | v_loss: 0.45300 v_acc: 0.89323 |  iteration: 6702 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 487 loss: 0.29123 acc: 0.90918 | v_loss: 0.75476 v_acc: 0.85352 |  iteration: 6703 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 488 loss: 0.30914 acc: 0.91178 | v_loss: 0.50828 v_acc: 0.90202 |  iteration: 6704 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 489 loss: 0.29178 acc: 0.91732 | v_loss: 0.54147 v_acc: 0.88379 |  iteration: 6705 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 490 loss: 0.29888 acc: 0.91146 | v_loss: 0.67815 v_acc: 0.85840 |  iteration: 6706 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 491 loss: 0.30682 acc: 0.92122 | v_loss: 0.46644 v_acc: 0.89909 |  iteration: 6707 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 492 loss: 0.35171 acc: 0.89974 | v_loss: 0.53879 v_acc: 0.86784 |  iteration: 6708 teacher: 0 stage: sketch lr: 0.000540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 493 loss: 0.29684 acc: 0.91797 | v_loss: 0.54926 v_acc: 0.86719 |  iteration: 6709 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 494 loss: 0.31971 acc: 0.90234 | v_loss: 0.73820 v_acc: 0.84049 |  iteration: 6710 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 495 loss: 0.30180 acc: 0.91309 | v_loss: 0.53291 v_acc: 0.87793 |  iteration: 6711 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 496 loss: 0.30380 acc: 0.90495 | v_loss: 0.59587 v_acc: 0.87174 |  iteration: 6712 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 497 loss: 0.26705 acc: 0.92155 | v_loss: 0.65517 v_acc: 0.86979 |  iteration: 6713 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 498 loss: 0.28464 acc: 0.91569 | v_loss: 0.55210 v_acc: 0.86198 |  iteration: 6714 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 499 loss: 0.22010 acc: 0.93262 | v_loss: 0.47238 v_acc: 0.89388 |  iteration: 6715 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 500 loss: 0.26845 acc: 0.91406 | v_loss: 0.73596 v_acc: 0.84115 |  iteration: 6716 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 501 loss: 0.23325 acc: 0.93066 | v_loss: 0.55508 v_acc: 0.87826 |  iteration: 6717 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 502 loss: 0.27389 acc: 0.92057 | v_loss: 0.58348 v_acc: 0.86100 |  iteration: 6718 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 503 loss: 0.31335 acc: 0.90397 | v_loss: 0.50961 v_acc: 0.87988 |  iteration: 6719 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 504 loss: 0.28615 acc: 0.91146 | v_loss: 0.45449 v_acc: 0.89355 |  iteration: 6720 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 505 loss: 0.28568 acc: 0.91699 | v_loss: 0.44471 v_acc: 0.89681 |  iteration: 6721 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 506 loss: 0.26005 acc: 0.93034 | v_loss: 0.54716 v_acc: 0.87663 |  iteration: 6722 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 507 loss: 0.17551 acc: 0.94499 | v_loss: 0.67516 v_acc: 0.84798 |  iteration: 6723 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 508 loss: 0.35148 acc: 0.90039 | v_loss: 0.57963 v_acc: 0.88542 |  iteration: 6724 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 509 loss: 0.27809 acc: 0.91699 | v_loss: 0.58268 v_acc: 0.87370 |  iteration: 6725 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 510 loss: 0.27644 acc: 0.91992 | v_loss: 0.36951 v_acc: 0.90299 |  iteration: 6726 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 511 loss: 0.24623 acc: 0.92578 | v_loss: 0.50737 v_acc: 0.88184 |  iteration: 6727 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 512 loss: 0.31100 acc: 0.91146 | v_loss: 0.45038 v_acc: 0.88281 |  iteration: 6728 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 513 loss: 0.26808 acc: 0.92285 | v_loss: 0.82676 v_acc: 0.83138 |  iteration: 6729 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 514 loss: 0.20866 acc: 0.93262 | v_loss: 0.37811 v_acc: 0.90299 |  iteration: 6730 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 515 loss: 0.29545 acc: 0.91406 | v_loss: 0.31648 v_acc: 0.92155 |  iteration: 6731 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 516 loss: 0.24343 acc: 0.93099 | v_loss: 0.56593 v_acc: 0.87467 |  iteration: 6732 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 517 loss: 0.34940 acc: 0.89583 | v_loss: 0.57343 v_acc: 0.87858 |  iteration: 6733 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 518 loss: 0.26248 acc: 0.92415 | v_loss: 0.63867 v_acc: 0.86003 |  iteration: 6734 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 519 loss: 0.28623 acc: 0.91732 | v_loss: 0.43575 v_acc: 0.89258 |  iteration: 6735 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 520 loss: 0.26384 acc: 0.92025 | v_loss: 0.55099 v_acc: 0.85612 |  iteration: 6736 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 521 loss: 0.43261 acc: 0.88737 | v_loss: 0.60815 v_acc: 0.86426 |  iteration: 6737 teacher: 1 stage: sketch lr: 0.000538\n",
      "batch 522 loss: 0.26971 acc: 0.91895 | v_loss: 0.63494 v_acc: 0.84635 |  iteration: 6738 teacher: 1 stage: sketch lr: 0.000538\n",
      "batch 523 loss: 0.27128 acc: 0.92318 | v_loss: 0.49345 v_acc: 0.89160 |  iteration: 6739 teacher: 1 stage: sketch lr: 0.000538\n",
      "batch 524 loss: 0.38854 acc: 0.89128 | v_loss: 0.39658 v_acc: 0.90202 |  iteration: 6740 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 525 loss: 0.24026 acc: 0.93132 | v_loss: 0.33020 v_acc: 0.92220 |  iteration: 6741 teacher: 1 stage: sketch lr: 0.000538\n",
      "batch 526 loss: 0.25830 acc: 0.92383 | v_loss: 0.48522 v_acc: 0.89258 |  iteration: 6742 teacher: 1 stage: sketch lr: 0.000538\n",
      "batch 527 loss: 0.31706 acc: 0.91309 | v_loss: 0.50305 v_acc: 0.88411 |  iteration: 6743 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 528 loss: 0.30226 acc: 0.90983 | v_loss: 0.77871 v_acc: 0.85970 |  iteration: 6744 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 529 loss: 0.25062 acc: 0.92611 | v_loss: 0.49912 v_acc: 0.88086 |  iteration: 6745 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 530 loss: 0.30587 acc: 0.91276 | v_loss: 0.62341 v_acc: 0.86589 |  iteration: 6746 teacher: 1 stage: sketch lr: 0.000538\n",
      "batch 531 loss: 0.27879 acc: 0.92253 | v_loss: 0.40376 v_acc: 0.89909 |  iteration: 6747 teacher: 1 stage: sketch lr: 0.000538\n",
      "batch 532 loss: 0.37549 acc: 0.89616 | v_loss: 0.51229 v_acc: 0.88281 |  iteration: 6748 teacher: 1 stage: sketch lr: 0.000538\n",
      "batch 533 loss: 0.30175 acc: 0.90951 | v_loss: 0.68785 v_acc: 0.84342 |  iteration: 6749 teacher: 1 stage: sketch lr: 0.000538\n",
      "batch 534 loss: 0.31767 acc: 0.90527 | v_loss: 0.50630 v_acc: 0.89225 |  iteration: 6750 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 535 loss: 0.27914 acc: 0.91992 | v_loss: 0.52012 v_acc: 0.89030 |  iteration: 6751 teacher: 1 stage: sketch lr: 0.000538\n",
      "batch 536 loss: 0.23995 acc: 0.92773 | v_loss: 0.50300 v_acc: 0.87826 |  iteration: 6752 teacher: 1 stage: sketch lr: 0.000538\n",
      "batch 537 loss: 0.36313 acc: 0.89160 | v_loss: 0.40313 v_acc: 0.90560 |  iteration: 6753 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 538 loss: 0.24977 acc: 0.92415 | v_loss: 0.50721 v_acc: 0.89616 |  iteration: 6754 teacher: 1 stage: sketch lr: 0.000538\n",
      "batch 539 loss: 0.23052 acc: 0.93294 | v_loss: 0.58326 v_acc: 0.87012 |  iteration: 6755 teacher: 1 stage: sketch lr: 0.000538\n",
      "batch 540 loss: 0.30250 acc: 0.91471 | v_loss: 0.40951 v_acc: 0.91341 |  iteration: 6756 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 541 loss: 0.31512 acc: 0.91276 | v_loss: 0.95372 v_acc: 0.82454 |  iteration: 6757 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 542 loss: 0.34011 acc: 0.90560 | v_loss: 0.61520 v_acc: 0.87565 |  iteration: 6758 teacher: 1 stage: sketch lr: 0.000538\n",
      "batch 543 loss: 0.32998 acc: 0.90104 | v_loss: 0.70626 v_acc: 0.85645 |  iteration: 6759 teacher: 1 stage: sketch lr: 0.000538\n",
      "batch 544 loss: 0.32561 acc: 0.90430 | v_loss: 0.54963 v_acc: 0.88477 |  iteration: 6760 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 545 loss: 0.38516 acc: 0.88737 | v_loss: 0.49171 v_acc: 0.88835 |  iteration: 6761 teacher: 1 stage: sketch lr: 0.000537\n",
      "batch 546 loss: 0.30224 acc: 0.91243 | v_loss: 0.56089 v_acc: 0.88249 |  iteration: 6762 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 547 loss: 0.26047 acc: 0.92318 | v_loss: 0.54540 v_acc: 0.88086 |  iteration: 6763 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 548 loss: 0.22096 acc: 0.93066 | v_loss: 0.51135 v_acc: 0.88542 |  iteration: 6764 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 549 loss: 0.28158 acc: 0.91862 | v_loss: 0.48434 v_acc: 0.90299 |  iteration: 6765 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 550 loss: 0.28858 acc: 0.91536 | v_loss: 0.44657 v_acc: 0.89421 |  iteration: 6766 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 551 loss: 0.33755 acc: 0.90853 | v_loss: 0.35806 v_acc: 0.90918 |  iteration: 6767 teacher: 1 stage: sketch lr: 0.000537\n",
      "batch 552 loss: 0.30009 acc: 0.91764 | v_loss: 0.62312 v_acc: 0.86003 |  iteration: 6768 teacher: 1 stage: sketch lr: 0.000537\n",
      "batch 553 loss: 0.29484 acc: 0.91764 | v_loss: 0.51337 v_acc: 0.86882 |  iteration: 6769 teacher: 1 stage: sketch lr: 0.000537\n",
      "batch 554 loss: 0.19446 acc: 0.94010 | v_loss: 0.58975 v_acc: 0.86556 |  iteration: 6770 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 555 loss: 0.27149 acc: 0.91732 | v_loss: 0.77374 v_acc: 0.84863 |  iteration: 6771 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 556 loss: 0.29821 acc: 0.90951 | v_loss: 0.44309 v_acc: 0.90560 |  iteration: 6772 teacher: 1 stage: sketch lr: 0.000537\n",
      "batch 557 loss: 0.25804 acc: 0.93001 | v_loss: 0.57553 v_acc: 0.87793 |  iteration: 6773 teacher: 1 stage: sketch lr: 0.000537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 558 loss: 0.28656 acc: 0.91536 | v_loss: 0.51945 v_acc: 0.89193 |  iteration: 6774 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 559 loss: 0.22665 acc: 0.92806 | v_loss: 0.44523 v_acc: 0.89941 |  iteration: 6775 teacher: 1 stage: sketch lr: 0.000537\n",
      "batch 560 loss: 0.30113 acc: 0.91374 | v_loss: 1.12268 v_acc: 0.80273 |  iteration: 6776 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 561 loss: 0.22422 acc: 0.93880 | v_loss: 0.39210 v_acc: 0.91243 |  iteration: 6777 teacher: 1 stage: sketch lr: 0.000537\n",
      "batch 562 loss: 0.20979 acc: 0.93620 | v_loss: 0.58210 v_acc: 0.87728 |  iteration: 6778 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 563 loss: 0.34767 acc: 0.90039 | v_loss: 0.51631 v_acc: 0.89421 |  iteration: 6779 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 564 loss: 0.38920 acc: 0.89290 | v_loss: 0.39718 v_acc: 0.91048 |  iteration: 6780 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 565 loss: 0.33877 acc: 0.90918 | v_loss: 0.47115 v_acc: 0.89486 |  iteration: 6781 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 566 loss: 0.28746 acc: 0.91471 | v_loss: 0.61514 v_acc: 0.86621 |  iteration: 6782 teacher: 1 stage: sketch lr: 0.000537\n",
      "batch 567 loss: 0.27676 acc: 0.91764 | v_loss: 0.41296 v_acc: 0.90267 |  iteration: 6783 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 568 loss: 0.20899 acc: 0.93197 | v_loss: 0.65475 v_acc: 0.85547 |  iteration: 6784 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 569 loss: 0.24753 acc: 0.92513 | v_loss: 0.40577 v_acc: 0.90299 |  iteration: 6785 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 570 loss: 0.23878 acc: 0.93392 | v_loss: 1.00694 v_acc: 0.81022 |  iteration: 6786 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 571 loss: 0.25473 acc: 0.92253 | v_loss: 0.59189 v_acc: 0.88086 |  iteration: 6787 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 572 loss: 0.27375 acc: 0.91927 | v_loss: 0.65021 v_acc: 0.87174 |  iteration: 6788 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 573 loss: 0.26133 acc: 0.92383 | v_loss: 0.40465 v_acc: 0.90527 |  iteration: 6789 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 574 loss: 0.31410 acc: 0.91797 | v_loss: 0.69354 v_acc: 0.85612 |  iteration: 6790 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 575 loss: 0.22328 acc: 0.93587 | v_loss: 0.47912 v_acc: 0.89616 |  iteration: 6791 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 576 loss: 0.27175 acc: 0.92708 | v_loss: 0.48261 v_acc: 0.89062 |  iteration: 6792 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 577 loss: 0.32894 acc: 0.90951 | v_loss: 0.47388 v_acc: 0.89062 |  iteration: 6793 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 578 loss: 0.20337 acc: 0.93978 | v_loss: 0.77412 v_acc: 0.84408 |  iteration: 6794 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 579 loss: 0.22423 acc: 0.93848 | v_loss: 0.53771 v_acc: 0.89518 |  iteration: 6795 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 580 loss: 0.22785 acc: 0.93652 | v_loss: 0.55705 v_acc: 0.87500 |  iteration: 6796 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 581 loss: 0.30487 acc: 0.90658 | v_loss: 0.65165 v_acc: 0.85221 |  iteration: 6797 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 582 loss: 0.22281 acc: 0.93424 | v_loss: 0.51199 v_acc: 0.88444 |  iteration: 6798 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 583 loss: 0.31738 acc: 0.91146 | v_loss: 0.56559 v_acc: 0.85384 |  iteration: 6799 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 584 loss: 0.36340 acc: 0.89160 | v_loss: 0.54416 v_acc: 0.87272 |  iteration: 6800 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 585 loss: 0.29228 acc: 0.91797 | v_loss: 0.72989 v_acc: 0.85059 |  iteration: 6801 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 586 loss: 0.27677 acc: 0.92025 | v_loss: 0.52642 v_acc: 0.88379 |  iteration: 6802 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 587 loss: 0.30737 acc: 0.91048 | v_loss: 0.53967 v_acc: 0.88672 |  iteration: 6803 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 588 loss: 0.37868 acc: 0.89062 | v_loss: 0.62057 v_acc: 0.87565 |  iteration: 6804 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 589 loss: 0.33031 acc: 0.90560 | v_loss: 0.58657 v_acc: 0.85417 |  iteration: 6805 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 590 loss: 0.22786 acc: 0.93555 | v_loss: 0.51068 v_acc: 0.88997 |  iteration: 6806 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 591 loss: 0.22176 acc: 0.93197 | v_loss: 0.74734 v_acc: 0.83398 |  iteration: 6807 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 592 loss: 0.28567 acc: 0.92188 | v_loss: 0.53372 v_acc: 0.88281 |  iteration: 6808 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 593 loss: 0.23721 acc: 0.92415 | v_loss: 0.53998 v_acc: 0.87305 |  iteration: 6809 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 594 loss: 0.34569 acc: 0.90104 | v_loss: 0.49957 v_acc: 0.87858 |  iteration: 6810 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 595 loss: 0.31557 acc: 0.90267 | v_loss: 0.46824 v_acc: 0.89160 |  iteration: 6811 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 596 loss: 0.23471 acc: 0.92415 | v_loss: 0.45201 v_acc: 0.89648 |  iteration: 6812 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 597 loss: 0.22774 acc: 0.93555 | v_loss: 0.53267 v_acc: 0.88379 |  iteration: 6813 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 598 loss: 0.22450 acc: 0.93555 | v_loss: 0.60896 v_acc: 0.86263 |  iteration: 6814 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 599 loss: 0.32102 acc: 0.91276 | v_loss: 0.56404 v_acc: 0.89225 |  iteration: 6815 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 600 loss: 0.24454 acc: 0.93229 | v_loss: 0.58617 v_acc: 0.88281 |  iteration: 6816 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 601 loss: 0.31864 acc: 0.91178 | v_loss: 0.36771 v_acc: 0.91016 |  iteration: 6817 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 602 loss: 0.24896 acc: 0.92904 | v_loss: 0.55119 v_acc: 0.87630 |  iteration: 6818 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 603 loss: 0.27898 acc: 0.91667 | v_loss: 0.50520 v_acc: 0.87695 |  iteration: 6819 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 604 loss: 0.27915 acc: 0.92253 | v_loss: 0.90228 v_acc: 0.82422 |  iteration: 6820 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 605 loss: 0.32557 acc: 0.90234 | v_loss: 0.36258 v_acc: 0.90983 |  iteration: 6821 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 606 loss: 0.26134 acc: 0.92188 | v_loss: 0.29110 v_acc: 0.93001 |  iteration: 6822 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 607 loss: 0.26704 acc: 0.92090 | v_loss: 0.55326 v_acc: 0.88281 |  iteration: 6823 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 608 loss: 0.21479 acc: 0.93034 | v_loss: 0.52270 v_acc: 0.88997 |  iteration: 6824 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 609 loss: 0.29884 acc: 0.91211 | v_loss: 0.63483 v_acc: 0.86068 |  iteration: 6825 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 610 loss: 0.22746 acc: 0.92871 | v_loss: 0.42044 v_acc: 0.89941 |  iteration: 6826 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 611 loss: 0.24569 acc: 0.92448 | v_loss: 0.55014 v_acc: 0.86621 |  iteration: 6827 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 612 loss: 0.33654 acc: 0.90625 | v_loss: 0.57258 v_acc: 0.87109 |  iteration: 6828 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 613 loss: 0.34125 acc: 0.90495 | v_loss: 0.66697 v_acc: 0.84733 |  iteration: 6829 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 614 loss: 0.26195 acc: 0.92122 | v_loss: 0.48597 v_acc: 0.89193 |  iteration: 6830 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 615 loss: 0.27479 acc: 0.91667 | v_loss: 0.38749 v_acc: 0.90820 |  iteration: 6831 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 616 loss: 0.29789 acc: 0.91178 | v_loss: 0.34965 v_acc: 0.90755 |  iteration: 6832 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 617 loss: 0.31366 acc: 0.90788 | v_loss: 0.44035 v_acc: 0.89355 |  iteration: 6833 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 618 loss: 0.34025 acc: 0.89518 | v_loss: 0.48039 v_acc: 0.88151 |  iteration: 6834 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 619 loss: 0.32351 acc: 0.90592 | v_loss: 0.80251 v_acc: 0.85124 |  iteration: 6835 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 620 loss: 0.22642 acc: 0.93001 | v_loss: 0.55087 v_acc: 0.87305 |  iteration: 6836 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 621 loss: 0.25056 acc: 0.92806 | v_loss: 0.63197 v_acc: 0.87207 |  iteration: 6837 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 622 loss: 0.23344 acc: 0.93294 | v_loss: 0.43836 v_acc: 0.89909 |  iteration: 6838 teacher: 1 stage: sketch lr: 0.000534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 623 loss: 0.32572 acc: 0.90592 | v_loss: 0.56216 v_acc: 0.87891 |  iteration: 6839 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 624 loss: 0.36694 acc: 0.89876 | v_loss: 0.75410 v_acc: 0.83887 |  iteration: 6840 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 625 loss: 0.25363 acc: 0.92578 | v_loss: 0.53702 v_acc: 0.88672 |  iteration: 6841 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 626 loss: 0.31698 acc: 0.90788 | v_loss: 0.49526 v_acc: 0.88672 |  iteration: 6842 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 627 loss: 0.27116 acc: 0.92318 | v_loss: 0.48727 v_acc: 0.88249 |  iteration: 6843 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 628 loss: 0.37338 acc: 0.88835 | v_loss: 0.42029 v_acc: 0.89909 |  iteration: 6844 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 629 loss: 0.25479 acc: 0.92155 | v_loss: 0.43210 v_acc: 0.90365 |  iteration: 6845 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 630 loss: 0.25323 acc: 0.92448 | v_loss: 0.58193 v_acc: 0.86458 |  iteration: 6846 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 631 loss: 0.24432 acc: 0.92188 | v_loss: 0.38218 v_acc: 0.91211 |  iteration: 6847 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 632 loss: 0.26155 acc: 0.91992 | v_loss: 0.89619 v_acc: 0.82975 |  iteration: 6848 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 633 loss: 0.20407 acc: 0.93685 | v_loss: 0.64099 v_acc: 0.87598 |  iteration: 6849 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 634 loss: 0.23617 acc: 0.93066 | v_loss: 0.67705 v_acc: 0.86523 |  iteration: 6850 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 635 loss: 0.29970 acc: 0.91309 | v_loss: 0.52324 v_acc: 0.89714 |  iteration: 6851 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 636 loss: 0.27918 acc: 0.92318 | v_loss: 0.50217 v_acc: 0.89323 |  iteration: 6852 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 637 loss: 0.29333 acc: 0.92188 | v_loss: 0.60614 v_acc: 0.88542 |  iteration: 6853 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 638 loss: 0.25340 acc: 0.92415 | v_loss: 0.54416 v_acc: 0.88835 |  iteration: 6854 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 639 loss: 0.28174 acc: 0.93034 | v_loss: 0.49317 v_acc: 0.88997 |  iteration: 6855 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 640 loss: 0.25308 acc: 0.92546 | v_loss: 0.47021 v_acc: 0.90039 |  iteration: 6856 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 641 loss: 0.19953 acc: 0.94434 | v_loss: 0.43887 v_acc: 0.89453 |  iteration: 6857 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 642 loss: 0.24499 acc: 0.93034 | v_loss: 0.33133 v_acc: 0.92188 |  iteration: 6858 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 643 loss: 0.27220 acc: 0.91797 | v_loss: 0.61622 v_acc: 0.86100 |  iteration: 6859 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 644 loss: 0.21263 acc: 0.93848 | v_loss: 0.52780 v_acc: 0.86654 |  iteration: 6860 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 645 loss: 0.29241 acc: 0.90658 | v_loss: 0.58694 v_acc: 0.86068 |  iteration: 6861 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 646 loss: 0.21944 acc: 0.92839 | v_loss: 0.79949 v_acc: 0.84408 |  iteration: 6862 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 647 loss: 0.24575 acc: 0.92578 | v_loss: 0.42534 v_acc: 0.90755 |  iteration: 6863 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 648 loss: 0.24133 acc: 0.92480 | v_loss: 0.58158 v_acc: 0.87272 |  iteration: 6864 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 649 loss: 0.18633 acc: 0.94629 | v_loss: 0.55493 v_acc: 0.88477 |  iteration: 6865 teacher: 0 stage: sketch lr: 0.000533\n",
      "batch 650 loss: 0.27809 acc: 0.92025 | v_loss: 0.42406 v_acc: 0.90267 |  iteration: 6866 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 651 loss: 0.30760 acc: 0.90560 | v_loss: 1.10228 v_acc: 0.80859 |  iteration: 6867 teacher: 0 stage: sketch lr: 0.000533\n",
      "batch 652 loss: 0.29396 acc: 0.91667 | v_loss: 0.40033 v_acc: 0.91536 |  iteration: 6868 teacher: 0 stage: sketch lr: 0.000533\n",
      "batch 653 loss: 0.27409 acc: 0.92025 | v_loss: 0.60694 v_acc: 0.86979 |  iteration: 6869 teacher: 0 stage: sketch lr: 0.000533\n",
      "batch 654 loss: 0.27729 acc: 0.91764 | v_loss: 0.52714 v_acc: 0.87891 |  iteration: 6870 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 655 loss: 0.26859 acc: 0.91667 | v_loss: 0.42183 v_acc: 0.89941 |  iteration: 6871 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 656 loss: 0.31455 acc: 0.91374 | v_loss: 0.51333 v_acc: 0.88639 |  iteration: 6872 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 657 loss: 0.29715 acc: 0.91341 | v_loss: 0.59014 v_acc: 0.87240 |  iteration: 6873 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 658 loss: 0.37697 acc: 0.90007 | v_loss: 0.43175 v_acc: 0.90299 |  iteration: 6874 teacher: 0 stage: sketch lr: 0.000533\n",
      "batch 659 loss: 0.23442 acc: 0.92708 | v_loss: 0.60774 v_acc: 0.86882 |  iteration: 6875 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 660 loss: 0.29990 acc: 0.90430 | v_loss: 0.41952 v_acc: 0.89811 |  iteration: 6876 teacher: 0 stage: sketch lr: 0.000533\n",
      "batch 661 loss: 0.28694 acc: 0.91504 | v_loss: 0.95210 v_acc: 0.80762 |  iteration: 6877 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 662 loss: 0.34315 acc: 0.90820 | v_loss: 0.58811 v_acc: 0.87467 |  iteration: 6878 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 663 loss: 0.26962 acc: 0.92090 | v_loss: 0.65578 v_acc: 0.86393 |  iteration: 6879 teacher: 0 stage: sketch lr: 0.000533\n",
      "batch 664 loss: 0.22736 acc: 0.93034 | v_loss: 0.45265 v_acc: 0.88932 |  iteration: 6880 teacher: 0 stage: sketch lr: 0.000533\n",
      "batch 665 loss: 0.32827 acc: 0.90332 | v_loss: 0.67254 v_acc: 0.84896 |  iteration: 6881 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 666 loss: 0.23775 acc: 0.92969 | v_loss: 0.42094 v_acc: 0.89648 |  iteration: 6882 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 667 loss: 0.25773 acc: 0.92513 | v_loss: 0.47827 v_acc: 0.88509 |  iteration: 6883 teacher: 0 stage: sketch lr: 0.000533\n",
      "batch 668 loss: 0.31598 acc: 0.90560 | v_loss: 0.43534 v_acc: 0.88835 |  iteration: 6884 teacher: 0 stage: sketch lr: 0.000533\n",
      "batch 669 loss: 0.23945 acc: 0.92806 | v_loss: 0.69978 v_acc: 0.84993 |  iteration: 6885 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 670 loss: 0.27450 acc: 0.91927 | v_loss: 0.49902 v_acc: 0.89323 |  iteration: 6886 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 671 loss: 0.34423 acc: 0.89811 | v_loss: 0.51714 v_acc: 0.87826 |  iteration: 6887 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 672 loss: 0.26688 acc: 0.92220 | v_loss: 0.66207 v_acc: 0.85449 |  iteration: 6888 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 673 loss: 0.42192 acc: 0.87956 | v_loss: 0.43648 v_acc: 0.89681 |  iteration: 6889 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 674 loss: 0.29243 acc: 0.91048 | v_loss: 0.48355 v_acc: 0.87174 |  iteration: 6890 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 675 loss: 0.40976 acc: 0.88118 | v_loss: 0.56446 v_acc: 0.86621 |  iteration: 6891 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 676 loss: 0.32907 acc: 0.90918 | v_loss: 0.79990 v_acc: 0.84473 |  iteration: 6892 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 677 loss: 0.30653 acc: 0.91178 | v_loss: 0.57109 v_acc: 0.88053 |  iteration: 6893 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 678 loss: 0.34592 acc: 0.90104 | v_loss: 0.61816 v_acc: 0.87370 |  iteration: 6894 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 679 loss: 0.34066 acc: 0.90951 | v_loss: 0.61663 v_acc: 0.87402 |  iteration: 6895 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 680 loss: 0.34214 acc: 0.90299 | v_loss: 0.58521 v_acc: 0.85872 |  iteration: 6896 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 681 loss: 0.33694 acc: 0.89811 | v_loss: 0.49731 v_acc: 0.88379 |  iteration: 6897 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 682 loss: 0.25873 acc: 0.92188 | v_loss: 0.77959 v_acc: 0.83333 |  iteration: 6898 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 683 loss: 0.30930 acc: 0.91309 | v_loss: 0.59514 v_acc: 0.87956 |  iteration: 6899 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 684 loss: 0.33280 acc: 0.90788 | v_loss: 0.58953 v_acc: 0.85970 |  iteration: 6900 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 685 loss: 0.28923 acc: 0.91048 | v_loss: 0.53696 v_acc: 0.87044 |  iteration: 6901 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 686 loss: 0.29748 acc: 0.91243 | v_loss: 0.49228 v_acc: 0.89616 |  iteration: 6902 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 687 loss: 0.30231 acc: 0.91016 | v_loss: 0.46950 v_acc: 0.88770 |  iteration: 6903 teacher: 1 stage: sketch lr: 0.000532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 688 loss: 0.48252 acc: 0.87240 | v_loss: 0.55227 v_acc: 0.88053 |  iteration: 6904 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 689 loss: 0.30122 acc: 0.91602 | v_loss: 0.65335 v_acc: 0.84635 |  iteration: 6905 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 690 loss: 0.29485 acc: 0.91309 | v_loss: 0.54369 v_acc: 0.88477 |  iteration: 6906 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 691 loss: 0.41309 acc: 0.89746 | v_loss: 0.62599 v_acc: 0.86589 |  iteration: 6907 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 692 loss: 0.29809 acc: 0.90853 | v_loss: 0.35973 v_acc: 0.90690 |  iteration: 6908 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 693 loss: 0.30898 acc: 0.91406 | v_loss: 0.54488 v_acc: 0.88249 |  iteration: 6909 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 694 loss: 0.29201 acc: 0.91634 | v_loss: 0.53810 v_acc: 0.87142 |  iteration: 6910 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 695 loss: 0.35040 acc: 0.90723 | v_loss: 0.84093 v_acc: 0.82910 |  iteration: 6911 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 696 loss: 0.34449 acc: 0.90267 | v_loss: 0.39236 v_acc: 0.90430 |  iteration: 6912 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 697 loss: 0.31856 acc: 0.91016 | v_loss: 0.32532 v_acc: 0.92155 |  iteration: 6913 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 698 loss: 0.35898 acc: 0.89811 | v_loss: 0.56879 v_acc: 0.87598 |  iteration: 6914 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 699 loss: 0.31496 acc: 0.90332 | v_loss: 0.56063 v_acc: 0.87793 |  iteration: 6915 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 700 loss: 0.28862 acc: 0.91764 | v_loss: 0.69180 v_acc: 0.84147 |  iteration: 6916 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 701 loss: 0.33300 acc: 0.89648 | v_loss: 0.43104 v_acc: 0.89909 |  iteration: 6917 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 702 loss: 0.38135 acc: 0.88314 | v_loss: 0.55371 v_acc: 0.86328 |  iteration: 6918 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 703 loss: 0.34439 acc: 0.90690 | v_loss: 0.65903 v_acc: 0.85189 |  iteration: 6919 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 704 loss: 0.37049 acc: 0.89518 | v_loss: 0.68323 v_acc: 0.84147 |  iteration: 6920 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 705 loss: 0.38239 acc: 0.89518 | v_loss: 0.48793 v_acc: 0.88900 |  iteration: 6921 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 706 loss: 0.30188 acc: 0.91471 | v_loss: 0.39285 v_acc: 0.90332 |  iteration: 6922 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 707 loss: 0.36546 acc: 0.90365 | v_loss: 0.33368 v_acc: 0.91439 |  iteration: 6923 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 708 loss: 0.35295 acc: 0.89258 | v_loss: 0.49896 v_acc: 0.88704 |  iteration: 6924 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 709 loss: 0.36059 acc: 0.89681 | v_loss: 0.53587 v_acc: 0.86849 |  iteration: 6925 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 710 loss: 0.30744 acc: 0.90462 | v_loss: 0.76843 v_acc: 0.85286 |  iteration: 6926 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 711 loss: 0.42979 acc: 0.87077 | v_loss: 0.54356 v_acc: 0.87077 |  iteration: 6927 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 712 loss: 0.34518 acc: 0.90072 | v_loss: 0.65907 v_acc: 0.85807 |  iteration: 6928 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 713 loss: 0.31425 acc: 0.91374 | v_loss: 0.44947 v_acc: 0.88086 |  iteration: 6929 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 714 loss: 0.33836 acc: 0.90039 | v_loss: 0.53943 v_acc: 0.87337 |  iteration: 6930 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 715 loss: 0.24848 acc: 0.92643 | v_loss: 0.71957 v_acc: 0.84180 |  iteration: 6931 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 716 loss: 0.34343 acc: 0.90072 | v_loss: 0.51176 v_acc: 0.88704 |  iteration: 6932 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 717 loss: 0.29093 acc: 0.91048 | v_loss: 0.52454 v_acc: 0.88379 |  iteration: 6933 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 718 loss: 0.33268 acc: 0.91243 | v_loss: 0.53467 v_acc: 0.87663 |  iteration: 6934 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 719 loss: 0.31278 acc: 0.91113 | v_loss: 0.42020 v_acc: 0.90007 |  iteration: 6935 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 720 loss: 0.33998 acc: 0.90462 | v_loss: 0.48244 v_acc: 0.89681 |  iteration: 6936 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 721 loss: 0.45035 acc: 0.87370 | v_loss: 0.61532 v_acc: 0.86165 |  iteration: 6937 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 722 loss: 0.31659 acc: 0.91178 | v_loss: 0.40041 v_acc: 0.91048 |  iteration: 6938 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 723 loss: 0.34902 acc: 0.89844 | v_loss: 0.92906 v_acc: 0.81510 |  iteration: 6939 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 724 loss: 0.29138 acc: 0.91667 | v_loss: 0.64746 v_acc: 0.86686 |  iteration: 6940 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 725 loss: 0.39067 acc: 0.88770 | v_loss: 0.68679 v_acc: 0.85547 |  iteration: 6941 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 726 loss: 0.31995 acc: 0.90625 | v_loss: 0.52720 v_acc: 0.88542 |  iteration: 6942 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 727 loss: 0.34683 acc: 0.90267 | v_loss: 0.52780 v_acc: 0.87435 |  iteration: 6943 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 728 loss: 0.25391 acc: 0.92285 | v_loss: 0.55945 v_acc: 0.87988 |  iteration: 6944 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 729 loss: 0.22868 acc: 0.92773 | v_loss: 0.56288 v_acc: 0.87598 |  iteration: 6945 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 730 loss: 0.35777 acc: 0.89290 | v_loss: 0.47974 v_acc: 0.88835 |  iteration: 6946 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 731 loss: 0.32508 acc: 0.90885 | v_loss: 0.52687 v_acc: 0.88672 |  iteration: 6947 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 732 loss: 0.33693 acc: 0.89714 | v_loss: 0.45474 v_acc: 0.89258 |  iteration: 6948 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 733 loss: 0.25304 acc: 0.92415 | v_loss: 0.39848 v_acc: 0.90234 |  iteration: 6949 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 734 loss: 0.25453 acc: 0.92806 | v_loss: 0.67238 v_acc: 0.85286 |  iteration: 6950 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 735 loss: 0.37346 acc: 0.88444 | v_loss: 0.59558 v_acc: 0.85449 |  iteration: 6951 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 736 loss: 0.47828 acc: 0.87565 | v_loss: 0.64351 v_acc: 0.85417 |  iteration: 6952 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 737 loss: 0.38896 acc: 0.88477 | v_loss: 0.77059 v_acc: 0.83659 |  iteration: 6953 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 738 loss: 0.30567 acc: 0.91016 | v_loss: 0.43015 v_acc: 0.89388 |  iteration: 6954 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 739 loss: 0.35204 acc: 0.88997 | v_loss: 0.56623 v_acc: 0.87142 |  iteration: 6955 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 740 loss: 0.23442 acc: 0.93229 | v_loss: 0.54835 v_acc: 0.88379 |  iteration: 6956 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 741 loss: 0.35124 acc: 0.90234 | v_loss: 0.43363 v_acc: 0.89486 |  iteration: 6957 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 742 loss: 0.29898 acc: 0.90885 | v_loss: 1.14412 v_acc: 0.79720 |  iteration: 6958 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 743 loss: 0.32919 acc: 0.89876 | v_loss: 0.41610 v_acc: 0.90430 |  iteration: 6959 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 744 loss: 0.28814 acc: 0.91406 | v_loss: 0.65214 v_acc: 0.85514 |  iteration: 6960 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 745 loss: 0.42787 acc: 0.88216 | v_loss: 0.53591 v_acc: 0.87793 |  iteration: 6961 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 746 loss: 0.42416 acc: 0.87305 | v_loss: 0.41121 v_acc: 0.89941 |  iteration: 6962 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 747 loss: 0.25522 acc: 0.92318 | v_loss: 0.51840 v_acc: 0.88444 |  iteration: 6963 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 748 loss: 0.40100 acc: 0.88086 | v_loss: 0.64284 v_acc: 0.85449 |  iteration: 6964 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 749 loss: 0.37769 acc: 0.89648 | v_loss: 0.52243 v_acc: 0.88997 |  iteration: 6965 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 750 loss: 0.41229 acc: 0.88411 | v_loss: 0.68981 v_acc: 0.85449 |  iteration: 6966 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 751 loss: 0.31620 acc: 0.91178 | v_loss: 0.42945 v_acc: 0.88770 |  iteration: 6967 teacher: 0 stage: sketch lr: 0.000529\n",
      "batch 752 loss: 0.35265 acc: 0.88932 | v_loss: 0.95377 v_acc: 0.79720 |  iteration: 6968 teacher: 1 stage: sketch lr: 0.000529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 753 loss: 0.31680 acc: 0.90495 | v_loss: 0.60473 v_acc: 0.86328 |  iteration: 6969 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 754 loss: 0.39609 acc: 0.87923 | v_loss: 0.68979 v_acc: 0.84473 |  iteration: 6970 teacher: 0 stage: sketch lr: 0.000529\n",
      "batch 755 loss: 0.29289 acc: 0.91243 | v_loss: 0.45852 v_acc: 0.88314 |  iteration: 6971 teacher: 0 stage: sketch lr: 0.000529\n",
      "batch 756 loss: 0.28964 acc: 0.91048 | v_loss: 0.71648 v_acc: 0.84147 |  iteration: 6972 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 757 loss: 0.33355 acc: 0.89941 | v_loss: 0.47327 v_acc: 0.88281 |  iteration: 6973 teacher: 0 stage: sketch lr: 0.000529\n",
      "batch 758 loss: 0.40905 acc: 0.88770 | v_loss: 0.49154 v_acc: 0.87663 |  iteration: 6974 teacher: 0 stage: sketch lr: 0.000529\n",
      "batch 759 loss: 0.29235 acc: 0.90723 | v_loss: 0.49934 v_acc: 0.87272 |  iteration: 6975 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 760 loss: 0.36156 acc: 0.89421 | v_loss: 0.78843 v_acc: 0.82227 |  iteration: 6976 teacher: 0 stage: sketch lr: 0.000529\n",
      "batch 761 loss: 0.36089 acc: 0.89160 | v_loss: 0.55208 v_acc: 0.87142 |  iteration: 6977 teacher: 0 stage: sketch lr: 0.000529\n",
      "batch 762 loss: 0.38647 acc: 0.88835 | v_loss: 0.60420 v_acc: 0.85026 |  iteration: 6978 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 763 loss: 0.30880 acc: 0.90592 | v_loss: 0.70412 v_acc: 0.83431 |  iteration: 6979 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 764 loss: 0.39305 acc: 0.88379 | v_loss: 0.49871 v_acc: 0.86947 |  iteration: 6980 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 765 loss: 0.38112 acc: 0.89030 | v_loss: 0.56117 v_acc: 0.84993 |  iteration: 6981 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 766 loss: 0.31033 acc: 0.90592 | v_loss: 0.63676 v_acc: 0.84049 |  iteration: 6982 teacher: 0 stage: sketch lr: 0.000529\n",
      "batch 767 loss: 0.47889 acc: 0.87370 | v_loss: 0.80619 v_acc: 0.83105 |  iteration: 6983 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 768 loss: 0.39759 acc: 0.88770 | v_loss: 0.65508 v_acc: 0.84831 |  iteration: 6984 teacher: 0 stage: sketch lr: 0.000529\n",
      "batch 769 loss: 0.47903 acc: 0.87956 | v_loss: 0.88829 v_acc: 0.81771 |  iteration: 6985 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 770 loss: 0.59521 acc: 0.84993 | v_loss: 0.87424 v_acc: 0.80143 |  iteration: 6986 teacher: 0 stage: sketch lr: 0.000529\n",
      "batch 771 loss: 0.77375 acc: 0.80469 | v_loss: 0.89533 v_acc: 0.77539 |  iteration: 6987 teacher: 0 stage: sketch lr: 0.000529\n",
      "batch 772 loss: 0.77753 acc: 0.79720 | v_loss: 0.72470 v_acc: 0.81641 |  iteration: 6988 teacher: 0 stage: sketch lr: 0.000529\n",
      "batch 773 loss: 0.74448 acc: 0.80566 | v_loss: 0.92538 v_acc: 0.77311 |  iteration: 6989 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 774 loss: 0.74101 acc: 0.79850 | v_loss: 0.93623 v_acc: 0.77702 |  iteration: 6990 teacher: 0 stage: sketch lr: 0.000529\n",
      "batch 775 loss: 0.92202 acc: 0.76953 | v_loss: 0.88822 v_acc: 0.77051 |  iteration: 6991 teacher: 0 stage: sketch lr: 0.000529\n",
      "batch 776 loss: 0.93397 acc: 0.76237 | v_loss: 1.07943 v_acc: 0.73828 |  iteration: 6992 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 777 loss: 0.92798 acc: 0.76139 | v_loss: 1.01512 v_acc: 0.73307 |  iteration: 6993 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 778 loss: 1.09121 acc: 0.72493 | v_loss: 0.82735 v_acc: 0.75326 |  iteration: 6994 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 779 loss: 0.95688 acc: 0.74219 | v_loss: 0.94391 v_acc: 0.76042 |  iteration: 6995 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 780 loss: 1.16745 acc: 0.73112 | v_loss: 0.96061 v_acc: 0.76302 |  iteration: 6996 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 781 loss: 0.94838 acc: 0.75749 | v_loss: 1.03047 v_acc: 0.75293 |  iteration: 6997 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 782 loss: 1.02533 acc: 0.75293 | v_loss: 0.99424 v_acc: 0.73698 |  iteration: 6998 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 783 loss: 1.05733 acc: 0.72721 | v_loss: 0.85425 v_acc: 0.76562 |  iteration: 6999 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 784 loss: 0.94700 acc: 0.74772 | v_loss: 1.05100 v_acc: 0.72786 |  iteration: 7000 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 785 loss: 1.19114 acc: 0.72493 | v_loss: 1.17392 v_acc: 0.69889 |  iteration: 7001 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 786 loss: 1.29225 acc: 0.71712 | v_loss: 1.35110 v_acc: 0.68848 |  iteration: 7002 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 787 loss: 1.26123 acc: 0.71647 | v_loss: 2.05267 v_acc: 0.68945 |  iteration: 7003 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 788 loss: 2.22261 acc: 0.68197 | v_loss: 2.35743 v_acc: 0.68359 |  iteration: 7004 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 789 loss: 2.42872 acc: 0.67090 | v_loss: 1.93833 v_acc: 0.68229 |  iteration: 7005 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 790 loss: 2.11921 acc: 0.65918 | v_loss: 1.93977 v_acc: 0.57747 |  iteration: 7006 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 791 loss: 1.99072 acc: 0.62207 | v_loss: 2.01970 v_acc: 0.65918 |  iteration: 7007 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 792 loss: 1.95385 acc: 0.62240 | v_loss: 1.66207 v_acc: 0.70605 |  iteration: 7008 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 793 loss: 1.81746 acc: 0.69434 | v_loss: 2.00379 v_acc: 0.67741 |  iteration: 7009 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 794 loss: 1.97584 acc: 0.66569 | v_loss: 2.42698 v_acc: 0.60905 |  iteration: 7010 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 795 loss: 1.87422 acc: 0.66536 | v_loss: 1.97147 v_acc: 0.66113 |  iteration: 7011 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 796 loss: 1.77344 acc: 0.67188 | v_loss: 1.65906 v_acc: 0.70866 |  iteration: 7012 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 797 loss: 1.76256 acc: 0.68327 | v_loss: 1.70148 v_acc: 0.69499 |  iteration: 7013 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 798 loss: 1.75699 acc: 0.69466 | v_loss: 1.57170 v_acc: 0.71289 |  iteration: 7014 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 799 loss: 1.73759 acc: 0.69336 | v_loss: 1.71872 v_acc: 0.70020 |  iteration: 7015 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 800 loss: 1.70374 acc: 0.69434 | v_loss: 1.65125 v_acc: 0.70247 |  iteration: 7016 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 801 loss: 1.67148 acc: 0.70280 | v_loss: 1.57548 v_acc: 0.71061 |  iteration: 7017 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 802 loss: 1.67675 acc: 0.69499 | v_loss: 1.61571 v_acc: 0.71777 |  iteration: 7018 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 803 loss: 1.71731 acc: 0.70117 | v_loss: 1.60732 v_acc: 0.70866 |  iteration: 7019 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 804 loss: 1.59245 acc: 0.70703 | v_loss: 1.53714 v_acc: 0.71810 |  iteration: 7020 teacher: 1 stage: sketch lr: 0.000527\n",
      "batch 805 loss: 1.68759 acc: 0.69596 | v_loss: 1.52762 v_acc: 0.71419 |  iteration: 7021 teacher: 1 stage: sketch lr: 0.000527\n",
      "batch 806 loss: 1.59105 acc: 0.69759 | v_loss: 1.68419 v_acc: 0.68457 |  iteration: 7022 teacher: 1 stage: sketch lr: 0.000527\n",
      "batch 807 loss: 1.64389 acc: 0.69206 | v_loss: 1.53301 v_acc: 0.70964 |  iteration: 7023 teacher: 1 stage: sketch lr: 0.000527\n",
      "batch 808 loss: 1.60332 acc: 0.69727 | v_loss: 1.60769 v_acc: 0.70508 |  iteration: 7024 teacher: 1 stage: sketch lr: 0.000527\n",
      "batch 809 loss: 1.54703 acc: 0.70052 | v_loss: 1.55656 v_acc: 0.70898 |  iteration: 7025 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 810 loss: 1.59940 acc: 0.69596 | v_loss: 1.70329 v_acc: 0.69694 |  iteration: 7026 teacher: 1 stage: sketch lr: 0.000527\n",
      "batch 811 loss: 1.59256 acc: 0.69303 | v_loss: 1.54098 v_acc: 0.72103 |  iteration: 7027 teacher: 1 stage: sketch lr: 0.000527\n",
      "batch 812 loss: 1.69521 acc: 0.68457 | v_loss: 1.77873 v_acc: 0.69271 |  iteration: 7028 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 813 loss: 1.68136 acc: 0.69141 | v_loss: 1.54108 v_acc: 0.70052 |  iteration: 7029 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 814 loss: 1.75012 acc: 0.68913 | v_loss: 1.52094 v_acc: 0.70573 |  iteration: 7030 teacher: 1 stage: sketch lr: 0.000527\n",
      "batch 815 loss: 1.63886 acc: 0.69173 | v_loss: 1.57440 v_acc: 0.70280 |  iteration: 7031 teacher: 1 stage: sketch lr: 0.000527\n",
      "batch 816 loss: 1.79671 acc: 0.68034 | v_loss: 1.61291 v_acc: 0.70150 |  iteration: 7032 teacher: 1 stage: sketch lr: 0.000527\n",
      "batch 817 loss: 1.50363 acc: 0.70638 | v_loss: 1.67228 v_acc: 0.68848 |  iteration: 7033 teacher: 1 stage: sketch lr: 0.000527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 818 loss: 1.69432 acc: 0.69108 | v_loss: 1.63590 v_acc: 0.70410 |  iteration: 7034 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 819 loss: 1.65202 acc: 0.69434 | v_loss: 1.55727 v_acc: 0.69694 |  iteration: 7035 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 820 loss: 1.60373 acc: 0.70345 | v_loss: 1.57437 v_acc: 0.71061 |  iteration: 7036 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 821 loss: 1.59079 acc: 0.69954 | v_loss: 1.62780 v_acc: 0.70443 |  iteration: 7037 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 822 loss: 1.60013 acc: 0.70671 | v_loss: 1.43510 v_acc: 0.71875 |  iteration: 7038 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 823 loss: 1.62080 acc: 0.69564 | v_loss: 1.48582 v_acc: 0.72493 |  iteration: 7039 teacher: 1 stage: sketch lr: 0.000527\n",
      "batch 824 loss: 1.57758 acc: 0.70573 | v_loss: 1.43753 v_acc: 0.70671 |  iteration: 7040 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 825 loss: 1.57556 acc: 0.70020 | v_loss: 1.50192 v_acc: 0.70508 |  iteration: 7041 teacher: 1 stage: sketch lr: 0.000527\n",
      "batch 826 loss: 1.64114 acc: 0.69173 | v_loss: 1.67303 v_acc: 0.69336 |  iteration: 7042 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 827 loss: 1.53735 acc: 0.70540 | v_loss: 1.46159 v_acc: 0.71126 |  iteration: 7043 teacher: 1 stage: sketch lr: 0.000527\n",
      "batch 828 loss: 1.67160 acc: 0.69368 | v_loss: 1.51648 v_acc: 0.70443 |  iteration: 7044 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 829 loss: 1.63030 acc: 0.69401 | v_loss: 1.44920 v_acc: 0.69954 |  iteration: 7045 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 830 loss: 1.70736 acc: 0.68490 | v_loss: 1.41912 v_acc: 0.70215 |  iteration: 7046 teacher: 1 stage: sketch lr: 0.000526\n",
      "batch 831 loss: 1.69178 acc: 0.68197 | v_loss: 1.40013 v_acc: 0.74447 |  iteration: 7047 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 832 loss: 1.58071 acc: 0.70085 | v_loss: 1.44853 v_acc: 0.72070 |  iteration: 7048 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 833 loss: 1.56412 acc: 0.70182 | v_loss: 1.50404 v_acc: 0.73438 |  iteration: 7049 teacher: 1 stage: sketch lr: 0.000526\n",
      "batch 834 loss: 1.55831 acc: 0.69173 | v_loss: 1.44903 v_acc: 0.73145 |  iteration: 7050 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 835 loss: 1.72017 acc: 0.68685 | v_loss: 1.47225 v_acc: 0.71061 |  iteration: 7051 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 836 loss: 1.67111 acc: 0.69010 | v_loss: 1.49670 v_acc: 0.70931 |  iteration: 7052 teacher: 1 stage: sketch lr: 0.000526\n",
      "batch 837 loss: 1.66706 acc: 0.69466 | v_loss: 1.54685 v_acc: 0.72201 |  iteration: 7053 teacher: 1 stage: sketch lr: 0.000526\n",
      "batch 838 loss: 1.58890 acc: 0.70638 | v_loss: 1.62292 v_acc: 0.70312 |  iteration: 7054 teacher: 1 stage: sketch lr: 0.000526\n",
      "batch 839 loss: 1.60884 acc: 0.69954 | v_loss: 1.52256 v_acc: 0.71680 |  iteration: 7055 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 840 loss: 1.57239 acc: 0.69727 | v_loss: 1.31750 v_acc: 0.73926 |  iteration: 7056 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 841 loss: 1.49821 acc: 0.70931 | v_loss: 1.44562 v_acc: 0.70150 |  iteration: 7057 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 842 loss: 1.54714 acc: 0.70443 | v_loss: 1.65616 v_acc: 0.69596 |  iteration: 7058 teacher: 1 stage: sketch lr: 0.000526\n",
      "batch 843 loss: 1.66544 acc: 0.69303 | v_loss: 1.40622 v_acc: 0.70443 |  iteration: 7059 teacher: 1 stage: sketch lr: 0.000526\n",
      "batch 844 loss: 1.62953 acc: 0.69922 | v_loss: 1.48046 v_acc: 0.71322 |  iteration: 7060 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 845 loss: 1.63250 acc: 0.69596 | v_loss: 1.52551 v_acc: 0.69206 |  iteration: 7061 teacher: 1 stage: sketch lr: 0.000526\n",
      "batch 846 loss: 1.57024 acc: 0.69531 | v_loss: 1.45943 v_acc: 0.71549 |  iteration: 7062 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 847 loss: 1.62820 acc: 0.69499 | v_loss: 1.59811 v_acc: 0.69792 |  iteration: 7063 teacher: 1 stage: sketch lr: 0.000526\n",
      "batch 848 loss: 1.61049 acc: 0.69434 | v_loss: 1.54925 v_acc: 0.71419 |  iteration: 7064 teacher: 1 stage: sketch lr: 0.000526\n",
      "batch 849 loss: 1.63139 acc: 0.69499 | v_loss: 1.47959 v_acc: 0.72363 |  iteration: 7065 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 850 loss: 1.48517 acc: 0.70573 | v_loss: 1.54795 v_acc: 0.70085 |  iteration: 7066 teacher: 1 stage: sketch lr: 0.000526\n",
      "batch 851 loss: 1.58070 acc: 0.69759 | v_loss: 1.48531 v_acc: 0.70768 |  iteration: 7067 teacher: 1 stage: sketch lr: 0.000526\n",
      "batch 852 loss: 1.60789 acc: 0.69368 | v_loss: 1.42955 v_acc: 0.70117 |  iteration: 7068 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 853 loss: 1.54524 acc: 0.70117 | v_loss: 1.73191 v_acc: 0.68099 |  iteration: 7069 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 854 loss: 1.64963 acc: 0.69206 | v_loss: 1.45699 v_acc: 0.71452 |  iteration: 7070 teacher: 1 stage: sketch lr: 0.000526\n",
      "batch 855 loss: 1.59529 acc: 0.69141 | v_loss: 1.69123 v_acc: 0.68327 |  iteration: 7071 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 856 loss: 1.63072 acc: 0.69596 | v_loss: 1.65663 v_acc: 0.69466 |  iteration: 7072 teacher: 1 stage: sketch lr: 0.000526\n",
      "batch 857 loss: 1.67921 acc: 0.68522 | v_loss: 1.67322 v_acc: 0.68848 |  iteration: 7073 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 858 loss: 1.78318 acc: 0.68262 | v_loss: 1.56339 v_acc: 0.69531 |  iteration: 7074 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 859 loss: 1.65537 acc: 0.68880 | v_loss: 1.46777 v_acc: 0.69661 |  iteration: 7075 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 860 loss: 1.60720 acc: 0.69922 | v_loss: 1.52198 v_acc: 0.69173 |  iteration: 7076 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 861 loss: 1.57287 acc: 0.69531 | v_loss: 1.46404 v_acc: 0.71582 |  iteration: 7077 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 862 loss: 1.44856 acc: 0.71484 | v_loss: 1.71706 v_acc: 0.67480 |  iteration: 7078 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 863 loss: 1.51415 acc: 0.70671 | v_loss: 1.50090 v_acc: 0.71257 |  iteration: 7079 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 864 loss: 1.56196 acc: 0.69401 | v_loss: 1.45605 v_acc: 0.70508 |  iteration: 7080 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 865 loss: 1.53849 acc: 0.69857 | v_loss: 1.48872 v_acc: 0.70833 |  iteration: 7081 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 866 loss: 1.54265 acc: 0.70280 | v_loss: 1.39265 v_acc: 0.71191 |  iteration: 7082 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 867 loss: 1.49081 acc: 0.71094 | v_loss: 1.62308 v_acc: 0.70052 |  iteration: 7083 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 868 loss: 1.50141 acc: 0.70150 | v_loss: 1.55379 v_acc: 0.71549 |  iteration: 7084 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 869 loss: 1.57189 acc: 0.69303 | v_loss: 1.40856 v_acc: 0.71680 |  iteration: 7085 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 870 loss: 1.60026 acc: 0.69629 | v_loss: 1.35028 v_acc: 0.73047 |  iteration: 7086 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 871 loss: 1.68755 acc: 0.68783 | v_loss: 1.52073 v_acc: 0.71289 |  iteration: 7087 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 872 loss: 1.55702 acc: 0.69368 | v_loss: 1.55124 v_acc: 0.69629 |  iteration: 7088 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 873 loss: 1.58597 acc: 0.69108 | v_loss: 1.52967 v_acc: 0.70378 |  iteration: 7089 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 874 loss: 1.62201 acc: 0.68587 | v_loss: 1.38708 v_acc: 0.71615 |  iteration: 7090 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 875 loss: 1.55748 acc: 0.69531 | v_loss: 1.49322 v_acc: 0.72852 |  iteration: 7091 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 876 loss: 1.64147 acc: 0.69141 | v_loss: 1.66667 v_acc: 0.69824 |  iteration: 7092 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 877 loss: 1.56088 acc: 0.69401 | v_loss: 1.61259 v_acc: 0.71810 |  iteration: 7093 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 878 loss: 1.52558 acc: 0.70638 | v_loss: 1.38112 v_acc: 0.71680 |  iteration: 7094 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 879 loss: 1.63704 acc: 0.67806 | v_loss: 1.34171 v_acc: 0.73112 |  iteration: 7095 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 880 loss: 1.58584 acc: 0.70215 | v_loss: 1.36587 v_acc: 0.71452 |  iteration: 7096 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 881 loss: 1.64556 acc: 0.68262 | v_loss: 1.39026 v_acc: 0.69727 |  iteration: 7097 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 882 loss: 1.68724 acc: 0.68034 | v_loss: 1.56572 v_acc: 0.69531 |  iteration: 7098 teacher: 1 stage: sketch lr: 0.000525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 883 loss: 1.57366 acc: 0.68880 | v_loss: 1.41770 v_acc: 0.70671 |  iteration: 7099 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 884 loss: 1.57643 acc: 0.70540 | v_loss: 1.67758 v_acc: 0.68848 |  iteration: 7100 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 885 loss: 1.51877 acc: 0.70801 | v_loss: 1.80399 v_acc: 0.68913 |  iteration: 7101 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 886 loss: 1.56069 acc: 0.69564 | v_loss: 1.66206 v_acc: 0.69531 |  iteration: 7102 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 887 loss: 1.54330 acc: 0.70020 | v_loss: 1.46024 v_acc: 0.72298 |  iteration: 7103 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 888 loss: 1.47523 acc: 0.70964 | v_loss: 1.52133 v_acc: 0.70573 |  iteration: 7104 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 889 loss: 1.54890 acc: 0.70280 | v_loss: 1.38328 v_acc: 0.71842 |  iteration: 7105 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 890 loss: 1.68520 acc: 0.69499 | v_loss: 1.55894 v_acc: 0.70085 |  iteration: 7106 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 891 loss: 1.63729 acc: 0.69043 | v_loss: 1.47861 v_acc: 0.71354 |  iteration: 7107 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 892 loss: 1.47604 acc: 0.70931 | v_loss: 1.47980 v_acc: 0.72559 |  iteration: 7108 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 893 loss: 1.63442 acc: 0.68880 | v_loss: 1.48016 v_acc: 0.71484 |  iteration: 7109 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 894 loss: 1.51387 acc: 0.70117 | v_loss: 1.48780 v_acc: 0.71126 |  iteration: 7110 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 895 loss: 1.62356 acc: 0.69368 | v_loss: 1.40603 v_acc: 0.72461 |  iteration: 7111 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 896 loss: 1.75594 acc: 0.68001 | v_loss: 1.41715 v_acc: 0.71712 |  iteration: 7112 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 897 loss: 1.72284 acc: 0.68620 | v_loss: 1.48769 v_acc: 0.69076 |  iteration: 7113 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 898 loss: 1.51499 acc: 0.70443 | v_loss: 1.50886 v_acc: 0.71126 |  iteration: 7114 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 899 loss: 1.58207 acc: 0.69727 | v_loss: 1.43754 v_acc: 0.71842 |  iteration: 7115 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 900 loss: 1.57844 acc: 0.69987 | v_loss: 1.41152 v_acc: 0.71484 |  iteration: 7116 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 901 loss: 1.51995 acc: 0.70312 | v_loss: 1.57745 v_acc: 0.70540 |  iteration: 7117 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 902 loss: 1.47907 acc: 0.70312 | v_loss: 1.41820 v_acc: 0.72917 |  iteration: 7118 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 903 loss: 1.55492 acc: 0.69857 | v_loss: 1.63460 v_acc: 0.70931 |  iteration: 7119 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 904 loss: 1.56906 acc: 0.69076 | v_loss: 1.42916 v_acc: 0.69987 |  iteration: 7120 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 905 loss: 1.52606 acc: 0.69661 | v_loss: 1.37221 v_acc: 0.70378 |  iteration: 7121 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 906 loss: 1.53925 acc: 0.69336 | v_loss: 1.51991 v_acc: 0.70280 |  iteration: 7122 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 907 loss: 1.47672 acc: 0.69792 | v_loss: 1.57824 v_acc: 0.69727 |  iteration: 7123 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 908 loss: 1.35197 acc: 0.71029 | v_loss: 1.66415 v_acc: 0.69401 |  iteration: 7124 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 909 loss: 1.57349 acc: 0.69076 | v_loss: 1.57154 v_acc: 0.70931 |  iteration: 7125 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 910 loss: 1.55307 acc: 0.69401 | v_loss: 1.49441 v_acc: 0.69889 |  iteration: 7126 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 911 loss: 1.56852 acc: 0.69108 | v_loss: 1.52370 v_acc: 0.71094 |  iteration: 7127 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 912 loss: 1.50021 acc: 0.69954 | v_loss: 1.52250 v_acc: 0.70443 |  iteration: 7128 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 913 loss: 1.57713 acc: 0.69401 | v_loss: 1.34757 v_acc: 0.71777 |  iteration: 7129 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 914 loss: 1.51638 acc: 0.69336 | v_loss: 1.44598 v_acc: 0.72363 |  iteration: 7130 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 915 loss: 1.46930 acc: 0.70768 | v_loss: 1.29256 v_acc: 0.70768 |  iteration: 7131 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 916 loss: 1.52506 acc: 0.70638 | v_loss: 1.42550 v_acc: 0.70573 |  iteration: 7132 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 917 loss: 1.61822 acc: 0.69238 | v_loss: 1.59813 v_acc: 0.69987 |  iteration: 7133 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 918 loss: 1.58858 acc: 0.69466 | v_loss: 1.44334 v_acc: 0.70866 |  iteration: 7134 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 919 loss: 1.45269 acc: 0.70378 | v_loss: 1.50320 v_acc: 0.70312 |  iteration: 7135 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 920 loss: 1.59977 acc: 0.68457 | v_loss: 1.34847 v_acc: 0.71615 |  iteration: 7136 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 921 loss: 1.55757 acc: 0.69499 | v_loss: 1.34587 v_acc: 0.70508 |  iteration: 7137 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 922 loss: 1.51056 acc: 0.69694 | v_loss: 1.38301 v_acc: 0.73372 |  iteration: 7138 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 923 loss: 1.45831 acc: 0.69531 | v_loss: 1.36256 v_acc: 0.71419 |  iteration: 7139 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 924 loss: 1.52004 acc: 0.69303 | v_loss: 1.48437 v_acc: 0.70410 |  iteration: 7140 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 925 loss: 1.65591 acc: 0.68555 | v_loss: 1.37664 v_acc: 0.72103 |  iteration: 7141 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 926 loss: 1.54247 acc: 0.69629 | v_loss: 1.41115 v_acc: 0.71517 |  iteration: 7142 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 927 loss: 1.49060 acc: 0.69792 | v_loss: 1.46826 v_acc: 0.71029 |  iteration: 7143 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 928 loss: 1.52271 acc: 0.69987 | v_loss: 1.52879 v_acc: 0.72103 |  iteration: 7144 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 929 loss: 1.46279 acc: 0.70247 | v_loss: 1.58507 v_acc: 0.70020 |  iteration: 7145 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 930 loss: 1.46935 acc: 0.70020 | v_loss: 1.51126 v_acc: 0.71615 |  iteration: 7146 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 931 loss: 1.58162 acc: 0.69499 | v_loss: 1.27212 v_acc: 0.74089 |  iteration: 7147 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 932 loss: 1.52708 acc: 0.69727 | v_loss: 1.36553 v_acc: 0.71322 |  iteration: 7148 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 933 loss: 1.46540 acc: 0.70085 | v_loss: 1.63002 v_acc: 0.69987 |  iteration: 7149 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 934 loss: 1.58830 acc: 0.69141 | v_loss: 1.31442 v_acc: 0.70768 |  iteration: 7150 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 935 loss: 1.63133 acc: 0.69694 | v_loss: 1.43109 v_acc: 0.71224 |  iteration: 7151 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 936 loss: 1.49815 acc: 0.70378 | v_loss: 1.47210 v_acc: 0.69010 |  iteration: 7152 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 937 loss: 1.68761 acc: 0.68392 | v_loss: 1.38321 v_acc: 0.71549 |  iteration: 7153 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 938 loss: 1.61248 acc: 0.68913 | v_loss: 1.52759 v_acc: 0.70215 |  iteration: 7154 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 939 loss: 1.47815 acc: 0.70247 | v_loss: 1.52087 v_acc: 0.72656 |  iteration: 7155 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 940 loss: 1.58015 acc: 0.69499 | v_loss: 1.42618 v_acc: 0.72786 |  iteration: 7156 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 941 loss: 1.56031 acc: 0.69629 | v_loss: 1.50983 v_acc: 0.70085 |  iteration: 7157 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 942 loss: 1.57495 acc: 0.69661 | v_loss: 1.45975 v_acc: 0.69108 |  iteration: 7158 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 943 loss: 1.44087 acc: 0.70508 | v_loss: 1.40065 v_acc: 0.70443 |  iteration: 7159 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 944 loss: 1.69810 acc: 0.68750 | v_loss: 1.71526 v_acc: 0.67969 |  iteration: 7160 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 945 loss: 1.50516 acc: 0.70312 | v_loss: 1.42186 v_acc: 0.72038 |  iteration: 7161 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 946 loss: 1.56465 acc: 0.70150 | v_loss: 1.65953 v_acc: 0.67708 |  iteration: 7162 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 947 loss: 1.56620 acc: 0.70247 | v_loss: 1.57194 v_acc: 0.69857 |  iteration: 7163 teacher: 1 stage: sketch lr: 0.000522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 948 loss: 1.49508 acc: 0.70475 | v_loss: 1.63735 v_acc: 0.68978 |  iteration: 7164 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 949 loss: 1.51489 acc: 0.70475 | v_loss: 1.50556 v_acc: 0.69922 |  iteration: 7165 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 950 loss: 1.54485 acc: 0.70443 | v_loss: 1.44186 v_acc: 0.70540 |  iteration: 7166 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 951 loss: 1.56165 acc: 0.69792 | v_loss: 1.47124 v_acc: 0.70280 |  iteration: 7167 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 952 loss: 1.58349 acc: 0.69434 | v_loss: 1.44371 v_acc: 0.71777 |  iteration: 7168 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 953 loss: 1.55550 acc: 0.69531 | v_loss: 1.64023 v_acc: 0.69303 |  iteration: 7169 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 954 loss: 1.53875 acc: 0.69759 | v_loss: 1.47659 v_acc: 0.70247 |  iteration: 7170 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 955 loss: 1.51735 acc: 0.70150 | v_loss: 1.44876 v_acc: 0.71517 |  iteration: 7171 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 956 loss: 1.53148 acc: 0.70020 | v_loss: 1.44608 v_acc: 0.71289 |  iteration: 7172 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 957 loss: 1.59473 acc: 0.69629 | v_loss: 1.37249 v_acc: 0.70150 |  iteration: 7173 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 958 loss: 1.53539 acc: 0.69922 | v_loss: 1.60844 v_acc: 0.69564 |  iteration: 7174 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 959 loss: 1.55435 acc: 0.69694 | v_loss: 1.53881 v_acc: 0.70833 |  iteration: 7175 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 960 loss: 1.53906 acc: 0.70215 | v_loss: 1.36765 v_acc: 0.72168 |  iteration: 7176 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 961 loss: 1.52509 acc: 0.68750 | v_loss: 1.32826 v_acc: 0.72396 |  iteration: 7177 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 962 loss: 1.52037 acc: 0.69922 | v_loss: 1.49183 v_acc: 0.71712 |  iteration: 7178 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 963 loss: 1.71376 acc: 0.68815 | v_loss: 1.49075 v_acc: 0.70475 |  iteration: 7179 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 964 loss: 1.56036 acc: 0.70540 | v_loss: 1.48634 v_acc: 0.70736 |  iteration: 7180 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 965 loss: 1.63502 acc: 0.69792 | v_loss: 1.34186 v_acc: 0.72493 |  iteration: 7181 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 966 loss: 1.47558 acc: 0.70736 | v_loss: 1.43920 v_acc: 0.72949 |  iteration: 7182 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 967 loss: 1.60162 acc: 0.69987 | v_loss: 1.57760 v_acc: 0.69368 |  iteration: 7183 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 968 loss: 1.53647 acc: 0.69727 | v_loss: 1.49925 v_acc: 0.71810 |  iteration: 7184 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 969 loss: 1.62140 acc: 0.69206 | v_loss: 1.36772 v_acc: 0.71680 |  iteration: 7185 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 970 loss: 1.51068 acc: 0.69434 | v_loss: 1.30924 v_acc: 0.73991 |  iteration: 7186 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 971 loss: 1.49536 acc: 0.70475 | v_loss: 1.31780 v_acc: 0.72038 |  iteration: 7187 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 972 loss: 1.49699 acc: 0.70703 | v_loss: 1.32785 v_acc: 0.70443 |  iteration: 7188 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 973 loss: 1.54325 acc: 0.69759 | v_loss: 1.50604 v_acc: 0.70117 |  iteration: 7189 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 974 loss: 1.54468 acc: 0.69401 | v_loss: 1.40317 v_acc: 0.70410 |  iteration: 7190 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 975 loss: 1.68364 acc: 0.68262 | v_loss: 1.61432 v_acc: 0.70215 |  iteration: 7191 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 976 loss: 1.49916 acc: 0.69043 | v_loss: 1.76157 v_acc: 0.69173 |  iteration: 7192 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 977 loss: 1.56898 acc: 0.69466 | v_loss: 1.62162 v_acc: 0.70052 |  iteration: 7193 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 978 loss: 1.60519 acc: 0.69238 | v_loss: 1.40607 v_acc: 0.72298 |  iteration: 7194 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 979 loss: 1.57468 acc: 0.69141 | v_loss: 1.48082 v_acc: 0.70247 |  iteration: 7195 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 980 loss: 1.50965 acc: 0.68750 | v_loss: 1.33351 v_acc: 0.71842 |  iteration: 7196 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 981 loss: 1.51136 acc: 0.69922 | v_loss: 1.53827 v_acc: 0.70378 |  iteration: 7197 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 982 loss: 1.47897 acc: 0.70247 | v_loss: 1.46006 v_acc: 0.71810 |  iteration: 7198 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 983 loss: 1.42729 acc: 0.70508 | v_loss: 1.45968 v_acc: 0.73014 |  iteration: 7199 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 984 loss: 1.49079 acc: 0.70410 | v_loss: 1.49264 v_acc: 0.71973 |  iteration: 7200 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 985 loss: 1.41913 acc: 0.70247 | v_loss: 1.47589 v_acc: 0.70996 |  iteration: 7201 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 986 loss: 1.48061 acc: 0.69434 | v_loss: 1.36831 v_acc: 0.72526 |  iteration: 7202 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 987 loss: 1.55986 acc: 0.69596 | v_loss: 1.37874 v_acc: 0.71777 |  iteration: 7203 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 988 loss: 1.47904 acc: 0.69661 | v_loss: 1.47778 v_acc: 0.68783 |  iteration: 7204 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 989 loss: 1.56696 acc: 0.68717 | v_loss: 1.43954 v_acc: 0.71224 |  iteration: 7205 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 990 loss: 1.59138 acc: 0.68880 | v_loss: 1.39932 v_acc: 0.71973 |  iteration: 7206 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 991 loss: 1.47780 acc: 0.70443 | v_loss: 1.37545 v_acc: 0.70898 |  iteration: 7207 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 992 loss: 1.47533 acc: 0.70508 | v_loss: 1.56713 v_acc: 0.70671 |  iteration: 7208 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 993 loss: 1.50229 acc: 0.70345 | v_loss: 1.42352 v_acc: 0.73210 |  iteration: 7209 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 994 loss: 1.56349 acc: 0.70085 | v_loss: 1.61822 v_acc: 0.71647 |  iteration: 7210 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 995 loss: 1.48565 acc: 0.70768 | v_loss: 1.45341 v_acc: 0.70150 |  iteration: 7211 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 996 loss: 1.49721 acc: 0.70801 | v_loss: 1.40510 v_acc: 0.70247 |  iteration: 7212 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 997 loss: 1.53944 acc: 0.69792 | v_loss: 1.50850 v_acc: 0.70573 |  iteration: 7213 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 998 loss: 1.55806 acc: 0.69954 | v_loss: 1.54201 v_acc: 0.70573 |  iteration: 7214 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 999 loss: 1.49052 acc: 0.69954 | v_loss: 1.62913 v_acc: 0.69043 |  iteration: 7215 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 1000 loss: 1.52253 acc: 0.69824 | v_loss: 1.56088 v_acc: 0.70540 |  iteration: 7216 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 1001 loss: 1.56764 acc: 0.69010 | v_loss: 1.48554 v_acc: 0.69824 |  iteration: 7217 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 1002 loss: 1.45310 acc: 0.69922 | v_loss: 1.51142 v_acc: 0.70736 |  iteration: 7218 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 1003 loss: 1.45696 acc: 0.70540 | v_loss: 1.49515 v_acc: 0.70833 |  iteration: 7219 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 1004 loss: 1.50053 acc: 0.70312 | v_loss: 1.32224 v_acc: 0.71647 |  iteration: 7220 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 1005 loss: 1.48878 acc: 0.69759 | v_loss: 1.42545 v_acc: 0.72396 |  iteration: 7221 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 1006 loss: 1.41115 acc: 0.69857 | v_loss: 1.22771 v_acc: 0.71126 |  iteration: 7222 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 1007 loss: 1.48890 acc: 0.69629 | v_loss: 1.38895 v_acc: 0.70801 |  iteration: 7223 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 1008 loss: 1.47493 acc: 0.70378 | v_loss: 1.60169 v_acc: 0.69076 |  iteration: 7224 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 1009 loss: 1.52642 acc: 0.70150 | v_loss: 1.38965 v_acc: 0.71126 |  iteration: 7225 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 1010 loss: 1.46291 acc: 0.72201 | v_loss: 1.49106 v_acc: 0.70443 |  iteration: 7226 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 1011 loss: 1.47846 acc: 0.70833 | v_loss: 1.33248 v_acc: 0.71419 |  iteration: 7227 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 1012 loss: 1.58772 acc: 0.70052 | v_loss: 1.35667 v_acc: 0.70703 |  iteration: 7228 teacher: 0 stage: sketch lr: 0.000520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1013 loss: 1.50644 acc: 0.70801 | v_loss: 1.36435 v_acc: 0.73405 |  iteration: 7229 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 1014 loss: 1.66329 acc: 0.69727 | v_loss: 1.38524 v_acc: 0.71647 |  iteration: 7230 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 1015 loss: 1.55135 acc: 0.70020 | v_loss: 1.47768 v_acc: 0.73438 |  iteration: 7231 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 1016 loss: 1.52400 acc: 0.69466 | v_loss: 1.37468 v_acc: 0.72331 |  iteration: 7232 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 1017 loss: 1.49992 acc: 0.70345 | v_loss: 1.40217 v_acc: 0.71061 |  iteration: 7233 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 1018 loss: 1.57547 acc: 0.69661 | v_loss: 1.46111 v_acc: 0.70931 |  iteration: 7234 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 1019 loss: 1.41557 acc: 0.71159 | v_loss: 1.51118 v_acc: 0.72201 |  iteration: 7235 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 1020 loss: 1.44002 acc: 0.71680 | v_loss: 1.56015 v_acc: 0.70312 |  iteration: 7236 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 1021 loss: 1.51404 acc: 0.69792 | v_loss: 1.50878 v_acc: 0.71419 |  iteration: 7237 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 1022 loss: 1.68144 acc: 0.68978 | v_loss: 1.26155 v_acc: 0.74219 |  iteration: 7238 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 1023 loss: 1.51948 acc: 0.70247 | v_loss: 1.30455 v_acc: 0.70605 |  iteration: 7239 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1024 loss: 1.43825 acc: 0.69596 | v_loss: 1.63150 v_acc: 0.68815 |  iteration: 7240 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1025 loss: 1.43380 acc: 0.69792 | v_loss: 1.28170 v_acc: 0.70964 |  iteration: 7241 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1026 loss: 1.48510 acc: 0.70247 | v_loss: 1.41879 v_acc: 0.71126 |  iteration: 7242 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1027 loss: 1.41281 acc: 0.70150 | v_loss: 1.44684 v_acc: 0.69076 |  iteration: 7243 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 1028 loss: 1.58509 acc: 0.69401 | v_loss: 1.34754 v_acc: 0.71777 |  iteration: 7244 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1029 loss: 1.44257 acc: 0.70801 | v_loss: 1.48245 v_acc: 0.69824 |  iteration: 7245 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 1030 loss: 1.52731 acc: 0.69694 | v_loss: 1.52277 v_acc: 0.72070 |  iteration: 7246 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1031 loss: 1.45574 acc: 0.69889 | v_loss: 1.42587 v_acc: 0.72559 |  iteration: 7247 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 1032 loss: 1.56557 acc: 0.69889 | v_loss: 1.49094 v_acc: 0.69857 |  iteration: 7248 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 1033 loss: 1.53737 acc: 0.69727 | v_loss: 1.48770 v_acc: 0.69076 |  iteration: 7249 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 1034 loss: 1.67796 acc: 0.68294 | v_loss: 1.38179 v_acc: 0.70410 |  iteration: 7250 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 1035 loss: 1.53844 acc: 0.68913 | v_loss: 1.72039 v_acc: 0.67969 |  iteration: 7251 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 1036 loss: 1.48167 acc: 0.70996 | v_loss: 1.42162 v_acc: 0.72038 |  iteration: 7252 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1037 loss: 1.49688 acc: 0.69531 | v_loss: 1.66091 v_acc: 0.67383 |  iteration: 7253 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1038 loss: 1.51312 acc: 0.69694 | v_loss: 1.56750 v_acc: 0.69368 |  iteration: 7254 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1039 loss: 1.48675 acc: 0.70443 | v_loss: 1.64477 v_acc: 0.69531 |  iteration: 7255 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1040 loss: 1.46733 acc: 0.70410 | v_loss: 1.45405 v_acc: 0.69792 |  iteration: 7256 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1041 loss: 1.49213 acc: 0.70215 | v_loss: 1.41895 v_acc: 0.70573 |  iteration: 7257 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 1042 loss: 1.54642 acc: 0.69792 | v_loss: 1.41495 v_acc: 0.70280 |  iteration: 7258 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 1043 loss: 1.54357 acc: 0.69564 | v_loss: 1.41906 v_acc: 0.72038 |  iteration: 7259 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 1044 loss: 1.42917 acc: 0.71126 | v_loss: 1.64516 v_acc: 0.68978 |  iteration: 7260 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 1045 loss: 1.64162 acc: 0.69271 | v_loss: 1.46466 v_acc: 0.71257 |  iteration: 7261 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 1046 loss: 1.50219 acc: 0.70085 | v_loss: 1.40948 v_acc: 0.70736 |  iteration: 7262 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1047 loss: 1.55523 acc: 0.69336 | v_loss: 1.43413 v_acc: 0.70833 |  iteration: 7263 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1048 loss: 1.52973 acc: 0.70247 | v_loss: 1.36362 v_acc: 0.70117 |  iteration: 7264 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1049 loss: 1.51140 acc: 0.70703 | v_loss: 1.57456 v_acc: 0.69368 |  iteration: 7265 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1050 loss: 1.49024 acc: 0.70410 | v_loss: 1.52417 v_acc: 0.71126 |  iteration: 7266 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1051 loss: 1.58859 acc: 0.69466 | v_loss: 1.36099 v_acc: 0.71191 |  iteration: 7267 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1052 loss: 1.58935 acc: 0.69401 | v_loss: 1.33664 v_acc: 0.72168 |  iteration: 7268 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1053 loss: 1.61171 acc: 0.69401 | v_loss: 1.50075 v_acc: 0.71191 |  iteration: 7269 teacher: 0 stage: sketch lr: 0.000518\n",
      "batch 1054 loss: 1.59738 acc: 0.69694 | v_loss: 1.50743 v_acc: 0.69759 |  iteration: 7270 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1055 loss: 1.55214 acc: 0.70410 | v_loss: 1.49157 v_acc: 0.70540 |  iteration: 7271 teacher: 0 stage: sketch lr: 0.000518\n",
      "batch 1056 loss: 1.62261 acc: 0.69661 | v_loss: 1.34352 v_acc: 0.71419 |  iteration: 7272 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1057 loss: 1.63174 acc: 0.69759 | v_loss: 1.43652 v_acc: 0.72819 |  iteration: 7273 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1058 loss: 1.49956 acc: 0.69987 | v_loss: 1.59335 v_acc: 0.69759 |  iteration: 7274 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1059 loss: 1.55590 acc: 0.69271 | v_loss: 1.50248 v_acc: 0.71842 |  iteration: 7275 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1060 loss: 1.49829 acc: 0.70085 | v_loss: 1.33905 v_acc: 0.71712 |  iteration: 7276 teacher: 0 stage: sketch lr: 0.000518\n",
      "batch 1061 loss: 1.52005 acc: 0.70085 | v_loss: 1.29636 v_acc: 0.72786 |  iteration: 7277 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1062 loss: 1.43590 acc: 0.69531 | v_loss: 1.32446 v_acc: 0.72298 |  iteration: 7278 teacher: 0 stage: sketch lr: 0.000518\n",
      "batch 1063 loss: 1.56212 acc: 0.69206 | v_loss: 1.34282 v_acc: 0.70280 |  iteration: 7279 teacher: 0 stage: sketch lr: 0.000518\n",
      "batch 1064 loss: 1.52073 acc: 0.69857 | v_loss: 1.53140 v_acc: 0.70540 |  iteration: 7280 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1065 loss: 1.45416 acc: 0.69661 | v_loss: 1.34513 v_acc: 0.71908 |  iteration: 7281 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1066 loss: 1.59082 acc: 0.69368 | v_loss: 1.60670 v_acc: 0.68815 |  iteration: 7282 teacher: 0 stage: sketch lr: 0.000518\n",
      "batch 1067 loss: 1.46417 acc: 0.69499 | v_loss: 1.79953 v_acc: 0.68848 |  iteration: 7283 teacher: 0 stage: sketch lr: 0.000518\n",
      "batch 1068 loss: 1.44890 acc: 0.70540 | v_loss: 1.62268 v_acc: 0.69336 |  iteration: 7284 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1069 loss: 1.50507 acc: 0.69499 | v_loss: 1.38468 v_acc: 0.72331 |  iteration: 7285 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1070 loss: 1.53893 acc: 0.69141 | v_loss: 1.45342 v_acc: 0.70768 |  iteration: 7286 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1071 loss: 1.55678 acc: 0.69010 | v_loss: 1.32340 v_acc: 0.71582 |  iteration: 7287 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1072 loss: 1.44094 acc: 0.69954 | v_loss: 1.53272 v_acc: 0.70085 |  iteration: 7288 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1073 loss: 1.53292 acc: 0.69564 | v_loss: 1.43746 v_acc: 0.71745 |  iteration: 7289 teacher: 0 stage: sketch lr: 0.000518\n",
      "batch 1074 loss: 1.56997 acc: 0.69596 | v_loss: 1.44392 v_acc: 0.72884 |  iteration: 7290 teacher: 0 stage: sketch lr: 0.000518\n",
      "batch 1075 loss: 1.62684 acc: 0.69922 | v_loss: 1.46492 v_acc: 0.71875 |  iteration: 7291 teacher: 0 stage: sketch lr: 0.000518\n",
      "batch 1076 loss: 1.51091 acc: 0.70182 | v_loss: 1.46233 v_acc: 0.70345 |  iteration: 7292 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1077 loss: 1.44016 acc: 0.70768 | v_loss: 1.38927 v_acc: 0.72233 |  iteration: 7293 teacher: 1 stage: sketch lr: 0.000518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1078 loss: 1.50010 acc: 0.70410 | v_loss: 1.39398 v_acc: 0.71712 |  iteration: 7294 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1079 loss: 1.45145 acc: 0.69889 | v_loss: 1.50280 v_acc: 0.69043 |  iteration: 7295 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1080 loss: 1.59308 acc: 0.69010 | v_loss: 1.43703 v_acc: 0.70833 |  iteration: 7296 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1081 loss: 1.50208 acc: 0.70508 | v_loss: 1.38131 v_acc: 0.71810 |  iteration: 7297 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1082 loss: 1.47408 acc: 0.70638 | v_loss: 1.37783 v_acc: 0.71452 |  iteration: 7298 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 1083 loss: 1.46712 acc: 0.70671 | v_loss: 1.54741 v_acc: 0.70605 |  iteration: 7299 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1084 loss: 1.56689 acc: 0.70540 | v_loss: 1.40215 v_acc: 0.73145 |  iteration: 7300 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1085 loss: 1.55231 acc: 0.70345 | v_loss: 1.60978 v_acc: 0.71549 |  iteration: 7301 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1086 loss: 1.49771 acc: 0.70182 | v_loss: 1.42517 v_acc: 0.69824 |  iteration: 7302 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1087 loss: 1.49772 acc: 0.69336 | v_loss: 1.37588 v_acc: 0.69792 |  iteration: 7303 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 1088 loss: 1.49272 acc: 0.70443 | v_loss: 1.49278 v_acc: 0.70638 |  iteration: 7304 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1089 loss: 1.58981 acc: 0.68424 | v_loss: 1.54620 v_acc: 0.70312 |  iteration: 7305 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 1090 loss: 1.63696 acc: 0.69303 | v_loss: 1.64820 v_acc: 0.68522 |  iteration: 7306 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1091 loss: 1.49236 acc: 0.69727 | v_loss: 1.54339 v_acc: 0.70931 |  iteration: 7307 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1092 loss: 1.59444 acc: 0.68620 | v_loss: 1.48521 v_acc: 0.69889 |  iteration: 7308 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 1093 loss: 1.48481 acc: 0.70247 | v_loss: 1.50101 v_acc: 0.71094 |  iteration: 7309 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 1094 loss: 1.56986 acc: 0.69857 | v_loss: 1.48206 v_acc: 0.70605 |  iteration: 7310 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1095 loss: 1.45356 acc: 0.70150 | v_loss: 1.31528 v_acc: 0.71973 |  iteration: 7311 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 1096 loss: 1.51405 acc: 0.69987 | v_loss: 1.41100 v_acc: 0.72526 |  iteration: 7312 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 1097 loss: 1.46380 acc: 0.71159 | v_loss: 1.24224 v_acc: 0.71712 |  iteration: 7313 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 1098 loss: 1.55694 acc: 0.70312 | v_loss: 1.38246 v_acc: 0.71061 |  iteration: 7314 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1099 loss: 1.56980 acc: 0.69368 | v_loss: 1.57921 v_acc: 0.69564 |  iteration: 7315 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 1100 loss: 1.43265 acc: 0.70508 | v_loss: 1.39866 v_acc: 0.71387 |  iteration: 7316 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1101 loss: 1.53273 acc: 0.70020 | v_loss: 1.46773 v_acc: 0.70768 |  iteration: 7317 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1102 loss: 1.58994 acc: 0.69954 | v_loss: 1.31475 v_acc: 0.71484 |  iteration: 7318 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1103 loss: 1.41250 acc: 0.71322 | v_loss: 1.34472 v_acc: 0.70703 |  iteration: 7319 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 1104 loss: 1.53708 acc: 0.69661 | v_loss: 1.35382 v_acc: 0.73405 |  iteration: 7320 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1105 loss: 1.45960 acc: 0.70378 | v_loss: 1.35350 v_acc: 0.71615 |  iteration: 7321 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 1106 loss: 1.55270 acc: 0.69694 | v_loss: 1.42269 v_acc: 0.73665 |  iteration: 7322 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1107 loss: 1.64621 acc: 0.68783 | v_loss: 1.35791 v_acc: 0.71419 |  iteration: 7323 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1108 loss: 1.49090 acc: 0.70182 | v_loss: 1.41871 v_acc: 0.71484 |  iteration: 7324 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1109 loss: 1.54047 acc: 0.69922 | v_loss: 1.46929 v_acc: 0.71289 |  iteration: 7325 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 1110 loss: 1.53119 acc: 0.69661 | v_loss: 1.49917 v_acc: 0.71875 |  iteration: 7326 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1111 loss: 1.53762 acc: 0.70410 | v_loss: 1.54625 v_acc: 0.69922 |  iteration: 7327 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1112 loss: 1.44919 acc: 0.71126 | v_loss: 1.48247 v_acc: 0.71745 |  iteration: 7328 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 1113 loss: 1.52960 acc: 0.70703 | v_loss: 1.25966 v_acc: 0.74284 |  iteration: 7329 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1114 loss: 1.50641 acc: 0.70638 | v_loss: 1.35343 v_acc: 0.70671 |  iteration: 7330 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1115 loss: 1.53329 acc: 0.70443 | v_loss: 1.59837 v_acc: 0.70020 |  iteration: 7331 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1116 loss: 1.57352 acc: 0.69271 | v_loss: 1.30425 v_acc: 0.71452 |  iteration: 7332 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 1117 loss: 1.58618 acc: 0.69336 | v_loss: 1.41778 v_acc: 0.71094 |  iteration: 7333 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 1118 loss: 1.44988 acc: 0.70280 | v_loss: 1.42684 v_acc: 0.69661 |  iteration: 7334 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1119 loss: 1.49968 acc: 0.69141 | v_loss: 1.32545 v_acc: 0.71191 |  iteration: 7335 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1120 loss: 1.55262 acc: 0.69368 | v_loss: 1.43038 v_acc: 0.69564 |  iteration: 7336 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1121 loss: 1.71431 acc: 0.68359 | v_loss: 1.56423 v_acc: 0.71582 |  iteration: 7337 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 1122 loss: 1.68176 acc: 0.68848 | v_loss: 1.40478 v_acc: 0.72233 |  iteration: 7338 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 1123 loss: 1.63578 acc: 0.69108 | v_loss: 1.50205 v_acc: 0.69889 |  iteration: 7339 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1124 loss: 1.43440 acc: 0.70898 | v_loss: 1.46007 v_acc: 0.69043 |  iteration: 7340 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1125 loss: 1.59632 acc: 0.68620 | v_loss: 1.41035 v_acc: 0.70833 |  iteration: 7341 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 1126 loss: 1.48744 acc: 0.70508 | v_loss: 1.64404 v_acc: 0.68848 |  iteration: 7342 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 1127 loss: 1.60508 acc: 0.69401 | v_loss: 1.40598 v_acc: 0.72103 |  iteration: 7343 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1128 loss: 1.53193 acc: 0.69499 | v_loss: 1.64092 v_acc: 0.68620 |  iteration: 7344 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 1129 loss: 1.57461 acc: 0.70182 | v_loss: 1.53440 v_acc: 0.69987 |  iteration: 7345 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1130 loss: 1.61693 acc: 0.69434 | v_loss: 1.60542 v_acc: 0.68815 |  iteration: 7346 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 1131 loss: 1.47788 acc: 0.69629 | v_loss: 1.47181 v_acc: 0.69531 |  iteration: 7347 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1132 loss: 1.39241 acc: 0.71517 | v_loss: 1.44383 v_acc: 0.70638 |  iteration: 7348 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 1133 loss: 1.49471 acc: 0.69271 | v_loss: 1.41464 v_acc: 0.70833 |  iteration: 7349 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 1134 loss: 1.50953 acc: 0.69857 | v_loss: 1.43505 v_acc: 0.72656 |  iteration: 7350 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1135 loss: 1.52973 acc: 0.69206 | v_loss: 1.64296 v_acc: 0.68587 |  iteration: 7351 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 1136 loss: 1.52719 acc: 0.69531 | v_loss: 1.44228 v_acc: 0.71387 |  iteration: 7352 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1137 loss: 1.54033 acc: 0.69271 | v_loss: 1.41743 v_acc: 0.70573 |  iteration: 7353 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 1138 loss: 1.59537 acc: 0.68848 | v_loss: 1.43756 v_acc: 0.70736 |  iteration: 7354 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 1139 loss: 1.54895 acc: 0.69173 | v_loss: 1.32817 v_acc: 0.70703 |  iteration: 7355 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 1140 loss: 1.48250 acc: 0.70150 | v_loss: 1.54765 v_acc: 0.70085 |  iteration: 7356 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1141 loss: 1.46803 acc: 0.70605 | v_loss: 1.48524 v_acc: 0.71419 |  iteration: 7357 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1142 loss: 1.56274 acc: 0.70085 | v_loss: 1.34949 v_acc: 0.71647 |  iteration: 7358 teacher: 0 stage: sketch lr: 0.000515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1143 loss: 1.55925 acc: 0.70150 | v_loss: 1.30432 v_acc: 0.72298 |  iteration: 7359 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 1144 loss: 1.43954 acc: 0.71419 | v_loss: 1.47147 v_acc: 0.71940 |  iteration: 7360 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 1145 loss: 1.51607 acc: 0.69596 | v_loss: 1.45831 v_acc: 0.70475 |  iteration: 7361 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 1146 loss: 1.55800 acc: 0.68815 | v_loss: 1.47154 v_acc: 0.70736 |  iteration: 7362 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1147 loss: 1.54044 acc: 0.69987 | v_loss: 1.28100 v_acc: 0.72493 |  iteration: 7363 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 1148 loss: 1.40147 acc: 0.70573 | v_loss: 1.46959 v_acc: 0.72949 |  iteration: 7364 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 1149 loss: 1.48894 acc: 0.68978 | v_loss: 1.59418 v_acc: 0.69759 |  iteration: 7365 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1150 loss: 1.58075 acc: 0.68652 | v_loss: 1.49630 v_acc: 0.71777 |  iteration: 7366 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1151 loss: 1.53306 acc: 0.68848 | v_loss: 1.31403 v_acc: 0.71647 |  iteration: 7367 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 1152 loss: 1.51626 acc: 0.69010 | v_loss: 1.28701 v_acc: 0.73112 |  iteration: 7368 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 1153 loss: 1.34482 acc: 0.70996 | v_loss: 1.31187 v_acc: 0.72656 |  iteration: 7369 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 1154 loss: 1.51971 acc: 0.69206 | v_loss: 1.35533 v_acc: 0.70703 |  iteration: 7370 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1155 loss: 1.54369 acc: 0.69206 | v_loss: 1.51777 v_acc: 0.70345 |  iteration: 7371 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1156 loss: 1.45176 acc: 0.70931 | v_loss: 1.32994 v_acc: 0.71615 |  iteration: 7372 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1157 loss: 1.48638 acc: 0.71517 | v_loss: 1.55049 v_acc: 0.70150 |  iteration: 7373 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1158 loss: 1.47232 acc: 0.70671 | v_loss: 1.75114 v_acc: 0.69303 |  iteration: 7374 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1159 loss: 1.48396 acc: 0.70280 | v_loss: 1.60870 v_acc: 0.69368 |  iteration: 7375 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 1160 loss: 1.52128 acc: 0.69922 | v_loss: 1.38253 v_acc: 0.72591 |  iteration: 7376 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1161 loss: 1.56045 acc: 0.69206 | v_loss: 1.45188 v_acc: 0.70312 |  iteration: 7377 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1162 loss: 1.53220 acc: 0.70182 | v_loss: 1.30838 v_acc: 0.71712 |  iteration: 7378 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1163 loss: 1.56538 acc: 0.69206 | v_loss: 1.48694 v_acc: 0.69564 |  iteration: 7379 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1164 loss: 1.54734 acc: 0.69336 | v_loss: 1.44046 v_acc: 0.71680 |  iteration: 7380 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1165 loss: 1.53109 acc: 0.70573 | v_loss: 1.41733 v_acc: 0.72754 |  iteration: 7381 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1166 loss: 1.60234 acc: 0.69368 | v_loss: 1.43577 v_acc: 0.71973 |  iteration: 7382 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1167 loss: 1.42883 acc: 0.69857 | v_loss: 1.42206 v_acc: 0.71387 |  iteration: 7383 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1168 loss: 1.49573 acc: 0.69368 | v_loss: 1.35475 v_acc: 0.72461 |  iteration: 7384 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1169 loss: 1.46191 acc: 0.70410 | v_loss: 1.34513 v_acc: 0.72298 |  iteration: 7385 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1170 loss: 1.56620 acc: 0.69987 | v_loss: 1.55226 v_acc: 0.69434 |  iteration: 7386 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1171 loss: 1.55130 acc: 0.69954 | v_loss: 1.41098 v_acc: 0.70703 |  iteration: 7387 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1172 loss: 1.50542 acc: 0.69792 | v_loss: 1.36151 v_acc: 0.71484 |  iteration: 7388 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1173 loss: 1.49903 acc: 0.69889 | v_loss: 1.34054 v_acc: 0.71745 |  iteration: 7389 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1174 loss: 1.47700 acc: 0.69531 | v_loss: 1.47851 v_acc: 0.70508 |  iteration: 7390 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1175 loss: 1.39589 acc: 0.71452 | v_loss: 1.38118 v_acc: 0.73079 |  iteration: 7391 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1176 loss: 1.58655 acc: 0.69466 | v_loss: 1.55791 v_acc: 0.71126 |  iteration: 7392 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1177 loss: 1.47132 acc: 0.70378 | v_loss: 1.39954 v_acc: 0.69531 |  iteration: 7393 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1178 loss: 1.42088 acc: 0.71810 | v_loss: 1.38377 v_acc: 0.70117 |  iteration: 7394 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1179 loss: 1.60182 acc: 0.69987 | v_loss: 1.48066 v_acc: 0.70312 |  iteration: 7395 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1180 loss: 1.56102 acc: 0.70410 | v_loss: 1.50916 v_acc: 0.70768 |  iteration: 7396 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1181 loss: 1.61738 acc: 0.68587 | v_loss: 1.56962 v_acc: 0.68685 |  iteration: 7397 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1182 loss: 1.46505 acc: 0.71094 | v_loss: 1.53850 v_acc: 0.70605 |  iteration: 7398 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1183 loss: 1.51718 acc: 0.69759 | v_loss: 1.47004 v_acc: 0.70573 |  iteration: 7399 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1184 loss: 1.47376 acc: 0.70703 | v_loss: 1.45977 v_acc: 0.70573 |  iteration: 7400 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1185 loss: 1.68489 acc: 0.68099 | v_loss: 1.48713 v_acc: 0.70312 |  iteration: 7401 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1186 loss: 1.49811 acc: 0.70182 | v_loss: 1.34630 v_acc: 0.71257 |  iteration: 7402 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1187 loss: 1.46038 acc: 0.70410 | v_loss: 1.39284 v_acc: 0.72526 |  iteration: 7403 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1188 loss: 1.57003 acc: 0.69401 | v_loss: 1.25527 v_acc: 0.70671 |  iteration: 7404 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1189 loss: 1.54442 acc: 0.69694 | v_loss: 1.38813 v_acc: 0.70605 |  iteration: 7405 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1190 loss: 1.54256 acc: 0.69661 | v_loss: 1.55214 v_acc: 0.69954 |  iteration: 7406 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1191 loss: 1.37486 acc: 0.70605 | v_loss: 1.35898 v_acc: 0.71484 |  iteration: 7407 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1192 loss: 1.37650 acc: 0.70605 | v_loss: 1.42391 v_acc: 0.69727 |  iteration: 7408 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1193 loss: 1.43302 acc: 0.71419 | v_loss: 1.31252 v_acc: 0.70573 |  iteration: 7409 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1194 loss: 1.39619 acc: 0.70638 | v_loss: 1.29354 v_acc: 0.70215 |  iteration: 7410 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1195 loss: 1.55660 acc: 0.69824 | v_loss: 1.30747 v_acc: 0.73340 |  iteration: 7411 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 1196 loss: 1.45587 acc: 0.70020 | v_loss: 1.31751 v_acc: 0.71647 |  iteration: 7412 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1197 loss: 1.54041 acc: 0.69303 | v_loss: 1.41050 v_acc: 0.74089 |  iteration: 7413 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 1198 loss: 1.47220 acc: 0.70052 | v_loss: 1.33486 v_acc: 0.72005 |  iteration: 7414 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1199 loss: 1.47706 acc: 0.70833 | v_loss: 1.36418 v_acc: 0.71582 |  iteration: 7415 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1200 loss: 1.35809 acc: 0.71777 | v_loss: 1.44750 v_acc: 0.71224 |  iteration: 7416 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1201 loss: 1.45770 acc: 0.70345 | v_loss: 1.43991 v_acc: 0.72038 |  iteration: 7417 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 1202 loss: 1.47562 acc: 0.69792 | v_loss: 1.51461 v_acc: 0.69727 |  iteration: 7418 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 1203 loss: 1.51978 acc: 0.70573 | v_loss: 1.44459 v_acc: 0.71745 |  iteration: 7419 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1204 loss: 1.44039 acc: 0.70410 | v_loss: 1.23711 v_acc: 0.74414 |  iteration: 7420 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 1205 loss: 1.52595 acc: 0.69759 | v_loss: 1.30793 v_acc: 0.70312 |  iteration: 7421 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 1206 loss: 1.33593 acc: 0.70703 | v_loss: 1.54979 v_acc: 0.70410 |  iteration: 7422 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1207 loss: 1.55710 acc: 0.68490 | v_loss: 1.27314 v_acc: 0.71549 |  iteration: 7423 teacher: 0 stage: sketch lr: 0.000513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1208 loss: 1.45135 acc: 0.70312 | v_loss: 1.39041 v_acc: 0.71191 |  iteration: 7424 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 1209 loss: 1.54133 acc: 0.69564 | v_loss: 1.40424 v_acc: 0.69141 |  iteration: 7425 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 1210 loss: 1.45264 acc: 0.69857 | v_loss: 1.33571 v_acc: 0.70898 |  iteration: 7426 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 1211 loss: 1.38313 acc: 0.70312 | v_loss: 1.41211 v_acc: 0.69531 |  iteration: 7427 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 1212 loss: 1.44332 acc: 0.69857 | v_loss: 1.52075 v_acc: 0.71777 |  iteration: 7428 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1213 loss: 1.48572 acc: 0.69889 | v_loss: 1.35819 v_acc: 0.72656 |  iteration: 7429 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1214 loss: 1.48000 acc: 0.70605 | v_loss: 1.49235 v_acc: 0.70280 |  iteration: 7430 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 1215 loss: 1.56217 acc: 0.69792 | v_loss: 1.38899 v_acc: 0.70085 |  iteration: 7431 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1216 loss: 1.55530 acc: 0.69629 | v_loss: 1.41230 v_acc: 0.70312 |  iteration: 7432 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1217 loss: 1.43114 acc: 0.70052 | v_loss: 1.56756 v_acc: 0.68815 |  iteration: 7433 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 1218 loss: 1.40004 acc: 0.71257 | v_loss: 1.37633 v_acc: 0.72038 |  iteration: 7434 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 1219 loss: 1.55009 acc: 0.70801 | v_loss: 1.63378 v_acc: 0.68424 |  iteration: 7435 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1220 loss: 1.47815 acc: 0.69629 | v_loss: 1.52423 v_acc: 0.69629 |  iteration: 7436 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1221 loss: 1.46549 acc: 0.70898 | v_loss: 1.56714 v_acc: 0.69727 |  iteration: 7437 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 1222 loss: 1.45163 acc: 0.70508 | v_loss: 1.42278 v_acc: 0.70020 |  iteration: 7438 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 1223 loss: 1.46492 acc: 0.70182 | v_loss: 1.37270 v_acc: 0.70540 |  iteration: 7439 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 1224 loss: 1.38680 acc: 0.71647 | v_loss: 1.37382 v_acc: 0.70410 |  iteration: 7440 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 1225 loss: 1.57308 acc: 0.69368 | v_loss: 1.37311 v_acc: 0.72038 |  iteration: 7441 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 1226 loss: 1.53269 acc: 0.69271 | v_loss: 1.57568 v_acc: 0.68848 |  iteration: 7442 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 1227 loss: 1.40938 acc: 0.70638 | v_loss: 1.43179 v_acc: 0.69889 |  iteration: 7443 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 1228 loss: 1.57045 acc: 0.69401 | v_loss: 1.44641 v_acc: 0.71029 |  iteration: 7444 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 1229 loss: 1.45062 acc: 0.70215 | v_loss: 1.42789 v_acc: 0.71810 |  iteration: 7445 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 1230 loss: 1.51489 acc: 0.69857 | v_loss: 1.33107 v_acc: 0.70573 |  iteration: 7446 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 1231 loss: 1.44171 acc: 0.70345 | v_loss: 1.50528 v_acc: 0.70052 |  iteration: 7447 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 1232 loss: 1.48639 acc: 0.69922 | v_loss: 1.44795 v_acc: 0.71191 |  iteration: 7448 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 1233 loss: 1.45713 acc: 0.70182 | v_loss: 1.30334 v_acc: 0.71810 |  iteration: 7449 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 1234 loss: 1.56514 acc: 0.70020 | v_loss: 1.29174 v_acc: 0.72786 |  iteration: 7450 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 1235 loss: 1.50418 acc: 0.69987 | v_loss: 1.41550 v_acc: 0.71875 |  iteration: 7451 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 1236 loss: 1.55383 acc: 0.69564 | v_loss: 1.45057 v_acc: 0.70052 |  iteration: 7452 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 1237 loss: 1.51393 acc: 0.69694 | v_loss: 1.48157 v_acc: 0.70312 |  iteration: 7453 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 1238 loss: 1.53577 acc: 0.69434 | v_loss: 1.30040 v_acc: 0.71745 |  iteration: 7454 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 1239 loss: 1.46935 acc: 0.69531 | v_loss: 1.44463 v_acc: 0.72786 |  iteration: 7455 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 1240 loss: 1.59391 acc: 0.68880 | v_loss: 1.53002 v_acc: 0.69792 |  iteration: 7456 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 1241 loss: 1.40764 acc: 0.70443 | v_loss: 1.46918 v_acc: 0.72135 |  iteration: 7457 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 1242 loss: 1.56512 acc: 0.69954 | v_loss: 1.28959 v_acc: 0.72233 |  iteration: 7458 teacher: 1 stage: sketch lr: 0.000512\n",
      "epoch 5 loss: 0.75827 acc: 0.83436 | v_loss: 0.89946 v_acc: 0.81467 \n",
      "epoch: 6\n",
      "__________________________________________\n",
      "batch 0 loss: 1.48158 acc: 0.70117 | v_loss: 1.45430 v_acc: 0.70085 |  iteration: 7459 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 1 loss: 1.54689 acc: 0.70182 | v_loss: 1.44509 v_acc: 0.70931 |  iteration: 7460 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 2 loss: 1.52520 acc: 0.70475 | v_loss: 1.48041 v_acc: 0.70703 |  iteration: 7461 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 3 loss: 1.47333 acc: 0.70736 | v_loss: 1.34174 v_acc: 0.71257 |  iteration: 7462 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 4 loss: 1.36889 acc: 0.70410 | v_loss: 1.38078 v_acc: 0.72493 |  iteration: 7463 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 5 loss: 1.45279 acc: 0.70573 | v_loss: 1.25557 v_acc: 0.70605 |  iteration: 7464 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 6 loss: 1.47536 acc: 0.69759 | v_loss: 1.38642 v_acc: 0.70150 |  iteration: 7465 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 7 loss: 1.53953 acc: 0.70215 | v_loss: 1.52792 v_acc: 0.70312 |  iteration: 7466 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 8 loss: 1.45613 acc: 0.69499 | v_loss: 1.40155 v_acc: 0.70443 |  iteration: 7467 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 9 loss: 1.46191 acc: 0.69303 | v_loss: 1.45106 v_acc: 0.69401 |  iteration: 7468 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 10 loss: 1.50094 acc: 0.70215 | v_loss: 1.28895 v_acc: 0.71029 |  iteration: 7469 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 11 loss: 1.43089 acc: 0.70475 | v_loss: 1.29573 v_acc: 0.70345 |  iteration: 7470 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 12 loss: 1.43630 acc: 0.70247 | v_loss: 1.31801 v_acc: 0.73405 |  iteration: 7471 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 13 loss: 1.51065 acc: 0.69987 | v_loss: 1.31692 v_acc: 0.71810 |  iteration: 7472 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 14 loss: 1.46842 acc: 0.70117 | v_loss: 1.42246 v_acc: 0.73242 |  iteration: 7473 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 15 loss: 1.53285 acc: 0.69824 | v_loss: 1.34523 v_acc: 0.71354 |  iteration: 7474 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 16 loss: 1.46139 acc: 0.70052 | v_loss: 1.35862 v_acc: 0.71224 |  iteration: 7475 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 17 loss: 1.47521 acc: 0.70703 | v_loss: 1.44461 v_acc: 0.70703 |  iteration: 7476 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 18 loss: 1.44856 acc: 0.69824 | v_loss: 1.45757 v_acc: 0.72135 |  iteration: 7477 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 19 loss: 1.53119 acc: 0.69043 | v_loss: 1.51703 v_acc: 0.70312 |  iteration: 7478 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 20 loss: 1.54446 acc: 0.69596 | v_loss: 1.48856 v_acc: 0.71419 |  iteration: 7479 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 21 loss: 1.37878 acc: 0.70345 | v_loss: 1.24178 v_acc: 0.74284 |  iteration: 7480 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 22 loss: 1.52180 acc: 0.69922 | v_loss: 1.25839 v_acc: 0.71159 |  iteration: 7481 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 23 loss: 1.40816 acc: 0.70312 | v_loss: 1.58894 v_acc: 0.70247 |  iteration: 7482 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 24 loss: 1.59194 acc: 0.68880 | v_loss: 1.23386 v_acc: 0.71745 |  iteration: 7483 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 25 loss: 1.55123 acc: 0.69727 | v_loss: 1.38237 v_acc: 0.71257 |  iteration: 7484 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 26 loss: 1.51631 acc: 0.69661 | v_loss: 1.40584 v_acc: 0.69531 |  iteration: 7485 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 27 loss: 1.55459 acc: 0.70508 | v_loss: 1.37320 v_acc: 0.70866 |  iteration: 7486 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 28 loss: 1.47475 acc: 0.69922 | v_loss: 1.48274 v_acc: 0.69010 |  iteration: 7487 teacher: 0 stage: sketch lr: 0.000511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 29 loss: 1.49200 acc: 0.70573 | v_loss: 1.49221 v_acc: 0.70768 |  iteration: 7488 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 30 loss: 1.40587 acc: 0.70671 | v_loss: 1.37996 v_acc: 0.72331 |  iteration: 7489 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 31 loss: 1.59838 acc: 0.68945 | v_loss: 1.46582 v_acc: 0.70443 |  iteration: 7490 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 32 loss: 1.50387 acc: 0.70443 | v_loss: 1.43497 v_acc: 0.69922 |  iteration: 7491 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 33 loss: 1.61559 acc: 0.68848 | v_loss: 1.38847 v_acc: 0.70703 |  iteration: 7492 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 34 loss: 1.47187 acc: 0.69661 | v_loss: 1.55936 v_acc: 0.69336 |  iteration: 7493 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 35 loss: 1.45010 acc: 0.69889 | v_loss: 1.39190 v_acc: 0.72461 |  iteration: 7494 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 36 loss: 1.45492 acc: 0.70215 | v_loss: 1.61475 v_acc: 0.68750 |  iteration: 7495 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 37 loss: 1.58521 acc: 0.68978 | v_loss: 1.43963 v_acc: 0.70215 |  iteration: 7496 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 38 loss: 1.51003 acc: 0.69922 | v_loss: 1.56883 v_acc: 0.69173 |  iteration: 7497 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 39 loss: 1.58897 acc: 0.69401 | v_loss: 1.41184 v_acc: 0.70182 |  iteration: 7498 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 40 loss: 1.43908 acc: 0.70215 | v_loss: 1.37138 v_acc: 0.70638 |  iteration: 7499 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 41 loss: 1.48158 acc: 0.69531 | v_loss: 1.39297 v_acc: 0.69987 |  iteration: 7500 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 42 loss: 1.47298 acc: 0.69531 | v_loss: 1.38548 v_acc: 0.71517 |  iteration: 7501 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 43 loss: 1.47278 acc: 0.69857 | v_loss: 1.58511 v_acc: 0.68555 |  iteration: 7502 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 44 loss: 1.38774 acc: 0.70801 | v_loss: 1.41393 v_acc: 0.70085 |  iteration: 7503 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 45 loss: 1.52230 acc: 0.69987 | v_loss: 1.40256 v_acc: 0.70964 |  iteration: 7504 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 46 loss: 1.61821 acc: 0.69466 | v_loss: 1.41715 v_acc: 0.71810 |  iteration: 7505 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 47 loss: 1.58253 acc: 0.68750 | v_loss: 1.32607 v_acc: 0.69759 |  iteration: 7506 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 48 loss: 1.56437 acc: 0.69499 | v_loss: 1.48308 v_acc: 0.69368 |  iteration: 7507 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 49 loss: 1.53650 acc: 0.69759 | v_loss: 1.45921 v_acc: 0.71842 |  iteration: 7508 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 50 loss: 1.44716 acc: 0.70866 | v_loss: 1.33271 v_acc: 0.71777 |  iteration: 7509 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 51 loss: 1.39413 acc: 0.70833 | v_loss: 1.32093 v_acc: 0.72526 |  iteration: 7510 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 52 loss: 1.56407 acc: 0.69238 | v_loss: 1.40853 v_acc: 0.71647 |  iteration: 7511 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 53 loss: 1.42117 acc: 0.70378 | v_loss: 1.46068 v_acc: 0.70052 |  iteration: 7512 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 54 loss: 1.53182 acc: 0.69954 | v_loss: 1.47248 v_acc: 0.70280 |  iteration: 7513 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 55 loss: 1.48464 acc: 0.69564 | v_loss: 1.30299 v_acc: 0.71159 |  iteration: 7514 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 56 loss: 1.42659 acc: 0.70052 | v_loss: 1.44788 v_acc: 0.72135 |  iteration: 7515 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 57 loss: 1.40807 acc: 0.69727 | v_loss: 1.55509 v_acc: 0.69368 |  iteration: 7516 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 58 loss: 1.45053 acc: 0.69694 | v_loss: 1.48724 v_acc: 0.72070 |  iteration: 7517 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 59 loss: 1.52296 acc: 0.70117 | v_loss: 1.26179 v_acc: 0.71908 |  iteration: 7518 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 60 loss: 1.48170 acc: 0.70150 | v_loss: 1.19556 v_acc: 0.73861 |  iteration: 7519 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 61 loss: 1.51439 acc: 0.69629 | v_loss: 1.25803 v_acc: 0.72331 |  iteration: 7520 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 62 loss: 1.53501 acc: 0.69466 | v_loss: 1.29819 v_acc: 0.70540 |  iteration: 7521 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 63 loss: 1.64226 acc: 0.68620 | v_loss: 1.49214 v_acc: 0.70312 |  iteration: 7522 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 64 loss: 1.38906 acc: 0.70345 | v_loss: 1.35698 v_acc: 0.70833 |  iteration: 7523 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 65 loss: 1.58202 acc: 0.69238 | v_loss: 1.52612 v_acc: 0.71289 |  iteration: 7524 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 66 loss: 1.49645 acc: 0.69759 | v_loss: 1.70211 v_acc: 0.69173 |  iteration: 7525 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 67 loss: 1.51613 acc: 0.69271 | v_loss: 1.53800 v_acc: 0.70508 |  iteration: 7526 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 68 loss: 1.55091 acc: 0.69076 | v_loss: 1.35716 v_acc: 0.71973 |  iteration: 7527 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 69 loss: 1.42959 acc: 0.71322 | v_loss: 1.42183 v_acc: 0.70312 |  iteration: 7528 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 70 loss: 1.48813 acc: 0.70215 | v_loss: 1.27943 v_acc: 0.71615 |  iteration: 7529 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 71 loss: 1.55998 acc: 0.69238 | v_loss: 1.47991 v_acc: 0.69857 |  iteration: 7530 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 72 loss: 1.44411 acc: 0.69954 | v_loss: 1.39205 v_acc: 0.70931 |  iteration: 7531 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 73 loss: 1.43726 acc: 0.70703 | v_loss: 1.38937 v_acc: 0.73079 |  iteration: 7532 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 74 loss: 1.50047 acc: 0.70117 | v_loss: 1.40436 v_acc: 0.71875 |  iteration: 7533 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 75 loss: 1.45945 acc: 0.70540 | v_loss: 1.40155 v_acc: 0.70345 |  iteration: 7534 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 76 loss: 1.51184 acc: 0.69954 | v_loss: 1.34583 v_acc: 0.72266 |  iteration: 7535 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 77 loss: 1.54682 acc: 0.69271 | v_loss: 1.34115 v_acc: 0.71875 |  iteration: 7536 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 78 loss: 1.57840 acc: 0.69727 | v_loss: 1.56366 v_acc: 0.68555 |  iteration: 7537 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 79 loss: 1.48530 acc: 0.70150 | v_loss: 1.39541 v_acc: 0.70866 |  iteration: 7538 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 80 loss: 1.39161 acc: 0.71484 | v_loss: 1.36702 v_acc: 0.71191 |  iteration: 7539 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 81 loss: 1.50941 acc: 0.69661 | v_loss: 1.34050 v_acc: 0.72624 |  iteration: 7540 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 82 loss: 1.48238 acc: 0.69531 | v_loss: 1.45214 v_acc: 0.70508 |  iteration: 7541 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 83 loss: 1.56251 acc: 0.68945 | v_loss: 1.35973 v_acc: 0.73145 |  iteration: 7542 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 84 loss: 1.43374 acc: 0.70020 | v_loss: 1.58492 v_acc: 0.71452 |  iteration: 7543 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 85 loss: 1.47237 acc: 0.70247 | v_loss: 1.31159 v_acc: 0.70150 |  iteration: 7544 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 86 loss: 1.47083 acc: 0.69173 | v_loss: 1.30205 v_acc: 0.70312 |  iteration: 7545 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 87 loss: 1.50894 acc: 0.69499 | v_loss: 1.48608 v_acc: 0.70345 |  iteration: 7546 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 88 loss: 1.47686 acc: 0.69727 | v_loss: 1.50922 v_acc: 0.70150 |  iteration: 7547 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 89 loss: 1.48840 acc: 0.70508 | v_loss: 1.55830 v_acc: 0.69173 |  iteration: 7548 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 90 loss: 1.47026 acc: 0.70573 | v_loss: 1.50811 v_acc: 0.70150 |  iteration: 7549 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 91 loss: 1.58759 acc: 0.69206 | v_loss: 1.44341 v_acc: 0.70378 |  iteration: 7550 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 92 loss: 1.48175 acc: 0.69889 | v_loss: 1.45295 v_acc: 0.70768 |  iteration: 7551 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 93 loss: 1.51755 acc: 0.69499 | v_loss: 1.46064 v_acc: 0.70508 |  iteration: 7552 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 94 loss: 1.48397 acc: 0.69857 | v_loss: 1.32817 v_acc: 0.71257 |  iteration: 7553 teacher: 1 stage: sketch lr: 0.000509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 95 loss: 1.48126 acc: 0.69206 | v_loss: 1.37291 v_acc: 0.72428 |  iteration: 7554 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 96 loss: 1.46078 acc: 0.70898 | v_loss: 1.25301 v_acc: 0.70671 |  iteration: 7555 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 97 loss: 1.49888 acc: 0.70052 | v_loss: 1.39442 v_acc: 0.70150 |  iteration: 7556 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 98 loss: 1.51013 acc: 0.69564 | v_loss: 1.52498 v_acc: 0.69987 |  iteration: 7557 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 99 loss: 1.61161 acc: 0.68880 | v_loss: 1.39506 v_acc: 0.70475 |  iteration: 7558 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 100 loss: 1.59673 acc: 0.69238 | v_loss: 1.40423 v_acc: 0.69401 |  iteration: 7559 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 101 loss: 1.36622 acc: 0.71322 | v_loss: 1.31884 v_acc: 0.70508 |  iteration: 7560 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 102 loss: 1.40405 acc: 0.70182 | v_loss: 1.28536 v_acc: 0.70508 |  iteration: 7561 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 103 loss: 1.42336 acc: 0.70703 | v_loss: 1.30929 v_acc: 0.73861 |  iteration: 7562 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 104 loss: 1.44243 acc: 0.70996 | v_loss: 1.30118 v_acc: 0.72168 |  iteration: 7563 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 105 loss: 1.45955 acc: 0.70475 | v_loss: 1.41199 v_acc: 0.73145 |  iteration: 7564 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 106 loss: 1.39392 acc: 0.71094 | v_loss: 1.33556 v_acc: 0.72493 |  iteration: 7565 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 107 loss: 1.50213 acc: 0.70182 | v_loss: 1.36765 v_acc: 0.71615 |  iteration: 7566 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 108 loss: 1.46689 acc: 0.70964 | v_loss: 1.46807 v_acc: 0.70931 |  iteration: 7567 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 109 loss: 1.41282 acc: 0.70475 | v_loss: 1.47271 v_acc: 0.72298 |  iteration: 7568 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 110 loss: 1.43142 acc: 0.70345 | v_loss: 1.49920 v_acc: 0.70020 |  iteration: 7569 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 111 loss: 1.54408 acc: 0.69531 | v_loss: 1.45715 v_acc: 0.71745 |  iteration: 7570 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 112 loss: 1.44552 acc: 0.70215 | v_loss: 1.22572 v_acc: 0.74251 |  iteration: 7571 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 113 loss: 1.55307 acc: 0.69336 | v_loss: 1.29273 v_acc: 0.70378 |  iteration: 7572 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 114 loss: 1.47136 acc: 0.70117 | v_loss: 1.56545 v_acc: 0.70475 |  iteration: 7573 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 115 loss: 1.41890 acc: 0.70540 | v_loss: 1.26299 v_acc: 0.71224 |  iteration: 7574 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 116 loss: 1.42719 acc: 0.70540 | v_loss: 1.38051 v_acc: 0.71159 |  iteration: 7575 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 117 loss: 1.47965 acc: 0.70866 | v_loss: 1.40250 v_acc: 0.69336 |  iteration: 7576 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 118 loss: 1.43109 acc: 0.71061 | v_loss: 1.33073 v_acc: 0.71191 |  iteration: 7577 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 119 loss: 1.57280 acc: 0.69564 | v_loss: 1.41910 v_acc: 0.69629 |  iteration: 7578 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 120 loss: 1.39037 acc: 0.71029 | v_loss: 1.49170 v_acc: 0.71517 |  iteration: 7579 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 121 loss: 1.43681 acc: 0.70378 | v_loss: 1.34843 v_acc: 0.72689 |  iteration: 7580 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 122 loss: 1.48825 acc: 0.69792 | v_loss: 1.47454 v_acc: 0.70215 |  iteration: 7581 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 123 loss: 1.61093 acc: 0.69141 | v_loss: 1.38771 v_acc: 0.70150 |  iteration: 7582 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 124 loss: 1.49408 acc: 0.70150 | v_loss: 1.39507 v_acc: 0.70378 |  iteration: 7583 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 125 loss: 1.42410 acc: 0.71354 | v_loss: 1.57390 v_acc: 0.68717 |  iteration: 7584 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 126 loss: 1.46635 acc: 0.69857 | v_loss: 1.37361 v_acc: 0.72331 |  iteration: 7585 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 127 loss: 1.52618 acc: 0.69694 | v_loss: 1.59459 v_acc: 0.69043 |  iteration: 7586 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 128 loss: 1.45222 acc: 0.69271 | v_loss: 1.48724 v_acc: 0.69792 |  iteration: 7587 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 129 loss: 1.37490 acc: 0.70703 | v_loss: 1.56057 v_acc: 0.69173 |  iteration: 7588 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 130 loss: 1.55047 acc: 0.69824 | v_loss: 1.43352 v_acc: 0.70020 |  iteration: 7589 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 131 loss: 1.57372 acc: 0.70020 | v_loss: 1.40188 v_acc: 0.70312 |  iteration: 7590 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 132 loss: 1.51664 acc: 0.70052 | v_loss: 1.40692 v_acc: 0.70020 |  iteration: 7591 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 133 loss: 1.51066 acc: 0.70573 | v_loss: 1.39661 v_acc: 0.71484 |  iteration: 7592 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 134 loss: 1.59523 acc: 0.69661 | v_loss: 1.53785 v_acc: 0.69401 |  iteration: 7593 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 135 loss: 1.46265 acc: 0.70052 | v_loss: 1.40799 v_acc: 0.69922 |  iteration: 7594 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 136 loss: 1.53106 acc: 0.69466 | v_loss: 1.41176 v_acc: 0.71322 |  iteration: 7595 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 137 loss: 1.57006 acc: 0.69727 | v_loss: 1.41422 v_acc: 0.71745 |  iteration: 7596 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 138 loss: 1.50476 acc: 0.70605 | v_loss: 1.34341 v_acc: 0.69857 |  iteration: 7597 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 139 loss: 1.55666 acc: 0.70020 | v_loss: 1.48506 v_acc: 0.69629 |  iteration: 7598 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 140 loss: 1.57042 acc: 0.69466 | v_loss: 1.44461 v_acc: 0.71452 |  iteration: 7599 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 141 loss: 1.56882 acc: 0.69499 | v_loss: 1.34607 v_acc: 0.71647 |  iteration: 7600 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 142 loss: 1.37594 acc: 0.71615 | v_loss: 1.29671 v_acc: 0.72526 |  iteration: 7601 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 143 loss: 1.41382 acc: 0.70410 | v_loss: 1.40270 v_acc: 0.71647 |  iteration: 7602 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 144 loss: 1.53954 acc: 0.69727 | v_loss: 1.44525 v_acc: 0.70052 |  iteration: 7603 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 145 loss: 1.59759 acc: 0.68587 | v_loss: 1.46589 v_acc: 0.70215 |  iteration: 7604 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 146 loss: 1.51094 acc: 0.69141 | v_loss: 1.30907 v_acc: 0.71126 |  iteration: 7605 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 147 loss: 1.48692 acc: 0.69401 | v_loss: 1.45897 v_acc: 0.72884 |  iteration: 7606 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 148 loss: 1.58865 acc: 0.68652 | v_loss: 1.52952 v_acc: 0.70085 |  iteration: 7607 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 149 loss: 1.47391 acc: 0.69792 | v_loss: 1.43547 v_acc: 0.71908 |  iteration: 7608 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 150 loss: 1.48142 acc: 0.70085 | v_loss: 1.28134 v_acc: 0.71810 |  iteration: 7609 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 151 loss: 1.45543 acc: 0.69531 | v_loss: 1.23431 v_acc: 0.74023 |  iteration: 7610 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 152 loss: 1.49076 acc: 0.69954 | v_loss: 1.25807 v_acc: 0.72559 |  iteration: 7611 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 153 loss: 1.44444 acc: 0.70996 | v_loss: 1.31194 v_acc: 0.70638 |  iteration: 7612 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 154 loss: 1.53601 acc: 0.69596 | v_loss: 1.47035 v_acc: 0.70052 |  iteration: 7613 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 155 loss: 1.48651 acc: 0.70052 | v_loss: 1.33160 v_acc: 0.71452 |  iteration: 7614 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 156 loss: 1.50048 acc: 0.69238 | v_loss: 1.52009 v_acc: 0.71647 |  iteration: 7615 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 157 loss: 1.44294 acc: 0.70638 | v_loss: 1.69960 v_acc: 0.69108 |  iteration: 7616 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 158 loss: 1.45870 acc: 0.70964 | v_loss: 1.55138 v_acc: 0.70020 |  iteration: 7617 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 159 loss: 1.47284 acc: 0.70020 | v_loss: 1.34930 v_acc: 0.72103 |  iteration: 7618 teacher: 0 stage: sketch lr: 0.000506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 160 loss: 1.40791 acc: 0.70703 | v_loss: 1.42499 v_acc: 0.70605 |  iteration: 7619 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 161 loss: 1.46420 acc: 0.69141 | v_loss: 1.26708 v_acc: 0.71875 |  iteration: 7620 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 162 loss: 1.34345 acc: 0.71549 | v_loss: 1.49279 v_acc: 0.69857 |  iteration: 7621 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 163 loss: 1.53393 acc: 0.69889 | v_loss: 1.38763 v_acc: 0.71549 |  iteration: 7622 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 164 loss: 1.55735 acc: 0.68848 | v_loss: 1.39619 v_acc: 0.72754 |  iteration: 7623 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 165 loss: 1.46990 acc: 0.70280 | v_loss: 1.43083 v_acc: 0.71842 |  iteration: 7624 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 166 loss: 1.48882 acc: 0.70996 | v_loss: 1.41142 v_acc: 0.70410 |  iteration: 7625 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 167 loss: 1.51757 acc: 0.70475 | v_loss: 1.32679 v_acc: 0.72233 |  iteration: 7626 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 168 loss: 1.39503 acc: 0.69954 | v_loss: 1.34185 v_acc: 0.71745 |  iteration: 7627 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 169 loss: 1.50729 acc: 0.70085 | v_loss: 1.54274 v_acc: 0.68685 |  iteration: 7628 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 170 loss: 1.42520 acc: 0.70508 | v_loss: 1.38522 v_acc: 0.70931 |  iteration: 7629 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 171 loss: 1.45691 acc: 0.70573 | v_loss: 1.33864 v_acc: 0.71094 |  iteration: 7630 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 172 loss: 1.56026 acc: 0.69043 | v_loss: 1.32919 v_acc: 0.71745 |  iteration: 7631 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 173 loss: 1.42967 acc: 0.70703 | v_loss: 1.46236 v_acc: 0.70410 |  iteration: 7632 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 174 loss: 1.55017 acc: 0.69173 | v_loss: 1.35691 v_acc: 0.73079 |  iteration: 7633 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 175 loss: 1.43409 acc: 0.70280 | v_loss: 1.56374 v_acc: 0.71224 |  iteration: 7634 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 176 loss: 1.46279 acc: 0.70378 | v_loss: 1.32859 v_acc: 0.69759 |  iteration: 7635 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 177 loss: 1.44318 acc: 0.69922 | v_loss: 1.31762 v_acc: 0.70443 |  iteration: 7636 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 178 loss: 1.33119 acc: 0.71549 | v_loss: 1.49108 v_acc: 0.70312 |  iteration: 7637 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 179 loss: 1.47093 acc: 0.69596 | v_loss: 1.51237 v_acc: 0.70378 |  iteration: 7638 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 180 loss: 1.52909 acc: 0.69661 | v_loss: 1.57529 v_acc: 0.68978 |  iteration: 7639 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 181 loss: 1.53484 acc: 0.68262 | v_loss: 1.50737 v_acc: 0.70638 |  iteration: 7640 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 182 loss: 1.41879 acc: 0.71029 | v_loss: 1.44277 v_acc: 0.70605 |  iteration: 7641 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 183 loss: 1.50225 acc: 0.69303 | v_loss: 1.45494 v_acc: 0.70703 |  iteration: 7642 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 184 loss: 1.51218 acc: 0.69531 | v_loss: 1.45512 v_acc: 0.70378 |  iteration: 7643 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 185 loss: 1.43035 acc: 0.69857 | v_loss: 1.31696 v_acc: 0.70931 |  iteration: 7644 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 186 loss: 1.44355 acc: 0.70410 | v_loss: 1.37403 v_acc: 0.72396 |  iteration: 7645 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 187 loss: 1.48831 acc: 0.69108 | v_loss: 1.24549 v_acc: 0.70573 |  iteration: 7646 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 188 loss: 1.53874 acc: 0.69792 | v_loss: 1.37432 v_acc: 0.70085 |  iteration: 7647 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 189 loss: 1.44256 acc: 0.69759 | v_loss: 1.53175 v_acc: 0.69987 |  iteration: 7648 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 190 loss: 1.45688 acc: 0.69466 | v_loss: 1.36410 v_acc: 0.70833 |  iteration: 7649 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 191 loss: 1.46571 acc: 0.69954 | v_loss: 1.41529 v_acc: 0.70312 |  iteration: 7650 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 192 loss: 1.47863 acc: 0.70020 | v_loss: 1.27881 v_acc: 0.71777 |  iteration: 7651 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 193 loss: 1.41451 acc: 0.70931 | v_loss: 1.28272 v_acc: 0.70671 |  iteration: 7652 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 194 loss: 1.43787 acc: 0.70410 | v_loss: 1.31468 v_acc: 0.73568 |  iteration: 7653 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 195 loss: 1.50157 acc: 0.69824 | v_loss: 1.29409 v_acc: 0.72168 |  iteration: 7654 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 196 loss: 1.65801 acc: 0.68327 | v_loss: 1.38798 v_acc: 0.74089 |  iteration: 7655 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 197 loss: 1.38182 acc: 0.70931 | v_loss: 1.33957 v_acc: 0.71452 |  iteration: 7656 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 198 loss: 1.50149 acc: 0.69303 | v_loss: 1.34472 v_acc: 0.71484 |  iteration: 7657 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 199 loss: 1.57385 acc: 0.69010 | v_loss: 1.43520 v_acc: 0.71094 |  iteration: 7658 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 200 loss: 1.49828 acc: 0.69596 | v_loss: 1.43002 v_acc: 0.71875 |  iteration: 7659 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 201 loss: 1.60358 acc: 0.68685 | v_loss: 1.53024 v_acc: 0.69629 |  iteration: 7660 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 202 loss: 1.50363 acc: 0.69922 | v_loss: 1.47297 v_acc: 0.72917 |  iteration: 7661 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 203 loss: 1.51098 acc: 0.69824 | v_loss: 1.23135 v_acc: 0.74219 |  iteration: 7662 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 204 loss: 1.39194 acc: 0.71419 | v_loss: 1.31931 v_acc: 0.70508 |  iteration: 7663 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 205 loss: 1.45741 acc: 0.70540 | v_loss: 1.54817 v_acc: 0.70443 |  iteration: 7664 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 206 loss: 1.45609 acc: 0.70443 | v_loss: 1.26189 v_acc: 0.70964 |  iteration: 7665 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 207 loss: 1.54032 acc: 0.69889 | v_loss: 1.36676 v_acc: 0.71159 |  iteration: 7666 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 208 loss: 1.48743 acc: 0.69531 | v_loss: 1.39627 v_acc: 0.69336 |  iteration: 7667 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 209 loss: 1.47673 acc: 0.69629 | v_loss: 1.30571 v_acc: 0.71842 |  iteration: 7668 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 210 loss: 1.47066 acc: 0.70150 | v_loss: 1.39422 v_acc: 0.70215 |  iteration: 7669 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 211 loss: 1.51128 acc: 0.70150 | v_loss: 1.51593 v_acc: 0.72005 |  iteration: 7670 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 212 loss: 1.38402 acc: 0.70703 | v_loss: 1.34983 v_acc: 0.72819 |  iteration: 7671 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 213 loss: 1.47435 acc: 0.70671 | v_loss: 1.47700 v_acc: 0.70443 |  iteration: 7672 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 214 loss: 1.49510 acc: 0.69661 | v_loss: 1.39939 v_acc: 0.69922 |  iteration: 7673 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 215 loss: 1.55417 acc: 0.69792 | v_loss: 1.36514 v_acc: 0.70898 |  iteration: 7674 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 216 loss: 1.46294 acc: 0.70085 | v_loss: 1.59265 v_acc: 0.68848 |  iteration: 7675 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 217 loss: 1.49019 acc: 0.69954 | v_loss: 1.36334 v_acc: 0.72201 |  iteration: 7676 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 218 loss: 1.53037 acc: 0.69564 | v_loss: 1.64755 v_acc: 0.68522 |  iteration: 7677 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 219 loss: 1.45936 acc: 0.70345 | v_loss: 1.51376 v_acc: 0.69401 |  iteration: 7678 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 220 loss: 1.45378 acc: 0.71061 | v_loss: 1.52747 v_acc: 0.68815 |  iteration: 7679 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 221 loss: 1.44936 acc: 0.70768 | v_loss: 1.42348 v_acc: 0.69792 |  iteration: 7680 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 222 loss: 1.53307 acc: 0.69238 | v_loss: 1.36561 v_acc: 0.70540 |  iteration: 7681 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 223 loss: 1.52467 acc: 0.70117 | v_loss: 1.37477 v_acc: 0.70117 |  iteration: 7682 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 224 loss: 1.54904 acc: 0.69727 | v_loss: 1.36332 v_acc: 0.71484 |  iteration: 7683 teacher: 0 stage: sketch lr: 0.000504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 225 loss: 1.54286 acc: 0.69271 | v_loss: 1.58676 v_acc: 0.68978 |  iteration: 7684 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 226 loss: 1.51786 acc: 0.69824 | v_loss: 1.43900 v_acc: 0.70768 |  iteration: 7685 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 227 loss: 1.48902 acc: 0.69759 | v_loss: 1.37623 v_acc: 0.70964 |  iteration: 7686 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 228 loss: 1.44211 acc: 0.70898 | v_loss: 1.40406 v_acc: 0.71680 |  iteration: 7687 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 229 loss: 1.39162 acc: 0.70247 | v_loss: 1.29960 v_acc: 0.70573 |  iteration: 7688 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 230 loss: 1.44336 acc: 0.69824 | v_loss: 1.46903 v_acc: 0.69727 |  iteration: 7689 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 231 loss: 1.51435 acc: 0.70280 | v_loss: 1.44903 v_acc: 0.71452 |  iteration: 7690 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 232 loss: 1.53452 acc: 0.69792 | v_loss: 1.32928 v_acc: 0.71615 |  iteration: 7691 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 233 loss: 1.45411 acc: 0.69499 | v_loss: 1.28154 v_acc: 0.72754 |  iteration: 7692 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 234 loss: 1.45811 acc: 0.69987 | v_loss: 1.40534 v_acc: 0.71289 |  iteration: 7693 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 235 loss: 1.41232 acc: 0.70410 | v_loss: 1.44236 v_acc: 0.70150 |  iteration: 7694 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 236 loss: 1.51149 acc: 0.69987 | v_loss: 1.45827 v_acc: 0.70215 |  iteration: 7695 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 237 loss: 1.44412 acc: 0.69889 | v_loss: 1.28345 v_acc: 0.71517 |  iteration: 7696 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 238 loss: 1.40829 acc: 0.70703 | v_loss: 1.40950 v_acc: 0.72493 |  iteration: 7697 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 239 loss: 1.45968 acc: 0.68945 | v_loss: 1.51873 v_acc: 0.69824 |  iteration: 7698 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 240 loss: 1.61483 acc: 0.69238 | v_loss: 1.49396 v_acc: 0.72103 |  iteration: 7699 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 241 loss: 1.56306 acc: 0.68522 | v_loss: 1.27562 v_acc: 0.71940 |  iteration: 7700 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 242 loss: 1.61244 acc: 0.69043 | v_loss: 1.23781 v_acc: 0.73535 |  iteration: 7701 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 243 loss: 1.43811 acc: 0.69922 | v_loss: 1.26187 v_acc: 0.72331 |  iteration: 7702 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 244 loss: 1.35790 acc: 0.70345 | v_loss: 1.31162 v_acc: 0.69922 |  iteration: 7703 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 245 loss: 1.45701 acc: 0.70117 | v_loss: 1.49976 v_acc: 0.69466 |  iteration: 7704 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 246 loss: 1.45447 acc: 0.69531 | v_loss: 1.30404 v_acc: 0.71517 |  iteration: 7705 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 247 loss: 1.48678 acc: 0.69466 | v_loss: 1.51343 v_acc: 0.68848 |  iteration: 7706 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 248 loss: 1.46961 acc: 0.69531 | v_loss: 1.74163 v_acc: 0.68913 |  iteration: 7707 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 249 loss: 1.43784 acc: 0.70443 | v_loss: 1.56556 v_acc: 0.69531 |  iteration: 7708 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 250 loss: 1.50990 acc: 0.70605 | v_loss: 1.33384 v_acc: 0.72526 |  iteration: 7709 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 251 loss: 1.51613 acc: 0.69954 | v_loss: 1.40459 v_acc: 0.70964 |  iteration: 7710 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 252 loss: 1.46999 acc: 0.69661 | v_loss: 1.25707 v_acc: 0.72103 |  iteration: 7711 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 253 loss: 1.43728 acc: 0.71191 | v_loss: 1.43267 v_acc: 0.70378 |  iteration: 7712 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 254 loss: 1.44789 acc: 0.70573 | v_loss: 1.42649 v_acc: 0.71354 |  iteration: 7713 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 255 loss: 1.47052 acc: 0.70345 | v_loss: 1.39369 v_acc: 0.72656 |  iteration: 7714 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 256 loss: 1.46724 acc: 0.70931 | v_loss: 1.40355 v_acc: 0.71680 |  iteration: 7715 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 257 loss: 1.47171 acc: 0.70150 | v_loss: 1.42351 v_acc: 0.70215 |  iteration: 7716 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 258 loss: 1.45013 acc: 0.70475 | v_loss: 1.33839 v_acc: 0.72266 |  iteration: 7717 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 259 loss: 1.52810 acc: 0.69629 | v_loss: 1.33250 v_acc: 0.71875 |  iteration: 7718 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 260 loss: 1.42538 acc: 0.71322 | v_loss: 1.54253 v_acc: 0.69108 |  iteration: 7719 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 261 loss: 1.51677 acc: 0.69336 | v_loss: 1.36728 v_acc: 0.71517 |  iteration: 7720 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 262 loss: 1.39417 acc: 0.70638 | v_loss: 1.30883 v_acc: 0.71517 |  iteration: 7721 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 263 loss: 1.46150 acc: 0.71126 | v_loss: 1.29386 v_acc: 0.71973 |  iteration: 7722 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 264 loss: 1.52244 acc: 0.68685 | v_loss: 1.43628 v_acc: 0.70638 |  iteration: 7723 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 265 loss: 1.49140 acc: 0.70768 | v_loss: 1.35323 v_acc: 0.73210 |  iteration: 7724 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 266 loss: 1.42308 acc: 0.70573 | v_loss: 1.53575 v_acc: 0.71126 |  iteration: 7725 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 267 loss: 1.48153 acc: 0.70182 | v_loss: 1.34731 v_acc: 0.69564 |  iteration: 7726 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 268 loss: 1.48232 acc: 0.70312 | v_loss: 1.32508 v_acc: 0.70052 |  iteration: 7727 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 269 loss: 1.51897 acc: 0.69564 | v_loss: 1.44977 v_acc: 0.70573 |  iteration: 7728 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 270 loss: 1.44712 acc: 0.70671 | v_loss: 1.47590 v_acc: 0.70443 |  iteration: 7729 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 271 loss: 1.42101 acc: 0.72363 | v_loss: 1.53341 v_acc: 0.68945 |  iteration: 7730 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 272 loss: 1.53145 acc: 0.68945 | v_loss: 1.49865 v_acc: 0.70638 |  iteration: 7731 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 273 loss: 1.40743 acc: 0.70801 | v_loss: 1.43907 v_acc: 0.70410 |  iteration: 7732 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 274 loss: 1.42566 acc: 0.69922 | v_loss: 1.44043 v_acc: 0.70736 |  iteration: 7733 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 275 loss: 1.41052 acc: 0.70671 | v_loss: 1.41676 v_acc: 0.70638 |  iteration: 7734 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 276 loss: 1.39721 acc: 0.70410 | v_loss: 1.28290 v_acc: 0.71224 |  iteration: 7735 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 277 loss: 1.39971 acc: 0.70573 | v_loss: 1.37463 v_acc: 0.71908 |  iteration: 7736 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 278 loss: 1.48694 acc: 0.70573 | v_loss: 1.17220 v_acc: 0.71452 |  iteration: 7737 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 279 loss: 1.37914 acc: 0.71517 | v_loss: 1.35748 v_acc: 0.71126 |  iteration: 7738 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 280 loss: 1.45465 acc: 0.70150 | v_loss: 1.52417 v_acc: 0.69987 |  iteration: 7739 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 281 loss: 1.57430 acc: 0.68978 | v_loss: 1.34401 v_acc: 0.70833 |  iteration: 7740 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 282 loss: 1.44265 acc: 0.70345 | v_loss: 1.39003 v_acc: 0.69336 |  iteration: 7741 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 283 loss: 1.47740 acc: 0.70605 | v_loss: 1.31409 v_acc: 0.70931 |  iteration: 7742 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 284 loss: 1.63452 acc: 0.69173 | v_loss: 1.34495 v_acc: 0.69987 |  iteration: 7743 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 285 loss: 1.41952 acc: 0.71061 | v_loss: 1.26075 v_acc: 0.73568 |  iteration: 7744 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 286 loss: 1.43928 acc: 0.71224 | v_loss: 1.32315 v_acc: 0.71452 |  iteration: 7745 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 287 loss: 1.54255 acc: 0.68913 | v_loss: 1.36415 v_acc: 0.73438 |  iteration: 7746 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 288 loss: 1.45221 acc: 0.70215 | v_loss: 1.31851 v_acc: 0.71452 |  iteration: 7747 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 289 loss: 1.50830 acc: 0.70182 | v_loss: 1.33031 v_acc: 0.71484 |  iteration: 7748 teacher: 1 stage: sketch lr: 0.000502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 290 loss: 1.48478 acc: 0.71061 | v_loss: 1.42918 v_acc: 0.71094 |  iteration: 7749 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 291 loss: 1.46578 acc: 0.69922 | v_loss: 1.40119 v_acc: 0.72038 |  iteration: 7750 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 292 loss: 1.38655 acc: 0.71029 | v_loss: 1.49812 v_acc: 0.69661 |  iteration: 7751 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 293 loss: 1.40195 acc: 0.71224 | v_loss: 1.45202 v_acc: 0.71615 |  iteration: 7752 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 294 loss: 1.48438 acc: 0.70280 | v_loss: 1.19527 v_acc: 0.74544 |  iteration: 7753 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 295 loss: 1.47987 acc: 0.69954 | v_loss: 1.27983 v_acc: 0.70931 |  iteration: 7754 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 296 loss: 1.47968 acc: 0.69336 | v_loss: 1.56194 v_acc: 0.68783 |  iteration: 7755 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 297 loss: 1.54223 acc: 0.69303 | v_loss: 1.27987 v_acc: 0.69531 |  iteration: 7756 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 298 loss: 1.41146 acc: 0.70052 | v_loss: 1.35873 v_acc: 0.70605 |  iteration: 7757 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 299 loss: 1.53566 acc: 0.68945 | v_loss: 1.38936 v_acc: 0.69824 |  iteration: 7758 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 300 loss: 1.45410 acc: 0.69043 | v_loss: 1.35040 v_acc: 0.70964 |  iteration: 7759 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 301 loss: 1.49939 acc: 0.69792 | v_loss: 1.40968 v_acc: 0.69401 |  iteration: 7760 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 302 loss: 1.53324 acc: 0.69466 | v_loss: 1.48711 v_acc: 0.71061 |  iteration: 7761 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 303 loss: 1.47262 acc: 0.69922 | v_loss: 1.33935 v_acc: 0.72201 |  iteration: 7762 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 304 loss: 1.40243 acc: 0.70605 | v_loss: 1.45344 v_acc: 0.70117 |  iteration: 7763 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 305 loss: 1.41182 acc: 0.70312 | v_loss: 1.42510 v_acc: 0.69922 |  iteration: 7764 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 306 loss: 1.55652 acc: 0.69238 | v_loss: 1.35829 v_acc: 0.70898 |  iteration: 7765 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 307 loss: 1.45767 acc: 0.71094 | v_loss: 1.57876 v_acc: 0.68815 |  iteration: 7766 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 308 loss: 1.45636 acc: 0.69987 | v_loss: 1.33788 v_acc: 0.72005 |  iteration: 7767 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 309 loss: 1.43296 acc: 0.71159 | v_loss: 1.60618 v_acc: 0.68620 |  iteration: 7768 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 310 loss: 1.37739 acc: 0.71159 | v_loss: 1.44719 v_acc: 0.69987 |  iteration: 7769 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 311 loss: 1.47987 acc: 0.70638 | v_loss: 1.52318 v_acc: 0.68750 |  iteration: 7770 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 312 loss: 1.48288 acc: 0.69661 | v_loss: 1.39952 v_acc: 0.69759 |  iteration: 7771 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 313 loss: 1.49668 acc: 0.69954 | v_loss: 1.34679 v_acc: 0.70703 |  iteration: 7772 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 314 loss: 1.45204 acc: 0.70475 | v_loss: 1.35963 v_acc: 0.70247 |  iteration: 7773 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 315 loss: 1.46946 acc: 0.69792 | v_loss: 1.37078 v_acc: 0.71387 |  iteration: 7774 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 316 loss: 1.46347 acc: 0.69434 | v_loss: 1.59242 v_acc: 0.68783 |  iteration: 7775 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 317 loss: 1.43426 acc: 0.70182 | v_loss: 1.43149 v_acc: 0.70996 |  iteration: 7776 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 318 loss: 1.41284 acc: 0.70182 | v_loss: 1.34877 v_acc: 0.71257 |  iteration: 7777 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 319 loss: 1.46887 acc: 0.69954 | v_loss: 1.40302 v_acc: 0.71419 |  iteration: 7778 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 320 loss: 1.45083 acc: 0.70898 | v_loss: 1.30764 v_acc: 0.70280 |  iteration: 7779 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 321 loss: 1.51077 acc: 0.69792 | v_loss: 1.46735 v_acc: 0.70117 |  iteration: 7780 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 322 loss: 1.46178 acc: 0.70020 | v_loss: 1.42620 v_acc: 0.71842 |  iteration: 7781 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 323 loss: 1.51928 acc: 0.69889 | v_loss: 1.34161 v_acc: 0.71615 |  iteration: 7782 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 324 loss: 1.52476 acc: 0.69824 | v_loss: 1.26993 v_acc: 0.72591 |  iteration: 7783 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 325 loss: 1.47914 acc: 0.70312 | v_loss: 1.39473 v_acc: 0.71549 |  iteration: 7784 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 326 loss: 1.45166 acc: 0.70312 | v_loss: 1.43467 v_acc: 0.70052 |  iteration: 7785 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 327 loss: 1.38437 acc: 0.70898 | v_loss: 1.43928 v_acc: 0.70345 |  iteration: 7786 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 328 loss: 1.55119 acc: 0.69531 | v_loss: 1.24687 v_acc: 0.72624 |  iteration: 7787 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 329 loss: 1.53609 acc: 0.69466 | v_loss: 1.41313 v_acc: 0.72852 |  iteration: 7788 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 330 loss: 1.63675 acc: 0.67936 | v_loss: 1.49644 v_acc: 0.69499 |  iteration: 7789 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 331 loss: 1.49652 acc: 0.69661 | v_loss: 1.48255 v_acc: 0.71745 |  iteration: 7790 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 332 loss: 1.54827 acc: 0.69694 | v_loss: 1.27340 v_acc: 0.72103 |  iteration: 7791 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 333 loss: 1.52783 acc: 0.69499 | v_loss: 1.25348 v_acc: 0.73470 |  iteration: 7792 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 334 loss: 1.42435 acc: 0.70768 | v_loss: 1.26580 v_acc: 0.72949 |  iteration: 7793 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 335 loss: 1.49498 acc: 0.69434 | v_loss: 1.36128 v_acc: 0.70410 |  iteration: 7794 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 336 loss: 1.45872 acc: 0.70996 | v_loss: 1.49708 v_acc: 0.69531 |  iteration: 7795 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 337 loss: 1.45277 acc: 0.69661 | v_loss: 1.32823 v_acc: 0.71191 |  iteration: 7796 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 338 loss: 1.48261 acc: 0.70573 | v_loss: 1.45715 v_acc: 0.72656 |  iteration: 7797 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 339 loss: 1.45941 acc: 0.69173 | v_loss: 1.68933 v_acc: 0.69303 |  iteration: 7798 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 340 loss: 1.47007 acc: 0.70736 | v_loss: 1.56200 v_acc: 0.69727 |  iteration: 7799 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 341 loss: 1.48331 acc: 0.70703 | v_loss: 1.32440 v_acc: 0.72526 |  iteration: 7800 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 342 loss: 1.45241 acc: 0.70508 | v_loss: 1.40663 v_acc: 0.70964 |  iteration: 7801 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 343 loss: 1.48461 acc: 0.69499 | v_loss: 1.24920 v_acc: 0.72103 |  iteration: 7802 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 344 loss: 1.54664 acc: 0.69206 | v_loss: 1.43597 v_acc: 0.70085 |  iteration: 7803 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 345 loss: 1.44421 acc: 0.70833 | v_loss: 1.38326 v_acc: 0.70964 |  iteration: 7804 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 346 loss: 1.58960 acc: 0.68587 | v_loss: 1.38643 v_acc: 0.72852 |  iteration: 7805 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 347 loss: 1.47584 acc: 0.70508 | v_loss: 1.37500 v_acc: 0.71842 |  iteration: 7806 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 348 loss: 1.43040 acc: 0.70866 | v_loss: 1.41938 v_acc: 0.69922 |  iteration: 7807 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 349 loss: 1.44503 acc: 0.70605 | v_loss: 1.34704 v_acc: 0.72266 |  iteration: 7808 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 350 loss: 1.38649 acc: 0.70996 | v_loss: 1.33812 v_acc: 0.71875 |  iteration: 7809 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 351 loss: 1.55047 acc: 0.69824 | v_loss: 1.57923 v_acc: 0.68555 |  iteration: 7810 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 352 loss: 1.42885 acc: 0.69954 | v_loss: 1.35192 v_acc: 0.70931 |  iteration: 7811 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 353 loss: 1.47670 acc: 0.69889 | v_loss: 1.31170 v_acc: 0.71582 |  iteration: 7812 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 354 loss: 1.32987 acc: 0.71810 | v_loss: 1.30515 v_acc: 0.71484 |  iteration: 7813 teacher: 0 stage: sketch lr: 0.000500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 355 loss: 1.50752 acc: 0.70280 | v_loss: 1.49282 v_acc: 0.70671 |  iteration: 7814 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 356 loss: 1.49759 acc: 0.70443 | v_loss: 1.34599 v_acc: 0.73210 |  iteration: 7815 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 357 loss: 1.51692 acc: 0.69303 | v_loss: 1.59445 v_acc: 0.71647 |  iteration: 7816 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 358 loss: 1.46372 acc: 0.70085 | v_loss: 1.31322 v_acc: 0.69987 |  iteration: 7817 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 359 loss: 1.51547 acc: 0.69857 | v_loss: 1.30955 v_acc: 0.70312 |  iteration: 7818 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 360 loss: 1.50742 acc: 0.70280 | v_loss: 1.44737 v_acc: 0.70703 |  iteration: 7819 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 361 loss: 1.56187 acc: 0.69401 | v_loss: 1.47589 v_acc: 0.70638 |  iteration: 7820 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 362 loss: 1.55785 acc: 0.69238 | v_loss: 1.52942 v_acc: 0.68815 |  iteration: 7821 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 363 loss: 1.53989 acc: 0.69173 | v_loss: 1.49327 v_acc: 0.70247 |  iteration: 7822 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 364 loss: 1.49321 acc: 0.69010 | v_loss: 1.44490 v_acc: 0.70671 |  iteration: 7823 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 365 loss: 1.41717 acc: 0.71159 | v_loss: 1.44202 v_acc: 0.70475 |  iteration: 7824 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 366 loss: 1.43174 acc: 0.70540 | v_loss: 1.43915 v_acc: 0.70312 |  iteration: 7825 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 367 loss: 1.52594 acc: 0.70085 | v_loss: 1.28667 v_acc: 0.71257 |  iteration: 7826 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 368 loss: 1.46137 acc: 0.70768 | v_loss: 1.35450 v_acc: 0.72461 |  iteration: 7827 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 369 loss: 1.49147 acc: 0.70215 | v_loss: 1.17997 v_acc: 0.71517 |  iteration: 7828 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 370 loss: 1.50688 acc: 0.70475 | v_loss: 1.37097 v_acc: 0.70801 |  iteration: 7829 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 371 loss: 1.46015 acc: 0.70475 | v_loss: 1.54461 v_acc: 0.69954 |  iteration: 7830 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 372 loss: 1.53479 acc: 0.69987 | v_loss: 1.35420 v_acc: 0.70703 |  iteration: 7831 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 373 loss: 1.45525 acc: 0.70898 | v_loss: 1.38526 v_acc: 0.69368 |  iteration: 7832 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 374 loss: 1.47431 acc: 0.70573 | v_loss: 1.30326 v_acc: 0.70573 |  iteration: 7833 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 375 loss: 1.59079 acc: 0.68652 | v_loss: 1.29301 v_acc: 0.70508 |  iteration: 7834 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 376 loss: 1.38954 acc: 0.71452 | v_loss: 1.26826 v_acc: 0.73861 |  iteration: 7835 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 377 loss: 1.46009 acc: 0.71061 | v_loss: 1.33152 v_acc: 0.71810 |  iteration: 7836 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 378 loss: 1.42630 acc: 0.71289 | v_loss: 1.36864 v_acc: 0.73112 |  iteration: 7837 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 379 loss: 1.55295 acc: 0.68783 | v_loss: 1.31680 v_acc: 0.71452 |  iteration: 7838 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 380 loss: 1.38869 acc: 0.71973 | v_loss: 1.32460 v_acc: 0.71484 |  iteration: 7839 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 381 loss: 1.40285 acc: 0.70247 | v_loss: 1.42394 v_acc: 0.71224 |  iteration: 7840 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 382 loss: 1.47607 acc: 0.70508 | v_loss: 1.39207 v_acc: 0.72038 |  iteration: 7841 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 383 loss: 1.37487 acc: 0.70996 | v_loss: 1.50033 v_acc: 0.69889 |  iteration: 7842 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 384 loss: 1.38339 acc: 0.70605 | v_loss: 1.45870 v_acc: 0.71777 |  iteration: 7843 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 385 loss: 1.45236 acc: 0.69922 | v_loss: 1.19829 v_acc: 0.74414 |  iteration: 7844 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 386 loss: 1.45593 acc: 0.69238 | v_loss: 1.26120 v_acc: 0.71159 |  iteration: 7845 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 387 loss: 1.39380 acc: 0.70964 | v_loss: 1.57485 v_acc: 0.69368 |  iteration: 7846 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 388 loss: 1.44117 acc: 0.69889 | v_loss: 1.22926 v_acc: 0.70866 |  iteration: 7847 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 389 loss: 1.54493 acc: 0.68815 | v_loss: 1.34651 v_acc: 0.71191 |  iteration: 7848 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 390 loss: 1.41230 acc: 0.70573 | v_loss: 1.37792 v_acc: 0.69076 |  iteration: 7849 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 391 loss: 1.44077 acc: 0.70768 | v_loss: 1.32965 v_acc: 0.70898 |  iteration: 7850 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 392 loss: 1.45480 acc: 0.70117 | v_loss: 1.40416 v_acc: 0.69206 |  iteration: 7851 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 393 loss: 1.39673 acc: 0.70671 | v_loss: 1.47152 v_acc: 0.70931 |  iteration: 7852 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 394 loss: 1.59078 acc: 0.69727 | v_loss: 1.32996 v_acc: 0.72363 |  iteration: 7853 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 395 loss: 1.44561 acc: 0.70931 | v_loss: 1.44286 v_acc: 0.70117 |  iteration: 7854 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 396 loss: 1.42192 acc: 0.70410 | v_loss: 1.39620 v_acc: 0.70085 |  iteration: 7855 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 397 loss: 1.53301 acc: 0.69206 | v_loss: 1.34883 v_acc: 0.70736 |  iteration: 7856 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 398 loss: 1.49052 acc: 0.70443 | v_loss: 1.57168 v_acc: 0.68815 |  iteration: 7857 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 399 loss: 1.48216 acc: 0.69271 | v_loss: 1.32074 v_acc: 0.72103 |  iteration: 7858 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 400 loss: 1.40734 acc: 0.70540 | v_loss: 1.61318 v_acc: 0.67969 |  iteration: 7859 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 401 loss: 1.50318 acc: 0.69173 | v_loss: 1.49636 v_acc: 0.69661 |  iteration: 7860 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 402 loss: 1.41086 acc: 0.70312 | v_loss: 1.53896 v_acc: 0.69238 |  iteration: 7861 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 403 loss: 1.45316 acc: 0.69727 | v_loss: 1.39019 v_acc: 0.69954 |  iteration: 7862 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 404 loss: 1.32843 acc: 0.71061 | v_loss: 1.35339 v_acc: 0.70540 |  iteration: 7863 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 405 loss: 1.52271 acc: 0.69401 | v_loss: 1.34937 v_acc: 0.70117 |  iteration: 7864 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 406 loss: 1.52624 acc: 0.69076 | v_loss: 1.35910 v_acc: 0.71419 |  iteration: 7865 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 407 loss: 1.48682 acc: 0.69954 | v_loss: 1.55023 v_acc: 0.68978 |  iteration: 7866 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 408 loss: 1.30730 acc: 0.71484 | v_loss: 1.40433 v_acc: 0.70443 |  iteration: 7867 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 409 loss: 1.42169 acc: 0.70508 | v_loss: 1.36017 v_acc: 0.71029 |  iteration: 7868 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 410 loss: 1.40841 acc: 0.71061 | v_loss: 1.40015 v_acc: 0.71680 |  iteration: 7869 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 411 loss: 1.42107 acc: 0.69759 | v_loss: 1.28854 v_acc: 0.70801 |  iteration: 7870 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 412 loss: 1.55946 acc: 0.69596 | v_loss: 1.47648 v_acc: 0.69792 |  iteration: 7871 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 413 loss: 1.57572 acc: 0.68815 | v_loss: 1.44347 v_acc: 0.71289 |  iteration: 7872 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 414 loss: 1.51547 acc: 0.69759 | v_loss: 1.31648 v_acc: 0.71647 |  iteration: 7873 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 415 loss: 1.42024 acc: 0.70443 | v_loss: 1.27003 v_acc: 0.72591 |  iteration: 7874 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 416 loss: 1.38620 acc: 0.71745 | v_loss: 1.38769 v_acc: 0.71452 |  iteration: 7875 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 417 loss: 1.39314 acc: 0.69727 | v_loss: 1.42132 v_acc: 0.70605 |  iteration: 7876 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 418 loss: 1.51343 acc: 0.69889 | v_loss: 1.44041 v_acc: 0.70410 |  iteration: 7877 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 419 loss: 1.34005 acc: 0.70443 | v_loss: 1.26120 v_acc: 0.71452 |  iteration: 7878 teacher: 1 stage: sketch lr: 0.000498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 420 loss: 1.45427 acc: 0.70247 | v_loss: 1.40389 v_acc: 0.73177 |  iteration: 7879 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 421 loss: 1.39054 acc: 0.70443 | v_loss: 1.49135 v_acc: 0.69661 |  iteration: 7880 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 422 loss: 1.40396 acc: 0.70540 | v_loss: 1.45700 v_acc: 0.71908 |  iteration: 7881 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 423 loss: 1.36770 acc: 0.70703 | v_loss: 1.25966 v_acc: 0.71908 |  iteration: 7882 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 424 loss: 1.43023 acc: 0.69564 | v_loss: 1.20032 v_acc: 0.73861 |  iteration: 7883 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 425 loss: 1.53284 acc: 0.69824 | v_loss: 1.22673 v_acc: 0.72493 |  iteration: 7884 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 426 loss: 1.46371 acc: 0.69499 | v_loss: 1.30576 v_acc: 0.70638 |  iteration: 7885 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 427 loss: 1.48114 acc: 0.70020 | v_loss: 1.46154 v_acc: 0.69499 |  iteration: 7886 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 428 loss: 1.51441 acc: 0.69303 | v_loss: 1.31167 v_acc: 0.71484 |  iteration: 7887 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 429 loss: 1.40378 acc: 0.71387 | v_loss: 1.46088 v_acc: 0.72949 |  iteration: 7888 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 430 loss: 1.48073 acc: 0.69271 | v_loss: 1.63851 v_acc: 0.69466 |  iteration: 7889 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 431 loss: 1.48358 acc: 0.70182 | v_loss: 1.51579 v_acc: 0.70410 |  iteration: 7890 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 432 loss: 1.43508 acc: 0.69434 | v_loss: 1.32814 v_acc: 0.72005 |  iteration: 7891 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 433 loss: 1.43619 acc: 0.71094 | v_loss: 1.38343 v_acc: 0.69987 |  iteration: 7892 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 434 loss: 1.48832 acc: 0.69694 | v_loss: 1.24866 v_acc: 0.71615 |  iteration: 7893 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 435 loss: 1.46915 acc: 0.70866 | v_loss: 1.43122 v_acc: 0.69954 |  iteration: 7894 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 436 loss: 1.58660 acc: 0.69336 | v_loss: 1.37209 v_acc: 0.71094 |  iteration: 7895 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 437 loss: 1.42157 acc: 0.69954 | v_loss: 1.37589 v_acc: 0.72819 |  iteration: 7896 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 438 loss: 1.53871 acc: 0.70117 | v_loss: 1.39349 v_acc: 0.71484 |  iteration: 7897 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 439 loss: 1.42331 acc: 0.70247 | v_loss: 1.38937 v_acc: 0.70866 |  iteration: 7898 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 440 loss: 1.50973 acc: 0.69531 | v_loss: 1.31123 v_acc: 0.72201 |  iteration: 7899 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 441 loss: 1.45025 acc: 0.69564 | v_loss: 1.31753 v_acc: 0.72201 |  iteration: 7900 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 442 loss: 1.46491 acc: 0.70085 | v_loss: 1.52133 v_acc: 0.69303 |  iteration: 7901 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 443 loss: 1.55576 acc: 0.69759 | v_loss: 1.35237 v_acc: 0.71159 |  iteration: 7902 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 444 loss: 1.47277 acc: 0.69531 | v_loss: 1.33476 v_acc: 0.71549 |  iteration: 7903 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 445 loss: 1.42704 acc: 0.70312 | v_loss: 1.31971 v_acc: 0.71973 |  iteration: 7904 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 446 loss: 1.48595 acc: 0.70866 | v_loss: 1.45100 v_acc: 0.70573 |  iteration: 7905 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 447 loss: 1.54785 acc: 0.68913 | v_loss: 1.32852 v_acc: 0.73112 |  iteration: 7906 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 448 loss: 1.40380 acc: 0.71061 | v_loss: 1.53698 v_acc: 0.71615 |  iteration: 7907 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 449 loss: 1.46010 acc: 0.70345 | v_loss: 1.31218 v_acc: 0.69759 |  iteration: 7908 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 450 loss: 1.37030 acc: 0.70768 | v_loss: 1.30421 v_acc: 0.70215 |  iteration: 7909 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 451 loss: 1.42989 acc: 0.70736 | v_loss: 1.45923 v_acc: 0.70312 |  iteration: 7910 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 452 loss: 1.47552 acc: 0.70312 | v_loss: 1.48829 v_acc: 0.70378 |  iteration: 7911 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 453 loss: 1.38373 acc: 0.70736 | v_loss: 1.53523 v_acc: 0.69368 |  iteration: 7912 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 454 loss: 1.48677 acc: 0.70182 | v_loss: 1.49572 v_acc: 0.70898 |  iteration: 7913 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 455 loss: 1.36401 acc: 0.70898 | v_loss: 1.45665 v_acc: 0.69759 |  iteration: 7914 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 456 loss: 1.40242 acc: 0.70508 | v_loss: 1.43384 v_acc: 0.71126 |  iteration: 7915 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 457 loss: 1.48059 acc: 0.70150 | v_loss: 1.41499 v_acc: 0.70703 |  iteration: 7916 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 458 loss: 1.47842 acc: 0.69759 | v_loss: 1.28155 v_acc: 0.71289 |  iteration: 7917 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 459 loss: 1.41102 acc: 0.70312 | v_loss: 1.34152 v_acc: 0.72493 |  iteration: 7918 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 460 loss: 1.40782 acc: 0.70508 | v_loss: 1.24622 v_acc: 0.70605 |  iteration: 7919 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 461 loss: 1.42101 acc: 0.70117 | v_loss: 1.36868 v_acc: 0.69987 |  iteration: 7920 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 462 loss: 1.42877 acc: 0.70280 | v_loss: 1.51028 v_acc: 0.69564 |  iteration: 7921 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 463 loss: 1.43872 acc: 0.70540 | v_loss: 1.37811 v_acc: 0.70443 |  iteration: 7922 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 464 loss: 1.46170 acc: 0.70638 | v_loss: 1.36865 v_acc: 0.69368 |  iteration: 7923 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 465 loss: 1.47370 acc: 0.69889 | v_loss: 1.27282 v_acc: 0.71126 |  iteration: 7924 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 466 loss: 1.35590 acc: 0.70801 | v_loss: 1.25997 v_acc: 0.70671 |  iteration: 7925 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 467 loss: 1.43764 acc: 0.71549 | v_loss: 1.26907 v_acc: 0.73568 |  iteration: 7926 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 468 loss: 1.45065 acc: 0.70182 | v_loss: 1.28179 v_acc: 0.72461 |  iteration: 7927 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 469 loss: 1.55996 acc: 0.69499 | v_loss: 1.33145 v_acc: 0.72689 |  iteration: 7928 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 470 loss: 1.44499 acc: 0.70020 | v_loss: 1.28440 v_acc: 0.72461 |  iteration: 7929 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 471 loss: 1.54413 acc: 0.69564 | v_loss: 1.31769 v_acc: 0.71582 |  iteration: 7930 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 472 loss: 1.36363 acc: 0.70996 | v_loss: 1.41189 v_acc: 0.71224 |  iteration: 7931 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 473 loss: 1.38486 acc: 0.71680 | v_loss: 1.39317 v_acc: 0.72038 |  iteration: 7932 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 474 loss: 1.42712 acc: 0.70898 | v_loss: 1.51606 v_acc: 0.69759 |  iteration: 7933 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 475 loss: 1.46917 acc: 0.69954 | v_loss: 1.42083 v_acc: 0.71940 |  iteration: 7934 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 476 loss: 1.46256 acc: 0.71126 | v_loss: 1.19270 v_acc: 0.74154 |  iteration: 7935 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 477 loss: 1.46660 acc: 0.69759 | v_loss: 1.27691 v_acc: 0.70150 |  iteration: 7936 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 478 loss: 1.37108 acc: 0.70345 | v_loss: 1.54476 v_acc: 0.70247 |  iteration: 7937 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 479 loss: 1.38028 acc: 0.70117 | v_loss: 1.22644 v_acc: 0.70833 |  iteration: 7938 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 480 loss: 1.59022 acc: 0.69954 | v_loss: 1.35021 v_acc: 0.71257 |  iteration: 7939 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 481 loss: 1.50544 acc: 0.70117 | v_loss: 1.39285 v_acc: 0.69368 |  iteration: 7940 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 482 loss: 1.49310 acc: 0.69661 | v_loss: 1.31606 v_acc: 0.71842 |  iteration: 7941 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 483 loss: 1.51495 acc: 0.69889 | v_loss: 1.39767 v_acc: 0.69629 |  iteration: 7942 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 484 loss: 1.46602 acc: 0.69661 | v_loss: 1.46414 v_acc: 0.71387 |  iteration: 7943 teacher: 1 stage: sketch lr: 0.000496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 485 loss: 1.42550 acc: 0.70052 | v_loss: 1.34771 v_acc: 0.72396 |  iteration: 7944 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 486 loss: 1.39133 acc: 0.71094 | v_loss: 1.43746 v_acc: 0.70801 |  iteration: 7945 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 487 loss: 1.46865 acc: 0.69987 | v_loss: 1.41034 v_acc: 0.69922 |  iteration: 7946 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 488 loss: 1.48903 acc: 0.69792 | v_loss: 1.35013 v_acc: 0.70605 |  iteration: 7947 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 489 loss: 1.42411 acc: 0.70410 | v_loss: 1.56812 v_acc: 0.68848 |  iteration: 7948 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 490 loss: 1.39367 acc: 0.71029 | v_loss: 1.31196 v_acc: 0.72135 |  iteration: 7949 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 491 loss: 1.45351 acc: 0.70671 | v_loss: 1.59790 v_acc: 0.68620 |  iteration: 7950 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 492 loss: 1.45898 acc: 0.70150 | v_loss: 1.46766 v_acc: 0.69792 |  iteration: 7951 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 493 loss: 1.48116 acc: 0.69987 | v_loss: 1.54839 v_acc: 0.69173 |  iteration: 7952 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 494 loss: 1.39942 acc: 0.69792 | v_loss: 1.38832 v_acc: 0.70020 |  iteration: 7953 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 495 loss: 1.48364 acc: 0.69466 | v_loss: 1.34498 v_acc: 0.70475 |  iteration: 7954 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 496 loss: 1.52499 acc: 0.69629 | v_loss: 1.35702 v_acc: 0.70020 |  iteration: 7955 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 497 loss: 1.40720 acc: 0.69303 | v_loss: 1.34891 v_acc: 0.71842 |  iteration: 7956 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 498 loss: 1.47995 acc: 0.69303 | v_loss: 1.58180 v_acc: 0.69108 |  iteration: 7957 teacher: 1 stage: sketch lr: 0.000495\n",
      "batch 499 loss: 1.47551 acc: 0.69824 | v_loss: 1.41551 v_acc: 0.71289 |  iteration: 7958 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 500 loss: 1.45231 acc: 0.70443 | v_loss: 1.33854 v_acc: 0.71061 |  iteration: 7959 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 501 loss: 1.41769 acc: 0.70150 | v_loss: 1.39715 v_acc: 0.71224 |  iteration: 7960 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 502 loss: 1.46456 acc: 0.69434 | v_loss: 1.28915 v_acc: 0.70736 |  iteration: 7961 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 503 loss: 1.43740 acc: 0.70182 | v_loss: 1.44925 v_acc: 0.70117 |  iteration: 7962 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 504 loss: 1.47260 acc: 0.70085 | v_loss: 1.42851 v_acc: 0.71842 |  iteration: 7963 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 505 loss: 1.50210 acc: 0.69238 | v_loss: 1.33985 v_acc: 0.71680 |  iteration: 7964 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 506 loss: 1.46247 acc: 0.70020 | v_loss: 1.26041 v_acc: 0.73047 |  iteration: 7965 teacher: 1 stage: sketch lr: 0.000495\n",
      "batch 507 loss: 1.49230 acc: 0.69759 | v_loss: 1.38427 v_acc: 0.71517 |  iteration: 7966 teacher: 1 stage: sketch lr: 0.000495\n",
      "batch 508 loss: 1.49932 acc: 0.69238 | v_loss: 1.43141 v_acc: 0.70150 |  iteration: 7967 teacher: 1 stage: sketch lr: 0.000495\n",
      "batch 509 loss: 1.49764 acc: 0.70182 | v_loss: 1.44599 v_acc: 0.70312 |  iteration: 7968 teacher: 1 stage: sketch lr: 0.000495\n",
      "batch 510 loss: 1.40705 acc: 0.71191 | v_loss: 1.25168 v_acc: 0.71712 |  iteration: 7969 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 511 loss: 1.33350 acc: 0.72070 | v_loss: 1.40551 v_acc: 0.73112 |  iteration: 7970 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 512 loss: 1.43254 acc: 0.71257 | v_loss: 1.50109 v_acc: 0.69759 |  iteration: 7971 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 513 loss: 1.52365 acc: 0.68945 | v_loss: 1.45881 v_acc: 0.72201 |  iteration: 7972 teacher: 1 stage: sketch lr: 0.000495\n",
      "batch 514 loss: 1.46707 acc: 0.70605 | v_loss: 1.27428 v_acc: 0.72201 |  iteration: 7973 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 515 loss: 1.47222 acc: 0.69889 | v_loss: 1.24009 v_acc: 0.73633 |  iteration: 7974 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 516 loss: 1.49984 acc: 0.69987 | v_loss: 1.24193 v_acc: 0.72233 |  iteration: 7975 teacher: 1 stage: sketch lr: 0.000495\n",
      "batch 517 loss: 1.52609 acc: 0.69076 | v_loss: 1.32762 v_acc: 0.70345 |  iteration: 7976 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 518 loss: 1.44728 acc: 0.69499 | v_loss: 1.49965 v_acc: 0.69564 |  iteration: 7977 teacher: 1 stage: sketch lr: 0.000495\n",
      "batch 519 loss: 1.62450 acc: 0.68392 | v_loss: 1.29901 v_acc: 0.70931 |  iteration: 7978 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 520 loss: 1.51568 acc: 0.70182 | v_loss: 1.44650 v_acc: 0.71257 |  iteration: 7979 teacher: 1 stage: sketch lr: 0.000495\n",
      "batch 521 loss: 1.53364 acc: 0.70573 | v_loss: 1.64486 v_acc: 0.69271 |  iteration: 7980 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 522 loss: 1.44933 acc: 0.69759 | v_loss: 1.51473 v_acc: 0.70410 |  iteration: 7981 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 523 loss: 1.47699 acc: 0.70866 | v_loss: 1.32920 v_acc: 0.72266 |  iteration: 7982 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 524 loss: 1.47181 acc: 0.70736 | v_loss: 1.40045 v_acc: 0.70378 |  iteration: 7983 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 525 loss: 1.55361 acc: 0.70378 | v_loss: 1.27111 v_acc: 0.71615 |  iteration: 7984 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 526 loss: 1.43987 acc: 0.69824 | v_loss: 1.45770 v_acc: 0.69857 |  iteration: 7985 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 527 loss: 1.40845 acc: 0.71159 | v_loss: 1.37620 v_acc: 0.70964 |  iteration: 7986 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 528 loss: 1.39970 acc: 0.70638 | v_loss: 1.38116 v_acc: 0.72949 |  iteration: 7987 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 529 loss: 1.48642 acc: 0.69987 | v_loss: 1.36861 v_acc: 0.71680 |  iteration: 7988 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 530 loss: 1.47747 acc: 0.69857 | v_loss: 1.39657 v_acc: 0.70345 |  iteration: 7989 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 531 loss: 1.37791 acc: 0.70280 | v_loss: 1.33930 v_acc: 0.72201 |  iteration: 7990 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 532 loss: 1.48037 acc: 0.70182 | v_loss: 1.33546 v_acc: 0.72005 |  iteration: 7991 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 533 loss: 1.34335 acc: 0.71224 | v_loss: 1.58585 v_acc: 0.69043 |  iteration: 7992 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 534 loss: 1.50506 acc: 0.70052 | v_loss: 1.34373 v_acc: 0.71159 |  iteration: 7993 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 535 loss: 1.44865 acc: 0.69889 | v_loss: 1.30991 v_acc: 0.71615 |  iteration: 7994 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 536 loss: 1.41878 acc: 0.69629 | v_loss: 1.30594 v_acc: 0.71875 |  iteration: 7995 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 537 loss: 1.41685 acc: 0.69954 | v_loss: 1.46304 v_acc: 0.70410 |  iteration: 7996 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 538 loss: 1.42390 acc: 0.70378 | v_loss: 1.32548 v_acc: 0.73210 |  iteration: 7997 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 539 loss: 1.39178 acc: 0.70182 | v_loss: 1.54038 v_acc: 0.71322 |  iteration: 7998 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 540 loss: 1.30778 acc: 0.70573 | v_loss: 1.30382 v_acc: 0.69531 |  iteration: 7999 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 541 loss: 1.48748 acc: 0.69336 | v_loss: 1.29641 v_acc: 0.70020 |  iteration: 8000 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 542 loss: 1.34777 acc: 0.70638 | v_loss: 1.46362 v_acc: 0.70378 |  iteration: 8001 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 543 loss: 1.54710 acc: 0.69141 | v_loss: 1.49117 v_acc: 0.70378 |  iteration: 8002 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 544 loss: 1.45769 acc: 0.69173 | v_loss: 1.53798 v_acc: 0.69076 |  iteration: 8003 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 545 loss: 1.38753 acc: 0.70964 | v_loss: 1.47822 v_acc: 0.70247 |  iteration: 8004 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 546 loss: 1.44336 acc: 0.69401 | v_loss: 1.43075 v_acc: 0.70540 |  iteration: 8005 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 547 loss: 1.46148 acc: 0.70540 | v_loss: 1.41521 v_acc: 0.70475 |  iteration: 8006 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 548 loss: 1.42127 acc: 0.70312 | v_loss: 1.43203 v_acc: 0.70312 |  iteration: 8007 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 549 loss: 1.35121 acc: 0.70638 | v_loss: 1.28910 v_acc: 0.71289 |  iteration: 8008 teacher: 1 stage: sketch lr: 0.000494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 550 loss: 1.45019 acc: 0.70020 | v_loss: 1.32859 v_acc: 0.72331 |  iteration: 8009 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 551 loss: 1.59036 acc: 0.68717 | v_loss: 1.21283 v_acc: 0.70671 |  iteration: 8010 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 552 loss: 1.40970 acc: 0.70508 | v_loss: 1.36658 v_acc: 0.70150 |  iteration: 8011 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 553 loss: 1.48281 acc: 0.70182 | v_loss: 1.50010 v_acc: 0.69987 |  iteration: 8012 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 554 loss: 1.58722 acc: 0.68099 | v_loss: 1.37411 v_acc: 0.70443 |  iteration: 8013 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 555 loss: 1.49868 acc: 0.69987 | v_loss: 1.36724 v_acc: 0.69922 |  iteration: 8014 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 556 loss: 1.45066 acc: 0.70605 | v_loss: 1.31961 v_acc: 0.70638 |  iteration: 8015 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 557 loss: 1.60133 acc: 0.68913 | v_loss: 1.29260 v_acc: 0.70703 |  iteration: 8016 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 558 loss: 1.48930 acc: 0.70215 | v_loss: 1.24374 v_acc: 0.74447 |  iteration: 8017 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 559 loss: 1.48277 acc: 0.69206 | v_loss: 1.30555 v_acc: 0.72070 |  iteration: 8018 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 560 loss: 1.46358 acc: 0.70833 | v_loss: 1.35611 v_acc: 0.72461 |  iteration: 8019 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 561 loss: 1.48010 acc: 0.70312 | v_loss: 1.27482 v_acc: 0.72331 |  iteration: 8020 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 562 loss: 1.48280 acc: 0.69889 | v_loss: 1.31025 v_acc: 0.72103 |  iteration: 8021 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 563 loss: 1.47170 acc: 0.69401 | v_loss: 1.42402 v_acc: 0.71224 |  iteration: 8022 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 564 loss: 1.46912 acc: 0.69987 | v_loss: 1.42046 v_acc: 0.72201 |  iteration: 8023 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 565 loss: 1.55150 acc: 0.69238 | v_loss: 1.50025 v_acc: 0.70312 |  iteration: 8024 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 566 loss: 1.49091 acc: 0.69661 | v_loss: 1.44462 v_acc: 0.71777 |  iteration: 8025 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 567 loss: 1.50312 acc: 0.69857 | v_loss: 1.18945 v_acc: 0.74544 |  iteration: 8026 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 568 loss: 1.51912 acc: 0.69206 | v_loss: 1.25304 v_acc: 0.70931 |  iteration: 8027 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 569 loss: 1.56672 acc: 0.68848 | v_loss: 1.52237 v_acc: 0.70280 |  iteration: 8028 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 570 loss: 1.38671 acc: 0.70931 | v_loss: 1.27743 v_acc: 0.71745 |  iteration: 8029 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 571 loss: 1.57221 acc: 0.69206 | v_loss: 1.34830 v_acc: 0.71419 |  iteration: 8030 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 572 loss: 1.42741 acc: 0.69303 | v_loss: 1.38510 v_acc: 0.69531 |  iteration: 8031 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 573 loss: 1.48308 acc: 0.70150 | v_loss: 1.35772 v_acc: 0.70801 |  iteration: 8032 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 574 loss: 1.45752 acc: 0.70312 | v_loss: 1.41339 v_acc: 0.69010 |  iteration: 8033 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 575 loss: 1.38890 acc: 0.70736 | v_loss: 1.48138 v_acc: 0.70801 |  iteration: 8034 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 576 loss: 1.48896 acc: 0.70410 | v_loss: 1.32613 v_acc: 0.72363 |  iteration: 8035 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 577 loss: 1.50493 acc: 0.69564 | v_loss: 1.44680 v_acc: 0.70443 |  iteration: 8036 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 578 loss: 1.50755 acc: 0.70117 | v_loss: 1.42952 v_acc: 0.69922 |  iteration: 8037 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 579 loss: 1.59188 acc: 0.69824 | v_loss: 1.34957 v_acc: 0.70898 |  iteration: 8038 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 580 loss: 1.54320 acc: 0.69987 | v_loss: 1.56179 v_acc: 0.68880 |  iteration: 8039 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 581 loss: 1.50335 acc: 0.70085 | v_loss: 1.30944 v_acc: 0.72103 |  iteration: 8040 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 582 loss: 1.48248 acc: 0.69922 | v_loss: 1.59442 v_acc: 0.69043 |  iteration: 8041 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 583 loss: 1.40004 acc: 0.70964 | v_loss: 1.44845 v_acc: 0.70215 |  iteration: 8042 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 584 loss: 1.40227 acc: 0.70508 | v_loss: 1.51751 v_acc: 0.68750 |  iteration: 8043 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 585 loss: 1.47814 acc: 0.69596 | v_loss: 1.40086 v_acc: 0.69759 |  iteration: 8044 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 586 loss: 1.49560 acc: 0.69564 | v_loss: 1.33948 v_acc: 0.70508 |  iteration: 8045 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 587 loss: 1.54586 acc: 0.70085 | v_loss: 1.35704 v_acc: 0.70117 |  iteration: 8046 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 588 loss: 1.45589 acc: 0.69922 | v_loss: 1.34790 v_acc: 0.71680 |  iteration: 8047 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 589 loss: 1.37618 acc: 0.70573 | v_loss: 1.57660 v_acc: 0.68945 |  iteration: 8048 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 590 loss: 1.48486 acc: 0.70410 | v_loss: 1.40284 v_acc: 0.71387 |  iteration: 8049 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 591 loss: 1.48592 acc: 0.69694 | v_loss: 1.38488 v_acc: 0.70898 |  iteration: 8050 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 592 loss: 1.46210 acc: 0.70085 | v_loss: 1.40433 v_acc: 0.71452 |  iteration: 8051 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 593 loss: 1.40453 acc: 0.69434 | v_loss: 1.28496 v_acc: 0.70736 |  iteration: 8052 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 594 loss: 1.46704 acc: 0.69792 | v_loss: 1.46796 v_acc: 0.70020 |  iteration: 8053 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 595 loss: 1.31304 acc: 0.70866 | v_loss: 1.44438 v_acc: 0.71224 |  iteration: 8054 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 596 loss: 1.46720 acc: 0.69141 | v_loss: 1.29582 v_acc: 0.72201 |  iteration: 8055 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 597 loss: 1.51517 acc: 0.69987 | v_loss: 1.27438 v_acc: 0.72526 |  iteration: 8056 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 598 loss: 1.46874 acc: 0.69987 | v_loss: 1.39514 v_acc: 0.71647 |  iteration: 8057 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 599 loss: 1.47133 acc: 0.69889 | v_loss: 1.42757 v_acc: 0.70052 |  iteration: 8058 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 600 loss: 1.33885 acc: 0.70703 | v_loss: 1.43903 v_acc: 0.70345 |  iteration: 8059 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 601 loss: 1.54732 acc: 0.68587 | v_loss: 1.26910 v_acc: 0.70964 |  iteration: 8060 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 602 loss: 1.53374 acc: 0.70085 | v_loss: 1.39720 v_acc: 0.72656 |  iteration: 8061 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 603 loss: 1.48325 acc: 0.69987 | v_loss: 1.48694 v_acc: 0.69759 |  iteration: 8062 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 604 loss: 1.54764 acc: 0.68457 | v_loss: 1.42359 v_acc: 0.71940 |  iteration: 8063 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 605 loss: 1.61191 acc: 0.68262 | v_loss: 1.28227 v_acc: 0.71810 |  iteration: 8064 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 606 loss: 1.41393 acc: 0.70280 | v_loss: 1.24234 v_acc: 0.73568 |  iteration: 8065 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 607 loss: 1.45985 acc: 0.70085 | v_loss: 1.23921 v_acc: 0.72656 |  iteration: 8066 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 608 loss: 1.56277 acc: 0.68815 | v_loss: 1.31893 v_acc: 0.70703 |  iteration: 8067 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 609 loss: 1.50535 acc: 0.70540 | v_loss: 1.46711 v_acc: 0.69466 |  iteration: 8068 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 610 loss: 1.46454 acc: 0.70736 | v_loss: 1.29831 v_acc: 0.71484 |  iteration: 8069 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 611 loss: 1.49131 acc: 0.69303 | v_loss: 1.46535 v_acc: 0.72949 |  iteration: 8070 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 612 loss: 1.52980 acc: 0.69694 | v_loss: 1.66699 v_acc: 0.69401 |  iteration: 8071 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 613 loss: 1.52663 acc: 0.69173 | v_loss: 1.52998 v_acc: 0.69824 |  iteration: 8072 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 614 loss: 1.42731 acc: 0.69661 | v_loss: 1.32816 v_acc: 0.72331 |  iteration: 8073 teacher: 0 stage: sketch lr: 0.000492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 615 loss: 1.36744 acc: 0.70671 | v_loss: 1.38530 v_acc: 0.70996 |  iteration: 8074 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 616 loss: 1.50825 acc: 0.69954 | v_loss: 1.25825 v_acc: 0.71973 |  iteration: 8075 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 617 loss: 1.37965 acc: 0.71354 | v_loss: 1.43177 v_acc: 0.69857 |  iteration: 8076 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 618 loss: 1.54085 acc: 0.69759 | v_loss: 1.36653 v_acc: 0.70964 |  iteration: 8077 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 619 loss: 1.47973 acc: 0.69076 | v_loss: 1.37420 v_acc: 0.72949 |  iteration: 8078 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 620 loss: 1.48172 acc: 0.69987 | v_loss: 1.36891 v_acc: 0.71842 |  iteration: 8079 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 621 loss: 1.49933 acc: 0.70085 | v_loss: 1.39846 v_acc: 0.70215 |  iteration: 8080 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 622 loss: 1.48435 acc: 0.69401 | v_loss: 1.32031 v_acc: 0.72201 |  iteration: 8081 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 623 loss: 1.45042 acc: 0.70215 | v_loss: 1.31121 v_acc: 0.72005 |  iteration: 8082 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 624 loss: 1.30226 acc: 0.71745 | v_loss: 1.53801 v_acc: 0.69336 |  iteration: 8083 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 625 loss: 1.41519 acc: 0.70996 | v_loss: 1.34072 v_acc: 0.71452 |  iteration: 8084 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 626 loss: 1.48611 acc: 0.70052 | v_loss: 1.31974 v_acc: 0.71777 |  iteration: 8085 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 627 loss: 1.44978 acc: 0.70312 | v_loss: 1.31228 v_acc: 0.71973 |  iteration: 8086 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 628 loss: 1.54027 acc: 0.69271 | v_loss: 1.45176 v_acc: 0.70768 |  iteration: 8087 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 629 loss: 1.40851 acc: 0.70280 | v_loss: 1.33210 v_acc: 0.73210 |  iteration: 8088 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 630 loss: 1.38946 acc: 0.70215 | v_loss: 1.55206 v_acc: 0.71322 |  iteration: 8089 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 631 loss: 1.50684 acc: 0.69596 | v_loss: 1.31179 v_acc: 0.69531 |  iteration: 8090 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 632 loss: 1.43311 acc: 0.70378 | v_loss: 1.31125 v_acc: 0.70117 |  iteration: 8091 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 633 loss: 1.52841 acc: 0.68945 | v_loss: 1.44785 v_acc: 0.70508 |  iteration: 8092 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 634 loss: 1.45500 acc: 0.70085 | v_loss: 1.47147 v_acc: 0.70573 |  iteration: 8093 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 635 loss: 1.41269 acc: 0.69987 | v_loss: 1.51743 v_acc: 0.68978 |  iteration: 8094 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 636 loss: 1.55326 acc: 0.69401 | v_loss: 1.47744 v_acc: 0.70540 |  iteration: 8095 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 637 loss: 1.43095 acc: 0.70898 | v_loss: 1.43867 v_acc: 0.70540 |  iteration: 8096 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 638 loss: 1.50669 acc: 0.69922 | v_loss: 1.41209 v_acc: 0.70475 |  iteration: 8097 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 639 loss: 1.38038 acc: 0.70736 | v_loss: 1.44793 v_acc: 0.70312 |  iteration: 8098 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 640 loss: 1.37335 acc: 0.71289 | v_loss: 1.31921 v_acc: 0.71257 |  iteration: 8099 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 641 loss: 1.40190 acc: 0.70280 | v_loss: 1.32296 v_acc: 0.72493 |  iteration: 8100 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 642 loss: 1.51235 acc: 0.70150 | v_loss: 1.23840 v_acc: 0.70768 |  iteration: 8101 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 643 loss: 1.48589 acc: 0.69661 | v_loss: 1.37212 v_acc: 0.70703 |  iteration: 8102 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 644 loss: 1.48654 acc: 0.70378 | v_loss: 1.50231 v_acc: 0.70117 |  iteration: 8103 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 645 loss: 1.47819 acc: 0.70345 | v_loss: 1.37283 v_acc: 0.70540 |  iteration: 8104 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 646 loss: 1.48910 acc: 0.70312 | v_loss: 1.36902 v_acc: 0.69368 |  iteration: 8105 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 647 loss: 1.40321 acc: 0.70182 | v_loss: 1.28679 v_acc: 0.70573 |  iteration: 8106 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 648 loss: 1.43710 acc: 0.70312 | v_loss: 1.24879 v_acc: 0.70410 |  iteration: 8107 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 649 loss: 1.42837 acc: 0.70280 | v_loss: 1.26435 v_acc: 0.73926 |  iteration: 8108 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 650 loss: 1.45430 acc: 0.69922 | v_loss: 1.28545 v_acc: 0.71908 |  iteration: 8109 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 651 loss: 1.34760 acc: 0.71094 | v_loss: 1.37627 v_acc: 0.73112 |  iteration: 8110 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 652 loss: 1.44110 acc: 0.70215 | v_loss: 1.27363 v_acc: 0.72201 |  iteration: 8111 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 653 loss: 1.46844 acc: 0.69759 | v_loss: 1.30641 v_acc: 0.72103 |  iteration: 8112 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 654 loss: 1.54843 acc: 0.69108 | v_loss: 1.41310 v_acc: 0.71322 |  iteration: 8113 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 655 loss: 1.59295 acc: 0.68750 | v_loss: 1.38114 v_acc: 0.71973 |  iteration: 8114 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 656 loss: 1.46856 acc: 0.70215 | v_loss: 1.50719 v_acc: 0.69661 |  iteration: 8115 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 657 loss: 1.42496 acc: 0.70312 | v_loss: 1.41995 v_acc: 0.71908 |  iteration: 8116 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 658 loss: 1.41092 acc: 0.70508 | v_loss: 1.20435 v_acc: 0.74284 |  iteration: 8117 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 659 loss: 1.43420 acc: 0.70475 | v_loss: 1.34783 v_acc: 0.70052 |  iteration: 8118 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 660 loss: 1.56006 acc: 0.70020 | v_loss: 1.50841 v_acc: 0.70898 |  iteration: 8119 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 661 loss: 1.46664 acc: 0.70443 | v_loss: 1.25283 v_acc: 0.73047 |  iteration: 8120 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 662 loss: 1.43525 acc: 0.70410 | v_loss: 1.34398 v_acc: 0.71191 |  iteration: 8121 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 663 loss: 1.49022 acc: 0.69954 | v_loss: 1.39785 v_acc: 0.69076 |  iteration: 8122 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 664 loss: 1.44561 acc: 0.70410 | v_loss: 1.32015 v_acc: 0.71191 |  iteration: 8123 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 665 loss: 1.41488 acc: 0.69922 | v_loss: 1.39428 v_acc: 0.70215 |  iteration: 8124 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 666 loss: 1.53900 acc: 0.70150 | v_loss: 1.48815 v_acc: 0.72005 |  iteration: 8125 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 667 loss: 1.42942 acc: 0.70345 | v_loss: 1.33895 v_acc: 0.72786 |  iteration: 8126 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 668 loss: 1.41995 acc: 0.70638 | v_loss: 1.45804 v_acc: 0.70312 |  iteration: 8127 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 669 loss: 1.48102 acc: 0.69238 | v_loss: 1.36477 v_acc: 0.70117 |  iteration: 8128 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 670 loss: 1.44609 acc: 0.69434 | v_loss: 1.34898 v_acc: 0.70605 |  iteration: 8129 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 671 loss: 1.43051 acc: 0.69759 | v_loss: 1.55520 v_acc: 0.68880 |  iteration: 8130 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 672 loss: 1.43616 acc: 0.70312 | v_loss: 1.31837 v_acc: 0.72363 |  iteration: 8131 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 673 loss: 1.49692 acc: 0.70052 | v_loss: 1.59836 v_acc: 0.68294 |  iteration: 8132 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 674 loss: 1.61897 acc: 0.69108 | v_loss: 1.45027 v_acc: 0.69987 |  iteration: 8133 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 675 loss: 1.46202 acc: 0.69368 | v_loss: 1.51191 v_acc: 0.68913 |  iteration: 8134 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 676 loss: 1.34595 acc: 0.70768 | v_loss: 1.38894 v_acc: 0.69759 |  iteration: 8135 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 677 loss: 1.48466 acc: 0.69759 | v_loss: 1.33972 v_acc: 0.70215 |  iteration: 8136 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 678 loss: 1.42410 acc: 0.69824 | v_loss: 1.35372 v_acc: 0.69889 |  iteration: 8137 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 679 loss: 1.40453 acc: 0.70638 | v_loss: 1.34070 v_acc: 0.71419 |  iteration: 8138 teacher: 0 stage: sketch lr: 0.000490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 680 loss: 1.52570 acc: 0.68848 | v_loss: 1.53156 v_acc: 0.69238 |  iteration: 8139 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 681 loss: 1.45371 acc: 0.69499 | v_loss: 1.39268 v_acc: 0.70443 |  iteration: 8140 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 682 loss: 1.50544 acc: 0.69466 | v_loss: 1.37881 v_acc: 0.71029 |  iteration: 8141 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 683 loss: 1.44847 acc: 0.70085 | v_loss: 1.38897 v_acc: 0.71680 |  iteration: 8142 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 684 loss: 1.41288 acc: 0.71159 | v_loss: 1.29201 v_acc: 0.70215 |  iteration: 8143 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 685 loss: 1.49028 acc: 0.69434 | v_loss: 1.44540 v_acc: 0.69434 |  iteration: 8144 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 686 loss: 1.44720 acc: 0.70573 | v_loss: 1.42721 v_acc: 0.71452 |  iteration: 8145 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 687 loss: 1.55353 acc: 0.69206 | v_loss: 1.31434 v_acc: 0.71777 |  iteration: 8146 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 688 loss: 1.56182 acc: 0.69206 | v_loss: 1.27461 v_acc: 0.72559 |  iteration: 8147 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 689 loss: 1.38328 acc: 0.71029 | v_loss: 1.40588 v_acc: 0.71322 |  iteration: 8148 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 690 loss: 1.43712 acc: 0.69857 | v_loss: 1.42639 v_acc: 0.70052 |  iteration: 8149 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 691 loss: 1.45501 acc: 0.69173 | v_loss: 1.43356 v_acc: 0.70312 |  iteration: 8150 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 692 loss: 1.39432 acc: 0.71191 | v_loss: 1.25747 v_acc: 0.71419 |  iteration: 8151 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 693 loss: 1.46010 acc: 0.70410 | v_loss: 1.42128 v_acc: 0.72819 |  iteration: 8152 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 694 loss: 1.52581 acc: 0.69499 | v_loss: 1.49743 v_acc: 0.69792 |  iteration: 8153 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 695 loss: 1.44067 acc: 0.70312 | v_loss: 1.43669 v_acc: 0.72070 |  iteration: 8154 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 696 loss: 1.39655 acc: 0.70898 | v_loss: 1.26918 v_acc: 0.72201 |  iteration: 8155 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 697 loss: 1.52620 acc: 0.69303 | v_loss: 1.21301 v_acc: 0.74023 |  iteration: 8156 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 698 loss: 1.51807 acc: 0.69987 | v_loss: 1.23512 v_acc: 0.72559 |  iteration: 8157 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 699 loss: 1.56832 acc: 0.69141 | v_loss: 1.32796 v_acc: 0.70638 |  iteration: 8158 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 700 loss: 1.44011 acc: 0.70638 | v_loss: 1.47396 v_acc: 0.70052 |  iteration: 8159 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 701 loss: 1.37367 acc: 0.71549 | v_loss: 1.31707 v_acc: 0.71484 |  iteration: 8160 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 702 loss: 1.46415 acc: 0.70312 | v_loss: 1.47429 v_acc: 0.72949 |  iteration: 8161 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 703 loss: 1.43404 acc: 0.70345 | v_loss: 1.63493 v_acc: 0.69466 |  iteration: 8162 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 704 loss: 1.48210 acc: 0.68815 | v_loss: 1.51238 v_acc: 0.70410 |  iteration: 8163 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 705 loss: 1.47625 acc: 0.69108 | v_loss: 1.32505 v_acc: 0.72005 |  iteration: 8164 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 706 loss: 1.45205 acc: 0.70052 | v_loss: 1.37456 v_acc: 0.70280 |  iteration: 8165 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 707 loss: 1.42808 acc: 0.71094 | v_loss: 1.23935 v_acc: 0.72103 |  iteration: 8166 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 708 loss: 1.34888 acc: 0.70345 | v_loss: 1.42964 v_acc: 0.70085 |  iteration: 8167 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 709 loss: 1.46031 acc: 0.69857 | v_loss: 1.38290 v_acc: 0.71029 |  iteration: 8168 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 710 loss: 1.43344 acc: 0.69661 | v_loss: 1.37313 v_acc: 0.72949 |  iteration: 8169 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 711 loss: 1.62785 acc: 0.68132 | v_loss: 1.37768 v_acc: 0.71777 |  iteration: 8170 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 712 loss: 1.42061 acc: 0.69727 | v_loss: 1.39852 v_acc: 0.70964 |  iteration: 8171 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 713 loss: 1.56698 acc: 0.69336 | v_loss: 1.30027 v_acc: 0.72233 |  iteration: 8172 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 714 loss: 1.52157 acc: 0.69206 | v_loss: 1.30356 v_acc: 0.72135 |  iteration: 8173 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 715 loss: 1.36917 acc: 0.71191 | v_loss: 1.53534 v_acc: 0.69043 |  iteration: 8174 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 716 loss: 1.53673 acc: 0.69596 | v_loss: 1.34098 v_acc: 0.70833 |  iteration: 8175 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 717 loss: 1.47603 acc: 0.70085 | v_loss: 1.33338 v_acc: 0.71094 |  iteration: 8176 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 718 loss: 1.39557 acc: 0.71061 | v_loss: 1.32957 v_acc: 0.71745 |  iteration: 8177 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 719 loss: 1.47624 acc: 0.69694 | v_loss: 1.45727 v_acc: 0.70410 |  iteration: 8178 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 720 loss: 1.44896 acc: 0.70117 | v_loss: 1.33017 v_acc: 0.73210 |  iteration: 8179 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 721 loss: 1.43578 acc: 0.70280 | v_loss: 1.53736 v_acc: 0.71322 |  iteration: 8180 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 722 loss: 1.45214 acc: 0.70345 | v_loss: 1.29705 v_acc: 0.69759 |  iteration: 8181 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 723 loss: 1.55425 acc: 0.68880 | v_loss: 1.29299 v_acc: 0.70443 |  iteration: 8182 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 724 loss: 1.40973 acc: 0.71094 | v_loss: 1.43805 v_acc: 0.70378 |  iteration: 8183 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 725 loss: 1.39701 acc: 0.71191 | v_loss: 1.46902 v_acc: 0.70150 |  iteration: 8184 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 726 loss: 1.40636 acc: 0.70964 | v_loss: 1.51181 v_acc: 0.69368 |  iteration: 8185 teacher: 1 stage: sketch lr: 0.000488\n",
      "batch 727 loss: 1.45627 acc: 0.69661 | v_loss: 1.48822 v_acc: 0.70833 |  iteration: 8186 teacher: 1 stage: sketch lr: 0.000488\n",
      "batch 728 loss: 1.50776 acc: 0.69043 | v_loss: 1.42998 v_acc: 0.70085 |  iteration: 8187 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 729 loss: 1.49894 acc: 0.69954 | v_loss: 1.40664 v_acc: 0.70931 |  iteration: 8188 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 730 loss: 1.42500 acc: 0.71061 | v_loss: 1.42842 v_acc: 0.70443 |  iteration: 8189 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 731 loss: 1.62071 acc: 0.68066 | v_loss: 1.30108 v_acc: 0.71257 |  iteration: 8190 teacher: 1 stage: sketch lr: 0.000488\n",
      "batch 732 loss: 1.43694 acc: 0.69661 | v_loss: 1.33502 v_acc: 0.72493 |  iteration: 8191 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 733 loss: 1.36258 acc: 0.71517 | v_loss: 1.23568 v_acc: 0.70638 |  iteration: 8192 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 734 loss: 1.44914 acc: 0.70671 | v_loss: 1.37089 v_acc: 0.70150 |  iteration: 8193 teacher: 1 stage: sketch lr: 0.000488\n",
      "batch 735 loss: 1.47310 acc: 0.69954 | v_loss: 1.49758 v_acc: 0.69987 |  iteration: 8194 teacher: 1 stage: sketch lr: 0.000488\n",
      "batch 736 loss: 1.53218 acc: 0.69434 | v_loss: 1.35491 v_acc: 0.70540 |  iteration: 8195 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 737 loss: 1.48914 acc: 0.69629 | v_loss: 1.38755 v_acc: 0.69368 |  iteration: 8196 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 738 loss: 1.47400 acc: 0.70703 | v_loss: 1.28618 v_acc: 0.70573 |  iteration: 8197 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 739 loss: 1.42487 acc: 0.70312 | v_loss: 1.26620 v_acc: 0.70345 |  iteration: 8198 teacher: 1 stage: sketch lr: 0.000488\n",
      "batch 740 loss: 1.44272 acc: 0.70605 | v_loss: 1.24643 v_acc: 0.73503 |  iteration: 8199 teacher: 1 stage: sketch lr: 0.000488\n",
      "batch 741 loss: 1.38637 acc: 0.71419 | v_loss: 1.28253 v_acc: 0.72461 |  iteration: 8200 teacher: 1 stage: sketch lr: 0.000488\n",
      "batch 742 loss: 1.49276 acc: 0.69694 | v_loss: 1.35393 v_acc: 0.72624 |  iteration: 8201 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 743 loss: 1.47657 acc: 0.70475 | v_loss: 1.27353 v_acc: 0.71940 |  iteration: 8202 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 744 loss: 1.38730 acc: 0.71061 | v_loss: 1.31280 v_acc: 0.72266 |  iteration: 8203 teacher: 0 stage: sketch lr: 0.000488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 745 loss: 1.38088 acc: 0.71322 | v_loss: 1.42512 v_acc: 0.71289 |  iteration: 8204 teacher: 1 stage: sketch lr: 0.000488\n",
      "batch 746 loss: 1.51810 acc: 0.69661 | v_loss: 1.39629 v_acc: 0.72038 |  iteration: 8205 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 747 loss: 1.38494 acc: 0.71159 | v_loss: 1.49856 v_acc: 0.69661 |  iteration: 8206 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 748 loss: 1.48335 acc: 0.69499 | v_loss: 1.42091 v_acc: 0.71745 |  iteration: 8207 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 749 loss: 1.49941 acc: 0.69922 | v_loss: 1.18726 v_acc: 0.74382 |  iteration: 8208 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 750 loss: 1.51544 acc: 0.69564 | v_loss: 1.28159 v_acc: 0.70280 |  iteration: 8209 teacher: 1 stage: sketch lr: 0.000488\n",
      "batch 751 loss: 1.43156 acc: 0.71029 | v_loss: 1.50612 v_acc: 0.70898 |  iteration: 8210 teacher: 1 stage: sketch lr: 0.000488\n",
      "batch 752 loss: 1.43814 acc: 0.69824 | v_loss: 1.23606 v_acc: 0.71647 |  iteration: 8211 teacher: 1 stage: sketch lr: 0.000488\n",
      "batch 753 loss: 1.52661 acc: 0.69792 | v_loss: 1.34189 v_acc: 0.71191 |  iteration: 8212 teacher: 1 stage: sketch lr: 0.000488\n",
      "batch 754 loss: 1.41036 acc: 0.70312 | v_loss: 1.38828 v_acc: 0.69076 |  iteration: 8213 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 755 loss: 1.50065 acc: 0.68880 | v_loss: 1.32366 v_acc: 0.70898 |  iteration: 8214 teacher: 1 stage: sketch lr: 0.000488\n",
      "batch 756 loss: 1.58163 acc: 0.68848 | v_loss: 1.37948 v_acc: 0.69206 |  iteration: 8215 teacher: 1 stage: sketch lr: 0.000488\n",
      "batch 757 loss: 1.53178 acc: 0.69206 | v_loss: 1.46836 v_acc: 0.71517 |  iteration: 8216 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 758 loss: 1.43056 acc: 0.69661 | v_loss: 1.32650 v_acc: 0.72689 |  iteration: 8217 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 759 loss: 1.38191 acc: 0.70671 | v_loss: 1.45743 v_acc: 0.70312 |  iteration: 8218 teacher: 1 stage: sketch lr: 0.000488\n",
      "batch 760 loss: 1.54402 acc: 0.68815 | v_loss: 1.36277 v_acc: 0.70150 |  iteration: 8219 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 761 loss: 1.52458 acc: 0.69271 | v_loss: 1.35552 v_acc: 0.70573 |  iteration: 8220 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 762 loss: 1.39568 acc: 0.70605 | v_loss: 1.54886 v_acc: 0.68913 |  iteration: 8221 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 763 loss: 1.43821 acc: 0.70345 | v_loss: 1.32399 v_acc: 0.72135 |  iteration: 8222 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 764 loss: 1.44189 acc: 0.69596 | v_loss: 1.59437 v_acc: 0.68424 |  iteration: 8223 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 765 loss: 1.48789 acc: 0.68913 | v_loss: 1.48546 v_acc: 0.69661 |  iteration: 8224 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 766 loss: 1.39913 acc: 0.70150 | v_loss: 1.53334 v_acc: 0.69238 |  iteration: 8225 teacher: 1 stage: sketch lr: 0.000487\n",
      "batch 767 loss: 1.55800 acc: 0.69271 | v_loss: 1.40234 v_acc: 0.70020 |  iteration: 8226 teacher: 1 stage: sketch lr: 0.000487\n",
      "batch 768 loss: 1.42141 acc: 0.70540 | v_loss: 1.31769 v_acc: 0.70540 |  iteration: 8227 teacher: 1 stage: sketch lr: 0.000487\n",
      "batch 769 loss: 1.33650 acc: 0.70768 | v_loss: 1.34610 v_acc: 0.70280 |  iteration: 8228 teacher: 1 stage: sketch lr: 0.000487\n",
      "batch 770 loss: 1.43447 acc: 0.70703 | v_loss: 1.35072 v_acc: 0.71842 |  iteration: 8229 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 771 loss: 1.45375 acc: 0.70117 | v_loss: 1.57582 v_acc: 0.69108 |  iteration: 8230 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 772 loss: 1.43705 acc: 0.69889 | v_loss: 1.38712 v_acc: 0.70247 |  iteration: 8231 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 773 loss: 1.42614 acc: 0.70215 | v_loss: 1.36975 v_acc: 0.71126 |  iteration: 8232 teacher: 1 stage: sketch lr: 0.000487\n",
      "batch 774 loss: 1.46291 acc: 0.69596 | v_loss: 1.40643 v_acc: 0.71810 |  iteration: 8233 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 775 loss: 1.47282 acc: 0.69238 | v_loss: 1.29106 v_acc: 0.70215 |  iteration: 8234 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 776 loss: 1.49802 acc: 0.69466 | v_loss: 1.43303 v_acc: 0.69434 |  iteration: 8235 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 777 loss: 1.50869 acc: 0.69206 | v_loss: 1.42494 v_acc: 0.71452 |  iteration: 8236 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 778 loss: 1.42200 acc: 0.70020 | v_loss: 1.31169 v_acc: 0.71647 |  iteration: 8237 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 779 loss: 1.66008 acc: 0.68848 | v_loss: 1.27169 v_acc: 0.72526 |  iteration: 8238 teacher: 1 stage: sketch lr: 0.000487\n",
      "batch 780 loss: 1.47351 acc: 0.69596 | v_loss: 1.38193 v_acc: 0.71647 |  iteration: 8239 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 781 loss: 1.52123 acc: 0.68913 | v_loss: 1.42420 v_acc: 0.70052 |  iteration: 8240 teacher: 1 stage: sketch lr: 0.000487\n",
      "batch 782 loss: 1.40968 acc: 0.69759 | v_loss: 1.43204 v_acc: 0.70312 |  iteration: 8241 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 783 loss: 1.37934 acc: 0.71549 | v_loss: 1.25563 v_acc: 0.71419 |  iteration: 8242 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 784 loss: 1.46497 acc: 0.69889 | v_loss: 1.39697 v_acc: 0.72819 |  iteration: 8243 teacher: 1 stage: sketch lr: 0.000487\n",
      "batch 785 loss: 1.61715 acc: 0.68945 | v_loss: 1.47711 v_acc: 0.69792 |  iteration: 8244 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 786 loss: 1.47232 acc: 0.69694 | v_loss: 1.40507 v_acc: 0.71842 |  iteration: 8245 teacher: 1 stage: sketch lr: 0.000487\n",
      "batch 787 loss: 1.41930 acc: 0.70345 | v_loss: 1.27414 v_acc: 0.71810 |  iteration: 8246 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 788 loss: 1.42482 acc: 0.69954 | v_loss: 1.23634 v_acc: 0.73535 |  iteration: 8247 teacher: 1 stage: sketch lr: 0.000487\n",
      "batch 789 loss: 1.50904 acc: 0.70215 | v_loss: 1.24147 v_acc: 0.72656 |  iteration: 8248 teacher: 1 stage: sketch lr: 0.000487\n",
      "batch 790 loss: 1.50564 acc: 0.68490 | v_loss: 1.31706 v_acc: 0.70703 |  iteration: 8249 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 791 loss: 1.43313 acc: 0.69987 | v_loss: 1.47146 v_acc: 0.69466 |  iteration: 8250 teacher: 1 stage: sketch lr: 0.000487\n",
      "batch 792 loss: 1.46597 acc: 0.69792 | v_loss: 1.28663 v_acc: 0.71452 |  iteration: 8251 teacher: 1 stage: sketch lr: 0.000487\n",
      "batch 793 loss: 1.41406 acc: 0.71257 | v_loss: 1.45685 v_acc: 0.71647 |  iteration: 8252 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 794 loss: 1.35205 acc: 0.71224 | v_loss: 1.68158 v_acc: 0.69303 |  iteration: 8253 teacher: 1 stage: sketch lr: 0.000486\n",
      "batch 795 loss: 1.42218 acc: 0.70833 | v_loss: 1.51736 v_acc: 0.70410 |  iteration: 8254 teacher: 0 stage: sketch lr: 0.000486\n",
      "batch 796 loss: 1.50584 acc: 0.70215 | v_loss: 1.31913 v_acc: 0.72005 |  iteration: 8255 teacher: 1 stage: sketch lr: 0.000486\n",
      "batch 797 loss: 1.36814 acc: 0.71257 | v_loss: 1.38612 v_acc: 0.69987 |  iteration: 8256 teacher: 0 stage: sketch lr: 0.000486\n",
      "batch 798 loss: 1.38900 acc: 0.71094 | v_loss: 1.26694 v_acc: 0.71615 |  iteration: 8257 teacher: 1 stage: sketch lr: 0.000486\n",
      "batch 799 loss: 1.44985 acc: 0.70215 | v_loss: 1.42574 v_acc: 0.69857 |  iteration: 8258 teacher: 0 stage: sketch lr: 0.000486\n",
      "batch 800 loss: 1.51363 acc: 0.69792 | v_loss: 1.37816 v_acc: 0.70964 |  iteration: 8259 teacher: 1 stage: sketch lr: 0.000486\n",
      "batch 801 loss: 1.38695 acc: 0.70898 | v_loss: 1.35732 v_acc: 0.72949 |  iteration: 8260 teacher: 0 stage: sketch lr: 0.000486\n",
      "batch 802 loss: 1.52842 acc: 0.70150 | v_loss: 1.36483 v_acc: 0.71842 |  iteration: 8261 teacher: 1 stage: sketch lr: 0.000486\n",
      "batch 803 loss: 1.39948 acc: 0.71322 | v_loss: 1.41036 v_acc: 0.69922 |  iteration: 8262 teacher: 0 stage: sketch lr: 0.000486\n",
      "batch 804 loss: 1.47418 acc: 0.70540 | v_loss: 1.34425 v_acc: 0.72168 |  iteration: 8263 teacher: 0 stage: sketch lr: 0.000486\n",
      "batch 805 loss: 1.49233 acc: 0.69792 | v_loss: 1.33807 v_acc: 0.71875 |  iteration: 8264 teacher: 1 stage: sketch lr: 0.000486\n",
      "batch 806 loss: 1.44295 acc: 0.70085 | v_loss: 1.59668 v_acc: 0.68555 |  iteration: 8265 teacher: 0 stage: sketch lr: 0.000486\n",
      "batch 807 loss: 1.45606 acc: 0.70703 | v_loss: 1.33777 v_acc: 0.70931 |  iteration: 8266 teacher: 1 stage: sketch lr: 0.000486\n",
      "batch 808 loss: 1.46956 acc: 0.70443 | v_loss: 1.30731 v_acc: 0.71582 |  iteration: 8267 teacher: 1 stage: sketch lr: 0.000486\n",
      "batch 809 loss: 1.53733 acc: 0.69661 | v_loss: 1.28680 v_acc: 0.72201 |  iteration: 8268 teacher: 1 stage: sketch lr: 0.000486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 810 loss: 1.42791 acc: 0.71549 | v_loss: 1.43259 v_acc: 0.70768 |  iteration: 8269 teacher: 0 stage: sketch lr: 0.000486\n",
      "batch 811 loss: 1.56987 acc: 0.68392 | v_loss: 1.33441 v_acc: 0.73210 |  iteration: 8270 teacher: 0 stage: sketch lr: 0.000486\n",
      "batch 812 loss: 1.44098 acc: 0.70280 | v_loss: 1.53827 v_acc: 0.71322 |  iteration: 8271 teacher: 1 stage: sketch lr: 0.000486\n",
      "batch 813 loss: 1.57443 acc: 0.69108 | v_loss: 1.31165 v_acc: 0.69531 |  iteration: 8272 teacher: 0 stage: sketch lr: 0.000486\n",
      "batch 814 loss: 1.42270 acc: 0.70312 | v_loss: 1.29942 v_acc: 0.70117 |  iteration: 8273 teacher: 1 stage: sketch lr: 0.000486\n",
      "batch 815 loss: 1.47159 acc: 0.69206 | v_loss: 1.45297 v_acc: 0.70508 |  iteration: 8274 teacher: 1 stage: sketch lr: 0.000486\n",
      "batch 816 loss: 1.40948 acc: 0.70280 | v_loss: 1.47231 v_acc: 0.70573 |  iteration: 8275 teacher: 1 stage: sketch lr: 0.000486\n",
      "batch 817 loss: 1.52205 acc: 0.69010 | v_loss: 1.51779 v_acc: 0.69076 |  iteration: 8276 teacher: 0 stage: sketch lr: 0.000486\n",
      "batch 818 loss: 1.47782 acc: 0.69889 | v_loss: 1.47938 v_acc: 0.70312 |  iteration: 8277 teacher: 1 stage: sketch lr: 0.000486\n",
      "batch 819 loss: 1.43334 acc: 0.69336 | v_loss: 1.44099 v_acc: 0.70866 |  iteration: 8278 teacher: 1 stage: sketch lr: 0.000486\n",
      "batch 820 loss: 1.42378 acc: 0.70605 | v_loss: 1.42233 v_acc: 0.70736 |  iteration: 8279 teacher: 0 stage: sketch lr: 0.000486\n",
      "batch 821 loss: 1.35601 acc: 0.70833 | v_loss: 1.42349 v_acc: 0.70703 |  iteration: 8280 teacher: 0 stage: sketch lr: 0.000486\n",
      "batch 822 loss: 1.38625 acc: 0.70540 | v_loss: 1.27295 v_acc: 0.71973 |  iteration: 8281 teacher: 1 stage: sketch lr: 0.000486\n",
      "batch 823 loss: 1.43733 acc: 0.70280 | v_loss: 1.33348 v_acc: 0.72526 |  iteration: 8282 teacher: 1 stage: sketch lr: 0.000486\n",
      "batch 824 loss: 1.34473 acc: 0.70898 | v_loss: 1.16826 v_acc: 0.71712 |  iteration: 8283 teacher: 0 stage: sketch lr: 0.000486\n",
      "batch 825 loss: 1.37222 acc: 0.71387 | v_loss: 1.35029 v_acc: 0.71061 |  iteration: 8284 teacher: 0 stage: sketch lr: 0.000486\n",
      "batch 826 loss: 1.51007 acc: 0.69336 | v_loss: 1.54140 v_acc: 0.69336 |  iteration: 8285 teacher: 0 stage: sketch lr: 0.000486\n",
      "batch 827 loss: 1.43185 acc: 0.71094 | v_loss: 1.32547 v_acc: 0.71484 |  iteration: 8286 teacher: 0 stage: sketch lr: 0.000486\n",
      "batch 828 loss: 1.45882 acc: 0.69824 | v_loss: 1.38492 v_acc: 0.69727 |  iteration: 8287 teacher: 0 stage: sketch lr: 0.000485\n",
      "batch 829 loss: 1.41839 acc: 0.70540 | v_loss: 1.27055 v_acc: 0.70573 |  iteration: 8288 teacher: 1 stage: sketch lr: 0.000485\n",
      "batch 830 loss: 1.35532 acc: 0.70996 | v_loss: 1.27635 v_acc: 0.70215 |  iteration: 8289 teacher: 0 stage: sketch lr: 0.000485\n",
      "batch 831 loss: 1.50764 acc: 0.69303 | v_loss: 1.25823 v_acc: 0.73438 |  iteration: 8290 teacher: 1 stage: sketch lr: 0.000485\n",
      "batch 832 loss: 1.53233 acc: 0.70508 | v_loss: 1.29881 v_acc: 0.71615 |  iteration: 8291 teacher: 0 stage: sketch lr: 0.000485\n",
      "batch 833 loss: 1.52690 acc: 0.69271 | v_loss: 1.35624 v_acc: 0.75423 |  iteration: 8292 teacher: 1 stage: sketch lr: 0.000485\n",
      "batch 834 loss: 1.47796 acc: 0.70605 | v_loss: 1.28629 v_acc: 0.72005 |  iteration: 8293 teacher: 0 stage: sketch lr: 0.000485\n",
      "batch 835 loss: 1.47544 acc: 0.69792 | v_loss: 1.31621 v_acc: 0.71582 |  iteration: 8294 teacher: 0 stage: sketch lr: 0.000485\n",
      "batch 836 loss: 1.45731 acc: 0.70280 | v_loss: 1.41116 v_acc: 0.71224 |  iteration: 8295 teacher: 1 stage: sketch lr: 0.000485\n",
      "batch 837 loss: 1.58009 acc: 0.69010 | v_loss: 1.38141 v_acc: 0.72038 |  iteration: 8296 teacher: 1 stage: sketch lr: 0.000485\n",
      "batch 838 loss: 1.43690 acc: 0.69499 | v_loss: 1.49670 v_acc: 0.69792 |  iteration: 8297 teacher: 0 stage: sketch lr: 0.000485\n",
      "batch 839 loss: 1.42977 acc: 0.71191 | v_loss: 1.42257 v_acc: 0.71777 |  iteration: 8298 teacher: 0 stage: sketch lr: 0.000485\n",
      "batch 840 loss: 1.45661 acc: 0.70182 | v_loss: 1.18589 v_acc: 0.74447 |  iteration: 8299 teacher: 1 stage: sketch lr: 0.000485\n",
      "batch 841 loss: 1.50667 acc: 0.69661 | v_loss: 1.26909 v_acc: 0.71322 |  iteration: 8300 teacher: 1 stage: sketch lr: 0.000485\n",
      "batch 842 loss: 1.46962 acc: 0.69954 | v_loss: 1.52549 v_acc: 0.69987 |  iteration: 8301 teacher: 0 stage: sketch lr: 0.000485\n",
      "batch 843 loss: 1.48757 acc: 0.69629 | v_loss: 1.24404 v_acc: 0.71647 |  iteration: 8302 teacher: 1 stage: sketch lr: 0.000485\n",
      "batch 844 loss: 1.47782 acc: 0.70085 | v_loss: 1.34293 v_acc: 0.71191 |  iteration: 8303 teacher: 1 stage: sketch lr: 0.000485\n",
      "batch 845 loss: 1.41803 acc: 0.70085 | v_loss: 1.38565 v_acc: 0.69076 |  iteration: 8304 teacher: 0 stage: sketch lr: 0.000485\n",
      "batch 846 loss: 1.42468 acc: 0.70866 | v_loss: 1.31267 v_acc: 0.70898 |  iteration: 8305 teacher: 1 stage: sketch lr: 0.000485\n",
      "batch 847 loss: 1.56997 acc: 0.69206 | v_loss: 1.37812 v_acc: 0.69206 |  iteration: 8306 teacher: 0 stage: sketch lr: 0.000485\n",
      "batch 848 loss: 1.46015 acc: 0.70573 | v_loss: 1.48985 v_acc: 0.70931 |  iteration: 8307 teacher: 0 stage: sketch lr: 0.000485\n",
      "batch 849 loss: 1.39640 acc: 0.70085 | v_loss: 1.32613 v_acc: 0.72363 |  iteration: 8308 teacher: 0 stage: sketch lr: 0.000485\n",
      "batch 850 loss: 1.37238 acc: 0.70833 | v_loss: 1.46636 v_acc: 0.70117 |  iteration: 8309 teacher: 0 stage: sketch lr: 0.000485\n",
      "batch 851 loss: 1.48274 acc: 0.69368 | v_loss: 1.38740 v_acc: 0.70052 |  iteration: 8310 teacher: 0 stage: sketch lr: 0.000485\n",
      "batch 852 loss: 1.44220 acc: 0.69954 | v_loss: 1.32513 v_acc: 0.70833 |  iteration: 8311 teacher: 1 stage: sketch lr: 0.000485\n",
      "batch 853 loss: 1.47733 acc: 0.69792 | v_loss: 1.58961 v_acc: 0.68522 |  iteration: 8312 teacher: 1 stage: sketch lr: 0.000485\n",
      "batch 854 loss: 1.37062 acc: 0.71061 | v_loss: 1.31457 v_acc: 0.71842 |  iteration: 8313 teacher: 0 stage: sketch lr: 0.000485\n",
      "batch 855 loss: 1.37414 acc: 0.71224 | v_loss: 1.63136 v_acc: 0.67513 |  iteration: 8314 teacher: 0 stage: sketch lr: 0.000485\n",
      "batch 856 loss: 1.54977 acc: 0.69434 | v_loss: 1.49035 v_acc: 0.69661 |  iteration: 8315 teacher: 0 stage: sketch lr: 0.000485\n",
      "batch 857 loss: 1.41872 acc: 0.70410 | v_loss: 1.53444 v_acc: 0.69108 |  iteration: 8316 teacher: 0 stage: sketch lr: 0.000485\n",
      "batch 858 loss: 1.51390 acc: 0.70312 | v_loss: 1.38953 v_acc: 0.69759 |  iteration: 8317 teacher: 1 stage: sketch lr: 0.000485\n",
      "batch 859 loss: 1.51001 acc: 0.69499 | v_loss: 1.33562 v_acc: 0.70215 |  iteration: 8318 teacher: 0 stage: sketch lr: 0.000485\n",
      "batch 860 loss: 1.51004 acc: 0.69564 | v_loss: 1.36427 v_acc: 0.69889 |  iteration: 8319 teacher: 0 stage: sketch lr: 0.000485\n",
      "batch 861 loss: 1.39258 acc: 0.71126 | v_loss: 1.35295 v_acc: 0.71419 |  iteration: 8320 teacher: 0 stage: sketch lr: 0.000485\n",
      "batch 862 loss: 1.49385 acc: 0.69466 | v_loss: 1.55034 v_acc: 0.69173 |  iteration: 8321 teacher: 0 stage: sketch lr: 0.000484\n",
      "batch 863 loss: 1.47463 acc: 0.70703 | v_loss: 1.41516 v_acc: 0.70247 |  iteration: 8322 teacher: 1 stage: sketch lr: 0.000484\n",
      "batch 864 loss: 1.42764 acc: 0.71322 | v_loss: 1.37478 v_acc: 0.71126 |  iteration: 8323 teacher: 0 stage: sketch lr: 0.000484\n",
      "batch 865 loss: 1.42058 acc: 0.70833 | v_loss: 1.39673 v_acc: 0.71810 |  iteration: 8324 teacher: 1 stage: sketch lr: 0.000484\n",
      "batch 866 loss: 1.45581 acc: 0.69824 | v_loss: 1.31134 v_acc: 0.70215 |  iteration: 8325 teacher: 1 stage: sketch lr: 0.000484\n",
      "batch 867 loss: 1.43416 acc: 0.70866 | v_loss: 1.44714 v_acc: 0.69434 |  iteration: 8326 teacher: 1 stage: sketch lr: 0.000484\n",
      "batch 868 loss: 1.43420 acc: 0.69954 | v_loss: 1.43957 v_acc: 0.71452 |  iteration: 8327 teacher: 1 stage: sketch lr: 0.000484\n",
      "batch 869 loss: 1.56495 acc: 0.68880 | v_loss: 1.30932 v_acc: 0.71647 |  iteration: 8328 teacher: 0 stage: sketch lr: 0.000484\n",
      "batch 870 loss: 1.41914 acc: 0.70150 | v_loss: 1.27790 v_acc: 0.72754 |  iteration: 8329 teacher: 0 stage: sketch lr: 0.000484\n",
      "batch 871 loss: 1.39821 acc: 0.70508 | v_loss: 1.39186 v_acc: 0.71940 |  iteration: 8330 teacher: 1 stage: sketch lr: 0.000484\n",
      "batch 872 loss: 1.33364 acc: 0.71842 | v_loss: 1.43329 v_acc: 0.70345 |  iteration: 8331 teacher: 1 stage: sketch lr: 0.000484\n",
      "batch 873 loss: 1.37241 acc: 0.71842 | v_loss: 1.43666 v_acc: 0.70833 |  iteration: 8332 teacher: 1 stage: sketch lr: 0.000484\n",
      "batch 874 loss: 1.47737 acc: 0.70182 | v_loss: 1.23168 v_acc: 0.72559 |  iteration: 8333 teacher: 0 stage: sketch lr: 0.000484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 875 loss: 1.33654 acc: 0.70312 | v_loss: 1.38928 v_acc: 0.73145 |  iteration: 8334 teacher: 0 stage: sketch lr: 0.000484\n",
      "batch 876 loss: 1.43705 acc: 0.70508 | v_loss: 1.48994 v_acc: 0.69694 |  iteration: 8335 teacher: 0 stage: sketch lr: 0.000484\n",
      "batch 877 loss: 1.57217 acc: 0.69043 | v_loss: 1.43410 v_acc: 0.72070 |  iteration: 8336 teacher: 1 stage: sketch lr: 0.000484\n",
      "batch 878 loss: 1.42763 acc: 0.69596 | v_loss: 1.27446 v_acc: 0.71940 |  iteration: 8337 teacher: 1 stage: sketch lr: 0.000484\n",
      "batch 879 loss: 1.43291 acc: 0.71322 | v_loss: 1.22699 v_acc: 0.73535 |  iteration: 8338 teacher: 1 stage: sketch lr: 0.000484\n",
      "batch 880 loss: 1.40663 acc: 0.69889 | v_loss: 1.23258 v_acc: 0.72656 |  iteration: 8339 teacher: 0 stage: sketch lr: 0.000484\n",
      "batch 881 loss: 1.45203 acc: 0.69499 | v_loss: 1.30800 v_acc: 0.70703 |  iteration: 8340 teacher: 0 stage: sketch lr: 0.000484\n",
      "batch 882 loss: 1.43298 acc: 0.69434 | v_loss: 1.46349 v_acc: 0.69466 |  iteration: 8341 teacher: 1 stage: sketch lr: 0.000484\n",
      "batch 883 loss: 1.42747 acc: 0.70996 | v_loss: 1.29118 v_acc: 0.71484 |  iteration: 8342 teacher: 1 stage: sketch lr: 0.000484\n",
      "batch 884 loss: 1.39860 acc: 0.69629 | v_loss: 1.43582 v_acc: 0.72949 |  iteration: 8343 teacher: 1 stage: sketch lr: 0.000484\n",
      "batch 885 loss: 1.48013 acc: 0.69271 | v_loss: 1.66121 v_acc: 0.69466 |  iteration: 8344 teacher: 1 stage: sketch lr: 0.000484\n",
      "batch 886 loss: 1.41913 acc: 0.71387 | v_loss: 1.54968 v_acc: 0.70117 |  iteration: 8345 teacher: 0 stage: sketch lr: 0.000484\n",
      "batch 887 loss: 1.38251 acc: 0.69629 | v_loss: 1.31380 v_acc: 0.72363 |  iteration: 8346 teacher: 0 stage: sketch lr: 0.000484\n",
      "batch 888 loss: 1.56948 acc: 0.69596 | v_loss: 1.37919 v_acc: 0.70410 |  iteration: 8347 teacher: 0 stage: sketch lr: 0.000484\n",
      "batch 889 loss: 1.40822 acc: 0.70508 | v_loss: 1.22539 v_acc: 0.72201 |  iteration: 8348 teacher: 0 stage: sketch lr: 0.000484\n",
      "batch 890 loss: 1.47190 acc: 0.70312 | v_loss: 1.41712 v_acc: 0.70378 |  iteration: 8349 teacher: 0 stage: sketch lr: 0.000484\n",
      "batch 891 loss: 1.47320 acc: 0.70801 | v_loss: 1.37533 v_acc: 0.71777 |  iteration: 8350 teacher: 1 stage: sketch lr: 0.000484\n",
      "batch 892 loss: 1.41980 acc: 0.69922 | v_loss: 1.35987 v_acc: 0.73079 |  iteration: 8351 teacher: 1 stage: sketch lr: 0.000484\n",
      "batch 893 loss: 1.49101 acc: 0.69629 | v_loss: 1.36917 v_acc: 0.71680 |  iteration: 8352 teacher: 1 stage: sketch lr: 0.000484\n",
      "batch 894 loss: 1.46110 acc: 0.70247 | v_loss: 1.39144 v_acc: 0.70345 |  iteration: 8353 teacher: 1 stage: sketch lr: 0.000484\n",
      "batch 895 loss: 1.51602 acc: 0.69889 | v_loss: 1.30742 v_acc: 0.72201 |  iteration: 8354 teacher: 0 stage: sketch lr: 0.000484\n",
      "batch 896 loss: 1.46496 acc: 0.69434 | v_loss: 1.32287 v_acc: 0.72005 |  iteration: 8355 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 897 loss: 1.41442 acc: 0.70345 | v_loss: 1.53228 v_acc: 0.69043 |  iteration: 8356 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 898 loss: 1.45229 acc: 0.69108 | v_loss: 1.34439 v_acc: 0.70833 |  iteration: 8357 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 899 loss: 1.36497 acc: 0.71159 | v_loss: 1.31136 v_acc: 0.71615 |  iteration: 8358 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 900 loss: 1.42891 acc: 0.69759 | v_loss: 1.30418 v_acc: 0.72201 |  iteration: 8359 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 901 loss: 1.46654 acc: 0.70605 | v_loss: 1.45826 v_acc: 0.70475 |  iteration: 8360 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 902 loss: 1.52022 acc: 0.69238 | v_loss: 1.31993 v_acc: 0.73210 |  iteration: 8361 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 903 loss: 1.39371 acc: 0.70020 | v_loss: 1.54498 v_acc: 0.71615 |  iteration: 8362 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 904 loss: 1.47768 acc: 0.70378 | v_loss: 1.30745 v_acc: 0.69759 |  iteration: 8363 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 905 loss: 1.46038 acc: 0.69206 | v_loss: 1.30430 v_acc: 0.70475 |  iteration: 8364 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 906 loss: 1.57619 acc: 0.68880 | v_loss: 1.43556 v_acc: 0.70312 |  iteration: 8365 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 907 loss: 1.38157 acc: 0.71745 | v_loss: 1.46354 v_acc: 0.70312 |  iteration: 8366 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 908 loss: 1.54057 acc: 0.69499 | v_loss: 1.51277 v_acc: 0.68978 |  iteration: 8367 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 909 loss: 1.44919 acc: 0.69661 | v_loss: 1.47898 v_acc: 0.70540 |  iteration: 8368 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 910 loss: 1.42592 acc: 0.70150 | v_loss: 1.44304 v_acc: 0.70540 |  iteration: 8369 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 911 loss: 1.44395 acc: 0.70931 | v_loss: 1.41301 v_acc: 0.70475 |  iteration: 8370 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 912 loss: 1.41561 acc: 0.70052 | v_loss: 1.44069 v_acc: 0.70312 |  iteration: 8371 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 913 loss: 1.40041 acc: 0.70736 | v_loss: 1.30648 v_acc: 0.71257 |  iteration: 8372 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 914 loss: 1.42315 acc: 0.71094 | v_loss: 1.32586 v_acc: 0.72493 |  iteration: 8373 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 915 loss: 1.52035 acc: 0.69043 | v_loss: 1.23847 v_acc: 0.70671 |  iteration: 8374 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 916 loss: 1.50375 acc: 0.70508 | v_loss: 1.36567 v_acc: 0.70150 |  iteration: 8375 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 917 loss: 1.43248 acc: 0.70085 | v_loss: 1.50121 v_acc: 0.69987 |  iteration: 8376 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 918 loss: 1.42031 acc: 0.70996 | v_loss: 1.36459 v_acc: 0.70540 |  iteration: 8377 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 919 loss: 1.46961 acc: 0.70280 | v_loss: 1.35630 v_acc: 0.69368 |  iteration: 8378 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 920 loss: 1.59450 acc: 0.69108 | v_loss: 1.27735 v_acc: 0.70638 |  iteration: 8379 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 921 loss: 1.51516 acc: 0.69108 | v_loss: 1.27794 v_acc: 0.70410 |  iteration: 8380 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 922 loss: 1.38430 acc: 0.70931 | v_loss: 1.22853 v_acc: 0.73926 |  iteration: 8381 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 923 loss: 1.37318 acc: 0.71159 | v_loss: 1.29051 v_acc: 0.71647 |  iteration: 8382 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 924 loss: 1.43486 acc: 0.71061 | v_loss: 1.33372 v_acc: 0.74089 |  iteration: 8383 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 925 loss: 1.38355 acc: 0.70605 | v_loss: 1.27121 v_acc: 0.72005 |  iteration: 8384 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 926 loss: 1.53613 acc: 0.69531 | v_loss: 1.31684 v_acc: 0.71582 |  iteration: 8385 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 927 loss: 1.47215 acc: 0.70410 | v_loss: 1.41758 v_acc: 0.71224 |  iteration: 8386 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 928 loss: 1.42676 acc: 0.70833 | v_loss: 1.39646 v_acc: 0.72038 |  iteration: 8387 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 929 loss: 1.30764 acc: 0.71745 | v_loss: 1.49883 v_acc: 0.69661 |  iteration: 8388 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 930 loss: 1.39952 acc: 0.70964 | v_loss: 1.42830 v_acc: 0.71615 |  iteration: 8389 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 931 loss: 1.39751 acc: 0.70671 | v_loss: 1.18067 v_acc: 0.74382 |  iteration: 8390 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 932 loss: 1.44762 acc: 0.71354 | v_loss: 1.28354 v_acc: 0.70280 |  iteration: 8391 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 933 loss: 1.37629 acc: 0.71257 | v_loss: 1.52640 v_acc: 0.70247 |  iteration: 8392 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 934 loss: 1.42036 acc: 0.70312 | v_loss: 1.26583 v_acc: 0.70833 |  iteration: 8393 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 935 loss: 1.45611 acc: 0.70247 | v_loss: 1.34284 v_acc: 0.71257 |  iteration: 8394 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 936 loss: 1.38973 acc: 0.70540 | v_loss: 1.37025 v_acc: 0.69531 |  iteration: 8395 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 937 loss: 1.38421 acc: 0.71029 | v_loss: 1.32012 v_acc: 0.70866 |  iteration: 8396 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 938 loss: 1.47493 acc: 0.70410 | v_loss: 1.38126 v_acc: 0.69434 |  iteration: 8397 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 939 loss: 1.35748 acc: 0.70768 | v_loss: 1.49544 v_acc: 0.71712 |  iteration: 8398 teacher: 1 stage: sketch lr: 0.000482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 940 loss: 1.52654 acc: 0.69857 | v_loss: 1.32673 v_acc: 0.72786 |  iteration: 8399 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 941 loss: 1.48691 acc: 0.69531 | v_loss: 1.44657 v_acc: 0.70540 |  iteration: 8400 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 942 loss: 1.60557 acc: 0.69010 | v_loss: 1.38277 v_acc: 0.69857 |  iteration: 8401 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 943 loss: 1.56631 acc: 0.68685 | v_loss: 1.34374 v_acc: 0.70833 |  iteration: 8402 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 944 loss: 1.43738 acc: 0.70801 | v_loss: 1.58255 v_acc: 0.68522 |  iteration: 8403 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 945 loss: 1.46334 acc: 0.70312 | v_loss: 1.30383 v_acc: 0.72005 |  iteration: 8404 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 946 loss: 1.41478 acc: 0.70280 | v_loss: 1.60683 v_acc: 0.68620 |  iteration: 8405 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 947 loss: 1.47839 acc: 0.69759 | v_loss: 1.44924 v_acc: 0.69987 |  iteration: 8406 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 948 loss: 1.44729 acc: 0.70182 | v_loss: 1.51635 v_acc: 0.68913 |  iteration: 8407 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 949 loss: 1.43443 acc: 0.70964 | v_loss: 1.38571 v_acc: 0.69759 |  iteration: 8408 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 950 loss: 1.39878 acc: 0.70117 | v_loss: 1.35577 v_acc: 0.70215 |  iteration: 8409 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 951 loss: 1.53915 acc: 0.69303 | v_loss: 1.36030 v_acc: 0.69889 |  iteration: 8410 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 952 loss: 1.40571 acc: 0.70671 | v_loss: 1.34568 v_acc: 0.71419 |  iteration: 8411 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 953 loss: 1.41132 acc: 0.70378 | v_loss: 1.55264 v_acc: 0.68978 |  iteration: 8412 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 954 loss: 1.40662 acc: 0.70768 | v_loss: 1.39464 v_acc: 0.70443 |  iteration: 8413 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 955 loss: 1.45506 acc: 0.69857 | v_loss: 1.37148 v_acc: 0.71029 |  iteration: 8414 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 956 loss: 1.47410 acc: 0.70182 | v_loss: 1.39288 v_acc: 0.71680 |  iteration: 8415 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 957 loss: 1.47450 acc: 0.70182 | v_loss: 1.28382 v_acc: 0.70573 |  iteration: 8416 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 958 loss: 1.62810 acc: 0.69434 | v_loss: 1.45822 v_acc: 0.69792 |  iteration: 8417 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 959 loss: 1.42614 acc: 0.71224 | v_loss: 1.42934 v_acc: 0.71191 |  iteration: 8418 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 960 loss: 1.44849 acc: 0.70605 | v_loss: 1.29793 v_acc: 0.72266 |  iteration: 8419 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 961 loss: 1.52713 acc: 0.70085 | v_loss: 1.28265 v_acc: 0.72331 |  iteration: 8420 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 962 loss: 1.59225 acc: 0.69368 | v_loss: 1.43617 v_acc: 0.70996 |  iteration: 8421 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 963 loss: 1.47166 acc: 0.69596 | v_loss: 1.43739 v_acc: 0.69694 |  iteration: 8422 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 964 loss: 1.47076 acc: 0.70150 | v_loss: 1.43194 v_acc: 0.70215 |  iteration: 8423 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 965 loss: 1.50284 acc: 0.71061 | v_loss: 1.28048 v_acc: 0.71126 |  iteration: 8424 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 966 loss: 1.50604 acc: 0.69434 | v_loss: 1.38303 v_acc: 0.72591 |  iteration: 8425 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 967 loss: 1.47223 acc: 0.69727 | v_loss: 1.46934 v_acc: 0.70117 |  iteration: 8426 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 968 loss: 1.45753 acc: 0.69694 | v_loss: 1.40732 v_acc: 0.71842 |  iteration: 8427 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 969 loss: 1.51008 acc: 0.69661 | v_loss: 1.27662 v_acc: 0.71810 |  iteration: 8428 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 970 loss: 1.48359 acc: 0.70508 | v_loss: 1.21902 v_acc: 0.74023 |  iteration: 8429 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 971 loss: 1.44334 acc: 0.70378 | v_loss: 1.22611 v_acc: 0.72591 |  iteration: 8430 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 972 loss: 1.43741 acc: 0.70443 | v_loss: 1.29398 v_acc: 0.71126 |  iteration: 8431 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 973 loss: 1.43845 acc: 0.70475 | v_loss: 1.46340 v_acc: 0.70671 |  iteration: 8432 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 974 loss: 1.53916 acc: 0.68913 | v_loss: 1.27524 v_acc: 0.71549 |  iteration: 8433 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 975 loss: 1.37061 acc: 0.70378 | v_loss: 1.49453 v_acc: 0.70475 |  iteration: 8434 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 976 loss: 1.50061 acc: 0.70052 | v_loss: 1.70510 v_acc: 0.69108 |  iteration: 8435 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 977 loss: 1.42518 acc: 0.69727 | v_loss: 1.54987 v_acc: 0.69368 |  iteration: 8436 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 978 loss: 1.39826 acc: 0.70085 | v_loss: 1.30871 v_acc: 0.71582 |  iteration: 8437 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 979 loss: 1.43397 acc: 0.69792 | v_loss: 1.38491 v_acc: 0.70671 |  iteration: 8438 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 980 loss: 1.40650 acc: 0.70150 | v_loss: 1.23446 v_acc: 0.71777 |  iteration: 8439 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 981 loss: 1.43728 acc: 0.69792 | v_loss: 1.42777 v_acc: 0.69792 |  iteration: 8440 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 982 loss: 1.52234 acc: 0.68685 | v_loss: 1.36769 v_acc: 0.71257 |  iteration: 8441 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 983 loss: 1.44879 acc: 0.70345 | v_loss: 1.35755 v_acc: 0.72884 |  iteration: 8442 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 984 loss: 1.47976 acc: 0.70703 | v_loss: 1.35620 v_acc: 0.71680 |  iteration: 8443 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 985 loss: 1.51073 acc: 0.70280 | v_loss: 1.39315 v_acc: 0.70345 |  iteration: 8444 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 986 loss: 1.48883 acc: 0.70215 | v_loss: 1.31864 v_acc: 0.72201 |  iteration: 8445 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 987 loss: 1.51499 acc: 0.69173 | v_loss: 1.32289 v_acc: 0.72005 |  iteration: 8446 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 988 loss: 1.41400 acc: 0.70736 | v_loss: 1.56367 v_acc: 0.69043 |  iteration: 8447 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 989 loss: 1.43016 acc: 0.70866 | v_loss: 1.36115 v_acc: 0.70833 |  iteration: 8448 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 990 loss: 1.56881 acc: 0.68913 | v_loss: 1.30739 v_acc: 0.71582 |  iteration: 8449 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 991 loss: 1.48206 acc: 0.69434 | v_loss: 1.30284 v_acc: 0.72201 |  iteration: 8450 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 992 loss: 1.40490 acc: 0.70964 | v_loss: 1.43492 v_acc: 0.70768 |  iteration: 8451 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 993 loss: 1.41929 acc: 0.70996 | v_loss: 1.32888 v_acc: 0.73210 |  iteration: 8452 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 994 loss: 1.47934 acc: 0.70117 | v_loss: 1.52412 v_acc: 0.71322 |  iteration: 8453 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 995 loss: 1.43264 acc: 0.70898 | v_loss: 1.31395 v_acc: 0.69759 |  iteration: 8454 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 996 loss: 1.50044 acc: 0.69661 | v_loss: 1.30456 v_acc: 0.70573 |  iteration: 8455 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 997 loss: 1.56154 acc: 0.70117 | v_loss: 1.42624 v_acc: 0.70378 |  iteration: 8456 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 998 loss: 1.52828 acc: 0.69661 | v_loss: 1.45647 v_acc: 0.70150 |  iteration: 8457 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 999 loss: 1.46725 acc: 0.70605 | v_loss: 1.50107 v_acc: 0.68978 |  iteration: 8458 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 1000 loss: 1.40140 acc: 0.70540 | v_loss: 1.48179 v_acc: 0.70540 |  iteration: 8459 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 1001 loss: 1.43271 acc: 0.70508 | v_loss: 1.43983 v_acc: 0.70540 |  iteration: 8460 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1002 loss: 1.40421 acc: 0.70703 | v_loss: 1.41969 v_acc: 0.70475 |  iteration: 8461 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1003 loss: 1.49149 acc: 0.70117 | v_loss: 1.42076 v_acc: 0.70312 |  iteration: 8462 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1004 loss: 1.47510 acc: 0.70573 | v_loss: 1.28107 v_acc: 0.71257 |  iteration: 8463 teacher: 0 stage: sketch lr: 0.000480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1005 loss: 1.51975 acc: 0.68685 | v_loss: 1.34560 v_acc: 0.72493 |  iteration: 8464 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1006 loss: 1.50813 acc: 0.70215 | v_loss: 1.21472 v_acc: 0.70671 |  iteration: 8465 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1007 loss: 1.50061 acc: 0.70247 | v_loss: 1.36200 v_acc: 0.70150 |  iteration: 8466 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1008 loss: 1.55832 acc: 0.69596 | v_loss: 1.49457 v_acc: 0.69987 |  iteration: 8467 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1009 loss: 1.48217 acc: 0.69954 | v_loss: 1.34864 v_acc: 0.70540 |  iteration: 8468 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1010 loss: 1.38739 acc: 0.69629 | v_loss: 1.36146 v_acc: 0.69368 |  iteration: 8469 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1011 loss: 1.51622 acc: 0.69043 | v_loss: 1.29525 v_acc: 0.70638 |  iteration: 8470 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1012 loss: 1.42779 acc: 0.70150 | v_loss: 1.29829 v_acc: 0.70215 |  iteration: 8471 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1013 loss: 1.43626 acc: 0.70605 | v_loss: 1.23731 v_acc: 0.73340 |  iteration: 8472 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1014 loss: 1.34180 acc: 0.70964 | v_loss: 1.28597 v_acc: 0.71647 |  iteration: 8473 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1015 loss: 1.39964 acc: 0.71484 | v_loss: 1.34721 v_acc: 0.74089 |  iteration: 8474 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1016 loss: 1.44974 acc: 0.70378 | v_loss: 1.27019 v_acc: 0.72005 |  iteration: 8475 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1017 loss: 1.38390 acc: 0.71582 | v_loss: 1.32248 v_acc: 0.71582 |  iteration: 8476 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1018 loss: 1.48590 acc: 0.70150 | v_loss: 1.44889 v_acc: 0.71224 |  iteration: 8477 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1019 loss: 1.34324 acc: 0.70573 | v_loss: 1.43214 v_acc: 0.72070 |  iteration: 8478 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1020 loss: 1.57216 acc: 0.68392 | v_loss: 1.50833 v_acc: 0.69954 |  iteration: 8479 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1021 loss: 1.34687 acc: 0.72428 | v_loss: 1.44718 v_acc: 0.71615 |  iteration: 8480 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1022 loss: 1.42406 acc: 0.70443 | v_loss: 1.18333 v_acc: 0.74544 |  iteration: 8481 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1023 loss: 1.48046 acc: 0.69596 | v_loss: 1.25102 v_acc: 0.70931 |  iteration: 8482 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1024 loss: 1.41998 acc: 0.70703 | v_loss: 1.51578 v_acc: 0.70378 |  iteration: 8483 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1025 loss: 1.44891 acc: 0.70345 | v_loss: 1.24027 v_acc: 0.71647 |  iteration: 8484 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1026 loss: 1.46167 acc: 0.70182 | v_loss: 1.34896 v_acc: 0.71191 |  iteration: 8485 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1027 loss: 1.49097 acc: 0.69629 | v_loss: 1.37796 v_acc: 0.69076 |  iteration: 8486 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1028 loss: 1.43176 acc: 0.70345 | v_loss: 1.32109 v_acc: 0.70898 |  iteration: 8487 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1029 loss: 1.45904 acc: 0.70150 | v_loss: 1.37750 v_acc: 0.69206 |  iteration: 8488 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1030 loss: 1.48918 acc: 0.68848 | v_loss: 1.49735 v_acc: 0.70768 |  iteration: 8489 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1031 loss: 1.46291 acc: 0.70182 | v_loss: 1.32649 v_acc: 0.72363 |  iteration: 8490 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1032 loss: 1.46487 acc: 0.68848 | v_loss: 1.46608 v_acc: 0.70117 |  iteration: 8491 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1033 loss: 1.41683 acc: 0.70215 | v_loss: 1.37703 v_acc: 0.70085 |  iteration: 8492 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1034 loss: 1.37536 acc: 0.70736 | v_loss: 1.33800 v_acc: 0.70866 |  iteration: 8493 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1035 loss: 1.46445 acc: 0.68913 | v_loss: 1.58418 v_acc: 0.68522 |  iteration: 8494 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1036 loss: 1.37741 acc: 0.70996 | v_loss: 1.29896 v_acc: 0.72005 |  iteration: 8495 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1037 loss: 1.52596 acc: 0.69499 | v_loss: 1.60976 v_acc: 0.68620 |  iteration: 8496 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1038 loss: 1.46912 acc: 0.70215 | v_loss: 1.45279 v_acc: 0.69987 |  iteration: 8497 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1039 loss: 1.41392 acc: 0.70475 | v_loss: 1.50663 v_acc: 0.68913 |  iteration: 8498 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1040 loss: 1.42145 acc: 0.70085 | v_loss: 1.40169 v_acc: 0.69759 |  iteration: 8499 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1041 loss: 1.40624 acc: 0.70247 | v_loss: 1.34116 v_acc: 0.70215 |  iteration: 8500 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1042 loss: 1.42252 acc: 0.71257 | v_loss: 1.35808 v_acc: 0.69889 |  iteration: 8501 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1043 loss: 1.41983 acc: 0.70898 | v_loss: 1.34443 v_acc: 0.71419 |  iteration: 8502 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1044 loss: 1.36796 acc: 0.70443 | v_loss: 1.53532 v_acc: 0.69173 |  iteration: 8503 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1045 loss: 1.50256 acc: 0.69727 | v_loss: 1.39039 v_acc: 0.70247 |  iteration: 8504 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1046 loss: 1.40323 acc: 0.69727 | v_loss: 1.36514 v_acc: 0.71126 |  iteration: 8505 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1047 loss: 1.40992 acc: 0.70052 | v_loss: 1.40179 v_acc: 0.71810 |  iteration: 8506 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1048 loss: 1.53956 acc: 0.69076 | v_loss: 1.28250 v_acc: 0.70215 |  iteration: 8507 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1049 loss: 1.24118 acc: 0.71615 | v_loss: 1.44924 v_acc: 0.69434 |  iteration: 8508 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1050 loss: 1.38617 acc: 0.70378 | v_loss: 1.44995 v_acc: 0.71452 |  iteration: 8509 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1051 loss: 1.54477 acc: 0.68685 | v_loss: 1.30060 v_acc: 0.71875 |  iteration: 8510 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1052 loss: 1.27640 acc: 0.71484 | v_loss: 1.27424 v_acc: 0.72754 |  iteration: 8511 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1053 loss: 1.43181 acc: 0.70443 | v_loss: 1.39318 v_acc: 0.72266 |  iteration: 8512 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1054 loss: 1.49827 acc: 0.70085 | v_loss: 1.42966 v_acc: 0.70410 |  iteration: 8513 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1055 loss: 1.41154 acc: 0.70638 | v_loss: 1.44371 v_acc: 0.70833 |  iteration: 8514 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1056 loss: 1.39218 acc: 0.70605 | v_loss: 1.22791 v_acc: 0.72591 |  iteration: 8515 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1057 loss: 1.52111 acc: 0.69922 | v_loss: 1.39225 v_acc: 0.73079 |  iteration: 8516 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1058 loss: 1.44666 acc: 0.71126 | v_loss: 1.47477 v_acc: 0.69792 |  iteration: 8517 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1059 loss: 1.34806 acc: 0.70345 | v_loss: 1.44876 v_acc: 0.72233 |  iteration: 8518 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1060 loss: 1.42126 acc: 0.70996 | v_loss: 1.28557 v_acc: 0.71484 |  iteration: 8519 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1061 loss: 1.55920 acc: 0.69466 | v_loss: 1.23732 v_acc: 0.73210 |  iteration: 8520 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1062 loss: 1.47414 acc: 0.70150 | v_loss: 1.23349 v_acc: 0.72656 |  iteration: 8521 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1063 loss: 1.37973 acc: 0.71647 | v_loss: 1.31359 v_acc: 0.70703 |  iteration: 8522 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1064 loss: 1.51194 acc: 0.69043 | v_loss: 1.45206 v_acc: 0.69466 |  iteration: 8523 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1065 loss: 1.45871 acc: 0.70280 | v_loss: 1.29267 v_acc: 0.71484 |  iteration: 8524 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1066 loss: 1.43477 acc: 0.70378 | v_loss: 1.43191 v_acc: 0.72949 |  iteration: 8525 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1067 loss: 1.29282 acc: 0.71680 | v_loss: 1.64395 v_acc: 0.69466 |  iteration: 8526 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1068 loss: 1.47593 acc: 0.70182 | v_loss: 1.51996 v_acc: 0.70410 |  iteration: 8527 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1069 loss: 1.31585 acc: 0.71810 | v_loss: 1.30818 v_acc: 0.72005 |  iteration: 8528 teacher: 1 stage: sketch lr: 0.000479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1070 loss: 1.38390 acc: 0.71126 | v_loss: 1.39417 v_acc: 0.69987 |  iteration: 8529 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1071 loss: 1.39216 acc: 0.71647 | v_loss: 1.23106 v_acc: 0.71940 |  iteration: 8530 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1072 loss: 1.42445 acc: 0.69954 | v_loss: 1.44132 v_acc: 0.70378 |  iteration: 8531 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1073 loss: 1.44304 acc: 0.70410 | v_loss: 1.36946 v_acc: 0.71810 |  iteration: 8532 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1074 loss: 1.61313 acc: 0.69629 | v_loss: 1.37019 v_acc: 0.72754 |  iteration: 8533 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1075 loss: 1.40630 acc: 0.70215 | v_loss: 1.40840 v_acc: 0.71842 |  iteration: 8534 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1076 loss: 1.48636 acc: 0.70638 | v_loss: 1.40257 v_acc: 0.71159 |  iteration: 8535 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1077 loss: 1.47640 acc: 0.70671 | v_loss: 1.29156 v_acc: 0.72461 |  iteration: 8536 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1078 loss: 1.56254 acc: 0.69206 | v_loss: 1.32065 v_acc: 0.71712 |  iteration: 8537 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1079 loss: 1.44577 acc: 0.69499 | v_loss: 1.50025 v_acc: 0.68457 |  iteration: 8538 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1080 loss: 1.45808 acc: 0.70996 | v_loss: 1.36317 v_acc: 0.70931 |  iteration: 8539 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1081 loss: 1.42546 acc: 0.70280 | v_loss: 1.31701 v_acc: 0.71257 |  iteration: 8540 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1082 loss: 1.40181 acc: 0.70182 | v_loss: 1.30113 v_acc: 0.72624 |  iteration: 8541 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1083 loss: 1.41346 acc: 0.69987 | v_loss: 1.43508 v_acc: 0.70508 |  iteration: 8542 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1084 loss: 1.31014 acc: 0.71940 | v_loss: 1.33062 v_acc: 0.73210 |  iteration: 8543 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1085 loss: 1.35367 acc: 0.71875 | v_loss: 1.55028 v_acc: 0.71322 |  iteration: 8544 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1086 loss: 1.39033 acc: 0.70964 | v_loss: 1.29114 v_acc: 0.69824 |  iteration: 8545 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1087 loss: 1.43462 acc: 0.69466 | v_loss: 1.29931 v_acc: 0.70573 |  iteration: 8546 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1088 loss: 1.37832 acc: 0.70931 | v_loss: 1.46749 v_acc: 0.70312 |  iteration: 8547 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1089 loss: 1.51498 acc: 0.69954 | v_loss: 1.49665 v_acc: 0.70117 |  iteration: 8548 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1090 loss: 1.48119 acc: 0.70280 | v_loss: 1.53383 v_acc: 0.69368 |  iteration: 8549 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1091 loss: 1.46943 acc: 0.69727 | v_loss: 1.49087 v_acc: 0.70833 |  iteration: 8550 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1092 loss: 1.36013 acc: 0.70964 | v_loss: 1.43699 v_acc: 0.70410 |  iteration: 8551 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1093 loss: 1.47918 acc: 0.69661 | v_loss: 1.42396 v_acc: 0.70475 |  iteration: 8552 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1094 loss: 1.35504 acc: 0.71322 | v_loss: 1.41175 v_acc: 0.70312 |  iteration: 8553 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1095 loss: 1.44638 acc: 0.69727 | v_loss: 1.28707 v_acc: 0.71029 |  iteration: 8554 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1096 loss: 1.40941 acc: 0.71387 | v_loss: 1.33915 v_acc: 0.72493 |  iteration: 8555 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1097 loss: 1.40261 acc: 0.69954 | v_loss: 1.24400 v_acc: 0.70605 |  iteration: 8556 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1098 loss: 1.36250 acc: 0.70378 | v_loss: 1.35621 v_acc: 0.69987 |  iteration: 8557 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1099 loss: 1.45832 acc: 0.69954 | v_loss: 1.49442 v_acc: 0.69987 |  iteration: 8558 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1100 loss: 1.39796 acc: 0.70345 | v_loss: 1.32693 v_acc: 0.71484 |  iteration: 8559 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1101 loss: 1.57009 acc: 0.69792 | v_loss: 1.37490 v_acc: 0.70312 |  iteration: 8560 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1102 loss: 1.40083 acc: 0.70671 | v_loss: 1.25397 v_acc: 0.71973 |  iteration: 8561 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1103 loss: 1.51127 acc: 0.70573 | v_loss: 1.29782 v_acc: 0.70833 |  iteration: 8562 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1104 loss: 1.46558 acc: 0.70215 | v_loss: 1.24026 v_acc: 0.73372 |  iteration: 8563 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1105 loss: 1.56789 acc: 0.69466 | v_loss: 1.28335 v_acc: 0.72461 |  iteration: 8564 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1106 loss: 1.42741 acc: 0.70768 | v_loss: 1.33754 v_acc: 0.74089 |  iteration: 8565 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1107 loss: 1.49203 acc: 0.69954 | v_loss: 1.28141 v_acc: 0.72005 |  iteration: 8566 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1108 loss: 1.40635 acc: 0.70410 | v_loss: 1.31753 v_acc: 0.71484 |  iteration: 8567 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1109 loss: 1.38117 acc: 0.70638 | v_loss: 1.42619 v_acc: 0.71094 |  iteration: 8568 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1110 loss: 1.50536 acc: 0.69336 | v_loss: 1.40141 v_acc: 0.72038 |  iteration: 8569 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1111 loss: 1.57585 acc: 0.69401 | v_loss: 1.50360 v_acc: 0.69759 |  iteration: 8570 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1112 loss: 1.43960 acc: 0.69987 | v_loss: 1.44875 v_acc: 0.71745 |  iteration: 8571 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1113 loss: 1.42469 acc: 0.70931 | v_loss: 1.19158 v_acc: 0.74382 |  iteration: 8572 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1114 loss: 1.47703 acc: 0.70312 | v_loss: 1.26521 v_acc: 0.70312 |  iteration: 8573 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1115 loss: 1.38683 acc: 0.70964 | v_loss: 1.52440 v_acc: 0.70052 |  iteration: 8574 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1116 loss: 1.39432 acc: 0.70508 | v_loss: 1.22942 v_acc: 0.70671 |  iteration: 8575 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1117 loss: 1.49238 acc: 0.70443 | v_loss: 1.34747 v_acc: 0.71257 |  iteration: 8576 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1118 loss: 1.45485 acc: 0.70573 | v_loss: 1.39755 v_acc: 0.69368 |  iteration: 8577 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1119 loss: 1.35244 acc: 0.71484 | v_loss: 1.33654 v_acc: 0.70898 |  iteration: 8578 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1120 loss: 1.42054 acc: 0.71419 | v_loss: 1.39189 v_acc: 0.69206 |  iteration: 8579 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1121 loss: 1.51676 acc: 0.69531 | v_loss: 1.46558 v_acc: 0.70931 |  iteration: 8580 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1122 loss: 1.46481 acc: 0.69694 | v_loss: 1.32104 v_acc: 0.72201 |  iteration: 8581 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1123 loss: 1.41610 acc: 0.70215 | v_loss: 1.45226 v_acc: 0.70150 |  iteration: 8582 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1124 loss: 1.38047 acc: 0.71029 | v_loss: 1.36353 v_acc: 0.70247 |  iteration: 8583 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1125 loss: 1.42735 acc: 0.70736 | v_loss: 1.35203 v_acc: 0.70247 |  iteration: 8584 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1126 loss: 1.34626 acc: 0.71289 | v_loss: 1.55396 v_acc: 0.68587 |  iteration: 8585 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1127 loss: 1.43046 acc: 0.70801 | v_loss: 1.32226 v_acc: 0.72103 |  iteration: 8586 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1128 loss: 1.53281 acc: 0.69434 | v_loss: 1.60382 v_acc: 0.68294 |  iteration: 8587 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1129 loss: 1.53267 acc: 0.69759 | v_loss: 1.44597 v_acc: 0.70020 |  iteration: 8588 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1130 loss: 1.44030 acc: 0.70540 | v_loss: 1.53251 v_acc: 0.69238 |  iteration: 8589 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1131 loss: 1.40964 acc: 0.70540 | v_loss: 1.39944 v_acc: 0.70182 |  iteration: 8590 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1132 loss: 1.37241 acc: 0.71126 | v_loss: 1.33749 v_acc: 0.70638 |  iteration: 8591 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1133 loss: 1.51305 acc: 0.69694 | v_loss: 1.34958 v_acc: 0.70410 |  iteration: 8592 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1134 loss: 1.52533 acc: 0.70247 | v_loss: 1.35742 v_acc: 0.71484 |  iteration: 8593 teacher: 1 stage: sketch lr: 0.000477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1135 loss: 1.46389 acc: 0.69759 | v_loss: 1.53040 v_acc: 0.69173 |  iteration: 8594 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1136 loss: 1.45515 acc: 0.70605 | v_loss: 1.39543 v_acc: 0.70247 |  iteration: 8595 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1137 loss: 1.47075 acc: 0.70605 | v_loss: 1.36182 v_acc: 0.71126 |  iteration: 8596 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1138 loss: 1.46322 acc: 0.69661 | v_loss: 1.39805 v_acc: 0.71810 |  iteration: 8597 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1139 loss: 1.53608 acc: 0.69922 | v_loss: 1.30725 v_acc: 0.70215 |  iteration: 8598 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1140 loss: 1.41956 acc: 0.70443 | v_loss: 1.44091 v_acc: 0.69434 |  iteration: 8599 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1141 loss: 1.39353 acc: 0.70736 | v_loss: 1.42158 v_acc: 0.71452 |  iteration: 8600 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1142 loss: 1.42459 acc: 0.70671 | v_loss: 1.30158 v_acc: 0.71647 |  iteration: 8601 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1143 loss: 1.49711 acc: 0.70215 | v_loss: 1.26896 v_acc: 0.72526 |  iteration: 8602 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1144 loss: 1.46229 acc: 0.70540 | v_loss: 1.37935 v_acc: 0.71615 |  iteration: 8603 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1145 loss: 1.44435 acc: 0.69564 | v_loss: 1.42093 v_acc: 0.70540 |  iteration: 8604 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1146 loss: 1.48993 acc: 0.69336 | v_loss: 1.43064 v_acc: 0.70508 |  iteration: 8605 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1147 loss: 1.39331 acc: 0.71126 | v_loss: 1.24021 v_acc: 0.71452 |  iteration: 8606 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1148 loss: 1.41721 acc: 0.69629 | v_loss: 1.39542 v_acc: 0.72819 |  iteration: 8607 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1149 loss: 1.49356 acc: 0.70247 | v_loss: 1.47987 v_acc: 0.69792 |  iteration: 8608 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1150 loss: 1.50444 acc: 0.69759 | v_loss: 1.40858 v_acc: 0.71842 |  iteration: 8609 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1151 loss: 1.44518 acc: 0.70280 | v_loss: 1.25981 v_acc: 0.71810 |  iteration: 8610 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1152 loss: 1.45355 acc: 0.70443 | v_loss: 1.22250 v_acc: 0.73535 |  iteration: 8611 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1153 loss: 1.44729 acc: 0.69629 | v_loss: 1.22729 v_acc: 0.72656 |  iteration: 8612 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1154 loss: 1.39639 acc: 0.70247 | v_loss: 1.30297 v_acc: 0.70703 |  iteration: 8613 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1155 loss: 1.39745 acc: 0.70345 | v_loss: 1.44890 v_acc: 0.69466 |  iteration: 8614 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1156 loss: 1.50139 acc: 0.69857 | v_loss: 1.30312 v_acc: 0.71484 |  iteration: 8615 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1157 loss: 1.47361 acc: 0.70573 | v_loss: 1.46465 v_acc: 0.72949 |  iteration: 8616 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1158 loss: 1.37188 acc: 0.70931 | v_loss: 1.63647 v_acc: 0.69466 |  iteration: 8617 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1159 loss: 1.54428 acc: 0.68424 | v_loss: 1.51051 v_acc: 0.70410 |  iteration: 8618 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1160 loss: 1.45013 acc: 0.69954 | v_loss: 1.30487 v_acc: 0.72005 |  iteration: 8619 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1161 loss: 1.32646 acc: 0.72135 | v_loss: 1.38443 v_acc: 0.69987 |  iteration: 8620 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1162 loss: 1.39329 acc: 0.71061 | v_loss: 1.24380 v_acc: 0.71615 |  iteration: 8621 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1163 loss: 1.42059 acc: 0.70703 | v_loss: 1.43529 v_acc: 0.69857 |  iteration: 8622 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1164 loss: 1.47270 acc: 0.70020 | v_loss: 1.36103 v_acc: 0.70964 |  iteration: 8623 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1165 loss: 1.43932 acc: 0.70964 | v_loss: 1.36592 v_acc: 0.72949 |  iteration: 8624 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1166 loss: 1.37661 acc: 0.70182 | v_loss: 1.36893 v_acc: 0.71680 |  iteration: 8625 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1167 loss: 1.48826 acc: 0.70215 | v_loss: 1.38602 v_acc: 0.70345 |  iteration: 8626 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1168 loss: 1.57196 acc: 0.69629 | v_loss: 1.30630 v_acc: 0.72201 |  iteration: 8627 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1169 loss: 1.38867 acc: 0.69629 | v_loss: 1.31252 v_acc: 0.72005 |  iteration: 8628 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1170 loss: 1.40012 acc: 0.70150 | v_loss: 1.52015 v_acc: 0.69303 |  iteration: 8629 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1171 loss: 1.56941 acc: 0.69076 | v_loss: 1.33416 v_acc: 0.71452 |  iteration: 8630 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1172 loss: 1.44806 acc: 0.69759 | v_loss: 1.30029 v_acc: 0.71777 |  iteration: 8631 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1173 loss: 1.44364 acc: 0.70247 | v_loss: 1.30454 v_acc: 0.71484 |  iteration: 8632 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1174 loss: 1.37784 acc: 0.70540 | v_loss: 1.45349 v_acc: 0.70540 |  iteration: 8633 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1175 loss: 1.39841 acc: 0.70638 | v_loss: 1.31826 v_acc: 0.73047 |  iteration: 8634 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1176 loss: 1.43591 acc: 0.69857 | v_loss: 1.52456 v_acc: 0.71322 |  iteration: 8635 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1177 loss: 1.28843 acc: 0.71322 | v_loss: 1.30709 v_acc: 0.69531 |  iteration: 8636 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1178 loss: 1.54425 acc: 0.70052 | v_loss: 1.29699 v_acc: 0.70117 |  iteration: 8637 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1179 loss: 1.45365 acc: 0.69206 | v_loss: 1.45320 v_acc: 0.70508 |  iteration: 8638 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1180 loss: 1.47315 acc: 0.69922 | v_loss: 1.48853 v_acc: 0.70573 |  iteration: 8639 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1181 loss: 1.49195 acc: 0.70182 | v_loss: 1.53958 v_acc: 0.68978 |  iteration: 8640 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1182 loss: 1.47330 acc: 0.70443 | v_loss: 1.47495 v_acc: 0.70540 |  iteration: 8641 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1183 loss: 1.53961 acc: 0.68978 | v_loss: 1.43847 v_acc: 0.70540 |  iteration: 8642 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1184 loss: 1.43313 acc: 0.69303 | v_loss: 1.41770 v_acc: 0.70475 |  iteration: 8643 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1185 loss: 1.48118 acc: 0.70020 | v_loss: 1.42375 v_acc: 0.70312 |  iteration: 8644 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1186 loss: 1.34909 acc: 0.71680 | v_loss: 1.29028 v_acc: 0.71257 |  iteration: 8645 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1187 loss: 1.58206 acc: 0.69010 | v_loss: 1.32512 v_acc: 0.72493 |  iteration: 8646 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1188 loss: 1.50456 acc: 0.69596 | v_loss: 1.21974 v_acc: 0.70671 |  iteration: 8647 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1189 loss: 1.44576 acc: 0.70247 | v_loss: 1.35838 v_acc: 0.70150 |  iteration: 8648 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1190 loss: 1.39423 acc: 0.69922 | v_loss: 1.49558 v_acc: 0.69987 |  iteration: 8649 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1191 loss: 1.39165 acc: 0.70638 | v_loss: 1.35510 v_acc: 0.70540 |  iteration: 8650 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1192 loss: 1.49188 acc: 0.69629 | v_loss: 1.37311 v_acc: 0.69368 |  iteration: 8651 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1193 loss: 1.49720 acc: 0.69629 | v_loss: 1.25977 v_acc: 0.70573 |  iteration: 8652 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1194 loss: 1.46383 acc: 0.70215 | v_loss: 1.27762 v_acc: 0.70215 |  iteration: 8653 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1195 loss: 1.56432 acc: 0.70443 | v_loss: 1.25534 v_acc: 0.73340 |  iteration: 8654 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1196 loss: 1.44652 acc: 0.70345 | v_loss: 1.28971 v_acc: 0.71647 |  iteration: 8655 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1197 loss: 1.36275 acc: 0.71322 | v_loss: 1.33423 v_acc: 0.74089 |  iteration: 8656 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1198 loss: 1.41530 acc: 0.70508 | v_loss: 1.27544 v_acc: 0.72005 |  iteration: 8657 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1199 loss: 1.37454 acc: 0.70833 | v_loss: 1.31061 v_acc: 0.71582 |  iteration: 8658 teacher: 0 stage: sketch lr: 0.000475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1200 loss: 1.35362 acc: 0.71354 | v_loss: 1.41721 v_acc: 0.71224 |  iteration: 8659 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1201 loss: 1.52347 acc: 0.70345 | v_loss: 1.40832 v_acc: 0.72070 |  iteration: 8660 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1202 loss: 1.33151 acc: 0.71484 | v_loss: 1.50327 v_acc: 0.69954 |  iteration: 8661 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1203 loss: 1.54325 acc: 0.69043 | v_loss: 1.45743 v_acc: 0.71615 |  iteration: 8662 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1204 loss: 1.46807 acc: 0.69759 | v_loss: 1.19139 v_acc: 0.74512 |  iteration: 8663 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1205 loss: 1.40746 acc: 0.70280 | v_loss: 1.26812 v_acc: 0.70964 |  iteration: 8664 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1206 loss: 1.39463 acc: 0.70736 | v_loss: 1.56950 v_acc: 0.69792 |  iteration: 8665 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1207 loss: 1.43683 acc: 0.70410 | v_loss: 1.23176 v_acc: 0.70671 |  iteration: 8666 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1208 loss: 1.35187 acc: 0.70736 | v_loss: 1.33944 v_acc: 0.71257 |  iteration: 8667 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1209 loss: 1.45163 acc: 0.69954 | v_loss: 1.37433 v_acc: 0.69368 |  iteration: 8668 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1210 loss: 1.38242 acc: 0.71191 | v_loss: 1.29776 v_acc: 0.71842 |  iteration: 8669 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1211 loss: 1.40062 acc: 0.70150 | v_loss: 1.37110 v_acc: 0.70215 |  iteration: 8670 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1212 loss: 1.44790 acc: 0.69792 | v_loss: 1.48228 v_acc: 0.72005 |  iteration: 8671 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1213 loss: 1.40395 acc: 0.70280 | v_loss: 1.33023 v_acc: 0.72689 |  iteration: 8672 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1214 loss: 1.43613 acc: 0.70410 | v_loss: 1.45722 v_acc: 0.70182 |  iteration: 8673 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1215 loss: 1.47195 acc: 0.69857 | v_loss: 1.35107 v_acc: 0.70085 |  iteration: 8674 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1216 loss: 1.48791 acc: 0.70312 | v_loss: 1.35021 v_acc: 0.70703 |  iteration: 8675 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1217 loss: 1.47273 acc: 0.69303 | v_loss: 1.53881 v_acc: 0.68880 |  iteration: 8676 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1218 loss: 1.53640 acc: 0.68880 | v_loss: 1.31317 v_acc: 0.72103 |  iteration: 8677 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1219 loss: 1.50530 acc: 0.68848 | v_loss: 1.58780 v_acc: 0.68620 |  iteration: 8678 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1220 loss: 1.48954 acc: 0.70378 | v_loss: 1.43554 v_acc: 0.69987 |  iteration: 8679 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1221 loss: 1.48724 acc: 0.70052 | v_loss: 1.50662 v_acc: 0.68913 |  iteration: 8680 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1222 loss: 1.57750 acc: 0.69076 | v_loss: 1.38660 v_acc: 0.69759 |  iteration: 8681 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1223 loss: 1.39611 acc: 0.71191 | v_loss: 1.33566 v_acc: 0.70215 |  iteration: 8682 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1224 loss: 1.37713 acc: 0.70866 | v_loss: 1.36094 v_acc: 0.69889 |  iteration: 8683 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 1225 loss: 1.42043 acc: 0.70150 | v_loss: 1.35132 v_acc: 0.71419 |  iteration: 8684 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 1226 loss: 1.40520 acc: 0.71094 | v_loss: 1.54509 v_acc: 0.69173 |  iteration: 8685 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 1227 loss: 1.48589 acc: 0.70117 | v_loss: 1.40729 v_acc: 0.70247 |  iteration: 8686 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 1228 loss: 1.45787 acc: 0.70475 | v_loss: 1.37356 v_acc: 0.71126 |  iteration: 8687 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1229 loss: 1.39094 acc: 0.70703 | v_loss: 1.39768 v_acc: 0.71810 |  iteration: 8688 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 1230 loss: 1.40783 acc: 0.70573 | v_loss: 1.29603 v_acc: 0.70215 |  iteration: 8689 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1231 loss: 1.34906 acc: 0.71191 | v_loss: 1.43767 v_acc: 0.69434 |  iteration: 8690 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1232 loss: 1.43271 acc: 0.69661 | v_loss: 1.42640 v_acc: 0.71452 |  iteration: 8691 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1233 loss: 1.49876 acc: 0.70247 | v_loss: 1.29537 v_acc: 0.71647 |  iteration: 8692 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 1234 loss: 1.48299 acc: 0.69596 | v_loss: 1.26640 v_acc: 0.72526 |  iteration: 8693 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1235 loss: 1.51643 acc: 0.70312 | v_loss: 1.38755 v_acc: 0.71615 |  iteration: 8694 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 1236 loss: 1.40648 acc: 0.70052 | v_loss: 1.41998 v_acc: 0.70605 |  iteration: 8695 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1237 loss: 1.43217 acc: 0.69694 | v_loss: 1.43055 v_acc: 0.70410 |  iteration: 8696 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1238 loss: 1.44308 acc: 0.69987 | v_loss: 1.24940 v_acc: 0.71159 |  iteration: 8697 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 1239 loss: 1.35681 acc: 0.70378 | v_loss: 1.38721 v_acc: 0.72819 |  iteration: 8698 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 1240 loss: 1.35249 acc: 0.71029 | v_loss: 1.48009 v_acc: 0.69792 |  iteration: 8699 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1241 loss: 1.50410 acc: 0.69303 | v_loss: 1.42150 v_acc: 0.71842 |  iteration: 8700 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 1242 loss: 1.45324 acc: 0.71191 | v_loss: 1.25585 v_acc: 0.71810 |  iteration: 8701 teacher: 1 stage: sketch lr: 0.000474\n",
      "epoch 6 loss: 1.46360 acc: 0.70116 | v_loss: 1.38910 v_acc: 0.70984 \n",
      "epoch: 7\n",
      "__________________________________________\n",
      "batch 0 loss: 1.47054 acc: 0.69792 | v_loss: 1.44923 v_acc: 0.70540 |  iteration: 8702 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1 loss: 1.53621 acc: 0.69564 | v_loss: 1.44229 v_acc: 0.70475 |  iteration: 8703 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 2 loss: 1.44034 acc: 0.70605 | v_loss: 1.41605 v_acc: 0.70312 |  iteration: 8704 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 3 loss: 1.38524 acc: 0.70540 | v_loss: 1.27461 v_acc: 0.71354 |  iteration: 8705 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 4 loss: 1.47545 acc: 0.70475 | v_loss: 1.33552 v_acc: 0.72461 |  iteration: 8706 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 5 loss: 1.42533 acc: 0.70833 | v_loss: 1.20083 v_acc: 0.71517 |  iteration: 8707 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 6 loss: 1.43703 acc: 0.70768 | v_loss: 1.35457 v_acc: 0.70703 |  iteration: 8708 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 7 loss: 1.41055 acc: 0.71061 | v_loss: 1.49687 v_acc: 0.69987 |  iteration: 8709 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 8 loss: 1.39333 acc: 0.70866 | v_loss: 1.35964 v_acc: 0.70540 |  iteration: 8710 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 9 loss: 1.50411 acc: 0.70443 | v_loss: 1.35873 v_acc: 0.69987 |  iteration: 8711 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 10 loss: 1.34635 acc: 0.70768 | v_loss: 1.28092 v_acc: 0.70703 |  iteration: 8712 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 11 loss: 1.41637 acc: 0.70475 | v_loss: 1.26463 v_acc: 0.70736 |  iteration: 8713 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 12 loss: 1.35894 acc: 0.71517 | v_loss: 1.24294 v_acc: 0.74447 |  iteration: 8714 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 13 loss: 1.52776 acc: 0.70020 | v_loss: 1.28939 v_acc: 0.71875 |  iteration: 8715 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 14 loss: 1.52142 acc: 0.69596 | v_loss: 1.37941 v_acc: 0.74089 |  iteration: 8716 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 15 loss: 1.53917 acc: 0.69954 | v_loss: 1.27959 v_acc: 0.72005 |  iteration: 8717 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 16 loss: 1.44538 acc: 0.69499 | v_loss: 1.32480 v_acc: 0.71582 |  iteration: 8718 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 17 loss: 1.39434 acc: 0.70573 | v_loss: 1.42299 v_acc: 0.71224 |  iteration: 8719 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 18 loss: 1.44598 acc: 0.70215 | v_loss: 1.38916 v_acc: 0.72038 |  iteration: 8720 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 19 loss: 1.46359 acc: 0.70280 | v_loss: 1.48714 v_acc: 0.69661 |  iteration: 8721 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 20 loss: 1.39925 acc: 0.70475 | v_loss: 1.42344 v_acc: 0.71615 |  iteration: 8722 teacher: 0 stage: sketch lr: 0.000473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 21 loss: 1.48392 acc: 0.69889 | v_loss: 1.18737 v_acc: 0.74544 |  iteration: 8723 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 22 loss: 1.46044 acc: 0.70117 | v_loss: 1.27559 v_acc: 0.70280 |  iteration: 8724 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 23 loss: 1.43262 acc: 0.70475 | v_loss: 1.52321 v_acc: 0.70280 |  iteration: 8725 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 24 loss: 1.54240 acc: 0.70215 | v_loss: 1.25386 v_acc: 0.71647 |  iteration: 8726 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 25 loss: 1.52768 acc: 0.69661 | v_loss: 1.33873 v_acc: 0.71191 |  iteration: 8727 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 26 loss: 1.35519 acc: 0.72233 | v_loss: 1.37540 v_acc: 0.69076 |  iteration: 8728 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 27 loss: 1.44075 acc: 0.70117 | v_loss: 1.33306 v_acc: 0.70898 |  iteration: 8729 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 28 loss: 1.43673 acc: 0.71126 | v_loss: 1.38712 v_acc: 0.69206 |  iteration: 8730 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 29 loss: 1.41587 acc: 0.70605 | v_loss: 1.47291 v_acc: 0.70931 |  iteration: 8731 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 30 loss: 1.47826 acc: 0.70736 | v_loss: 1.31841 v_acc: 0.72363 |  iteration: 8732 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 31 loss: 1.42097 acc: 0.70182 | v_loss: 1.45385 v_acc: 0.70117 |  iteration: 8733 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 32 loss: 1.37536 acc: 0.70866 | v_loss: 1.36648 v_acc: 0.70085 |  iteration: 8734 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 33 loss: 1.44561 acc: 0.70638 | v_loss: 1.34175 v_acc: 0.70703 |  iteration: 8735 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 34 loss: 1.47612 acc: 0.69499 | v_loss: 1.54827 v_acc: 0.68880 |  iteration: 8736 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 35 loss: 1.32873 acc: 0.70540 | v_loss: 1.33229 v_acc: 0.72038 |  iteration: 8737 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 36 loss: 1.61005 acc: 0.68815 | v_loss: 1.61104 v_acc: 0.68197 |  iteration: 8738 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 37 loss: 1.44914 acc: 0.69629 | v_loss: 1.43296 v_acc: 0.69987 |  iteration: 8739 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 38 loss: 1.56213 acc: 0.69694 | v_loss: 1.53441 v_acc: 0.69043 |  iteration: 8740 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 39 loss: 1.41560 acc: 0.70898 | v_loss: 1.38094 v_acc: 0.70020 |  iteration: 8741 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 40 loss: 1.50771 acc: 0.69401 | v_loss: 1.33827 v_acc: 0.70312 |  iteration: 8742 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 41 loss: 1.35466 acc: 0.70215 | v_loss: 1.33497 v_acc: 0.70410 |  iteration: 8743 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 42 loss: 1.46543 acc: 0.70182 | v_loss: 1.34402 v_acc: 0.71842 |  iteration: 8744 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 43 loss: 1.49215 acc: 0.69401 | v_loss: 1.55258 v_acc: 0.69108 |  iteration: 8745 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 44 loss: 1.51632 acc: 0.69889 | v_loss: 1.39920 v_acc: 0.71126 |  iteration: 8746 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 45 loss: 1.40654 acc: 0.70443 | v_loss: 1.35663 v_acc: 0.71029 |  iteration: 8747 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 46 loss: 1.50500 acc: 0.69596 | v_loss: 1.39264 v_acc: 0.71810 |  iteration: 8748 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 47 loss: 1.40020 acc: 0.70638 | v_loss: 1.29929 v_acc: 0.70215 |  iteration: 8749 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 48 loss: 1.38507 acc: 0.70736 | v_loss: 1.43511 v_acc: 0.69434 |  iteration: 8750 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 49 loss: 1.46823 acc: 0.71191 | v_loss: 1.42960 v_acc: 0.71452 |  iteration: 8751 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 50 loss: 1.42612 acc: 0.70508 | v_loss: 1.30685 v_acc: 0.71647 |  iteration: 8752 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 51 loss: 1.38589 acc: 0.71322 | v_loss: 1.27918 v_acc: 0.72526 |  iteration: 8753 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 52 loss: 1.49000 acc: 0.69629 | v_loss: 1.37880 v_acc: 0.71647 |  iteration: 8754 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 53 loss: 1.39601 acc: 0.70540 | v_loss: 1.43156 v_acc: 0.70052 |  iteration: 8755 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 54 loss: 1.38951 acc: 0.70801 | v_loss: 1.44037 v_acc: 0.70833 |  iteration: 8756 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 55 loss: 1.37147 acc: 0.71615 | v_loss: 1.23931 v_acc: 0.72591 |  iteration: 8757 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 56 loss: 1.48362 acc: 0.69206 | v_loss: 1.42366 v_acc: 0.73112 |  iteration: 8758 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 57 loss: 1.46731 acc: 0.70508 | v_loss: 1.49774 v_acc: 0.69759 |  iteration: 8759 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 58 loss: 1.31631 acc: 0.71940 | v_loss: 1.43230 v_acc: 0.72201 |  iteration: 8760 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 59 loss: 1.49922 acc: 0.69857 | v_loss: 1.24494 v_acc: 0.72233 |  iteration: 8761 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 60 loss: 1.37634 acc: 0.70833 | v_loss: 1.20003 v_acc: 0.74186 |  iteration: 8762 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 61 loss: 1.47569 acc: 0.69889 | v_loss: 1.23037 v_acc: 0.72656 |  iteration: 8763 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 62 loss: 1.41172 acc: 0.70475 | v_loss: 1.30672 v_acc: 0.70703 |  iteration: 8764 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 63 loss: 1.54636 acc: 0.69987 | v_loss: 1.46420 v_acc: 0.69466 |  iteration: 8765 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 64 loss: 1.50775 acc: 0.70638 | v_loss: 1.28899 v_acc: 0.71484 |  iteration: 8766 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 65 loss: 1.47402 acc: 0.70020 | v_loss: 1.44453 v_acc: 0.72949 |  iteration: 8767 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 66 loss: 1.49196 acc: 0.70117 | v_loss: 1.62920 v_acc: 0.69466 |  iteration: 8768 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 67 loss: 1.56642 acc: 0.68783 | v_loss: 1.50610 v_acc: 0.70410 |  iteration: 8769 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 68 loss: 1.45248 acc: 0.69857 | v_loss: 1.31046 v_acc: 0.72005 |  iteration: 8770 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 69 loss: 1.52337 acc: 0.69629 | v_loss: 1.38326 v_acc: 0.69987 |  iteration: 8771 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 70 loss: 1.46047 acc: 0.70540 | v_loss: 1.24938 v_acc: 0.71615 |  iteration: 8772 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 71 loss: 1.38150 acc: 0.70280 | v_loss: 1.42056 v_acc: 0.69857 |  iteration: 8773 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 72 loss: 1.50847 acc: 0.69629 | v_loss: 1.36272 v_acc: 0.70964 |  iteration: 8774 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 73 loss: 1.45236 acc: 0.70378 | v_loss: 1.35553 v_acc: 0.72949 |  iteration: 8775 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 74 loss: 1.53782 acc: 0.69303 | v_loss: 1.35566 v_acc: 0.71680 |  iteration: 8776 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 75 loss: 1.36537 acc: 0.71940 | v_loss: 1.37810 v_acc: 0.70345 |  iteration: 8777 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 76 loss: 1.32133 acc: 0.70898 | v_loss: 1.30837 v_acc: 0.72201 |  iteration: 8778 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 77 loss: 1.41988 acc: 0.71094 | v_loss: 1.32377 v_acc: 0.72005 |  iteration: 8779 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 78 loss: 1.40037 acc: 0.70573 | v_loss: 1.51143 v_acc: 0.69043 |  iteration: 8780 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 79 loss: 1.44108 acc: 0.70443 | v_loss: 1.34723 v_acc: 0.70833 |  iteration: 8781 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 80 loss: 1.44261 acc: 0.70247 | v_loss: 1.29830 v_acc: 0.71810 |  iteration: 8782 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 81 loss: 1.51735 acc: 0.70052 | v_loss: 1.30020 v_acc: 0.71484 |  iteration: 8783 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 82 loss: 1.53596 acc: 0.69922 | v_loss: 1.45465 v_acc: 0.70540 |  iteration: 8784 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 83 loss: 1.44132 acc: 0.70443 | v_loss: 1.31688 v_acc: 0.73047 |  iteration: 8785 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 84 loss: 1.44520 acc: 0.69694 | v_loss: 1.55198 v_acc: 0.71582 |  iteration: 8786 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 85 loss: 1.45455 acc: 0.69889 | v_loss: 1.30692 v_acc: 0.70150 |  iteration: 8787 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 86 loss: 1.41886 acc: 0.69564 | v_loss: 1.30140 v_acc: 0.70833 |  iteration: 8788 teacher: 0 stage: sketch lr: 0.000471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 87 loss: 1.53366 acc: 0.68750 | v_loss: 1.43323 v_acc: 0.70475 |  iteration: 8789 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 88 loss: 1.45063 acc: 0.69434 | v_loss: 1.47211 v_acc: 0.70280 |  iteration: 8790 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 89 loss: 1.44718 acc: 0.70280 | v_loss: 1.53397 v_acc: 0.68783 |  iteration: 8791 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 90 loss: 1.42911 acc: 0.70768 | v_loss: 1.47398 v_acc: 0.70540 |  iteration: 8792 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 91 loss: 1.44253 acc: 0.70345 | v_loss: 1.44575 v_acc: 0.70540 |  iteration: 8793 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 92 loss: 1.44214 acc: 0.69922 | v_loss: 1.42747 v_acc: 0.70475 |  iteration: 8794 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 93 loss: 1.44853 acc: 0.70573 | v_loss: 1.41262 v_acc: 0.70312 |  iteration: 8795 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 94 loss: 1.36587 acc: 0.70768 | v_loss: 1.27990 v_acc: 0.71257 |  iteration: 8796 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 95 loss: 1.49327 acc: 0.70215 | v_loss: 1.32872 v_acc: 0.72493 |  iteration: 8797 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 96 loss: 1.41424 acc: 0.71224 | v_loss: 1.20306 v_acc: 0.70671 |  iteration: 8798 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 97 loss: 1.43908 acc: 0.69857 | v_loss: 1.35899 v_acc: 0.70150 |  iteration: 8799 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 98 loss: 1.36652 acc: 0.71517 | v_loss: 1.51782 v_acc: 0.69987 |  iteration: 8800 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 99 loss: 1.44125 acc: 0.70508 | v_loss: 1.35516 v_acc: 0.70833 |  iteration: 8801 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 100 loss: 1.31623 acc: 0.71484 | v_loss: 1.35145 v_acc: 0.69661 |  iteration: 8802 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 101 loss: 1.42077 acc: 0.70378 | v_loss: 1.27880 v_acc: 0.70638 |  iteration: 8803 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 102 loss: 1.43171 acc: 0.70247 | v_loss: 1.25030 v_acc: 0.70703 |  iteration: 8804 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 103 loss: 1.50936 acc: 0.69238 | v_loss: 1.25873 v_acc: 0.74447 |  iteration: 8805 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 104 loss: 1.36320 acc: 0.70703 | v_loss: 1.29821 v_acc: 0.72070 |  iteration: 8806 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 105 loss: 1.48664 acc: 0.68750 | v_loss: 1.37123 v_acc: 0.73177 |  iteration: 8807 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 106 loss: 1.48866 acc: 0.70052 | v_loss: 1.26943 v_acc: 0.72005 |  iteration: 8808 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 107 loss: 1.47810 acc: 0.70475 | v_loss: 1.31515 v_acc: 0.71582 |  iteration: 8809 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 108 loss: 1.54580 acc: 0.68424 | v_loss: 1.41648 v_acc: 0.71224 |  iteration: 8810 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 109 loss: 1.47437 acc: 0.70150 | v_loss: 1.39043 v_acc: 0.72038 |  iteration: 8811 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 110 loss: 1.42811 acc: 0.69759 | v_loss: 1.49081 v_acc: 0.69661 |  iteration: 8812 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 111 loss: 1.49281 acc: 0.69531 | v_loss: 1.40678 v_acc: 0.71745 |  iteration: 8813 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 112 loss: 1.37826 acc: 0.70247 | v_loss: 1.19446 v_acc: 0.74382 |  iteration: 8814 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 113 loss: 1.53597 acc: 0.70085 | v_loss: 1.28219 v_acc: 0.70280 |  iteration: 8815 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 114 loss: 1.32562 acc: 0.71973 | v_loss: 1.50664 v_acc: 0.70280 |  iteration: 8816 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 115 loss: 1.51368 acc: 0.69401 | v_loss: 1.25318 v_acc: 0.71647 |  iteration: 8817 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 116 loss: 1.43034 acc: 0.70638 | v_loss: 1.33349 v_acc: 0.71191 |  iteration: 8818 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 117 loss: 1.43001 acc: 0.69987 | v_loss: 1.37655 v_acc: 0.69076 |  iteration: 8819 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 118 loss: 1.45077 acc: 0.70605 | v_loss: 1.32982 v_acc: 0.70898 |  iteration: 8820 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 119 loss: 1.54193 acc: 0.70475 | v_loss: 1.38124 v_acc: 0.69206 |  iteration: 8821 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 120 loss: 1.52404 acc: 0.70052 | v_loss: 1.47482 v_acc: 0.70931 |  iteration: 8822 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 121 loss: 1.50221 acc: 0.69792 | v_loss: 1.31796 v_acc: 0.72363 |  iteration: 8823 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 122 loss: 1.50334 acc: 0.70085 | v_loss: 1.45526 v_acc: 0.70443 |  iteration: 8824 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 123 loss: 1.42243 acc: 0.70117 | v_loss: 1.37479 v_acc: 0.69922 |  iteration: 8825 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 124 loss: 1.46563 acc: 0.70150 | v_loss: 1.34804 v_acc: 0.70898 |  iteration: 8826 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 125 loss: 1.51320 acc: 0.69531 | v_loss: 1.53614 v_acc: 0.68880 |  iteration: 8827 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 126 loss: 1.52567 acc: 0.69857 | v_loss: 1.32584 v_acc: 0.72103 |  iteration: 8828 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 127 loss: 1.42493 acc: 0.70540 | v_loss: 1.58211 v_acc: 0.68294 |  iteration: 8829 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 128 loss: 1.43564 acc: 0.70020 | v_loss: 1.44171 v_acc: 0.69889 |  iteration: 8830 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 129 loss: 1.54969 acc: 0.69987 | v_loss: 1.50754 v_acc: 0.68978 |  iteration: 8831 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 130 loss: 1.49476 acc: 0.70312 | v_loss: 1.38552 v_acc: 0.69792 |  iteration: 8832 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 131 loss: 1.52940 acc: 0.70540 | v_loss: 1.33427 v_acc: 0.70182 |  iteration: 8833 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 132 loss: 1.53574 acc: 0.69759 | v_loss: 1.36506 v_acc: 0.69694 |  iteration: 8834 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 133 loss: 1.48377 acc: 0.69727 | v_loss: 1.37070 v_acc: 0.71419 |  iteration: 8835 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 134 loss: 1.40047 acc: 0.70247 | v_loss: 1.57609 v_acc: 0.68945 |  iteration: 8836 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 135 loss: 1.48203 acc: 0.69531 | v_loss: 1.40731 v_acc: 0.70247 |  iteration: 8837 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 136 loss: 1.43080 acc: 0.70768 | v_loss: 1.37428 v_acc: 0.71126 |  iteration: 8838 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 137 loss: 1.39488 acc: 0.70605 | v_loss: 1.40387 v_acc: 0.71810 |  iteration: 8839 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 138 loss: 1.33877 acc: 0.71094 | v_loss: 1.30872 v_acc: 0.70215 |  iteration: 8840 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 139 loss: 1.48829 acc: 0.69889 | v_loss: 1.45642 v_acc: 0.69271 |  iteration: 8841 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 140 loss: 1.45282 acc: 0.70475 | v_loss: 1.46775 v_acc: 0.71452 |  iteration: 8842 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 141 loss: 1.40448 acc: 0.70573 | v_loss: 1.32259 v_acc: 0.71647 |  iteration: 8843 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 142 loss: 1.45551 acc: 0.70345 | v_loss: 1.28109 v_acc: 0.72754 |  iteration: 8844 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 143 loss: 1.42304 acc: 0.70312 | v_loss: 1.37911 v_acc: 0.71940 |  iteration: 8845 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 144 loss: 1.38753 acc: 0.71257 | v_loss: 1.42826 v_acc: 0.70410 |  iteration: 8846 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 145 loss: 1.53160 acc: 0.70052 | v_loss: 1.43972 v_acc: 0.70833 |  iteration: 8847 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 146 loss: 1.37814 acc: 0.70378 | v_loss: 1.23968 v_acc: 0.72591 |  iteration: 8848 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 147 loss: 1.47612 acc: 0.70605 | v_loss: 1.38390 v_acc: 0.72786 |  iteration: 8849 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 148 loss: 1.58276 acc: 0.68978 | v_loss: 1.47595 v_acc: 0.69694 |  iteration: 8850 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 149 loss: 1.45720 acc: 0.69857 | v_loss: 1.40834 v_acc: 0.72005 |  iteration: 8851 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 150 loss: 1.51460 acc: 0.69889 | v_loss: 1.29751 v_acc: 0.71322 |  iteration: 8852 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 151 loss: 1.42282 acc: 0.70410 | v_loss: 1.27798 v_acc: 0.73177 |  iteration: 8853 teacher: 1 stage: sketch lr: 0.000470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 152 loss: 1.44134 acc: 0.70801 | v_loss: 1.25268 v_acc: 0.72559 |  iteration: 8854 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 153 loss: 1.40669 acc: 0.70475 | v_loss: 1.34450 v_acc: 0.70540 |  iteration: 8855 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 154 loss: 1.43191 acc: 0.70020 | v_loss: 1.48139 v_acc: 0.69596 |  iteration: 8856 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 155 loss: 1.32100 acc: 0.71615 | v_loss: 1.29533 v_acc: 0.71582 |  iteration: 8857 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 156 loss: 1.46182 acc: 0.69857 | v_loss: 1.43422 v_acc: 0.72949 |  iteration: 8858 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 157 loss: 1.38894 acc: 0.70215 | v_loss: 1.65690 v_acc: 0.69466 |  iteration: 8859 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 158 loss: 1.43780 acc: 0.69889 | v_loss: 1.54435 v_acc: 0.70117 |  iteration: 8860 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 159 loss: 1.48757 acc: 0.69401 | v_loss: 1.31502 v_acc: 0.72396 |  iteration: 8861 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 160 loss: 1.45141 acc: 0.70085 | v_loss: 1.37630 v_acc: 0.70801 |  iteration: 8862 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 161 loss: 1.42529 acc: 0.70345 | v_loss: 1.22521 v_acc: 0.72331 |  iteration: 8863 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 162 loss: 1.43086 acc: 0.69792 | v_loss: 1.42553 v_acc: 0.70182 |  iteration: 8864 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 163 loss: 1.53942 acc: 0.69792 | v_loss: 1.36594 v_acc: 0.71875 |  iteration: 8865 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 164 loss: 1.39234 acc: 0.70898 | v_loss: 1.35780 v_acc: 0.72884 |  iteration: 8866 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 165 loss: 1.41817 acc: 0.70605 | v_loss: 1.36582 v_acc: 0.71777 |  iteration: 8867 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 166 loss: 1.46483 acc: 0.69922 | v_loss: 1.39411 v_acc: 0.70345 |  iteration: 8868 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 167 loss: 1.48732 acc: 0.69759 | v_loss: 1.29544 v_acc: 0.72201 |  iteration: 8869 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 168 loss: 1.46228 acc: 0.69531 | v_loss: 1.31392 v_acc: 0.72005 |  iteration: 8870 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 169 loss: 1.42083 acc: 0.70280 | v_loss: 1.49276 v_acc: 0.69043 |  iteration: 8871 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 170 loss: 1.37457 acc: 0.70443 | v_loss: 1.35419 v_acc: 0.70833 |  iteration: 8872 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 171 loss: 1.44224 acc: 0.70475 | v_loss: 1.30831 v_acc: 0.71582 |  iteration: 8873 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 172 loss: 1.50990 acc: 0.69173 | v_loss: 1.30098 v_acc: 0.72201 |  iteration: 8874 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 173 loss: 1.37327 acc: 0.70898 | v_loss: 1.43344 v_acc: 0.70768 |  iteration: 8875 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 174 loss: 1.49631 acc: 0.70378 | v_loss: 1.32035 v_acc: 0.73210 |  iteration: 8876 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 175 loss: 1.49509 acc: 0.70085 | v_loss: 1.54914 v_acc: 0.71452 |  iteration: 8877 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 176 loss: 1.39162 acc: 0.70931 | v_loss: 1.28598 v_acc: 0.69759 |  iteration: 8878 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 177 loss: 1.47273 acc: 0.69434 | v_loss: 1.28952 v_acc: 0.70443 |  iteration: 8879 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 178 loss: 1.42378 acc: 0.70247 | v_loss: 1.45341 v_acc: 0.70378 |  iteration: 8880 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 179 loss: 1.42485 acc: 0.69889 | v_loss: 1.48088 v_acc: 0.70150 |  iteration: 8881 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 180 loss: 1.49501 acc: 0.69531 | v_loss: 1.51135 v_acc: 0.69368 |  iteration: 8882 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 181 loss: 1.50944 acc: 0.69987 | v_loss: 1.48124 v_acc: 0.70833 |  iteration: 8883 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 182 loss: 1.48520 acc: 0.69564 | v_loss: 1.43151 v_acc: 0.70410 |  iteration: 8884 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 183 loss: 1.38074 acc: 0.70540 | v_loss: 1.40817 v_acc: 0.70475 |  iteration: 8885 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 184 loss: 1.33977 acc: 0.70866 | v_loss: 1.41831 v_acc: 0.70312 |  iteration: 8886 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 185 loss: 1.41699 acc: 0.69466 | v_loss: 1.28285 v_acc: 0.71257 |  iteration: 8887 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 186 loss: 1.40901 acc: 0.70508 | v_loss: 1.33536 v_acc: 0.72331 |  iteration: 8888 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 187 loss: 1.40014 acc: 0.70052 | v_loss: 1.22780 v_acc: 0.70605 |  iteration: 8889 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 188 loss: 1.38405 acc: 0.70964 | v_loss: 1.36170 v_acc: 0.70150 |  iteration: 8890 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 189 loss: 1.42697 acc: 0.70280 | v_loss: 1.51575 v_acc: 0.69564 |  iteration: 8891 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 190 loss: 1.41085 acc: 0.70671 | v_loss: 1.37199 v_acc: 0.70540 |  iteration: 8892 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 191 loss: 1.34366 acc: 0.71029 | v_loss: 1.36960 v_acc: 0.69368 |  iteration: 8893 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 192 loss: 1.46587 acc: 0.70573 | v_loss: 1.27176 v_acc: 0.70573 |  iteration: 8894 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 193 loss: 1.41427 acc: 0.70671 | v_loss: 1.25764 v_acc: 0.70215 |  iteration: 8895 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 194 loss: 1.39168 acc: 0.71387 | v_loss: 1.23833 v_acc: 0.73503 |  iteration: 8896 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 195 loss: 1.49316 acc: 0.69629 | v_loss: 1.27521 v_acc: 0.72461 |  iteration: 8897 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 196 loss: 1.42840 acc: 0.70182 | v_loss: 1.33874 v_acc: 0.72689 |  iteration: 8898 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 197 loss: 1.49836 acc: 0.69499 | v_loss: 1.26695 v_acc: 0.72852 |  iteration: 8899 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 198 loss: 1.40395 acc: 0.70605 | v_loss: 1.30406 v_acc: 0.72103 |  iteration: 8900 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 199 loss: 1.31427 acc: 0.71094 | v_loss: 1.41077 v_acc: 0.71126 |  iteration: 8901 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 200 loss: 1.55470 acc: 0.68978 | v_loss: 1.40330 v_acc: 0.71875 |  iteration: 8902 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 201 loss: 1.38697 acc: 0.70540 | v_loss: 1.49778 v_acc: 0.69694 |  iteration: 8903 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 202 loss: 1.33301 acc: 0.71549 | v_loss: 1.42947 v_acc: 0.71615 |  iteration: 8904 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 203 loss: 1.47163 acc: 0.69336 | v_loss: 1.18889 v_acc: 0.74382 |  iteration: 8905 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 204 loss: 1.37342 acc: 0.70801 | v_loss: 1.26580 v_acc: 0.70280 |  iteration: 8906 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 205 loss: 1.40352 acc: 0.70540 | v_loss: 1.52146 v_acc: 0.70280 |  iteration: 8907 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 206 loss: 1.51114 acc: 0.68913 | v_loss: 1.22413 v_acc: 0.71647 |  iteration: 8908 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 207 loss: 1.47977 acc: 0.70052 | v_loss: 1.33360 v_acc: 0.71191 |  iteration: 8909 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 208 loss: 1.46998 acc: 0.69661 | v_loss: 1.37794 v_acc: 0.69076 |  iteration: 8910 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 209 loss: 1.48807 acc: 0.70508 | v_loss: 1.30684 v_acc: 0.71029 |  iteration: 8911 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 210 loss: 1.35819 acc: 0.70671 | v_loss: 1.38055 v_acc: 0.69629 |  iteration: 8912 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 211 loss: 1.56342 acc: 0.69466 | v_loss: 1.47731 v_acc: 0.72005 |  iteration: 8913 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 212 loss: 1.44996 acc: 0.70573 | v_loss: 1.33285 v_acc: 0.72786 |  iteration: 8914 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 213 loss: 1.53374 acc: 0.70215 | v_loss: 1.44686 v_acc: 0.70443 |  iteration: 8915 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 214 loss: 1.47672 acc: 0.69954 | v_loss: 1.37309 v_acc: 0.69922 |  iteration: 8916 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 215 loss: 1.44799 acc: 0.69987 | v_loss: 1.34430 v_acc: 0.70964 |  iteration: 8917 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 216 loss: 1.48840 acc: 0.69043 | v_loss: 1.54723 v_acc: 0.68913 |  iteration: 8918 teacher: 0 stage: sketch lr: 0.000468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 217 loss: 1.35550 acc: 0.70898 | v_loss: 1.32068 v_acc: 0.72135 |  iteration: 8919 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 218 loss: 1.40225 acc: 0.70964 | v_loss: 1.57687 v_acc: 0.68620 |  iteration: 8920 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 219 loss: 1.34056 acc: 0.70638 | v_loss: 1.43232 v_acc: 0.69987 |  iteration: 8921 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 220 loss: 1.36705 acc: 0.71029 | v_loss: 1.52547 v_acc: 0.68913 |  iteration: 8922 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 221 loss: 1.43598 acc: 0.70540 | v_loss: 1.38102 v_acc: 0.69759 |  iteration: 8923 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 222 loss: 1.48635 acc: 0.69596 | v_loss: 1.33996 v_acc: 0.70312 |  iteration: 8924 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 223 loss: 1.45554 acc: 0.70605 | v_loss: 1.35080 v_acc: 0.70020 |  iteration: 8925 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 224 loss: 1.34716 acc: 0.70964 | v_loss: 1.35158 v_acc: 0.71484 |  iteration: 8926 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 225 loss: 1.34176 acc: 0.70736 | v_loss: 1.53651 v_acc: 0.69238 |  iteration: 8927 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 226 loss: 1.46489 acc: 0.70247 | v_loss: 1.39076 v_acc: 0.70247 |  iteration: 8928 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 227 loss: 1.52593 acc: 0.69108 | v_loss: 1.35813 v_acc: 0.71126 |  iteration: 8929 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 228 loss: 1.44251 acc: 0.70605 | v_loss: 1.38872 v_acc: 0.71484 |  iteration: 8930 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 229 loss: 1.50762 acc: 0.69141 | v_loss: 1.29434 v_acc: 0.70215 |  iteration: 8931 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 230 loss: 1.49327 acc: 0.69857 | v_loss: 1.43469 v_acc: 0.69434 |  iteration: 8932 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 231 loss: 1.36974 acc: 0.70964 | v_loss: 1.42718 v_acc: 0.71777 |  iteration: 8933 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 232 loss: 1.42349 acc: 0.69759 | v_loss: 1.30379 v_acc: 0.71712 |  iteration: 8934 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 233 loss: 1.43167 acc: 0.70410 | v_loss: 1.28112 v_acc: 0.72526 |  iteration: 8935 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 234 loss: 1.46489 acc: 0.70410 | v_loss: 1.38939 v_acc: 0.71647 |  iteration: 8936 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 235 loss: 1.43979 acc: 0.70475 | v_loss: 1.43104 v_acc: 0.70052 |  iteration: 8937 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 236 loss: 1.38487 acc: 0.69466 | v_loss: 1.43334 v_acc: 0.70410 |  iteration: 8938 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 237 loss: 1.34539 acc: 0.71322 | v_loss: 1.22320 v_acc: 0.72591 |  iteration: 8939 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 238 loss: 1.49056 acc: 0.68750 | v_loss: 1.41579 v_acc: 0.73112 |  iteration: 8940 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 239 loss: 1.35781 acc: 0.71745 | v_loss: 1.49346 v_acc: 0.69759 |  iteration: 8941 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 240 loss: 1.34280 acc: 0.69727 | v_loss: 1.42466 v_acc: 0.72201 |  iteration: 8942 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 241 loss: 1.43504 acc: 0.70605 | v_loss: 1.25905 v_acc: 0.71842 |  iteration: 8943 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 242 loss: 1.47236 acc: 0.70736 | v_loss: 1.20916 v_acc: 0.73730 |  iteration: 8944 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 243 loss: 1.55399 acc: 0.69238 | v_loss: 1.23052 v_acc: 0.72656 |  iteration: 8945 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 244 loss: 1.53327 acc: 0.69368 | v_loss: 1.30637 v_acc: 0.70801 |  iteration: 8946 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 245 loss: 1.46972 acc: 0.69499 | v_loss: 1.46051 v_acc: 0.69466 |  iteration: 8947 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 246 loss: 1.36926 acc: 0.71061 | v_loss: 1.29362 v_acc: 0.71484 |  iteration: 8948 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 247 loss: 1.42764 acc: 0.70345 | v_loss: 1.44769 v_acc: 0.72949 |  iteration: 8949 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 248 loss: 1.40271 acc: 0.70703 | v_loss: 1.63345 v_acc: 0.69466 |  iteration: 8950 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 249 loss: 1.49591 acc: 0.69661 | v_loss: 1.50978 v_acc: 0.70410 |  iteration: 8951 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 250 loss: 1.33231 acc: 0.71257 | v_loss: 1.29942 v_acc: 0.72005 |  iteration: 8952 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 251 loss: 1.49951 acc: 0.69141 | v_loss: 1.38313 v_acc: 0.70410 |  iteration: 8953 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 252 loss: 1.45050 acc: 0.69531 | v_loss: 1.23588 v_acc: 0.71973 |  iteration: 8954 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 253 loss: 1.39667 acc: 0.71126 | v_loss: 1.41984 v_acc: 0.70052 |  iteration: 8955 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 254 loss: 1.35945 acc: 0.71940 | v_loss: 1.37425 v_acc: 0.71029 |  iteration: 8956 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 255 loss: 1.43690 acc: 0.69629 | v_loss: 1.35798 v_acc: 0.72949 |  iteration: 8957 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 256 loss: 1.47507 acc: 0.69661 | v_loss: 1.35401 v_acc: 0.71973 |  iteration: 8958 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 257 loss: 1.55726 acc: 0.69987 | v_loss: 1.37616 v_acc: 0.70085 |  iteration: 8959 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 258 loss: 1.33734 acc: 0.71289 | v_loss: 1.30826 v_acc: 0.72266 |  iteration: 8960 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 259 loss: 1.36765 acc: 0.71810 | v_loss: 1.30527 v_acc: 0.72005 |  iteration: 8961 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 260 loss: 1.38026 acc: 0.71061 | v_loss: 1.52676 v_acc: 0.69173 |  iteration: 8962 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 261 loss: 1.43045 acc: 0.70280 | v_loss: 1.33754 v_acc: 0.70833 |  iteration: 8963 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 262 loss: 1.40701 acc: 0.70378 | v_loss: 1.29660 v_acc: 0.71549 |  iteration: 8964 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 263 loss: 1.47886 acc: 0.70085 | v_loss: 1.29230 v_acc: 0.71973 |  iteration: 8965 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 264 loss: 1.52433 acc: 0.70378 | v_loss: 1.43906 v_acc: 0.70573 |  iteration: 8966 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 265 loss: 1.36637 acc: 0.70638 | v_loss: 1.32358 v_acc: 0.73112 |  iteration: 8967 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 266 loss: 1.51977 acc: 0.69173 | v_loss: 1.56858 v_acc: 0.71582 |  iteration: 8968 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 267 loss: 1.53922 acc: 0.69238 | v_loss: 1.28872 v_acc: 0.70150 |  iteration: 8969 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 268 loss: 1.32155 acc: 0.71973 | v_loss: 1.28860 v_acc: 0.70573 |  iteration: 8970 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 269 loss: 1.36682 acc: 0.70703 | v_loss: 1.43611 v_acc: 0.70378 |  iteration: 8971 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 270 loss: 1.49312 acc: 0.69173 | v_loss: 1.46835 v_acc: 0.70378 |  iteration: 8972 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 271 loss: 1.52123 acc: 0.69434 | v_loss: 1.51309 v_acc: 0.68978 |  iteration: 8973 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 272 loss: 1.55244 acc: 0.69141 | v_loss: 1.47307 v_acc: 0.70638 |  iteration: 8974 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 273 loss: 1.51367 acc: 0.69076 | v_loss: 1.43390 v_acc: 0.70736 |  iteration: 8975 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 274 loss: 1.42581 acc: 0.69466 | v_loss: 1.42019 v_acc: 0.70703 |  iteration: 8976 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 275 loss: 1.38440 acc: 0.71224 | v_loss: 1.41518 v_acc: 0.70443 |  iteration: 8977 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 276 loss: 1.39927 acc: 0.70182 | v_loss: 1.27549 v_acc: 0.71159 |  iteration: 8978 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 277 loss: 1.49375 acc: 0.68848 | v_loss: 1.33115 v_acc: 0.72461 |  iteration: 8979 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 278 loss: 1.48621 acc: 0.69434 | v_loss: 1.19303 v_acc: 0.71517 |  iteration: 8980 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 279 loss: 1.40659 acc: 0.70703 | v_loss: 1.35369 v_acc: 0.70703 |  iteration: 8981 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 280 loss: 1.50899 acc: 0.69368 | v_loss: 1.50887 v_acc: 0.69987 |  iteration: 8982 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 281 loss: 1.42099 acc: 0.70768 | v_loss: 1.34207 v_acc: 0.70540 |  iteration: 8983 teacher: 0 stage: sketch lr: 0.000466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 282 loss: 1.56266 acc: 0.69629 | v_loss: 1.37240 v_acc: 0.69368 |  iteration: 8984 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 283 loss: 1.31646 acc: 0.70475 | v_loss: 1.26843 v_acc: 0.70573 |  iteration: 8985 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 284 loss: 1.37303 acc: 0.70866 | v_loss: 1.27079 v_acc: 0.70215 |  iteration: 8986 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 285 loss: 1.46122 acc: 0.69531 | v_loss: 1.24915 v_acc: 0.73340 |  iteration: 8987 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 286 loss: 1.42680 acc: 0.70247 | v_loss: 1.28492 v_acc: 0.71647 |  iteration: 8988 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 287 loss: 1.44369 acc: 0.70215 | v_loss: 1.36957 v_acc: 0.74089 |  iteration: 8989 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 288 loss: 1.54188 acc: 0.69206 | v_loss: 1.28631 v_acc: 0.71484 |  iteration: 8990 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 289 loss: 1.42102 acc: 0.70085 | v_loss: 1.30330 v_acc: 0.72168 |  iteration: 8991 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 290 loss: 1.48640 acc: 0.70182 | v_loss: 1.41129 v_acc: 0.71191 |  iteration: 8992 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 291 loss: 1.42495 acc: 0.70345 | v_loss: 1.38840 v_acc: 0.72298 |  iteration: 8993 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 292 loss: 1.50418 acc: 0.70345 | v_loss: 1.50151 v_acc: 0.69922 |  iteration: 8994 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 293 loss: 1.50288 acc: 0.70898 | v_loss: 1.41327 v_acc: 0.71908 |  iteration: 8995 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 294 loss: 1.48420 acc: 0.69076 | v_loss: 1.18196 v_acc: 0.74284 |  iteration: 8996 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 295 loss: 1.44686 acc: 0.69759 | v_loss: 1.26624 v_acc: 0.70280 |  iteration: 8997 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 296 loss: 1.41151 acc: 0.71647 | v_loss: 1.51870 v_acc: 0.70280 |  iteration: 8998 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 297 loss: 1.59966 acc: 0.68880 | v_loss: 1.23059 v_acc: 0.71647 |  iteration: 8999 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 298 loss: 1.48044 acc: 0.70410 | v_loss: 1.33768 v_acc: 0.71191 |  iteration: 9000 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 299 loss: 1.46678 acc: 0.70150 | v_loss: 1.39036 v_acc: 0.69076 |  iteration: 9001 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 300 loss: 1.52070 acc: 0.69466 | v_loss: 1.32003 v_acc: 0.70898 |  iteration: 9002 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 301 loss: 1.39483 acc: 0.70833 | v_loss: 1.37933 v_acc: 0.69206 |  iteration: 9003 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 302 loss: 1.35441 acc: 0.70215 | v_loss: 1.47848 v_acc: 0.70931 |  iteration: 9004 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 303 loss: 1.35947 acc: 0.71191 | v_loss: 1.32188 v_acc: 0.72363 |  iteration: 9005 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 304 loss: 1.43074 acc: 0.70215 | v_loss: 1.45494 v_acc: 0.70117 |  iteration: 9006 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 305 loss: 1.38515 acc: 0.70052 | v_loss: 1.37956 v_acc: 0.69824 |  iteration: 9007 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 306 loss: 1.54136 acc: 0.69857 | v_loss: 1.32208 v_acc: 0.70833 |  iteration: 9008 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 307 loss: 1.49440 acc: 0.70085 | v_loss: 1.58968 v_acc: 0.68522 |  iteration: 9009 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 308 loss: 1.52590 acc: 0.70866 | v_loss: 1.32727 v_acc: 0.71842 |  iteration: 9010 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 309 loss: 1.52570 acc: 0.70312 | v_loss: 1.59818 v_acc: 0.67969 |  iteration: 9011 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 310 loss: 1.32336 acc: 0.72005 | v_loss: 1.47950 v_acc: 0.69661 |  iteration: 9012 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 311 loss: 1.39721 acc: 0.70345 | v_loss: 1.52749 v_acc: 0.69238 |  iteration: 9013 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 312 loss: 1.48630 acc: 0.70671 | v_loss: 1.38570 v_acc: 0.70020 |  iteration: 9014 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 313 loss: 1.45376 acc: 0.70768 | v_loss: 1.33323 v_acc: 0.70215 |  iteration: 9015 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 314 loss: 1.38792 acc: 0.71289 | v_loss: 1.35782 v_acc: 0.69889 |  iteration: 9016 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 315 loss: 1.45491 acc: 0.70150 | v_loss: 1.34775 v_acc: 0.71419 |  iteration: 9017 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 316 loss: 1.48262 acc: 0.69596 | v_loss: 1.54239 v_acc: 0.69173 |  iteration: 9018 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 317 loss: 1.46031 acc: 0.70345 | v_loss: 1.40482 v_acc: 0.70247 |  iteration: 9019 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 318 loss: 1.49215 acc: 0.70085 | v_loss: 1.36729 v_acc: 0.71126 |  iteration: 9020 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 319 loss: 1.43439 acc: 0.69727 | v_loss: 1.39642 v_acc: 0.71810 |  iteration: 9021 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 320 loss: 1.42582 acc: 0.71419 | v_loss: 1.30337 v_acc: 0.70215 |  iteration: 9022 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 321 loss: 1.46497 acc: 0.69434 | v_loss: 1.42907 v_acc: 0.69434 |  iteration: 9023 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 322 loss: 1.41486 acc: 0.70117 | v_loss: 1.42707 v_acc: 0.71452 |  iteration: 9024 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 323 loss: 1.44847 acc: 0.70736 | v_loss: 1.28836 v_acc: 0.71875 |  iteration: 9025 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 324 loss: 1.58368 acc: 0.68880 | v_loss: 1.27592 v_acc: 0.72754 |  iteration: 9026 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 325 loss: 1.39896 acc: 0.70931 | v_loss: 1.38526 v_acc: 0.71940 |  iteration: 9027 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 326 loss: 1.48181 acc: 0.69010 | v_loss: 1.43990 v_acc: 0.70345 |  iteration: 9028 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 327 loss: 1.30866 acc: 0.71875 | v_loss: 1.44482 v_acc: 0.70410 |  iteration: 9029 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 328 loss: 1.43101 acc: 0.71224 | v_loss: 1.23219 v_acc: 0.71712 |  iteration: 9030 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 329 loss: 1.41736 acc: 0.70540 | v_loss: 1.40470 v_acc: 0.72786 |  iteration: 9031 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 330 loss: 1.46173 acc: 0.70215 | v_loss: 1.47631 v_acc: 0.69792 |  iteration: 9032 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 331 loss: 1.62212 acc: 0.69108 | v_loss: 1.40239 v_acc: 0.72233 |  iteration: 9033 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 332 loss: 1.38565 acc: 0.70671 | v_loss: 1.27575 v_acc: 0.71484 |  iteration: 9034 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 333 loss: 1.42926 acc: 0.69857 | v_loss: 1.23430 v_acc: 0.72852 |  iteration: 9035 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 334 loss: 1.46382 acc: 0.69987 | v_loss: 1.23648 v_acc: 0.72331 |  iteration: 9036 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 335 loss: 1.43472 acc: 0.70280 | v_loss: 1.32542 v_acc: 0.70410 |  iteration: 9037 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 336 loss: 1.55178 acc: 0.69336 | v_loss: 1.46008 v_acc: 0.69466 |  iteration: 9038 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 337 loss: 1.39566 acc: 0.70898 | v_loss: 1.29214 v_acc: 0.71419 |  iteration: 9039 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 338 loss: 1.55547 acc: 0.68652 | v_loss: 1.44773 v_acc: 0.71647 |  iteration: 9040 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 339 loss: 1.52539 acc: 0.70085 | v_loss: 1.65811 v_acc: 0.69466 |  iteration: 9041 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 340 loss: 1.46633 acc: 0.69727 | v_loss: 1.51429 v_acc: 0.70410 |  iteration: 9042 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 341 loss: 1.50520 acc: 0.69271 | v_loss: 1.30187 v_acc: 0.72005 |  iteration: 9043 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 342 loss: 1.59488 acc: 0.68652 | v_loss: 1.39279 v_acc: 0.69987 |  iteration: 9044 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 343 loss: 1.46218 acc: 0.70996 | v_loss: 1.25269 v_acc: 0.71615 |  iteration: 9045 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 344 loss: 1.39625 acc: 0.70540 | v_loss: 1.44102 v_acc: 0.69857 |  iteration: 9046 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 345 loss: 1.46344 acc: 0.69564 | v_loss: 1.36257 v_acc: 0.70996 |  iteration: 9047 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 346 loss: 1.39330 acc: 0.70703 | v_loss: 1.36562 v_acc: 0.72949 |  iteration: 9048 teacher: 0 stage: sketch lr: 0.000465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 347 loss: 1.47011 acc: 0.68750 | v_loss: 1.35139 v_acc: 0.71842 |  iteration: 9049 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 348 loss: 1.41743 acc: 0.69954 | v_loss: 1.37678 v_acc: 0.70312 |  iteration: 9050 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 349 loss: 1.48571 acc: 0.70768 | v_loss: 1.31365 v_acc: 0.72201 |  iteration: 9051 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 350 loss: 1.42802 acc: 0.70605 | v_loss: 1.31779 v_acc: 0.72005 |  iteration: 9052 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 351 loss: 1.44712 acc: 0.70508 | v_loss: 1.55290 v_acc: 0.69043 |  iteration: 9053 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 352 loss: 1.45878 acc: 0.69792 | v_loss: 1.34409 v_acc: 0.70833 |  iteration: 9054 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 353 loss: 1.47610 acc: 0.70605 | v_loss: 1.29974 v_acc: 0.71582 |  iteration: 9055 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 354 loss: 1.44619 acc: 0.70052 | v_loss: 1.29626 v_acc: 0.71712 |  iteration: 9056 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 355 loss: 1.46925 acc: 0.69303 | v_loss: 1.44938 v_acc: 0.70540 |  iteration: 9057 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 356 loss: 1.47941 acc: 0.69759 | v_loss: 1.32382 v_acc: 0.73210 |  iteration: 9058 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 357 loss: 1.38616 acc: 0.69727 | v_loss: 1.57643 v_acc: 0.71647 |  iteration: 9059 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 358 loss: 1.47638 acc: 0.69206 | v_loss: 1.30155 v_acc: 0.69889 |  iteration: 9060 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 359 loss: 1.60706 acc: 0.67871 | v_loss: 1.29530 v_acc: 0.70378 |  iteration: 9061 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 360 loss: 1.48480 acc: 0.69206 | v_loss: 1.43368 v_acc: 0.70378 |  iteration: 9062 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 361 loss: 1.36710 acc: 0.70150 | v_loss: 1.47050 v_acc: 0.70280 |  iteration: 9063 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 362 loss: 1.45570 acc: 0.69922 | v_loss: 1.51452 v_acc: 0.68880 |  iteration: 9064 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 363 loss: 1.42407 acc: 0.69727 | v_loss: 1.47466 v_acc: 0.70312 |  iteration: 9065 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 364 loss: 1.46321 acc: 0.69434 | v_loss: 1.42912 v_acc: 0.70866 |  iteration: 9066 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 365 loss: 1.47471 acc: 0.70736 | v_loss: 1.41169 v_acc: 0.70703 |  iteration: 9067 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 366 loss: 1.54305 acc: 0.69076 | v_loss: 1.40847 v_acc: 0.70312 |  iteration: 9068 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 367 loss: 1.45951 acc: 0.70280 | v_loss: 1.28664 v_acc: 0.71257 |  iteration: 9069 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 368 loss: 1.49092 acc: 0.70052 | v_loss: 1.32668 v_acc: 0.72493 |  iteration: 9070 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 369 loss: 1.43853 acc: 0.70312 | v_loss: 1.20778 v_acc: 0.70671 |  iteration: 9071 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 370 loss: 1.46083 acc: 0.70085 | v_loss: 1.36177 v_acc: 0.70150 |  iteration: 9072 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 371 loss: 1.38361 acc: 0.70247 | v_loss: 1.50549 v_acc: 0.69987 |  iteration: 9073 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 372 loss: 1.45065 acc: 0.69922 | v_loss: 1.34222 v_acc: 0.70833 |  iteration: 9074 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 373 loss: 1.44591 acc: 0.69987 | v_loss: 1.36367 v_acc: 0.69727 |  iteration: 9075 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 374 loss: 1.55479 acc: 0.69336 | v_loss: 1.26797 v_acc: 0.71126 |  iteration: 9076 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 375 loss: 1.50092 acc: 0.69173 | v_loss: 1.24387 v_acc: 0.70345 |  iteration: 9077 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 376 loss: 1.43850 acc: 0.70540 | v_loss: 1.25534 v_acc: 0.73438 |  iteration: 9078 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 377 loss: 1.40876 acc: 0.70866 | v_loss: 1.28634 v_acc: 0.71908 |  iteration: 9079 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 378 loss: 1.37210 acc: 0.70020 | v_loss: 1.34249 v_acc: 0.73112 |  iteration: 9080 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 379 loss: 1.38111 acc: 0.70638 | v_loss: 1.27079 v_acc: 0.71940 |  iteration: 9081 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 380 loss: 1.45957 acc: 0.71159 | v_loss: 1.30574 v_acc: 0.71810 |  iteration: 9082 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 381 loss: 1.50863 acc: 0.69596 | v_loss: 1.40611 v_acc: 0.71159 |  iteration: 9083 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 382 loss: 1.44732 acc: 0.70378 | v_loss: 1.37961 v_acc: 0.71810 |  iteration: 9084 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 383 loss: 1.36978 acc: 0.70540 | v_loss: 1.50401 v_acc: 0.69661 |  iteration: 9085 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 384 loss: 1.33931 acc: 0.71289 | v_loss: 1.41235 v_acc: 0.71745 |  iteration: 9086 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 385 loss: 1.42058 acc: 0.70866 | v_loss: 1.18010 v_acc: 0.74382 |  iteration: 9087 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 386 loss: 1.37040 acc: 0.69727 | v_loss: 1.27422 v_acc: 0.70280 |  iteration: 9088 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 387 loss: 1.55530 acc: 0.69401 | v_loss: 1.52104 v_acc: 0.70280 |  iteration: 9089 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 388 loss: 1.39584 acc: 0.70768 | v_loss: 1.24825 v_acc: 0.71647 |  iteration: 9090 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 389 loss: 1.40788 acc: 0.70085 | v_loss: 1.33856 v_acc: 0.71289 |  iteration: 9091 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 390 loss: 1.72142 acc: 0.68132 | v_loss: 1.38046 v_acc: 0.69076 |  iteration: 9092 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 391 loss: 1.54326 acc: 0.69629 | v_loss: 1.31409 v_acc: 0.70898 |  iteration: 9093 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 392 loss: 1.45536 acc: 0.69857 | v_loss: 1.37051 v_acc: 0.69206 |  iteration: 9094 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 393 loss: 1.50011 acc: 0.69531 | v_loss: 1.47451 v_acc: 0.70931 |  iteration: 9095 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 394 loss: 1.41430 acc: 0.70671 | v_loss: 1.31976 v_acc: 0.72363 |  iteration: 9096 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 395 loss: 1.38318 acc: 0.70345 | v_loss: 1.44377 v_acc: 0.70312 |  iteration: 9097 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 396 loss: 1.46608 acc: 0.69596 | v_loss: 1.37316 v_acc: 0.69889 |  iteration: 9098 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 397 loss: 1.45122 acc: 0.70703 | v_loss: 1.32778 v_acc: 0.70833 |  iteration: 9099 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 398 loss: 1.50303 acc: 0.70182 | v_loss: 1.57740 v_acc: 0.68522 |  iteration: 9100 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 399 loss: 1.40400 acc: 0.69987 | v_loss: 1.31948 v_acc: 0.71842 |  iteration: 9101 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 400 loss: 1.40127 acc: 0.70182 | v_loss: 1.59928 v_acc: 0.67969 |  iteration: 9102 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 401 loss: 1.39784 acc: 0.71159 | v_loss: 1.46933 v_acc: 0.69661 |  iteration: 9103 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 402 loss: 1.42562 acc: 0.70085 | v_loss: 1.54448 v_acc: 0.69238 |  iteration: 9104 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 403 loss: 1.44925 acc: 0.70508 | v_loss: 1.37247 v_acc: 0.70182 |  iteration: 9105 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 404 loss: 1.40265 acc: 0.70508 | v_loss: 1.34977 v_acc: 0.70312 |  iteration: 9106 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 405 loss: 1.35822 acc: 0.71549 | v_loss: 1.34658 v_acc: 0.69889 |  iteration: 9107 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 406 loss: 1.40473 acc: 0.69629 | v_loss: 1.33451 v_acc: 0.71419 |  iteration: 9108 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 407 loss: 1.33311 acc: 0.71810 | v_loss: 1.53561 v_acc: 0.69173 |  iteration: 9109 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 408 loss: 1.38304 acc: 0.70475 | v_loss: 1.38257 v_acc: 0.70247 |  iteration: 9110 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 409 loss: 1.43384 acc: 0.69987 | v_loss: 1.37562 v_acc: 0.71126 |  iteration: 9111 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 410 loss: 1.45884 acc: 0.69889 | v_loss: 1.39244 v_acc: 0.71810 |  iteration: 9112 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 411 loss: 1.43018 acc: 0.69336 | v_loss: 1.28160 v_acc: 0.70215 |  iteration: 9113 teacher: 1 stage: sketch lr: 0.000463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 412 loss: 1.36137 acc: 0.70247 | v_loss: 1.43852 v_acc: 0.69434 |  iteration: 9114 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 413 loss: 1.41250 acc: 0.69857 | v_loss: 1.44549 v_acc: 0.71452 |  iteration: 9115 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 414 loss: 1.40082 acc: 0.70117 | v_loss: 1.30252 v_acc: 0.71647 |  iteration: 9116 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 415 loss: 1.38863 acc: 0.70215 | v_loss: 1.26849 v_acc: 0.72526 |  iteration: 9117 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 416 loss: 1.39516 acc: 0.70996 | v_loss: 1.38160 v_acc: 0.71647 |  iteration: 9118 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 417 loss: 1.45281 acc: 0.69954 | v_loss: 1.42137 v_acc: 0.70052 |  iteration: 9119 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 418 loss: 1.42681 acc: 0.69336 | v_loss: 1.42789 v_acc: 0.70833 |  iteration: 9120 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 419 loss: 1.51509 acc: 0.69661 | v_loss: 1.22934 v_acc: 0.72591 |  iteration: 9121 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 420 loss: 1.41351 acc: 0.70508 | v_loss: 1.38434 v_acc: 0.73112 |  iteration: 9122 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 421 loss: 1.39869 acc: 0.70736 | v_loss: 1.47686 v_acc: 0.69727 |  iteration: 9123 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 422 loss: 1.52870 acc: 0.69271 | v_loss: 1.43999 v_acc: 0.72168 |  iteration: 9124 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 423 loss: 1.31894 acc: 0.71094 | v_loss: 1.26314 v_acc: 0.71973 |  iteration: 9125 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 424 loss: 1.43258 acc: 0.71159 | v_loss: 1.21460 v_acc: 0.73893 |  iteration: 9126 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 425 loss: 1.42737 acc: 0.70215 | v_loss: 1.22630 v_acc: 0.72721 |  iteration: 9127 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 426 loss: 1.49853 acc: 0.68652 | v_loss: 1.30672 v_acc: 0.70638 |  iteration: 9128 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 427 loss: 1.44387 acc: 0.69694 | v_loss: 1.47314 v_acc: 0.69531 |  iteration: 9129 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 428 loss: 1.49335 acc: 0.68717 | v_loss: 1.29522 v_acc: 0.71289 |  iteration: 9130 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 429 loss: 1.45866 acc: 0.70312 | v_loss: 1.47400 v_acc: 0.71517 |  iteration: 9131 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 430 loss: 1.33134 acc: 0.71484 | v_loss: 1.67738 v_acc: 0.69238 |  iteration: 9132 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 431 loss: 1.47770 acc: 0.70020 | v_loss: 1.53397 v_acc: 0.69824 |  iteration: 9133 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 432 loss: 1.52763 acc: 0.68815 | v_loss: 1.30687 v_acc: 0.72070 |  iteration: 9134 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 433 loss: 1.43331 acc: 0.69824 | v_loss: 1.38119 v_acc: 0.70117 |  iteration: 9135 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 434 loss: 1.54174 acc: 0.68490 | v_loss: 1.23353 v_acc: 0.72103 |  iteration: 9136 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 435 loss: 1.33393 acc: 0.70736 | v_loss: 1.42959 v_acc: 0.70020 |  iteration: 9137 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 436 loss: 1.42462 acc: 0.71126 | v_loss: 1.36179 v_acc: 0.71029 |  iteration: 9138 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 437 loss: 1.42549 acc: 0.71029 | v_loss: 1.35775 v_acc: 0.73047 |  iteration: 9139 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 438 loss: 1.38436 acc: 0.70964 | v_loss: 1.36851 v_acc: 0.71842 |  iteration: 9140 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 439 loss: 1.39852 acc: 0.71777 | v_loss: 1.38149 v_acc: 0.70410 |  iteration: 9141 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 440 loss: 1.40521 acc: 0.69434 | v_loss: 1.28797 v_acc: 0.72233 |  iteration: 9142 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 441 loss: 1.42122 acc: 0.70801 | v_loss: 1.31102 v_acc: 0.72005 |  iteration: 9143 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 442 loss: 1.43720 acc: 0.70312 | v_loss: 1.48165 v_acc: 0.69043 |  iteration: 9144 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 443 loss: 1.33758 acc: 0.71647 | v_loss: 1.33995 v_acc: 0.70833 |  iteration: 9145 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 444 loss: 1.46902 acc: 0.69531 | v_loss: 1.30792 v_acc: 0.71582 |  iteration: 9146 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 445 loss: 1.52663 acc: 0.69303 | v_loss: 1.30391 v_acc: 0.72201 |  iteration: 9147 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 446 loss: 1.37650 acc: 0.71061 | v_loss: 1.44270 v_acc: 0.70768 |  iteration: 9148 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 447 loss: 1.36190 acc: 0.70508 | v_loss: 1.32494 v_acc: 0.72754 |  iteration: 9149 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 448 loss: 1.40665 acc: 0.70020 | v_loss: 1.54632 v_acc: 0.71322 |  iteration: 9150 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 449 loss: 1.39943 acc: 0.69987 | v_loss: 1.29000 v_acc: 0.69531 |  iteration: 9151 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 450 loss: 1.43432 acc: 0.71061 | v_loss: 1.28818 v_acc: 0.70117 |  iteration: 9152 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 451 loss: 1.44357 acc: 0.70540 | v_loss: 1.43469 v_acc: 0.70443 |  iteration: 9153 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 452 loss: 1.45335 acc: 0.70182 | v_loss: 1.46583 v_acc: 0.70378 |  iteration: 9154 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 453 loss: 1.41953 acc: 0.70085 | v_loss: 1.51753 v_acc: 0.69010 |  iteration: 9155 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 454 loss: 1.38493 acc: 0.69141 | v_loss: 1.48660 v_acc: 0.70801 |  iteration: 9156 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 455 loss: 1.43474 acc: 0.70508 | v_loss: 1.43281 v_acc: 0.70378 |  iteration: 9157 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 456 loss: 1.46971 acc: 0.70312 | v_loss: 1.42368 v_acc: 0.70768 |  iteration: 9158 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 457 loss: 1.47135 acc: 0.70182 | v_loss: 1.42325 v_acc: 0.70475 |  iteration: 9159 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 458 loss: 1.46527 acc: 0.69466 | v_loss: 1.27468 v_acc: 0.71257 |  iteration: 9160 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 459 loss: 1.30531 acc: 0.70931 | v_loss: 1.33977 v_acc: 0.72493 |  iteration: 9161 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 460 loss: 1.42447 acc: 0.70378 | v_loss: 1.19968 v_acc: 0.70671 |  iteration: 9162 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 461 loss: 1.38813 acc: 0.70573 | v_loss: 1.35423 v_acc: 0.70182 |  iteration: 9163 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 462 loss: 1.49150 acc: 0.69010 | v_loss: 1.49996 v_acc: 0.69987 |  iteration: 9164 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 463 loss: 1.53619 acc: 0.69727 | v_loss: 1.35004 v_acc: 0.70540 |  iteration: 9165 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 464 loss: 1.53190 acc: 0.70508 | v_loss: 1.36429 v_acc: 0.69368 |  iteration: 9166 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 465 loss: 1.45406 acc: 0.71094 | v_loss: 1.27528 v_acc: 0.70573 |  iteration: 9167 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 466 loss: 1.42317 acc: 0.70182 | v_loss: 1.27862 v_acc: 0.70215 |  iteration: 9168 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 467 loss: 1.53149 acc: 0.69368 | v_loss: 1.24252 v_acc: 0.73372 |  iteration: 9169 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 468 loss: 1.42618 acc: 0.70312 | v_loss: 1.29990 v_acc: 0.71452 |  iteration: 9170 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 469 loss: 1.44974 acc: 0.70312 | v_loss: 1.32508 v_acc: 0.74089 |  iteration: 9171 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 470 loss: 1.39531 acc: 0.70638 | v_loss: 1.27770 v_acc: 0.72005 |  iteration: 9172 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 471 loss: 1.40950 acc: 0.70833 | v_loss: 1.30366 v_acc: 0.71582 |  iteration: 9173 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 472 loss: 1.41238 acc: 0.70703 | v_loss: 1.41439 v_acc: 0.71224 |  iteration: 9174 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 473 loss: 1.44765 acc: 0.70801 | v_loss: 1.39959 v_acc: 0.72038 |  iteration: 9175 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 474 loss: 1.46061 acc: 0.71191 | v_loss: 1.50509 v_acc: 0.69661 |  iteration: 9176 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 475 loss: 1.42018 acc: 0.69629 | v_loss: 1.44147 v_acc: 0.71745 |  iteration: 9177 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 476 loss: 1.48244 acc: 0.70312 | v_loss: 1.18222 v_acc: 0.74382 |  iteration: 9178 teacher: 0 stage: sketch lr: 0.000461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 477 loss: 1.44343 acc: 0.71061 | v_loss: 1.26836 v_acc: 0.70280 |  iteration: 9179 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 478 loss: 1.44072 acc: 0.70703 | v_loss: 1.53161 v_acc: 0.70247 |  iteration: 9180 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 479 loss: 1.38323 acc: 0.70638 | v_loss: 1.25955 v_acc: 0.70833 |  iteration: 9181 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 480 loss: 1.31576 acc: 0.71745 | v_loss: 1.33692 v_acc: 0.71354 |  iteration: 9182 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 481 loss: 1.44531 acc: 0.70605 | v_loss: 1.37010 v_acc: 0.69368 |  iteration: 9183 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 482 loss: 1.40523 acc: 0.70736 | v_loss: 1.30885 v_acc: 0.71842 |  iteration: 9184 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 483 loss: 1.47052 acc: 0.70182 | v_loss: 1.37956 v_acc: 0.70215 |  iteration: 9185 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 484 loss: 1.45764 acc: 0.70280 | v_loss: 1.48114 v_acc: 0.72005 |  iteration: 9186 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 485 loss: 1.43310 acc: 0.70052 | v_loss: 1.33339 v_acc: 0.72786 |  iteration: 9187 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 486 loss: 1.48818 acc: 0.69564 | v_loss: 1.47841 v_acc: 0.70540 |  iteration: 9188 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 487 loss: 1.58258 acc: 0.69661 | v_loss: 1.36824 v_acc: 0.69922 |  iteration: 9189 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 488 loss: 1.53739 acc: 0.69499 | v_loss: 1.35869 v_acc: 0.70898 |  iteration: 9190 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 489 loss: 1.38592 acc: 0.70182 | v_loss: 1.54613 v_acc: 0.68880 |  iteration: 9191 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 490 loss: 1.58852 acc: 0.67904 | v_loss: 1.33725 v_acc: 0.72070 |  iteration: 9192 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 491 loss: 1.56610 acc: 0.69694 | v_loss: 1.57990 v_acc: 0.68685 |  iteration: 9193 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 492 loss: 1.38882 acc: 0.70605 | v_loss: 1.42655 v_acc: 0.69629 |  iteration: 9194 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 493 loss: 1.41614 acc: 0.70736 | v_loss: 1.51367 v_acc: 0.68750 |  iteration: 9195 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 494 loss: 1.39714 acc: 0.70020 | v_loss: 1.38027 v_acc: 0.69792 |  iteration: 9196 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 495 loss: 1.29775 acc: 0.72624 | v_loss: 1.34608 v_acc: 0.70117 |  iteration: 9197 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 496 loss: 1.35814 acc: 0.71452 | v_loss: 1.35125 v_acc: 0.69727 |  iteration: 9198 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 497 loss: 1.39509 acc: 0.71029 | v_loss: 1.33657 v_acc: 0.71419 |  iteration: 9199 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 498 loss: 1.42023 acc: 0.71615 | v_loss: 1.56170 v_acc: 0.68978 |  iteration: 9200 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 499 loss: 1.50755 acc: 0.69727 | v_loss: 1.40414 v_acc: 0.70443 |  iteration: 9201 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 500 loss: 1.44391 acc: 0.70508 | v_loss: 1.36078 v_acc: 0.71061 |  iteration: 9202 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 501 loss: 1.45799 acc: 0.70996 | v_loss: 1.39193 v_acc: 0.71452 |  iteration: 9203 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 502 loss: 1.40405 acc: 0.71387 | v_loss: 1.27669 v_acc: 0.70736 |  iteration: 9204 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 503 loss: 1.46410 acc: 0.70410 | v_loss: 1.45714 v_acc: 0.69499 |  iteration: 9205 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 504 loss: 1.41063 acc: 0.70378 | v_loss: 1.44049 v_acc: 0.71224 |  iteration: 9206 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 505 loss: 1.45217 acc: 0.70638 | v_loss: 1.30503 v_acc: 0.71549 |  iteration: 9207 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 506 loss: 1.48487 acc: 0.69987 | v_loss: 1.27267 v_acc: 0.72168 |  iteration: 9208 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 507 loss: 1.43907 acc: 0.69564 | v_loss: 1.38047 v_acc: 0.71582 |  iteration: 9209 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 508 loss: 1.47799 acc: 0.69238 | v_loss: 1.43420 v_acc: 0.69727 |  iteration: 9210 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 509 loss: 1.48714 acc: 0.69987 | v_loss: 1.44263 v_acc: 0.70378 |  iteration: 9211 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 510 loss: 1.52816 acc: 0.69629 | v_loss: 1.24718 v_acc: 0.71419 |  iteration: 9212 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 511 loss: 1.42507 acc: 0.71191 | v_loss: 1.39468 v_acc: 0.72819 |  iteration: 9213 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 512 loss: 1.36679 acc: 0.70768 | v_loss: 1.47982 v_acc: 0.69792 |  iteration: 9214 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 513 loss: 1.46951 acc: 0.69727 | v_loss: 1.45417 v_acc: 0.72201 |  iteration: 9215 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 514 loss: 1.43219 acc: 0.70312 | v_loss: 1.25622 v_acc: 0.72233 |  iteration: 9216 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 515 loss: 1.54514 acc: 0.68685 | v_loss: 1.19544 v_acc: 0.74447 |  iteration: 9217 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 516 loss: 1.43544 acc: 0.70671 | v_loss: 1.22192 v_acc: 0.72559 |  iteration: 9218 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 517 loss: 1.44500 acc: 0.71159 | v_loss: 1.29860 v_acc: 0.70703 |  iteration: 9219 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 518 loss: 1.48730 acc: 0.70378 | v_loss: 1.45107 v_acc: 0.69466 |  iteration: 9220 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 519 loss: 1.38972 acc: 0.70671 | v_loss: 1.29554 v_acc: 0.71484 |  iteration: 9221 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 520 loss: 1.50535 acc: 0.69271 | v_loss: 1.44345 v_acc: 0.72786 |  iteration: 9222 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 521 loss: 1.49599 acc: 0.69596 | v_loss: 1.63119 v_acc: 0.69271 |  iteration: 9223 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 522 loss: 1.43930 acc: 0.70378 | v_loss: 1.51340 v_acc: 0.70508 |  iteration: 9224 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 523 loss: 1.46730 acc: 0.69303 | v_loss: 1.30177 v_acc: 0.72005 |  iteration: 9225 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 524 loss: 1.35488 acc: 0.70605 | v_loss: 1.37982 v_acc: 0.69987 |  iteration: 9226 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 525 loss: 1.40200 acc: 0.70378 | v_loss: 1.23513 v_acc: 0.71615 |  iteration: 9227 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 526 loss: 1.41628 acc: 0.70931 | v_loss: 1.43315 v_acc: 0.70150 |  iteration: 9228 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 527 loss: 1.56234 acc: 0.68197 | v_loss: 1.37099 v_acc: 0.71029 |  iteration: 9229 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 528 loss: 1.47514 acc: 0.69954 | v_loss: 1.37034 v_acc: 0.72949 |  iteration: 9230 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 529 loss: 1.46416 acc: 0.70150 | v_loss: 1.36788 v_acc: 0.71680 |  iteration: 9231 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 530 loss: 1.31816 acc: 0.70833 | v_loss: 1.37877 v_acc: 0.70345 |  iteration: 9232 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 531 loss: 1.41523 acc: 0.70866 | v_loss: 1.30160 v_acc: 0.72201 |  iteration: 9233 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 532 loss: 1.48198 acc: 0.69759 | v_loss: 1.31793 v_acc: 0.72005 |  iteration: 9234 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 533 loss: 1.40686 acc: 0.70280 | v_loss: 1.50555 v_acc: 0.69043 |  iteration: 9235 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 534 loss: 1.47570 acc: 0.69531 | v_loss: 1.33984 v_acc: 0.70833 |  iteration: 9236 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 535 loss: 1.48059 acc: 0.69857 | v_loss: 1.30779 v_acc: 0.71549 |  iteration: 9237 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 536 loss: 1.42689 acc: 0.70410 | v_loss: 1.28739 v_acc: 0.72070 |  iteration: 9238 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 537 loss: 1.34538 acc: 0.70573 | v_loss: 1.44911 v_acc: 0.70540 |  iteration: 9239 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 538 loss: 1.37593 acc: 0.70280 | v_loss: 1.31599 v_acc: 0.73047 |  iteration: 9240 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 539 loss: 1.51668 acc: 0.69727 | v_loss: 1.53508 v_acc: 0.71322 |  iteration: 9241 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 540 loss: 1.49684 acc: 0.69303 | v_loss: 1.28315 v_acc: 0.69661 |  iteration: 9242 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 541 loss: 1.35690 acc: 0.70312 | v_loss: 1.28463 v_acc: 0.70117 |  iteration: 9243 teacher: 1 stage: sketch lr: 0.000460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 542 loss: 1.48779 acc: 0.69727 | v_loss: 1.45014 v_acc: 0.70508 |  iteration: 9244 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 543 loss: 1.43542 acc: 0.69954 | v_loss: 1.47759 v_acc: 0.70573 |  iteration: 9245 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 544 loss: 1.34847 acc: 0.70117 | v_loss: 1.51912 v_acc: 0.68978 |  iteration: 9246 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 545 loss: 1.43480 acc: 0.70378 | v_loss: 1.46540 v_acc: 0.70540 |  iteration: 9247 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 546 loss: 1.47680 acc: 0.70312 | v_loss: 1.43581 v_acc: 0.70410 |  iteration: 9248 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 547 loss: 1.39438 acc: 0.70443 | v_loss: 1.40857 v_acc: 0.70768 |  iteration: 9249 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 548 loss: 1.55852 acc: 0.69173 | v_loss: 1.41155 v_acc: 0.70312 |  iteration: 9250 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 549 loss: 1.37193 acc: 0.70508 | v_loss: 1.28561 v_acc: 0.71257 |  iteration: 9251 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 550 loss: 1.44777 acc: 0.70671 | v_loss: 1.32263 v_acc: 0.72493 |  iteration: 9252 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 551 loss: 1.51163 acc: 0.69987 | v_loss: 1.22699 v_acc: 0.70671 |  iteration: 9253 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 552 loss: 1.46325 acc: 0.70378 | v_loss: 1.35424 v_acc: 0.70150 |  iteration: 9254 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 553 loss: 1.50050 acc: 0.69889 | v_loss: 1.48945 v_acc: 0.69987 |  iteration: 9255 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 554 loss: 1.45767 acc: 0.70085 | v_loss: 1.34278 v_acc: 0.70833 |  iteration: 9256 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 555 loss: 1.38857 acc: 0.70898 | v_loss: 1.35978 v_acc: 0.69727 |  iteration: 9257 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 556 loss: 1.45496 acc: 0.69499 | v_loss: 1.24994 v_acc: 0.71680 |  iteration: 9258 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 557 loss: 1.48746 acc: 0.69401 | v_loss: 1.25503 v_acc: 0.70671 |  iteration: 9259 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 558 loss: 1.45313 acc: 0.69661 | v_loss: 1.25929 v_acc: 0.73568 |  iteration: 9260 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 559 loss: 1.43637 acc: 0.70410 | v_loss: 1.27638 v_acc: 0.72461 |  iteration: 9261 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 560 loss: 1.64948 acc: 0.68034 | v_loss: 1.34997 v_acc: 0.72689 |  iteration: 9262 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 561 loss: 1.44901 acc: 0.69368 | v_loss: 1.27054 v_acc: 0.71940 |  iteration: 9263 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 562 loss: 1.39656 acc: 0.70247 | v_loss: 1.30793 v_acc: 0.72168 |  iteration: 9264 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 563 loss: 1.47554 acc: 0.70898 | v_loss: 1.40034 v_acc: 0.71159 |  iteration: 9265 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 564 loss: 1.45773 acc: 0.70736 | v_loss: 1.37282 v_acc: 0.72038 |  iteration: 9266 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 565 loss: 1.42636 acc: 0.70247 | v_loss: 1.49979 v_acc: 0.69759 |  iteration: 9267 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 566 loss: 1.52801 acc: 0.68750 | v_loss: 1.40768 v_acc: 0.71940 |  iteration: 9268 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 567 loss: 1.44464 acc: 0.69889 | v_loss: 1.18859 v_acc: 0.74382 |  iteration: 9269 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 568 loss: 1.43118 acc: 0.70605 | v_loss: 1.29709 v_acc: 0.70280 |  iteration: 9270 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 569 loss: 1.42563 acc: 0.70085 | v_loss: 1.51166 v_acc: 0.70280 |  iteration: 9271 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 570 loss: 1.50974 acc: 0.69922 | v_loss: 1.24748 v_acc: 0.71647 |  iteration: 9272 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 571 loss: 1.37224 acc: 0.71354 | v_loss: 1.34023 v_acc: 0.71191 |  iteration: 9273 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 572 loss: 1.46353 acc: 0.70280 | v_loss: 1.38827 v_acc: 0.69336 |  iteration: 9274 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 573 loss: 1.48248 acc: 0.70345 | v_loss: 1.30627 v_acc: 0.71191 |  iteration: 9275 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 574 loss: 1.46960 acc: 0.69629 | v_loss: 1.37091 v_acc: 0.69629 |  iteration: 9276 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 575 loss: 1.35666 acc: 0.70052 | v_loss: 1.47663 v_acc: 0.72005 |  iteration: 9277 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 576 loss: 1.43378 acc: 0.70215 | v_loss: 1.32689 v_acc: 0.72786 |  iteration: 9278 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 577 loss: 1.48660 acc: 0.69889 | v_loss: 1.46420 v_acc: 0.70540 |  iteration: 9279 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 578 loss: 1.51465 acc: 0.70508 | v_loss: 1.35934 v_acc: 0.69922 |  iteration: 9280 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 579 loss: 1.42942 acc: 0.69824 | v_loss: 1.34513 v_acc: 0.70964 |  iteration: 9281 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 580 loss: 1.46971 acc: 0.70345 | v_loss: 1.54548 v_acc: 0.68913 |  iteration: 9282 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 581 loss: 1.38844 acc: 0.70671 | v_loss: 1.31280 v_acc: 0.72135 |  iteration: 9283 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 582 loss: 1.41136 acc: 0.70443 | v_loss: 1.58130 v_acc: 0.68620 |  iteration: 9284 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 583 loss: 1.39448 acc: 0.70085 | v_loss: 1.45279 v_acc: 0.69792 |  iteration: 9285 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 584 loss: 1.47030 acc: 0.69401 | v_loss: 1.51763 v_acc: 0.69173 |  iteration: 9286 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 585 loss: 1.32301 acc: 0.71582 | v_loss: 1.38002 v_acc: 0.70020 |  iteration: 9287 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 586 loss: 1.49561 acc: 0.69792 | v_loss: 1.33572 v_acc: 0.70312 |  iteration: 9288 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 587 loss: 1.41237 acc: 0.70801 | v_loss: 1.33955 v_acc: 0.70020 |  iteration: 9289 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 588 loss: 1.53645 acc: 0.69857 | v_loss: 1.33724 v_acc: 0.71484 |  iteration: 9290 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 589 loss: 1.29378 acc: 0.71484 | v_loss: 1.54631 v_acc: 0.68978 |  iteration: 9291 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 590 loss: 1.47805 acc: 0.69824 | v_loss: 1.38458 v_acc: 0.70247 |  iteration: 9292 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 591 loss: 1.51698 acc: 0.69434 | v_loss: 1.37793 v_acc: 0.70801 |  iteration: 9293 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 592 loss: 1.35583 acc: 0.70931 | v_loss: 1.38946 v_acc: 0.71582 |  iteration: 9294 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 593 loss: 1.48846 acc: 0.70443 | v_loss: 1.30302 v_acc: 0.70085 |  iteration: 9295 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 594 loss: 1.42254 acc: 0.70410 | v_loss: 1.44959 v_acc: 0.70117 |  iteration: 9296 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 595 loss: 1.35774 acc: 0.70475 | v_loss: 1.42241 v_acc: 0.71517 |  iteration: 9297 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 596 loss: 1.41297 acc: 0.70833 | v_loss: 1.30095 v_acc: 0.71647 |  iteration: 9298 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 597 loss: 1.44938 acc: 0.68978 | v_loss: 1.26080 v_acc: 0.72526 |  iteration: 9299 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 598 loss: 1.34432 acc: 0.71224 | v_loss: 1.39605 v_acc: 0.72266 |  iteration: 9300 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 599 loss: 1.41797 acc: 0.70703 | v_loss: 1.41463 v_acc: 0.70410 |  iteration: 9301 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 600 loss: 1.49283 acc: 0.69694 | v_loss: 1.43125 v_acc: 0.70833 |  iteration: 9302 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 601 loss: 1.48169 acc: 0.68913 | v_loss: 1.22279 v_acc: 0.72266 |  iteration: 9303 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 602 loss: 1.42420 acc: 0.70573 | v_loss: 1.40776 v_acc: 0.73242 |  iteration: 9304 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 603 loss: 1.52885 acc: 0.68848 | v_loss: 1.49662 v_acc: 0.69629 |  iteration: 9305 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 604 loss: 1.36896 acc: 0.70898 | v_loss: 1.45456 v_acc: 0.71875 |  iteration: 9306 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 605 loss: 1.49979 acc: 0.69141 | v_loss: 1.26311 v_acc: 0.71810 |  iteration: 9307 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 606 loss: 1.36500 acc: 0.70964 | v_loss: 1.21976 v_acc: 0.73535 |  iteration: 9308 teacher: 0 stage: sketch lr: 0.000458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 607 loss: 1.53587 acc: 0.68913 | v_loss: 1.22152 v_acc: 0.72656 |  iteration: 9309 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 608 loss: 1.45755 acc: 0.70605 | v_loss: 1.28664 v_acc: 0.70703 |  iteration: 9310 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 609 loss: 1.44307 acc: 0.70312 | v_loss: 1.45835 v_acc: 0.69596 |  iteration: 9311 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 610 loss: 1.43367 acc: 0.71224 | v_loss: 1.29228 v_acc: 0.71484 |  iteration: 9312 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 611 loss: 1.61002 acc: 0.68620 | v_loss: 1.44420 v_acc: 0.72949 |  iteration: 9313 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 612 loss: 1.31057 acc: 0.73503 | v_loss: 1.65083 v_acc: 0.69466 |  iteration: 9314 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 613 loss: 1.42975 acc: 0.71224 | v_loss: 1.52369 v_acc: 0.70410 |  iteration: 9315 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 614 loss: 1.44898 acc: 0.70638 | v_loss: 1.30887 v_acc: 0.72005 |  iteration: 9316 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 615 loss: 1.53106 acc: 0.69368 | v_loss: 1.39076 v_acc: 0.69987 |  iteration: 9317 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 616 loss: 1.43128 acc: 0.70833 | v_loss: 1.23226 v_acc: 0.71615 |  iteration: 9318 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 617 loss: 1.47158 acc: 0.70443 | v_loss: 1.43989 v_acc: 0.69857 |  iteration: 9319 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 618 loss: 1.49505 acc: 0.69466 | v_loss: 1.36668 v_acc: 0.70964 |  iteration: 9320 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 619 loss: 1.48111 acc: 0.69792 | v_loss: 1.35966 v_acc: 0.73079 |  iteration: 9321 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 620 loss: 1.48497 acc: 0.69238 | v_loss: 1.36430 v_acc: 0.71777 |  iteration: 9322 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 621 loss: 1.49712 acc: 0.69368 | v_loss: 1.37756 v_acc: 0.70410 |  iteration: 9323 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 622 loss: 1.39634 acc: 0.69759 | v_loss: 1.29407 v_acc: 0.72493 |  iteration: 9324 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 623 loss: 1.55295 acc: 0.69271 | v_loss: 1.30480 v_acc: 0.72038 |  iteration: 9325 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 624 loss: 1.44957 acc: 0.69987 | v_loss: 1.48486 v_acc: 0.69173 |  iteration: 9326 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 625 loss: 1.42537 acc: 0.70378 | v_loss: 1.34752 v_acc: 0.70996 |  iteration: 9327 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 626 loss: 1.53718 acc: 0.69141 | v_loss: 1.31366 v_acc: 0.71549 |  iteration: 9328 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 627 loss: 1.48547 acc: 0.69043 | v_loss: 1.30541 v_acc: 0.71452 |  iteration: 9329 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 628 loss: 1.31728 acc: 0.71680 | v_loss: 1.43655 v_acc: 0.70475 |  iteration: 9330 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 629 loss: 1.47491 acc: 0.71159 | v_loss: 1.31492 v_acc: 0.73210 |  iteration: 9331 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 630 loss: 1.44712 acc: 0.69727 | v_loss: 1.52014 v_acc: 0.71322 |  iteration: 9332 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 631 loss: 1.44600 acc: 0.70378 | v_loss: 1.30996 v_acc: 0.69531 |  iteration: 9333 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 632 loss: 1.48134 acc: 0.70312 | v_loss: 1.29442 v_acc: 0.70117 |  iteration: 9334 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 633 loss: 1.37207 acc: 0.70866 | v_loss: 1.45401 v_acc: 0.70312 |  iteration: 9335 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 634 loss: 1.38307 acc: 0.70996 | v_loss: 1.48809 v_acc: 0.70378 |  iteration: 9336 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 635 loss: 1.40229 acc: 0.70020 | v_loss: 1.54644 v_acc: 0.69368 |  iteration: 9337 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 636 loss: 1.46855 acc: 0.69629 | v_loss: 1.49451 v_acc: 0.70833 |  iteration: 9338 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 637 loss: 1.47533 acc: 0.69661 | v_loss: 1.44594 v_acc: 0.70085 |  iteration: 9339 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 638 loss: 1.33328 acc: 0.70996 | v_loss: 1.43654 v_acc: 0.70931 |  iteration: 9340 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 639 loss: 1.44042 acc: 0.71126 | v_loss: 1.41268 v_acc: 0.70703 |  iteration: 9341 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 640 loss: 1.39850 acc: 0.69564 | v_loss: 1.25525 v_acc: 0.71680 |  iteration: 9342 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 641 loss: 1.44895 acc: 0.70410 | v_loss: 1.34004 v_acc: 0.72396 |  iteration: 9343 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 642 loss: 1.50052 acc: 0.69954 | v_loss: 1.18509 v_acc: 0.70638 |  iteration: 9344 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 643 loss: 1.35096 acc: 0.70605 | v_loss: 1.34889 v_acc: 0.70247 |  iteration: 9345 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 644 loss: 1.40444 acc: 0.69889 | v_loss: 1.50094 v_acc: 0.69987 |  iteration: 9346 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 645 loss: 1.46846 acc: 0.70280 | v_loss: 1.34031 v_acc: 0.70540 |  iteration: 9347 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 646 loss: 1.33237 acc: 0.71745 | v_loss: 1.37288 v_acc: 0.69368 |  iteration: 9348 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 647 loss: 1.44850 acc: 0.69629 | v_loss: 1.26377 v_acc: 0.70573 |  iteration: 9349 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 648 loss: 1.36496 acc: 0.70312 | v_loss: 1.26893 v_acc: 0.70345 |  iteration: 9350 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 649 loss: 1.44636 acc: 0.70605 | v_loss: 1.25354 v_acc: 0.73503 |  iteration: 9351 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 650 loss: 1.49696 acc: 0.70117 | v_loss: 1.28182 v_acc: 0.72168 |  iteration: 9352 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 651 loss: 1.45113 acc: 0.69531 | v_loss: 1.31723 v_acc: 0.73145 |  iteration: 9353 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 652 loss: 1.44701 acc: 0.70085 | v_loss: 1.26466 v_acc: 0.72461 |  iteration: 9354 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 653 loss: 1.47197 acc: 0.69368 | v_loss: 1.30633 v_acc: 0.72005 |  iteration: 9355 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 654 loss: 1.39857 acc: 0.69857 | v_loss: 1.41340 v_acc: 0.70996 |  iteration: 9356 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 655 loss: 1.42085 acc: 0.69531 | v_loss: 1.40330 v_acc: 0.71875 |  iteration: 9357 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 656 loss: 1.52955 acc: 0.68783 | v_loss: 1.50680 v_acc: 0.69694 |  iteration: 9358 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 657 loss: 1.35760 acc: 0.70345 | v_loss: 1.42884 v_acc: 0.71615 |  iteration: 9359 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 658 loss: 1.42743 acc: 0.69368 | v_loss: 1.18194 v_acc: 0.74219 |  iteration: 9360 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 659 loss: 1.48195 acc: 0.68848 | v_loss: 1.27055 v_acc: 0.70312 |  iteration: 9361 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 660 loss: 1.45432 acc: 0.69824 | v_loss: 1.53450 v_acc: 0.69857 |  iteration: 9362 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 661 loss: 1.52351 acc: 0.70247 | v_loss: 1.23967 v_acc: 0.70736 |  iteration: 9363 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 662 loss: 1.52548 acc: 0.70312 | v_loss: 1.33832 v_acc: 0.70898 |  iteration: 9364 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 663 loss: 1.46872 acc: 0.70182 | v_loss: 1.37076 v_acc: 0.69076 |  iteration: 9365 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 664 loss: 1.37962 acc: 0.71777 | v_loss: 1.32240 v_acc: 0.70898 |  iteration: 9366 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 665 loss: 1.39875 acc: 0.71289 | v_loss: 1.38931 v_acc: 0.69206 |  iteration: 9367 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 666 loss: 1.56033 acc: 0.68262 | v_loss: 1.46152 v_acc: 0.70931 |  iteration: 9368 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 667 loss: 1.43462 acc: 0.71126 | v_loss: 1.32370 v_acc: 0.72363 |  iteration: 9369 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 668 loss: 1.46790 acc: 0.70052 | v_loss: 1.44888 v_acc: 0.70117 |  iteration: 9370 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 669 loss: 1.39933 acc: 0.70540 | v_loss: 1.37129 v_acc: 0.70085 |  iteration: 9371 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 670 loss: 1.39531 acc: 0.70833 | v_loss: 1.34373 v_acc: 0.70703 |  iteration: 9372 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 671 loss: 1.39748 acc: 0.70475 | v_loss: 1.54305 v_acc: 0.68880 |  iteration: 9373 teacher: 1 stage: sketch lr: 0.000456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 672 loss: 1.48223 acc: 0.69694 | v_loss: 1.31660 v_acc: 0.72103 |  iteration: 9374 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 673 loss: 1.43852 acc: 0.70736 | v_loss: 1.58521 v_acc: 0.68620 |  iteration: 9375 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 674 loss: 1.53991 acc: 0.69141 | v_loss: 1.42898 v_acc: 0.69987 |  iteration: 9376 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 675 loss: 1.37539 acc: 0.70833 | v_loss: 1.52605 v_acc: 0.68913 |  iteration: 9377 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 676 loss: 1.52803 acc: 0.68783 | v_loss: 1.37053 v_acc: 0.69759 |  iteration: 9378 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 677 loss: 1.41634 acc: 0.70182 | v_loss: 1.32536 v_acc: 0.70378 |  iteration: 9379 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 678 loss: 1.34359 acc: 0.70996 | v_loss: 1.33595 v_acc: 0.70215 |  iteration: 9380 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 679 loss: 1.40356 acc: 0.69889 | v_loss: 1.33370 v_acc: 0.71615 |  iteration: 9381 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 680 loss: 1.52427 acc: 0.69759 | v_loss: 1.53112 v_acc: 0.69173 |  iteration: 9382 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 681 loss: 1.47500 acc: 0.70475 | v_loss: 1.38260 v_acc: 0.70247 |  iteration: 9383 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 682 loss: 1.53478 acc: 0.69531 | v_loss: 1.34855 v_acc: 0.71126 |  iteration: 9384 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 683 loss: 1.44296 acc: 0.70150 | v_loss: 1.39087 v_acc: 0.71810 |  iteration: 9385 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 684 loss: 1.46629 acc: 0.69531 | v_loss: 1.28055 v_acc: 0.70215 |  iteration: 9386 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 685 loss: 1.41362 acc: 0.70215 | v_loss: 1.43378 v_acc: 0.69434 |  iteration: 9387 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 686 loss: 1.50280 acc: 0.69987 | v_loss: 1.43174 v_acc: 0.71452 |  iteration: 9388 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 687 loss: 1.39562 acc: 0.70247 | v_loss: 1.29111 v_acc: 0.71647 |  iteration: 9389 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 688 loss: 1.40971 acc: 0.70378 | v_loss: 1.27022 v_acc: 0.72526 |  iteration: 9390 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 689 loss: 1.47948 acc: 0.69857 | v_loss: 1.37631 v_acc: 0.71647 |  iteration: 9391 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 690 loss: 1.41559 acc: 0.71322 | v_loss: 1.42135 v_acc: 0.70052 |  iteration: 9392 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 691 loss: 1.37344 acc: 0.70215 | v_loss: 1.42874 v_acc: 0.70312 |  iteration: 9393 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 692 loss: 1.43116 acc: 0.70898 | v_loss: 1.24338 v_acc: 0.71452 |  iteration: 9394 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 693 loss: 1.49513 acc: 0.69173 | v_loss: 1.39145 v_acc: 0.72819 |  iteration: 9395 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 694 loss: 1.37432 acc: 0.70638 | v_loss: 1.47214 v_acc: 0.69792 |  iteration: 9396 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 695 loss: 1.55134 acc: 0.68848 | v_loss: 1.40440 v_acc: 0.71842 |  iteration: 9397 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 696 loss: 1.39316 acc: 0.70996 | v_loss: 1.25221 v_acc: 0.72201 |  iteration: 9398 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 697 loss: 1.53162 acc: 0.69303 | v_loss: 1.19638 v_acc: 0.74023 |  iteration: 9399 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 698 loss: 1.40952 acc: 0.69824 | v_loss: 1.21545 v_acc: 0.72493 |  iteration: 9400 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 699 loss: 1.47456 acc: 0.69434 | v_loss: 1.28474 v_acc: 0.71126 |  iteration: 9401 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 700 loss: 1.48738 acc: 0.70345 | v_loss: 1.45349 v_acc: 0.70671 |  iteration: 9402 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 701 loss: 1.46526 acc: 0.70150 | v_loss: 1.28487 v_acc: 0.71452 |  iteration: 9403 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 702 loss: 1.38302 acc: 0.71419 | v_loss: 1.43593 v_acc: 0.71745 |  iteration: 9404 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 703 loss: 1.42418 acc: 0.70117 | v_loss: 1.63700 v_acc: 0.69466 |  iteration: 9405 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 704 loss: 1.44049 acc: 0.70475 | v_loss: 1.51301 v_acc: 0.70410 |  iteration: 9406 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 705 loss: 1.40017 acc: 0.71387 | v_loss: 1.30607 v_acc: 0.72005 |  iteration: 9407 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 706 loss: 1.36484 acc: 0.70540 | v_loss: 1.38360 v_acc: 0.69987 |  iteration: 9408 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 707 loss: 1.46319 acc: 0.70020 | v_loss: 1.23479 v_acc: 0.71615 |  iteration: 9409 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 708 loss: 1.46241 acc: 0.69629 | v_loss: 1.42448 v_acc: 0.69857 |  iteration: 9410 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 709 loss: 1.36265 acc: 0.71224 | v_loss: 1.36688 v_acc: 0.71029 |  iteration: 9411 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 710 loss: 1.49227 acc: 0.70215 | v_loss: 1.35137 v_acc: 0.73079 |  iteration: 9412 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 711 loss: 1.51859 acc: 0.70085 | v_loss: 1.36985 v_acc: 0.71777 |  iteration: 9413 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 712 loss: 1.47212 acc: 0.69694 | v_loss: 1.39156 v_acc: 0.70410 |  iteration: 9414 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 713 loss: 1.35870 acc: 0.71029 | v_loss: 1.28856 v_acc: 0.72233 |  iteration: 9415 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 714 loss: 1.55017 acc: 0.70247 | v_loss: 1.31183 v_acc: 0.72005 |  iteration: 9416 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 715 loss: 1.43100 acc: 0.70117 | v_loss: 1.49314 v_acc: 0.69043 |  iteration: 9417 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 716 loss: 1.38586 acc: 0.71159 | v_loss: 1.34027 v_acc: 0.70833 |  iteration: 9418 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 717 loss: 1.48825 acc: 0.70020 | v_loss: 1.30857 v_acc: 0.71582 |  iteration: 9419 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 718 loss: 1.48187 acc: 0.69857 | v_loss: 1.30494 v_acc: 0.72201 |  iteration: 9420 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 719 loss: 1.45004 acc: 0.70475 | v_loss: 1.43876 v_acc: 0.70768 |  iteration: 9421 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 720 loss: 1.54258 acc: 0.69824 | v_loss: 1.31268 v_acc: 0.73210 |  iteration: 9422 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 721 loss: 1.45089 acc: 0.70247 | v_loss: 1.51925 v_acc: 0.71322 |  iteration: 9423 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 722 loss: 1.45580 acc: 0.69922 | v_loss: 1.30413 v_acc: 0.69531 |  iteration: 9424 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 723 loss: 1.43332 acc: 0.69792 | v_loss: 1.28890 v_acc: 0.70443 |  iteration: 9425 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 724 loss: 1.48153 acc: 0.70573 | v_loss: 1.43686 v_acc: 0.70312 |  iteration: 9426 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 725 loss: 1.41965 acc: 0.70671 | v_loss: 1.46680 v_acc: 0.70378 |  iteration: 9427 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 726 loss: 1.36374 acc: 0.71224 | v_loss: 1.51529 v_acc: 0.69368 |  iteration: 9428 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 727 loss: 1.48340 acc: 0.69271 | v_loss: 1.47720 v_acc: 0.70833 |  iteration: 9429 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 728 loss: 1.38027 acc: 0.70573 | v_loss: 1.43391 v_acc: 0.70085 |  iteration: 9430 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 729 loss: 1.53030 acc: 0.68685 | v_loss: 1.42770 v_acc: 0.70931 |  iteration: 9431 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 730 loss: 1.52342 acc: 0.70508 | v_loss: 1.38802 v_acc: 0.70475 |  iteration: 9432 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 731 loss: 1.40034 acc: 0.70736 | v_loss: 1.25670 v_acc: 0.71875 |  iteration: 9433 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 732 loss: 1.53910 acc: 0.70182 | v_loss: 1.33051 v_acc: 0.72461 |  iteration: 9434 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 733 loss: 1.38834 acc: 0.69922 | v_loss: 1.18374 v_acc: 0.71517 |  iteration: 9435 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 734 loss: 1.54247 acc: 0.69206 | v_loss: 1.34668 v_acc: 0.70150 |  iteration: 9436 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 735 loss: 1.50602 acc: 0.69954 | v_loss: 1.49669 v_acc: 0.69987 |  iteration: 9437 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 736 loss: 1.38026 acc: 0.71191 | v_loss: 1.35800 v_acc: 0.70638 |  iteration: 9438 teacher: 1 stage: sketch lr: 0.000455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 737 loss: 1.40703 acc: 0.70475 | v_loss: 1.35619 v_acc: 0.70247 |  iteration: 9439 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 738 loss: 1.41641 acc: 0.70410 | v_loss: 1.29143 v_acc: 0.70573 |  iteration: 9440 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 739 loss: 1.49801 acc: 0.70215 | v_loss: 1.27051 v_acc: 0.70215 |  iteration: 9441 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 740 loss: 1.48942 acc: 0.69531 | v_loss: 1.24474 v_acc: 0.73340 |  iteration: 9442 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 741 loss: 1.52794 acc: 0.69889 | v_loss: 1.29560 v_acc: 0.71647 |  iteration: 9443 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 742 loss: 1.42096 acc: 0.70931 | v_loss: 1.32396 v_acc: 0.74089 |  iteration: 9444 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 743 loss: 1.48145 acc: 0.70182 | v_loss: 1.26151 v_acc: 0.72005 |  iteration: 9445 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 744 loss: 1.50216 acc: 0.70378 | v_loss: 1.31076 v_acc: 0.71582 |  iteration: 9446 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 745 loss: 1.50292 acc: 0.69727 | v_loss: 1.40981 v_acc: 0.71224 |  iteration: 9447 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 746 loss: 1.45239 acc: 0.69238 | v_loss: 1.39799 v_acc: 0.71875 |  iteration: 9448 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 747 loss: 1.42805 acc: 0.71322 | v_loss: 1.49696 v_acc: 0.69694 |  iteration: 9449 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 748 loss: 1.53101 acc: 0.69141 | v_loss: 1.41041 v_acc: 0.71615 |  iteration: 9450 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 749 loss: 1.46941 acc: 0.69499 | v_loss: 1.17997 v_acc: 0.74544 |  iteration: 9451 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 750 loss: 1.45891 acc: 0.70117 | v_loss: 1.25535 v_acc: 0.70573 |  iteration: 9452 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 751 loss: 1.44087 acc: 0.70085 | v_loss: 1.51888 v_acc: 0.70247 |  iteration: 9453 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 752 loss: 1.53908 acc: 0.70085 | v_loss: 1.22038 v_acc: 0.70833 |  iteration: 9454 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 753 loss: 1.50537 acc: 0.69596 | v_loss: 1.33043 v_acc: 0.71257 |  iteration: 9455 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 754 loss: 1.39396 acc: 0.70833 | v_loss: 1.37124 v_acc: 0.69076 |  iteration: 9456 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 755 loss: 1.40542 acc: 0.70996 | v_loss: 1.32574 v_acc: 0.70898 |  iteration: 9457 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 756 loss: 1.51987 acc: 0.69694 | v_loss: 1.38206 v_acc: 0.69206 |  iteration: 9458 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 757 loss: 1.51428 acc: 0.70280 | v_loss: 1.46106 v_acc: 0.70931 |  iteration: 9459 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 758 loss: 1.45429 acc: 0.70117 | v_loss: 1.32023 v_acc: 0.72363 |  iteration: 9460 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 759 loss: 1.46411 acc: 0.69857 | v_loss: 1.44937 v_acc: 0.70117 |  iteration: 9461 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 760 loss: 1.49696 acc: 0.68945 | v_loss: 1.38728 v_acc: 0.70085 |  iteration: 9462 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 761 loss: 1.42551 acc: 0.70703 | v_loss: 1.34317 v_acc: 0.70703 |  iteration: 9463 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 762 loss: 1.51797 acc: 0.69434 | v_loss: 1.54764 v_acc: 0.68880 |  iteration: 9464 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 763 loss: 1.45030 acc: 0.70638 | v_loss: 1.29953 v_acc: 0.72103 |  iteration: 9465 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 764 loss: 1.59510 acc: 0.69401 | v_loss: 1.59041 v_acc: 0.68620 |  iteration: 9466 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 765 loss: 1.39498 acc: 0.70996 | v_loss: 1.43984 v_acc: 0.69987 |  iteration: 9467 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 766 loss: 1.51760 acc: 0.70215 | v_loss: 1.50840 v_acc: 0.68913 |  iteration: 9468 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 767 loss: 1.43540 acc: 0.70931 | v_loss: 1.38697 v_acc: 0.69759 |  iteration: 9469 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 768 loss: 1.45566 acc: 0.70475 | v_loss: 1.32443 v_acc: 0.70443 |  iteration: 9470 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 769 loss: 1.37480 acc: 0.70638 | v_loss: 1.34183 v_acc: 0.70052 |  iteration: 9471 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 770 loss: 1.39330 acc: 0.70182 | v_loss: 1.33320 v_acc: 0.71680 |  iteration: 9472 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 771 loss: 1.42927 acc: 0.71061 | v_loss: 1.55501 v_acc: 0.68783 |  iteration: 9473 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 772 loss: 1.35335 acc: 0.70605 | v_loss: 1.39706 v_acc: 0.70280 |  iteration: 9474 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 773 loss: 1.42331 acc: 0.69596 | v_loss: 1.37076 v_acc: 0.71029 |  iteration: 9475 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 774 loss: 1.38520 acc: 0.70638 | v_loss: 1.39411 v_acc: 0.71680 |  iteration: 9476 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 775 loss: 1.53729 acc: 0.69043 | v_loss: 1.27325 v_acc: 0.70573 |  iteration: 9477 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 776 loss: 1.38453 acc: 0.70768 | v_loss: 1.44593 v_acc: 0.69792 |  iteration: 9478 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 777 loss: 1.42747 acc: 0.70020 | v_loss: 1.44628 v_acc: 0.71289 |  iteration: 9479 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 778 loss: 1.39803 acc: 0.70736 | v_loss: 1.29710 v_acc: 0.71875 |  iteration: 9480 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 779 loss: 1.50186 acc: 0.70247 | v_loss: 1.25696 v_acc: 0.72754 |  iteration: 9481 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 780 loss: 1.36991 acc: 0.70508 | v_loss: 1.37652 v_acc: 0.71615 |  iteration: 9482 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 781 loss: 1.41245 acc: 0.70671 | v_loss: 1.41463 v_acc: 0.70540 |  iteration: 9483 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 782 loss: 1.50181 acc: 0.70345 | v_loss: 1.41951 v_acc: 0.70508 |  iteration: 9484 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 783 loss: 1.37222 acc: 0.70736 | v_loss: 1.24064 v_acc: 0.71452 |  iteration: 9485 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 784 loss: 1.41293 acc: 0.71517 | v_loss: 1.37936 v_acc: 0.72754 |  iteration: 9486 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 785 loss: 1.50696 acc: 0.69857 | v_loss: 1.46871 v_acc: 0.69792 |  iteration: 9487 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 786 loss: 1.42955 acc: 0.71517 | v_loss: 1.41701 v_acc: 0.71842 |  iteration: 9488 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 787 loss: 1.39815 acc: 0.70573 | v_loss: 1.26672 v_acc: 0.71615 |  iteration: 9489 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 788 loss: 1.47806 acc: 0.70150 | v_loss: 1.23302 v_acc: 0.72819 |  iteration: 9490 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 789 loss: 1.39635 acc: 0.70671 | v_loss: 1.23558 v_acc: 0.72559 |  iteration: 9491 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 790 loss: 1.39648 acc: 0.71029 | v_loss: 1.32212 v_acc: 0.70540 |  iteration: 9492 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 791 loss: 1.42283 acc: 0.70378 | v_loss: 1.50094 v_acc: 0.69466 |  iteration: 9493 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 792 loss: 1.46614 acc: 0.70150 | v_loss: 1.28104 v_acc: 0.71354 |  iteration: 9494 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 793 loss: 1.43373 acc: 0.70508 | v_loss: 1.43776 v_acc: 0.71647 |  iteration: 9495 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 794 loss: 1.63170 acc: 0.67969 | v_loss: 1.68301 v_acc: 0.69303 |  iteration: 9496 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 795 loss: 1.34713 acc: 0.70866 | v_loss: 1.52635 v_acc: 0.70117 |  iteration: 9497 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 796 loss: 1.49013 acc: 0.69727 | v_loss: 1.30246 v_acc: 0.72396 |  iteration: 9498 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 797 loss: 1.47384 acc: 0.69303 | v_loss: 1.36006 v_acc: 0.70996 |  iteration: 9499 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 798 loss: 1.51866 acc: 0.70378 | v_loss: 1.21844 v_acc: 0.72201 |  iteration: 9500 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 799 loss: 1.42517 acc: 0.70671 | v_loss: 1.41973 v_acc: 0.70150 |  iteration: 9501 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 800 loss: 1.44453 acc: 0.70540 | v_loss: 1.36074 v_acc: 0.71029 |  iteration: 9502 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 801 loss: 1.42906 acc: 0.70247 | v_loss: 1.36156 v_acc: 0.73079 |  iteration: 9503 teacher: 0 stage: sketch lr: 0.000453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 802 loss: 1.47222 acc: 0.69206 | v_loss: 1.35154 v_acc: 0.71680 |  iteration: 9504 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 803 loss: 1.38461 acc: 0.70182 | v_loss: 1.37930 v_acc: 0.70345 |  iteration: 9505 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 804 loss: 1.49704 acc: 0.69531 | v_loss: 1.31499 v_acc: 0.72201 |  iteration: 9506 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 805 loss: 1.41549 acc: 0.70443 | v_loss: 1.32676 v_acc: 0.72005 |  iteration: 9507 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 806 loss: 1.46959 acc: 0.70117 | v_loss: 1.50599 v_acc: 0.69043 |  iteration: 9508 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 807 loss: 1.49191 acc: 0.70312 | v_loss: 1.35056 v_acc: 0.70833 |  iteration: 9509 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 808 loss: 1.53427 acc: 0.69857 | v_loss: 1.29942 v_acc: 0.71582 |  iteration: 9510 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 809 loss: 1.45177 acc: 0.70378 | v_loss: 1.29502 v_acc: 0.72201 |  iteration: 9511 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 810 loss: 1.39136 acc: 0.71094 | v_loss: 1.42563 v_acc: 0.70768 |  iteration: 9512 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 811 loss: 1.34421 acc: 0.71289 | v_loss: 1.31131 v_acc: 0.73210 |  iteration: 9513 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 812 loss: 1.49755 acc: 0.69661 | v_loss: 1.52160 v_acc: 0.71322 |  iteration: 9514 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 813 loss: 1.68834 acc: 0.68099 | v_loss: 1.30802 v_acc: 0.69531 |  iteration: 9515 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 814 loss: 1.39507 acc: 0.69922 | v_loss: 1.29057 v_acc: 0.70117 |  iteration: 9516 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 815 loss: 1.39360 acc: 0.70605 | v_loss: 1.45894 v_acc: 0.70508 |  iteration: 9517 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 816 loss: 1.43783 acc: 0.69727 | v_loss: 1.49715 v_acc: 0.70573 |  iteration: 9518 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 817 loss: 1.48868 acc: 0.69596 | v_loss: 1.55294 v_acc: 0.68978 |  iteration: 9519 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 818 loss: 1.37546 acc: 0.71517 | v_loss: 1.47235 v_acc: 0.70540 |  iteration: 9520 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 819 loss: 1.39441 acc: 0.70996 | v_loss: 1.45804 v_acc: 0.70410 |  iteration: 9521 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 820 loss: 1.50804 acc: 0.69206 | v_loss: 1.44222 v_acc: 0.70768 |  iteration: 9522 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 821 loss: 1.52676 acc: 0.69824 | v_loss: 1.39383 v_acc: 0.70703 |  iteration: 9523 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 822 loss: 1.38524 acc: 0.70833 | v_loss: 1.26409 v_acc: 0.71875 |  iteration: 9524 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 823 loss: 1.47280 acc: 0.70378 | v_loss: 1.32476 v_acc: 0.72331 |  iteration: 9525 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 824 loss: 1.45524 acc: 0.69922 | v_loss: 1.20575 v_acc: 0.71615 |  iteration: 9526 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 825 loss: 1.50409 acc: 0.71224 | v_loss: 1.35715 v_acc: 0.70703 |  iteration: 9527 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 826 loss: 1.48722 acc: 0.70801 | v_loss: 1.50433 v_acc: 0.69987 |  iteration: 9528 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 827 loss: 1.49134 acc: 0.70345 | v_loss: 1.37002 v_acc: 0.70638 |  iteration: 9529 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 828 loss: 1.46418 acc: 0.70020 | v_loss: 1.36514 v_acc: 0.69531 |  iteration: 9530 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 829 loss: 1.52510 acc: 0.69010 | v_loss: 1.31512 v_acc: 0.70312 |  iteration: 9531 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 830 loss: 1.43845 acc: 0.69857 | v_loss: 1.29293 v_acc: 0.70085 |  iteration: 9532 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 831 loss: 1.38045 acc: 0.70410 | v_loss: 1.24730 v_acc: 0.73568 |  iteration: 9533 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 832 loss: 1.40825 acc: 0.70475 | v_loss: 1.29887 v_acc: 0.71647 |  iteration: 9534 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 833 loss: 1.39078 acc: 0.70964 | v_loss: 1.34236 v_acc: 0.74089 |  iteration: 9535 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 834 loss: 1.36363 acc: 0.71875 | v_loss: 1.26711 v_acc: 0.72005 |  iteration: 9536 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 835 loss: 1.36261 acc: 0.71257 | v_loss: 1.32692 v_acc: 0.72005 |  iteration: 9537 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 836 loss: 1.43279 acc: 0.71484 | v_loss: 1.43715 v_acc: 0.71354 |  iteration: 9538 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 837 loss: 1.52417 acc: 0.69987 | v_loss: 1.42123 v_acc: 0.72428 |  iteration: 9539 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 838 loss: 1.46101 acc: 0.69434 | v_loss: 1.50031 v_acc: 0.70182 |  iteration: 9540 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 839 loss: 1.39079 acc: 0.69727 | v_loss: 1.44079 v_acc: 0.71777 |  iteration: 9541 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 840 loss: 1.49973 acc: 0.69759 | v_loss: 1.18494 v_acc: 0.74544 |  iteration: 9542 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 841 loss: 1.39209 acc: 0.70378 | v_loss: 1.27477 v_acc: 0.70573 |  iteration: 9543 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 842 loss: 1.46615 acc: 0.69499 | v_loss: 1.53466 v_acc: 0.70247 |  iteration: 9544 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 843 loss: 1.51104 acc: 0.69661 | v_loss: 1.25181 v_acc: 0.70833 |  iteration: 9545 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 844 loss: 1.42577 acc: 0.71354 | v_loss: 1.33356 v_acc: 0.71159 |  iteration: 9546 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 845 loss: 1.49252 acc: 0.70345 | v_loss: 1.36623 v_acc: 0.69368 |  iteration: 9547 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 846 loss: 1.41095 acc: 0.69824 | v_loss: 1.30585 v_acc: 0.71842 |  iteration: 9548 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 847 loss: 1.49602 acc: 0.69531 | v_loss: 1.36423 v_acc: 0.69629 |  iteration: 9549 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 848 loss: 1.54966 acc: 0.70020 | v_loss: 1.47438 v_acc: 0.71517 |  iteration: 9550 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 849 loss: 1.35445 acc: 0.70540 | v_loss: 1.32597 v_acc: 0.72689 |  iteration: 9551 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 850 loss: 1.53596 acc: 0.69043 | v_loss: 1.46493 v_acc: 0.70443 |  iteration: 9552 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 851 loss: 1.48712 acc: 0.70703 | v_loss: 1.36132 v_acc: 0.70085 |  iteration: 9553 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 852 loss: 1.39168 acc: 0.70443 | v_loss: 1.36107 v_acc: 0.70703 |  iteration: 9554 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 853 loss: 1.58983 acc: 0.69108 | v_loss: 1.54586 v_acc: 0.68880 |  iteration: 9555 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 854 loss: 1.40870 acc: 0.70345 | v_loss: 1.30741 v_acc: 0.72103 |  iteration: 9556 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 855 loss: 1.52122 acc: 0.69303 | v_loss: 1.58567 v_acc: 0.68620 |  iteration: 9557 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 856 loss: 1.38285 acc: 0.71224 | v_loss: 1.44467 v_acc: 0.69987 |  iteration: 9558 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 857 loss: 1.49943 acc: 0.69368 | v_loss: 1.50833 v_acc: 0.68913 |  iteration: 9559 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 858 loss: 1.46477 acc: 0.69857 | v_loss: 1.39999 v_acc: 0.69759 |  iteration: 9560 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 859 loss: 1.52260 acc: 0.69792 | v_loss: 1.34750 v_acc: 0.70215 |  iteration: 9561 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 860 loss: 1.47535 acc: 0.70410 | v_loss: 1.35172 v_acc: 0.69889 |  iteration: 9562 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 861 loss: 1.43051 acc: 0.70312 | v_loss: 1.33765 v_acc: 0.71419 |  iteration: 9563 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 862 loss: 1.37571 acc: 0.70638 | v_loss: 1.53932 v_acc: 0.68945 |  iteration: 9564 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 863 loss: 1.40345 acc: 0.70247 | v_loss: 1.38374 v_acc: 0.70703 |  iteration: 9565 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 864 loss: 1.56884 acc: 0.69238 | v_loss: 1.39308 v_acc: 0.70508 |  iteration: 9566 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 865 loss: 1.44759 acc: 0.69922 | v_loss: 1.39951 v_acc: 0.70833 |  iteration: 9567 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 866 loss: 1.47647 acc: 0.69238 | v_loss: 1.27848 v_acc: 0.70605 |  iteration: 9568 teacher: 0 stage: sketch lr: 0.000452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 867 loss: 1.48064 acc: 0.69238 | v_loss: 1.43761 v_acc: 0.70150 |  iteration: 9569 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 868 loss: 1.57079 acc: 0.69271 | v_loss: 1.41798 v_acc: 0.71549 |  iteration: 9570 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 869 loss: 1.44239 acc: 0.70866 | v_loss: 1.29054 v_acc: 0.72038 |  iteration: 9571 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 870 loss: 1.38030 acc: 0.69792 | v_loss: 1.25411 v_acc: 0.72819 |  iteration: 9572 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 871 loss: 1.46133 acc: 0.69727 | v_loss: 1.37079 v_acc: 0.71615 |  iteration: 9573 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 872 loss: 1.55351 acc: 0.69531 | v_loss: 1.41300 v_acc: 0.70345 |  iteration: 9574 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 873 loss: 1.40697 acc: 0.71387 | v_loss: 1.42334 v_acc: 0.70410 |  iteration: 9575 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 874 loss: 1.49973 acc: 0.69759 | v_loss: 1.24801 v_acc: 0.71419 |  iteration: 9576 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 875 loss: 1.39347 acc: 0.70443 | v_loss: 1.39413 v_acc: 0.72819 |  iteration: 9577 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 876 loss: 1.37687 acc: 0.69857 | v_loss: 1.46747 v_acc: 0.69792 |  iteration: 9578 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 877 loss: 1.45657 acc: 0.70150 | v_loss: 1.40121 v_acc: 0.71842 |  iteration: 9579 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 878 loss: 1.51871 acc: 0.69987 | v_loss: 1.26727 v_acc: 0.71810 |  iteration: 9580 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 879 loss: 1.52624 acc: 0.69206 | v_loss: 1.23083 v_acc: 0.73535 |  iteration: 9581 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 880 loss: 1.49551 acc: 0.70085 | v_loss: 1.22481 v_acc: 0.72656 |  iteration: 9582 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 881 loss: 1.43792 acc: 0.70508 | v_loss: 1.29123 v_acc: 0.70703 |  iteration: 9583 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 882 loss: 1.47024 acc: 0.70117 | v_loss: 1.43690 v_acc: 0.69466 |  iteration: 9584 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 883 loss: 1.46912 acc: 0.69857 | v_loss: 1.29167 v_acc: 0.71484 |  iteration: 9585 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 884 loss: 1.47177 acc: 0.69889 | v_loss: 1.46451 v_acc: 0.71647 |  iteration: 9586 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 885 loss: 1.54737 acc: 0.69466 | v_loss: 1.65148 v_acc: 0.69401 |  iteration: 9587 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 886 loss: 1.38553 acc: 0.70443 | v_loss: 1.52016 v_acc: 0.69922 |  iteration: 9588 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 887 loss: 1.36786 acc: 0.70475 | v_loss: 1.30680 v_acc: 0.72135 |  iteration: 9589 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 888 loss: 1.33657 acc: 0.71484 | v_loss: 1.37337 v_acc: 0.70117 |  iteration: 9590 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 889 loss: 1.46871 acc: 0.70215 | v_loss: 1.22594 v_acc: 0.71908 |  iteration: 9591 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 890 loss: 1.49247 acc: 0.70345 | v_loss: 1.42996 v_acc: 0.69238 |  iteration: 9592 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 891 loss: 1.48047 acc: 0.70312 | v_loss: 1.36898 v_acc: 0.70736 |  iteration: 9593 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 892 loss: 1.37316 acc: 0.70573 | v_loss: 1.35928 v_acc: 0.72884 |  iteration: 9594 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 893 loss: 1.42041 acc: 0.70671 | v_loss: 1.35666 v_acc: 0.71680 |  iteration: 9595 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 894 loss: 1.39061 acc: 0.70280 | v_loss: 1.37787 v_acc: 0.70345 |  iteration: 9596 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 895 loss: 1.48199 acc: 0.70801 | v_loss: 1.28958 v_acc: 0.72233 |  iteration: 9597 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 896 loss: 1.42838 acc: 0.70768 | v_loss: 1.30207 v_acc: 0.72135 |  iteration: 9598 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 897 loss: 1.44235 acc: 0.69759 | v_loss: 1.46947 v_acc: 0.69368 |  iteration: 9599 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 898 loss: 1.56130 acc: 0.68685 | v_loss: 1.35050 v_acc: 0.71452 |  iteration: 9600 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 899 loss: 1.41720 acc: 0.69824 | v_loss: 1.29563 v_acc: 0.71777 |  iteration: 9601 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 900 loss: 1.45163 acc: 0.69824 | v_loss: 1.27940 v_acc: 0.71484 |  iteration: 9602 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 901 loss: 1.56274 acc: 0.68522 | v_loss: 1.43036 v_acc: 0.70573 |  iteration: 9603 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 902 loss: 1.38937 acc: 0.71061 | v_loss: 1.32102 v_acc: 0.73112 |  iteration: 9604 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 903 loss: 1.57936 acc: 0.68457 | v_loss: 1.53937 v_acc: 0.71615 |  iteration: 9605 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 904 loss: 1.35620 acc: 0.71777 | v_loss: 1.28702 v_acc: 0.69759 |  iteration: 9606 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 905 loss: 1.40558 acc: 0.70345 | v_loss: 1.28193 v_acc: 0.70703 |  iteration: 9607 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 906 loss: 1.38731 acc: 0.70085 | v_loss: 1.45677 v_acc: 0.70475 |  iteration: 9608 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 907 loss: 1.42701 acc: 0.69954 | v_loss: 1.48806 v_acc: 0.70443 |  iteration: 9609 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 908 loss: 1.45947 acc: 0.70410 | v_loss: 1.52791 v_acc: 0.69076 |  iteration: 9610 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 909 loss: 1.36965 acc: 0.71322 | v_loss: 1.48675 v_acc: 0.70833 |  iteration: 9611 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 910 loss: 1.42149 acc: 0.69889 | v_loss: 1.43533 v_acc: 0.70085 |  iteration: 9612 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 911 loss: 1.42695 acc: 0.70671 | v_loss: 1.40522 v_acc: 0.70931 |  iteration: 9613 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 912 loss: 1.38613 acc: 0.70215 | v_loss: 1.41117 v_acc: 0.70703 |  iteration: 9614 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 913 loss: 1.41799 acc: 0.70996 | v_loss: 1.27186 v_acc: 0.71875 |  iteration: 9615 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 914 loss: 1.41743 acc: 0.70378 | v_loss: 1.32656 v_acc: 0.72331 |  iteration: 9616 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 915 loss: 1.46814 acc: 0.70215 | v_loss: 1.19797 v_acc: 0.70573 |  iteration: 9617 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 916 loss: 1.42787 acc: 0.69792 | v_loss: 1.35338 v_acc: 0.70052 |  iteration: 9618 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 917 loss: 1.45132 acc: 0.69661 | v_loss: 1.50498 v_acc: 0.69727 |  iteration: 9619 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 918 loss: 1.49685 acc: 0.70020 | v_loss: 1.34212 v_acc: 0.70540 |  iteration: 9620 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 919 loss: 1.58823 acc: 0.68783 | v_loss: 1.35594 v_acc: 0.69401 |  iteration: 9621 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 920 loss: 1.46822 acc: 0.70378 | v_loss: 1.27459 v_acc: 0.70280 |  iteration: 9622 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 921 loss: 1.45613 acc: 0.70247 | v_loss: 1.27977 v_acc: 0.70085 |  iteration: 9623 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 922 loss: 1.53219 acc: 0.69108 | v_loss: 1.24012 v_acc: 0.73568 |  iteration: 9624 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 923 loss: 1.52694 acc: 0.69368 | v_loss: 1.28427 v_acc: 0.71647 |  iteration: 9625 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 924 loss: 1.39372 acc: 0.71029 | v_loss: 1.31731 v_acc: 0.74089 |  iteration: 9626 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 925 loss: 1.52466 acc: 0.69727 | v_loss: 1.26572 v_acc: 0.72005 |  iteration: 9627 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 926 loss: 1.55469 acc: 0.68913 | v_loss: 1.31103 v_acc: 0.72005 |  iteration: 9628 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 927 loss: 1.38077 acc: 0.70996 | v_loss: 1.42408 v_acc: 0.71224 |  iteration: 9629 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 928 loss: 1.41464 acc: 0.70475 | v_loss: 1.40693 v_acc: 0.72070 |  iteration: 9630 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 929 loss: 1.44188 acc: 0.70898 | v_loss: 1.49021 v_acc: 0.69954 |  iteration: 9631 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 930 loss: 1.58162 acc: 0.69238 | v_loss: 1.43826 v_acc: 0.71615 |  iteration: 9632 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 931 loss: 1.47369 acc: 0.70020 | v_loss: 1.18471 v_acc: 0.74544 |  iteration: 9633 teacher: 0 stage: sketch lr: 0.000450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 932 loss: 1.49078 acc: 0.69759 | v_loss: 1.27076 v_acc: 0.70573 |  iteration: 9634 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 933 loss: 1.44094 acc: 0.69792 | v_loss: 1.53298 v_acc: 0.70443 |  iteration: 9635 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 934 loss: 1.34263 acc: 0.71582 | v_loss: 1.24380 v_acc: 0.70833 |  iteration: 9636 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 935 loss: 1.42682 acc: 0.70247 | v_loss: 1.32895 v_acc: 0.71257 |  iteration: 9637 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 936 loss: 1.34074 acc: 0.71973 | v_loss: 1.36994 v_acc: 0.69076 |  iteration: 9638 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 937 loss: 1.40559 acc: 0.70182 | v_loss: 1.30062 v_acc: 0.70898 |  iteration: 9639 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 938 loss: 1.47122 acc: 0.70605 | v_loss: 1.37680 v_acc: 0.69206 |  iteration: 9640 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 939 loss: 1.45329 acc: 0.70312 | v_loss: 1.48001 v_acc: 0.70931 |  iteration: 9641 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 940 loss: 1.40822 acc: 0.70801 | v_loss: 1.32345 v_acc: 0.72363 |  iteration: 9642 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 941 loss: 1.40844 acc: 0.69792 | v_loss: 1.45089 v_acc: 0.70117 |  iteration: 9643 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 942 loss: 1.31628 acc: 0.70964 | v_loss: 1.38379 v_acc: 0.70085 |  iteration: 9644 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 943 loss: 1.45887 acc: 0.69792 | v_loss: 1.32853 v_acc: 0.70703 |  iteration: 9645 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 944 loss: 1.43693 acc: 0.70801 | v_loss: 1.54574 v_acc: 0.68880 |  iteration: 9646 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 945 loss: 1.47530 acc: 0.70215 | v_loss: 1.30912 v_acc: 0.72103 |  iteration: 9647 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 946 loss: 1.56496 acc: 0.69303 | v_loss: 1.59011 v_acc: 0.68620 |  iteration: 9648 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 947 loss: 1.42490 acc: 0.69727 | v_loss: 1.43044 v_acc: 0.69987 |  iteration: 9649 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 948 loss: 1.41686 acc: 0.70540 | v_loss: 1.52356 v_acc: 0.68913 |  iteration: 9650 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 949 loss: 1.41630 acc: 0.69889 | v_loss: 1.37335 v_acc: 0.69759 |  iteration: 9651 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 950 loss: 1.41208 acc: 0.69889 | v_loss: 1.33290 v_acc: 0.70215 |  iteration: 9652 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 951 loss: 1.44698 acc: 0.70996 | v_loss: 1.34470 v_acc: 0.70020 |  iteration: 9653 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 952 loss: 1.36552 acc: 0.71712 | v_loss: 1.34876 v_acc: 0.71484 |  iteration: 9654 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 953 loss: 1.38064 acc: 0.71061 | v_loss: 1.55340 v_acc: 0.69108 |  iteration: 9655 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 954 loss: 1.39942 acc: 0.71029 | v_loss: 1.39697 v_acc: 0.70443 |  iteration: 9656 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 955 loss: 1.43198 acc: 0.70508 | v_loss: 1.34314 v_acc: 0.71126 |  iteration: 9657 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 956 loss: 1.44705 acc: 0.71126 | v_loss: 1.39034 v_acc: 0.71810 |  iteration: 9658 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 957 loss: 1.32380 acc: 0.70443 | v_loss: 1.28382 v_acc: 0.70215 |  iteration: 9659 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 958 loss: 1.45219 acc: 0.70345 | v_loss: 1.43795 v_acc: 0.69434 |  iteration: 9660 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 959 loss: 1.34538 acc: 0.70996 | v_loss: 1.43448 v_acc: 0.71452 |  iteration: 9661 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 960 loss: 1.47024 acc: 0.69824 | v_loss: 1.30994 v_acc: 0.71257 |  iteration: 9662 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 961 loss: 1.42565 acc: 0.70280 | v_loss: 1.25833 v_acc: 0.72331 |  iteration: 9663 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 962 loss: 1.43348 acc: 0.71191 | v_loss: 1.37859 v_acc: 0.71582 |  iteration: 9664 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 963 loss: 1.61202 acc: 0.69531 | v_loss: 1.41800 v_acc: 0.70215 |  iteration: 9665 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 964 loss: 1.43681 acc: 0.69434 | v_loss: 1.42164 v_acc: 0.70508 |  iteration: 9666 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 965 loss: 1.50787 acc: 0.70345 | v_loss: 1.24042 v_acc: 0.71452 |  iteration: 9667 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 966 loss: 1.36857 acc: 0.71419 | v_loss: 1.37906 v_acc: 0.73112 |  iteration: 9668 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 967 loss: 1.30975 acc: 0.71680 | v_loss: 1.46849 v_acc: 0.69792 |  iteration: 9669 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 968 loss: 1.41052 acc: 0.70736 | v_loss: 1.42250 v_acc: 0.72070 |  iteration: 9670 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 969 loss: 1.43636 acc: 0.70866 | v_loss: 1.26505 v_acc: 0.71810 |  iteration: 9671 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 970 loss: 1.51738 acc: 0.69336 | v_loss: 1.22795 v_acc: 0.73535 |  iteration: 9672 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 971 loss: 1.48328 acc: 0.70410 | v_loss: 1.22864 v_acc: 0.72656 |  iteration: 9673 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 972 loss: 1.53237 acc: 0.69629 | v_loss: 1.31318 v_acc: 0.70703 |  iteration: 9674 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 973 loss: 1.52855 acc: 0.69922 | v_loss: 1.45092 v_acc: 0.69466 |  iteration: 9675 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 974 loss: 1.58920 acc: 0.68685 | v_loss: 1.29544 v_acc: 0.71484 |  iteration: 9676 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 975 loss: 1.49493 acc: 0.70117 | v_loss: 1.44084 v_acc: 0.72949 |  iteration: 9677 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 976 loss: 1.37567 acc: 0.71289 | v_loss: 1.62473 v_acc: 0.69466 |  iteration: 9678 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 977 loss: 1.42063 acc: 0.70475 | v_loss: 1.50353 v_acc: 0.70410 |  iteration: 9679 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 978 loss: 1.41556 acc: 0.71647 | v_loss: 1.30256 v_acc: 0.72396 |  iteration: 9680 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 979 loss: 1.45457 acc: 0.69987 | v_loss: 1.37184 v_acc: 0.70345 |  iteration: 9681 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 980 loss: 1.49620 acc: 0.69238 | v_loss: 1.23151 v_acc: 0.71908 |  iteration: 9682 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 981 loss: 1.49067 acc: 0.70117 | v_loss: 1.41259 v_acc: 0.70378 |  iteration: 9683 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 982 loss: 1.46233 acc: 0.70345 | v_loss: 1.36734 v_acc: 0.71810 |  iteration: 9684 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 983 loss: 1.41731 acc: 0.70671 | v_loss: 1.36024 v_acc: 0.72852 |  iteration: 9685 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 984 loss: 1.49646 acc: 0.69596 | v_loss: 1.36352 v_acc: 0.72201 |  iteration: 9686 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 985 loss: 1.38960 acc: 0.71549 | v_loss: 1.38042 v_acc: 0.71061 |  iteration: 9687 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 986 loss: 1.38148 acc: 0.70964 | v_loss: 1.30828 v_acc: 0.72461 |  iteration: 9688 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 987 loss: 1.46062 acc: 0.70345 | v_loss: 1.29844 v_acc: 0.72038 |  iteration: 9689 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 988 loss: 1.47587 acc: 0.69857 | v_loss: 1.54156 v_acc: 0.69368 |  iteration: 9690 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 989 loss: 1.41615 acc: 0.70150 | v_loss: 1.32611 v_acc: 0.71452 |  iteration: 9691 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 990 loss: 1.38190 acc: 0.70540 | v_loss: 1.29489 v_acc: 0.71777 |  iteration: 9692 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 991 loss: 1.50802 acc: 0.69954 | v_loss: 1.28536 v_acc: 0.71484 |  iteration: 9693 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 992 loss: 1.43328 acc: 0.70605 | v_loss: 1.43768 v_acc: 0.70540 |  iteration: 9694 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 993 loss: 1.37552 acc: 0.70964 | v_loss: 1.32329 v_acc: 0.73047 |  iteration: 9695 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 994 loss: 1.42026 acc: 0.70508 | v_loss: 1.56192 v_acc: 0.71582 |  iteration: 9696 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 995 loss: 1.53973 acc: 0.69987 | v_loss: 1.29587 v_acc: 0.69759 |  iteration: 9697 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 996 loss: 1.48789 acc: 0.70247 | v_loss: 1.28419 v_acc: 0.70443 |  iteration: 9698 teacher: 0 stage: sketch lr: 0.000449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 997 loss: 1.48907 acc: 0.69596 | v_loss: 1.44445 v_acc: 0.70508 |  iteration: 9699 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 998 loss: 1.62122 acc: 0.68327 | v_loss: 1.47266 v_acc: 0.70768 |  iteration: 9700 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 999 loss: 1.40770 acc: 0.71094 | v_loss: 1.51719 v_acc: 0.68783 |  iteration: 9701 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 1000 loss: 1.50757 acc: 0.70020 | v_loss: 1.46609 v_acc: 0.70410 |  iteration: 9702 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 1001 loss: 1.45882 acc: 0.70247 | v_loss: 1.43972 v_acc: 0.71029 |  iteration: 9703 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 1002 loss: 1.57004 acc: 0.68717 | v_loss: 1.42764 v_acc: 0.70508 |  iteration: 9704 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 1003 loss: 1.43852 acc: 0.70866 | v_loss: 1.43917 v_acc: 0.70605 |  iteration: 9705 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 1004 loss: 1.54844 acc: 0.70671 | v_loss: 1.29632 v_acc: 0.71257 |  iteration: 9706 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 1005 loss: 1.49518 acc: 0.69629 | v_loss: 1.32766 v_acc: 0.72493 |  iteration: 9707 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 1006 loss: 1.55031 acc: 0.68783 | v_loss: 1.21660 v_acc: 0.71517 |  iteration: 9708 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 1007 loss: 1.37667 acc: 0.71452 | v_loss: 1.35175 v_acc: 0.70703 |  iteration: 9709 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 1008 loss: 1.43695 acc: 0.70378 | v_loss: 1.51043 v_acc: 0.69954 |  iteration: 9710 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1009 loss: 1.56597 acc: 0.69954 | v_loss: 1.32477 v_acc: 0.71484 |  iteration: 9711 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1010 loss: 1.35622 acc: 0.70671 | v_loss: 1.36590 v_acc: 0.70312 |  iteration: 9712 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1011 loss: 1.54123 acc: 0.69596 | v_loss: 1.23535 v_acc: 0.71680 |  iteration: 9713 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1012 loss: 1.44138 acc: 0.69954 | v_loss: 1.24772 v_acc: 0.70671 |  iteration: 9714 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1013 loss: 1.28683 acc: 0.70898 | v_loss: 1.27290 v_acc: 0.73242 |  iteration: 9715 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1014 loss: 1.46136 acc: 0.69727 | v_loss: 1.28097 v_acc: 0.71647 |  iteration: 9716 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1015 loss: 1.41162 acc: 0.69629 | v_loss: 1.39758 v_acc: 0.71582 |  iteration: 9717 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1016 loss: 1.66255 acc: 0.67350 | v_loss: 1.28625 v_acc: 0.71615 |  iteration: 9718 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1017 loss: 1.43278 acc: 0.69857 | v_loss: 1.31566 v_acc: 0.71517 |  iteration: 9719 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1018 loss: 1.40301 acc: 0.70410 | v_loss: 1.40938 v_acc: 0.71289 |  iteration: 9720 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1019 loss: 1.40437 acc: 0.71615 | v_loss: 1.38059 v_acc: 0.72038 |  iteration: 9721 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1020 loss: 1.55300 acc: 0.68652 | v_loss: 1.49064 v_acc: 0.69661 |  iteration: 9722 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1021 loss: 1.49557 acc: 0.70182 | v_loss: 1.40672 v_acc: 0.71745 |  iteration: 9723 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1022 loss: 1.48985 acc: 0.70703 | v_loss: 1.18277 v_acc: 0.74382 |  iteration: 9724 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1023 loss: 1.48963 acc: 0.69922 | v_loss: 1.29224 v_acc: 0.70280 |  iteration: 9725 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1024 loss: 1.43951 acc: 0.70573 | v_loss: 1.50233 v_acc: 0.70280 |  iteration: 9726 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1025 loss: 1.34049 acc: 0.71159 | v_loss: 1.24111 v_acc: 0.71647 |  iteration: 9727 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1026 loss: 1.56877 acc: 0.68717 | v_loss: 1.33172 v_acc: 0.71191 |  iteration: 9728 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1027 loss: 1.53052 acc: 0.69206 | v_loss: 1.37306 v_acc: 0.69076 |  iteration: 9729 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1028 loss: 1.33734 acc: 0.71419 | v_loss: 1.31594 v_acc: 0.70866 |  iteration: 9730 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1029 loss: 1.42215 acc: 0.70605 | v_loss: 1.37384 v_acc: 0.69238 |  iteration: 9731 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1030 loss: 1.35721 acc: 0.71224 | v_loss: 1.48927 v_acc: 0.71484 |  iteration: 9732 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1031 loss: 1.50693 acc: 0.70117 | v_loss: 1.32485 v_acc: 0.72786 |  iteration: 9733 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1032 loss: 1.35639 acc: 0.70931 | v_loss: 1.45071 v_acc: 0.70540 |  iteration: 9734 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1033 loss: 1.56406 acc: 0.69987 | v_loss: 1.38157 v_acc: 0.69857 |  iteration: 9735 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1034 loss: 1.55596 acc: 0.69434 | v_loss: 1.32088 v_acc: 0.70833 |  iteration: 9736 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1035 loss: 1.47880 acc: 0.70150 | v_loss: 1.57478 v_acc: 0.68522 |  iteration: 9737 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1036 loss: 1.46181 acc: 0.69499 | v_loss: 1.30597 v_acc: 0.72298 |  iteration: 9738 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1037 loss: 1.41632 acc: 0.69922 | v_loss: 1.58294 v_acc: 0.68294 |  iteration: 9739 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1038 loss: 1.39804 acc: 0.71452 | v_loss: 1.45681 v_acc: 0.69499 |  iteration: 9740 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1039 loss: 1.42033 acc: 0.70020 | v_loss: 1.50976 v_acc: 0.68978 |  iteration: 9741 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1040 loss: 1.42141 acc: 0.71257 | v_loss: 1.37595 v_acc: 0.69857 |  iteration: 9742 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1041 loss: 1.48452 acc: 0.69499 | v_loss: 1.33394 v_acc: 0.70117 |  iteration: 9743 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1042 loss: 1.50827 acc: 0.70247 | v_loss: 1.34088 v_acc: 0.69759 |  iteration: 9744 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1043 loss: 1.37428 acc: 0.70508 | v_loss: 1.33082 v_acc: 0.71549 |  iteration: 9745 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1044 loss: 1.35292 acc: 0.71029 | v_loss: 1.53276 v_acc: 0.69173 |  iteration: 9746 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1045 loss: 1.45638 acc: 0.69596 | v_loss: 1.38098 v_acc: 0.70247 |  iteration: 9747 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1046 loss: 1.41607 acc: 0.69531 | v_loss: 1.37602 v_acc: 0.71029 |  iteration: 9748 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1047 loss: 1.46124 acc: 0.70540 | v_loss: 1.39461 v_acc: 0.71452 |  iteration: 9749 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1048 loss: 1.50363 acc: 0.69336 | v_loss: 1.26502 v_acc: 0.71191 |  iteration: 9750 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1049 loss: 1.44716 acc: 0.70540 | v_loss: 1.44887 v_acc: 0.70020 |  iteration: 9751 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1050 loss: 1.46587 acc: 0.70540 | v_loss: 1.43269 v_acc: 0.71094 |  iteration: 9752 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1051 loss: 1.55876 acc: 0.69173 | v_loss: 1.28177 v_acc: 0.71810 |  iteration: 9753 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1052 loss: 1.52173 acc: 0.69173 | v_loss: 1.25659 v_acc: 0.72591 |  iteration: 9754 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1053 loss: 1.37199 acc: 0.71354 | v_loss: 1.38519 v_acc: 0.71387 |  iteration: 9755 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1054 loss: 1.45704 acc: 0.69108 | v_loss: 1.41243 v_acc: 0.70540 |  iteration: 9756 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1055 loss: 1.33686 acc: 0.70833 | v_loss: 1.42294 v_acc: 0.70508 |  iteration: 9757 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1056 loss: 1.34644 acc: 0.71712 | v_loss: 1.24617 v_acc: 0.71419 |  iteration: 9758 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1057 loss: 1.48346 acc: 0.69531 | v_loss: 1.39714 v_acc: 0.72819 |  iteration: 9759 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1058 loss: 1.48743 acc: 0.69727 | v_loss: 1.47109 v_acc: 0.69792 |  iteration: 9760 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1059 loss: 1.36863 acc: 0.71419 | v_loss: 1.39655 v_acc: 0.71842 |  iteration: 9761 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1060 loss: 1.45634 acc: 0.70052 | v_loss: 1.25853 v_acc: 0.71810 |  iteration: 9762 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1061 loss: 1.39801 acc: 0.70605 | v_loss: 1.21868 v_acc: 0.73535 |  iteration: 9763 teacher: 1 stage: sketch lr: 0.000447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1062 loss: 1.45896 acc: 0.70020 | v_loss: 1.22240 v_acc: 0.72559 |  iteration: 9764 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1063 loss: 1.40698 acc: 0.70020 | v_loss: 1.28728 v_acc: 0.71126 |  iteration: 9765 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1064 loss: 1.60269 acc: 0.69076 | v_loss: 1.46604 v_acc: 0.70671 |  iteration: 9766 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1065 loss: 1.30799 acc: 0.71615 | v_loss: 1.27958 v_acc: 0.71452 |  iteration: 9767 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1066 loss: 1.48042 acc: 0.70443 | v_loss: 1.43793 v_acc: 0.71647 |  iteration: 9768 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1067 loss: 1.44179 acc: 0.70736 | v_loss: 1.64496 v_acc: 0.69466 |  iteration: 9769 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1068 loss: 1.48754 acc: 0.69499 | v_loss: 1.51198 v_acc: 0.70410 |  iteration: 9770 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1069 loss: 1.47446 acc: 0.69792 | v_loss: 1.29721 v_acc: 0.72005 |  iteration: 9771 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1070 loss: 1.41292 acc: 0.69857 | v_loss: 1.37832 v_acc: 0.69987 |  iteration: 9772 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1071 loss: 1.32445 acc: 0.71517 | v_loss: 1.23291 v_acc: 0.71615 |  iteration: 9773 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1072 loss: 1.43074 acc: 0.69954 | v_loss: 1.43373 v_acc: 0.69857 |  iteration: 9774 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1073 loss: 1.51379 acc: 0.69596 | v_loss: 1.36078 v_acc: 0.71094 |  iteration: 9775 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1074 loss: 1.37248 acc: 0.71224 | v_loss: 1.35950 v_acc: 0.72949 |  iteration: 9776 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1075 loss: 1.53122 acc: 0.69271 | v_loss: 1.36004 v_acc: 0.71810 |  iteration: 9777 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1076 loss: 1.41079 acc: 0.69987 | v_loss: 1.37978 v_acc: 0.71061 |  iteration: 9778 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1077 loss: 1.54319 acc: 0.69368 | v_loss: 1.30009 v_acc: 0.72493 |  iteration: 9779 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1078 loss: 1.42801 acc: 0.70573 | v_loss: 1.30066 v_acc: 0.72038 |  iteration: 9780 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1079 loss: 1.49042 acc: 0.69954 | v_loss: 1.49788 v_acc: 0.69368 |  iteration: 9781 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1080 loss: 1.54896 acc: 0.68978 | v_loss: 1.32937 v_acc: 0.71452 |  iteration: 9782 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1081 loss: 1.49782 acc: 0.69564 | v_loss: 1.31646 v_acc: 0.71549 |  iteration: 9783 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1082 loss: 1.54140 acc: 0.69954 | v_loss: 1.30070 v_acc: 0.72201 |  iteration: 9784 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1083 loss: 1.40251 acc: 0.70215 | v_loss: 1.43339 v_acc: 0.70768 |  iteration: 9785 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1084 loss: 1.51155 acc: 0.69108 | v_loss: 1.31207 v_acc: 0.73210 |  iteration: 9786 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1085 loss: 1.44289 acc: 0.71159 | v_loss: 1.51046 v_acc: 0.71224 |  iteration: 9787 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1086 loss: 1.40854 acc: 0.70801 | v_loss: 1.30688 v_acc: 0.69596 |  iteration: 9788 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1087 loss: 1.45043 acc: 0.70508 | v_loss: 1.28913 v_acc: 0.70052 |  iteration: 9789 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1088 loss: 1.36510 acc: 0.71191 | v_loss: 1.45454 v_acc: 0.70703 |  iteration: 9790 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1089 loss: 1.48310 acc: 0.70117 | v_loss: 1.48169 v_acc: 0.70768 |  iteration: 9791 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1090 loss: 1.47590 acc: 0.69401 | v_loss: 1.53318 v_acc: 0.68978 |  iteration: 9792 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1091 loss: 1.50800 acc: 0.69922 | v_loss: 1.46475 v_acc: 0.70540 |  iteration: 9793 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1092 loss: 1.52802 acc: 0.69889 | v_loss: 1.42883 v_acc: 0.70736 |  iteration: 9794 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1093 loss: 1.41836 acc: 0.70898 | v_loss: 1.40455 v_acc: 0.70931 |  iteration: 9795 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1094 loss: 1.38774 acc: 0.71322 | v_loss: 1.41357 v_acc: 0.70703 |  iteration: 9796 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1095 loss: 1.47323 acc: 0.70605 | v_loss: 1.27682 v_acc: 0.71875 |  iteration: 9797 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1096 loss: 1.43456 acc: 0.70117 | v_loss: 1.31700 v_acc: 0.72331 |  iteration: 9798 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1097 loss: 1.36259 acc: 0.69694 | v_loss: 1.17920 v_acc: 0.71615 |  iteration: 9799 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1098 loss: 1.42293 acc: 0.70345 | v_loss: 1.34452 v_acc: 0.71126 |  iteration: 9800 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1099 loss: 1.50977 acc: 0.69824 | v_loss: 1.51562 v_acc: 0.69954 |  iteration: 9801 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1100 loss: 1.45303 acc: 0.69629 | v_loss: 1.34393 v_acc: 0.71484 |  iteration: 9802 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1101 loss: 1.41799 acc: 0.70378 | v_loss: 1.36406 v_acc: 0.70312 |  iteration: 9803 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1102 loss: 1.42323 acc: 0.70638 | v_loss: 1.25185 v_acc: 0.71680 |  iteration: 9804 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1103 loss: 1.45253 acc: 0.70703 | v_loss: 1.24135 v_acc: 0.70671 |  iteration: 9805 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1104 loss: 1.48421 acc: 0.69857 | v_loss: 1.25534 v_acc: 0.73503 |  iteration: 9806 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1105 loss: 1.42433 acc: 0.70638 | v_loss: 1.28761 v_acc: 0.72168 |  iteration: 9807 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1106 loss: 1.59445 acc: 0.69141 | v_loss: 1.33612 v_acc: 0.73145 |  iteration: 9808 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1107 loss: 1.39198 acc: 0.71224 | v_loss: 1.26480 v_acc: 0.72461 |  iteration: 9809 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1108 loss: 1.46380 acc: 0.70345 | v_loss: 1.29973 v_acc: 0.72005 |  iteration: 9810 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1109 loss: 1.34963 acc: 0.71484 | v_loss: 1.40755 v_acc: 0.71224 |  iteration: 9811 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1110 loss: 1.48848 acc: 0.69043 | v_loss: 1.37585 v_acc: 0.72038 |  iteration: 9812 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1111 loss: 1.38733 acc: 0.71419 | v_loss: 1.49113 v_acc: 0.69661 |  iteration: 9813 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1112 loss: 1.49070 acc: 0.69954 | v_loss: 1.41611 v_acc: 0.71745 |  iteration: 9814 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1113 loss: 1.31808 acc: 0.71484 | v_loss: 1.17954 v_acc: 0.74382 |  iteration: 9815 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1114 loss: 1.32099 acc: 0.71224 | v_loss: 1.26434 v_acc: 0.70280 |  iteration: 9816 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1115 loss: 1.38303 acc: 0.70410 | v_loss: 1.55098 v_acc: 0.69824 |  iteration: 9817 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1116 loss: 1.48005 acc: 0.69857 | v_loss: 1.22363 v_acc: 0.70768 |  iteration: 9818 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1117 loss: 1.41623 acc: 0.69922 | v_loss: 1.34261 v_acc: 0.71615 |  iteration: 9819 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1118 loss: 1.53098 acc: 0.68848 | v_loss: 1.38051 v_acc: 0.69368 |  iteration: 9820 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1119 loss: 1.53474 acc: 0.69564 | v_loss: 1.29958 v_acc: 0.71842 |  iteration: 9821 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1120 loss: 1.46672 acc: 0.69629 | v_loss: 1.36540 v_acc: 0.70215 |  iteration: 9822 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1121 loss: 1.43147 acc: 0.70182 | v_loss: 1.46428 v_acc: 0.72005 |  iteration: 9823 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1122 loss: 1.47730 acc: 0.69922 | v_loss: 1.32457 v_acc: 0.72786 |  iteration: 9824 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1123 loss: 1.42268 acc: 0.70280 | v_loss: 1.42971 v_acc: 0.70443 |  iteration: 9825 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1124 loss: 1.49427 acc: 0.69824 | v_loss: 1.37205 v_acc: 0.70085 |  iteration: 9826 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1125 loss: 1.43656 acc: 0.70540 | v_loss: 1.33822 v_acc: 0.70703 |  iteration: 9827 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1126 loss: 1.49252 acc: 0.70085 | v_loss: 1.54618 v_acc: 0.68880 |  iteration: 9828 teacher: 1 stage: sketch lr: 0.000446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1127 loss: 1.35480 acc: 0.70931 | v_loss: 1.31128 v_acc: 0.72103 |  iteration: 9829 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1128 loss: 1.49160 acc: 0.69824 | v_loss: 1.57238 v_acc: 0.69043 |  iteration: 9830 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1129 loss: 1.46484 acc: 0.70931 | v_loss: 1.43151 v_acc: 0.70215 |  iteration: 9831 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1130 loss: 1.39182 acc: 0.71257 | v_loss: 1.51952 v_acc: 0.68913 |  iteration: 9832 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1131 loss: 1.51165 acc: 0.69954 | v_loss: 1.39241 v_acc: 0.69759 |  iteration: 9833 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1132 loss: 1.40204 acc: 0.70443 | v_loss: 1.33091 v_acc: 0.70215 |  iteration: 9834 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1133 loss: 1.43186 acc: 0.70117 | v_loss: 1.35116 v_acc: 0.70020 |  iteration: 9835 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1134 loss: 1.42051 acc: 0.70931 | v_loss: 1.34850 v_acc: 0.71484 |  iteration: 9836 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1135 loss: 1.38316 acc: 0.71582 | v_loss: 1.57338 v_acc: 0.69108 |  iteration: 9837 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1136 loss: 1.45146 acc: 0.70508 | v_loss: 1.39518 v_acc: 0.70443 |  iteration: 9838 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1137 loss: 1.39331 acc: 0.70931 | v_loss: 1.34761 v_acc: 0.71029 |  iteration: 9839 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1138 loss: 1.43488 acc: 0.70378 | v_loss: 1.38986 v_acc: 0.71680 |  iteration: 9840 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1139 loss: 1.38395 acc: 0.70475 | v_loss: 1.27862 v_acc: 0.70573 |  iteration: 9841 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1140 loss: 1.36662 acc: 0.72103 | v_loss: 1.44422 v_acc: 0.69792 |  iteration: 9842 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1141 loss: 1.42803 acc: 0.70378 | v_loss: 1.42854 v_acc: 0.71289 |  iteration: 9843 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1142 loss: 1.62738 acc: 0.68783 | v_loss: 1.28312 v_acc: 0.71875 |  iteration: 9844 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1143 loss: 1.41308 acc: 0.70573 | v_loss: 1.26782 v_acc: 0.72754 |  iteration: 9845 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1144 loss: 1.37829 acc: 0.70280 | v_loss: 1.38526 v_acc: 0.71940 |  iteration: 9846 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1145 loss: 1.45675 acc: 0.70247 | v_loss: 1.43301 v_acc: 0.70410 |  iteration: 9847 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1146 loss: 1.32435 acc: 0.71061 | v_loss: 1.44715 v_acc: 0.70833 |  iteration: 9848 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1147 loss: 1.39572 acc: 0.70703 | v_loss: 1.22545 v_acc: 0.72591 |  iteration: 9849 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1148 loss: 1.32960 acc: 0.71224 | v_loss: 1.42187 v_acc: 0.73112 |  iteration: 9850 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1149 loss: 1.37271 acc: 0.70833 | v_loss: 1.48887 v_acc: 0.69792 |  iteration: 9851 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1150 loss: 1.52889 acc: 0.70508 | v_loss: 1.39702 v_acc: 0.72168 |  iteration: 9852 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1151 loss: 1.39234 acc: 0.70671 | v_loss: 1.26373 v_acc: 0.71810 |  iteration: 9853 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1152 loss: 1.38017 acc: 0.70410 | v_loss: 1.22075 v_acc: 0.73600 |  iteration: 9854 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1153 loss: 1.45696 acc: 0.70345 | v_loss: 1.22663 v_acc: 0.72656 |  iteration: 9855 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1154 loss: 1.41006 acc: 0.70410 | v_loss: 1.30204 v_acc: 0.70768 |  iteration: 9856 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1155 loss: 1.40636 acc: 0.70573 | v_loss: 1.46379 v_acc: 0.70052 |  iteration: 9857 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1156 loss: 1.41103 acc: 0.70703 | v_loss: 1.28558 v_acc: 0.71452 |  iteration: 9858 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1157 loss: 1.48586 acc: 0.70378 | v_loss: 1.46290 v_acc: 0.71647 |  iteration: 9859 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1158 loss: 1.46114 acc: 0.70931 | v_loss: 1.67066 v_acc: 0.69303 |  iteration: 9860 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1159 loss: 1.55115 acc: 0.69889 | v_loss: 1.50635 v_acc: 0.70410 |  iteration: 9861 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1160 loss: 1.35081 acc: 0.71745 | v_loss: 1.30165 v_acc: 0.72005 |  iteration: 9862 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1161 loss: 1.45999 acc: 0.70020 | v_loss: 1.37531 v_acc: 0.69987 |  iteration: 9863 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1162 loss: 1.50389 acc: 0.69108 | v_loss: 1.23912 v_acc: 0.71615 |  iteration: 9864 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1163 loss: 1.42675 acc: 0.70345 | v_loss: 1.42373 v_acc: 0.69857 |  iteration: 9865 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1164 loss: 1.43097 acc: 0.70931 | v_loss: 1.36224 v_acc: 0.70964 |  iteration: 9866 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1165 loss: 1.50226 acc: 0.69434 | v_loss: 1.35817 v_acc: 0.72949 |  iteration: 9867 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1166 loss: 1.51868 acc: 0.69531 | v_loss: 1.34941 v_acc: 0.71680 |  iteration: 9868 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1167 loss: 1.47160 acc: 0.69889 | v_loss: 1.37501 v_acc: 0.70508 |  iteration: 9869 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1168 loss: 1.40881 acc: 0.70508 | v_loss: 1.30681 v_acc: 0.72201 |  iteration: 9870 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1169 loss: 1.41259 acc: 0.71875 | v_loss: 1.30608 v_acc: 0.72038 |  iteration: 9871 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1170 loss: 1.41782 acc: 0.70964 | v_loss: 1.52713 v_acc: 0.69303 |  iteration: 9872 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1171 loss: 1.40553 acc: 0.70215 | v_loss: 1.32988 v_acc: 0.71159 |  iteration: 9873 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1172 loss: 1.41552 acc: 0.70345 | v_loss: 1.30040 v_acc: 0.71549 |  iteration: 9874 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1173 loss: 1.40520 acc: 0.70931 | v_loss: 1.29380 v_acc: 0.71484 |  iteration: 9875 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1174 loss: 1.41401 acc: 0.70736 | v_loss: 1.44224 v_acc: 0.70540 |  iteration: 9876 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1175 loss: 1.33910 acc: 0.70378 | v_loss: 1.31768 v_acc: 0.73047 |  iteration: 9877 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1176 loss: 1.47944 acc: 0.70150 | v_loss: 1.57912 v_acc: 0.71582 |  iteration: 9878 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1177 loss: 1.39152 acc: 0.69987 | v_loss: 1.28226 v_acc: 0.70247 |  iteration: 9879 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1178 loss: 1.46919 acc: 0.70182 | v_loss: 1.28891 v_acc: 0.70215 |  iteration: 9880 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1179 loss: 1.38502 acc: 0.70215 | v_loss: 1.46572 v_acc: 0.70312 |  iteration: 9881 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1180 loss: 1.41480 acc: 0.70410 | v_loss: 1.49087 v_acc: 0.70117 |  iteration: 9882 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1181 loss: 1.39916 acc: 0.69824 | v_loss: 1.52930 v_acc: 0.69661 |  iteration: 9883 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1182 loss: 1.36765 acc: 0.70280 | v_loss: 1.47744 v_acc: 0.70833 |  iteration: 9884 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1183 loss: 1.42333 acc: 0.70898 | v_loss: 1.41967 v_acc: 0.70410 |  iteration: 9885 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1184 loss: 1.38727 acc: 0.70736 | v_loss: 1.39722 v_acc: 0.70866 |  iteration: 9886 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1185 loss: 1.34900 acc: 0.70671 | v_loss: 1.41774 v_acc: 0.70703 |  iteration: 9887 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1186 loss: 1.36438 acc: 0.70605 | v_loss: 1.28675 v_acc: 0.71354 |  iteration: 9888 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1187 loss: 1.38154 acc: 0.70931 | v_loss: 1.31877 v_acc: 0.72461 |  iteration: 9889 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1188 loss: 1.38840 acc: 0.70573 | v_loss: 1.19453 v_acc: 0.71517 |  iteration: 9890 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1189 loss: 1.55206 acc: 0.68652 | v_loss: 1.34310 v_acc: 0.70703 |  iteration: 9891 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1190 loss: 1.36598 acc: 0.70931 | v_loss: 1.51735 v_acc: 0.69987 |  iteration: 9892 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1191 loss: 1.44090 acc: 0.69629 | v_loss: 1.36914 v_acc: 0.70833 |  iteration: 9893 teacher: 0 stage: sketch lr: 0.000444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1192 loss: 1.47564 acc: 0.69499 | v_loss: 1.38597 v_acc: 0.69727 |  iteration: 9894 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1193 loss: 1.43457 acc: 0.69922 | v_loss: 1.26584 v_acc: 0.71126 |  iteration: 9895 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1194 loss: 1.48664 acc: 0.69824 | v_loss: 1.23555 v_acc: 0.70345 |  iteration: 9896 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1195 loss: 1.50872 acc: 0.69206 | v_loss: 1.26930 v_acc: 0.73503 |  iteration: 9897 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1196 loss: 1.44406 acc: 0.70671 | v_loss: 1.27920 v_acc: 0.72233 |  iteration: 9898 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1197 loss: 1.57536 acc: 0.69434 | v_loss: 1.36344 v_acc: 0.74089 |  iteration: 9899 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1198 loss: 1.40373 acc: 0.70085 | v_loss: 1.27211 v_acc: 0.72005 |  iteration: 9900 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1199 loss: 1.46166 acc: 0.70020 | v_loss: 1.30521 v_acc: 0.71582 |  iteration: 9901 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1200 loss: 1.42586 acc: 0.70638 | v_loss: 1.41131 v_acc: 0.71224 |  iteration: 9902 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1201 loss: 1.45697 acc: 0.69889 | v_loss: 1.37462 v_acc: 0.71908 |  iteration: 9903 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1202 loss: 1.38992 acc: 0.70247 | v_loss: 1.48805 v_acc: 0.69564 |  iteration: 9904 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1203 loss: 1.53718 acc: 0.69336 | v_loss: 1.42039 v_acc: 0.71810 |  iteration: 9905 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1204 loss: 1.43825 acc: 0.70215 | v_loss: 1.18836 v_acc: 0.73796 |  iteration: 9906 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1205 loss: 1.40116 acc: 0.71354 | v_loss: 1.28425 v_acc: 0.70215 |  iteration: 9907 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1206 loss: 1.48758 acc: 0.69596 | v_loss: 1.54703 v_acc: 0.69336 |  iteration: 9908 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1207 loss: 1.39857 acc: 0.71061 | v_loss: 1.25389 v_acc: 0.70833 |  iteration: 9909 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1208 loss: 1.45721 acc: 0.70312 | v_loss: 1.33406 v_acc: 0.71094 |  iteration: 9910 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1209 loss: 1.43638 acc: 0.70150 | v_loss: 1.37693 v_acc: 0.69336 |  iteration: 9911 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1210 loss: 1.41793 acc: 0.69499 | v_loss: 1.31706 v_acc: 0.71842 |  iteration: 9912 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1211 loss: 1.49438 acc: 0.69466 | v_loss: 1.37401 v_acc: 0.70215 |  iteration: 9913 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1212 loss: 1.46709 acc: 0.70703 | v_loss: 1.45301 v_acc: 0.72005 |  iteration: 9914 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1213 loss: 1.51916 acc: 0.69889 | v_loss: 1.32117 v_acc: 0.72786 |  iteration: 9915 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1214 loss: 1.39523 acc: 0.70671 | v_loss: 1.43606 v_acc: 0.70117 |  iteration: 9916 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1215 loss: 1.43776 acc: 0.70150 | v_loss: 1.36969 v_acc: 0.69987 |  iteration: 9917 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1216 loss: 1.33188 acc: 0.70964 | v_loss: 1.34458 v_acc: 0.70964 |  iteration: 9918 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1217 loss: 1.38650 acc: 0.70605 | v_loss: 1.54482 v_acc: 0.68880 |  iteration: 9919 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1218 loss: 1.40587 acc: 0.69824 | v_loss: 1.31176 v_acc: 0.72168 |  iteration: 9920 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1219 loss: 1.35655 acc: 0.71322 | v_loss: 1.58397 v_acc: 0.68620 |  iteration: 9921 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1220 loss: 1.44200 acc: 0.70052 | v_loss: 1.43349 v_acc: 0.69987 |  iteration: 9922 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1221 loss: 1.38932 acc: 0.70605 | v_loss: 1.53126 v_acc: 0.68913 |  iteration: 9923 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1222 loss: 1.49188 acc: 0.69759 | v_loss: 1.38938 v_acc: 0.70182 |  iteration: 9924 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1223 loss: 1.46715 acc: 0.70117 | v_loss: 1.34331 v_acc: 0.70638 |  iteration: 9925 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1224 loss: 1.47752 acc: 0.70052 | v_loss: 1.33972 v_acc: 0.70410 |  iteration: 9926 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1225 loss: 1.36382 acc: 0.70508 | v_loss: 1.34354 v_acc: 0.71842 |  iteration: 9927 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1226 loss: 1.43275 acc: 0.70736 | v_loss: 1.52705 v_acc: 0.69173 |  iteration: 9928 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1227 loss: 1.41403 acc: 0.70345 | v_loss: 1.38075 v_acc: 0.70247 |  iteration: 9929 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1228 loss: 1.55438 acc: 0.68652 | v_loss: 1.35877 v_acc: 0.71126 |  iteration: 9930 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 1229 loss: 1.42882 acc: 0.69792 | v_loss: 1.38927 v_acc: 0.71484 |  iteration: 9931 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 1230 loss: 1.39484 acc: 0.71354 | v_loss: 1.28825 v_acc: 0.70215 |  iteration: 9932 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 1231 loss: 1.43771 acc: 0.70150 | v_loss: 1.42964 v_acc: 0.69434 |  iteration: 9933 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 1232 loss: 1.37974 acc: 0.70964 | v_loss: 1.42911 v_acc: 0.71452 |  iteration: 9934 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 1233 loss: 1.45248 acc: 0.70052 | v_loss: 1.29788 v_acc: 0.71647 |  iteration: 9935 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 1234 loss: 1.39397 acc: 0.71257 | v_loss: 1.26292 v_acc: 0.72526 |  iteration: 9936 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 1235 loss: 1.52933 acc: 0.69759 | v_loss: 1.37718 v_acc: 0.71647 |  iteration: 9937 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 1236 loss: 1.53742 acc: 0.69857 | v_loss: 1.42397 v_acc: 0.70052 |  iteration: 9938 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 1237 loss: 1.45758 acc: 0.70182 | v_loss: 1.42080 v_acc: 0.70312 |  iteration: 9939 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 1238 loss: 1.43866 acc: 0.70475 | v_loss: 1.24471 v_acc: 0.71419 |  iteration: 9940 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 1239 loss: 1.42143 acc: 0.70247 | v_loss: 1.38238 v_acc: 0.72819 |  iteration: 9941 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 1240 loss: 1.37453 acc: 0.70833 | v_loss: 1.46037 v_acc: 0.69792 |  iteration: 9942 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 1241 loss: 1.44274 acc: 0.70573 | v_loss: 1.38877 v_acc: 0.71842 |  iteration: 9943 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 1242 loss: 1.51445 acc: 0.70638 | v_loss: 1.27213 v_acc: 0.71810 |  iteration: 9944 teacher: 0 stage: sketch lr: 0.000443\n",
      "epoch 7 loss: 1.44669 acc: 0.70219 | v_loss: 1.37420 v_acc: 0.71006 \n",
      "epoch: 8\n",
      "__________________________________________\n",
      "batch 0 loss: 1.45592 acc: 0.70280 | v_loss: 1.42937 v_acc: 0.70540 |  iteration: 9945 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 1 loss: 1.39447 acc: 0.70996 | v_loss: 1.40670 v_acc: 0.70931 |  iteration: 9946 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 2 loss: 1.50763 acc: 0.69238 | v_loss: 1.41264 v_acc: 0.70703 |  iteration: 9947 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 3 loss: 1.55335 acc: 0.68945 | v_loss: 1.26687 v_acc: 0.71875 |  iteration: 9948 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 4 loss: 1.44255 acc: 0.70117 | v_loss: 1.31976 v_acc: 0.72331 |  iteration: 9949 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 5 loss: 1.59777 acc: 0.69043 | v_loss: 1.18617 v_acc: 0.71615 |  iteration: 9950 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 6 loss: 1.43067 acc: 0.69206 | v_loss: 1.34163 v_acc: 0.71126 |  iteration: 9951 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 7 loss: 1.39085 acc: 0.71289 | v_loss: 1.50237 v_acc: 0.69954 |  iteration: 9952 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 8 loss: 1.41310 acc: 0.70378 | v_loss: 1.34197 v_acc: 0.71289 |  iteration: 9953 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 9 loss: 1.52721 acc: 0.68945 | v_loss: 1.35290 v_acc: 0.69727 |  iteration: 9954 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 10 loss: 1.50609 acc: 0.69206 | v_loss: 1.26010 v_acc: 0.71126 |  iteration: 9955 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 11 loss: 1.42679 acc: 0.70703 | v_loss: 1.26295 v_acc: 0.70345 |  iteration: 9956 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 12 loss: 1.44706 acc: 0.70378 | v_loss: 1.23549 v_acc: 0.73503 |  iteration: 9957 teacher: 0 stage: sketch lr: 0.000443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 13 loss: 1.53403 acc: 0.69792 | v_loss: 1.27657 v_acc: 0.72168 |  iteration: 9958 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 14 loss: 1.54843 acc: 0.69434 | v_loss: 1.31987 v_acc: 0.74089 |  iteration: 9959 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 15 loss: 1.36952 acc: 0.71061 | v_loss: 1.25929 v_acc: 0.72005 |  iteration: 9960 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 16 loss: 1.54674 acc: 0.69108 | v_loss: 1.30246 v_acc: 0.71582 |  iteration: 9961 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 17 loss: 1.43229 acc: 0.70703 | v_loss: 1.41244 v_acc: 0.71224 |  iteration: 9962 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 18 loss: 1.48946 acc: 0.69661 | v_loss: 1.38849 v_acc: 0.72038 |  iteration: 9963 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 19 loss: 1.46774 acc: 0.70638 | v_loss: 1.48652 v_acc: 0.69661 |  iteration: 9964 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 20 loss: 1.56256 acc: 0.69987 | v_loss: 1.42090 v_acc: 0.71745 |  iteration: 9965 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 21 loss: 1.44411 acc: 0.69694 | v_loss: 1.18821 v_acc: 0.74382 |  iteration: 9966 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 22 loss: 1.50231 acc: 0.69889 | v_loss: 1.25216 v_acc: 0.70280 |  iteration: 9967 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 23 loss: 1.51075 acc: 0.70247 | v_loss: 1.52032 v_acc: 0.70247 |  iteration: 9968 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 24 loss: 1.38487 acc: 0.70768 | v_loss: 1.21212 v_acc: 0.70866 |  iteration: 9969 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 25 loss: 1.47298 acc: 0.69368 | v_loss: 1.33927 v_acc: 0.71159 |  iteration: 9970 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 26 loss: 1.47312 acc: 0.69759 | v_loss: 1.37035 v_acc: 0.69076 |  iteration: 9971 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 27 loss: 1.46205 acc: 0.69954 | v_loss: 1.31477 v_acc: 0.70898 |  iteration: 9972 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 28 loss: 1.40353 acc: 0.70833 | v_loss: 1.37348 v_acc: 0.69206 |  iteration: 9973 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 29 loss: 1.43443 acc: 0.70801 | v_loss: 1.45896 v_acc: 0.70931 |  iteration: 9974 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 30 loss: 1.43349 acc: 0.70540 | v_loss: 1.31643 v_acc: 0.72363 |  iteration: 9975 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 31 loss: 1.49158 acc: 0.69661 | v_loss: 1.44687 v_acc: 0.70117 |  iteration: 9976 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 32 loss: 1.52350 acc: 0.69661 | v_loss: 1.35336 v_acc: 0.70443 |  iteration: 9977 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 33 loss: 1.41911 acc: 0.71257 | v_loss: 1.35456 v_acc: 0.70410 |  iteration: 9978 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 34 loss: 1.42255 acc: 0.70540 | v_loss: 1.53495 v_acc: 0.68913 |  iteration: 9979 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 35 loss: 1.31885 acc: 0.71810 | v_loss: 1.30540 v_acc: 0.72461 |  iteration: 9980 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 36 loss: 1.37502 acc: 0.70573 | v_loss: 1.58503 v_acc: 0.69043 |  iteration: 9981 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 37 loss: 1.51368 acc: 0.69466 | v_loss: 1.43169 v_acc: 0.69954 |  iteration: 9982 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 38 loss: 1.48140 acc: 0.70215 | v_loss: 1.52773 v_acc: 0.68913 |  iteration: 9983 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 39 loss: 1.39054 acc: 0.71452 | v_loss: 1.37539 v_acc: 0.69759 |  iteration: 9984 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 40 loss: 1.37049 acc: 0.70540 | v_loss: 1.32819 v_acc: 0.70312 |  iteration: 9985 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 41 loss: 1.53445 acc: 0.69141 | v_loss: 1.33116 v_acc: 0.70410 |  iteration: 9986 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 42 loss: 1.41373 acc: 0.70378 | v_loss: 1.34064 v_acc: 0.71842 |  iteration: 9987 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 43 loss: 1.56246 acc: 0.70312 | v_loss: 1.56278 v_acc: 0.69108 |  iteration: 9988 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 44 loss: 1.39827 acc: 0.70150 | v_loss: 1.39688 v_acc: 0.71126 |  iteration: 9989 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 45 loss: 1.60035 acc: 0.68848 | v_loss: 1.34112 v_acc: 0.71061 |  iteration: 9990 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 46 loss: 1.41644 acc: 0.70085 | v_loss: 1.38732 v_acc: 0.71452 |  iteration: 9991 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 47 loss: 1.42551 acc: 0.70833 | v_loss: 1.29311 v_acc: 0.70540 |  iteration: 9992 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 48 loss: 1.47191 acc: 0.70247 | v_loss: 1.44083 v_acc: 0.69889 |  iteration: 9993 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 49 loss: 1.40670 acc: 0.70898 | v_loss: 1.41725 v_acc: 0.71615 |  iteration: 9994 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 50 loss: 1.41222 acc: 0.70215 | v_loss: 1.30440 v_acc: 0.71712 |  iteration: 9995 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 51 loss: 1.52539 acc: 0.69531 | v_loss: 1.25621 v_acc: 0.72689 |  iteration: 9996 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 52 loss: 1.40873 acc: 0.70508 | v_loss: 1.37411 v_acc: 0.71647 |  iteration: 9997 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 53 loss: 1.42344 acc: 0.70866 | v_loss: 1.43483 v_acc: 0.70052 |  iteration: 9998 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 54 loss: 1.46602 acc: 0.69759 | v_loss: 1.43886 v_acc: 0.70312 |  iteration: 9999 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 55 loss: 1.25557 acc: 0.71094 | v_loss: 1.24025 v_acc: 0.71615 |  iteration: 10000 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 56 loss: 1.47178 acc: 0.69499 | v_loss: 1.41277 v_acc: 0.72786 |  iteration: 10001 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 57 loss: 1.40602 acc: 0.70215 | v_loss: 1.49298 v_acc: 0.69759 |  iteration: 10002 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 58 loss: 1.35362 acc: 0.70898 | v_loss: 1.44054 v_acc: 0.72201 |  iteration: 10003 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 59 loss: 1.49986 acc: 0.69954 | v_loss: 1.26210 v_acc: 0.71908 |  iteration: 10004 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 60 loss: 1.47507 acc: 0.68848 | v_loss: 1.20398 v_acc: 0.73861 |  iteration: 10005 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 61 loss: 1.50235 acc: 0.69466 | v_loss: 1.21867 v_acc: 0.72331 |  iteration: 10006 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 62 loss: 1.59807 acc: 0.69010 | v_loss: 1.27263 v_acc: 0.71257 |  iteration: 10007 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 63 loss: 1.38493 acc: 0.69922 | v_loss: 1.45644 v_acc: 0.69792 |  iteration: 10008 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 64 loss: 1.46407 acc: 0.69889 | v_loss: 1.28277 v_acc: 0.70703 |  iteration: 10009 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 65 loss: 1.51907 acc: 0.69889 | v_loss: 1.43935 v_acc: 0.71289 |  iteration: 10010 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 66 loss: 1.45861 acc: 0.70345 | v_loss: 1.65626 v_acc: 0.69206 |  iteration: 10011 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 67 loss: 1.45708 acc: 0.70443 | v_loss: 1.52126 v_acc: 0.70020 |  iteration: 10012 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 68 loss: 1.45176 acc: 0.70703 | v_loss: 1.30880 v_acc: 0.72005 |  iteration: 10013 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 69 loss: 1.45536 acc: 0.70085 | v_loss: 1.38254 v_acc: 0.69987 |  iteration: 10014 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 70 loss: 1.48269 acc: 0.71029 | v_loss: 1.22833 v_acc: 0.71615 |  iteration: 10015 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 71 loss: 1.49222 acc: 0.69694 | v_loss: 1.41683 v_acc: 0.69857 |  iteration: 10016 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 72 loss: 1.42025 acc: 0.70117 | v_loss: 1.37433 v_acc: 0.71029 |  iteration: 10017 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 73 loss: 1.36579 acc: 0.72168 | v_loss: 1.35684 v_acc: 0.73014 |  iteration: 10018 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 74 loss: 1.34316 acc: 0.70898 | v_loss: 1.38258 v_acc: 0.72005 |  iteration: 10019 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 75 loss: 1.48723 acc: 0.69596 | v_loss: 1.39570 v_acc: 0.71029 |  iteration: 10020 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 76 loss: 1.37234 acc: 0.71875 | v_loss: 1.29709 v_acc: 0.72819 |  iteration: 10021 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 77 loss: 1.50729 acc: 0.69531 | v_loss: 1.30529 v_acc: 0.72005 |  iteration: 10022 teacher: 0 stage: sketch lr: 0.000441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 78 loss: 1.47886 acc: 0.69629 | v_loss: 1.51466 v_acc: 0.69043 |  iteration: 10023 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 79 loss: 1.46137 acc: 0.69401 | v_loss: 1.34889 v_acc: 0.70833 |  iteration: 10024 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 80 loss: 1.44779 acc: 0.70280 | v_loss: 1.29526 v_acc: 0.71322 |  iteration: 10025 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 81 loss: 1.41103 acc: 0.70508 | v_loss: 1.29979 v_acc: 0.72201 |  iteration: 10026 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 82 loss: 1.45368 acc: 0.70540 | v_loss: 1.42832 v_acc: 0.70768 |  iteration: 10027 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 83 loss: 1.46419 acc: 0.69238 | v_loss: 1.32625 v_acc: 0.73145 |  iteration: 10028 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 84 loss: 1.44595 acc: 0.70573 | v_loss: 1.54507 v_acc: 0.71615 |  iteration: 10029 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 85 loss: 1.40196 acc: 0.70052 | v_loss: 1.28882 v_acc: 0.69759 |  iteration: 10030 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 86 loss: 1.53275 acc: 0.69303 | v_loss: 1.28451 v_acc: 0.70605 |  iteration: 10031 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 87 loss: 1.55514 acc: 0.68587 | v_loss: 1.44046 v_acc: 0.70378 |  iteration: 10032 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 88 loss: 1.39592 acc: 0.71126 | v_loss: 1.47135 v_acc: 0.70378 |  iteration: 10033 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 89 loss: 1.40264 acc: 0.69987 | v_loss: 1.52464 v_acc: 0.68978 |  iteration: 10034 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 90 loss: 1.46843 acc: 0.70801 | v_loss: 1.47364 v_acc: 0.70638 |  iteration: 10035 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 91 loss: 1.51904 acc: 0.69336 | v_loss: 1.43620 v_acc: 0.70410 |  iteration: 10036 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 92 loss: 1.45755 acc: 0.70638 | v_loss: 1.43041 v_acc: 0.70768 |  iteration: 10037 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 93 loss: 1.49359 acc: 0.70573 | v_loss: 1.39431 v_acc: 0.70475 |  iteration: 10038 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 94 loss: 1.41756 acc: 0.71094 | v_loss: 1.25780 v_acc: 0.71354 |  iteration: 10039 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 95 loss: 1.43897 acc: 0.69824 | v_loss: 1.34448 v_acc: 0.72461 |  iteration: 10040 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 96 loss: 1.43507 acc: 0.70117 | v_loss: 1.18997 v_acc: 0.71517 |  iteration: 10041 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 97 loss: 1.54922 acc: 0.69303 | v_loss: 1.34817 v_acc: 0.70150 |  iteration: 10042 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 98 loss: 1.51372 acc: 0.69629 | v_loss: 1.50579 v_acc: 0.69727 |  iteration: 10043 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 99 loss: 1.40599 acc: 0.70833 | v_loss: 1.34870 v_acc: 0.70443 |  iteration: 10044 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 100 loss: 1.43593 acc: 0.70605 | v_loss: 1.35727 v_acc: 0.69661 |  iteration: 10045 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 101 loss: 1.47078 acc: 0.69727 | v_loss: 1.27665 v_acc: 0.70638 |  iteration: 10046 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 102 loss: 1.46422 acc: 0.70280 | v_loss: 1.28029 v_acc: 0.70378 |  iteration: 10047 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 103 loss: 1.51049 acc: 0.69336 | v_loss: 1.23358 v_acc: 0.73861 |  iteration: 10048 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 104 loss: 1.35547 acc: 0.70898 | v_loss: 1.28382 v_acc: 0.71745 |  iteration: 10049 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 105 loss: 1.48617 acc: 0.69564 | v_loss: 1.35036 v_acc: 0.74023 |  iteration: 10050 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 106 loss: 1.47341 acc: 0.69954 | v_loss: 1.26836 v_acc: 0.71973 |  iteration: 10051 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 107 loss: 1.54200 acc: 0.68099 | v_loss: 1.31440 v_acc: 0.71582 |  iteration: 10052 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 108 loss: 1.39485 acc: 0.70247 | v_loss: 1.42794 v_acc: 0.71224 |  iteration: 10053 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 109 loss: 1.42981 acc: 0.70117 | v_loss: 1.40244 v_acc: 0.72038 |  iteration: 10054 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 110 loss: 1.37847 acc: 0.70573 | v_loss: 1.49014 v_acc: 0.69661 |  iteration: 10055 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 111 loss: 1.45216 acc: 0.70410 | v_loss: 1.43247 v_acc: 0.71745 |  iteration: 10056 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 112 loss: 1.41544 acc: 0.71322 | v_loss: 1.17977 v_acc: 0.74382 |  iteration: 10057 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 113 loss: 1.33428 acc: 0.70833 | v_loss: 1.24722 v_acc: 0.70280 |  iteration: 10058 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 114 loss: 1.35033 acc: 0.70605 | v_loss: 1.51713 v_acc: 0.70280 |  iteration: 10059 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 115 loss: 1.46954 acc: 0.69564 | v_loss: 1.21300 v_acc: 0.71647 |  iteration: 10060 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 116 loss: 1.44924 acc: 0.70345 | v_loss: 1.33285 v_acc: 0.71191 |  iteration: 10061 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 117 loss: 1.53285 acc: 0.69368 | v_loss: 1.36788 v_acc: 0.69076 |  iteration: 10062 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 118 loss: 1.35794 acc: 0.70866 | v_loss: 1.30718 v_acc: 0.70898 |  iteration: 10063 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 119 loss: 1.49779 acc: 0.69336 | v_loss: 1.38126 v_acc: 0.69206 |  iteration: 10064 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 120 loss: 1.46052 acc: 0.70085 | v_loss: 1.47490 v_acc: 0.70931 |  iteration: 10065 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 121 loss: 1.37665 acc: 0.70020 | v_loss: 1.33377 v_acc: 0.72331 |  iteration: 10066 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 122 loss: 1.41173 acc: 0.71582 | v_loss: 1.45064 v_acc: 0.70215 |  iteration: 10067 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 123 loss: 1.40436 acc: 0.70671 | v_loss: 1.35661 v_acc: 0.69922 |  iteration: 10068 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 124 loss: 1.35974 acc: 0.70964 | v_loss: 1.32700 v_acc: 0.70898 |  iteration: 10069 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 125 loss: 1.47811 acc: 0.69922 | v_loss: 1.55595 v_acc: 0.68815 |  iteration: 10070 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 126 loss: 1.38117 acc: 0.70443 | v_loss: 1.30100 v_acc: 0.72005 |  iteration: 10071 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 127 loss: 1.50650 acc: 0.69303 | v_loss: 1.59547 v_acc: 0.68424 |  iteration: 10072 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 128 loss: 1.46102 acc: 0.70052 | v_loss: 1.47927 v_acc: 0.69661 |  iteration: 10073 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 129 loss: 1.48540 acc: 0.69303 | v_loss: 1.53536 v_acc: 0.69238 |  iteration: 10074 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 130 loss: 1.44098 acc: 0.70085 | v_loss: 1.37663 v_acc: 0.70020 |  iteration: 10075 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 131 loss: 1.48610 acc: 0.69694 | v_loss: 1.32655 v_acc: 0.70052 |  iteration: 10076 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 132 loss: 1.36522 acc: 0.70508 | v_loss: 1.35383 v_acc: 0.69661 |  iteration: 10077 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 133 loss: 1.35220 acc: 0.70898 | v_loss: 1.33914 v_acc: 0.71354 |  iteration: 10078 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 134 loss: 1.48018 acc: 0.70345 | v_loss: 1.56699 v_acc: 0.68457 |  iteration: 10079 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 135 loss: 1.38681 acc: 0.70410 | v_loss: 1.39397 v_acc: 0.70052 |  iteration: 10080 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 136 loss: 1.53032 acc: 0.69303 | v_loss: 1.37461 v_acc: 0.71322 |  iteration: 10081 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 137 loss: 1.41582 acc: 0.69661 | v_loss: 1.37729 v_acc: 0.71647 |  iteration: 10082 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 138 loss: 1.45436 acc: 0.70215 | v_loss: 1.28950 v_acc: 0.70052 |  iteration: 10083 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 139 loss: 1.54871 acc: 0.70020 | v_loss: 1.43893 v_acc: 0.69434 |  iteration: 10084 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 140 loss: 1.47567 acc: 0.70280 | v_loss: 1.42471 v_acc: 0.71419 |  iteration: 10085 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 141 loss: 1.47212 acc: 0.69987 | v_loss: 1.44410 v_acc: 0.71159 |  iteration: 10086 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 142 loss: 1.49982 acc: 0.69889 | v_loss: 1.64458 v_acc: 0.70443 |  iteration: 10087 teacher: 1 stage: sketch lr: 0.000440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 143 loss: 1.63121 acc: 0.69173 | v_loss: 1.49224 v_acc: 0.71354 |  iteration: 10088 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 144 loss: 1.46492 acc: 0.71029 | v_loss: 1.44584 v_acc: 0.70378 |  iteration: 10089 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 145 loss: 1.59469 acc: 0.67773 | v_loss: 1.42678 v_acc: 0.70475 |  iteration: 10090 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 146 loss: 1.41804 acc: 0.70410 | v_loss: 1.24011 v_acc: 0.71484 |  iteration: 10091 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 147 loss: 1.43458 acc: 0.69987 | v_loss: 1.40267 v_acc: 0.72884 |  iteration: 10092 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 148 loss: 1.49073 acc: 0.69596 | v_loss: 1.47730 v_acc: 0.69824 |  iteration: 10093 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 149 loss: 1.42195 acc: 0.70312 | v_loss: 1.42980 v_acc: 0.72005 |  iteration: 10094 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 150 loss: 1.38636 acc: 0.70020 | v_loss: 1.26066 v_acc: 0.71908 |  iteration: 10095 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 151 loss: 1.34727 acc: 0.70964 | v_loss: 1.20633 v_acc: 0.73438 |  iteration: 10096 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 152 loss: 1.49996 acc: 0.70671 | v_loss: 1.21764 v_acc: 0.72949 |  iteration: 10097 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 153 loss: 1.47522 acc: 0.69499 | v_loss: 1.30404 v_acc: 0.70703 |  iteration: 10098 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 154 loss: 1.42528 acc: 0.69792 | v_loss: 1.46467 v_acc: 0.70020 |  iteration: 10099 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 155 loss: 1.56778 acc: 0.69173 | v_loss: 1.29723 v_acc: 0.71354 |  iteration: 10100 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 156 loss: 1.50321 acc: 0.70931 | v_loss: 1.52695 v_acc: 0.70410 |  iteration: 10101 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 157 loss: 1.52325 acc: 0.69238 | v_loss: 1.71807 v_acc: 0.68978 |  iteration: 10102 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 158 loss: 1.44414 acc: 0.70638 | v_loss: 1.55889 v_acc: 0.69564 |  iteration: 10103 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 159 loss: 1.50506 acc: 0.70345 | v_loss: 1.31438 v_acc: 0.72103 |  iteration: 10104 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 160 loss: 1.53100 acc: 0.69499 | v_loss: 1.37196 v_acc: 0.70085 |  iteration: 10105 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 161 loss: 1.34976 acc: 0.71712 | v_loss: 1.23161 v_acc: 0.71615 |  iteration: 10106 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 162 loss: 1.39753 acc: 0.71322 | v_loss: 1.42815 v_acc: 0.69857 |  iteration: 10107 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 163 loss: 1.49109 acc: 0.69401 | v_loss: 1.36618 v_acc: 0.70964 |  iteration: 10108 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 164 loss: 1.45110 acc: 0.70410 | v_loss: 1.36360 v_acc: 0.72949 |  iteration: 10109 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 165 loss: 1.44547 acc: 0.70085 | v_loss: 1.36715 v_acc: 0.71680 |  iteration: 10110 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 166 loss: 1.47667 acc: 0.70280 | v_loss: 1.38397 v_acc: 0.70410 |  iteration: 10111 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 167 loss: 1.41908 acc: 0.69694 | v_loss: 1.29843 v_acc: 0.72233 |  iteration: 10112 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 168 loss: 1.43581 acc: 0.71094 | v_loss: 1.30661 v_acc: 0.72038 |  iteration: 10113 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 169 loss: 1.36250 acc: 0.70540 | v_loss: 1.49585 v_acc: 0.69368 |  iteration: 10114 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 170 loss: 1.47740 acc: 0.70117 | v_loss: 1.33522 v_acc: 0.71452 |  iteration: 10115 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 171 loss: 1.53804 acc: 0.69401 | v_loss: 1.30852 v_acc: 0.71777 |  iteration: 10116 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 172 loss: 1.45716 acc: 0.69564 | v_loss: 1.30159 v_acc: 0.71484 |  iteration: 10117 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 173 loss: 1.39719 acc: 0.71126 | v_loss: 1.44586 v_acc: 0.70540 |  iteration: 10118 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 174 loss: 1.42730 acc: 0.70996 | v_loss: 1.31106 v_acc: 0.73242 |  iteration: 10119 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 175 loss: 1.38296 acc: 0.70768 | v_loss: 1.53130 v_acc: 0.71322 |  iteration: 10120 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 176 loss: 1.46168 acc: 0.70703 | v_loss: 1.30292 v_acc: 0.69531 |  iteration: 10121 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 177 loss: 1.37415 acc: 0.71452 | v_loss: 1.29006 v_acc: 0.70117 |  iteration: 10122 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 178 loss: 1.43133 acc: 0.71191 | v_loss: 1.44611 v_acc: 0.70508 |  iteration: 10123 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 179 loss: 1.50158 acc: 0.70573 | v_loss: 1.47343 v_acc: 0.70573 |  iteration: 10124 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 180 loss: 1.49053 acc: 0.69759 | v_loss: 1.51985 v_acc: 0.68978 |  iteration: 10125 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 181 loss: 1.44394 acc: 0.69922 | v_loss: 1.46933 v_acc: 0.70540 |  iteration: 10126 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 182 loss: 1.52850 acc: 0.69954 | v_loss: 1.42972 v_acc: 0.70540 |  iteration: 10127 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 183 loss: 1.48730 acc: 0.70768 | v_loss: 1.40863 v_acc: 0.70475 |  iteration: 10128 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 184 loss: 1.41597 acc: 0.70703 | v_loss: 1.43636 v_acc: 0.70312 |  iteration: 10129 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 185 loss: 1.56870 acc: 0.69564 | v_loss: 1.29104 v_acc: 0.71257 |  iteration: 10130 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 186 loss: 1.39092 acc: 0.70312 | v_loss: 1.31995 v_acc: 0.72493 |  iteration: 10131 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 187 loss: 1.39952 acc: 0.70540 | v_loss: 1.21159 v_acc: 0.70996 |  iteration: 10132 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 188 loss: 1.51684 acc: 0.69206 | v_loss: 1.35364 v_acc: 0.70703 |  iteration: 10133 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 189 loss: 1.50168 acc: 0.70247 | v_loss: 1.49739 v_acc: 0.69987 |  iteration: 10134 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 190 loss: 1.45516 acc: 0.70247 | v_loss: 1.33796 v_acc: 0.70573 |  iteration: 10135 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 191 loss: 1.47981 acc: 0.69857 | v_loss: 1.37513 v_acc: 0.69368 |  iteration: 10136 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 192 loss: 1.48606 acc: 0.69141 | v_loss: 1.25233 v_acc: 0.70573 |  iteration: 10137 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 193 loss: 1.45812 acc: 0.70931 | v_loss: 1.26575 v_acc: 0.70215 |  iteration: 10138 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 194 loss: 1.41738 acc: 0.70736 | v_loss: 1.26497 v_acc: 0.73340 |  iteration: 10139 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 195 loss: 1.48548 acc: 0.69108 | v_loss: 1.28457 v_acc: 0.71647 |  iteration: 10140 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 196 loss: 1.45034 acc: 0.70475 | v_loss: 1.36225 v_acc: 0.74089 |  iteration: 10141 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 197 loss: 1.42155 acc: 0.69922 | v_loss: 1.27465 v_acc: 0.72005 |  iteration: 10142 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 198 loss: 1.48152 acc: 0.69922 | v_loss: 1.30660 v_acc: 0.71582 |  iteration: 10143 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 199 loss: 1.43070 acc: 0.70508 | v_loss: 1.41362 v_acc: 0.71224 |  iteration: 10144 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 200 loss: 1.34578 acc: 0.71191 | v_loss: 1.39588 v_acc: 0.72103 |  iteration: 10145 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 201 loss: 1.52676 acc: 0.69954 | v_loss: 1.49353 v_acc: 0.69661 |  iteration: 10146 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 202 loss: 1.38964 acc: 0.71126 | v_loss: 1.40606 v_acc: 0.71745 |  iteration: 10147 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 203 loss: 1.54206 acc: 0.69108 | v_loss: 1.17885 v_acc: 0.74382 |  iteration: 10148 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 204 loss: 1.51652 acc: 0.69531 | v_loss: 1.26881 v_acc: 0.70280 |  iteration: 10149 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 205 loss: 1.54115 acc: 0.69954 | v_loss: 1.51578 v_acc: 0.70280 |  iteration: 10150 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 206 loss: 1.39755 acc: 0.70898 | v_loss: 1.25059 v_acc: 0.71647 |  iteration: 10151 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 207 loss: 1.37782 acc: 0.71159 | v_loss: 1.32642 v_acc: 0.71680 |  iteration: 10152 teacher: 1 stage: sketch lr: 0.000439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 208 loss: 1.37589 acc: 0.71322 | v_loss: 1.37086 v_acc: 0.69076 |  iteration: 10153 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 209 loss: 1.43283 acc: 0.70475 | v_loss: 1.31757 v_acc: 0.70898 |  iteration: 10154 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 210 loss: 1.35279 acc: 0.70312 | v_loss: 1.37344 v_acc: 0.69206 |  iteration: 10155 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 211 loss: 1.44193 acc: 0.70768 | v_loss: 1.47321 v_acc: 0.70931 |  iteration: 10156 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 212 loss: 1.49283 acc: 0.69857 | v_loss: 1.31822 v_acc: 0.72689 |  iteration: 10157 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 213 loss: 1.38363 acc: 0.71094 | v_loss: 1.44305 v_acc: 0.70540 |  iteration: 10158 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 214 loss: 1.48881 acc: 0.70443 | v_loss: 1.39057 v_acc: 0.69889 |  iteration: 10159 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 215 loss: 1.40867 acc: 0.70801 | v_loss: 1.31912 v_acc: 0.70801 |  iteration: 10160 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 216 loss: 1.33855 acc: 0.70540 | v_loss: 1.55562 v_acc: 0.68685 |  iteration: 10161 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 217 loss: 1.47203 acc: 0.70573 | v_loss: 1.29691 v_acc: 0.72298 |  iteration: 10162 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 218 loss: 1.48187 acc: 0.70117 | v_loss: 1.60287 v_acc: 0.68262 |  iteration: 10163 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 219 loss: 1.44586 acc: 0.70638 | v_loss: 1.46467 v_acc: 0.69629 |  iteration: 10164 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 220 loss: 1.38920 acc: 0.69987 | v_loss: 1.51723 v_acc: 0.69076 |  iteration: 10165 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 221 loss: 1.52715 acc: 0.68880 | v_loss: 1.38131 v_acc: 0.69824 |  iteration: 10166 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 222 loss: 1.45298 acc: 0.69824 | v_loss: 1.32055 v_acc: 0.70215 |  iteration: 10167 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 223 loss: 1.48710 acc: 0.70443 | v_loss: 1.34599 v_acc: 0.69889 |  iteration: 10168 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 224 loss: 1.46393 acc: 0.70475 | v_loss: 1.34146 v_acc: 0.71419 |  iteration: 10169 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 225 loss: 1.52325 acc: 0.69499 | v_loss: 1.53845 v_acc: 0.69173 |  iteration: 10170 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 226 loss: 1.45821 acc: 0.70085 | v_loss: 1.40361 v_acc: 0.70247 |  iteration: 10171 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 227 loss: 1.47148 acc: 0.69466 | v_loss: 1.34782 v_acc: 0.71126 |  iteration: 10172 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 228 loss: 1.46088 acc: 0.69596 | v_loss: 1.38509 v_acc: 0.71810 |  iteration: 10173 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 229 loss: 1.46708 acc: 0.70117 | v_loss: 1.28642 v_acc: 0.70540 |  iteration: 10174 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 230 loss: 1.46151 acc: 0.70638 | v_loss: 1.43206 v_acc: 0.69954 |  iteration: 10175 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 231 loss: 1.39964 acc: 0.70345 | v_loss: 1.42143 v_acc: 0.71549 |  iteration: 10176 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 232 loss: 1.34465 acc: 0.71745 | v_loss: 1.28756 v_acc: 0.72266 |  iteration: 10177 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 233 loss: 1.48038 acc: 0.70215 | v_loss: 1.25537 v_acc: 0.72526 |  iteration: 10178 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 234 loss: 1.29541 acc: 0.70345 | v_loss: 1.39006 v_acc: 0.71745 |  iteration: 10179 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 235 loss: 1.34691 acc: 0.71615 | v_loss: 1.42226 v_acc: 0.70410 |  iteration: 10180 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 236 loss: 1.43728 acc: 0.69629 | v_loss: 1.43940 v_acc: 0.70833 |  iteration: 10181 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 237 loss: 1.40405 acc: 0.70508 | v_loss: 1.22186 v_acc: 0.72363 |  iteration: 10182 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 238 loss: 1.54765 acc: 0.69206 | v_loss: 1.39521 v_acc: 0.73177 |  iteration: 10183 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 239 loss: 1.41405 acc: 0.70020 | v_loss: 1.48453 v_acc: 0.69824 |  iteration: 10184 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 240 loss: 1.46998 acc: 0.70964 | v_loss: 1.43101 v_acc: 0.72266 |  iteration: 10185 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 241 loss: 1.45214 acc: 0.69759 | v_loss: 1.25834 v_acc: 0.71777 |  iteration: 10186 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 242 loss: 1.45811 acc: 0.69564 | v_loss: 1.21930 v_acc: 0.72852 |  iteration: 10187 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 243 loss: 1.45773 acc: 0.70540 | v_loss: 1.22436 v_acc: 0.72331 |  iteration: 10188 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 244 loss: 1.45996 acc: 0.70247 | v_loss: 1.30740 v_acc: 0.70443 |  iteration: 10189 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 245 loss: 1.41970 acc: 0.70345 | v_loss: 1.47465 v_acc: 0.69466 |  iteration: 10190 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 246 loss: 1.49668 acc: 0.69043 | v_loss: 1.28116 v_acc: 0.71484 |  iteration: 10191 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 247 loss: 1.46264 acc: 0.69727 | v_loss: 1.43026 v_acc: 0.72949 |  iteration: 10192 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 248 loss: 1.39114 acc: 0.70703 | v_loss: 1.66135 v_acc: 0.69499 |  iteration: 10193 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 249 loss: 1.47205 acc: 0.69499 | v_loss: 1.52117 v_acc: 0.70085 |  iteration: 10194 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 250 loss: 1.60579 acc: 0.68978 | v_loss: 1.29898 v_acc: 0.72591 |  iteration: 10195 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 251 loss: 1.46063 acc: 0.70378 | v_loss: 1.37451 v_acc: 0.70345 |  iteration: 10196 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 252 loss: 1.52589 acc: 0.68978 | v_loss: 1.22124 v_acc: 0.71842 |  iteration: 10197 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 253 loss: 1.52790 acc: 0.68392 | v_loss: 1.41975 v_acc: 0.70247 |  iteration: 10198 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 254 loss: 1.39497 acc: 0.70573 | v_loss: 1.35938 v_acc: 0.70703 |  iteration: 10199 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 255 loss: 1.44427 acc: 0.70605 | v_loss: 1.35374 v_acc: 0.72949 |  iteration: 10200 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 256 loss: 1.37322 acc: 0.70866 | v_loss: 1.36511 v_acc: 0.72005 |  iteration: 10201 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 257 loss: 1.44046 acc: 0.71615 | v_loss: 1.38313 v_acc: 0.70866 |  iteration: 10202 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 258 loss: 1.43648 acc: 0.70443 | v_loss: 1.30034 v_acc: 0.72201 |  iteration: 10203 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 259 loss: 1.46951 acc: 0.69792 | v_loss: 1.31289 v_acc: 0.72005 |  iteration: 10204 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 260 loss: 1.45834 acc: 0.69922 | v_loss: 1.49856 v_acc: 0.69043 |  iteration: 10205 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 261 loss: 1.34794 acc: 0.71094 | v_loss: 1.34038 v_acc: 0.70833 |  iteration: 10206 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 262 loss: 1.49933 acc: 0.70150 | v_loss: 1.29107 v_acc: 0.71582 |  iteration: 10207 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 263 loss: 1.38272 acc: 0.70573 | v_loss: 1.29058 v_acc: 0.72201 |  iteration: 10208 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 264 loss: 1.46561 acc: 0.69499 | v_loss: 1.43080 v_acc: 0.70768 |  iteration: 10209 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 265 loss: 1.41900 acc: 0.70345 | v_loss: 1.32145 v_acc: 0.73210 |  iteration: 10210 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 266 loss: 1.40607 acc: 0.70215 | v_loss: 1.55981 v_acc: 0.71615 |  iteration: 10211 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 267 loss: 1.42375 acc: 0.71029 | v_loss: 1.27437 v_acc: 0.70150 |  iteration: 10212 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 268 loss: 1.46710 acc: 0.70638 | v_loss: 1.27314 v_acc: 0.70833 |  iteration: 10213 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 269 loss: 1.48840 acc: 0.69661 | v_loss: 1.43447 v_acc: 0.70540 |  iteration: 10214 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 270 loss: 1.41659 acc: 0.70801 | v_loss: 1.46328 v_acc: 0.70150 |  iteration: 10215 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 271 loss: 1.41817 acc: 0.71224 | v_loss: 1.49999 v_acc: 0.69368 |  iteration: 10216 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 272 loss: 1.45627 acc: 0.69694 | v_loss: 1.47675 v_acc: 0.70833 |  iteration: 10217 teacher: 1 stage: sketch lr: 0.000437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 273 loss: 1.41538 acc: 0.70638 | v_loss: 1.42722 v_acc: 0.70085 |  iteration: 10218 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 274 loss: 1.47980 acc: 0.71257 | v_loss: 1.40141 v_acc: 0.70931 |  iteration: 10219 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 275 loss: 1.43386 acc: 0.70052 | v_loss: 1.40795 v_acc: 0.70703 |  iteration: 10220 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 276 loss: 1.40378 acc: 0.69987 | v_loss: 1.26622 v_acc: 0.71875 |  iteration: 10221 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 277 loss: 1.43409 acc: 0.70866 | v_loss: 1.32596 v_acc: 0.72331 |  iteration: 10222 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 278 loss: 1.47442 acc: 0.70312 | v_loss: 1.19367 v_acc: 0.71517 |  iteration: 10223 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 279 loss: 1.41083 acc: 0.70573 | v_loss: 1.35249 v_acc: 0.70312 |  iteration: 10224 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 280 loss: 1.45010 acc: 0.71159 | v_loss: 1.51300 v_acc: 0.70117 |  iteration: 10225 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 281 loss: 1.50688 acc: 0.70052 | v_loss: 1.36841 v_acc: 0.70540 |  iteration: 10226 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 282 loss: 1.47226 acc: 0.70736 | v_loss: 1.37839 v_acc: 0.69368 |  iteration: 10227 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 283 loss: 1.52253 acc: 0.70085 | v_loss: 1.27079 v_acc: 0.70573 |  iteration: 10228 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 284 loss: 1.39672 acc: 0.70182 | v_loss: 1.28853 v_acc: 0.70215 |  iteration: 10229 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 285 loss: 1.53931 acc: 0.69401 | v_loss: 1.23044 v_acc: 0.73340 |  iteration: 10230 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 286 loss: 1.46122 acc: 0.69661 | v_loss: 1.29417 v_acc: 0.71647 |  iteration: 10231 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 287 loss: 1.40519 acc: 0.70443 | v_loss: 1.32858 v_acc: 0.74089 |  iteration: 10232 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 288 loss: 1.49658 acc: 0.70020 | v_loss: 1.26754 v_acc: 0.72005 |  iteration: 10233 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 289 loss: 1.55693 acc: 0.69336 | v_loss: 1.29772 v_acc: 0.71582 |  iteration: 10234 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 290 loss: 1.47818 acc: 0.71094 | v_loss: 1.41050 v_acc: 0.71224 |  iteration: 10235 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 291 loss: 1.38431 acc: 0.70801 | v_loss: 1.38921 v_acc: 0.72038 |  iteration: 10236 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 292 loss: 1.48071 acc: 0.70215 | v_loss: 1.49332 v_acc: 0.69661 |  iteration: 10237 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 293 loss: 1.47841 acc: 0.70312 | v_loss: 1.45694 v_acc: 0.71745 |  iteration: 10238 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 294 loss: 1.40354 acc: 0.70703 | v_loss: 1.19629 v_acc: 0.74382 |  iteration: 10239 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 295 loss: 1.43131 acc: 0.71029 | v_loss: 1.27088 v_acc: 0.70280 |  iteration: 10240 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 296 loss: 1.44024 acc: 0.71061 | v_loss: 1.53623 v_acc: 0.70280 |  iteration: 10241 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 297 loss: 1.50825 acc: 0.69759 | v_loss: 1.22105 v_acc: 0.70671 |  iteration: 10242 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 298 loss: 1.41751 acc: 0.70410 | v_loss: 1.33322 v_acc: 0.71257 |  iteration: 10243 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 299 loss: 1.43091 acc: 0.70605 | v_loss: 1.36889 v_acc: 0.69368 |  iteration: 10244 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 300 loss: 1.48552 acc: 0.70703 | v_loss: 1.31806 v_acc: 0.71842 |  iteration: 10245 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 301 loss: 1.40667 acc: 0.70996 | v_loss: 1.39666 v_acc: 0.70020 |  iteration: 10246 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 302 loss: 1.52726 acc: 0.69206 | v_loss: 1.44868 v_acc: 0.71777 |  iteration: 10247 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 303 loss: 1.40747 acc: 0.70312 | v_loss: 1.33668 v_acc: 0.72624 |  iteration: 10248 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 304 loss: 1.42663 acc: 0.70605 | v_loss: 1.42452 v_acc: 0.70117 |  iteration: 10249 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 305 loss: 1.45146 acc: 0.70703 | v_loss: 1.38379 v_acc: 0.70085 |  iteration: 10250 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 306 loss: 1.56626 acc: 0.69336 | v_loss: 1.34123 v_acc: 0.70703 |  iteration: 10251 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 307 loss: 1.48050 acc: 0.70052 | v_loss: 1.54961 v_acc: 0.68685 |  iteration: 10252 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 308 loss: 1.44294 acc: 0.69238 | v_loss: 1.30398 v_acc: 0.72298 |  iteration: 10253 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 309 loss: 1.42515 acc: 0.70475 | v_loss: 1.59650 v_acc: 0.68359 |  iteration: 10254 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 310 loss: 1.40358 acc: 0.70898 | v_loss: 1.45326 v_acc: 0.69727 |  iteration: 10255 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 311 loss: 1.37250 acc: 0.70573 | v_loss: 1.52373 v_acc: 0.69271 |  iteration: 10256 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 312 loss: 1.44225 acc: 0.70215 | v_loss: 1.38211 v_acc: 0.69922 |  iteration: 10257 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 313 loss: 1.44509 acc: 0.70475 | v_loss: 1.33174 v_acc: 0.70638 |  iteration: 10258 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 314 loss: 1.45890 acc: 0.69922 | v_loss: 1.33258 v_acc: 0.70410 |  iteration: 10259 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 315 loss: 1.49460 acc: 0.69238 | v_loss: 1.34128 v_acc: 0.71842 |  iteration: 10260 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 316 loss: 1.61694 acc: 0.68913 | v_loss: 1.55443 v_acc: 0.69108 |  iteration: 10261 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 317 loss: 1.42688 acc: 0.69499 | v_loss: 1.38447 v_acc: 0.70443 |  iteration: 10262 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 318 loss: 1.33509 acc: 0.70801 | v_loss: 1.36877 v_acc: 0.71126 |  iteration: 10263 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 319 loss: 1.40380 acc: 0.70866 | v_loss: 1.38847 v_acc: 0.71810 |  iteration: 10264 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 320 loss: 1.38134 acc: 0.69857 | v_loss: 1.28171 v_acc: 0.70215 |  iteration: 10265 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 321 loss: 1.30708 acc: 0.71615 | v_loss: 1.43287 v_acc: 0.69434 |  iteration: 10266 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 322 loss: 1.38159 acc: 0.70671 | v_loss: 1.44873 v_acc: 0.71452 |  iteration: 10267 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 323 loss: 1.43710 acc: 0.70443 | v_loss: 1.30973 v_acc: 0.71647 |  iteration: 10268 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 324 loss: 1.37155 acc: 0.70378 | v_loss: 1.28351 v_acc: 0.72526 |  iteration: 10269 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 325 loss: 1.43170 acc: 0.70573 | v_loss: 1.38124 v_acc: 0.71940 |  iteration: 10270 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 326 loss: 1.37993 acc: 0.71061 | v_loss: 1.43711 v_acc: 0.70410 |  iteration: 10271 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 327 loss: 1.53089 acc: 0.69792 | v_loss: 1.43873 v_acc: 0.70833 |  iteration: 10272 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 328 loss: 1.45881 acc: 0.69368 | v_loss: 1.22756 v_acc: 0.72591 |  iteration: 10273 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 329 loss: 1.42304 acc: 0.70443 | v_loss: 1.39573 v_acc: 0.73112 |  iteration: 10274 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 330 loss: 1.38836 acc: 0.71549 | v_loss: 1.47334 v_acc: 0.69727 |  iteration: 10275 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 331 loss: 1.43654 acc: 0.70345 | v_loss: 1.41396 v_acc: 0.73145 |  iteration: 10276 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 332 loss: 1.45497 acc: 0.69661 | v_loss: 1.26453 v_acc: 0.71484 |  iteration: 10277 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 333 loss: 1.43833 acc: 0.70768 | v_loss: 1.22657 v_acc: 0.72852 |  iteration: 10278 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 334 loss: 1.40784 acc: 0.69596 | v_loss: 1.22292 v_acc: 0.72331 |  iteration: 10279 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 335 loss: 1.47866 acc: 0.69238 | v_loss: 1.29389 v_acc: 0.70703 |  iteration: 10280 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 336 loss: 1.40260 acc: 0.69824 | v_loss: 1.44605 v_acc: 0.69466 |  iteration: 10281 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 337 loss: 1.35798 acc: 0.71647 | v_loss: 1.28427 v_acc: 0.71484 |  iteration: 10282 teacher: 1 stage: sketch lr: 0.000436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 338 loss: 1.49148 acc: 0.69727 | v_loss: 1.43578 v_acc: 0.72949 |  iteration: 10283 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 339 loss: 1.51207 acc: 0.69987 | v_loss: 1.64010 v_acc: 0.69466 |  iteration: 10284 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 340 loss: 1.43804 acc: 0.70378 | v_loss: 1.50808 v_acc: 0.70410 |  iteration: 10285 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 341 loss: 1.46655 acc: 0.70247 | v_loss: 1.29719 v_acc: 0.72005 |  iteration: 10286 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 342 loss: 1.43512 acc: 0.70378 | v_loss: 1.37235 v_acc: 0.70410 |  iteration: 10287 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 343 loss: 1.40824 acc: 0.69889 | v_loss: 1.22290 v_acc: 0.71973 |  iteration: 10288 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 344 loss: 1.55319 acc: 0.69661 | v_loss: 1.42197 v_acc: 0.70378 |  iteration: 10289 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 345 loss: 1.47066 acc: 0.70378 | v_loss: 1.36447 v_acc: 0.71810 |  iteration: 10290 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 346 loss: 1.43244 acc: 0.70247 | v_loss: 1.36311 v_acc: 0.73014 |  iteration: 10291 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 347 loss: 1.44072 acc: 0.69043 | v_loss: 1.36734 v_acc: 0.71973 |  iteration: 10292 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 348 loss: 1.44529 acc: 0.69694 | v_loss: 1.36926 v_acc: 0.70508 |  iteration: 10293 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 349 loss: 1.38413 acc: 0.70964 | v_loss: 1.29375 v_acc: 0.72201 |  iteration: 10294 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 350 loss: 1.38474 acc: 0.70410 | v_loss: 1.30305 v_acc: 0.72005 |  iteration: 10295 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 351 loss: 1.39300 acc: 0.69564 | v_loss: 1.49494 v_acc: 0.69238 |  iteration: 10296 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 352 loss: 1.57326 acc: 0.69206 | v_loss: 1.33723 v_acc: 0.71159 |  iteration: 10297 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 353 loss: 1.42116 acc: 0.69987 | v_loss: 1.29553 v_acc: 0.71549 |  iteration: 10298 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 354 loss: 1.40874 acc: 0.70052 | v_loss: 1.28924 v_acc: 0.71484 |  iteration: 10299 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 355 loss: 1.44889 acc: 0.69824 | v_loss: 1.43780 v_acc: 0.70540 |  iteration: 10300 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 356 loss: 1.47617 acc: 0.70866 | v_loss: 1.31551 v_acc: 0.73047 |  iteration: 10301 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 357 loss: 1.39401 acc: 0.70540 | v_loss: 1.55777 v_acc: 0.71582 |  iteration: 10302 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 358 loss: 1.34231 acc: 0.70540 | v_loss: 1.28126 v_acc: 0.70052 |  iteration: 10303 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 359 loss: 1.41436 acc: 0.70833 | v_loss: 1.28364 v_acc: 0.70378 |  iteration: 10304 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 360 loss: 1.50870 acc: 0.70182 | v_loss: 1.44453 v_acc: 0.70475 |  iteration: 10305 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 361 loss: 1.34773 acc: 0.70866 | v_loss: 1.47451 v_acc: 0.70312 |  iteration: 10306 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 362 loss: 1.35924 acc: 0.70638 | v_loss: 1.52465 v_acc: 0.68880 |  iteration: 10307 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 363 loss: 1.40640 acc: 0.70605 | v_loss: 1.47206 v_acc: 0.70671 |  iteration: 10308 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 364 loss: 1.42459 acc: 0.70768 | v_loss: 1.43971 v_acc: 0.70540 |  iteration: 10309 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 365 loss: 1.37820 acc: 0.70638 | v_loss: 1.42186 v_acc: 0.70475 |  iteration: 10310 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 366 loss: 1.39037 acc: 0.70378 | v_loss: 1.41152 v_acc: 0.70312 |  iteration: 10311 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 367 loss: 1.50823 acc: 0.68945 | v_loss: 1.26513 v_acc: 0.71257 |  iteration: 10312 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 368 loss: 1.33389 acc: 0.71680 | v_loss: 1.32779 v_acc: 0.72493 |  iteration: 10313 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 369 loss: 1.45073 acc: 0.70443 | v_loss: 1.17685 v_acc: 0.70768 |  iteration: 10314 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 370 loss: 1.45239 acc: 0.69727 | v_loss: 1.35244 v_acc: 0.70150 |  iteration: 10315 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 371 loss: 1.40589 acc: 0.70280 | v_loss: 1.49576 v_acc: 0.69987 |  iteration: 10316 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 372 loss: 1.35534 acc: 0.70931 | v_loss: 1.32272 v_acc: 0.70540 |  iteration: 10317 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 373 loss: 1.40638 acc: 0.70475 | v_loss: 1.36696 v_acc: 0.69368 |  iteration: 10318 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 374 loss: 1.39099 acc: 0.70378 | v_loss: 1.24570 v_acc: 0.70573 |  iteration: 10319 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 375 loss: 1.41555 acc: 0.69759 | v_loss: 1.25757 v_acc: 0.70215 |  iteration: 10320 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 376 loss: 1.39603 acc: 0.70866 | v_loss: 1.24629 v_acc: 0.73340 |  iteration: 10321 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 377 loss: 1.46876 acc: 0.70703 | v_loss: 1.26945 v_acc: 0.71647 |  iteration: 10322 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 378 loss: 1.51683 acc: 0.69434 | v_loss: 1.35301 v_acc: 0.74089 |  iteration: 10323 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 379 loss: 1.37527 acc: 0.71289 | v_loss: 1.26753 v_acc: 0.72005 |  iteration: 10324 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 380 loss: 1.44373 acc: 0.69759 | v_loss: 1.30469 v_acc: 0.71582 |  iteration: 10325 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 381 loss: 1.40422 acc: 0.70182 | v_loss: 1.40690 v_acc: 0.71224 |  iteration: 10326 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 382 loss: 1.58192 acc: 0.68848 | v_loss: 1.39016 v_acc: 0.72038 |  iteration: 10327 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 383 loss: 1.48878 acc: 0.69922 | v_loss: 1.49038 v_acc: 0.69661 |  iteration: 10328 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 384 loss: 1.37045 acc: 0.70443 | v_loss: 1.40811 v_acc: 0.71745 |  iteration: 10329 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 385 loss: 1.34639 acc: 0.71387 | v_loss: 1.18164 v_acc: 0.74382 |  iteration: 10330 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 386 loss: 1.53956 acc: 0.69043 | v_loss: 1.25748 v_acc: 0.70280 |  iteration: 10331 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 387 loss: 1.48800 acc: 0.70866 | v_loss: 1.50959 v_acc: 0.70280 |  iteration: 10332 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 388 loss: 1.47892 acc: 0.70378 | v_loss: 1.23841 v_acc: 0.71647 |  iteration: 10333 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 389 loss: 1.56418 acc: 0.68848 | v_loss: 1.32988 v_acc: 0.71191 |  iteration: 10334 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 390 loss: 1.30923 acc: 0.71029 | v_loss: 1.37425 v_acc: 0.69076 |  iteration: 10335 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 391 loss: 1.35871 acc: 0.70768 | v_loss: 1.31726 v_acc: 0.70898 |  iteration: 10336 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 392 loss: 1.37553 acc: 0.70475 | v_loss: 1.37058 v_acc: 0.69629 |  iteration: 10337 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 393 loss: 1.39450 acc: 0.70345 | v_loss: 1.46786 v_acc: 0.71094 |  iteration: 10338 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 394 loss: 1.42393 acc: 0.69922 | v_loss: 1.31638 v_acc: 0.72233 |  iteration: 10339 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 395 loss: 1.49849 acc: 0.69661 | v_loss: 1.45098 v_acc: 0.70378 |  iteration: 10340 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 396 loss: 1.39182 acc: 0.70768 | v_loss: 1.36858 v_acc: 0.69954 |  iteration: 10341 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 397 loss: 1.58206 acc: 0.68783 | v_loss: 1.33144 v_acc: 0.70768 |  iteration: 10342 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 398 loss: 1.48439 acc: 0.69206 | v_loss: 1.54929 v_acc: 0.68913 |  iteration: 10343 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 399 loss: 1.29938 acc: 0.70540 | v_loss: 1.31036 v_acc: 0.72135 |  iteration: 10344 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 400 loss: 1.41705 acc: 0.71191 | v_loss: 1.58019 v_acc: 0.68620 |  iteration: 10345 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 401 loss: 1.33710 acc: 0.71940 | v_loss: 1.42830 v_acc: 0.69987 |  iteration: 10346 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 402 loss: 1.41046 acc: 0.70150 | v_loss: 1.52273 v_acc: 0.68913 |  iteration: 10347 teacher: 0 stage: sketch lr: 0.000434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 403 loss: 1.46729 acc: 0.70312 | v_loss: 1.37114 v_acc: 0.69759 |  iteration: 10348 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 404 loss: 1.41268 acc: 0.70833 | v_loss: 1.32652 v_acc: 0.70215 |  iteration: 10349 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 405 loss: 1.45916 acc: 0.70573 | v_loss: 1.34809 v_acc: 0.69889 |  iteration: 10350 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 406 loss: 1.54672 acc: 0.68750 | v_loss: 1.33678 v_acc: 0.71419 |  iteration: 10351 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 407 loss: 1.32968 acc: 0.71387 | v_loss: 1.53908 v_acc: 0.69173 |  iteration: 10352 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 408 loss: 1.46044 acc: 0.70020 | v_loss: 1.40035 v_acc: 0.70443 |  iteration: 10353 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 409 loss: 1.34438 acc: 0.71354 | v_loss: 1.33698 v_acc: 0.71061 |  iteration: 10354 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 410 loss: 1.44646 acc: 0.70182 | v_loss: 1.37934 v_acc: 0.71452 |  iteration: 10355 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 411 loss: 1.39442 acc: 0.70898 | v_loss: 1.25966 v_acc: 0.70736 |  iteration: 10356 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 412 loss: 1.41361 acc: 0.70833 | v_loss: 1.43708 v_acc: 0.70052 |  iteration: 10357 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 413 loss: 1.45872 acc: 0.70085 | v_loss: 1.42789 v_acc: 0.71549 |  iteration: 10358 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 414 loss: 1.43660 acc: 0.69564 | v_loss: 1.29662 v_acc: 0.72038 |  iteration: 10359 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 415 loss: 1.33624 acc: 0.70964 | v_loss: 1.25512 v_acc: 0.72819 |  iteration: 10360 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 416 loss: 1.48545 acc: 0.69954 | v_loss: 1.37833 v_acc: 0.71615 |  iteration: 10361 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 417 loss: 1.46285 acc: 0.69499 | v_loss: 1.41841 v_acc: 0.70540 |  iteration: 10362 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 418 loss: 1.27401 acc: 0.71419 | v_loss: 1.42111 v_acc: 0.70410 |  iteration: 10363 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 419 loss: 1.37072 acc: 0.70345 | v_loss: 1.23064 v_acc: 0.71484 |  iteration: 10364 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 420 loss: 1.55970 acc: 0.70085 | v_loss: 1.38161 v_acc: 0.72819 |  iteration: 10365 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 421 loss: 1.44281 acc: 0.71908 | v_loss: 1.46528 v_acc: 0.69792 |  iteration: 10366 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 422 loss: 1.43495 acc: 0.71289 | v_loss: 1.41961 v_acc: 0.71842 |  iteration: 10367 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 423 loss: 1.44580 acc: 0.70573 | v_loss: 1.26892 v_acc: 0.71810 |  iteration: 10368 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 424 loss: 1.35186 acc: 0.71061 | v_loss: 1.21792 v_acc: 0.73535 |  iteration: 10369 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 425 loss: 1.54104 acc: 0.69336 | v_loss: 1.21451 v_acc: 0.72656 |  iteration: 10370 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 426 loss: 1.48206 acc: 0.69694 | v_loss: 1.29267 v_acc: 0.70898 |  iteration: 10371 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 427 loss: 1.45757 acc: 0.70312 | v_loss: 1.44974 v_acc: 0.69629 |  iteration: 10372 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 428 loss: 1.41249 acc: 0.71159 | v_loss: 1.29304 v_acc: 0.71126 |  iteration: 10373 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 429 loss: 1.49386 acc: 0.69759 | v_loss: 1.47207 v_acc: 0.71647 |  iteration: 10374 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 430 loss: 1.47023 acc: 0.70703 | v_loss: 1.70658 v_acc: 0.69076 |  iteration: 10375 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 431 loss: 1.37909 acc: 0.70801 | v_loss: 1.55123 v_acc: 0.69499 |  iteration: 10376 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 432 loss: 1.45558 acc: 0.69466 | v_loss: 1.30410 v_acc: 0.72201 |  iteration: 10377 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 433 loss: 1.49342 acc: 0.69727 | v_loss: 1.36717 v_acc: 0.70443 |  iteration: 10378 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 434 loss: 1.45025 acc: 0.70020 | v_loss: 1.21711 v_acc: 0.72070 |  iteration: 10379 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 435 loss: 1.43430 acc: 0.69922 | v_loss: 1.41858 v_acc: 0.70475 |  iteration: 10380 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 436 loss: 1.35526 acc: 0.71322 | v_loss: 1.35502 v_acc: 0.71484 |  iteration: 10381 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 437 loss: 1.58247 acc: 0.69043 | v_loss: 1.36317 v_acc: 0.73014 |  iteration: 10382 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 438 loss: 1.36666 acc: 0.70573 | v_loss: 1.37169 v_acc: 0.71973 |  iteration: 10383 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 439 loss: 1.35096 acc: 0.71029 | v_loss: 1.37893 v_acc: 0.70964 |  iteration: 10384 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 440 loss: 1.41311 acc: 0.70605 | v_loss: 1.28766 v_acc: 0.72233 |  iteration: 10385 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 441 loss: 1.36019 acc: 0.71191 | v_loss: 1.31309 v_acc: 0.72005 |  iteration: 10386 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 442 loss: 1.48032 acc: 0.69954 | v_loss: 1.50817 v_acc: 0.69043 |  iteration: 10387 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 443 loss: 1.51012 acc: 0.68880 | v_loss: 1.33904 v_acc: 0.70866 |  iteration: 10388 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 444 loss: 1.45430 acc: 0.70605 | v_loss: 1.32418 v_acc: 0.71126 |  iteration: 10389 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 445 loss: 1.44358 acc: 0.69857 | v_loss: 1.30843 v_acc: 0.71777 |  iteration: 10390 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 446 loss: 1.47835 acc: 0.70085 | v_loss: 1.43463 v_acc: 0.70150 |  iteration: 10391 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 447 loss: 1.53303 acc: 0.69661 | v_loss: 1.31063 v_acc: 0.73210 |  iteration: 10392 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 448 loss: 1.55385 acc: 0.69368 | v_loss: 1.53235 v_acc: 0.71322 |  iteration: 10393 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 449 loss: 1.40443 acc: 0.70638 | v_loss: 1.29036 v_acc: 0.69531 |  iteration: 10394 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 450 loss: 1.44637 acc: 0.70638 | v_loss: 1.28338 v_acc: 0.70117 |  iteration: 10395 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 451 loss: 1.34493 acc: 0.70410 | v_loss: 1.44631 v_acc: 0.70508 |  iteration: 10396 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 452 loss: 1.50007 acc: 0.70215 | v_loss: 1.47491 v_acc: 0.70573 |  iteration: 10397 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 453 loss: 1.56006 acc: 0.68848 | v_loss: 1.51960 v_acc: 0.68978 |  iteration: 10398 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 454 loss: 1.41000 acc: 0.70247 | v_loss: 1.45987 v_acc: 0.70540 |  iteration: 10399 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 455 loss: 1.54422 acc: 0.69434 | v_loss: 1.42411 v_acc: 0.70540 |  iteration: 10400 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 456 loss: 1.40758 acc: 0.70150 | v_loss: 1.40885 v_acc: 0.70475 |  iteration: 10401 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 457 loss: 1.36552 acc: 0.71647 | v_loss: 1.40735 v_acc: 0.70703 |  iteration: 10402 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 458 loss: 1.41502 acc: 0.69206 | v_loss: 1.26412 v_acc: 0.71875 |  iteration: 10403 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 459 loss: 1.43124 acc: 0.70475 | v_loss: 1.32421 v_acc: 0.72233 |  iteration: 10404 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 460 loss: 1.34756 acc: 0.70964 | v_loss: 1.16612 v_acc: 0.71647 |  iteration: 10405 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 461 loss: 1.32831 acc: 0.70671 | v_loss: 1.33847 v_acc: 0.71061 |  iteration: 10406 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 462 loss: 1.43753 acc: 0.70964 | v_loss: 1.51977 v_acc: 0.69954 |  iteration: 10407 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 463 loss: 1.45082 acc: 0.70768 | v_loss: 1.33979 v_acc: 0.71484 |  iteration: 10408 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 464 loss: 1.47144 acc: 0.70150 | v_loss: 1.36323 v_acc: 0.70312 |  iteration: 10409 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 465 loss: 1.37876 acc: 0.70182 | v_loss: 1.24699 v_acc: 0.71680 |  iteration: 10410 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 466 loss: 1.42912 acc: 0.70931 | v_loss: 1.24596 v_acc: 0.70215 |  iteration: 10411 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 467 loss: 1.48147 acc: 0.69531 | v_loss: 1.25956 v_acc: 0.73340 |  iteration: 10412 teacher: 0 stage: sketch lr: 0.000433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 468 loss: 1.39832 acc: 0.69987 | v_loss: 1.28409 v_acc: 0.71647 |  iteration: 10413 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 469 loss: 1.36160 acc: 0.70801 | v_loss: 1.37693 v_acc: 0.74089 |  iteration: 10414 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 470 loss: 1.45219 acc: 0.69727 | v_loss: 1.27090 v_acc: 0.72461 |  iteration: 10415 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 471 loss: 1.45230 acc: 0.70247 | v_loss: 1.31023 v_acc: 0.72103 |  iteration: 10416 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 472 loss: 1.43110 acc: 0.70247 | v_loss: 1.41678 v_acc: 0.71354 |  iteration: 10417 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 473 loss: 1.47170 acc: 0.70443 | v_loss: 1.40698 v_acc: 0.72428 |  iteration: 10418 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 474 loss: 1.37623 acc: 0.70020 | v_loss: 1.50802 v_acc: 0.70182 |  iteration: 10419 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 475 loss: 1.50956 acc: 0.70085 | v_loss: 1.41446 v_acc: 0.71777 |  iteration: 10420 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 476 loss: 1.50180 acc: 0.69987 | v_loss: 1.18577 v_acc: 0.74447 |  iteration: 10421 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 477 loss: 1.49542 acc: 0.69206 | v_loss: 1.25895 v_acc: 0.71322 |  iteration: 10422 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 478 loss: 1.51618 acc: 0.70410 | v_loss: 1.50354 v_acc: 0.70410 |  iteration: 10423 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 479 loss: 1.38808 acc: 0.71094 | v_loss: 1.23446 v_acc: 0.71647 |  iteration: 10424 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 480 loss: 1.47835 acc: 0.69076 | v_loss: 1.32780 v_acc: 0.71191 |  iteration: 10425 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 481 loss: 1.49828 acc: 0.69857 | v_loss: 1.37164 v_acc: 0.69076 |  iteration: 10426 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 482 loss: 1.50287 acc: 0.69401 | v_loss: 1.33393 v_acc: 0.70898 |  iteration: 10427 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 483 loss: 1.36149 acc: 0.71061 | v_loss: 1.37715 v_acc: 0.69206 |  iteration: 10428 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 484 loss: 1.45091 acc: 0.70117 | v_loss: 1.46742 v_acc: 0.70768 |  iteration: 10429 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 485 loss: 1.42131 acc: 0.70833 | v_loss: 1.31926 v_acc: 0.72363 |  iteration: 10430 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 486 loss: 1.42635 acc: 0.70605 | v_loss: 1.44225 v_acc: 0.70117 |  iteration: 10431 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 487 loss: 1.50757 acc: 0.69206 | v_loss: 1.37019 v_acc: 0.70085 |  iteration: 10432 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 488 loss: 1.43137 acc: 0.70247 | v_loss: 1.33588 v_acc: 0.70703 |  iteration: 10433 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 489 loss: 1.47162 acc: 0.70312 | v_loss: 1.54938 v_acc: 0.68880 |  iteration: 10434 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 490 loss: 1.55691 acc: 0.69466 | v_loss: 1.30016 v_acc: 0.72103 |  iteration: 10435 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 491 loss: 1.51576 acc: 0.70410 | v_loss: 1.58708 v_acc: 0.68652 |  iteration: 10436 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 492 loss: 1.36632 acc: 0.70801 | v_loss: 1.48240 v_acc: 0.69661 |  iteration: 10437 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 493 loss: 1.55896 acc: 0.68652 | v_loss: 1.53621 v_acc: 0.69238 |  iteration: 10438 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 494 loss: 1.39084 acc: 0.69857 | v_loss: 1.37982 v_acc: 0.70182 |  iteration: 10439 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 495 loss: 1.53169 acc: 0.69173 | v_loss: 1.32465 v_acc: 0.70638 |  iteration: 10440 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 496 loss: 1.39545 acc: 0.69629 | v_loss: 1.33197 v_acc: 0.70410 |  iteration: 10441 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 497 loss: 1.36271 acc: 0.71159 | v_loss: 1.33617 v_acc: 0.71549 |  iteration: 10442 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 498 loss: 1.38325 acc: 0.70378 | v_loss: 1.52149 v_acc: 0.69173 |  iteration: 10443 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 499 loss: 1.45664 acc: 0.70638 | v_loss: 1.37072 v_acc: 0.70247 |  iteration: 10444 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 500 loss: 1.38974 acc: 0.70280 | v_loss: 1.37629 v_acc: 0.70833 |  iteration: 10445 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 501 loss: 1.59275 acc: 0.67871 | v_loss: 1.38874 v_acc: 0.71582 |  iteration: 10446 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 502 loss: 1.39373 acc: 0.70508 | v_loss: 1.27809 v_acc: 0.70443 |  iteration: 10447 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 503 loss: 1.50009 acc: 0.69499 | v_loss: 1.43227 v_acc: 0.70150 |  iteration: 10448 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 504 loss: 1.47078 acc: 0.70312 | v_loss: 1.41742 v_acc: 0.71224 |  iteration: 10449 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 505 loss: 1.41067 acc: 0.69922 | v_loss: 1.28779 v_acc: 0.72201 |  iteration: 10450 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 506 loss: 1.33786 acc: 0.70964 | v_loss: 1.25022 v_acc: 0.72591 |  iteration: 10451 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 507 loss: 1.42827 acc: 0.70215 | v_loss: 1.38157 v_acc: 0.71745 |  iteration: 10452 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 508 loss: 1.44672 acc: 0.69954 | v_loss: 1.41259 v_acc: 0.70410 |  iteration: 10453 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 509 loss: 1.49897 acc: 0.69336 | v_loss: 1.41790 v_acc: 0.70410 |  iteration: 10454 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 510 loss: 1.41330 acc: 0.70117 | v_loss: 1.22930 v_acc: 0.71484 |  iteration: 10455 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 511 loss: 1.45426 acc: 0.69987 | v_loss: 1.40424 v_acc: 0.72852 |  iteration: 10456 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 512 loss: 1.45697 acc: 0.69987 | v_loss: 1.48268 v_acc: 0.69564 |  iteration: 10457 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 513 loss: 1.39284 acc: 0.70215 | v_loss: 1.42492 v_acc: 0.72103 |  iteration: 10458 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 514 loss: 1.42054 acc: 0.69661 | v_loss: 1.25015 v_acc: 0.72233 |  iteration: 10459 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 515 loss: 1.38257 acc: 0.70540 | v_loss: 1.22465 v_acc: 0.73535 |  iteration: 10460 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 516 loss: 1.51016 acc: 0.69824 | v_loss: 1.23420 v_acc: 0.72656 |  iteration: 10461 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 517 loss: 1.31472 acc: 0.72103 | v_loss: 1.29173 v_acc: 0.70703 |  iteration: 10462 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 518 loss: 1.31059 acc: 0.69954 | v_loss: 1.45677 v_acc: 0.69466 |  iteration: 10463 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 519 loss: 1.46368 acc: 0.70345 | v_loss: 1.27502 v_acc: 0.71484 |  iteration: 10464 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 520 loss: 1.51522 acc: 0.69824 | v_loss: 1.42653 v_acc: 0.72949 |  iteration: 10465 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 521 loss: 1.42436 acc: 0.71029 | v_loss: 1.63965 v_acc: 0.69466 |  iteration: 10466 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 522 loss: 1.40352 acc: 0.70215 | v_loss: 1.51321 v_acc: 0.70410 |  iteration: 10467 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 523 loss: 1.40805 acc: 0.71126 | v_loss: 1.29888 v_acc: 0.72005 |  iteration: 10468 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 524 loss: 1.40633 acc: 0.70150 | v_loss: 1.38382 v_acc: 0.69987 |  iteration: 10469 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 525 loss: 1.44265 acc: 0.71061 | v_loss: 1.22987 v_acc: 0.71615 |  iteration: 10470 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 526 loss: 1.38065 acc: 0.71387 | v_loss: 1.43548 v_acc: 0.69857 |  iteration: 10471 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 527 loss: 1.41812 acc: 0.70931 | v_loss: 1.35696 v_acc: 0.70964 |  iteration: 10472 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 528 loss: 1.50067 acc: 0.70247 | v_loss: 1.35091 v_acc: 0.72949 |  iteration: 10473 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 529 loss: 1.45533 acc: 0.70215 | v_loss: 1.37285 v_acc: 0.71875 |  iteration: 10474 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 530 loss: 1.45092 acc: 0.70833 | v_loss: 1.38961 v_acc: 0.70964 |  iteration: 10475 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 531 loss: 1.39921 acc: 0.71354 | v_loss: 1.28808 v_acc: 0.72819 |  iteration: 10476 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 532 loss: 1.53961 acc: 0.70833 | v_loss: 1.29892 v_acc: 0.72005 |  iteration: 10477 teacher: 0 stage: sketch lr: 0.000432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 533 loss: 1.46255 acc: 0.70833 | v_loss: 1.50585 v_acc: 0.69043 |  iteration: 10478 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 534 loss: 1.47094 acc: 0.69792 | v_loss: 1.33617 v_acc: 0.70964 |  iteration: 10479 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 535 loss: 1.52141 acc: 0.69792 | v_loss: 1.30340 v_acc: 0.71354 |  iteration: 10480 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 536 loss: 1.43888 acc: 0.70508 | v_loss: 1.30332 v_acc: 0.71712 |  iteration: 10481 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 537 loss: 1.47270 acc: 0.69466 | v_loss: 1.42935 v_acc: 0.70540 |  iteration: 10482 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 538 loss: 1.42749 acc: 0.71061 | v_loss: 1.31070 v_acc: 0.73112 |  iteration: 10483 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 539 loss: 1.57687 acc: 0.68490 | v_loss: 1.53252 v_acc: 0.71354 |  iteration: 10484 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 540 loss: 1.42255 acc: 0.69922 | v_loss: 1.29115 v_acc: 0.69922 |  iteration: 10485 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 541 loss: 1.50016 acc: 0.69792 | v_loss: 1.28686 v_acc: 0.70443 |  iteration: 10486 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 542 loss: 1.48807 acc: 0.69824 | v_loss: 1.45825 v_acc: 0.70312 |  iteration: 10487 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 543 loss: 1.47554 acc: 0.69889 | v_loss: 1.47877 v_acc: 0.70378 |  iteration: 10488 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 544 loss: 1.41622 acc: 0.70247 | v_loss: 1.50592 v_acc: 0.69368 |  iteration: 10489 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 545 loss: 1.38288 acc: 0.70866 | v_loss: 1.46932 v_acc: 0.70833 |  iteration: 10490 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 546 loss: 1.38865 acc: 0.70475 | v_loss: 1.42644 v_acc: 0.70085 |  iteration: 10491 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 547 loss: 1.45629 acc: 0.71029 | v_loss: 1.40568 v_acc: 0.70931 |  iteration: 10492 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 548 loss: 1.46070 acc: 0.69661 | v_loss: 1.39904 v_acc: 0.70475 |  iteration: 10493 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 549 loss: 1.61146 acc: 0.69173 | v_loss: 1.26571 v_acc: 0.71354 |  iteration: 10494 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 550 loss: 1.41832 acc: 0.70573 | v_loss: 1.32531 v_acc: 0.72493 |  iteration: 10495 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 551 loss: 1.46830 acc: 0.70150 | v_loss: 1.21143 v_acc: 0.70671 |  iteration: 10496 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 552 loss: 1.42538 acc: 0.70833 | v_loss: 1.35491 v_acc: 0.70150 |  iteration: 10497 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 553 loss: 1.56894 acc: 0.69076 | v_loss: 1.48909 v_acc: 0.70312 |  iteration: 10498 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 554 loss: 1.45810 acc: 0.70605 | v_loss: 1.34685 v_acc: 0.70540 |  iteration: 10499 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 555 loss: 1.41225 acc: 0.70964 | v_loss: 1.36223 v_acc: 0.69368 |  iteration: 10500 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 556 loss: 1.40599 acc: 0.71419 | v_loss: 1.26110 v_acc: 0.70573 |  iteration: 10501 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 557 loss: 1.50642 acc: 0.69889 | v_loss: 1.26431 v_acc: 0.70345 |  iteration: 10502 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 558 loss: 1.43127 acc: 0.70573 | v_loss: 1.23510 v_acc: 0.73503 |  iteration: 10503 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 559 loss: 1.45018 acc: 0.70150 | v_loss: 1.26874 v_acc: 0.72461 |  iteration: 10504 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 560 loss: 1.45904 acc: 0.70638 | v_loss: 1.32504 v_acc: 0.72689 |  iteration: 10505 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 561 loss: 1.39051 acc: 0.70540 | v_loss: 1.25779 v_acc: 0.72852 |  iteration: 10506 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 562 loss: 1.46844 acc: 0.70801 | v_loss: 1.30312 v_acc: 0.72103 |  iteration: 10507 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 563 loss: 1.45076 acc: 0.70410 | v_loss: 1.41507 v_acc: 0.71354 |  iteration: 10508 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 564 loss: 1.36037 acc: 0.70898 | v_loss: 1.39431 v_acc: 0.72070 |  iteration: 10509 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 565 loss: 1.48540 acc: 0.69661 | v_loss: 1.48827 v_acc: 0.69954 |  iteration: 10510 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 566 loss: 1.46411 acc: 0.69401 | v_loss: 1.42950 v_acc: 0.71810 |  iteration: 10511 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 567 loss: 1.54274 acc: 0.69173 | v_loss: 1.18437 v_acc: 0.74219 |  iteration: 10512 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 568 loss: 1.44656 acc: 0.70085 | v_loss: 1.26984 v_acc: 0.70312 |  iteration: 10513 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 569 loss: 1.43112 acc: 0.70280 | v_loss: 1.52901 v_acc: 0.69857 |  iteration: 10514 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 570 loss: 1.37433 acc: 0.70540 | v_loss: 1.23775 v_acc: 0.71647 |  iteration: 10515 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 571 loss: 1.55056 acc: 0.69857 | v_loss: 1.32683 v_acc: 0.71191 |  iteration: 10516 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 572 loss: 1.32546 acc: 0.70312 | v_loss: 1.36997 v_acc: 0.69076 |  iteration: 10517 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 573 loss: 1.44990 acc: 0.70247 | v_loss: 1.30850 v_acc: 0.70898 |  iteration: 10518 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 574 loss: 1.44467 acc: 0.70443 | v_loss: 1.36508 v_acc: 0.69206 |  iteration: 10519 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 575 loss: 1.42450 acc: 0.70378 | v_loss: 1.46592 v_acc: 0.71517 |  iteration: 10520 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 576 loss: 1.46052 acc: 0.70443 | v_loss: 1.32006 v_acc: 0.72689 |  iteration: 10521 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 577 loss: 1.44548 acc: 0.70475 | v_loss: 1.45123 v_acc: 0.70117 |  iteration: 10522 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 578 loss: 1.45490 acc: 0.70898 | v_loss: 1.37367 v_acc: 0.70085 |  iteration: 10523 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 579 loss: 1.34447 acc: 0.71484 | v_loss: 1.34020 v_acc: 0.70703 |  iteration: 10524 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 580 loss: 1.43790 acc: 0.71159 | v_loss: 1.54831 v_acc: 0.68880 |  iteration: 10525 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 581 loss: 1.32912 acc: 0.71354 | v_loss: 1.31653 v_acc: 0.72103 |  iteration: 10526 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 582 loss: 1.46838 acc: 0.70117 | v_loss: 1.59292 v_acc: 0.68815 |  iteration: 10527 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 583 loss: 1.49797 acc: 0.69596 | v_loss: 1.43202 v_acc: 0.69596 |  iteration: 10528 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 584 loss: 1.43757 acc: 0.69954 | v_loss: 1.52445 v_acc: 0.68913 |  iteration: 10529 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 585 loss: 1.42547 acc: 0.70898 | v_loss: 1.36900 v_acc: 0.69824 |  iteration: 10530 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 586 loss: 1.56344 acc: 0.68913 | v_loss: 1.32409 v_acc: 0.70117 |  iteration: 10531 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 587 loss: 1.35133 acc: 0.71029 | v_loss: 1.33255 v_acc: 0.69889 |  iteration: 10532 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 588 loss: 1.40074 acc: 0.70703 | v_loss: 1.33059 v_acc: 0.71419 |  iteration: 10533 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 589 loss: 1.44540 acc: 0.70833 | v_loss: 1.52714 v_acc: 0.69173 |  iteration: 10534 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 590 loss: 1.45401 acc: 0.70378 | v_loss: 1.38528 v_acc: 0.70247 |  iteration: 10535 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 591 loss: 1.43012 acc: 0.70345 | v_loss: 1.37590 v_acc: 0.71126 |  iteration: 10536 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 592 loss: 1.30357 acc: 0.71680 | v_loss: 1.38760 v_acc: 0.71810 |  iteration: 10537 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 593 loss: 1.48943 acc: 0.70182 | v_loss: 1.28366 v_acc: 0.70215 |  iteration: 10538 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 594 loss: 1.36832 acc: 0.71191 | v_loss: 1.42971 v_acc: 0.69434 |  iteration: 10539 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 595 loss: 1.51497 acc: 0.69010 | v_loss: 1.43478 v_acc: 0.71452 |  iteration: 10540 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 596 loss: 1.49154 acc: 0.69824 | v_loss: 1.30006 v_acc: 0.71647 |  iteration: 10541 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 597 loss: 1.46482 acc: 0.69922 | v_loss: 1.26686 v_acc: 0.72526 |  iteration: 10542 teacher: 0 stage: sketch lr: 0.000430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 598 loss: 1.44341 acc: 0.69857 | v_loss: 1.37837 v_acc: 0.71647 |  iteration: 10543 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 599 loss: 1.50769 acc: 0.69531 | v_loss: 1.42876 v_acc: 0.70052 |  iteration: 10544 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 600 loss: 1.38256 acc: 0.70768 | v_loss: 1.42673 v_acc: 0.70312 |  iteration: 10545 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 601 loss: 1.46875 acc: 0.69336 | v_loss: 1.23690 v_acc: 0.71419 |  iteration: 10546 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 602 loss: 1.46576 acc: 0.69368 | v_loss: 1.40359 v_acc: 0.72819 |  iteration: 10547 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 603 loss: 1.48686 acc: 0.70671 | v_loss: 1.47172 v_acc: 0.69792 |  iteration: 10548 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 604 loss: 1.42016 acc: 0.69661 | v_loss: 1.39194 v_acc: 0.71842 |  iteration: 10549 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 605 loss: 1.30606 acc: 0.72201 | v_loss: 1.25765 v_acc: 0.71615 |  iteration: 10550 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 606 loss: 1.44514 acc: 0.70085 | v_loss: 1.22660 v_acc: 0.72949 |  iteration: 10551 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 607 loss: 1.43694 acc: 0.70638 | v_loss: 1.22947 v_acc: 0.71842 |  iteration: 10552 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 608 loss: 1.39367 acc: 0.70801 | v_loss: 1.31951 v_acc: 0.70703 |  iteration: 10553 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 609 loss: 1.57729 acc: 0.68717 | v_loss: 1.47344 v_acc: 0.69466 |  iteration: 10554 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 610 loss: 1.46739 acc: 0.69792 | v_loss: 1.28287 v_acc: 0.71484 |  iteration: 10555 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 611 loss: 1.43352 acc: 0.70345 | v_loss: 1.42906 v_acc: 0.72949 |  iteration: 10556 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 612 loss: 1.39651 acc: 0.70638 | v_loss: 1.64520 v_acc: 0.69466 |  iteration: 10557 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 613 loss: 1.57101 acc: 0.69857 | v_loss: 1.50657 v_acc: 0.70410 |  iteration: 10558 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 614 loss: 1.37417 acc: 0.71940 | v_loss: 1.30022 v_acc: 0.72005 |  iteration: 10559 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 615 loss: 1.51155 acc: 0.68783 | v_loss: 1.37505 v_acc: 0.69987 |  iteration: 10560 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 616 loss: 1.44986 acc: 0.70280 | v_loss: 1.24134 v_acc: 0.71615 |  iteration: 10561 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 617 loss: 1.38859 acc: 0.70638 | v_loss: 1.41032 v_acc: 0.69857 |  iteration: 10562 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 618 loss: 1.33522 acc: 0.70638 | v_loss: 1.36381 v_acc: 0.70964 |  iteration: 10563 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 619 loss: 1.33603 acc: 0.70117 | v_loss: 1.35234 v_acc: 0.72949 |  iteration: 10564 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 620 loss: 1.36728 acc: 0.71582 | v_loss: 1.36175 v_acc: 0.71680 |  iteration: 10565 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 621 loss: 1.45832 acc: 0.69661 | v_loss: 1.37808 v_acc: 0.70345 |  iteration: 10566 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 622 loss: 1.46911 acc: 0.69531 | v_loss: 1.29755 v_acc: 0.72201 |  iteration: 10567 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 623 loss: 1.36411 acc: 0.70085 | v_loss: 1.31312 v_acc: 0.72005 |  iteration: 10568 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 624 loss: 1.55924 acc: 0.68717 | v_loss: 1.50253 v_acc: 0.69043 |  iteration: 10569 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 625 loss: 1.34667 acc: 0.70736 | v_loss: 1.33640 v_acc: 0.70931 |  iteration: 10570 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 626 loss: 1.38012 acc: 0.70182 | v_loss: 1.29899 v_acc: 0.71777 |  iteration: 10571 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 627 loss: 1.42419 acc: 0.70345 | v_loss: 1.28857 v_acc: 0.71484 |  iteration: 10572 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 628 loss: 1.31948 acc: 0.71094 | v_loss: 1.44370 v_acc: 0.70540 |  iteration: 10573 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 629 loss: 1.41644 acc: 0.70378 | v_loss: 1.32480 v_acc: 0.73047 |  iteration: 10574 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 630 loss: 1.46825 acc: 0.70052 | v_loss: 1.56963 v_acc: 0.71582 |  iteration: 10575 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 631 loss: 1.54531 acc: 0.70020 | v_loss: 1.30056 v_acc: 0.69759 |  iteration: 10576 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 632 loss: 1.37066 acc: 0.70638 | v_loss: 1.29155 v_acc: 0.70117 |  iteration: 10577 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 633 loss: 1.38923 acc: 0.70378 | v_loss: 1.43504 v_acc: 0.70508 |  iteration: 10578 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 634 loss: 1.42258 acc: 0.70410 | v_loss: 1.45938 v_acc: 0.70573 |  iteration: 10579 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 635 loss: 1.40128 acc: 0.70508 | v_loss: 1.51322 v_acc: 0.68978 |  iteration: 10580 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 636 loss: 1.40383 acc: 0.70345 | v_loss: 1.46130 v_acc: 0.70540 |  iteration: 10581 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 637 loss: 1.43413 acc: 0.70247 | v_loss: 1.42136 v_acc: 0.70540 |  iteration: 10582 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 638 loss: 1.47447 acc: 0.69434 | v_loss: 1.41195 v_acc: 0.70475 |  iteration: 10583 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 639 loss: 1.51965 acc: 0.68978 | v_loss: 1.40743 v_acc: 0.70703 |  iteration: 10584 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 640 loss: 1.39291 acc: 0.70475 | v_loss: 1.26638 v_acc: 0.71875 |  iteration: 10585 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 641 loss: 1.47773 acc: 0.69466 | v_loss: 1.33109 v_acc: 0.72331 |  iteration: 10586 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 642 loss: 1.40804 acc: 0.70085 | v_loss: 1.17815 v_acc: 0.71615 |  iteration: 10587 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 643 loss: 1.40215 acc: 0.71191 | v_loss: 1.34263 v_acc: 0.71126 |  iteration: 10588 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 644 loss: 1.44467 acc: 0.69434 | v_loss: 1.50783 v_acc: 0.69954 |  iteration: 10589 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 645 loss: 1.54714 acc: 0.70020 | v_loss: 1.32225 v_acc: 0.70833 |  iteration: 10590 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 646 loss: 1.39754 acc: 0.70312 | v_loss: 1.36421 v_acc: 0.69368 |  iteration: 10591 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 647 loss: 1.38640 acc: 0.70345 | v_loss: 1.26018 v_acc: 0.70573 |  iteration: 10592 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 648 loss: 1.37724 acc: 0.70996 | v_loss: 1.26730 v_acc: 0.70215 |  iteration: 10593 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 649 loss: 1.40582 acc: 0.70540 | v_loss: 1.25890 v_acc: 0.73340 |  iteration: 10594 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 650 loss: 1.37139 acc: 0.70573 | v_loss: 1.27865 v_acc: 0.71647 |  iteration: 10595 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 651 loss: 1.40821 acc: 0.70898 | v_loss: 1.37660 v_acc: 0.74089 |  iteration: 10596 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 652 loss: 1.45160 acc: 0.70052 | v_loss: 1.28621 v_acc: 0.72005 |  iteration: 10597 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 653 loss: 1.41251 acc: 0.69824 | v_loss: 1.33611 v_acc: 0.71517 |  iteration: 10598 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 654 loss: 1.36632 acc: 0.71224 | v_loss: 1.44718 v_acc: 0.71289 |  iteration: 10599 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 655 loss: 1.66342 acc: 0.68229 | v_loss: 1.42127 v_acc: 0.72428 |  iteration: 10600 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 656 loss: 1.45893 acc: 0.69629 | v_loss: 1.49090 v_acc: 0.69759 |  iteration: 10601 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 657 loss: 1.33755 acc: 0.70768 | v_loss: 1.42972 v_acc: 0.71973 |  iteration: 10602 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 658 loss: 1.48685 acc: 0.69336 | v_loss: 1.18312 v_acc: 0.74447 |  iteration: 10603 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 659 loss: 1.60630 acc: 0.68652 | v_loss: 1.25026 v_acc: 0.71322 |  iteration: 10604 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 660 loss: 1.36382 acc: 0.71582 | v_loss: 1.52449 v_acc: 0.69987 |  iteration: 10605 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 661 loss: 1.34773 acc: 0.70801 | v_loss: 1.20687 v_acc: 0.70671 |  iteration: 10606 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 662 loss: 1.50378 acc: 0.69694 | v_loss: 1.32430 v_acc: 0.71257 |  iteration: 10607 teacher: 0 stage: sketch lr: 0.000429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 663 loss: 1.48965 acc: 0.70573 | v_loss: 1.37190 v_acc: 0.69076 |  iteration: 10608 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 664 loss: 1.50046 acc: 0.69238 | v_loss: 1.30659 v_acc: 0.70898 |  iteration: 10609 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 665 loss: 1.52855 acc: 0.69401 | v_loss: 1.37067 v_acc: 0.69206 |  iteration: 10610 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 666 loss: 1.54628 acc: 0.68815 | v_loss: 1.50420 v_acc: 0.70931 |  iteration: 10611 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 667 loss: 1.44831 acc: 0.71322 | v_loss: 1.32732 v_acc: 0.72363 |  iteration: 10612 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 668 loss: 1.53955 acc: 0.69434 | v_loss: 1.48318 v_acc: 0.70117 |  iteration: 10613 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 669 loss: 1.39781 acc: 0.70638 | v_loss: 1.36189 v_acc: 0.70085 |  iteration: 10614 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 670 loss: 1.47104 acc: 0.70540 | v_loss: 1.35568 v_acc: 0.70703 |  iteration: 10615 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 671 loss: 1.46410 acc: 0.70540 | v_loss: 1.54052 v_acc: 0.68880 |  iteration: 10616 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 672 loss: 1.42964 acc: 0.70247 | v_loss: 1.29961 v_acc: 0.72103 |  iteration: 10617 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 673 loss: 1.38473 acc: 0.71191 | v_loss: 1.59731 v_acc: 0.68164 |  iteration: 10618 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 674 loss: 1.40720 acc: 0.71191 | v_loss: 1.47707 v_acc: 0.69661 |  iteration: 10619 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 675 loss: 1.50062 acc: 0.69954 | v_loss: 1.51945 v_acc: 0.69238 |  iteration: 10620 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 676 loss: 1.44883 acc: 0.70150 | v_loss: 1.39139 v_acc: 0.70312 |  iteration: 10621 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 677 loss: 1.37507 acc: 0.70996 | v_loss: 1.31343 v_acc: 0.70638 |  iteration: 10622 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 678 loss: 1.46596 acc: 0.70996 | v_loss: 1.33393 v_acc: 0.70605 |  iteration: 10623 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 679 loss: 1.43549 acc: 0.70605 | v_loss: 1.33138 v_acc: 0.71973 |  iteration: 10624 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 680 loss: 1.52053 acc: 0.69531 | v_loss: 1.56405 v_acc: 0.69076 |  iteration: 10625 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 681 loss: 1.37209 acc: 0.70703 | v_loss: 1.38586 v_acc: 0.70703 |  iteration: 10626 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 682 loss: 1.41484 acc: 0.71094 | v_loss: 1.35050 v_acc: 0.70833 |  iteration: 10627 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 683 loss: 1.41736 acc: 0.70150 | v_loss: 1.38509 v_acc: 0.71582 |  iteration: 10628 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 684 loss: 1.42611 acc: 0.69954 | v_loss: 1.28891 v_acc: 0.70215 |  iteration: 10629 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 685 loss: 1.44686 acc: 0.70833 | v_loss: 1.43144 v_acc: 0.69434 |  iteration: 10630 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 686 loss: 1.47158 acc: 0.70345 | v_loss: 1.42057 v_acc: 0.71452 |  iteration: 10631 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 687 loss: 1.49515 acc: 0.70443 | v_loss: 1.29266 v_acc: 0.71647 |  iteration: 10632 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 688 loss: 1.42372 acc: 0.69629 | v_loss: 1.26423 v_acc: 0.72754 |  iteration: 10633 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 689 loss: 1.41732 acc: 0.69596 | v_loss: 1.39101 v_acc: 0.72266 |  iteration: 10634 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 690 loss: 1.44277 acc: 0.70866 | v_loss: 1.42376 v_acc: 0.70410 |  iteration: 10635 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 691 loss: 1.51162 acc: 0.70182 | v_loss: 1.43128 v_acc: 0.70833 |  iteration: 10636 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 692 loss: 1.39473 acc: 0.70475 | v_loss: 1.22168 v_acc: 0.72591 |  iteration: 10637 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 693 loss: 1.36767 acc: 0.71289 | v_loss: 1.40872 v_acc: 0.73112 |  iteration: 10638 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 694 loss: 1.43118 acc: 0.70833 | v_loss: 1.48342 v_acc: 0.69792 |  iteration: 10639 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 695 loss: 1.36679 acc: 0.70052 | v_loss: 1.42930 v_acc: 0.72070 |  iteration: 10640 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 696 loss: 1.46254 acc: 0.70931 | v_loss: 1.25408 v_acc: 0.71810 |  iteration: 10641 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 697 loss: 1.53125 acc: 0.69889 | v_loss: 1.21198 v_acc: 0.73535 |  iteration: 10642 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 698 loss: 1.39506 acc: 0.69727 | v_loss: 1.21702 v_acc: 0.72656 |  iteration: 10643 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 699 loss: 1.48738 acc: 0.70573 | v_loss: 1.28795 v_acc: 0.70703 |  iteration: 10644 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 700 loss: 1.51243 acc: 0.69824 | v_loss: 1.44835 v_acc: 0.69466 |  iteration: 10645 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 701 loss: 1.37888 acc: 0.69922 | v_loss: 1.28466 v_acc: 0.71484 |  iteration: 10646 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 702 loss: 1.45286 acc: 0.69564 | v_loss: 1.45071 v_acc: 0.71647 |  iteration: 10647 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 703 loss: 1.36981 acc: 0.70898 | v_loss: 1.66928 v_acc: 0.69303 |  iteration: 10648 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 704 loss: 1.48292 acc: 0.69564 | v_loss: 1.53156 v_acc: 0.70117 |  iteration: 10649 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 705 loss: 1.39178 acc: 0.70866 | v_loss: 1.30042 v_acc: 0.72396 |  iteration: 10650 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 706 loss: 1.44160 acc: 0.70410 | v_loss: 1.38385 v_acc: 0.70996 |  iteration: 10651 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 707 loss: 1.43532 acc: 0.70443 | v_loss: 1.22229 v_acc: 0.72201 |  iteration: 10652 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 708 loss: 1.40325 acc: 0.70020 | v_loss: 1.44406 v_acc: 0.70378 |  iteration: 10653 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 709 loss: 1.42873 acc: 0.69564 | v_loss: 1.36290 v_acc: 0.71810 |  iteration: 10654 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 710 loss: 1.37311 acc: 0.70410 | v_loss: 1.37528 v_acc: 0.73014 |  iteration: 10655 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 711 loss: 1.41411 acc: 0.69727 | v_loss: 1.37719 v_acc: 0.71973 |  iteration: 10656 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 712 loss: 1.50482 acc: 0.69727 | v_loss: 1.37793 v_acc: 0.70964 |  iteration: 10657 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 713 loss: 1.46866 acc: 0.69987 | v_loss: 1.28817 v_acc: 0.72493 |  iteration: 10658 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 714 loss: 1.43691 acc: 0.69531 | v_loss: 1.31195 v_acc: 0.72038 |  iteration: 10659 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 715 loss: 1.50028 acc: 0.69629 | v_loss: 1.46676 v_acc: 0.69108 |  iteration: 10660 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 716 loss: 1.37783 acc: 0.71159 | v_loss: 1.34361 v_acc: 0.70833 |  iteration: 10661 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 717 loss: 1.49787 acc: 0.70020 | v_loss: 1.30967 v_acc: 0.71126 |  iteration: 10662 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 718 loss: 1.50148 acc: 0.69238 | v_loss: 1.30100 v_acc: 0.71777 |  iteration: 10663 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 719 loss: 1.43299 acc: 0.70768 | v_loss: 1.43547 v_acc: 0.70768 |  iteration: 10664 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 720 loss: 1.43347 acc: 0.70573 | v_loss: 1.30944 v_acc: 0.73210 |  iteration: 10665 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 721 loss: 1.46986 acc: 0.70475 | v_loss: 1.53126 v_acc: 0.71322 |  iteration: 10666 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 722 loss: 1.50986 acc: 0.69271 | v_loss: 1.30023 v_acc: 0.69531 |  iteration: 10667 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 723 loss: 1.40203 acc: 0.70931 | v_loss: 1.28227 v_acc: 0.70215 |  iteration: 10668 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 724 loss: 1.36771 acc: 0.70280 | v_loss: 1.45737 v_acc: 0.70312 |  iteration: 10669 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 725 loss: 1.45425 acc: 0.70768 | v_loss: 1.48686 v_acc: 0.70150 |  iteration: 10670 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 726 loss: 1.57252 acc: 0.69987 | v_loss: 1.53574 v_acc: 0.69368 |  iteration: 10671 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 727 loss: 1.44348 acc: 0.70996 | v_loss: 1.47893 v_acc: 0.70833 |  iteration: 10672 teacher: 1 stage: sketch lr: 0.000428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 728 loss: 1.48804 acc: 0.69434 | v_loss: 1.42870 v_acc: 0.70085 |  iteration: 10673 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 729 loss: 1.41779 acc: 0.71159 | v_loss: 1.41864 v_acc: 0.70768 |  iteration: 10674 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 730 loss: 1.39003 acc: 0.70801 | v_loss: 1.39648 v_acc: 0.70312 |  iteration: 10675 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 731 loss: 1.49338 acc: 0.70052 | v_loss: 1.26517 v_acc: 0.71257 |  iteration: 10676 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 732 loss: 1.45674 acc: 0.70540 | v_loss: 1.32785 v_acc: 0.72493 |  iteration: 10677 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 733 loss: 1.58748 acc: 0.69043 | v_loss: 1.19926 v_acc: 0.70638 |  iteration: 10678 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 734 loss: 1.41148 acc: 0.70508 | v_loss: 1.34636 v_acc: 0.70247 |  iteration: 10679 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 735 loss: 1.47290 acc: 0.70801 | v_loss: 1.49633 v_acc: 0.69987 |  iteration: 10680 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 736 loss: 1.42557 acc: 0.70280 | v_loss: 1.34233 v_acc: 0.70833 |  iteration: 10681 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 737 loss: 1.51526 acc: 0.69141 | v_loss: 1.35782 v_acc: 0.70312 |  iteration: 10682 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 738 loss: 1.47288 acc: 0.70247 | v_loss: 1.24530 v_acc: 0.71680 |  iteration: 10683 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 739 loss: 1.42421 acc: 0.70573 | v_loss: 1.24693 v_acc: 0.70671 |  iteration: 10684 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 740 loss: 1.38787 acc: 0.71549 | v_loss: 1.26326 v_acc: 0.73568 |  iteration: 10685 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 741 loss: 1.36370 acc: 0.71354 | v_loss: 1.26601 v_acc: 0.72135 |  iteration: 10686 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 742 loss: 1.56452 acc: 0.69238 | v_loss: 1.35226 v_acc: 0.72689 |  iteration: 10687 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 743 loss: 1.46785 acc: 0.69173 | v_loss: 1.27633 v_acc: 0.72852 |  iteration: 10688 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 744 loss: 1.54089 acc: 0.69466 | v_loss: 1.31536 v_acc: 0.71745 |  iteration: 10689 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 745 loss: 1.43147 acc: 0.71191 | v_loss: 1.41413 v_acc: 0.70996 |  iteration: 10690 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 746 loss: 1.41909 acc: 0.70345 | v_loss: 1.38875 v_acc: 0.72038 |  iteration: 10691 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 747 loss: 1.52860 acc: 0.68815 | v_loss: 1.48253 v_acc: 0.69661 |  iteration: 10692 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 748 loss: 1.40509 acc: 0.71387 | v_loss: 1.41274 v_acc: 0.71973 |  iteration: 10693 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 749 loss: 1.42646 acc: 0.71257 | v_loss: 1.18020 v_acc: 0.74544 |  iteration: 10694 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 750 loss: 1.41135 acc: 0.70215 | v_loss: 1.26699 v_acc: 0.70573 |  iteration: 10695 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 751 loss: 1.51091 acc: 0.69499 | v_loss: 1.52238 v_acc: 0.70247 |  iteration: 10696 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 752 loss: 1.35773 acc: 0.71680 | v_loss: 1.22528 v_acc: 0.70671 |  iteration: 10697 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 753 loss: 1.37225 acc: 0.70833 | v_loss: 1.33099 v_acc: 0.71257 |  iteration: 10698 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 754 loss: 1.44514 acc: 0.70117 | v_loss: 1.37991 v_acc: 0.69368 |  iteration: 10699 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 755 loss: 1.43930 acc: 0.71419 | v_loss: 1.30115 v_acc: 0.71842 |  iteration: 10700 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 756 loss: 1.39956 acc: 0.70768 | v_loss: 1.37205 v_acc: 0.70215 |  iteration: 10701 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 757 loss: 1.48828 acc: 0.70410 | v_loss: 1.48695 v_acc: 0.72005 |  iteration: 10702 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 758 loss: 1.38364 acc: 0.70605 | v_loss: 1.32504 v_acc: 0.72786 |  iteration: 10703 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 759 loss: 1.39511 acc: 0.70768 | v_loss: 1.45733 v_acc: 0.70540 |  iteration: 10704 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 760 loss: 1.48652 acc: 0.69857 | v_loss: 1.36553 v_acc: 0.69857 |  iteration: 10705 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 761 loss: 1.35809 acc: 0.70410 | v_loss: 1.33493 v_acc: 0.70898 |  iteration: 10706 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 762 loss: 1.41630 acc: 0.70736 | v_loss: 1.53968 v_acc: 0.68880 |  iteration: 10707 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 763 loss: 1.45849 acc: 0.71159 | v_loss: 1.30500 v_acc: 0.72103 |  iteration: 10708 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 764 loss: 1.41535 acc: 0.70768 | v_loss: 1.57775 v_acc: 0.68620 |  iteration: 10709 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 765 loss: 1.37218 acc: 0.70964 | v_loss: 1.42948 v_acc: 0.69987 |  iteration: 10710 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 766 loss: 1.47283 acc: 0.70117 | v_loss: 1.51938 v_acc: 0.68913 |  iteration: 10711 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 767 loss: 1.52761 acc: 0.69727 | v_loss: 1.36920 v_acc: 0.69759 |  iteration: 10712 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 768 loss: 1.44672 acc: 0.69661 | v_loss: 1.32988 v_acc: 0.70215 |  iteration: 10713 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 769 loss: 1.40737 acc: 0.70378 | v_loss: 1.33563 v_acc: 0.69889 |  iteration: 10714 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 770 loss: 1.34819 acc: 0.70475 | v_loss: 1.32320 v_acc: 0.71517 |  iteration: 10715 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 771 loss: 1.39784 acc: 0.70150 | v_loss: 1.55679 v_acc: 0.69043 |  iteration: 10716 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 772 loss: 1.44333 acc: 0.69857 | v_loss: 1.37977 v_acc: 0.70964 |  iteration: 10717 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 773 loss: 1.48197 acc: 0.70117 | v_loss: 1.37663 v_acc: 0.70638 |  iteration: 10718 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 774 loss: 1.49029 acc: 0.70280 | v_loss: 1.39662 v_acc: 0.70833 |  iteration: 10719 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 775 loss: 1.42035 acc: 0.70345 | v_loss: 1.25715 v_acc: 0.71191 |  iteration: 10720 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 776 loss: 1.53894 acc: 0.69076 | v_loss: 1.44143 v_acc: 0.70020 |  iteration: 10721 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 777 loss: 1.44639 acc: 0.69694 | v_loss: 1.42768 v_acc: 0.71094 |  iteration: 10722 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 778 loss: 1.38549 acc: 0.71159 | v_loss: 1.28059 v_acc: 0.72201 |  iteration: 10723 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 779 loss: 1.37793 acc: 0.70671 | v_loss: 1.25463 v_acc: 0.72591 |  iteration: 10724 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 780 loss: 1.39906 acc: 0.70573 | v_loss: 1.37468 v_acc: 0.71647 |  iteration: 10725 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 781 loss: 1.46240 acc: 0.69727 | v_loss: 1.42127 v_acc: 0.70052 |  iteration: 10726 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 782 loss: 1.49696 acc: 0.69922 | v_loss: 1.42769 v_acc: 0.70378 |  iteration: 10727 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 783 loss: 1.37199 acc: 0.71322 | v_loss: 1.25936 v_acc: 0.71257 |  iteration: 10728 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 784 loss: 1.44325 acc: 0.69857 | v_loss: 1.39585 v_acc: 0.72884 |  iteration: 10729 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 785 loss: 1.50894 acc: 0.70020 | v_loss: 1.47029 v_acc: 0.70085 |  iteration: 10730 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 786 loss: 1.41328 acc: 0.70475 | v_loss: 1.39239 v_acc: 0.71908 |  iteration: 10731 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 787 loss: 1.43332 acc: 0.70410 | v_loss: 1.25825 v_acc: 0.71810 |  iteration: 10732 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 788 loss: 1.31236 acc: 0.71615 | v_loss: 1.21112 v_acc: 0.73535 |  iteration: 10733 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 789 loss: 1.34005 acc: 0.70801 | v_loss: 1.21551 v_acc: 0.72493 |  iteration: 10734 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 790 loss: 1.36308 acc: 0.70671 | v_loss: 1.26573 v_acc: 0.70573 |  iteration: 10735 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 791 loss: 1.41816 acc: 0.70703 | v_loss: 1.46391 v_acc: 0.70866 |  iteration: 10736 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 792 loss: 1.37538 acc: 0.71159 | v_loss: 1.28629 v_acc: 0.71777 |  iteration: 10737 teacher: 1 stage: sketch lr: 0.000427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 793 loss: 1.42430 acc: 0.70085 | v_loss: 1.52492 v_acc: 0.68848 |  iteration: 10738 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 794 loss: 1.41607 acc: 0.70866 | v_loss: 1.73041 v_acc: 0.68913 |  iteration: 10739 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 795 loss: 1.46083 acc: 0.69792 | v_loss: 1.55912 v_acc: 0.69531 |  iteration: 10740 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 796 loss: 1.43528 acc: 0.69889 | v_loss: 1.29684 v_acc: 0.72396 |  iteration: 10741 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 797 loss: 1.63175 acc: 0.68132 | v_loss: 1.36531 v_acc: 0.70866 |  iteration: 10742 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 798 loss: 1.45826 acc: 0.69824 | v_loss: 1.22401 v_acc: 0.72103 |  iteration: 10743 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 799 loss: 1.32754 acc: 0.71029 | v_loss: 1.42670 v_acc: 0.69857 |  iteration: 10744 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 800 loss: 1.40653 acc: 0.69499 | v_loss: 1.36312 v_acc: 0.70964 |  iteration: 10745 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 801 loss: 1.35500 acc: 0.70768 | v_loss: 1.36422 v_acc: 0.72949 |  iteration: 10746 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 802 loss: 1.38975 acc: 0.69596 | v_loss: 1.35522 v_acc: 0.71680 |  iteration: 10747 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 803 loss: 1.45095 acc: 0.70150 | v_loss: 1.37136 v_acc: 0.70345 |  iteration: 10748 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 804 loss: 1.44972 acc: 0.70540 | v_loss: 1.30070 v_acc: 0.72233 |  iteration: 10749 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 805 loss: 1.42099 acc: 0.70573 | v_loss: 1.31118 v_acc: 0.72135 |  iteration: 10750 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 806 loss: 1.40316 acc: 0.70540 | v_loss: 1.53097 v_acc: 0.69303 |  iteration: 10751 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 807 loss: 1.41972 acc: 0.70964 | v_loss: 1.33377 v_acc: 0.71452 |  iteration: 10752 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 808 loss: 1.49806 acc: 0.70605 | v_loss: 1.30094 v_acc: 0.71549 |  iteration: 10753 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 809 loss: 1.40087 acc: 0.69824 | v_loss: 1.28340 v_acc: 0.71973 |  iteration: 10754 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 810 loss: 1.44158 acc: 0.69531 | v_loss: 1.43315 v_acc: 0.70573 |  iteration: 10755 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 811 loss: 1.51247 acc: 0.69954 | v_loss: 1.31883 v_acc: 0.73210 |  iteration: 10756 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 812 loss: 1.35166 acc: 0.71549 | v_loss: 1.53764 v_acc: 0.71322 |  iteration: 10757 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 813 loss: 1.46324 acc: 0.69954 | v_loss: 1.29449 v_acc: 0.69531 |  iteration: 10758 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 814 loss: 1.44576 acc: 0.70898 | v_loss: 1.28329 v_acc: 0.70117 |  iteration: 10759 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 815 loss: 1.49372 acc: 0.69661 | v_loss: 1.45213 v_acc: 0.70508 |  iteration: 10760 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 816 loss: 1.46476 acc: 0.69531 | v_loss: 1.47548 v_acc: 0.70573 |  iteration: 10761 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 817 loss: 1.36469 acc: 0.70475 | v_loss: 1.52471 v_acc: 0.68815 |  iteration: 10762 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 818 loss: 1.48695 acc: 0.68945 | v_loss: 1.46520 v_acc: 0.70605 |  iteration: 10763 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 819 loss: 1.39914 acc: 0.70052 | v_loss: 1.42787 v_acc: 0.70052 |  iteration: 10764 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 820 loss: 1.34304 acc: 0.71159 | v_loss: 1.42307 v_acc: 0.70801 |  iteration: 10765 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 821 loss: 1.35231 acc: 0.70768 | v_loss: 1.40720 v_acc: 0.71257 |  iteration: 10766 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 822 loss: 1.40683 acc: 0.71126 | v_loss: 1.25565 v_acc: 0.71810 |  iteration: 10767 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 823 loss: 1.36739 acc: 0.71582 | v_loss: 1.34134 v_acc: 0.72266 |  iteration: 10768 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 824 loss: 1.40958 acc: 0.70671 | v_loss: 1.19389 v_acc: 0.70671 |  iteration: 10769 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 825 loss: 1.42810 acc: 0.70443 | v_loss: 1.34089 v_acc: 0.70150 |  iteration: 10770 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 826 loss: 1.47873 acc: 0.70866 | v_loss: 1.50656 v_acc: 0.69987 |  iteration: 10771 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 827 loss: 1.48297 acc: 0.69336 | v_loss: 1.35525 v_acc: 0.70540 |  iteration: 10772 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 828 loss: 1.48194 acc: 0.69987 | v_loss: 1.35672 v_acc: 0.69368 |  iteration: 10773 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 829 loss: 1.48188 acc: 0.69987 | v_loss: 1.27722 v_acc: 0.70573 |  iteration: 10774 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 830 loss: 1.53059 acc: 0.69596 | v_loss: 1.25616 v_acc: 0.70215 |  iteration: 10775 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 831 loss: 1.51012 acc: 0.68750 | v_loss: 1.25522 v_acc: 0.73340 |  iteration: 10776 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 832 loss: 1.51700 acc: 0.69401 | v_loss: 1.29303 v_acc: 0.71647 |  iteration: 10777 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 833 loss: 1.56791 acc: 0.69238 | v_loss: 1.35058 v_acc: 0.74089 |  iteration: 10778 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 834 loss: 1.39503 acc: 0.69857 | v_loss: 1.26745 v_acc: 0.72005 |  iteration: 10779 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 835 loss: 1.50897 acc: 0.69564 | v_loss: 1.31906 v_acc: 0.71810 |  iteration: 10780 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 836 loss: 1.46756 acc: 0.70150 | v_loss: 1.41810 v_acc: 0.71159 |  iteration: 10781 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 837 loss: 1.39878 acc: 0.70475 | v_loss: 1.38814 v_acc: 0.71810 |  iteration: 10782 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 838 loss: 1.45786 acc: 0.69727 | v_loss: 1.49015 v_acc: 0.69857 |  iteration: 10783 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 839 loss: 1.44184 acc: 0.70801 | v_loss: 1.41525 v_acc: 0.71745 |  iteration: 10784 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 840 loss: 1.45799 acc: 0.69368 | v_loss: 1.18216 v_acc: 0.74479 |  iteration: 10785 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 841 loss: 1.39651 acc: 0.70964 | v_loss: 1.27111 v_acc: 0.70378 |  iteration: 10786 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 842 loss: 1.58619 acc: 0.68750 | v_loss: 1.50271 v_acc: 0.70150 |  iteration: 10787 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 843 loss: 1.44136 acc: 0.70345 | v_loss: 1.23769 v_acc: 0.71647 |  iteration: 10788 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 844 loss: 1.43183 acc: 0.70410 | v_loss: 1.33151 v_acc: 0.71191 |  iteration: 10789 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 845 loss: 1.44215 acc: 0.69824 | v_loss: 1.38134 v_acc: 0.69076 |  iteration: 10790 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 846 loss: 1.51053 acc: 0.69889 | v_loss: 1.31768 v_acc: 0.70898 |  iteration: 10791 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 847 loss: 1.45344 acc: 0.70085 | v_loss: 1.37824 v_acc: 0.69206 |  iteration: 10792 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 848 loss: 1.46532 acc: 0.70605 | v_loss: 1.48883 v_acc: 0.70931 |  iteration: 10793 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 849 loss: 1.52464 acc: 0.69368 | v_loss: 1.31825 v_acc: 0.72363 |  iteration: 10794 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 850 loss: 1.36763 acc: 0.70801 | v_loss: 1.45625 v_acc: 0.70117 |  iteration: 10795 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 851 loss: 1.37907 acc: 0.70671 | v_loss: 1.36901 v_acc: 0.69857 |  iteration: 10796 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 852 loss: 1.47795 acc: 0.70475 | v_loss: 1.31860 v_acc: 0.70833 |  iteration: 10797 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 853 loss: 1.41076 acc: 0.70898 | v_loss: 1.57914 v_acc: 0.68522 |  iteration: 10798 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 854 loss: 1.39006 acc: 0.70312 | v_loss: 1.30277 v_acc: 0.72168 |  iteration: 10799 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 855 loss: 1.30972 acc: 0.72070 | v_loss: 1.60136 v_acc: 0.67969 |  iteration: 10800 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 856 loss: 1.50967 acc: 0.70052 | v_loss: 1.47195 v_acc: 0.69661 |  iteration: 10801 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 857 loss: 1.49424 acc: 0.70215 | v_loss: 1.54062 v_acc: 0.69238 |  iteration: 10802 teacher: 0 stage: sketch lr: 0.000425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 858 loss: 1.32056 acc: 0.71875 | v_loss: 1.36982 v_acc: 0.70182 |  iteration: 10803 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 859 loss: 1.53683 acc: 0.69271 | v_loss: 1.32463 v_acc: 0.70508 |  iteration: 10804 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 860 loss: 1.51490 acc: 0.69759 | v_loss: 1.32913 v_acc: 0.70378 |  iteration: 10805 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 861 loss: 1.48483 acc: 0.69759 | v_loss: 1.32579 v_acc: 0.71419 |  iteration: 10806 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 862 loss: 1.36362 acc: 0.70247 | v_loss: 1.52604 v_acc: 0.69173 |  iteration: 10807 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 863 loss: 1.47605 acc: 0.70703 | v_loss: 1.37169 v_acc: 0.70247 |  iteration: 10808 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 864 loss: 1.55103 acc: 0.69466 | v_loss: 1.36046 v_acc: 0.71126 |  iteration: 10809 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 865 loss: 1.40502 acc: 0.70801 | v_loss: 1.39208 v_acc: 0.71810 |  iteration: 10810 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 866 loss: 1.38292 acc: 0.70605 | v_loss: 1.28302 v_acc: 0.70215 |  iteration: 10811 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 867 loss: 1.33970 acc: 0.71354 | v_loss: 1.42644 v_acc: 0.69434 |  iteration: 10812 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 868 loss: 1.47171 acc: 0.68783 | v_loss: 1.42581 v_acc: 0.71452 |  iteration: 10813 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 869 loss: 1.41814 acc: 0.71061 | v_loss: 1.29869 v_acc: 0.71647 |  iteration: 10814 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 870 loss: 1.44325 acc: 0.70638 | v_loss: 1.26789 v_acc: 0.72526 |  iteration: 10815 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 871 loss: 1.40569 acc: 0.70020 | v_loss: 1.38743 v_acc: 0.71647 |  iteration: 10816 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 872 loss: 1.42046 acc: 0.70475 | v_loss: 1.44053 v_acc: 0.70052 |  iteration: 10817 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 873 loss: 1.47203 acc: 0.69954 | v_loss: 1.43561 v_acc: 0.70312 |  iteration: 10818 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 874 loss: 1.42104 acc: 0.70443 | v_loss: 1.23473 v_acc: 0.71419 |  iteration: 10819 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 875 loss: 1.47932 acc: 0.69434 | v_loss: 1.39778 v_acc: 0.72819 |  iteration: 10820 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 876 loss: 1.45810 acc: 0.70508 | v_loss: 1.48761 v_acc: 0.69759 |  iteration: 10821 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 877 loss: 1.57624 acc: 0.69499 | v_loss: 1.43047 v_acc: 0.72201 |  iteration: 10822 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 878 loss: 1.43386 acc: 0.71354 | v_loss: 1.24792 v_acc: 0.71810 |  iteration: 10823 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 879 loss: 1.45628 acc: 0.71094 | v_loss: 1.20524 v_acc: 0.73535 |  iteration: 10824 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 880 loss: 1.36496 acc: 0.70475 | v_loss: 1.21728 v_acc: 0.72656 |  iteration: 10825 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 881 loss: 1.54702 acc: 0.68652 | v_loss: 1.28957 v_acc: 0.70703 |  iteration: 10826 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 882 loss: 1.52231 acc: 0.68457 | v_loss: 1.44641 v_acc: 0.69466 |  iteration: 10827 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 883 loss: 1.51411 acc: 0.69629 | v_loss: 1.27688 v_acc: 0.71484 |  iteration: 10828 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 884 loss: 1.56430 acc: 0.69564 | v_loss: 1.43418 v_acc: 0.72949 |  iteration: 10829 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 885 loss: 1.39469 acc: 0.70605 | v_loss: 1.62558 v_acc: 0.69466 |  iteration: 10830 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 886 loss: 1.43055 acc: 0.69629 | v_loss: 1.50649 v_acc: 0.70410 |  iteration: 10831 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 887 loss: 1.46397 acc: 0.69271 | v_loss: 1.29618 v_acc: 0.72005 |  iteration: 10832 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 888 loss: 1.54210 acc: 0.69857 | v_loss: 1.37230 v_acc: 0.70345 |  iteration: 10833 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 889 loss: 1.48347 acc: 0.69499 | v_loss: 1.22702 v_acc: 0.71842 |  iteration: 10834 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 890 loss: 1.40809 acc: 0.70312 | v_loss: 1.40853 v_acc: 0.70475 |  iteration: 10835 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 891 loss: 1.50162 acc: 0.69987 | v_loss: 1.35897 v_acc: 0.71484 |  iteration: 10836 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 892 loss: 1.44750 acc: 0.70052 | v_loss: 1.34873 v_acc: 0.72949 |  iteration: 10837 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 893 loss: 1.39069 acc: 0.70052 | v_loss: 1.35824 v_acc: 0.71842 |  iteration: 10838 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 894 loss: 1.47316 acc: 0.69987 | v_loss: 1.38060 v_acc: 0.71029 |  iteration: 10839 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 895 loss: 1.36480 acc: 0.70508 | v_loss: 1.28923 v_acc: 0.72819 |  iteration: 10840 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 896 loss: 1.40258 acc: 0.70671 | v_loss: 1.30192 v_acc: 0.71908 |  iteration: 10841 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 897 loss: 1.52589 acc: 0.69466 | v_loss: 1.48931 v_acc: 0.69108 |  iteration: 10842 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 898 loss: 1.50791 acc: 0.70085 | v_loss: 1.34061 v_acc: 0.71452 |  iteration: 10843 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 899 loss: 1.44300 acc: 0.70540 | v_loss: 1.29797 v_acc: 0.71777 |  iteration: 10844 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 900 loss: 1.44040 acc: 0.70020 | v_loss: 1.28750 v_acc: 0.72201 |  iteration: 10845 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 901 loss: 1.39901 acc: 0.70898 | v_loss: 1.41651 v_acc: 0.70768 |  iteration: 10846 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 902 loss: 1.42341 acc: 0.71191 | v_loss: 1.31661 v_acc: 0.73210 |  iteration: 10847 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 903 loss: 1.42539 acc: 0.70671 | v_loss: 1.52827 v_acc: 0.71322 |  iteration: 10848 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 904 loss: 1.41043 acc: 0.70052 | v_loss: 1.29908 v_acc: 0.69531 |  iteration: 10849 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 905 loss: 1.44426 acc: 0.69857 | v_loss: 1.28461 v_acc: 0.70117 |  iteration: 10850 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 906 loss: 1.36868 acc: 0.70736 | v_loss: 1.45502 v_acc: 0.70312 |  iteration: 10851 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 907 loss: 1.39012 acc: 0.71419 | v_loss: 1.47640 v_acc: 0.70378 |  iteration: 10852 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 908 loss: 1.44876 acc: 0.69792 | v_loss: 1.51602 v_acc: 0.69368 |  iteration: 10853 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 909 loss: 1.48429 acc: 0.69336 | v_loss: 1.47603 v_acc: 0.70833 |  iteration: 10854 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 910 loss: 1.30409 acc: 0.72135 | v_loss: 1.42418 v_acc: 0.70085 |  iteration: 10855 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 911 loss: 1.40166 acc: 0.70703 | v_loss: 1.41659 v_acc: 0.70540 |  iteration: 10856 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 912 loss: 1.49020 acc: 0.69759 | v_loss: 1.42338 v_acc: 0.70345 |  iteration: 10857 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 913 loss: 1.60574 acc: 0.67578 | v_loss: 1.26734 v_acc: 0.71224 |  iteration: 10858 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 914 loss: 1.48828 acc: 0.69987 | v_loss: 1.32482 v_acc: 0.72493 |  iteration: 10859 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 915 loss: 1.48870 acc: 0.69499 | v_loss: 1.20546 v_acc: 0.70671 |  iteration: 10860 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 916 loss: 1.36386 acc: 0.71647 | v_loss: 1.35386 v_acc: 0.70150 |  iteration: 10861 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 917 loss: 1.36989 acc: 0.70378 | v_loss: 1.49445 v_acc: 0.69987 |  iteration: 10862 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 918 loss: 1.32285 acc: 0.71094 | v_loss: 1.33404 v_acc: 0.70540 |  iteration: 10863 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 919 loss: 1.63639 acc: 0.68685 | v_loss: 1.36071 v_acc: 0.69368 |  iteration: 10864 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 920 loss: 1.44987 acc: 0.69857 | v_loss: 1.26325 v_acc: 0.70573 |  iteration: 10865 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 921 loss: 1.40548 acc: 0.71159 | v_loss: 1.26146 v_acc: 0.70215 |  iteration: 10866 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 922 loss: 1.52796 acc: 0.69564 | v_loss: 1.23939 v_acc: 0.73340 |  iteration: 10867 teacher: 0 stage: sketch lr: 0.000424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 923 loss: 1.45038 acc: 0.70117 | v_loss: 1.27719 v_acc: 0.71647 |  iteration: 10868 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 924 loss: 1.34748 acc: 0.71517 | v_loss: 1.34123 v_acc: 0.74089 |  iteration: 10869 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 925 loss: 1.59665 acc: 0.68392 | v_loss: 1.26382 v_acc: 0.72005 |  iteration: 10870 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 926 loss: 1.52537 acc: 0.68848 | v_loss: 1.30778 v_acc: 0.71582 |  iteration: 10871 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 927 loss: 1.39864 acc: 0.70768 | v_loss: 1.41945 v_acc: 0.71289 |  iteration: 10872 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 928 loss: 1.41055 acc: 0.70247 | v_loss: 1.39251 v_acc: 0.72298 |  iteration: 10873 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 929 loss: 1.37496 acc: 0.70605 | v_loss: 1.48368 v_acc: 0.69922 |  iteration: 10874 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 930 loss: 1.48760 acc: 0.69531 | v_loss: 1.42923 v_acc: 0.72135 |  iteration: 10875 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 931 loss: 1.41789 acc: 0.70736 | v_loss: 1.18155 v_acc: 0.74447 |  iteration: 10876 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 932 loss: 1.49668 acc: 0.69857 | v_loss: 1.25151 v_acc: 0.70964 |  iteration: 10877 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 933 loss: 1.46006 acc: 0.70443 | v_loss: 1.53232 v_acc: 0.69987 |  iteration: 10878 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 934 loss: 1.37081 acc: 0.71257 | v_loss: 1.22546 v_acc: 0.70638 |  iteration: 10879 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 935 loss: 1.42419 acc: 0.70020 | v_loss: 1.33748 v_acc: 0.71354 |  iteration: 10880 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 936 loss: 1.44706 acc: 0.69857 | v_loss: 1.37679 v_acc: 0.69531 |  iteration: 10881 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 937 loss: 1.38040 acc: 0.71680 | v_loss: 1.29686 v_acc: 0.70996 |  iteration: 10882 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 938 loss: 1.39912 acc: 0.70410 | v_loss: 1.37298 v_acc: 0.69434 |  iteration: 10883 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 939 loss: 1.44525 acc: 0.70312 | v_loss: 1.48552 v_acc: 0.70931 |  iteration: 10884 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 940 loss: 1.50295 acc: 0.69857 | v_loss: 1.32222 v_acc: 0.72819 |  iteration: 10885 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 941 loss: 1.37382 acc: 0.69954 | v_loss: 1.46495 v_acc: 0.70312 |  iteration: 10886 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 942 loss: 1.45261 acc: 0.70833 | v_loss: 1.34687 v_acc: 0.69889 |  iteration: 10887 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 943 loss: 1.49526 acc: 0.69238 | v_loss: 1.33869 v_acc: 0.70898 |  iteration: 10888 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 944 loss: 1.51901 acc: 0.69434 | v_loss: 1.56482 v_acc: 0.68392 |  iteration: 10889 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 945 loss: 1.48926 acc: 0.69987 | v_loss: 1.30005 v_acc: 0.72168 |  iteration: 10890 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 946 loss: 1.35350 acc: 0.71387 | v_loss: 1.60393 v_acc: 0.67969 |  iteration: 10891 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 947 loss: 1.51217 acc: 0.69531 | v_loss: 1.47037 v_acc: 0.69661 |  iteration: 10892 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 948 loss: 1.42629 acc: 0.69987 | v_loss: 1.51842 v_acc: 0.69238 |  iteration: 10893 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 949 loss: 1.52570 acc: 0.69889 | v_loss: 1.37788 v_acc: 0.70182 |  iteration: 10894 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 950 loss: 1.43799 acc: 0.70378 | v_loss: 1.32295 v_acc: 0.70638 |  iteration: 10895 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 951 loss: 1.49048 acc: 0.69759 | v_loss: 1.33768 v_acc: 0.69889 |  iteration: 10896 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 952 loss: 1.39418 acc: 0.71094 | v_loss: 1.33161 v_acc: 0.71419 |  iteration: 10897 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 953 loss: 1.43414 acc: 0.70150 | v_loss: 1.53160 v_acc: 0.69173 |  iteration: 10898 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 954 loss: 1.50215 acc: 0.69434 | v_loss: 1.39041 v_acc: 0.70247 |  iteration: 10899 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 955 loss: 1.38420 acc: 0.70085 | v_loss: 1.37929 v_acc: 0.71126 |  iteration: 10900 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 956 loss: 1.41474 acc: 0.70703 | v_loss: 1.39698 v_acc: 0.71810 |  iteration: 10901 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 957 loss: 1.40930 acc: 0.70866 | v_loss: 1.28343 v_acc: 0.70215 |  iteration: 10902 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 958 loss: 1.38188 acc: 0.70801 | v_loss: 1.43369 v_acc: 0.69564 |  iteration: 10903 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 959 loss: 1.42111 acc: 0.70703 | v_loss: 1.43654 v_acc: 0.71289 |  iteration: 10904 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 960 loss: 1.38376 acc: 0.70312 | v_loss: 1.29148 v_acc: 0.72201 |  iteration: 10905 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 961 loss: 1.44420 acc: 0.70182 | v_loss: 1.26201 v_acc: 0.72591 |  iteration: 10906 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 962 loss: 1.41727 acc: 0.70475 | v_loss: 1.38618 v_acc: 0.72266 |  iteration: 10907 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 963 loss: 1.49310 acc: 0.69303 | v_loss: 1.42289 v_acc: 0.70410 |  iteration: 10908 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 964 loss: 1.44033 acc: 0.70280 | v_loss: 1.42734 v_acc: 0.70833 |  iteration: 10909 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 965 loss: 1.44861 acc: 0.70443 | v_loss: 1.22287 v_acc: 0.72591 |  iteration: 10910 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 966 loss: 1.40837 acc: 0.70117 | v_loss: 1.38510 v_acc: 0.73112 |  iteration: 10911 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 967 loss: 1.42847 acc: 0.70150 | v_loss: 1.46636 v_acc: 0.69564 |  iteration: 10912 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 968 loss: 1.47794 acc: 0.69857 | v_loss: 1.40108 v_acc: 0.71842 |  iteration: 10913 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 969 loss: 1.38445 acc: 0.70247 | v_loss: 1.27340 v_acc: 0.71810 |  iteration: 10914 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 970 loss: 1.45045 acc: 0.70085 | v_loss: 1.23032 v_acc: 0.73535 |  iteration: 10915 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 971 loss: 1.45456 acc: 0.70866 | v_loss: 1.22253 v_acc: 0.72656 |  iteration: 10916 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 972 loss: 1.48006 acc: 0.70801 | v_loss: 1.30068 v_acc: 0.70703 |  iteration: 10917 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 973 loss: 1.59137 acc: 0.68652 | v_loss: 1.45276 v_acc: 0.69466 |  iteration: 10918 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 974 loss: 1.44787 acc: 0.69368 | v_loss: 1.28195 v_acc: 0.71484 |  iteration: 10919 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 975 loss: 1.50956 acc: 0.70150 | v_loss: 1.42543 v_acc: 0.72949 |  iteration: 10920 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 976 loss: 1.53028 acc: 0.69303 | v_loss: 1.67035 v_acc: 0.69303 |  iteration: 10921 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 977 loss: 1.38847 acc: 0.70573 | v_loss: 1.54033 v_acc: 0.69727 |  iteration: 10922 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 978 loss: 1.55123 acc: 0.69043 | v_loss: 1.30010 v_acc: 0.72396 |  iteration: 10923 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 979 loss: 1.46090 acc: 0.70671 | v_loss: 1.36726 v_acc: 0.70996 |  iteration: 10924 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 980 loss: 1.43150 acc: 0.70508 | v_loss: 1.21813 v_acc: 0.72103 |  iteration: 10925 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 981 loss: 1.39739 acc: 0.70345 | v_loss: 1.40051 v_acc: 0.70443 |  iteration: 10926 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 982 loss: 1.31683 acc: 0.71126 | v_loss: 1.36874 v_acc: 0.71842 |  iteration: 10927 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 983 loss: 1.29766 acc: 0.71680 | v_loss: 1.35824 v_acc: 0.72884 |  iteration: 10928 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 984 loss: 1.47396 acc: 0.69596 | v_loss: 1.37043 v_acc: 0.72005 |  iteration: 10929 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 985 loss: 1.38477 acc: 0.70898 | v_loss: 1.37858 v_acc: 0.71029 |  iteration: 10930 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 986 loss: 1.35103 acc: 0.71094 | v_loss: 1.28624 v_acc: 0.72559 |  iteration: 10931 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 987 loss: 1.52106 acc: 0.69010 | v_loss: 1.30510 v_acc: 0.72005 |  iteration: 10932 teacher: 1 stage: sketch lr: 0.000423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 988 loss: 1.37378 acc: 0.71419 | v_loss: 1.49942 v_acc: 0.69043 |  iteration: 10933 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 989 loss: 1.33434 acc: 0.71159 | v_loss: 1.34031 v_acc: 0.70833 |  iteration: 10934 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 990 loss: 1.44165 acc: 0.70508 | v_loss: 1.29056 v_acc: 0.71582 |  iteration: 10935 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 991 loss: 1.50399 acc: 0.69368 | v_loss: 1.28381 v_acc: 0.72201 |  iteration: 10936 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 992 loss: 1.47060 acc: 0.70475 | v_loss: 1.41937 v_acc: 0.70768 |  iteration: 10937 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 993 loss: 1.44208 acc: 0.69694 | v_loss: 1.31215 v_acc: 0.73112 |  iteration: 10938 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 994 loss: 1.41588 acc: 0.70182 | v_loss: 1.55574 v_acc: 0.71582 |  iteration: 10939 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 995 loss: 1.59431 acc: 0.68620 | v_loss: 1.29723 v_acc: 0.70150 |  iteration: 10940 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 996 loss: 1.46427 acc: 0.69661 | v_loss: 1.29197 v_acc: 0.70573 |  iteration: 10941 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 997 loss: 1.56340 acc: 0.68457 | v_loss: 1.43165 v_acc: 0.70378 |  iteration: 10942 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 998 loss: 1.39980 acc: 0.70378 | v_loss: 1.46547 v_acc: 0.70378 |  iteration: 10943 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 999 loss: 1.42898 acc: 0.70996 | v_loss: 1.51176 v_acc: 0.68978 |  iteration: 10944 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1000 loss: 1.41664 acc: 0.70020 | v_loss: 1.46833 v_acc: 0.70638 |  iteration: 10945 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1001 loss: 1.41370 acc: 0.70898 | v_loss: 1.43955 v_acc: 0.70573 |  iteration: 10946 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1002 loss: 1.62384 acc: 0.69076 | v_loss: 1.43074 v_acc: 0.70475 |  iteration: 10947 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1003 loss: 1.47694 acc: 0.69434 | v_loss: 1.41790 v_acc: 0.70312 |  iteration: 10948 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1004 loss: 1.42293 acc: 0.69889 | v_loss: 1.27677 v_acc: 0.71257 |  iteration: 10949 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1005 loss: 1.47901 acc: 0.69401 | v_loss: 1.34094 v_acc: 0.72396 |  iteration: 10950 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1006 loss: 1.44210 acc: 0.70443 | v_loss: 1.21657 v_acc: 0.70671 |  iteration: 10951 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1007 loss: 1.47362 acc: 0.69629 | v_loss: 1.34733 v_acc: 0.70150 |  iteration: 10952 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1008 loss: 1.48714 acc: 0.69368 | v_loss: 1.49188 v_acc: 0.69987 |  iteration: 10953 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1009 loss: 1.34638 acc: 0.70931 | v_loss: 1.34420 v_acc: 0.70540 |  iteration: 10954 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1010 loss: 1.38417 acc: 0.71029 | v_loss: 1.35904 v_acc: 0.69368 |  iteration: 10955 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1011 loss: 1.47862 acc: 0.70182 | v_loss: 1.26837 v_acc: 0.70573 |  iteration: 10956 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1012 loss: 1.42120 acc: 0.71289 | v_loss: 1.27365 v_acc: 0.70215 |  iteration: 10957 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1013 loss: 1.47580 acc: 0.70280 | v_loss: 1.23400 v_acc: 0.73340 |  iteration: 10958 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1014 loss: 1.41461 acc: 0.70540 | v_loss: 1.28111 v_acc: 0.71647 |  iteration: 10959 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1015 loss: 1.38909 acc: 0.70540 | v_loss: 1.33999 v_acc: 0.74089 |  iteration: 10960 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1016 loss: 1.47234 acc: 0.70280 | v_loss: 1.26438 v_acc: 0.72005 |  iteration: 10961 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1017 loss: 1.37327 acc: 0.70475 | v_loss: 1.31781 v_acc: 0.71647 |  iteration: 10962 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1018 loss: 1.48398 acc: 0.69857 | v_loss: 1.41697 v_acc: 0.71452 |  iteration: 10963 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1019 loss: 1.44398 acc: 0.71061 | v_loss: 1.40926 v_acc: 0.71875 |  iteration: 10964 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1020 loss: 1.41360 acc: 0.71191 | v_loss: 1.49917 v_acc: 0.70182 |  iteration: 10965 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1021 loss: 1.48816 acc: 0.69824 | v_loss: 1.42297 v_acc: 0.71777 |  iteration: 10966 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1022 loss: 1.42623 acc: 0.71191 | v_loss: 1.17335 v_acc: 0.74447 |  iteration: 10967 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1023 loss: 1.41699 acc: 0.69889 | v_loss: 1.26465 v_acc: 0.71322 |  iteration: 10968 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1024 loss: 1.44393 acc: 0.69922 | v_loss: 1.50976 v_acc: 0.69987 |  iteration: 10969 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1025 loss: 1.51796 acc: 0.70345 | v_loss: 1.22701 v_acc: 0.70671 |  iteration: 10970 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1026 loss: 1.44297 acc: 0.70312 | v_loss: 1.33734 v_acc: 0.71257 |  iteration: 10971 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1027 loss: 1.40139 acc: 0.70573 | v_loss: 1.36451 v_acc: 0.69368 |  iteration: 10972 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1028 loss: 1.47523 acc: 0.70150 | v_loss: 1.31373 v_acc: 0.71842 |  iteration: 10973 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1029 loss: 1.50508 acc: 0.69141 | v_loss: 1.37664 v_acc: 0.69629 |  iteration: 10974 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1030 loss: 1.40781 acc: 0.70475 | v_loss: 1.46160 v_acc: 0.70931 |  iteration: 10975 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1031 loss: 1.49507 acc: 0.70378 | v_loss: 1.31503 v_acc: 0.72363 |  iteration: 10976 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1032 loss: 1.38652 acc: 0.70898 | v_loss: 1.44439 v_acc: 0.70117 |  iteration: 10977 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1033 loss: 1.42498 acc: 0.70052 | v_loss: 1.35637 v_acc: 0.70085 |  iteration: 10978 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1034 loss: 1.44855 acc: 0.70312 | v_loss: 1.33209 v_acc: 0.70768 |  iteration: 10979 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1035 loss: 1.52805 acc: 0.68783 | v_loss: 1.55168 v_acc: 0.68815 |  iteration: 10980 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1036 loss: 1.50966 acc: 0.68913 | v_loss: 1.30388 v_acc: 0.72005 |  iteration: 10981 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1037 loss: 1.36871 acc: 0.71029 | v_loss: 1.59228 v_acc: 0.67969 |  iteration: 10982 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1038 loss: 1.43707 acc: 0.70378 | v_loss: 1.46227 v_acc: 0.69661 |  iteration: 10983 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1039 loss: 1.38508 acc: 0.70215 | v_loss: 1.53593 v_acc: 0.69238 |  iteration: 10984 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1040 loss: 1.39167 acc: 0.70410 | v_loss: 1.37345 v_acc: 0.70182 |  iteration: 10985 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1041 loss: 1.38201 acc: 0.70182 | v_loss: 1.32911 v_acc: 0.70638 |  iteration: 10986 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1042 loss: 1.45499 acc: 0.70605 | v_loss: 1.32610 v_acc: 0.70410 |  iteration: 10987 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1043 loss: 1.55161 acc: 0.70150 | v_loss: 1.33222 v_acc: 0.71842 |  iteration: 10988 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1044 loss: 1.46105 acc: 0.70312 | v_loss: 1.52889 v_acc: 0.69173 |  iteration: 10989 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1045 loss: 1.49719 acc: 0.69954 | v_loss: 1.38508 v_acc: 0.70247 |  iteration: 10990 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1046 loss: 1.43566 acc: 0.70280 | v_loss: 1.36215 v_acc: 0.71126 |  iteration: 10991 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1047 loss: 1.50311 acc: 0.69434 | v_loss: 1.38928 v_acc: 0.71810 |  iteration: 10992 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1048 loss: 1.48122 acc: 0.69271 | v_loss: 1.29230 v_acc: 0.70215 |  iteration: 10993 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1049 loss: 1.37860 acc: 0.70736 | v_loss: 1.44059 v_acc: 0.69792 |  iteration: 10994 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1050 loss: 1.41697 acc: 0.71419 | v_loss: 1.42257 v_acc: 0.71224 |  iteration: 10995 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1051 loss: 1.45897 acc: 0.69889 | v_loss: 1.28800 v_acc: 0.72266 |  iteration: 10996 teacher: 0 stage: sketch lr: 0.000421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1052 loss: 1.43144 acc: 0.70671 | v_loss: 1.24980 v_acc: 0.72526 |  iteration: 10997 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1053 loss: 1.48254 acc: 0.70215 | v_loss: 1.37854 v_acc: 0.71745 |  iteration: 10998 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1054 loss: 1.44590 acc: 0.69466 | v_loss: 1.41849 v_acc: 0.70345 |  iteration: 10999 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1055 loss: 1.46523 acc: 0.69759 | v_loss: 1.43178 v_acc: 0.70410 |  iteration: 11000 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1056 loss: 1.47656 acc: 0.69857 | v_loss: 1.23150 v_acc: 0.71484 |  iteration: 11001 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1057 loss: 1.50864 acc: 0.69173 | v_loss: 1.41040 v_acc: 0.72852 |  iteration: 11002 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1058 loss: 1.51398 acc: 0.69727 | v_loss: 1.48293 v_acc: 0.69694 |  iteration: 11003 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1059 loss: 1.49843 acc: 0.69629 | v_loss: 1.39408 v_acc: 0.72786 |  iteration: 11004 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1060 loss: 1.49400 acc: 0.69954 | v_loss: 1.26637 v_acc: 0.71419 |  iteration: 11005 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1061 loss: 1.44918 acc: 0.70410 | v_loss: 1.23717 v_acc: 0.73535 |  iteration: 11006 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1062 loss: 1.38150 acc: 0.70671 | v_loss: 1.22695 v_acc: 0.72656 |  iteration: 11007 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1063 loss: 1.41161 acc: 0.69661 | v_loss: 1.28811 v_acc: 0.70638 |  iteration: 11008 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1064 loss: 1.44000 acc: 0.70182 | v_loss: 1.44634 v_acc: 0.70671 |  iteration: 11009 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1065 loss: 1.45180 acc: 0.70020 | v_loss: 1.27480 v_acc: 0.71549 |  iteration: 11010 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1066 loss: 1.47936 acc: 0.70117 | v_loss: 1.48274 v_acc: 0.70475 |  iteration: 11011 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1067 loss: 1.41175 acc: 0.70866 | v_loss: 1.68395 v_acc: 0.69141 |  iteration: 11012 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1068 loss: 1.46029 acc: 0.69303 | v_loss: 1.53067 v_acc: 0.69531 |  iteration: 11013 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1069 loss: 1.41379 acc: 0.70671 | v_loss: 1.29786 v_acc: 0.72168 |  iteration: 11014 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1070 loss: 1.48218 acc: 0.70182 | v_loss: 1.37208 v_acc: 0.70378 |  iteration: 11015 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1071 loss: 1.34297 acc: 0.70996 | v_loss: 1.21367 v_acc: 0.72233 |  iteration: 11016 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1072 loss: 1.45152 acc: 0.70215 | v_loss: 1.41810 v_acc: 0.70150 |  iteration: 11017 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1073 loss: 1.32849 acc: 0.71419 | v_loss: 1.36302 v_acc: 0.71875 |  iteration: 11018 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1074 loss: 1.43908 acc: 0.70280 | v_loss: 1.36529 v_acc: 0.73014 |  iteration: 11019 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1075 loss: 1.57147 acc: 0.69629 | v_loss: 1.37048 v_acc: 0.71973 |  iteration: 11020 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1076 loss: 1.54851 acc: 0.69629 | v_loss: 1.36975 v_acc: 0.70410 |  iteration: 11021 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1077 loss: 1.51387 acc: 0.69108 | v_loss: 1.29780 v_acc: 0.72201 |  iteration: 11022 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1078 loss: 1.52807 acc: 0.70052 | v_loss: 1.30956 v_acc: 0.72005 |  iteration: 11023 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1079 loss: 1.50246 acc: 0.69596 | v_loss: 1.51262 v_acc: 0.69043 |  iteration: 11024 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1080 loss: 1.39926 acc: 0.71257 | v_loss: 1.34192 v_acc: 0.70833 |  iteration: 11025 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1081 loss: 1.43783 acc: 0.70996 | v_loss: 1.30746 v_acc: 0.71582 |  iteration: 11026 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1082 loss: 1.50191 acc: 0.69629 | v_loss: 1.29538 v_acc: 0.72201 |  iteration: 11027 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1083 loss: 1.49494 acc: 0.70736 | v_loss: 1.41986 v_acc: 0.70768 |  iteration: 11028 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1084 loss: 1.50091 acc: 0.69661 | v_loss: 1.31137 v_acc: 0.73210 |  iteration: 11029 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1085 loss: 1.49024 acc: 0.69466 | v_loss: 1.53980 v_acc: 0.71452 |  iteration: 11030 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1086 loss: 1.53033 acc: 0.69824 | v_loss: 1.28398 v_acc: 0.69759 |  iteration: 11031 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1087 loss: 1.41182 acc: 0.69889 | v_loss: 1.28610 v_acc: 0.70573 |  iteration: 11032 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1088 loss: 1.51147 acc: 0.70475 | v_loss: 1.44752 v_acc: 0.70378 |  iteration: 11033 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1089 loss: 1.38946 acc: 0.70215 | v_loss: 1.48067 v_acc: 0.70150 |  iteration: 11034 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1090 loss: 1.44697 acc: 0.69694 | v_loss: 1.52397 v_acc: 0.69368 |  iteration: 11035 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1091 loss: 1.36025 acc: 0.71908 | v_loss: 1.47044 v_acc: 0.70833 |  iteration: 11036 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1092 loss: 1.37289 acc: 0.71810 | v_loss: 1.43328 v_acc: 0.70085 |  iteration: 11037 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1093 loss: 1.49257 acc: 0.68522 | v_loss: 1.41394 v_acc: 0.70931 |  iteration: 11038 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1094 loss: 1.32563 acc: 0.70605 | v_loss: 1.40163 v_acc: 0.70443 |  iteration: 11039 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1095 loss: 1.47694 acc: 0.70150 | v_loss: 1.25603 v_acc: 0.71159 |  iteration: 11040 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1096 loss: 1.52112 acc: 0.69336 | v_loss: 1.34487 v_acc: 0.72396 |  iteration: 11041 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1097 loss: 1.45393 acc: 0.70117 | v_loss: 1.19381 v_acc: 0.70638 |  iteration: 11042 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1098 loss: 1.43251 acc: 0.70085 | v_loss: 1.34193 v_acc: 0.70247 |  iteration: 11043 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1099 loss: 1.43293 acc: 0.70475 | v_loss: 1.51642 v_acc: 0.69954 |  iteration: 11044 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1100 loss: 1.55063 acc: 0.69368 | v_loss: 1.33841 v_acc: 0.71484 |  iteration: 11045 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1101 loss: 1.49082 acc: 0.69368 | v_loss: 1.36463 v_acc: 0.70312 |  iteration: 11046 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1102 loss: 1.49065 acc: 0.69466 | v_loss: 1.24032 v_acc: 0.71680 |  iteration: 11047 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1103 loss: 1.39758 acc: 0.71224 | v_loss: 1.24695 v_acc: 0.70671 |  iteration: 11048 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1104 loss: 1.36147 acc: 0.71940 | v_loss: 1.24313 v_acc: 0.73568 |  iteration: 11049 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1105 loss: 1.47704 acc: 0.69792 | v_loss: 1.26861 v_acc: 0.72168 |  iteration: 11050 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1106 loss: 1.40124 acc: 0.71126 | v_loss: 1.33026 v_acc: 0.74089 |  iteration: 11051 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1107 loss: 1.36891 acc: 0.70410 | v_loss: 1.25917 v_acc: 0.72005 |  iteration: 11052 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1108 loss: 1.45203 acc: 0.71061 | v_loss: 1.30812 v_acc: 0.71582 |  iteration: 11053 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1109 loss: 1.45476 acc: 0.69564 | v_loss: 1.40940 v_acc: 0.71224 |  iteration: 11054 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1110 loss: 1.29770 acc: 0.70931 | v_loss: 1.39407 v_acc: 0.72038 |  iteration: 11055 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1111 loss: 1.53673 acc: 0.68913 | v_loss: 1.50078 v_acc: 0.69954 |  iteration: 11056 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1112 loss: 1.49855 acc: 0.69043 | v_loss: 1.43993 v_acc: 0.71615 |  iteration: 11057 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1113 loss: 1.41433 acc: 0.70736 | v_loss: 1.18245 v_acc: 0.74316 |  iteration: 11058 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1114 loss: 1.36519 acc: 0.70345 | v_loss: 1.27153 v_acc: 0.70345 |  iteration: 11059 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1115 loss: 1.50807 acc: 0.69661 | v_loss: 1.53211 v_acc: 0.70280 |  iteration: 11060 teacher: 0 stage: sketch lr: 0.000420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1116 loss: 1.50911 acc: 0.69238 | v_loss: 1.22828 v_acc: 0.71647 |  iteration: 11061 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1117 loss: 1.40512 acc: 0.69857 | v_loss: 1.32656 v_acc: 0.71159 |  iteration: 11062 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1118 loss: 1.39330 acc: 0.70898 | v_loss: 1.35862 v_acc: 0.69336 |  iteration: 11063 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1119 loss: 1.40881 acc: 0.70801 | v_loss: 1.29725 v_acc: 0.71191 |  iteration: 11064 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1120 loss: 1.41391 acc: 0.70085 | v_loss: 1.35501 v_acc: 0.70215 |  iteration: 11065 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1121 loss: 1.46561 acc: 0.70215 | v_loss: 1.48156 v_acc: 0.72005 |  iteration: 11066 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1122 loss: 1.39513 acc: 0.69857 | v_loss: 1.32887 v_acc: 0.72786 |  iteration: 11067 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1123 loss: 1.48214 acc: 0.70215 | v_loss: 1.46534 v_acc: 0.70540 |  iteration: 11068 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1124 loss: 1.42129 acc: 0.70638 | v_loss: 1.36664 v_acc: 0.69857 |  iteration: 11069 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1125 loss: 1.34040 acc: 0.71126 | v_loss: 1.33005 v_acc: 0.70833 |  iteration: 11070 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1126 loss: 1.40401 acc: 0.71061 | v_loss: 1.57571 v_acc: 0.68522 |  iteration: 11071 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1127 loss: 1.39332 acc: 0.70605 | v_loss: 1.31731 v_acc: 0.72005 |  iteration: 11072 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1128 loss: 1.40769 acc: 0.69271 | v_loss: 1.58637 v_acc: 0.68424 |  iteration: 11073 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1129 loss: 1.41960 acc: 0.70215 | v_loss: 1.44989 v_acc: 0.69792 |  iteration: 11074 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1130 loss: 1.43412 acc: 0.70508 | v_loss: 1.53610 v_acc: 0.69238 |  iteration: 11075 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1131 loss: 1.37848 acc: 0.71289 | v_loss: 1.37841 v_acc: 0.70182 |  iteration: 11076 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1132 loss: 1.41286 acc: 0.70671 | v_loss: 1.31876 v_acc: 0.70638 |  iteration: 11077 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1133 loss: 1.48588 acc: 0.69596 | v_loss: 1.33439 v_acc: 0.70410 |  iteration: 11078 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1134 loss: 1.49830 acc: 0.70182 | v_loss: 1.34359 v_acc: 0.71842 |  iteration: 11079 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1135 loss: 1.39455 acc: 0.71061 | v_loss: 1.55501 v_acc: 0.68978 |  iteration: 11080 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1136 loss: 1.43703 acc: 0.70345 | v_loss: 1.39368 v_acc: 0.70247 |  iteration: 11081 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1137 loss: 1.40890 acc: 0.70703 | v_loss: 1.35144 v_acc: 0.71126 |  iteration: 11082 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1138 loss: 1.43832 acc: 0.70052 | v_loss: 1.39463 v_acc: 0.71810 |  iteration: 11083 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1139 loss: 1.39359 acc: 0.70410 | v_loss: 1.29048 v_acc: 0.70215 |  iteration: 11084 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1140 loss: 1.46191 acc: 0.69954 | v_loss: 1.43349 v_acc: 0.69434 |  iteration: 11085 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1141 loss: 1.37487 acc: 0.70996 | v_loss: 1.43429 v_acc: 0.71452 |  iteration: 11086 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1142 loss: 1.40146 acc: 0.71322 | v_loss: 1.30318 v_acc: 0.71647 |  iteration: 11087 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1143 loss: 1.35098 acc: 0.71029 | v_loss: 1.26368 v_acc: 0.72526 |  iteration: 11088 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1144 loss: 1.47546 acc: 0.69596 | v_loss: 1.37897 v_acc: 0.71940 |  iteration: 11089 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1145 loss: 1.37526 acc: 0.70475 | v_loss: 1.42240 v_acc: 0.70410 |  iteration: 11090 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1146 loss: 1.40504 acc: 0.70996 | v_loss: 1.43232 v_acc: 0.70833 |  iteration: 11091 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1147 loss: 1.45603 acc: 0.70247 | v_loss: 1.21581 v_acc: 0.72591 |  iteration: 11092 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1148 loss: 1.32929 acc: 0.71387 | v_loss: 1.40266 v_acc: 0.73112 |  iteration: 11093 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1149 loss: 1.45293 acc: 0.70475 | v_loss: 1.49030 v_acc: 0.69759 |  iteration: 11094 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1150 loss: 1.37417 acc: 0.70736 | v_loss: 1.44033 v_acc: 0.72201 |  iteration: 11095 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1151 loss: 1.43724 acc: 0.70182 | v_loss: 1.24938 v_acc: 0.72233 |  iteration: 11096 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1152 loss: 1.33351 acc: 0.71549 | v_loss: 1.21128 v_acc: 0.73535 |  iteration: 11097 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1153 loss: 1.44576 acc: 0.69922 | v_loss: 1.22564 v_acc: 0.72656 |  iteration: 11098 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1154 loss: 1.35331 acc: 0.71029 | v_loss: 1.28640 v_acc: 0.70703 |  iteration: 11099 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1155 loss: 1.41275 acc: 0.70866 | v_loss: 1.46415 v_acc: 0.69466 |  iteration: 11100 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1156 loss: 1.44931 acc: 0.71029 | v_loss: 1.27305 v_acc: 0.71484 |  iteration: 11101 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1157 loss: 1.50156 acc: 0.69206 | v_loss: 1.43171 v_acc: 0.72949 |  iteration: 11102 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1158 loss: 1.45105 acc: 0.70117 | v_loss: 1.64115 v_acc: 0.69466 |  iteration: 11103 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1159 loss: 1.39580 acc: 0.70475 | v_loss: 1.50653 v_acc: 0.70410 |  iteration: 11104 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1160 loss: 1.47241 acc: 0.70996 | v_loss: 1.29754 v_acc: 0.72005 |  iteration: 11105 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1161 loss: 1.54805 acc: 0.69987 | v_loss: 1.36966 v_acc: 0.69987 |  iteration: 11106 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1162 loss: 1.49604 acc: 0.69954 | v_loss: 1.23284 v_acc: 0.71615 |  iteration: 11107 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1163 loss: 1.48448 acc: 0.69596 | v_loss: 1.40741 v_acc: 0.69857 |  iteration: 11108 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1164 loss: 1.40097 acc: 0.70736 | v_loss: 1.37156 v_acc: 0.70964 |  iteration: 11109 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1165 loss: 1.34337 acc: 0.71745 | v_loss: 1.34695 v_acc: 0.72949 |  iteration: 11110 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1166 loss: 1.52920 acc: 0.69336 | v_loss: 1.36012 v_acc: 0.71810 |  iteration: 11111 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1167 loss: 1.42254 acc: 0.70378 | v_loss: 1.37984 v_acc: 0.70475 |  iteration: 11112 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1168 loss: 1.42657 acc: 0.70573 | v_loss: 1.30049 v_acc: 0.72559 |  iteration: 11113 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1169 loss: 1.50775 acc: 0.69173 | v_loss: 1.30264 v_acc: 0.72005 |  iteration: 11114 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1170 loss: 1.44001 acc: 0.69759 | v_loss: 1.55097 v_acc: 0.69043 |  iteration: 11115 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1171 loss: 1.40392 acc: 0.70117 | v_loss: 1.33893 v_acc: 0.70964 |  iteration: 11116 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1172 loss: 1.39838 acc: 0.70540 | v_loss: 1.28788 v_acc: 0.71582 |  iteration: 11117 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1173 loss: 1.37588 acc: 0.70443 | v_loss: 1.29981 v_acc: 0.71224 |  iteration: 11118 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1174 loss: 1.52471 acc: 0.69792 | v_loss: 1.43203 v_acc: 0.70703 |  iteration: 11119 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1175 loss: 1.41100 acc: 0.70443 | v_loss: 1.31852 v_acc: 0.73047 |  iteration: 11120 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1176 loss: 1.42478 acc: 0.71224 | v_loss: 1.55960 v_acc: 0.71387 |  iteration: 11121 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1177 loss: 1.53440 acc: 0.70280 | v_loss: 1.28857 v_acc: 0.70052 |  iteration: 11122 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1178 loss: 1.45661 acc: 0.70638 | v_loss: 1.28874 v_acc: 0.70443 |  iteration: 11123 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1179 loss: 1.47601 acc: 0.70768 | v_loss: 1.43855 v_acc: 0.70508 |  iteration: 11124 teacher: 1 stage: sketch lr: 0.000419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1180 loss: 1.44423 acc: 0.70312 | v_loss: 1.46588 v_acc: 0.70573 |  iteration: 11125 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1181 loss: 1.50458 acc: 0.69759 | v_loss: 1.51617 v_acc: 0.68978 |  iteration: 11126 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1182 loss: 1.38955 acc: 0.70540 | v_loss: 1.46329 v_acc: 0.70540 |  iteration: 11127 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1183 loss: 1.36098 acc: 0.71257 | v_loss: 1.43404 v_acc: 0.70540 |  iteration: 11128 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1184 loss: 1.38059 acc: 0.71387 | v_loss: 1.41684 v_acc: 0.70768 |  iteration: 11129 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1185 loss: 1.34090 acc: 0.72135 | v_loss: 1.40362 v_acc: 0.70475 |  iteration: 11130 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1186 loss: 1.38720 acc: 0.70638 | v_loss: 1.26415 v_acc: 0.71354 |  iteration: 11131 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1187 loss: 1.48415 acc: 0.70085 | v_loss: 1.33588 v_acc: 0.72461 |  iteration: 11132 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1188 loss: 1.59797 acc: 0.69108 | v_loss: 1.19200 v_acc: 0.71615 |  iteration: 11133 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1189 loss: 1.34816 acc: 0.71061 | v_loss: 1.34020 v_acc: 0.71126 |  iteration: 11134 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1190 loss: 1.39471 acc: 0.70703 | v_loss: 1.52697 v_acc: 0.69954 |  iteration: 11135 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1191 loss: 1.35615 acc: 0.70475 | v_loss: 1.36019 v_acc: 0.71484 |  iteration: 11136 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1192 loss: 1.36977 acc: 0.70410 | v_loss: 1.36004 v_acc: 0.70312 |  iteration: 11137 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1193 loss: 1.47396 acc: 0.70345 | v_loss: 1.24269 v_acc: 0.71680 |  iteration: 11138 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1194 loss: 1.41516 acc: 0.70605 | v_loss: 1.23619 v_acc: 0.70671 |  iteration: 11139 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1195 loss: 1.41000 acc: 0.69889 | v_loss: 1.24691 v_acc: 0.73568 |  iteration: 11140 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1196 loss: 1.39658 acc: 0.70605 | v_loss: 1.25821 v_acc: 0.72461 |  iteration: 11141 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1197 loss: 1.43651 acc: 0.70378 | v_loss: 1.33150 v_acc: 0.72786 |  iteration: 11142 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1198 loss: 1.45561 acc: 0.70508 | v_loss: 1.26905 v_acc: 0.72266 |  iteration: 11143 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1199 loss: 1.39883 acc: 0.70866 | v_loss: 1.30707 v_acc: 0.71842 |  iteration: 11144 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1200 loss: 1.45662 acc: 0.69987 | v_loss: 1.40919 v_acc: 0.71387 |  iteration: 11145 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1201 loss: 1.61445 acc: 0.67708 | v_loss: 1.38919 v_acc: 0.71940 |  iteration: 11146 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1202 loss: 1.51721 acc: 0.69727 | v_loss: 1.49348 v_acc: 0.69889 |  iteration: 11147 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1203 loss: 1.51258 acc: 0.69336 | v_loss: 1.41045 v_acc: 0.71973 |  iteration: 11148 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1204 loss: 1.44812 acc: 0.70312 | v_loss: 1.19697 v_acc: 0.74121 |  iteration: 11149 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1205 loss: 1.43318 acc: 0.69629 | v_loss: 1.30262 v_acc: 0.70378 |  iteration: 11150 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1206 loss: 1.40835 acc: 0.71289 | v_loss: 1.52013 v_acc: 0.70182 |  iteration: 11151 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1207 loss: 1.42970 acc: 0.70475 | v_loss: 1.26969 v_acc: 0.71647 |  iteration: 11152 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1208 loss: 1.36011 acc: 0.70638 | v_loss: 1.32818 v_acc: 0.71061 |  iteration: 11153 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1209 loss: 1.43721 acc: 0.69629 | v_loss: 1.37328 v_acc: 0.69043 |  iteration: 11154 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1210 loss: 1.41060 acc: 0.70280 | v_loss: 1.32159 v_acc: 0.70898 |  iteration: 11155 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1211 loss: 1.51598 acc: 0.69336 | v_loss: 1.36089 v_acc: 0.69434 |  iteration: 11156 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1212 loss: 1.44171 acc: 0.71289 | v_loss: 1.48920 v_acc: 0.71517 |  iteration: 11157 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1213 loss: 1.39068 acc: 0.70378 | v_loss: 1.32408 v_acc: 0.72786 |  iteration: 11158 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1214 loss: 1.44471 acc: 0.69987 | v_loss: 1.45748 v_acc: 0.70540 |  iteration: 11159 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1215 loss: 1.47190 acc: 0.69336 | v_loss: 1.36996 v_acc: 0.69857 |  iteration: 11160 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1216 loss: 1.41468 acc: 0.69922 | v_loss: 1.32768 v_acc: 0.70833 |  iteration: 11161 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1217 loss: 1.43692 acc: 0.70964 | v_loss: 1.58188 v_acc: 0.68229 |  iteration: 11162 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1218 loss: 1.47273 acc: 0.69661 | v_loss: 1.32256 v_acc: 0.71973 |  iteration: 11163 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1219 loss: 1.44347 acc: 0.70215 | v_loss: 1.57127 v_acc: 0.68620 |  iteration: 11164 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1220 loss: 1.41924 acc: 0.69954 | v_loss: 1.42806 v_acc: 0.69987 |  iteration: 11165 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1221 loss: 1.42424 acc: 0.69661 | v_loss: 1.52361 v_acc: 0.68913 |  iteration: 11166 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1222 loss: 1.45540 acc: 0.71029 | v_loss: 1.35875 v_acc: 0.69759 |  iteration: 11167 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1223 loss: 1.42220 acc: 0.71289 | v_loss: 1.33124 v_acc: 0.70215 |  iteration: 11168 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1224 loss: 1.41831 acc: 0.70052 | v_loss: 1.32476 v_acc: 0.69889 |  iteration: 11169 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1225 loss: 1.39788 acc: 0.70671 | v_loss: 1.32858 v_acc: 0.71484 |  iteration: 11170 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1226 loss: 1.45809 acc: 0.69954 | v_loss: 1.54426 v_acc: 0.68978 |  iteration: 11171 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1227 loss: 1.34925 acc: 0.70052 | v_loss: 1.38348 v_acc: 0.70443 |  iteration: 11172 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1228 loss: 1.52275 acc: 0.69206 | v_loss: 1.37199 v_acc: 0.71029 |  iteration: 11173 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1229 loss: 1.40981 acc: 0.70508 | v_loss: 1.38853 v_acc: 0.71452 |  iteration: 11174 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1230 loss: 1.43995 acc: 0.71387 | v_loss: 1.26922 v_acc: 0.70736 |  iteration: 11175 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1231 loss: 1.53555 acc: 0.69596 | v_loss: 1.44052 v_acc: 0.69792 |  iteration: 11176 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1232 loss: 1.43399 acc: 0.70182 | v_loss: 1.42451 v_acc: 0.71289 |  iteration: 11177 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1233 loss: 1.44398 acc: 0.70280 | v_loss: 1.29406 v_acc: 0.71647 |  iteration: 11178 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1234 loss: 1.37879 acc: 0.70020 | v_loss: 1.25791 v_acc: 0.72493 |  iteration: 11179 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1235 loss: 1.37544 acc: 0.70898 | v_loss: 1.40554 v_acc: 0.71712 |  iteration: 11180 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1236 loss: 1.49643 acc: 0.68587 | v_loss: 1.41455 v_acc: 0.70280 |  iteration: 11181 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1237 loss: 1.44006 acc: 0.70443 | v_loss: 1.41938 v_acc: 0.70866 |  iteration: 11182 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1238 loss: 1.51179 acc: 0.68490 | v_loss: 1.21916 v_acc: 0.72591 |  iteration: 11183 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1239 loss: 1.45903 acc: 0.69824 | v_loss: 1.39224 v_acc: 0.73112 |  iteration: 11184 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1240 loss: 1.43781 acc: 0.69987 | v_loss: 1.47673 v_acc: 0.69759 |  iteration: 11185 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1241 loss: 1.47273 acc: 0.69466 | v_loss: 1.42018 v_acc: 0.72201 |  iteration: 11186 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1242 loss: 1.40229 acc: 0.70833 | v_loss: 1.25532 v_acc: 0.72233 |  iteration: 11187 teacher: 0 stage: sketch lr: 0.000418\n",
      "epoch 8 loss: 1.44378 acc: 0.70236 | v_loss: 1.37153 v_acc: 0.71020 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9\n",
      "__________________________________________\n",
      "batch 0 loss: 1.45894 acc: 0.69889 | v_loss: 1.43612 v_acc: 0.70410 |  iteration: 11188 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1 loss: 1.47216 acc: 0.70150 | v_loss: 1.42469 v_acc: 0.70768 |  iteration: 11189 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 2 loss: 1.40967 acc: 0.69141 | v_loss: 1.40909 v_acc: 0.70475 |  iteration: 11190 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 3 loss: 1.41004 acc: 0.70898 | v_loss: 1.26736 v_acc: 0.71354 |  iteration: 11191 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 4 loss: 1.38835 acc: 0.70996 | v_loss: 1.32814 v_acc: 0.72461 |  iteration: 11192 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 5 loss: 1.42426 acc: 0.70540 | v_loss: 1.17698 v_acc: 0.71615 |  iteration: 11193 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 6 loss: 1.47641 acc: 0.70117 | v_loss: 1.34330 v_acc: 0.71126 |  iteration: 11194 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 7 loss: 1.43269 acc: 0.70443 | v_loss: 1.51757 v_acc: 0.69954 |  iteration: 11195 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 8 loss: 1.40218 acc: 0.72135 | v_loss: 1.33208 v_acc: 0.71484 |  iteration: 11196 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 9 loss: 1.37221 acc: 0.71224 | v_loss: 1.36393 v_acc: 0.69954 |  iteration: 11197 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 10 loss: 1.42418 acc: 0.70312 | v_loss: 1.26637 v_acc: 0.70573 |  iteration: 11198 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 11 loss: 1.32853 acc: 0.70703 | v_loss: 1.24237 v_acc: 0.70215 |  iteration: 11199 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 12 loss: 1.48158 acc: 0.69694 | v_loss: 1.25849 v_acc: 0.73242 |  iteration: 11200 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 13 loss: 1.45688 acc: 0.70931 | v_loss: 1.27772 v_acc: 0.71647 |  iteration: 11201 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 14 loss: 1.43034 acc: 0.70638 | v_loss: 1.37022 v_acc: 0.74089 |  iteration: 11202 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 15 loss: 1.54790 acc: 0.69206 | v_loss: 1.26303 v_acc: 0.72396 |  iteration: 11203 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 16 loss: 1.47104 acc: 0.70443 | v_loss: 1.30419 v_acc: 0.71582 |  iteration: 11204 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 17 loss: 1.36241 acc: 0.70638 | v_loss: 1.41024 v_acc: 0.71224 |  iteration: 11205 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 18 loss: 1.47460 acc: 0.69857 | v_loss: 1.38059 v_acc: 0.72038 |  iteration: 11206 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 19 loss: 1.40500 acc: 0.70801 | v_loss: 1.49338 v_acc: 0.69661 |  iteration: 11207 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 20 loss: 1.47695 acc: 0.70085 | v_loss: 1.40284 v_acc: 0.71745 |  iteration: 11208 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 21 loss: 1.35274 acc: 0.70020 | v_loss: 1.17895 v_acc: 0.74382 |  iteration: 11209 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 22 loss: 1.36072 acc: 0.71289 | v_loss: 1.26001 v_acc: 0.70280 |  iteration: 11210 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 23 loss: 1.41204 acc: 0.70866 | v_loss: 1.51209 v_acc: 0.70280 |  iteration: 11211 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 24 loss: 1.40922 acc: 0.70768 | v_loss: 1.20782 v_acc: 0.71647 |  iteration: 11212 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 25 loss: 1.62111 acc: 0.68913 | v_loss: 1.32983 v_acc: 0.71191 |  iteration: 11213 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 26 loss: 1.59368 acc: 0.69010 | v_loss: 1.37731 v_acc: 0.69076 |  iteration: 11214 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 27 loss: 1.41995 acc: 0.70150 | v_loss: 1.30555 v_acc: 0.70898 |  iteration: 11215 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 28 loss: 1.40409 acc: 0.70117 | v_loss: 1.37263 v_acc: 0.69206 |  iteration: 11216 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 29 loss: 1.53245 acc: 0.68783 | v_loss: 1.48091 v_acc: 0.70931 |  iteration: 11217 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 30 loss: 1.41567 acc: 0.70508 | v_loss: 1.31612 v_acc: 0.72363 |  iteration: 11218 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 31 loss: 1.46309 acc: 0.70085 | v_loss: 1.45082 v_acc: 0.70117 |  iteration: 11219 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 32 loss: 1.40806 acc: 0.70247 | v_loss: 1.35759 v_acc: 0.69922 |  iteration: 11220 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 33 loss: 1.39395 acc: 0.70020 | v_loss: 1.31836 v_acc: 0.70833 |  iteration: 11221 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 34 loss: 1.43911 acc: 0.70150 | v_loss: 1.57149 v_acc: 0.68522 |  iteration: 11222 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 35 loss: 1.39276 acc: 0.70410 | v_loss: 1.31315 v_acc: 0.72168 |  iteration: 11223 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 36 loss: 1.45384 acc: 0.70768 | v_loss: 1.59756 v_acc: 0.67839 |  iteration: 11224 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 37 loss: 1.42917 acc: 0.70475 | v_loss: 1.46280 v_acc: 0.69759 |  iteration: 11225 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 38 loss: 1.34721 acc: 0.71484 | v_loss: 1.53466 v_acc: 0.69043 |  iteration: 11226 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 39 loss: 1.54520 acc: 0.69206 | v_loss: 1.37609 v_acc: 0.70020 |  iteration: 11227 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 40 loss: 1.48718 acc: 0.69466 | v_loss: 1.31134 v_acc: 0.70671 |  iteration: 11228 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 41 loss: 1.42017 acc: 0.69629 | v_loss: 1.33761 v_acc: 0.70573 |  iteration: 11229 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 42 loss: 1.36004 acc: 0.70605 | v_loss: 1.33290 v_acc: 0.71875 |  iteration: 11230 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 43 loss: 1.41862 acc: 0.70833 | v_loss: 1.55775 v_acc: 0.68783 |  iteration: 11231 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 44 loss: 1.38202 acc: 0.70280 | v_loss: 1.38540 v_acc: 0.70247 |  iteration: 11232 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 45 loss: 1.46123 acc: 0.68913 | v_loss: 1.36637 v_acc: 0.71126 |  iteration: 11233 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 46 loss: 1.34371 acc: 0.71582 | v_loss: 1.39110 v_acc: 0.71810 |  iteration: 11234 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 47 loss: 1.39464 acc: 0.70703 | v_loss: 1.27190 v_acc: 0.70215 |  iteration: 11235 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 48 loss: 1.38931 acc: 0.70638 | v_loss: 1.42637 v_acc: 0.69434 |  iteration: 11236 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 49 loss: 1.47876 acc: 0.70345 | v_loss: 1.42617 v_acc: 0.71452 |  iteration: 11237 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 50 loss: 1.37869 acc: 0.71029 | v_loss: 1.29199 v_acc: 0.71647 |  iteration: 11238 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 51 loss: 1.55834 acc: 0.69076 | v_loss: 1.25606 v_acc: 0.72526 |  iteration: 11239 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 52 loss: 1.39286 acc: 0.70768 | v_loss: 1.37592 v_acc: 0.71647 |  iteration: 11240 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 53 loss: 1.54984 acc: 0.69499 | v_loss: 1.42229 v_acc: 0.70182 |  iteration: 11241 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 54 loss: 1.40457 acc: 0.70638 | v_loss: 1.42402 v_acc: 0.70410 |  iteration: 11242 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 55 loss: 1.48158 acc: 0.70052 | v_loss: 1.23484 v_acc: 0.71517 |  iteration: 11243 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 56 loss: 1.38710 acc: 0.70638 | v_loss: 1.38231 v_acc: 0.72819 |  iteration: 11244 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 57 loss: 1.47852 acc: 0.70150 | v_loss: 1.46331 v_acc: 0.69759 |  iteration: 11245 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 58 loss: 1.45891 acc: 0.70378 | v_loss: 1.41282 v_acc: 0.72233 |  iteration: 11246 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 59 loss: 1.36972 acc: 0.70671 | v_loss: 1.25986 v_acc: 0.71810 |  iteration: 11247 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 60 loss: 1.40753 acc: 0.70573 | v_loss: 1.20500 v_acc: 0.73438 |  iteration: 11248 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 61 loss: 1.48472 acc: 0.68815 | v_loss: 1.20762 v_acc: 0.72917 |  iteration: 11249 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 62 loss: 1.49037 acc: 0.69694 | v_loss: 1.28046 v_acc: 0.70898 |  iteration: 11250 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 63 loss: 1.41258 acc: 0.70833 | v_loss: 1.45300 v_acc: 0.69629 |  iteration: 11251 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 64 loss: 1.45328 acc: 0.70410 | v_loss: 1.28312 v_acc: 0.71061 |  iteration: 11252 teacher: 1 stage: sketch lr: 0.000417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 65 loss: 1.45481 acc: 0.70117 | v_loss: 1.50189 v_acc: 0.70475 |  iteration: 11253 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 66 loss: 1.47896 acc: 0.69141 | v_loss: 1.68713 v_acc: 0.69336 |  iteration: 11254 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 67 loss: 1.50270 acc: 0.68359 | v_loss: 1.54068 v_acc: 0.69727 |  iteration: 11255 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 68 loss: 1.39849 acc: 0.70312 | v_loss: 1.29765 v_acc: 0.72396 |  iteration: 11256 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 69 loss: 1.47452 acc: 0.69922 | v_loss: 1.36717 v_acc: 0.70996 |  iteration: 11257 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 70 loss: 1.44254 acc: 0.70671 | v_loss: 1.22455 v_acc: 0.71973 |  iteration: 11258 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 71 loss: 1.43464 acc: 0.69792 | v_loss: 1.40626 v_acc: 0.70150 |  iteration: 11259 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 72 loss: 1.52186 acc: 0.69108 | v_loss: 1.36535 v_acc: 0.71029 |  iteration: 11260 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 73 loss: 1.52463 acc: 0.68978 | v_loss: 1.35166 v_acc: 0.72949 |  iteration: 11261 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 74 loss: 1.51456 acc: 0.69824 | v_loss: 1.35466 v_acc: 0.71680 |  iteration: 11262 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 75 loss: 1.46568 acc: 0.70508 | v_loss: 1.37358 v_acc: 0.70345 |  iteration: 11263 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 76 loss: 1.60877 acc: 0.69043 | v_loss: 1.30654 v_acc: 0.72201 |  iteration: 11264 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 77 loss: 1.51055 acc: 0.69141 | v_loss: 1.31505 v_acc: 0.72005 |  iteration: 11265 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 78 loss: 1.41249 acc: 0.70410 | v_loss: 1.51472 v_acc: 0.69206 |  iteration: 11266 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 79 loss: 1.42547 acc: 0.70573 | v_loss: 1.32191 v_acc: 0.71452 |  iteration: 11267 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 80 loss: 1.46116 acc: 0.69466 | v_loss: 1.30145 v_acc: 0.71777 |  iteration: 11268 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 81 loss: 1.42070 acc: 0.70345 | v_loss: 1.29476 v_acc: 0.71484 |  iteration: 11269 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 82 loss: 1.38891 acc: 0.69759 | v_loss: 1.44433 v_acc: 0.70540 |  iteration: 11270 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 83 loss: 1.38846 acc: 0.69792 | v_loss: 1.30928 v_acc: 0.73047 |  iteration: 11271 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 84 loss: 1.37696 acc: 0.70996 | v_loss: 1.56759 v_acc: 0.71582 |  iteration: 11272 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 85 loss: 1.44244 acc: 0.70443 | v_loss: 1.26994 v_acc: 0.69889 |  iteration: 11273 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 86 loss: 1.38345 acc: 0.70410 | v_loss: 1.28305 v_acc: 0.70117 |  iteration: 11274 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 87 loss: 1.52766 acc: 0.69238 | v_loss: 1.45504 v_acc: 0.70182 |  iteration: 11275 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 88 loss: 1.40329 acc: 0.70638 | v_loss: 1.48251 v_acc: 0.69987 |  iteration: 11276 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 89 loss: 1.43550 acc: 0.70996 | v_loss: 1.52404 v_acc: 0.68783 |  iteration: 11277 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 90 loss: 1.43254 acc: 0.70671 | v_loss: 1.47506 v_acc: 0.70671 |  iteration: 11278 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 91 loss: 1.42709 acc: 0.69824 | v_loss: 1.42178 v_acc: 0.70410 |  iteration: 11279 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 92 loss: 1.45982 acc: 0.70378 | v_loss: 1.39603 v_acc: 0.70866 |  iteration: 11280 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 93 loss: 1.43244 acc: 0.69922 | v_loss: 1.42428 v_acc: 0.70671 |  iteration: 11281 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 94 loss: 1.40380 acc: 0.70280 | v_loss: 1.28896 v_acc: 0.71354 |  iteration: 11282 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 95 loss: 1.47852 acc: 0.69824 | v_loss: 1.31141 v_acc: 0.72461 |  iteration: 11283 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 96 loss: 1.39402 acc: 0.70312 | v_loss: 1.19680 v_acc: 0.71615 |  iteration: 11284 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 97 loss: 1.41532 acc: 0.70215 | v_loss: 1.34227 v_acc: 0.71126 |  iteration: 11285 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 98 loss: 1.44279 acc: 0.70378 | v_loss: 1.50821 v_acc: 0.69954 |  iteration: 11286 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 99 loss: 1.49551 acc: 0.69759 | v_loss: 1.34265 v_acc: 0.71484 |  iteration: 11287 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 100 loss: 1.42487 acc: 0.70833 | v_loss: 1.34716 v_acc: 0.70312 |  iteration: 11288 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 101 loss: 1.44130 acc: 0.69108 | v_loss: 1.25542 v_acc: 0.71680 |  iteration: 11289 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 102 loss: 1.36227 acc: 0.71517 | v_loss: 1.23400 v_acc: 0.70671 |  iteration: 11290 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 103 loss: 1.53274 acc: 0.69661 | v_loss: 1.24607 v_acc: 0.73568 |  iteration: 11291 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 104 loss: 1.34833 acc: 0.70801 | v_loss: 1.25972 v_acc: 0.72461 |  iteration: 11292 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 105 loss: 1.39811 acc: 0.70833 | v_loss: 1.34158 v_acc: 0.72689 |  iteration: 11293 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 106 loss: 1.53519 acc: 0.70085 | v_loss: 1.26381 v_acc: 0.72852 |  iteration: 11294 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 107 loss: 1.39652 acc: 0.70475 | v_loss: 1.30166 v_acc: 0.72103 |  iteration: 11295 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 108 loss: 1.49873 acc: 0.70573 | v_loss: 1.40784 v_acc: 0.71354 |  iteration: 11296 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 109 loss: 1.32583 acc: 0.72005 | v_loss: 1.38153 v_acc: 0.72038 |  iteration: 11297 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 110 loss: 1.44499 acc: 0.70540 | v_loss: 1.48701 v_acc: 0.69661 |  iteration: 11298 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 111 loss: 1.49559 acc: 0.69727 | v_loss: 1.40820 v_acc: 0.71745 |  iteration: 11299 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 112 loss: 1.42111 acc: 0.70703 | v_loss: 1.18227 v_acc: 0.74382 |  iteration: 11300 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 113 loss: 1.40354 acc: 0.70280 | v_loss: 1.28077 v_acc: 0.70280 |  iteration: 11301 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 114 loss: 1.34897 acc: 0.71680 | v_loss: 1.51345 v_acc: 0.70280 |  iteration: 11302 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 115 loss: 1.38232 acc: 0.70215 | v_loss: 1.23502 v_acc: 0.71647 |  iteration: 11303 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 116 loss: 1.39192 acc: 0.70768 | v_loss: 1.33349 v_acc: 0.71159 |  iteration: 11304 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 117 loss: 1.41825 acc: 0.70150 | v_loss: 1.37896 v_acc: 0.69368 |  iteration: 11305 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 118 loss: 1.51094 acc: 0.69434 | v_loss: 1.29113 v_acc: 0.71842 |  iteration: 11306 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 119 loss: 1.42433 acc: 0.70638 | v_loss: 1.36159 v_acc: 0.70215 |  iteration: 11307 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 120 loss: 1.34445 acc: 0.71159 | v_loss: 1.48812 v_acc: 0.72005 |  iteration: 11308 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 121 loss: 1.33391 acc: 0.71615 | v_loss: 1.32952 v_acc: 0.72786 |  iteration: 11309 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 122 loss: 1.34244 acc: 0.71484 | v_loss: 1.44414 v_acc: 0.70540 |  iteration: 11310 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 123 loss: 1.49758 acc: 0.70020 | v_loss: 1.36846 v_acc: 0.69857 |  iteration: 11311 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 124 loss: 1.46411 acc: 0.70247 | v_loss: 1.32979 v_acc: 0.70703 |  iteration: 11312 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 125 loss: 1.43691 acc: 0.70833 | v_loss: 1.54177 v_acc: 0.68880 |  iteration: 11313 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 126 loss: 1.50278 acc: 0.69792 | v_loss: 1.30854 v_acc: 0.72103 |  iteration: 11314 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 127 loss: 1.32915 acc: 0.71191 | v_loss: 1.57307 v_acc: 0.68620 |  iteration: 11315 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 128 loss: 1.34118 acc: 0.71452 | v_loss: 1.43868 v_acc: 0.69987 |  iteration: 11316 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 129 loss: 1.35733 acc: 0.70215 | v_loss: 1.52033 v_acc: 0.68913 |  iteration: 11317 teacher: 0 stage: sketch lr: 0.000415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 130 loss: 1.47609 acc: 0.69954 | v_loss: 1.37497 v_acc: 0.70182 |  iteration: 11318 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 131 loss: 1.42036 acc: 0.70443 | v_loss: 1.32043 v_acc: 0.70638 |  iteration: 11319 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 132 loss: 1.54374 acc: 0.68620 | v_loss: 1.32371 v_acc: 0.70410 |  iteration: 11320 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 133 loss: 1.44436 acc: 0.70182 | v_loss: 1.33058 v_acc: 0.71842 |  iteration: 11321 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 134 loss: 1.47390 acc: 0.69987 | v_loss: 1.56013 v_acc: 0.69108 |  iteration: 11322 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 135 loss: 1.46384 acc: 0.70052 | v_loss: 1.38218 v_acc: 0.71126 |  iteration: 11323 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 136 loss: 1.40962 acc: 0.69889 | v_loss: 1.37227 v_acc: 0.71061 |  iteration: 11324 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 137 loss: 1.47041 acc: 0.70150 | v_loss: 1.38545 v_acc: 0.71452 |  iteration: 11325 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 138 loss: 1.43112 acc: 0.70247 | v_loss: 1.27282 v_acc: 0.70573 |  iteration: 11326 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 139 loss: 1.52432 acc: 0.69661 | v_loss: 1.42541 v_acc: 0.69792 |  iteration: 11327 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 140 loss: 1.37975 acc: 0.70605 | v_loss: 1.41791 v_acc: 0.71289 |  iteration: 11328 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 141 loss: 1.43432 acc: 0.70150 | v_loss: 1.29539 v_acc: 0.71875 |  iteration: 11329 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 142 loss: 1.39098 acc: 0.70312 | v_loss: 1.25218 v_acc: 0.72754 |  iteration: 11330 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 143 loss: 1.36628 acc: 0.70996 | v_loss: 1.38433 v_acc: 0.71973 |  iteration: 11331 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 144 loss: 1.39191 acc: 0.71712 | v_loss: 1.42014 v_acc: 0.70052 |  iteration: 11332 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 145 loss: 1.54303 acc: 0.69564 | v_loss: 1.41539 v_acc: 0.70312 |  iteration: 11333 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 146 loss: 1.41639 acc: 0.70312 | v_loss: 1.23814 v_acc: 0.71419 |  iteration: 11334 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 147 loss: 1.42236 acc: 0.70736 | v_loss: 1.39279 v_acc: 0.72819 |  iteration: 11335 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 148 loss: 1.38493 acc: 0.72070 | v_loss: 1.46802 v_acc: 0.69792 |  iteration: 11336 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 149 loss: 1.46215 acc: 0.69661 | v_loss: 1.39791 v_acc: 0.71842 |  iteration: 11337 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 150 loss: 1.47665 acc: 0.69434 | v_loss: 1.25408 v_acc: 0.71810 |  iteration: 11338 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 151 loss: 1.41785 acc: 0.70671 | v_loss: 1.20895 v_acc: 0.73535 |  iteration: 11339 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 152 loss: 1.46822 acc: 0.70280 | v_loss: 1.20892 v_acc: 0.72559 |  iteration: 11340 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 153 loss: 1.40632 acc: 0.69922 | v_loss: 1.28460 v_acc: 0.70638 |  iteration: 11341 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 154 loss: 1.29226 acc: 0.71354 | v_loss: 1.45448 v_acc: 0.70671 |  iteration: 11342 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 155 loss: 1.39598 acc: 0.71061 | v_loss: 1.27320 v_acc: 0.71549 |  iteration: 11343 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 156 loss: 1.49574 acc: 0.69303 | v_loss: 1.50415 v_acc: 0.68848 |  iteration: 11344 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 157 loss: 1.39315 acc: 0.70638 | v_loss: 1.72521 v_acc: 0.68913 |  iteration: 11345 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 158 loss: 1.47348 acc: 0.69694 | v_loss: 1.56365 v_acc: 0.69531 |  iteration: 11346 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 159 loss: 1.37158 acc: 0.70964 | v_loss: 1.29787 v_acc: 0.72526 |  iteration: 11347 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 160 loss: 1.54736 acc: 0.69661 | v_loss: 1.37265 v_acc: 0.70964 |  iteration: 11348 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 161 loss: 1.43497 acc: 0.69596 | v_loss: 1.22290 v_acc: 0.72201 |  iteration: 11349 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 162 loss: 1.46797 acc: 0.69336 | v_loss: 1.41730 v_acc: 0.70378 |  iteration: 11350 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 163 loss: 1.37403 acc: 0.70378 | v_loss: 1.36034 v_acc: 0.71810 |  iteration: 11351 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 164 loss: 1.31909 acc: 0.71582 | v_loss: 1.36381 v_acc: 0.73014 |  iteration: 11352 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 165 loss: 1.38508 acc: 0.70866 | v_loss: 1.36052 v_acc: 0.71777 |  iteration: 11353 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 166 loss: 1.35919 acc: 0.70540 | v_loss: 1.37408 v_acc: 0.70410 |  iteration: 11354 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 167 loss: 1.51747 acc: 0.69987 | v_loss: 1.28453 v_acc: 0.72493 |  iteration: 11355 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 168 loss: 1.42289 acc: 0.69759 | v_loss: 1.30111 v_acc: 0.72038 |  iteration: 11356 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 169 loss: 1.47657 acc: 0.69889 | v_loss: 1.51279 v_acc: 0.69303 |  iteration: 11357 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 170 loss: 1.45911 acc: 0.69857 | v_loss: 1.33722 v_acc: 0.71159 |  iteration: 11358 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 171 loss: 1.48894 acc: 0.70573 | v_loss: 1.29562 v_acc: 0.71549 |  iteration: 11359 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 172 loss: 1.41154 acc: 0.70736 | v_loss: 1.28255 v_acc: 0.72201 |  iteration: 11360 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 173 loss: 1.44812 acc: 0.70671 | v_loss: 1.42306 v_acc: 0.70768 |  iteration: 11361 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 174 loss: 1.37588 acc: 0.70703 | v_loss: 1.31296 v_acc: 0.73210 |  iteration: 11362 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 175 loss: 1.46585 acc: 0.69531 | v_loss: 1.52487 v_acc: 0.71322 |  iteration: 11363 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 176 loss: 1.47748 acc: 0.68880 | v_loss: 1.31304 v_acc: 0.69531 |  iteration: 11364 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 177 loss: 1.41177 acc: 0.70540 | v_loss: 1.30089 v_acc: 0.70117 |  iteration: 11365 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 178 loss: 1.44797 acc: 0.70378 | v_loss: 1.42412 v_acc: 0.70378 |  iteration: 11366 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 179 loss: 1.39483 acc: 0.71224 | v_loss: 1.45752 v_acc: 0.70117 |  iteration: 11367 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 180 loss: 1.37822 acc: 0.71712 | v_loss: 1.50216 v_acc: 0.68978 |  iteration: 11368 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 181 loss: 1.43173 acc: 0.69987 | v_loss: 1.47564 v_acc: 0.70671 |  iteration: 11369 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 182 loss: 1.34859 acc: 0.70736 | v_loss: 1.42036 v_acc: 0.70410 |  iteration: 11370 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 183 loss: 1.40879 acc: 0.70605 | v_loss: 1.40299 v_acc: 0.70866 |  iteration: 11371 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 184 loss: 1.46083 acc: 0.69759 | v_loss: 1.41910 v_acc: 0.70638 |  iteration: 11372 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 185 loss: 1.44761 acc: 0.69922 | v_loss: 1.27086 v_acc: 0.71289 |  iteration: 11373 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 186 loss: 1.38378 acc: 0.71419 | v_loss: 1.34198 v_acc: 0.72135 |  iteration: 11374 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 187 loss: 1.54428 acc: 0.69889 | v_loss: 1.21452 v_acc: 0.70605 |  iteration: 11375 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 188 loss: 1.37631 acc: 0.71354 | v_loss: 1.34701 v_acc: 0.70150 |  iteration: 11376 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 189 loss: 1.39954 acc: 0.71061 | v_loss: 1.50258 v_acc: 0.69987 |  iteration: 11377 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 190 loss: 1.47587 acc: 0.70117 | v_loss: 1.34320 v_acc: 0.70540 |  iteration: 11378 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 191 loss: 1.43765 acc: 0.70833 | v_loss: 1.36691 v_acc: 0.69531 |  iteration: 11379 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 192 loss: 1.45916 acc: 0.69434 | v_loss: 1.24468 v_acc: 0.71126 |  iteration: 11380 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 193 loss: 1.37907 acc: 0.70931 | v_loss: 1.26195 v_acc: 0.70671 |  iteration: 11381 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 194 loss: 1.53635 acc: 0.68945 | v_loss: 1.25117 v_acc: 0.73568 |  iteration: 11382 teacher: 1 stage: sketch lr: 0.000414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 195 loss: 1.36401 acc: 0.70768 | v_loss: 1.26638 v_acc: 0.72461 |  iteration: 11383 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 196 loss: 1.41062 acc: 0.70443 | v_loss: 1.34557 v_acc: 0.72689 |  iteration: 11384 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 197 loss: 1.46407 acc: 0.69694 | v_loss: 1.26996 v_acc: 0.72852 |  iteration: 11385 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 198 loss: 1.53315 acc: 0.69043 | v_loss: 1.31166 v_acc: 0.72103 |  iteration: 11386 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 199 loss: 1.52102 acc: 0.69596 | v_loss: 1.41773 v_acc: 0.71354 |  iteration: 11387 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 200 loss: 1.41475 acc: 0.70150 | v_loss: 1.39483 v_acc: 0.72721 |  iteration: 11388 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 201 loss: 1.48544 acc: 0.70052 | v_loss: 1.48765 v_acc: 0.70150 |  iteration: 11389 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 202 loss: 1.43789 acc: 0.69889 | v_loss: 1.41697 v_acc: 0.72135 |  iteration: 11390 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 203 loss: 1.43135 acc: 0.69434 | v_loss: 1.17961 v_acc: 0.74447 |  iteration: 11391 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 204 loss: 1.42982 acc: 0.70866 | v_loss: 1.26147 v_acc: 0.70964 |  iteration: 11392 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 205 loss: 1.46798 acc: 0.70443 | v_loss: 1.51025 v_acc: 0.70150 |  iteration: 11393 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 206 loss: 1.46842 acc: 0.70182 | v_loss: 1.23744 v_acc: 0.70671 |  iteration: 11394 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 207 loss: 1.50734 acc: 0.69499 | v_loss: 1.33118 v_acc: 0.71191 |  iteration: 11395 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 208 loss: 1.40946 acc: 0.70671 | v_loss: 1.37855 v_acc: 0.69076 |  iteration: 11396 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 209 loss: 1.41853 acc: 0.70378 | v_loss: 1.31669 v_acc: 0.70898 |  iteration: 11397 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 210 loss: 1.49657 acc: 0.70020 | v_loss: 1.38438 v_acc: 0.69206 |  iteration: 11398 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 211 loss: 1.34884 acc: 0.71191 | v_loss: 1.46389 v_acc: 0.70931 |  iteration: 11399 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 212 loss: 1.48835 acc: 0.69564 | v_loss: 1.31533 v_acc: 0.72363 |  iteration: 11400 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 213 loss: 1.35415 acc: 0.70931 | v_loss: 1.45075 v_acc: 0.70117 |  iteration: 11401 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 214 loss: 1.41818 acc: 0.71419 | v_loss: 1.35737 v_acc: 0.70085 |  iteration: 11402 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 215 loss: 1.42473 acc: 0.69922 | v_loss: 1.34282 v_acc: 0.70703 |  iteration: 11403 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 216 loss: 1.42058 acc: 0.70540 | v_loss: 1.55328 v_acc: 0.68620 |  iteration: 11404 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 217 loss: 1.54959 acc: 0.70345 | v_loss: 1.31614 v_acc: 0.72005 |  iteration: 11405 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 218 loss: 1.39687 acc: 0.70964 | v_loss: 1.58701 v_acc: 0.68424 |  iteration: 11406 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 219 loss: 1.40240 acc: 0.70182 | v_loss: 1.43587 v_acc: 0.69889 |  iteration: 11407 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 220 loss: 1.46209 acc: 0.70345 | v_loss: 1.52799 v_acc: 0.68978 |  iteration: 11408 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 221 loss: 1.54239 acc: 0.69466 | v_loss: 1.36116 v_acc: 0.69954 |  iteration: 11409 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 222 loss: 1.44011 acc: 0.70573 | v_loss: 1.32288 v_acc: 0.70638 |  iteration: 11410 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 223 loss: 1.56992 acc: 0.69987 | v_loss: 1.31883 v_acc: 0.70410 |  iteration: 11411 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 224 loss: 1.42275 acc: 0.70085 | v_loss: 1.32607 v_acc: 0.71484 |  iteration: 11412 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 225 loss: 1.38379 acc: 0.71647 | v_loss: 1.53937 v_acc: 0.68978 |  iteration: 11413 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 226 loss: 1.38662 acc: 0.71126 | v_loss: 1.38887 v_acc: 0.70247 |  iteration: 11414 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 227 loss: 1.36961 acc: 0.71029 | v_loss: 1.34815 v_acc: 0.71126 |  iteration: 11415 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 228 loss: 1.47426 acc: 0.70150 | v_loss: 1.38811 v_acc: 0.71810 |  iteration: 11416 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 229 loss: 1.43932 acc: 0.71257 | v_loss: 1.28649 v_acc: 0.70215 |  iteration: 11417 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 230 loss: 1.42925 acc: 0.71029 | v_loss: 1.44426 v_acc: 0.69434 |  iteration: 11418 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 231 loss: 1.40279 acc: 0.70443 | v_loss: 1.42861 v_acc: 0.71452 |  iteration: 11419 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 232 loss: 1.48674 acc: 0.70638 | v_loss: 1.29035 v_acc: 0.71647 |  iteration: 11420 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 233 loss: 1.54591 acc: 0.69499 | v_loss: 1.26671 v_acc: 0.72526 |  iteration: 11421 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 234 loss: 1.42912 acc: 0.71680 | v_loss: 1.38584 v_acc: 0.71647 |  iteration: 11422 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 235 loss: 1.39028 acc: 0.70508 | v_loss: 1.42865 v_acc: 0.70052 |  iteration: 11423 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 236 loss: 1.55028 acc: 0.70345 | v_loss: 1.42412 v_acc: 0.70312 |  iteration: 11424 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 237 loss: 1.40615 acc: 0.71257 | v_loss: 1.23722 v_acc: 0.71419 |  iteration: 11425 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 238 loss: 1.38455 acc: 0.71777 | v_loss: 1.38843 v_acc: 0.72819 |  iteration: 11426 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 239 loss: 1.39725 acc: 0.70703 | v_loss: 1.46967 v_acc: 0.69792 |  iteration: 11427 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 240 loss: 1.47473 acc: 0.70150 | v_loss: 1.39588 v_acc: 0.71842 |  iteration: 11428 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 241 loss: 1.37235 acc: 0.71354 | v_loss: 1.25584 v_acc: 0.71810 |  iteration: 11429 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 242 loss: 1.36701 acc: 0.70475 | v_loss: 1.21075 v_acc: 0.73535 |  iteration: 11430 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 243 loss: 1.39892 acc: 0.71257 | v_loss: 1.21744 v_acc: 0.72559 |  iteration: 11431 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 244 loss: 1.37356 acc: 0.71159 | v_loss: 1.28847 v_acc: 0.70638 |  iteration: 11432 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 245 loss: 1.47445 acc: 0.69694 | v_loss: 1.45979 v_acc: 0.70052 |  iteration: 11433 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 246 loss: 1.36971 acc: 0.72005 | v_loss: 1.27193 v_acc: 0.71452 |  iteration: 11434 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 247 loss: 1.38716 acc: 0.71647 | v_loss: 1.44377 v_acc: 0.71647 |  iteration: 11435 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 248 loss: 1.49753 acc: 0.71159 | v_loss: 1.68505 v_acc: 0.69303 |  iteration: 11436 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 249 loss: 1.30812 acc: 0.70768 | v_loss: 1.53681 v_acc: 0.70117 |  iteration: 11437 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 250 loss: 1.37545 acc: 0.71549 | v_loss: 1.29508 v_acc: 0.72005 |  iteration: 11438 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 251 loss: 1.40858 acc: 0.70378 | v_loss: 1.39085 v_acc: 0.69987 |  iteration: 11439 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 252 loss: 1.44768 acc: 0.70312 | v_loss: 1.23116 v_acc: 0.71615 |  iteration: 11440 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 253 loss: 1.41149 acc: 0.70605 | v_loss: 1.45719 v_acc: 0.69857 |  iteration: 11441 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 254 loss: 1.39904 acc: 0.70182 | v_loss: 1.37034 v_acc: 0.71094 |  iteration: 11442 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 255 loss: 1.45570 acc: 0.70117 | v_loss: 1.37231 v_acc: 0.72949 |  iteration: 11443 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 256 loss: 1.21669 acc: 0.71126 | v_loss: 1.37656 v_acc: 0.71777 |  iteration: 11444 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 257 loss: 1.48991 acc: 0.69531 | v_loss: 1.38095 v_acc: 0.70410 |  iteration: 11445 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 258 loss: 1.45309 acc: 0.70410 | v_loss: 1.28285 v_acc: 0.72493 |  iteration: 11446 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 259 loss: 1.49634 acc: 0.70540 | v_loss: 1.28991 v_acc: 0.72038 |  iteration: 11447 teacher: 1 stage: sketch lr: 0.000413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 260 loss: 1.54672 acc: 0.69954 | v_loss: 1.46137 v_acc: 0.69368 |  iteration: 11448 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 261 loss: 1.41784 acc: 0.70703 | v_loss: 1.34055 v_acc: 0.71452 |  iteration: 11449 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 262 loss: 1.62830 acc: 0.68034 | v_loss: 1.30419 v_acc: 0.71777 |  iteration: 11450 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 263 loss: 1.51566 acc: 0.69303 | v_loss: 1.29274 v_acc: 0.71875 |  iteration: 11451 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 264 loss: 1.42275 acc: 0.69889 | v_loss: 1.43666 v_acc: 0.70475 |  iteration: 11452 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 265 loss: 1.41950 acc: 0.70085 | v_loss: 1.31955 v_acc: 0.73014 |  iteration: 11453 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 266 loss: 1.40396 acc: 0.70020 | v_loss: 1.53381 v_acc: 0.71322 |  iteration: 11454 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 267 loss: 1.40744 acc: 0.71354 | v_loss: 1.28586 v_acc: 0.69531 |  iteration: 11455 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 268 loss: 1.50118 acc: 0.69759 | v_loss: 1.28850 v_acc: 0.70280 |  iteration: 11456 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 269 loss: 1.36752 acc: 0.70280 | v_loss: 1.46412 v_acc: 0.70117 |  iteration: 11457 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 270 loss: 1.33467 acc: 0.70866 | v_loss: 1.49984 v_acc: 0.70150 |  iteration: 11458 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 271 loss: 1.44248 acc: 0.71061 | v_loss: 1.54395 v_acc: 0.69368 |  iteration: 11459 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 272 loss: 1.56782 acc: 0.69173 | v_loss: 1.48088 v_acc: 0.70833 |  iteration: 11460 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 273 loss: 1.46089 acc: 0.69889 | v_loss: 1.43620 v_acc: 0.70085 |  iteration: 11461 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 274 loss: 1.38672 acc: 0.71029 | v_loss: 1.41759 v_acc: 0.70931 |  iteration: 11462 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 275 loss: 1.42473 acc: 0.71517 | v_loss: 1.40855 v_acc: 0.70475 |  iteration: 11463 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 276 loss: 1.48024 acc: 0.70150 | v_loss: 1.26826 v_acc: 0.71354 |  iteration: 11464 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 277 loss: 1.35566 acc: 0.71061 | v_loss: 1.33378 v_acc: 0.71973 |  iteration: 11465 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 278 loss: 1.39917 acc: 0.71680 | v_loss: 1.20120 v_acc: 0.70605 |  iteration: 11466 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 279 loss: 1.44037 acc: 0.71159 | v_loss: 1.34691 v_acc: 0.70703 |  iteration: 11467 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 280 loss: 1.40472 acc: 0.71484 | v_loss: 1.51419 v_acc: 0.69987 |  iteration: 11468 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 281 loss: 1.42139 acc: 0.71029 | v_loss: 1.34181 v_acc: 0.70638 |  iteration: 11469 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 282 loss: 1.38835 acc: 0.71224 | v_loss: 1.35711 v_acc: 0.69661 |  iteration: 11470 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 283 loss: 1.39828 acc: 0.71908 | v_loss: 1.26499 v_acc: 0.70573 |  iteration: 11471 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 284 loss: 1.37472 acc: 0.70475 | v_loss: 1.25107 v_acc: 0.70215 |  iteration: 11472 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 285 loss: 1.50211 acc: 0.70475 | v_loss: 1.24064 v_acc: 0.73438 |  iteration: 11473 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 286 loss: 1.53920 acc: 0.69499 | v_loss: 1.27881 v_acc: 0.71680 |  iteration: 11474 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 287 loss: 1.58013 acc: 0.68848 | v_loss: 1.34915 v_acc: 0.73014 |  iteration: 11475 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 288 loss: 1.38670 acc: 0.70182 | v_loss: 1.27070 v_acc: 0.72396 |  iteration: 11476 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 289 loss: 1.37953 acc: 0.70443 | v_loss: 1.30978 v_acc: 0.71810 |  iteration: 11477 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 290 loss: 1.50750 acc: 0.69857 | v_loss: 1.41919 v_acc: 0.71191 |  iteration: 11478 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 291 loss: 1.51621 acc: 0.69564 | v_loss: 1.39270 v_acc: 0.72070 |  iteration: 11479 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 292 loss: 1.48531 acc: 0.70182 | v_loss: 1.48847 v_acc: 0.69954 |  iteration: 11480 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 293 loss: 1.50456 acc: 0.69466 | v_loss: 1.42231 v_acc: 0.71777 |  iteration: 11481 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 294 loss: 1.41240 acc: 0.70182 | v_loss: 1.18673 v_acc: 0.74512 |  iteration: 11482 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 295 loss: 1.40594 acc: 0.70768 | v_loss: 1.26874 v_acc: 0.70931 |  iteration: 11483 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 296 loss: 1.42923 acc: 0.70996 | v_loss: 1.50738 v_acc: 0.70247 |  iteration: 11484 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 297 loss: 1.44258 acc: 0.70345 | v_loss: 1.22740 v_acc: 0.70866 |  iteration: 11485 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 298 loss: 1.36501 acc: 0.70605 | v_loss: 1.32703 v_acc: 0.71159 |  iteration: 11486 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 299 loss: 1.31429 acc: 0.70736 | v_loss: 1.35832 v_acc: 0.69336 |  iteration: 11487 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 300 loss: 1.41591 acc: 0.70085 | v_loss: 1.29543 v_acc: 0.71191 |  iteration: 11488 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 301 loss: 1.39655 acc: 0.71322 | v_loss: 1.36709 v_acc: 0.69531 |  iteration: 11489 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 302 loss: 1.40246 acc: 0.70573 | v_loss: 1.49019 v_acc: 0.71191 |  iteration: 11490 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 303 loss: 1.50764 acc: 0.70020 | v_loss: 1.32361 v_acc: 0.72461 |  iteration: 11491 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 304 loss: 1.40505 acc: 0.69824 | v_loss: 1.45315 v_acc: 0.70312 |  iteration: 11492 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 305 loss: 1.46932 acc: 0.69531 | v_loss: 1.36735 v_acc: 0.69857 |  iteration: 11493 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 306 loss: 1.45520 acc: 0.69303 | v_loss: 1.31668 v_acc: 0.70833 |  iteration: 11494 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 307 loss: 1.56915 acc: 0.69922 | v_loss: 1.57593 v_acc: 0.68522 |  iteration: 11495 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 308 loss: 1.38881 acc: 0.70410 | v_loss: 1.30688 v_acc: 0.72363 |  iteration: 11496 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 309 loss: 1.55936 acc: 0.68424 | v_loss: 1.58074 v_acc: 0.68294 |  iteration: 11497 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 310 loss: 1.36286 acc: 0.70898 | v_loss: 1.45228 v_acc: 0.69889 |  iteration: 11498 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 311 loss: 1.47736 acc: 0.69368 | v_loss: 1.51254 v_acc: 0.68978 |  iteration: 11499 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 312 loss: 1.40625 acc: 0.70540 | v_loss: 1.37317 v_acc: 0.69792 |  iteration: 11500 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 313 loss: 1.49483 acc: 0.70020 | v_loss: 1.31705 v_acc: 0.70378 |  iteration: 11501 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 314 loss: 1.49954 acc: 0.69922 | v_loss: 1.33318 v_acc: 0.69889 |  iteration: 11502 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 315 loss: 1.44917 acc: 0.69987 | v_loss: 1.33173 v_acc: 0.71419 |  iteration: 11503 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 316 loss: 1.41590 acc: 0.70573 | v_loss: 1.53612 v_acc: 0.68978 |  iteration: 11504 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 317 loss: 1.50411 acc: 0.70117 | v_loss: 1.39008 v_acc: 0.70443 |  iteration: 11505 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 318 loss: 1.39079 acc: 0.70540 | v_loss: 1.35538 v_acc: 0.71029 |  iteration: 11506 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 319 loss: 1.40943 acc: 0.70378 | v_loss: 1.38656 v_acc: 0.71680 |  iteration: 11507 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 320 loss: 1.39889 acc: 0.71191 | v_loss: 1.27853 v_acc: 0.70508 |  iteration: 11508 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 321 loss: 1.48565 acc: 0.69987 | v_loss: 1.43484 v_acc: 0.69922 |  iteration: 11509 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 322 loss: 1.39568 acc: 0.70443 | v_loss: 1.43583 v_acc: 0.71354 |  iteration: 11510 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 323 loss: 1.42041 acc: 0.70866 | v_loss: 1.29100 v_acc: 0.71940 |  iteration: 11511 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 324 loss: 1.32550 acc: 0.71159 | v_loss: 1.26727 v_acc: 0.72689 |  iteration: 11512 teacher: 0 stage: sketch lr: 0.000412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 325 loss: 1.40915 acc: 0.70345 | v_loss: 1.39503 v_acc: 0.71908 |  iteration: 11513 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 326 loss: 1.35653 acc: 0.70508 | v_loss: 1.42490 v_acc: 0.70150 |  iteration: 11514 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 327 loss: 1.44531 acc: 0.71029 | v_loss: 1.42643 v_acc: 0.70833 |  iteration: 11515 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 328 loss: 1.37209 acc: 0.71126 | v_loss: 1.22173 v_acc: 0.72331 |  iteration: 11516 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 329 loss: 1.34336 acc: 0.70898 | v_loss: 1.38712 v_acc: 0.73145 |  iteration: 11517 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 330 loss: 1.36259 acc: 0.70671 | v_loss: 1.48006 v_acc: 0.69727 |  iteration: 11518 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 331 loss: 1.53455 acc: 0.68913 | v_loss: 1.42599 v_acc: 0.72363 |  iteration: 11519 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 332 loss: 1.43503 acc: 0.69857 | v_loss: 1.24421 v_acc: 0.71842 |  iteration: 11520 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 333 loss: 1.43615 acc: 0.70378 | v_loss: 1.19197 v_acc: 0.74023 |  iteration: 11521 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 334 loss: 1.61990 acc: 0.69303 | v_loss: 1.21116 v_acc: 0.72591 |  iteration: 11522 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 335 loss: 1.49522 acc: 0.68620 | v_loss: 1.28230 v_acc: 0.71126 |  iteration: 11523 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 336 loss: 1.49426 acc: 0.69303 | v_loss: 1.44871 v_acc: 0.70052 |  iteration: 11524 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 337 loss: 1.42721 acc: 0.70736 | v_loss: 1.28742 v_acc: 0.71452 |  iteration: 11525 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 338 loss: 1.47042 acc: 0.69108 | v_loss: 1.45457 v_acc: 0.71647 |  iteration: 11526 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 339 loss: 1.37165 acc: 0.70964 | v_loss: 1.65699 v_acc: 0.69303 |  iteration: 11527 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 340 loss: 1.33393 acc: 0.71517 | v_loss: 1.51682 v_acc: 0.70117 |  iteration: 11528 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 341 loss: 1.50864 acc: 0.70280 | v_loss: 1.29405 v_acc: 0.72363 |  iteration: 11529 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 342 loss: 1.54663 acc: 0.69173 | v_loss: 1.37878 v_acc: 0.69987 |  iteration: 11530 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 343 loss: 1.61376 acc: 0.68652 | v_loss: 1.23847 v_acc: 0.71615 |  iteration: 11531 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 344 loss: 1.44661 acc: 0.70117 | v_loss: 1.43146 v_acc: 0.69857 |  iteration: 11532 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 345 loss: 1.39405 acc: 0.69303 | v_loss: 1.36652 v_acc: 0.71029 |  iteration: 11533 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 346 loss: 1.47572 acc: 0.69759 | v_loss: 1.36076 v_acc: 0.73079 |  iteration: 11534 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 347 loss: 1.53991 acc: 0.69238 | v_loss: 1.35884 v_acc: 0.71777 |  iteration: 11535 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 348 loss: 1.43696 acc: 0.70508 | v_loss: 1.37398 v_acc: 0.70964 |  iteration: 11536 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 349 loss: 1.52699 acc: 0.69596 | v_loss: 1.29397 v_acc: 0.72493 |  iteration: 11537 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 350 loss: 1.34779 acc: 0.70931 | v_loss: 1.30055 v_acc: 0.72038 |  iteration: 11538 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 351 loss: 1.47100 acc: 0.70280 | v_loss: 1.51450 v_acc: 0.69368 |  iteration: 11539 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 352 loss: 1.37680 acc: 0.70443 | v_loss: 1.32880 v_acc: 0.71452 |  iteration: 11540 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 353 loss: 1.48435 acc: 0.70020 | v_loss: 1.30120 v_acc: 0.71777 |  iteration: 11541 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 354 loss: 1.41505 acc: 0.69922 | v_loss: 1.29743 v_acc: 0.71484 |  iteration: 11542 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 355 loss: 1.47861 acc: 0.69727 | v_loss: 1.44185 v_acc: 0.70540 |  iteration: 11543 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 356 loss: 1.38186 acc: 0.70443 | v_loss: 1.31597 v_acc: 0.73112 |  iteration: 11544 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 357 loss: 1.39146 acc: 0.70931 | v_loss: 1.55470 v_acc: 0.71354 |  iteration: 11545 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 358 loss: 1.49540 acc: 0.69792 | v_loss: 1.28011 v_acc: 0.69922 |  iteration: 11546 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 359 loss: 1.52880 acc: 0.70475 | v_loss: 1.28404 v_acc: 0.70117 |  iteration: 11547 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 360 loss: 1.45420 acc: 0.70085 | v_loss: 1.45828 v_acc: 0.70508 |  iteration: 11548 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 361 loss: 1.29669 acc: 0.72266 | v_loss: 1.47706 v_acc: 0.70573 |  iteration: 11549 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 362 loss: 1.45954 acc: 0.70378 | v_loss: 1.51947 v_acc: 0.68978 |  iteration: 11550 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 363 loss: 1.48924 acc: 0.69596 | v_loss: 1.46745 v_acc: 0.70540 |  iteration: 11551 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 364 loss: 1.39717 acc: 0.70898 | v_loss: 1.41869 v_acc: 0.70540 |  iteration: 11552 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 365 loss: 1.41153 acc: 0.71029 | v_loss: 1.40125 v_acc: 0.70475 |  iteration: 11553 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 366 loss: 1.45265 acc: 0.69499 | v_loss: 1.43226 v_acc: 0.70312 |  iteration: 11554 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 367 loss: 1.43130 acc: 0.70085 | v_loss: 1.28720 v_acc: 0.71354 |  iteration: 11555 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 368 loss: 1.52443 acc: 0.69531 | v_loss: 1.31713 v_acc: 0.72331 |  iteration: 11556 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 369 loss: 1.36565 acc: 0.71061 | v_loss: 1.19243 v_acc: 0.71615 |  iteration: 11557 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 370 loss: 1.44499 acc: 0.70508 | v_loss: 1.34042 v_acc: 0.71126 |  iteration: 11558 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 371 loss: 1.33981 acc: 0.71940 | v_loss: 1.51118 v_acc: 0.69954 |  iteration: 11559 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 372 loss: 1.43118 acc: 0.70280 | v_loss: 1.33745 v_acc: 0.71484 |  iteration: 11560 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 373 loss: 1.43287 acc: 0.70345 | v_loss: 1.35325 v_acc: 0.70312 |  iteration: 11561 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 374 loss: 1.49244 acc: 0.69857 | v_loss: 1.24884 v_acc: 0.71680 |  iteration: 11562 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 375 loss: 1.52257 acc: 0.69434 | v_loss: 1.23601 v_acc: 0.70671 |  iteration: 11563 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 376 loss: 1.43691 acc: 0.69499 | v_loss: 1.25652 v_acc: 0.73568 |  iteration: 11564 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 377 loss: 1.58987 acc: 0.69076 | v_loss: 1.26630 v_acc: 0.72461 |  iteration: 11565 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 378 loss: 1.41084 acc: 0.70085 | v_loss: 1.34418 v_acc: 0.72689 |  iteration: 11566 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 379 loss: 1.54078 acc: 0.69824 | v_loss: 1.26354 v_acc: 0.72852 |  iteration: 11567 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 380 loss: 1.47515 acc: 0.69238 | v_loss: 1.30027 v_acc: 0.72005 |  iteration: 11568 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 381 loss: 1.45417 acc: 0.70280 | v_loss: 1.40364 v_acc: 0.71224 |  iteration: 11569 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 382 loss: 1.49005 acc: 0.70182 | v_loss: 1.37954 v_acc: 0.72070 |  iteration: 11570 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 383 loss: 1.55133 acc: 0.69368 | v_loss: 1.48765 v_acc: 0.69954 |  iteration: 11571 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 384 loss: 1.42404 acc: 0.69987 | v_loss: 1.41413 v_acc: 0.71615 |  iteration: 11572 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 385 loss: 1.45627 acc: 0.70703 | v_loss: 1.19189 v_acc: 0.74544 |  iteration: 11573 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 386 loss: 1.47993 acc: 0.69401 | v_loss: 1.28931 v_acc: 0.70931 |  iteration: 11574 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 387 loss: 1.52779 acc: 0.70247 | v_loss: 1.52151 v_acc: 0.70247 |  iteration: 11575 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 388 loss: 1.43515 acc: 0.69889 | v_loss: 1.24872 v_acc: 0.70866 |  iteration: 11576 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 389 loss: 1.52515 acc: 0.69987 | v_loss: 1.32950 v_acc: 0.71159 |  iteration: 11577 teacher: 0 stage: sketch lr: 0.000411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 390 loss: 1.48421 acc: 0.70410 | v_loss: 1.37799 v_acc: 0.69336 |  iteration: 11578 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 391 loss: 1.50217 acc: 0.70443 | v_loss: 1.30062 v_acc: 0.71191 |  iteration: 11579 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 392 loss: 1.46296 acc: 0.70378 | v_loss: 1.36680 v_acc: 0.69629 |  iteration: 11580 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 393 loss: 1.46894 acc: 0.70801 | v_loss: 1.47040 v_acc: 0.71517 |  iteration: 11581 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 394 loss: 1.45969 acc: 0.69727 | v_loss: 1.31394 v_acc: 0.72363 |  iteration: 11582 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 395 loss: 1.53678 acc: 0.69987 | v_loss: 1.45922 v_acc: 0.70117 |  iteration: 11583 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 396 loss: 1.47880 acc: 0.70768 | v_loss: 1.35148 v_acc: 0.70085 |  iteration: 11584 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 397 loss: 1.45771 acc: 0.71094 | v_loss: 1.34688 v_acc: 0.70703 |  iteration: 11585 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 398 loss: 1.36868 acc: 0.71908 | v_loss: 1.53724 v_acc: 0.68880 |  iteration: 11586 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 399 loss: 1.49582 acc: 0.70703 | v_loss: 1.31257 v_acc: 0.72103 |  iteration: 11587 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 400 loss: 1.41590 acc: 0.70833 | v_loss: 1.57756 v_acc: 0.68620 |  iteration: 11588 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 401 loss: 1.36341 acc: 0.70898 | v_loss: 1.43496 v_acc: 0.69987 |  iteration: 11589 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 402 loss: 1.47826 acc: 0.70020 | v_loss: 1.51894 v_acc: 0.68913 |  iteration: 11590 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 403 loss: 1.35563 acc: 0.71615 | v_loss: 1.37662 v_acc: 0.69759 |  iteration: 11591 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 404 loss: 1.43918 acc: 0.70703 | v_loss: 1.32240 v_acc: 0.70312 |  iteration: 11592 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 405 loss: 1.42628 acc: 0.70312 | v_loss: 1.33977 v_acc: 0.70020 |  iteration: 11593 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 406 loss: 1.40546 acc: 0.70247 | v_loss: 1.33473 v_acc: 0.71842 |  iteration: 11594 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 407 loss: 1.49729 acc: 0.69596 | v_loss: 1.57413 v_acc: 0.69108 |  iteration: 11595 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 408 loss: 1.40693 acc: 0.70085 | v_loss: 1.39704 v_acc: 0.71126 |  iteration: 11596 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 409 loss: 1.35233 acc: 0.71484 | v_loss: 1.35289 v_acc: 0.71029 |  iteration: 11597 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 410 loss: 1.46820 acc: 0.70540 | v_loss: 1.38937 v_acc: 0.71680 |  iteration: 11598 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 411 loss: 1.36534 acc: 0.70671 | v_loss: 1.26979 v_acc: 0.70443 |  iteration: 11599 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 412 loss: 1.43546 acc: 0.70312 | v_loss: 1.43088 v_acc: 0.69922 |  iteration: 11600 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 413 loss: 1.44451 acc: 0.70280 | v_loss: 1.42439 v_acc: 0.71354 |  iteration: 11601 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 414 loss: 1.47258 acc: 0.69531 | v_loss: 1.28936 v_acc: 0.71940 |  iteration: 11602 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 415 loss: 1.45839 acc: 0.70475 | v_loss: 1.25609 v_acc: 0.72754 |  iteration: 11603 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 416 loss: 1.45337 acc: 0.70020 | v_loss: 1.37512 v_acc: 0.71940 |  iteration: 11604 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 417 loss: 1.31476 acc: 0.71126 | v_loss: 1.41994 v_acc: 0.70345 |  iteration: 11605 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 418 loss: 1.37780 acc: 0.69759 | v_loss: 1.42497 v_acc: 0.70410 |  iteration: 11606 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 419 loss: 1.53874 acc: 0.69857 | v_loss: 1.22690 v_acc: 0.71712 |  iteration: 11607 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 420 loss: 1.48891 acc: 0.69434 | v_loss: 1.40302 v_acc: 0.72786 |  iteration: 11608 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 421 loss: 1.37469 acc: 0.70605 | v_loss: 1.47611 v_acc: 0.69792 |  iteration: 11609 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 422 loss: 1.48641 acc: 0.69466 | v_loss: 1.41136 v_acc: 0.72070 |  iteration: 11610 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 423 loss: 1.35879 acc: 0.70866 | v_loss: 1.24725 v_acc: 0.72201 |  iteration: 11611 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 424 loss: 1.42232 acc: 0.70964 | v_loss: 1.20029 v_acc: 0.74023 |  iteration: 11612 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 425 loss: 1.36242 acc: 0.70801 | v_loss: 1.21749 v_acc: 0.72656 |  iteration: 11613 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 426 loss: 1.54597 acc: 0.69434 | v_loss: 1.29373 v_acc: 0.70703 |  iteration: 11614 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 427 loss: 1.56527 acc: 0.69336 | v_loss: 1.45791 v_acc: 0.69466 |  iteration: 11615 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 428 loss: 1.42839 acc: 0.70475 | v_loss: 1.27336 v_acc: 0.71484 |  iteration: 11616 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 429 loss: 1.39530 acc: 0.71126 | v_loss: 1.43016 v_acc: 0.72949 |  iteration: 11617 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 430 loss: 1.37520 acc: 0.71419 | v_loss: 1.64512 v_acc: 0.69466 |  iteration: 11618 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 431 loss: 1.51953 acc: 0.69661 | v_loss: 1.51093 v_acc: 0.70410 |  iteration: 11619 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 432 loss: 1.48612 acc: 0.69922 | v_loss: 1.29613 v_acc: 0.72005 |  iteration: 11620 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 433 loss: 1.49507 acc: 0.69368 | v_loss: 1.37159 v_acc: 0.70215 |  iteration: 11621 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 434 loss: 1.41064 acc: 0.70768 | v_loss: 1.21997 v_acc: 0.72201 |  iteration: 11622 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 435 loss: 1.50543 acc: 0.69336 | v_loss: 1.40962 v_acc: 0.70378 |  iteration: 11623 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 436 loss: 1.45817 acc: 0.69694 | v_loss: 1.36993 v_acc: 0.71810 |  iteration: 11624 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 437 loss: 1.47755 acc: 0.69661 | v_loss: 1.35896 v_acc: 0.73014 |  iteration: 11625 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 438 loss: 1.39749 acc: 0.69889 | v_loss: 1.38168 v_acc: 0.71842 |  iteration: 11626 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 439 loss: 1.41056 acc: 0.70866 | v_loss: 1.37809 v_acc: 0.71452 |  iteration: 11627 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 440 loss: 1.33242 acc: 0.70736 | v_loss: 1.28041 v_acc: 0.72526 |  iteration: 11628 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 441 loss: 1.37759 acc: 0.70345 | v_loss: 1.28853 v_acc: 0.72298 |  iteration: 11629 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 442 loss: 1.45437 acc: 0.69531 | v_loss: 1.46611 v_acc: 0.69043 |  iteration: 11630 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 443 loss: 1.46526 acc: 0.69727 | v_loss: 1.33728 v_acc: 0.71191 |  iteration: 11631 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 444 loss: 1.49946 acc: 0.69792 | v_loss: 1.28875 v_acc: 0.71973 |  iteration: 11632 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 445 loss: 1.49955 acc: 0.70020 | v_loss: 1.29468 v_acc: 0.71484 |  iteration: 11633 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 446 loss: 1.45793 acc: 0.69824 | v_loss: 1.45192 v_acc: 0.70443 |  iteration: 11634 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 447 loss: 1.50073 acc: 0.69531 | v_loss: 1.32128 v_acc: 0.73145 |  iteration: 11635 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 448 loss: 1.42831 acc: 0.70540 | v_loss: 1.56204 v_acc: 0.71191 |  iteration: 11636 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 449 loss: 1.47103 acc: 0.70117 | v_loss: 1.28444 v_acc: 0.70215 |  iteration: 11637 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 450 loss: 1.37130 acc: 0.70573 | v_loss: 1.29390 v_acc: 0.70671 |  iteration: 11638 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 451 loss: 1.59872 acc: 0.69206 | v_loss: 1.44448 v_acc: 0.70345 |  iteration: 11639 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 452 loss: 1.37046 acc: 0.70182 | v_loss: 1.46573 v_acc: 0.70378 |  iteration: 11640 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 453 loss: 1.46583 acc: 0.70475 | v_loss: 1.50648 v_acc: 0.68978 |  iteration: 11641 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 454 loss: 1.35912 acc: 0.71289 | v_loss: 1.46957 v_acc: 0.70540 |  iteration: 11642 teacher: 0 stage: sketch lr: 0.000410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 455 loss: 1.43000 acc: 0.70280 | v_loss: 1.42519 v_acc: 0.70410 |  iteration: 11643 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 456 loss: 1.47258 acc: 0.70671 | v_loss: 1.40204 v_acc: 0.70768 |  iteration: 11644 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 457 loss: 1.55091 acc: 0.68717 | v_loss: 1.40992 v_acc: 0.70475 |  iteration: 11645 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 458 loss: 1.40235 acc: 0.71126 | v_loss: 1.26932 v_acc: 0.71354 |  iteration: 11646 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 459 loss: 1.45637 acc: 0.69466 | v_loss: 1.32769 v_acc: 0.72461 |  iteration: 11647 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 460 loss: 1.47292 acc: 0.69727 | v_loss: 1.18418 v_acc: 0.71517 |  iteration: 11648 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 461 loss: 1.45860 acc: 0.70410 | v_loss: 1.34126 v_acc: 0.71126 |  iteration: 11649 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 462 loss: 1.40273 acc: 0.71452 | v_loss: 1.51439 v_acc: 0.69954 |  iteration: 11650 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 463 loss: 1.44104 acc: 0.70280 | v_loss: 1.33575 v_acc: 0.70540 |  iteration: 11651 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 464 loss: 1.35387 acc: 0.70475 | v_loss: 1.37785 v_acc: 0.69368 |  iteration: 11652 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 465 loss: 1.47491 acc: 0.69759 | v_loss: 1.25007 v_acc: 0.70573 |  iteration: 11653 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 466 loss: 1.51109 acc: 0.69661 | v_loss: 1.25571 v_acc: 0.70215 |  iteration: 11654 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 467 loss: 1.48442 acc: 0.69889 | v_loss: 1.25073 v_acc: 0.73340 |  iteration: 11655 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 468 loss: 1.47644 acc: 0.69792 | v_loss: 1.27980 v_acc: 0.71647 |  iteration: 11656 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 469 loss: 1.47903 acc: 0.69401 | v_loss: 1.34201 v_acc: 0.74089 |  iteration: 11657 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 470 loss: 1.39463 acc: 0.70443 | v_loss: 1.26980 v_acc: 0.72005 |  iteration: 11658 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 471 loss: 1.35618 acc: 0.71354 | v_loss: 1.30291 v_acc: 0.71582 |  iteration: 11659 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 472 loss: 1.42064 acc: 0.70638 | v_loss: 1.41220 v_acc: 0.71289 |  iteration: 11660 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 473 loss: 1.54786 acc: 0.69368 | v_loss: 1.38379 v_acc: 0.72298 |  iteration: 11661 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 474 loss: 1.33065 acc: 0.71615 | v_loss: 1.49306 v_acc: 0.70182 |  iteration: 11662 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 475 loss: 1.49564 acc: 0.70247 | v_loss: 1.41716 v_acc: 0.71777 |  iteration: 11663 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 476 loss: 1.50789 acc: 0.69694 | v_loss: 1.17049 v_acc: 0.74447 |  iteration: 11664 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 477 loss: 1.29226 acc: 0.70964 | v_loss: 1.26269 v_acc: 0.71159 |  iteration: 11665 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 478 loss: 1.36582 acc: 0.70768 | v_loss: 1.54429 v_acc: 0.69303 |  iteration: 11666 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 479 loss: 1.43937 acc: 0.69954 | v_loss: 1.24189 v_acc: 0.69466 |  iteration: 11667 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 480 loss: 1.40220 acc: 0.70703 | v_loss: 1.33694 v_acc: 0.70182 |  iteration: 11668 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 481 loss: 1.35622 acc: 0.70931 | v_loss: 1.36573 v_acc: 0.69076 |  iteration: 11669 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 482 loss: 1.32068 acc: 0.70475 | v_loss: 1.29385 v_acc: 0.70768 |  iteration: 11670 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 483 loss: 1.52830 acc: 0.70378 | v_loss: 1.37007 v_acc: 0.69466 |  iteration: 11671 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 484 loss: 1.47978 acc: 0.70573 | v_loss: 1.47377 v_acc: 0.71094 |  iteration: 11672 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 485 loss: 1.37248 acc: 0.70898 | v_loss: 1.31533 v_acc: 0.72233 |  iteration: 11673 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 486 loss: 1.57574 acc: 0.69173 | v_loss: 1.43513 v_acc: 0.70378 |  iteration: 11674 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 487 loss: 1.39803 acc: 0.70215 | v_loss: 1.37453 v_acc: 0.70085 |  iteration: 11675 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 488 loss: 1.50399 acc: 0.69401 | v_loss: 1.34186 v_acc: 0.70703 |  iteration: 11676 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 489 loss: 1.40243 acc: 0.70410 | v_loss: 1.54036 v_acc: 0.68880 |  iteration: 11677 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 490 loss: 1.46555 acc: 0.69727 | v_loss: 1.29718 v_acc: 0.72103 |  iteration: 11678 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 491 loss: 1.41397 acc: 0.70215 | v_loss: 1.57673 v_acc: 0.68620 |  iteration: 11679 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 492 loss: 1.41419 acc: 0.70085 | v_loss: 1.44507 v_acc: 0.69792 |  iteration: 11680 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 493 loss: 1.43100 acc: 0.70410 | v_loss: 1.53671 v_acc: 0.69173 |  iteration: 11681 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 494 loss: 1.47878 acc: 0.69857 | v_loss: 1.36919 v_acc: 0.70052 |  iteration: 11682 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 495 loss: 1.43164 acc: 0.69824 | v_loss: 1.33480 v_acc: 0.70540 |  iteration: 11683 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 496 loss: 1.32804 acc: 0.70703 | v_loss: 1.32976 v_acc: 0.70410 |  iteration: 11684 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 497 loss: 1.40241 acc: 0.70085 | v_loss: 1.32858 v_acc: 0.71484 |  iteration: 11685 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 498 loss: 1.40981 acc: 0.70345 | v_loss: 1.53403 v_acc: 0.68978 |  iteration: 11686 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 499 loss: 1.39425 acc: 0.71549 | v_loss: 1.37531 v_acc: 0.70443 |  iteration: 11687 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 500 loss: 1.48759 acc: 0.69336 | v_loss: 1.35898 v_acc: 0.71029 |  iteration: 11688 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 501 loss: 1.47516 acc: 0.70150 | v_loss: 1.38275 v_acc: 0.71582 |  iteration: 11689 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 502 loss: 1.47422 acc: 0.69499 | v_loss: 1.27023 v_acc: 0.70443 |  iteration: 11690 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 503 loss: 1.55736 acc: 0.68327 | v_loss: 1.43404 v_acc: 0.69889 |  iteration: 11691 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 504 loss: 1.54310 acc: 0.70247 | v_loss: 1.41578 v_acc: 0.71615 |  iteration: 11692 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 505 loss: 1.42497 acc: 0.70052 | v_loss: 1.30191 v_acc: 0.71257 |  iteration: 11693 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 506 loss: 1.47988 acc: 0.69857 | v_loss: 1.24997 v_acc: 0.72559 |  iteration: 11694 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 507 loss: 1.49677 acc: 0.69824 | v_loss: 1.37843 v_acc: 0.71615 |  iteration: 11695 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 508 loss: 1.44013 acc: 0.70573 | v_loss: 1.42385 v_acc: 0.69727 |  iteration: 11696 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 509 loss: 1.40883 acc: 0.70443 | v_loss: 1.42328 v_acc: 0.70312 |  iteration: 11697 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 510 loss: 1.33949 acc: 0.71387 | v_loss: 1.24811 v_acc: 0.71419 |  iteration: 11698 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 511 loss: 1.40020 acc: 0.70638 | v_loss: 1.40412 v_acc: 0.72819 |  iteration: 11699 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 512 loss: 1.41278 acc: 0.70540 | v_loss: 1.47991 v_acc: 0.69792 |  iteration: 11700 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 513 loss: 1.35212 acc: 0.70964 | v_loss: 1.40143 v_acc: 0.71842 |  iteration: 11701 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 514 loss: 1.51340 acc: 0.69108 | v_loss: 1.24937 v_acc: 0.72201 |  iteration: 11702 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 515 loss: 1.49310 acc: 0.69889 | v_loss: 1.19910 v_acc: 0.74023 |  iteration: 11703 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 516 loss: 1.54369 acc: 0.69499 | v_loss: 1.20845 v_acc: 0.72493 |  iteration: 11704 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 517 loss: 1.39066 acc: 0.71322 | v_loss: 1.27094 v_acc: 0.71126 |  iteration: 11705 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 518 loss: 1.43714 acc: 0.70573 | v_loss: 1.44523 v_acc: 0.70671 |  iteration: 11706 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 519 loss: 1.39668 acc: 0.70638 | v_loss: 1.27599 v_acc: 0.71549 |  iteration: 11707 teacher: 1 stage: sketch lr: 0.000408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 520 loss: 1.43435 acc: 0.70410 | v_loss: 1.49062 v_acc: 0.70410 |  iteration: 11708 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 521 loss: 1.37713 acc: 0.70801 | v_loss: 1.67894 v_acc: 0.69238 |  iteration: 11709 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 522 loss: 1.41698 acc: 0.70312 | v_loss: 1.53199 v_acc: 0.69531 |  iteration: 11710 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 523 loss: 1.48785 acc: 0.68652 | v_loss: 1.29797 v_acc: 0.72168 |  iteration: 11711 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 524 loss: 1.39281 acc: 0.70833 | v_loss: 1.37015 v_acc: 0.70866 |  iteration: 11712 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 525 loss: 1.42285 acc: 0.70540 | v_loss: 1.21675 v_acc: 0.72103 |  iteration: 11713 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 526 loss: 1.35914 acc: 0.71419 | v_loss: 1.43000 v_acc: 0.70020 |  iteration: 11714 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 527 loss: 1.45400 acc: 0.70215 | v_loss: 1.35823 v_acc: 0.71094 |  iteration: 11715 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 528 loss: 1.34218 acc: 0.70703 | v_loss: 1.35958 v_acc: 0.72949 |  iteration: 11716 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 529 loss: 1.42565 acc: 0.71680 | v_loss: 1.36001 v_acc: 0.71777 |  iteration: 11717 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 530 loss: 1.48079 acc: 0.70345 | v_loss: 1.37813 v_acc: 0.70410 |  iteration: 11718 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 531 loss: 1.47452 acc: 0.70247 | v_loss: 1.28643 v_acc: 0.72233 |  iteration: 11719 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 532 loss: 1.48670 acc: 0.70280 | v_loss: 1.29603 v_acc: 0.72135 |  iteration: 11720 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 533 loss: 1.35552 acc: 0.70052 | v_loss: 1.51075 v_acc: 0.69043 |  iteration: 11721 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 534 loss: 1.45716 acc: 0.70247 | v_loss: 1.35451 v_acc: 0.70833 |  iteration: 11722 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 535 loss: 1.50957 acc: 0.68783 | v_loss: 1.29027 v_acc: 0.71582 |  iteration: 11723 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 536 loss: 1.46114 acc: 0.70020 | v_loss: 1.28147 v_acc: 0.72201 |  iteration: 11724 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 537 loss: 1.31579 acc: 0.71387 | v_loss: 1.41468 v_acc: 0.70768 |  iteration: 11725 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 538 loss: 1.47846 acc: 0.69857 | v_loss: 1.32423 v_acc: 0.73210 |  iteration: 11726 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 539 loss: 1.32860 acc: 0.70443 | v_loss: 1.55283 v_acc: 0.71257 |  iteration: 11727 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 540 loss: 1.42840 acc: 0.69661 | v_loss: 1.27522 v_acc: 0.70312 |  iteration: 11728 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 541 loss: 1.46131 acc: 0.70215 | v_loss: 1.27193 v_acc: 0.69987 |  iteration: 11729 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 542 loss: 1.48384 acc: 0.70508 | v_loss: 1.45919 v_acc: 0.70475 |  iteration: 11730 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 543 loss: 1.33433 acc: 0.71289 | v_loss: 1.48017 v_acc: 0.70378 |  iteration: 11731 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 544 loss: 1.56189 acc: 0.69759 | v_loss: 1.51973 v_acc: 0.68978 |  iteration: 11732 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 545 loss: 1.55854 acc: 0.69108 | v_loss: 1.47574 v_acc: 0.70833 |  iteration: 11733 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 546 loss: 1.40089 acc: 0.70215 | v_loss: 1.43131 v_acc: 0.70410 |  iteration: 11734 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 547 loss: 1.38467 acc: 0.70833 | v_loss: 1.41403 v_acc: 0.70768 |  iteration: 11735 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 548 loss: 1.57570 acc: 0.69141 | v_loss: 1.40507 v_acc: 0.70475 |  iteration: 11736 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 549 loss: 1.30715 acc: 0.71777 | v_loss: 1.26146 v_acc: 0.71354 |  iteration: 11737 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 550 loss: 1.40470 acc: 0.70247 | v_loss: 1.33935 v_acc: 0.72461 |  iteration: 11738 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 551 loss: 1.52420 acc: 0.70247 | v_loss: 1.19040 v_acc: 0.71517 |  iteration: 11739 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 552 loss: 1.41120 acc: 0.70898 | v_loss: 1.34095 v_acc: 0.70150 |  iteration: 11740 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 553 loss: 1.29538 acc: 0.71549 | v_loss: 1.50867 v_acc: 0.69987 |  iteration: 11741 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 554 loss: 1.46627 acc: 0.68783 | v_loss: 1.34792 v_acc: 0.70540 |  iteration: 11742 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 555 loss: 1.52806 acc: 0.69368 | v_loss: 1.36785 v_acc: 0.69368 |  iteration: 11743 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 556 loss: 1.41924 acc: 0.70638 | v_loss: 1.24691 v_acc: 0.71094 |  iteration: 11744 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 557 loss: 1.38440 acc: 0.71191 | v_loss: 1.25572 v_acc: 0.70182 |  iteration: 11745 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 558 loss: 1.44463 acc: 0.70378 | v_loss: 1.24344 v_acc: 0.73535 |  iteration: 11746 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 559 loss: 1.32752 acc: 0.71452 | v_loss: 1.27018 v_acc: 0.71647 |  iteration: 11747 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 560 loss: 1.48455 acc: 0.70020 | v_loss: 1.33423 v_acc: 0.74089 |  iteration: 11748 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 561 loss: 1.51094 acc: 0.69499 | v_loss: 1.26638 v_acc: 0.72005 |  iteration: 11749 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 562 loss: 1.39513 acc: 0.70768 | v_loss: 1.30284 v_acc: 0.71582 |  iteration: 11750 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 563 loss: 1.44946 acc: 0.70378 | v_loss: 1.41141 v_acc: 0.71224 |  iteration: 11751 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 564 loss: 1.30535 acc: 0.71126 | v_loss: 1.38564 v_acc: 0.72038 |  iteration: 11752 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 565 loss: 1.40352 acc: 0.69889 | v_loss: 1.49284 v_acc: 0.69661 |  iteration: 11753 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 566 loss: 1.46556 acc: 0.69889 | v_loss: 1.43278 v_acc: 0.71615 |  iteration: 11754 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 567 loss: 1.40655 acc: 0.70475 | v_loss: 1.18166 v_acc: 0.74447 |  iteration: 11755 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 568 loss: 1.38605 acc: 0.70443 | v_loss: 1.25885 v_acc: 0.71322 |  iteration: 11756 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 569 loss: 1.43352 acc: 0.70833 | v_loss: 1.53487 v_acc: 0.69987 |  iteration: 11757 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 570 loss: 1.49165 acc: 0.69108 | v_loss: 1.20329 v_acc: 0.70671 |  iteration: 11758 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 571 loss: 1.45361 acc: 0.70215 | v_loss: 1.32616 v_acc: 0.71159 |  iteration: 11759 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 572 loss: 1.53431 acc: 0.70052 | v_loss: 1.36010 v_acc: 0.69076 |  iteration: 11760 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 573 loss: 1.38048 acc: 0.70475 | v_loss: 1.30430 v_acc: 0.70898 |  iteration: 11761 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 574 loss: 1.52356 acc: 0.70052 | v_loss: 1.36730 v_acc: 0.69206 |  iteration: 11762 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 575 loss: 1.28561 acc: 0.71257 | v_loss: 1.47239 v_acc: 0.70931 |  iteration: 11763 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 576 loss: 1.50322 acc: 0.69499 | v_loss: 1.31988 v_acc: 0.72363 |  iteration: 11764 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 577 loss: 1.48822 acc: 0.70345 | v_loss: 1.44728 v_acc: 0.70117 |  iteration: 11765 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 578 loss: 1.37179 acc: 0.70768 | v_loss: 1.37365 v_acc: 0.69954 |  iteration: 11766 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 579 loss: 1.40184 acc: 0.71549 | v_loss: 1.32162 v_acc: 0.70540 |  iteration: 11767 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 580 loss: 1.54505 acc: 0.69173 | v_loss: 1.58398 v_acc: 0.68587 |  iteration: 11768 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 581 loss: 1.44203 acc: 0.70247 | v_loss: 1.29180 v_acc: 0.72168 |  iteration: 11769 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 582 loss: 1.58321 acc: 0.69010 | v_loss: 1.60468 v_acc: 0.67969 |  iteration: 11770 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 583 loss: 1.33081 acc: 0.70703 | v_loss: 1.48626 v_acc: 0.69661 |  iteration: 11771 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 584 loss: 1.54110 acc: 0.68945 | v_loss: 1.52202 v_acc: 0.69238 |  iteration: 11772 teacher: 0 stage: sketch lr: 0.000407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 585 loss: 1.56968 acc: 0.70020 | v_loss: 1.38473 v_acc: 0.69759 |  iteration: 11773 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 586 loss: 1.40047 acc: 0.69987 | v_loss: 1.32582 v_acc: 0.70215 |  iteration: 11774 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 587 loss: 1.49038 acc: 0.70280 | v_loss: 1.34062 v_acc: 0.69889 |  iteration: 11775 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 588 loss: 1.36943 acc: 0.70768 | v_loss: 1.33242 v_acc: 0.71419 |  iteration: 11776 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 589 loss: 1.45170 acc: 0.70150 | v_loss: 1.51854 v_acc: 0.69401 |  iteration: 11777 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 590 loss: 1.43261 acc: 0.70215 | v_loss: 1.37868 v_acc: 0.69922 |  iteration: 11778 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 591 loss: 1.54151 acc: 0.69173 | v_loss: 1.35645 v_acc: 0.71126 |  iteration: 11779 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 592 loss: 1.47897 acc: 0.70378 | v_loss: 1.38784 v_acc: 0.71810 |  iteration: 11780 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 593 loss: 1.66332 acc: 0.68652 | v_loss: 1.28863 v_acc: 0.70215 |  iteration: 11781 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 594 loss: 1.43419 acc: 0.70638 | v_loss: 1.43256 v_acc: 0.69434 |  iteration: 11782 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 595 loss: 1.49584 acc: 0.70443 | v_loss: 1.42256 v_acc: 0.71452 |  iteration: 11783 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 596 loss: 1.45143 acc: 0.70443 | v_loss: 1.28464 v_acc: 0.71875 |  iteration: 11784 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 597 loss: 1.51071 acc: 0.70703 | v_loss: 1.26467 v_acc: 0.72754 |  iteration: 11785 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 598 loss: 1.44878 acc: 0.69857 | v_loss: 1.37400 v_acc: 0.71940 |  iteration: 11786 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 599 loss: 1.37529 acc: 0.70931 | v_loss: 1.41536 v_acc: 0.70345 |  iteration: 11787 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 600 loss: 1.53280 acc: 0.69434 | v_loss: 1.41979 v_acc: 0.70410 |  iteration: 11788 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 601 loss: 1.48134 acc: 0.70052 | v_loss: 1.23708 v_acc: 0.71712 |  iteration: 11789 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 602 loss: 1.39986 acc: 0.70345 | v_loss: 1.40918 v_acc: 0.72493 |  iteration: 11790 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 603 loss: 1.42852 acc: 0.70443 | v_loss: 1.48107 v_acc: 0.69531 |  iteration: 11791 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 604 loss: 1.34678 acc: 0.71191 | v_loss: 1.39384 v_acc: 0.72461 |  iteration: 11792 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 605 loss: 1.35768 acc: 0.71224 | v_loss: 1.26869 v_acc: 0.71061 |  iteration: 11793 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 606 loss: 1.39907 acc: 0.71712 | v_loss: 1.24069 v_acc: 0.73242 |  iteration: 11794 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 607 loss: 1.47451 acc: 0.69661 | v_loss: 1.23520 v_acc: 0.72656 |  iteration: 11795 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 608 loss: 1.46323 acc: 0.70996 | v_loss: 1.30247 v_acc: 0.70703 |  iteration: 11796 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 609 loss: 1.43390 acc: 0.70540 | v_loss: 1.46318 v_acc: 0.69466 |  iteration: 11797 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 610 loss: 1.51799 acc: 0.69727 | v_loss: 1.27809 v_acc: 0.71484 |  iteration: 11798 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 611 loss: 1.42827 acc: 0.70117 | v_loss: 1.44408 v_acc: 0.71647 |  iteration: 11799 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 612 loss: 1.42652 acc: 0.70703 | v_loss: 1.68690 v_acc: 0.69141 |  iteration: 11800 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 613 loss: 1.37814 acc: 0.70801 | v_loss: 1.52824 v_acc: 0.69727 |  iteration: 11801 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 614 loss: 1.57512 acc: 0.69368 | v_loss: 1.30327 v_acc: 0.72396 |  iteration: 11802 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 615 loss: 1.40428 acc: 0.70996 | v_loss: 1.36898 v_acc: 0.70996 |  iteration: 11803 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 616 loss: 1.44626 acc: 0.70215 | v_loss: 1.22729 v_acc: 0.72201 |  iteration: 11804 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 617 loss: 1.46769 acc: 0.70247 | v_loss: 1.40768 v_acc: 0.70378 |  iteration: 11805 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 618 loss: 1.47307 acc: 0.70573 | v_loss: 1.36528 v_acc: 0.71029 |  iteration: 11806 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 619 loss: 1.38033 acc: 0.69857 | v_loss: 1.35978 v_acc: 0.72949 |  iteration: 11807 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 620 loss: 1.45057 acc: 0.69564 | v_loss: 1.36003 v_acc: 0.72005 |  iteration: 11808 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 621 loss: 1.46330 acc: 0.70247 | v_loss: 1.37017 v_acc: 0.70573 |  iteration: 11809 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 622 loss: 1.43837 acc: 0.69857 | v_loss: 1.30658 v_acc: 0.72038 |  iteration: 11810 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 623 loss: 1.41492 acc: 0.69824 | v_loss: 1.31357 v_acc: 0.71875 |  iteration: 11811 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 624 loss: 1.50011 acc: 0.69564 | v_loss: 1.51686 v_acc: 0.69108 |  iteration: 11812 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 625 loss: 1.44413 acc: 0.69954 | v_loss: 1.32903 v_acc: 0.70931 |  iteration: 11813 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 626 loss: 1.42778 acc: 0.70215 | v_loss: 1.28941 v_acc: 0.71452 |  iteration: 11814 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 627 loss: 1.41832 acc: 0.70150 | v_loss: 1.28887 v_acc: 0.71940 |  iteration: 11815 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 628 loss: 1.49827 acc: 0.69303 | v_loss: 1.42788 v_acc: 0.70475 |  iteration: 11816 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 629 loss: 1.53552 acc: 0.69466 | v_loss: 1.31078 v_acc: 0.73210 |  iteration: 11817 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 630 loss: 1.45491 acc: 0.69434 | v_loss: 1.53519 v_acc: 0.71615 |  iteration: 11818 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 631 loss: 1.44254 acc: 0.70312 | v_loss: 1.28767 v_acc: 0.69922 |  iteration: 11819 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 632 loss: 1.37160 acc: 0.70996 | v_loss: 1.28056 v_acc: 0.70182 |  iteration: 11820 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 633 loss: 1.41041 acc: 0.69824 | v_loss: 1.43811 v_acc: 0.70378 |  iteration: 11821 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 634 loss: 1.42606 acc: 0.70931 | v_loss: 1.46700 v_acc: 0.70345 |  iteration: 11822 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 635 loss: 1.38208 acc: 0.70508 | v_loss: 1.52664 v_acc: 0.68783 |  iteration: 11823 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 636 loss: 1.45655 acc: 0.69531 | v_loss: 1.46954 v_acc: 0.70638 |  iteration: 11824 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 637 loss: 1.45047 acc: 0.69434 | v_loss: 1.41941 v_acc: 0.70410 |  iteration: 11825 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 638 loss: 1.35521 acc: 0.70247 | v_loss: 1.41006 v_acc: 0.70768 |  iteration: 11826 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 639 loss: 1.25946 acc: 0.71810 | v_loss: 1.40208 v_acc: 0.70703 |  iteration: 11827 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 640 loss: 1.58645 acc: 0.69238 | v_loss: 1.25461 v_acc: 0.71875 |  iteration: 11828 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 641 loss: 1.48316 acc: 0.69857 | v_loss: 1.33304 v_acc: 0.72331 |  iteration: 11829 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 642 loss: 1.44827 acc: 0.70573 | v_loss: 1.16634 v_acc: 0.71615 |  iteration: 11830 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 643 loss: 1.47404 acc: 0.69824 | v_loss: 1.33893 v_acc: 0.71126 |  iteration: 11831 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 644 loss: 1.34258 acc: 0.70638 | v_loss: 1.50311 v_acc: 0.69987 |  iteration: 11832 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 645 loss: 1.51310 acc: 0.69629 | v_loss: 1.33219 v_acc: 0.70833 |  iteration: 11833 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 646 loss: 1.52770 acc: 0.69564 | v_loss: 1.35185 v_acc: 0.69727 |  iteration: 11834 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 647 loss: 1.36195 acc: 0.70671 | v_loss: 1.25331 v_acc: 0.71126 |  iteration: 11835 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 648 loss: 1.47480 acc: 0.70833 | v_loss: 1.25460 v_acc: 0.70345 |  iteration: 11836 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 649 loss: 1.46691 acc: 0.70671 | v_loss: 1.23672 v_acc: 0.73503 |  iteration: 11837 teacher: 0 stage: sketch lr: 0.000406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 650 loss: 1.45830 acc: 0.69694 | v_loss: 1.27599 v_acc: 0.71647 |  iteration: 11838 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 651 loss: 1.50520 acc: 0.69401 | v_loss: 1.33426 v_acc: 0.74089 |  iteration: 11839 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 652 loss: 1.41440 acc: 0.70345 | v_loss: 1.26851 v_acc: 0.72005 |  iteration: 11840 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 653 loss: 1.41866 acc: 0.69889 | v_loss: 1.31289 v_acc: 0.71582 |  iteration: 11841 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 654 loss: 1.40472 acc: 0.70247 | v_loss: 1.41705 v_acc: 0.71224 |  iteration: 11842 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 655 loss: 1.46991 acc: 0.70247 | v_loss: 1.39767 v_acc: 0.72070 |  iteration: 11843 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 656 loss: 1.36030 acc: 0.71029 | v_loss: 1.48884 v_acc: 0.69954 |  iteration: 11844 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 657 loss: 1.44928 acc: 0.70085 | v_loss: 1.41619 v_acc: 0.71615 |  iteration: 11845 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 658 loss: 1.48056 acc: 0.70443 | v_loss: 1.17165 v_acc: 0.74447 |  iteration: 11846 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 659 loss: 1.45479 acc: 0.69466 | v_loss: 1.24655 v_acc: 0.71322 |  iteration: 11847 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 660 loss: 1.42720 acc: 0.70573 | v_loss: 1.52773 v_acc: 0.69987 |  iteration: 11848 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 661 loss: 1.41178 acc: 0.70378 | v_loss: 1.21728 v_acc: 0.70671 |  iteration: 11849 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 662 loss: 1.28929 acc: 0.71484 | v_loss: 1.33209 v_acc: 0.71257 |  iteration: 11850 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 663 loss: 1.41001 acc: 0.71191 | v_loss: 1.37401 v_acc: 0.69368 |  iteration: 11851 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 664 loss: 1.44514 acc: 0.69857 | v_loss: 1.29065 v_acc: 0.71842 |  iteration: 11852 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 665 loss: 1.54435 acc: 0.70345 | v_loss: 1.37034 v_acc: 0.70215 |  iteration: 11853 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 666 loss: 1.46862 acc: 0.70117 | v_loss: 1.48522 v_acc: 0.72005 |  iteration: 11854 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 667 loss: 1.48948 acc: 0.69206 | v_loss: 1.32341 v_acc: 0.72786 |  iteration: 11855 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 668 loss: 1.41558 acc: 0.70312 | v_loss: 1.43952 v_acc: 0.70540 |  iteration: 11856 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 669 loss: 1.43944 acc: 0.70508 | v_loss: 1.37724 v_acc: 0.69922 |  iteration: 11857 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 670 loss: 1.39325 acc: 0.70150 | v_loss: 1.32401 v_acc: 0.70898 |  iteration: 11858 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 671 loss: 1.42813 acc: 0.70736 | v_loss: 1.54107 v_acc: 0.68880 |  iteration: 11859 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 672 loss: 1.52447 acc: 0.69759 | v_loss: 1.29456 v_acc: 0.72103 |  iteration: 11860 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 673 loss: 1.46626 acc: 0.69987 | v_loss: 1.56927 v_acc: 0.69043 |  iteration: 11861 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 674 loss: 1.58483 acc: 0.69010 | v_loss: 1.42672 v_acc: 0.70215 |  iteration: 11862 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 675 loss: 1.48243 acc: 0.70345 | v_loss: 1.51175 v_acc: 0.68750 |  iteration: 11863 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 676 loss: 1.45684 acc: 0.70508 | v_loss: 1.37368 v_acc: 0.69824 |  iteration: 11864 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 677 loss: 1.49263 acc: 0.70833 | v_loss: 1.33173 v_acc: 0.70215 |  iteration: 11865 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 678 loss: 1.56135 acc: 0.69173 | v_loss: 1.34315 v_acc: 0.69759 |  iteration: 11866 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 679 loss: 1.53489 acc: 0.69694 | v_loss: 1.32633 v_acc: 0.71549 |  iteration: 11867 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 680 loss: 1.43744 acc: 0.70345 | v_loss: 1.53164 v_acc: 0.69173 |  iteration: 11868 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 681 loss: 1.35113 acc: 0.71289 | v_loss: 1.38786 v_acc: 0.70247 |  iteration: 11869 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 682 loss: 1.36281 acc: 0.71029 | v_loss: 1.34118 v_acc: 0.71029 |  iteration: 11870 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 683 loss: 1.31798 acc: 0.70931 | v_loss: 1.38517 v_acc: 0.71452 |  iteration: 11871 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 684 loss: 1.36812 acc: 0.71322 | v_loss: 1.26199 v_acc: 0.70736 |  iteration: 11872 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 685 loss: 1.45497 acc: 0.69922 | v_loss: 1.43453 v_acc: 0.70020 |  iteration: 11873 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 686 loss: 1.44885 acc: 0.70312 | v_loss: 1.43068 v_acc: 0.71094 |  iteration: 11874 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 687 loss: 1.49775 acc: 0.69596 | v_loss: 1.28131 v_acc: 0.71810 |  iteration: 11875 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 688 loss: 1.61676 acc: 0.69108 | v_loss: 1.25093 v_acc: 0.72591 |  iteration: 11876 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 689 loss: 1.51442 acc: 0.69466 | v_loss: 1.38188 v_acc: 0.71582 |  iteration: 11877 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 690 loss: 1.32388 acc: 0.70443 | v_loss: 1.42357 v_acc: 0.70540 |  iteration: 11878 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 691 loss: 1.44209 acc: 0.70182 | v_loss: 1.42223 v_acc: 0.70508 |  iteration: 11879 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 692 loss: 1.44099 acc: 0.69792 | v_loss: 1.24281 v_acc: 0.71419 |  iteration: 11880 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 693 loss: 1.46645 acc: 0.69271 | v_loss: 1.38190 v_acc: 0.72819 |  iteration: 11881 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 694 loss: 1.37752 acc: 0.70443 | v_loss: 1.46649 v_acc: 0.69792 |  iteration: 11882 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 695 loss: 1.39705 acc: 0.71094 | v_loss: 1.40979 v_acc: 0.71842 |  iteration: 11883 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 696 loss: 1.42354 acc: 0.70410 | v_loss: 1.25438 v_acc: 0.71810 |  iteration: 11884 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 697 loss: 1.48575 acc: 0.69889 | v_loss: 1.21548 v_acc: 0.73535 |  iteration: 11885 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 698 loss: 1.36632 acc: 0.71159 | v_loss: 1.21611 v_acc: 0.72656 |  iteration: 11886 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 699 loss: 1.36871 acc: 0.71289 | v_loss: 1.29059 v_acc: 0.70703 |  iteration: 11887 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 700 loss: 1.32326 acc: 0.71257 | v_loss: 1.46429 v_acc: 0.69466 |  iteration: 11888 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 701 loss: 1.41168 acc: 0.70280 | v_loss: 1.27982 v_acc: 0.71452 |  iteration: 11889 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 702 loss: 1.51159 acc: 0.69076 | v_loss: 1.44832 v_acc: 0.71615 |  iteration: 11890 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 703 loss: 1.39368 acc: 0.71029 | v_loss: 1.69690 v_acc: 0.69303 |  iteration: 11891 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 704 loss: 1.50109 acc: 0.69531 | v_loss: 1.53954 v_acc: 0.70117 |  iteration: 11892 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 705 loss: 1.33071 acc: 0.71257 | v_loss: 1.29789 v_acc: 0.72363 |  iteration: 11893 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 706 loss: 1.38445 acc: 0.70508 | v_loss: 1.37363 v_acc: 0.70410 |  iteration: 11894 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 707 loss: 1.45962 acc: 0.70801 | v_loss: 1.21298 v_acc: 0.72103 |  iteration: 11895 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 708 loss: 1.44428 acc: 0.70052 | v_loss: 1.43154 v_acc: 0.70020 |  iteration: 11896 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 709 loss: 1.49998 acc: 0.69303 | v_loss: 1.36198 v_acc: 0.71094 |  iteration: 11897 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 710 loss: 1.52684 acc: 0.69141 | v_loss: 1.36173 v_acc: 0.72949 |  iteration: 11898 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 711 loss: 1.48662 acc: 0.69271 | v_loss: 1.36035 v_acc: 0.71810 |  iteration: 11899 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 712 loss: 1.45402 acc: 0.69889 | v_loss: 1.37181 v_acc: 0.70508 |  iteration: 11900 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 713 loss: 1.38869 acc: 0.70801 | v_loss: 1.28538 v_acc: 0.72266 |  iteration: 11901 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 714 loss: 1.46101 acc: 0.69564 | v_loss: 1.29325 v_acc: 0.72038 |  iteration: 11902 teacher: 0 stage: sketch lr: 0.000405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 715 loss: 1.45374 acc: 0.70345 | v_loss: 1.46856 v_acc: 0.69368 |  iteration: 11903 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 716 loss: 1.48373 acc: 0.69694 | v_loss: 1.33082 v_acc: 0.71159 |  iteration: 11904 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 717 loss: 1.42307 acc: 0.70215 | v_loss: 1.28940 v_acc: 0.71549 |  iteration: 11905 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 718 loss: 1.40318 acc: 0.69661 | v_loss: 1.28144 v_acc: 0.71973 |  iteration: 11906 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 719 loss: 1.51014 acc: 0.70312 | v_loss: 1.42166 v_acc: 0.70573 |  iteration: 11907 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 720 loss: 1.42700 acc: 0.69922 | v_loss: 1.31726 v_acc: 0.73112 |  iteration: 11908 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 721 loss: 1.58848 acc: 0.68327 | v_loss: 1.54124 v_acc: 0.71452 |  iteration: 11909 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 722 loss: 1.46643 acc: 0.70182 | v_loss: 1.29287 v_acc: 0.69759 |  iteration: 11910 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 723 loss: 1.50008 acc: 0.69010 | v_loss: 1.28813 v_acc: 0.70443 |  iteration: 11911 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 724 loss: 1.37967 acc: 0.70182 | v_loss: 1.44306 v_acc: 0.70312 |  iteration: 11912 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 725 loss: 1.48297 acc: 0.70508 | v_loss: 1.46580 v_acc: 0.70378 |  iteration: 11913 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 726 loss: 1.37409 acc: 0.71191 | v_loss: 1.51178 v_acc: 0.68978 |  iteration: 11914 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 727 loss: 1.44347 acc: 0.69108 | v_loss: 1.46154 v_acc: 0.70703 |  iteration: 11915 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 728 loss: 1.34586 acc: 0.70443 | v_loss: 1.42355 v_acc: 0.70410 |  iteration: 11916 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 729 loss: 1.41190 acc: 0.70215 | v_loss: 1.41372 v_acc: 0.70475 |  iteration: 11917 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 730 loss: 1.40320 acc: 0.70866 | v_loss: 1.38582 v_acc: 0.70312 |  iteration: 11918 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 731 loss: 1.55357 acc: 0.69564 | v_loss: 1.25390 v_acc: 0.71159 |  iteration: 11919 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 732 loss: 1.40431 acc: 0.70247 | v_loss: 1.34585 v_acc: 0.72396 |  iteration: 11920 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 733 loss: 1.56471 acc: 0.69857 | v_loss: 1.20299 v_acc: 0.70638 |  iteration: 11921 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 734 loss: 1.46770 acc: 0.70150 | v_loss: 1.34638 v_acc: 0.70052 |  iteration: 11922 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 735 loss: 1.43327 acc: 0.69629 | v_loss: 1.50356 v_acc: 0.69596 |  iteration: 11923 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 736 loss: 1.42701 acc: 0.70345 | v_loss: 1.36256 v_acc: 0.70540 |  iteration: 11924 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 737 loss: 1.40495 acc: 0.70443 | v_loss: 1.36711 v_acc: 0.69368 |  iteration: 11925 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 738 loss: 1.42982 acc: 0.70833 | v_loss: 1.24344 v_acc: 0.71126 |  iteration: 11926 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 739 loss: 1.47416 acc: 0.70605 | v_loss: 1.26375 v_acc: 0.70345 |  iteration: 11927 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 740 loss: 1.51338 acc: 0.69564 | v_loss: 1.24188 v_acc: 0.73503 |  iteration: 11928 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 741 loss: 1.60092 acc: 0.68750 | v_loss: 1.27157 v_acc: 0.72168 |  iteration: 11929 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 742 loss: 1.44372 acc: 0.70410 | v_loss: 1.33546 v_acc: 0.73145 |  iteration: 11930 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 743 loss: 1.45567 acc: 0.70085 | v_loss: 1.26618 v_acc: 0.72461 |  iteration: 11931 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 744 loss: 1.43039 acc: 0.70996 | v_loss: 1.31025 v_acc: 0.72005 |  iteration: 11932 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 745 loss: 1.42686 acc: 0.70247 | v_loss: 1.41458 v_acc: 0.71224 |  iteration: 11933 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 746 loss: 1.44452 acc: 0.69727 | v_loss: 1.40754 v_acc: 0.72428 |  iteration: 11934 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 747 loss: 1.50175 acc: 0.70052 | v_loss: 1.48826 v_acc: 0.70182 |  iteration: 11935 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 748 loss: 1.47587 acc: 0.69759 | v_loss: 1.42072 v_acc: 0.71777 |  iteration: 11936 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 749 loss: 1.36125 acc: 0.70508 | v_loss: 1.17642 v_acc: 0.74447 |  iteration: 11937 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 750 loss: 1.41400 acc: 0.70085 | v_loss: 1.25411 v_acc: 0.71322 |  iteration: 11938 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 751 loss: 1.42466 acc: 0.70280 | v_loss: 1.51343 v_acc: 0.70247 |  iteration: 11939 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 752 loss: 1.45293 acc: 0.70052 | v_loss: 1.21981 v_acc: 0.70866 |  iteration: 11940 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 753 loss: 1.55703 acc: 0.69792 | v_loss: 1.33010 v_acc: 0.71159 |  iteration: 11941 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 754 loss: 1.48196 acc: 0.70247 | v_loss: 1.36875 v_acc: 0.69336 |  iteration: 11942 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 755 loss: 1.49456 acc: 0.70410 | v_loss: 1.31155 v_acc: 0.70898 |  iteration: 11943 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 756 loss: 1.32893 acc: 0.71387 | v_loss: 1.37281 v_acc: 0.69206 |  iteration: 11944 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 757 loss: 1.47307 acc: 0.69759 | v_loss: 1.46581 v_acc: 0.70931 |  iteration: 11945 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 758 loss: 1.42319 acc: 0.70898 | v_loss: 1.31542 v_acc: 0.72363 |  iteration: 11946 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 759 loss: 1.46416 acc: 0.70052 | v_loss: 1.45719 v_acc: 0.70117 |  iteration: 11947 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 760 loss: 1.43626 acc: 0.69987 | v_loss: 1.35877 v_acc: 0.70085 |  iteration: 11948 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 761 loss: 1.41170 acc: 0.70605 | v_loss: 1.33428 v_acc: 0.70898 |  iteration: 11949 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 762 loss: 1.49460 acc: 0.69792 | v_loss: 1.55086 v_acc: 0.68815 |  iteration: 11950 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 763 loss: 1.39394 acc: 0.70540 | v_loss: 1.31149 v_acc: 0.72005 |  iteration: 11951 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 764 loss: 1.50008 acc: 0.69401 | v_loss: 1.58584 v_acc: 0.68522 |  iteration: 11952 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 765 loss: 1.41657 acc: 0.70736 | v_loss: 1.45615 v_acc: 0.69661 |  iteration: 11953 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 766 loss: 1.32821 acc: 0.71257 | v_loss: 1.53721 v_acc: 0.69238 |  iteration: 11954 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 767 loss: 1.49006 acc: 0.69824 | v_loss: 1.36590 v_acc: 0.70182 |  iteration: 11955 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 768 loss: 1.41874 acc: 0.71224 | v_loss: 1.31682 v_acc: 0.70638 |  iteration: 11956 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 769 loss: 1.37927 acc: 0.71061 | v_loss: 1.31348 v_acc: 0.70410 |  iteration: 11957 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 770 loss: 1.44357 acc: 0.70117 | v_loss: 1.32658 v_acc: 0.71842 |  iteration: 11958 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 771 loss: 1.41775 acc: 0.71126 | v_loss: 1.56321 v_acc: 0.69108 |  iteration: 11959 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 772 loss: 1.52438 acc: 0.70150 | v_loss: 1.39083 v_acc: 0.71126 |  iteration: 11960 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 773 loss: 1.50066 acc: 0.68978 | v_loss: 1.34305 v_acc: 0.71061 |  iteration: 11961 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 774 loss: 1.50839 acc: 0.70182 | v_loss: 1.38736 v_acc: 0.71680 |  iteration: 11962 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 775 loss: 1.48392 acc: 0.70020 | v_loss: 1.28459 v_acc: 0.70215 |  iteration: 11963 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 776 loss: 1.49527 acc: 0.70671 | v_loss: 1.43520 v_acc: 0.69434 |  iteration: 11964 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 777 loss: 1.42732 acc: 0.70020 | v_loss: 1.42574 v_acc: 0.71452 |  iteration: 11965 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 778 loss: 1.49161 acc: 0.69987 | v_loss: 1.29387 v_acc: 0.71647 |  iteration: 11966 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 779 loss: 1.39873 acc: 0.70671 | v_loss: 1.27193 v_acc: 0.72526 |  iteration: 11967 teacher: 0 stage: sketch lr: 0.000404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 780 loss: 1.40424 acc: 0.71387 | v_loss: 1.37852 v_acc: 0.71647 |  iteration: 11968 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 781 loss: 1.45119 acc: 0.70215 | v_loss: 1.43169 v_acc: 0.70052 |  iteration: 11969 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 782 loss: 1.44015 acc: 0.70378 | v_loss: 1.42693 v_acc: 0.70312 |  iteration: 11970 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 783 loss: 1.53439 acc: 0.69564 | v_loss: 1.23090 v_acc: 0.71419 |  iteration: 11971 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 784 loss: 1.55670 acc: 0.70280 | v_loss: 1.39162 v_acc: 0.72786 |  iteration: 11972 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 785 loss: 1.52314 acc: 0.68783 | v_loss: 1.47130 v_acc: 0.69792 |  iteration: 11973 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 786 loss: 1.51320 acc: 0.69303 | v_loss: 1.40419 v_acc: 0.72070 |  iteration: 11974 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 787 loss: 1.49864 acc: 0.70085 | v_loss: 1.25892 v_acc: 0.71810 |  iteration: 11975 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 788 loss: 1.53705 acc: 0.69531 | v_loss: 1.21934 v_acc: 0.73600 |  iteration: 11976 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 789 loss: 1.34540 acc: 0.70703 | v_loss: 1.22754 v_acc: 0.72656 |  iteration: 11977 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 790 loss: 1.49150 acc: 0.69727 | v_loss: 1.30820 v_acc: 0.70768 |  iteration: 11978 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 791 loss: 1.52152 acc: 0.69596 | v_loss: 1.46578 v_acc: 0.69596 |  iteration: 11979 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 792 loss: 1.42607 acc: 0.70573 | v_loss: 1.28344 v_acc: 0.71224 |  iteration: 11980 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 793 loss: 1.35727 acc: 0.70410 | v_loss: 1.44946 v_acc: 0.71647 |  iteration: 11981 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 794 loss: 1.44184 acc: 0.70182 | v_loss: 1.68432 v_acc: 0.69141 |  iteration: 11982 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 795 loss: 1.52948 acc: 0.69466 | v_loss: 1.53096 v_acc: 0.69727 |  iteration: 11983 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 796 loss: 1.43594 acc: 0.69661 | v_loss: 1.29364 v_acc: 0.72396 |  iteration: 11984 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 797 loss: 1.54226 acc: 0.69889 | v_loss: 1.37013 v_acc: 0.70996 |  iteration: 11985 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 798 loss: 1.41717 acc: 0.70768 | v_loss: 1.21769 v_acc: 0.72201 |  iteration: 11986 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 799 loss: 1.42100 acc: 0.70052 | v_loss: 1.42233 v_acc: 0.70345 |  iteration: 11987 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 800 loss: 1.45637 acc: 0.69238 | v_loss: 1.36174 v_acc: 0.71029 |  iteration: 11988 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 801 loss: 1.42453 acc: 0.70508 | v_loss: 1.35977 v_acc: 0.72917 |  iteration: 11989 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 802 loss: 1.39525 acc: 0.70996 | v_loss: 1.35762 v_acc: 0.72005 |  iteration: 11990 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 803 loss: 1.48754 acc: 0.70443 | v_loss: 1.37491 v_acc: 0.70736 |  iteration: 11991 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 804 loss: 1.28673 acc: 0.71680 | v_loss: 1.30305 v_acc: 0.72201 |  iteration: 11992 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 805 loss: 1.43091 acc: 0.70605 | v_loss: 1.31446 v_acc: 0.72005 |  iteration: 11993 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 806 loss: 1.46443 acc: 0.69206 | v_loss: 1.50929 v_acc: 0.69043 |  iteration: 11994 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 807 loss: 1.37389 acc: 0.70736 | v_loss: 1.33307 v_acc: 0.70833 |  iteration: 11995 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 808 loss: 1.47365 acc: 0.69987 | v_loss: 1.29567 v_acc: 0.71549 |  iteration: 11996 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 809 loss: 1.42159 acc: 0.70280 | v_loss: 1.28347 v_acc: 0.71973 |  iteration: 11997 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 810 loss: 1.48219 acc: 0.70020 | v_loss: 1.42186 v_acc: 0.70573 |  iteration: 11998 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 811 loss: 1.41012 acc: 0.70833 | v_loss: 1.31361 v_acc: 0.73047 |  iteration: 11999 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 812 loss: 1.37955 acc: 0.70345 | v_loss: 1.55394 v_acc: 0.71582 |  iteration: 12000 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 813 loss: 1.50039 acc: 0.69694 | v_loss: 1.28140 v_acc: 0.70150 |  iteration: 12001 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 814 loss: 1.33926 acc: 0.70996 | v_loss: 1.27656 v_acc: 0.70573 |  iteration: 12002 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 815 loss: 1.45507 acc: 0.69889 | v_loss: 1.44496 v_acc: 0.70378 |  iteration: 12003 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 816 loss: 1.27357 acc: 0.71908 | v_loss: 1.49011 v_acc: 0.70085 |  iteration: 12004 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 817 loss: 1.39203 acc: 0.71549 | v_loss: 1.54615 v_acc: 0.68848 |  iteration: 12005 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 818 loss: 1.50422 acc: 0.69727 | v_loss: 1.48390 v_acc: 0.70605 |  iteration: 12006 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 819 loss: 1.52150 acc: 0.69010 | v_loss: 1.43579 v_acc: 0.70215 |  iteration: 12007 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 820 loss: 1.50597 acc: 0.69759 | v_loss: 1.41845 v_acc: 0.70768 |  iteration: 12008 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 821 loss: 1.47556 acc: 0.69076 | v_loss: 1.40392 v_acc: 0.70475 |  iteration: 12009 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 822 loss: 1.35727 acc: 0.71224 | v_loss: 1.26318 v_acc: 0.71354 |  iteration: 12010 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 823 loss: 1.43735 acc: 0.70020 | v_loss: 1.31995 v_acc: 0.72461 |  iteration: 12011 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 824 loss: 1.36926 acc: 0.70996 | v_loss: 1.19935 v_acc: 0.71517 |  iteration: 12012 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 825 loss: 1.38200 acc: 0.70345 | v_loss: 1.34927 v_acc: 0.70150 |  iteration: 12013 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 826 loss: 1.39480 acc: 0.69694 | v_loss: 1.49193 v_acc: 0.69987 |  iteration: 12014 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 827 loss: 1.38586 acc: 0.70443 | v_loss: 1.34170 v_acc: 0.70540 |  iteration: 12015 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 828 loss: 1.43392 acc: 0.70085 | v_loss: 1.35069 v_acc: 0.69368 |  iteration: 12016 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 829 loss: 1.44330 acc: 0.69824 | v_loss: 1.26604 v_acc: 0.70508 |  iteration: 12017 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 830 loss: 1.31413 acc: 0.71810 | v_loss: 1.24074 v_acc: 0.70020 |  iteration: 12018 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 831 loss: 1.47333 acc: 0.70182 | v_loss: 1.26154 v_acc: 0.73438 |  iteration: 12019 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 832 loss: 1.44967 acc: 0.70247 | v_loss: 1.27194 v_acc: 0.72168 |  iteration: 12020 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 833 loss: 1.43922 acc: 0.70150 | v_loss: 1.35543 v_acc: 0.73145 |  iteration: 12021 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 834 loss: 1.49616 acc: 0.69922 | v_loss: 1.26365 v_acc: 0.72461 |  iteration: 12022 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 835 loss: 1.49886 acc: 0.68750 | v_loss: 1.31118 v_acc: 0.72005 |  iteration: 12023 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 836 loss: 1.57145 acc: 0.69076 | v_loss: 1.41844 v_acc: 0.71224 |  iteration: 12024 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 837 loss: 1.38500 acc: 0.70801 | v_loss: 1.39212 v_acc: 0.72070 |  iteration: 12025 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 838 loss: 1.45800 acc: 0.69759 | v_loss: 1.49010 v_acc: 0.69954 |  iteration: 12026 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 839 loss: 1.43739 acc: 0.70215 | v_loss: 1.40744 v_acc: 0.71615 |  iteration: 12027 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 840 loss: 1.37562 acc: 0.70833 | v_loss: 1.18376 v_acc: 0.74544 |  iteration: 12028 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 841 loss: 1.43086 acc: 0.70833 | v_loss: 1.27375 v_acc: 0.70931 |  iteration: 12029 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 842 loss: 1.36996 acc: 0.71322 | v_loss: 1.51347 v_acc: 0.70247 |  iteration: 12030 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 843 loss: 1.27566 acc: 0.72266 | v_loss: 1.24388 v_acc: 0.70866 |  iteration: 12031 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 844 loss: 1.34049 acc: 0.70443 | v_loss: 1.32794 v_acc: 0.71094 |  iteration: 12032 teacher: 1 stage: sketch lr: 0.000403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 845 loss: 1.64086 acc: 0.68229 | v_loss: 1.36753 v_acc: 0.69824 |  iteration: 12033 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 846 loss: 1.32277 acc: 0.70573 | v_loss: 1.30670 v_acc: 0.71257 |  iteration: 12034 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 847 loss: 1.37550 acc: 0.70801 | v_loss: 1.36915 v_acc: 0.69629 |  iteration: 12035 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 848 loss: 1.48893 acc: 0.70280 | v_loss: 1.50528 v_acc: 0.72005 |  iteration: 12036 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 849 loss: 1.47829 acc: 0.69596 | v_loss: 1.32857 v_acc: 0.72786 |  iteration: 12037 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 850 loss: 1.49459 acc: 0.70671 | v_loss: 1.45604 v_acc: 0.70443 |  iteration: 12038 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 851 loss: 1.45806 acc: 0.69759 | v_loss: 1.36578 v_acc: 0.69922 |  iteration: 12039 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 852 loss: 1.49465 acc: 0.69401 | v_loss: 1.32642 v_acc: 0.70898 |  iteration: 12040 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 853 loss: 1.45857 acc: 0.69336 | v_loss: 1.54730 v_acc: 0.68815 |  iteration: 12041 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 854 loss: 1.34265 acc: 0.71322 | v_loss: 1.30562 v_acc: 0.72005 |  iteration: 12042 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 855 loss: 1.36754 acc: 0.70280 | v_loss: 1.58576 v_acc: 0.68392 |  iteration: 12043 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 856 loss: 1.44165 acc: 0.70540 | v_loss: 1.46499 v_acc: 0.69759 |  iteration: 12044 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 857 loss: 1.47768 acc: 0.70182 | v_loss: 1.52577 v_acc: 0.69076 |  iteration: 12045 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 858 loss: 1.51848 acc: 0.69824 | v_loss: 1.38008 v_acc: 0.69759 |  iteration: 12046 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 859 loss: 1.44651 acc: 0.70573 | v_loss: 1.31933 v_acc: 0.70215 |  iteration: 12047 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 860 loss: 1.42317 acc: 0.70736 | v_loss: 1.33595 v_acc: 0.69889 |  iteration: 12048 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 861 loss: 1.39543 acc: 0.70736 | v_loss: 1.32754 v_acc: 0.71419 |  iteration: 12049 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 862 loss: 1.36537 acc: 0.70605 | v_loss: 1.54320 v_acc: 0.68783 |  iteration: 12050 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 863 loss: 1.42827 acc: 0.70768 | v_loss: 1.39434 v_acc: 0.70280 |  iteration: 12051 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 864 loss: 1.51541 acc: 0.70150 | v_loss: 1.35712 v_acc: 0.70898 |  iteration: 12052 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 865 loss: 1.39742 acc: 0.70345 | v_loss: 1.38917 v_acc: 0.71615 |  iteration: 12053 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 866 loss: 1.56495 acc: 0.68392 | v_loss: 1.27219 v_acc: 0.70736 |  iteration: 12054 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 867 loss: 1.42966 acc: 0.69694 | v_loss: 1.44034 v_acc: 0.70052 |  iteration: 12055 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 868 loss: 1.32814 acc: 0.71387 | v_loss: 1.44282 v_acc: 0.71094 |  iteration: 12056 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 869 loss: 1.51460 acc: 0.69629 | v_loss: 1.29251 v_acc: 0.71810 |  iteration: 12057 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 870 loss: 1.37938 acc: 0.70931 | v_loss: 1.26293 v_acc: 0.72298 |  iteration: 12058 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 871 loss: 1.51199 acc: 0.69727 | v_loss: 1.39330 v_acc: 0.71940 |  iteration: 12059 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 872 loss: 1.33872 acc: 0.70996 | v_loss: 1.42774 v_acc: 0.70410 |  iteration: 12060 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 873 loss: 1.46760 acc: 0.70443 | v_loss: 1.43662 v_acc: 0.70833 |  iteration: 12061 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 874 loss: 1.37891 acc: 0.70378 | v_loss: 1.22154 v_acc: 0.72591 |  iteration: 12062 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 875 loss: 1.54468 acc: 0.68717 | v_loss: 1.39739 v_acc: 0.73112 |  iteration: 12063 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 876 loss: 1.43528 acc: 0.70475 | v_loss: 1.47684 v_acc: 0.69792 |  iteration: 12064 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 877 loss: 1.46007 acc: 0.70150 | v_loss: 1.39965 v_acc: 0.72070 |  iteration: 12065 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 878 loss: 1.43748 acc: 0.70117 | v_loss: 1.25802 v_acc: 0.72201 |  iteration: 12066 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 879 loss: 1.41316 acc: 0.71126 | v_loss: 1.23643 v_acc: 0.73535 |  iteration: 12067 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 880 loss: 1.43555 acc: 0.70117 | v_loss: 1.23362 v_acc: 0.72656 |  iteration: 12068 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 881 loss: 1.40405 acc: 0.70866 | v_loss: 1.31680 v_acc: 0.70475 |  iteration: 12069 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 882 loss: 1.44254 acc: 0.70280 | v_loss: 1.46892 v_acc: 0.69466 |  iteration: 12070 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 883 loss: 1.35041 acc: 0.71322 | v_loss: 1.27987 v_acc: 0.71452 |  iteration: 12071 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 884 loss: 1.38789 acc: 0.70345 | v_loss: 1.45368 v_acc: 0.71647 |  iteration: 12072 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 885 loss: 1.47634 acc: 0.70280 | v_loss: 1.68444 v_acc: 0.69303 |  iteration: 12073 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 886 loss: 1.49837 acc: 0.69792 | v_loss: 1.54712 v_acc: 0.69727 |  iteration: 12074 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 887 loss: 1.41266 acc: 0.70638 | v_loss: 1.30494 v_acc: 0.72396 |  iteration: 12075 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 888 loss: 1.44971 acc: 0.70020 | v_loss: 1.36876 v_acc: 0.70996 |  iteration: 12076 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 889 loss: 1.38736 acc: 0.70215 | v_loss: 1.20830 v_acc: 0.72201 |  iteration: 12077 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 890 loss: 1.46557 acc: 0.70117 | v_loss: 1.41319 v_acc: 0.70378 |  iteration: 12078 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 891 loss: 1.58518 acc: 0.69010 | v_loss: 1.36069 v_acc: 0.71094 |  iteration: 12079 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 892 loss: 1.38039 acc: 0.70312 | v_loss: 1.35177 v_acc: 0.72949 |  iteration: 12080 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 893 loss: 1.43160 acc: 0.70671 | v_loss: 1.36086 v_acc: 0.71810 |  iteration: 12081 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 894 loss: 1.39004 acc: 0.69824 | v_loss: 1.37741 v_acc: 0.70475 |  iteration: 12082 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 895 loss: 1.43823 acc: 0.71094 | v_loss: 1.29347 v_acc: 0.72559 |  iteration: 12083 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 896 loss: 1.40295 acc: 0.70964 | v_loss: 1.30386 v_acc: 0.72005 |  iteration: 12084 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 897 loss: 1.36072 acc: 0.70703 | v_loss: 1.49238 v_acc: 0.69043 |  iteration: 12085 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 898 loss: 1.37392 acc: 0.69466 | v_loss: 1.33235 v_acc: 0.71159 |  iteration: 12086 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 899 loss: 1.43086 acc: 0.69694 | v_loss: 1.28982 v_acc: 0.71549 |  iteration: 12087 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 900 loss: 1.39006 acc: 0.70768 | v_loss: 1.28603 v_acc: 0.71484 |  iteration: 12088 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 901 loss: 1.48091 acc: 0.69661 | v_loss: 1.43261 v_acc: 0.70540 |  iteration: 12089 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 902 loss: 1.49667 acc: 0.69434 | v_loss: 1.31810 v_acc: 0.73047 |  iteration: 12090 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 903 loss: 1.51618 acc: 0.70085 | v_loss: 1.55501 v_acc: 0.71582 |  iteration: 12091 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 904 loss: 1.45729 acc: 0.70378 | v_loss: 1.27457 v_acc: 0.70150 |  iteration: 12092 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 905 loss: 1.40513 acc: 0.70540 | v_loss: 1.27779 v_acc: 0.70443 |  iteration: 12093 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 906 loss: 1.48198 acc: 0.69857 | v_loss: 1.43810 v_acc: 0.70312 |  iteration: 12094 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 907 loss: 1.38876 acc: 0.69954 | v_loss: 1.46684 v_acc: 0.70378 |  iteration: 12095 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 908 loss: 1.49043 acc: 0.70443 | v_loss: 1.51610 v_acc: 0.68978 |  iteration: 12096 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 909 loss: 1.36466 acc: 0.71257 | v_loss: 1.45965 v_acc: 0.70540 |  iteration: 12097 teacher: 1 stage: sketch lr: 0.000402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 910 loss: 1.44396 acc: 0.70703 | v_loss: 1.42031 v_acc: 0.70540 |  iteration: 12098 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 911 loss: 1.55359 acc: 0.69303 | v_loss: 1.40758 v_acc: 0.70540 |  iteration: 12099 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 912 loss: 1.34266 acc: 0.71159 | v_loss: 1.40009 v_acc: 0.70605 |  iteration: 12100 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 913 loss: 1.44319 acc: 0.70410 | v_loss: 1.28002 v_acc: 0.71126 |  iteration: 12101 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 914 loss: 1.41408 acc: 0.70345 | v_loss: 1.31938 v_acc: 0.72331 |  iteration: 12102 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 915 loss: 1.31658 acc: 0.70443 | v_loss: 1.20250 v_acc: 0.70671 |  iteration: 12103 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 916 loss: 1.39431 acc: 0.70898 | v_loss: 1.34585 v_acc: 0.70150 |  iteration: 12104 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 917 loss: 1.41957 acc: 0.70215 | v_loss: 1.50977 v_acc: 0.69987 |  iteration: 12105 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 918 loss: 1.36070 acc: 0.70671 | v_loss: 1.33677 v_acc: 0.71484 |  iteration: 12106 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 919 loss: 1.52463 acc: 0.69336 | v_loss: 1.37235 v_acc: 0.70312 |  iteration: 12107 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 920 loss: 1.35112 acc: 0.70833 | v_loss: 1.23907 v_acc: 0.71680 |  iteration: 12108 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 921 loss: 1.50113 acc: 0.70117 | v_loss: 1.23503 v_acc: 0.70671 |  iteration: 12109 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 922 loss: 1.40100 acc: 0.70020 | v_loss: 1.26448 v_acc: 0.73568 |  iteration: 12110 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 923 loss: 1.44259 acc: 0.70052 | v_loss: 1.26230 v_acc: 0.72461 |  iteration: 12111 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 924 loss: 1.54077 acc: 0.70117 | v_loss: 1.35488 v_acc: 0.73145 |  iteration: 12112 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 925 loss: 1.37530 acc: 0.70638 | v_loss: 1.26432 v_acc: 0.72461 |  iteration: 12113 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 926 loss: 1.37602 acc: 0.70703 | v_loss: 1.30552 v_acc: 0.71582 |  iteration: 12114 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 927 loss: 1.36231 acc: 0.71680 | v_loss: 1.41916 v_acc: 0.71224 |  iteration: 12115 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 928 loss: 1.50162 acc: 0.70573 | v_loss: 1.39269 v_acc: 0.72038 |  iteration: 12116 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 929 loss: 1.38446 acc: 0.71126 | v_loss: 1.48147 v_acc: 0.69661 |  iteration: 12117 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 930 loss: 1.50953 acc: 0.69922 | v_loss: 1.42437 v_acc: 0.71745 |  iteration: 12118 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 931 loss: 1.50411 acc: 0.69271 | v_loss: 1.18300 v_acc: 0.74382 |  iteration: 12119 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 932 loss: 1.46215 acc: 0.70312 | v_loss: 1.25995 v_acc: 0.70671 |  iteration: 12120 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 933 loss: 1.43741 acc: 0.70378 | v_loss: 1.51551 v_acc: 0.70247 |  iteration: 12121 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 934 loss: 1.51424 acc: 0.69954 | v_loss: 1.22150 v_acc: 0.70866 |  iteration: 12122 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 935 loss: 1.38466 acc: 0.70768 | v_loss: 1.32813 v_acc: 0.71159 |  iteration: 12123 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 936 loss: 1.47725 acc: 0.69922 | v_loss: 1.36818 v_acc: 0.69368 |  iteration: 12124 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 937 loss: 1.50013 acc: 0.69824 | v_loss: 1.30468 v_acc: 0.71842 |  iteration: 12125 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 938 loss: 1.48006 acc: 0.69759 | v_loss: 1.36631 v_acc: 0.70215 |  iteration: 12126 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 939 loss: 1.60906 acc: 0.69043 | v_loss: 1.45603 v_acc: 0.72005 |  iteration: 12127 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 940 loss: 1.37918 acc: 0.70898 | v_loss: 1.31535 v_acc: 0.72786 |  iteration: 12128 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 941 loss: 1.46143 acc: 0.70150 | v_loss: 1.44339 v_acc: 0.70443 |  iteration: 12129 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 942 loss: 1.41454 acc: 0.70312 | v_loss: 1.35671 v_acc: 0.69922 |  iteration: 12130 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 943 loss: 1.49587 acc: 0.70671 | v_loss: 1.34270 v_acc: 0.70866 |  iteration: 12131 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 944 loss: 1.58025 acc: 0.68262 | v_loss: 1.54272 v_acc: 0.68685 |  iteration: 12132 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 945 loss: 1.47436 acc: 0.69987 | v_loss: 1.30767 v_acc: 0.72103 |  iteration: 12133 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 946 loss: 1.41886 acc: 0.70931 | v_loss: 1.58742 v_acc: 0.68620 |  iteration: 12134 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 947 loss: 1.53502 acc: 0.69108 | v_loss: 1.43030 v_acc: 0.69987 |  iteration: 12135 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 948 loss: 1.51917 acc: 0.69434 | v_loss: 1.50773 v_acc: 0.68913 |  iteration: 12136 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 949 loss: 1.45302 acc: 0.70638 | v_loss: 1.38000 v_acc: 0.69759 |  iteration: 12137 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 950 loss: 1.41494 acc: 0.70866 | v_loss: 1.32958 v_acc: 0.70215 |  iteration: 12138 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 951 loss: 1.33107 acc: 0.71289 | v_loss: 1.34540 v_acc: 0.69889 |  iteration: 12139 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 952 loss: 1.39916 acc: 0.70638 | v_loss: 1.33393 v_acc: 0.71419 |  iteration: 12140 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 953 loss: 1.44599 acc: 0.69629 | v_loss: 1.52899 v_acc: 0.69173 |  iteration: 12141 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 954 loss: 1.45784 acc: 0.70475 | v_loss: 1.38348 v_acc: 0.70378 |  iteration: 12142 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 955 loss: 1.43616 acc: 0.71126 | v_loss: 1.35522 v_acc: 0.71029 |  iteration: 12143 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 956 loss: 1.43773 acc: 0.70443 | v_loss: 1.38876 v_acc: 0.71680 |  iteration: 12144 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 957 loss: 1.45903 acc: 0.70508 | v_loss: 1.27199 v_acc: 0.70573 |  iteration: 12145 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 958 loss: 1.34912 acc: 0.70508 | v_loss: 1.43995 v_acc: 0.69792 |  iteration: 12146 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 959 loss: 1.41403 acc: 0.70833 | v_loss: 1.43169 v_acc: 0.71289 |  iteration: 12147 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 960 loss: 1.47757 acc: 0.70052 | v_loss: 1.27747 v_acc: 0.72201 |  iteration: 12148 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 961 loss: 1.32108 acc: 0.71680 | v_loss: 1.26255 v_acc: 0.72591 |  iteration: 12149 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 962 loss: 1.41348 acc: 0.69759 | v_loss: 1.38832 v_acc: 0.72266 |  iteration: 12150 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 963 loss: 1.33572 acc: 0.71224 | v_loss: 1.43076 v_acc: 0.70345 |  iteration: 12151 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 964 loss: 1.36240 acc: 0.69889 | v_loss: 1.43939 v_acc: 0.70410 |  iteration: 12152 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 965 loss: 1.43435 acc: 0.70020 | v_loss: 1.23041 v_acc: 0.71712 |  iteration: 12153 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 966 loss: 1.44364 acc: 0.69499 | v_loss: 1.41292 v_acc: 0.72786 |  iteration: 12154 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 967 loss: 1.41581 acc: 0.70085 | v_loss: 1.48319 v_acc: 0.69792 |  iteration: 12155 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 968 loss: 1.45464 acc: 0.70410 | v_loss: 1.40104 v_acc: 0.72070 |  iteration: 12156 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 969 loss: 1.34672 acc: 0.70573 | v_loss: 1.25289 v_acc: 0.72201 |  iteration: 12157 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 970 loss: 1.38363 acc: 0.70247 | v_loss: 1.21699 v_acc: 0.74023 |  iteration: 12158 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 971 loss: 1.51659 acc: 0.69596 | v_loss: 1.22588 v_acc: 0.72559 |  iteration: 12159 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 972 loss: 1.37867 acc: 0.70833 | v_loss: 1.29361 v_acc: 0.70638 |  iteration: 12160 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 973 loss: 1.41943 acc: 0.70931 | v_loss: 1.45556 v_acc: 0.70052 |  iteration: 12161 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 974 loss: 1.41811 acc: 0.69857 | v_loss: 1.26932 v_acc: 0.71452 |  iteration: 12162 teacher: 0 stage: sketch lr: 0.000401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 975 loss: 1.48808 acc: 0.69824 | v_loss: 1.43625 v_acc: 0.71647 |  iteration: 12163 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 976 loss: 1.47867 acc: 0.70150 | v_loss: 1.67190 v_acc: 0.69303 |  iteration: 12164 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 977 loss: 1.47414 acc: 0.69824 | v_loss: 1.52104 v_acc: 0.70117 |  iteration: 12165 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 978 loss: 1.41407 acc: 0.69922 | v_loss: 1.29539 v_acc: 0.72363 |  iteration: 12166 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 979 loss: 1.48246 acc: 0.69466 | v_loss: 1.37342 v_acc: 0.70410 |  iteration: 12167 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 980 loss: 1.46633 acc: 0.70085 | v_loss: 1.21736 v_acc: 0.71973 |  iteration: 12168 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 981 loss: 1.35204 acc: 0.70833 | v_loss: 1.42445 v_acc: 0.70150 |  iteration: 12169 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 982 loss: 1.39302 acc: 0.70768 | v_loss: 1.36677 v_acc: 0.71029 |  iteration: 12170 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 983 loss: 1.43204 acc: 0.70410 | v_loss: 1.35695 v_acc: 0.73079 |  iteration: 12171 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 984 loss: 1.43629 acc: 0.70475 | v_loss: 1.36249 v_acc: 0.71777 |  iteration: 12172 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 985 loss: 1.32978 acc: 0.71484 | v_loss: 1.37622 v_acc: 0.70410 |  iteration: 12173 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 986 loss: 1.39353 acc: 0.70671 | v_loss: 1.28496 v_acc: 0.72559 |  iteration: 12174 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 987 loss: 1.50274 acc: 0.69824 | v_loss: 1.29977 v_acc: 0.72005 |  iteration: 12175 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 988 loss: 1.52855 acc: 0.69336 | v_loss: 1.49492 v_acc: 0.69043 |  iteration: 12176 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 989 loss: 1.38961 acc: 0.70768 | v_loss: 1.33977 v_acc: 0.70833 |  iteration: 12177 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 990 loss: 1.50813 acc: 0.69954 | v_loss: 1.28837 v_acc: 0.71582 |  iteration: 12178 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 991 loss: 1.34732 acc: 0.71029 | v_loss: 1.28399 v_acc: 0.72201 |  iteration: 12179 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 992 loss: 1.41764 acc: 0.70020 | v_loss: 1.42866 v_acc: 0.70573 |  iteration: 12180 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 993 loss: 1.46510 acc: 0.70540 | v_loss: 1.31598 v_acc: 0.73112 |  iteration: 12181 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 994 loss: 1.42858 acc: 0.70182 | v_loss: 1.54625 v_acc: 0.71452 |  iteration: 12182 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 995 loss: 1.54871 acc: 0.68848 | v_loss: 1.28506 v_acc: 0.69759 |  iteration: 12183 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 996 loss: 1.37556 acc: 0.70768 | v_loss: 1.27842 v_acc: 0.70443 |  iteration: 12184 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 997 loss: 1.53133 acc: 0.69954 | v_loss: 1.44849 v_acc: 0.70312 |  iteration: 12185 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 998 loss: 1.46599 acc: 0.69889 | v_loss: 1.47611 v_acc: 0.70378 |  iteration: 12186 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 999 loss: 1.53095 acc: 0.69401 | v_loss: 1.51925 v_acc: 0.68978 |  iteration: 12187 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1000 loss: 1.46129 acc: 0.71191 | v_loss: 1.46326 v_acc: 0.70638 |  iteration: 12188 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1001 loss: 1.31853 acc: 0.71126 | v_loss: 1.42868 v_acc: 0.70410 |  iteration: 12189 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1002 loss: 1.52334 acc: 0.69596 | v_loss: 1.41354 v_acc: 0.70768 |  iteration: 12190 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1003 loss: 1.32966 acc: 0.71322 | v_loss: 1.39822 v_acc: 0.70475 |  iteration: 12191 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1004 loss: 1.43719 acc: 0.70182 | v_loss: 1.26587 v_acc: 0.71257 |  iteration: 12192 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1005 loss: 1.47047 acc: 0.69661 | v_loss: 1.32810 v_acc: 0.72493 |  iteration: 12193 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1006 loss: 1.45427 acc: 0.71029 | v_loss: 1.18890 v_acc: 0.70671 |  iteration: 12194 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1007 loss: 1.36220 acc: 0.71517 | v_loss: 1.34827 v_acc: 0.70150 |  iteration: 12195 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1008 loss: 1.27683 acc: 0.72103 | v_loss: 1.50933 v_acc: 0.69987 |  iteration: 12196 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1009 loss: 1.44870 acc: 0.70475 | v_loss: 1.35674 v_acc: 0.70540 |  iteration: 12197 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1010 loss: 1.41584 acc: 0.70508 | v_loss: 1.36827 v_acc: 0.69368 |  iteration: 12198 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1011 loss: 1.47318 acc: 0.69173 | v_loss: 1.25076 v_acc: 0.70964 |  iteration: 12199 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1012 loss: 1.51433 acc: 0.69238 | v_loss: 1.24264 v_acc: 0.70345 |  iteration: 12200 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1013 loss: 1.36952 acc: 0.70638 | v_loss: 1.24490 v_acc: 0.73568 |  iteration: 12201 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1014 loss: 1.34321 acc: 0.71224 | v_loss: 1.26370 v_acc: 0.72461 |  iteration: 12202 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1015 loss: 1.43651 acc: 0.69694 | v_loss: 1.33754 v_acc: 0.72689 |  iteration: 12203 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1016 loss: 1.44008 acc: 0.69954 | v_loss: 1.26754 v_acc: 0.72852 |  iteration: 12204 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1017 loss: 1.40959 acc: 0.70605 | v_loss: 1.30253 v_acc: 0.72103 |  iteration: 12205 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1018 loss: 1.37598 acc: 0.70540 | v_loss: 1.41510 v_acc: 0.71354 |  iteration: 12206 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1019 loss: 1.42237 acc: 0.70508 | v_loss: 1.41103 v_acc: 0.72428 |  iteration: 12207 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1020 loss: 1.38657 acc: 0.70736 | v_loss: 1.49334 v_acc: 0.69954 |  iteration: 12208 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1021 loss: 1.38432 acc: 0.70801 | v_loss: 1.42141 v_acc: 0.71745 |  iteration: 12209 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1022 loss: 1.47016 acc: 0.70540 | v_loss: 1.17562 v_acc: 0.74382 |  iteration: 12210 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1023 loss: 1.38245 acc: 0.70378 | v_loss: 1.26362 v_acc: 0.70280 |  iteration: 12211 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1024 loss: 1.43943 acc: 0.70150 | v_loss: 1.51694 v_acc: 0.70280 |  iteration: 12212 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1025 loss: 1.45907 acc: 0.70573 | v_loss: 1.22890 v_acc: 0.71647 |  iteration: 12213 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1026 loss: 1.51834 acc: 0.69076 | v_loss: 1.32498 v_acc: 0.71191 |  iteration: 12214 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1027 loss: 1.45598 acc: 0.71061 | v_loss: 1.36764 v_acc: 0.69076 |  iteration: 12215 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1028 loss: 1.41695 acc: 0.69792 | v_loss: 1.30714 v_acc: 0.70898 |  iteration: 12216 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1029 loss: 1.42302 acc: 0.70117 | v_loss: 1.36274 v_acc: 0.69206 |  iteration: 12217 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1030 loss: 1.47445 acc: 0.69531 | v_loss: 1.46367 v_acc: 0.71517 |  iteration: 12218 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1031 loss: 1.47434 acc: 0.70215 | v_loss: 1.31210 v_acc: 0.72689 |  iteration: 12219 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1032 loss: 1.40412 acc: 0.71061 | v_loss: 1.44116 v_acc: 0.70508 |  iteration: 12220 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1033 loss: 1.33860 acc: 0.70833 | v_loss: 1.37124 v_acc: 0.69857 |  iteration: 12221 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1034 loss: 1.38165 acc: 0.70540 | v_loss: 1.32625 v_acc: 0.70898 |  iteration: 12222 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1035 loss: 1.46181 acc: 0.69531 | v_loss: 1.54819 v_acc: 0.68815 |  iteration: 12223 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1036 loss: 1.47536 acc: 0.69954 | v_loss: 1.30416 v_acc: 0.72005 |  iteration: 12224 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1037 loss: 1.40317 acc: 0.70215 | v_loss: 1.58578 v_acc: 0.68457 |  iteration: 12225 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1038 loss: 1.40262 acc: 0.70280 | v_loss: 1.44026 v_acc: 0.69889 |  iteration: 12226 teacher: 1 stage: sketch lr: 0.000400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1039 loss: 1.41709 acc: 0.69434 | v_loss: 1.52855 v_acc: 0.68978 |  iteration: 12227 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1040 loss: 1.38189 acc: 0.70833 | v_loss: 1.36902 v_acc: 0.69792 |  iteration: 12228 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1041 loss: 1.46189 acc: 0.69596 | v_loss: 1.33100 v_acc: 0.70378 |  iteration: 12229 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1042 loss: 1.32966 acc: 0.71094 | v_loss: 1.33261 v_acc: 0.70215 |  iteration: 12230 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1043 loss: 1.46982 acc: 0.69694 | v_loss: 1.33304 v_acc: 0.71419 |  iteration: 12231 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1044 loss: 1.46388 acc: 0.70312 | v_loss: 1.52381 v_acc: 0.69173 |  iteration: 12232 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1045 loss: 1.53976 acc: 0.70085 | v_loss: 1.37799 v_acc: 0.70247 |  iteration: 12233 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1046 loss: 1.42954 acc: 0.72038 | v_loss: 1.35591 v_acc: 0.71126 |  iteration: 12234 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1047 loss: 1.39950 acc: 0.70345 | v_loss: 1.38218 v_acc: 0.71680 |  iteration: 12235 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1048 loss: 1.49025 acc: 0.70150 | v_loss: 1.27818 v_acc: 0.70573 |  iteration: 12236 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1049 loss: 1.35687 acc: 0.70964 | v_loss: 1.44015 v_acc: 0.69792 |  iteration: 12237 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1050 loss: 1.37189 acc: 0.70247 | v_loss: 1.42978 v_acc: 0.71289 |  iteration: 12238 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1051 loss: 1.46638 acc: 0.69987 | v_loss: 1.29699 v_acc: 0.71875 |  iteration: 12239 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1052 loss: 1.37129 acc: 0.70996 | v_loss: 1.25404 v_acc: 0.72591 |  iteration: 12240 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1053 loss: 1.41796 acc: 0.69954 | v_loss: 1.38713 v_acc: 0.72266 |  iteration: 12241 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1054 loss: 1.35732 acc: 0.71289 | v_loss: 1.42531 v_acc: 0.70345 |  iteration: 12242 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1055 loss: 1.42755 acc: 0.70638 | v_loss: 1.43025 v_acc: 0.70443 |  iteration: 12243 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1056 loss: 1.38974 acc: 0.70378 | v_loss: 1.23021 v_acc: 0.71615 |  iteration: 12244 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1057 loss: 1.46034 acc: 0.70638 | v_loss: 1.40022 v_acc: 0.72786 |  iteration: 12245 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1058 loss: 1.42667 acc: 0.70964 | v_loss: 1.47586 v_acc: 0.69857 |  iteration: 12246 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1059 loss: 1.37147 acc: 0.70443 | v_loss: 1.42097 v_acc: 0.72005 |  iteration: 12247 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1060 loss: 1.37802 acc: 0.71484 | v_loss: 1.24662 v_acc: 0.71973 |  iteration: 12248 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1061 loss: 1.43001 acc: 0.70410 | v_loss: 1.20418 v_acc: 0.73828 |  iteration: 12249 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1062 loss: 1.45705 acc: 0.70052 | v_loss: 1.21278 v_acc: 0.72656 |  iteration: 12250 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1063 loss: 1.40285 acc: 0.70475 | v_loss: 1.28817 v_acc: 0.70703 |  iteration: 12251 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1064 loss: 1.42791 acc: 0.69401 | v_loss: 1.45427 v_acc: 0.69466 |  iteration: 12252 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1065 loss: 1.48038 acc: 0.69727 | v_loss: 1.27763 v_acc: 0.71484 |  iteration: 12253 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1066 loss: 1.35852 acc: 0.70703 | v_loss: 1.43807 v_acc: 0.72949 |  iteration: 12254 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1067 loss: 1.37571 acc: 0.69987 | v_loss: 1.65301 v_acc: 0.69466 |  iteration: 12255 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1068 loss: 1.40066 acc: 0.70312 | v_loss: 1.51807 v_acc: 0.70410 |  iteration: 12256 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1069 loss: 1.32010 acc: 0.71745 | v_loss: 1.29427 v_acc: 0.72363 |  iteration: 12257 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1070 loss: 1.46958 acc: 0.69759 | v_loss: 1.37280 v_acc: 0.70410 |  iteration: 12258 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1071 loss: 1.36169 acc: 0.70540 | v_loss: 1.21617 v_acc: 0.71973 |  iteration: 12259 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1072 loss: 1.43419 acc: 0.70443 | v_loss: 1.43158 v_acc: 0.69857 |  iteration: 12260 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1073 loss: 1.52105 acc: 0.69857 | v_loss: 1.35342 v_acc: 0.70964 |  iteration: 12261 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1074 loss: 1.48078 acc: 0.70150 | v_loss: 1.35246 v_acc: 0.72949 |  iteration: 12262 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1075 loss: 1.47814 acc: 0.71126 | v_loss: 1.35527 v_acc: 0.71582 |  iteration: 12263 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1076 loss: 1.39153 acc: 0.70508 | v_loss: 1.37844 v_acc: 0.70052 |  iteration: 12264 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1077 loss: 1.42653 acc: 0.69792 | v_loss: 1.29193 v_acc: 0.72363 |  iteration: 12265 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1078 loss: 1.41633 acc: 0.69727 | v_loss: 1.30573 v_acc: 0.72005 |  iteration: 12266 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1079 loss: 1.32163 acc: 0.71549 | v_loss: 1.49269 v_acc: 0.69043 |  iteration: 12267 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1080 loss: 1.44118 acc: 0.69303 | v_loss: 1.32869 v_acc: 0.71159 |  iteration: 12268 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1081 loss: 1.45058 acc: 0.69141 | v_loss: 1.29130 v_acc: 0.71549 |  iteration: 12269 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1082 loss: 1.46615 acc: 0.70508 | v_loss: 1.28841 v_acc: 0.71973 |  iteration: 12270 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1083 loss: 1.47253 acc: 0.69531 | v_loss: 1.44564 v_acc: 0.70540 |  iteration: 12271 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1084 loss: 1.57894 acc: 0.69466 | v_loss: 1.31960 v_acc: 0.73047 |  iteration: 12272 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1085 loss: 1.48974 acc: 0.70182 | v_loss: 1.55731 v_acc: 0.71452 |  iteration: 12273 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1086 loss: 1.54204 acc: 0.69499 | v_loss: 1.27057 v_acc: 0.69759 |  iteration: 12274 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1087 loss: 1.45289 acc: 0.69792 | v_loss: 1.27466 v_acc: 0.70443 |  iteration: 12275 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1088 loss: 1.44815 acc: 0.69499 | v_loss: 1.43454 v_acc: 0.70312 |  iteration: 12276 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1089 loss: 1.42638 acc: 0.70247 | v_loss: 1.46131 v_acc: 0.70573 |  iteration: 12277 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1090 loss: 1.40766 acc: 0.70247 | v_loss: 1.50196 v_acc: 0.68978 |  iteration: 12278 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1091 loss: 1.35062 acc: 0.71419 | v_loss: 1.46378 v_acc: 0.70540 |  iteration: 12279 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1092 loss: 1.42993 acc: 0.70085 | v_loss: 1.41137 v_acc: 0.70410 |  iteration: 12280 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1093 loss: 1.42163 acc: 0.70052 | v_loss: 1.39640 v_acc: 0.70768 |  iteration: 12281 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1094 loss: 1.55677 acc: 0.69434 | v_loss: 1.42159 v_acc: 0.70475 |  iteration: 12282 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1095 loss: 1.45391 acc: 0.70443 | v_loss: 1.27335 v_acc: 0.71354 |  iteration: 12283 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1096 loss: 1.45633 acc: 0.70020 | v_loss: 1.32008 v_acc: 0.72461 |  iteration: 12284 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1097 loss: 1.42699 acc: 0.70703 | v_loss: 1.19007 v_acc: 0.71517 |  iteration: 12285 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1098 loss: 1.41782 acc: 0.70182 | v_loss: 1.34147 v_acc: 0.70703 |  iteration: 12286 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1099 loss: 1.42970 acc: 0.69922 | v_loss: 1.50669 v_acc: 0.69987 |  iteration: 12287 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1100 loss: 1.31687 acc: 0.72689 | v_loss: 1.34910 v_acc: 0.70638 |  iteration: 12288 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1101 loss: 1.47535 acc: 0.69922 | v_loss: 1.34830 v_acc: 0.69661 |  iteration: 12289 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1102 loss: 1.49091 acc: 0.70020 | v_loss: 1.25362 v_acc: 0.70638 |  iteration: 12290 teacher: 0 stage: sketch lr: 0.000399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1103 loss: 1.43115 acc: 0.70280 | v_loss: 1.24568 v_acc: 0.70410 |  iteration: 12291 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1104 loss: 1.37450 acc: 0.70801 | v_loss: 1.23749 v_acc: 0.73828 |  iteration: 12292 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1105 loss: 1.42050 acc: 0.70215 | v_loss: 1.26766 v_acc: 0.72168 |  iteration: 12293 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1106 loss: 1.48019 acc: 0.70410 | v_loss: 1.33792 v_acc: 0.72689 |  iteration: 12294 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1107 loss: 1.46468 acc: 0.69564 | v_loss: 1.25995 v_acc: 0.72852 |  iteration: 12295 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1108 loss: 1.34955 acc: 0.70931 | v_loss: 1.30647 v_acc: 0.72103 |  iteration: 12296 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1109 loss: 1.45536 acc: 0.70540 | v_loss: 1.42473 v_acc: 0.71354 |  iteration: 12297 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1110 loss: 1.44063 acc: 0.71615 | v_loss: 1.40326 v_acc: 0.72070 |  iteration: 12298 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1111 loss: 1.44046 acc: 0.70378 | v_loss: 1.48598 v_acc: 0.69954 |  iteration: 12299 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1112 loss: 1.46972 acc: 0.69629 | v_loss: 1.42319 v_acc: 0.71615 |  iteration: 12300 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1113 loss: 1.37672 acc: 0.70801 | v_loss: 1.18025 v_acc: 0.74544 |  iteration: 12301 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1114 loss: 1.43054 acc: 0.70573 | v_loss: 1.26600 v_acc: 0.70931 |  iteration: 12302 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1115 loss: 1.48367 acc: 0.69694 | v_loss: 1.51649 v_acc: 0.70247 |  iteration: 12303 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1116 loss: 1.46523 acc: 0.69922 | v_loss: 1.22904 v_acc: 0.70866 |  iteration: 12304 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1117 loss: 1.39504 acc: 0.70345 | v_loss: 1.32823 v_acc: 0.71159 |  iteration: 12305 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1118 loss: 1.46124 acc: 0.69727 | v_loss: 1.36155 v_acc: 0.69043 |  iteration: 12306 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1119 loss: 1.54136 acc: 0.70410 | v_loss: 1.31256 v_acc: 0.70898 |  iteration: 12307 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1120 loss: 1.37676 acc: 0.71289 | v_loss: 1.36320 v_acc: 0.69206 |  iteration: 12308 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1121 loss: 1.52171 acc: 0.69531 | v_loss: 1.46848 v_acc: 0.70768 |  iteration: 12309 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1122 loss: 1.37121 acc: 0.70736 | v_loss: 1.31277 v_acc: 0.72201 |  iteration: 12310 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1123 loss: 1.36142 acc: 0.71549 | v_loss: 1.45896 v_acc: 0.70312 |  iteration: 12311 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1124 loss: 1.42585 acc: 0.69857 | v_loss: 1.35150 v_acc: 0.70443 |  iteration: 12312 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1125 loss: 1.40487 acc: 0.70638 | v_loss: 1.33651 v_acc: 0.70898 |  iteration: 12313 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1126 loss: 1.39730 acc: 0.71973 | v_loss: 1.54838 v_acc: 0.68815 |  iteration: 12314 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1127 loss: 1.41137 acc: 0.70508 | v_loss: 1.31172 v_acc: 0.72005 |  iteration: 12315 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1128 loss: 1.35288 acc: 0.71615 | v_loss: 1.60995 v_acc: 0.67969 |  iteration: 12316 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1129 loss: 1.49203 acc: 0.68978 | v_loss: 1.45901 v_acc: 0.69661 |  iteration: 12317 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1130 loss: 1.39451 acc: 0.70866 | v_loss: 1.54812 v_acc: 0.69238 |  iteration: 12318 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1131 loss: 1.39850 acc: 0.69889 | v_loss: 1.37188 v_acc: 0.70182 |  iteration: 12319 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1132 loss: 1.55727 acc: 0.69401 | v_loss: 1.32052 v_acc: 0.70312 |  iteration: 12320 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1133 loss: 1.46477 acc: 0.70020 | v_loss: 1.32059 v_acc: 0.70020 |  iteration: 12321 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1134 loss: 1.44123 acc: 0.70312 | v_loss: 1.32677 v_acc: 0.71484 |  iteration: 12322 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1135 loss: 1.32751 acc: 0.70996 | v_loss: 1.54781 v_acc: 0.68978 |  iteration: 12323 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1136 loss: 1.42780 acc: 0.69954 | v_loss: 1.39274 v_acc: 0.70898 |  iteration: 12324 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1137 loss: 1.48937 acc: 0.68913 | v_loss: 1.33430 v_acc: 0.71224 |  iteration: 12325 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1138 loss: 1.50973 acc: 0.69922 | v_loss: 1.39057 v_acc: 0.71419 |  iteration: 12326 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1139 loss: 1.47613 acc: 0.69596 | v_loss: 1.26663 v_acc: 0.70378 |  iteration: 12327 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1140 loss: 1.38927 acc: 0.70866 | v_loss: 1.44544 v_acc: 0.69466 |  iteration: 12328 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1141 loss: 1.48359 acc: 0.69857 | v_loss: 1.43620 v_acc: 0.71191 |  iteration: 12329 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1142 loss: 1.38576 acc: 0.70703 | v_loss: 1.28031 v_acc: 0.71875 |  iteration: 12330 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1143 loss: 1.36913 acc: 0.70085 | v_loss: 1.26911 v_acc: 0.72754 |  iteration: 12331 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1144 loss: 1.47402 acc: 0.69564 | v_loss: 1.38087 v_acc: 0.71940 |  iteration: 12332 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1145 loss: 1.39981 acc: 0.71452 | v_loss: 1.42813 v_acc: 0.70345 |  iteration: 12333 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1146 loss: 1.45858 acc: 0.69922 | v_loss: 1.43182 v_acc: 0.70410 |  iteration: 12334 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1147 loss: 1.51962 acc: 0.69629 | v_loss: 1.22994 v_acc: 0.71712 |  iteration: 12335 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1148 loss: 1.43375 acc: 0.69531 | v_loss: 1.38642 v_acc: 0.72786 |  iteration: 12336 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1149 loss: 1.42012 acc: 0.69889 | v_loss: 1.47027 v_acc: 0.69792 |  iteration: 12337 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1150 loss: 1.47953 acc: 0.69434 | v_loss: 1.42154 v_acc: 0.72070 |  iteration: 12338 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1151 loss: 1.41960 acc: 0.69922 | v_loss: 1.24600 v_acc: 0.72233 |  iteration: 12339 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1152 loss: 1.35480 acc: 0.71322 | v_loss: 1.19032 v_acc: 0.74447 |  iteration: 12340 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1153 loss: 1.47874 acc: 0.69336 | v_loss: 1.21798 v_acc: 0.72493 |  iteration: 12341 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1154 loss: 1.45458 acc: 0.70378 | v_loss: 1.28188 v_acc: 0.70475 |  iteration: 12342 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1155 loss: 1.45425 acc: 0.70052 | v_loss: 1.48015 v_acc: 0.69238 |  iteration: 12343 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1156 loss: 1.51671 acc: 0.69694 | v_loss: 1.27304 v_acc: 0.71322 |  iteration: 12344 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1157 loss: 1.51783 acc: 0.69206 | v_loss: 1.44966 v_acc: 0.71582 |  iteration: 12345 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1158 loss: 1.36666 acc: 0.70605 | v_loss: 1.67082 v_acc: 0.69303 |  iteration: 12346 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1159 loss: 1.43101 acc: 0.70345 | v_loss: 1.52322 v_acc: 0.70117 |  iteration: 12347 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1160 loss: 1.39996 acc: 0.69727 | v_loss: 1.29254 v_acc: 0.72363 |  iteration: 12348 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1161 loss: 1.56288 acc: 0.68913 | v_loss: 1.37335 v_acc: 0.70410 |  iteration: 12349 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1162 loss: 1.44136 acc: 0.70312 | v_loss: 1.22977 v_acc: 0.71973 |  iteration: 12350 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1163 loss: 1.48936 acc: 0.70280 | v_loss: 1.41765 v_acc: 0.70150 |  iteration: 12351 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1164 loss: 1.58727 acc: 0.69010 | v_loss: 1.35422 v_acc: 0.71029 |  iteration: 12352 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1165 loss: 1.53219 acc: 0.70378 | v_loss: 1.35386 v_acc: 0.73079 |  iteration: 12353 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1166 loss: 1.35344 acc: 0.70671 | v_loss: 1.35594 v_acc: 0.71777 |  iteration: 12354 teacher: 1 stage: sketch lr: 0.000398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1167 loss: 1.42569 acc: 0.70703 | v_loss: 1.36737 v_acc: 0.70345 |  iteration: 12355 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1168 loss: 1.49862 acc: 0.69303 | v_loss: 1.31002 v_acc: 0.72201 |  iteration: 12356 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1169 loss: 1.47782 acc: 0.70085 | v_loss: 1.33110 v_acc: 0.72070 |  iteration: 12357 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1170 loss: 1.41307 acc: 0.69889 | v_loss: 1.53301 v_acc: 0.69043 |  iteration: 12358 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1171 loss: 1.39929 acc: 0.71647 | v_loss: 1.34640 v_acc: 0.70833 |  iteration: 12359 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1172 loss: 1.33321 acc: 0.71061 | v_loss: 1.28907 v_acc: 0.71582 |  iteration: 12360 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1173 loss: 1.47841 acc: 0.69987 | v_loss: 1.28449 v_acc: 0.72201 |  iteration: 12361 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1174 loss: 1.62903 acc: 0.68978 | v_loss: 1.42412 v_acc: 0.70768 |  iteration: 12362 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1175 loss: 1.46954 acc: 0.70508 | v_loss: 1.30688 v_acc: 0.73210 |  iteration: 12363 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1176 loss: 1.55593 acc: 0.69661 | v_loss: 1.52391 v_acc: 0.71322 |  iteration: 12364 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1177 loss: 1.51825 acc: 0.69206 | v_loss: 1.31318 v_acc: 0.69596 |  iteration: 12365 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1178 loss: 1.39067 acc: 0.70378 | v_loss: 1.29899 v_acc: 0.70703 |  iteration: 12366 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1179 loss: 1.45858 acc: 0.70703 | v_loss: 1.42350 v_acc: 0.70475 |  iteration: 12367 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1180 loss: 1.34387 acc: 0.71224 | v_loss: 1.45410 v_acc: 0.70443 |  iteration: 12368 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1181 loss: 1.44069 acc: 0.69531 | v_loss: 1.50100 v_acc: 0.69076 |  iteration: 12369 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1182 loss: 1.49886 acc: 0.70020 | v_loss: 1.46815 v_acc: 0.70605 |  iteration: 12370 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1183 loss: 1.34217 acc: 0.70768 | v_loss: 1.41756 v_acc: 0.70736 |  iteration: 12371 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1184 loss: 1.46140 acc: 0.70312 | v_loss: 1.40953 v_acc: 0.70703 |  iteration: 12372 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1185 loss: 1.42885 acc: 0.70475 | v_loss: 1.39979 v_acc: 0.70703 |  iteration: 12373 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1186 loss: 1.45432 acc: 0.69694 | v_loss: 1.26245 v_acc: 0.71257 |  iteration: 12374 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1187 loss: 1.46568 acc: 0.70150 | v_loss: 1.32598 v_acc: 0.72461 |  iteration: 12375 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1188 loss: 1.42555 acc: 0.69922 | v_loss: 1.18270 v_acc: 0.71517 |  iteration: 12376 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1189 loss: 1.58991 acc: 0.69043 | v_loss: 1.34452 v_acc: 0.71126 |  iteration: 12377 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1190 loss: 1.44509 acc: 0.70345 | v_loss: 1.50195 v_acc: 0.69954 |  iteration: 12378 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1191 loss: 1.46393 acc: 0.70443 | v_loss: 1.32013 v_acc: 0.70833 |  iteration: 12379 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1192 loss: 1.39234 acc: 0.70475 | v_loss: 1.35303 v_acc: 0.69727 |  iteration: 12380 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1193 loss: 1.41611 acc: 0.71029 | v_loss: 1.25888 v_acc: 0.71126 |  iteration: 12381 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1194 loss: 1.41297 acc: 0.70312 | v_loss: 1.25980 v_acc: 0.70345 |  iteration: 12382 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1195 loss: 1.55091 acc: 0.69792 | v_loss: 1.23924 v_acc: 0.73340 |  iteration: 12383 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1196 loss: 1.52579 acc: 0.69824 | v_loss: 1.27995 v_acc: 0.71647 |  iteration: 12384 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1197 loss: 1.34993 acc: 0.71908 | v_loss: 1.32397 v_acc: 0.75488 |  iteration: 12385 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1198 loss: 1.50817 acc: 0.70508 | v_loss: 1.27230 v_acc: 0.72005 |  iteration: 12386 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1199 loss: 1.41959 acc: 0.70736 | v_loss: 1.31085 v_acc: 0.71745 |  iteration: 12387 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1200 loss: 1.44521 acc: 0.69076 | v_loss: 1.41922 v_acc: 0.71354 |  iteration: 12388 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1201 loss: 1.35855 acc: 0.70182 | v_loss: 1.40002 v_acc: 0.72038 |  iteration: 12389 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1202 loss: 1.32907 acc: 0.71094 | v_loss: 1.49188 v_acc: 0.69954 |  iteration: 12390 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1203 loss: 1.42286 acc: 0.70312 | v_loss: 1.44275 v_acc: 0.71615 |  iteration: 12391 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1204 loss: 1.44659 acc: 0.70866 | v_loss: 1.18187 v_acc: 0.74219 |  iteration: 12392 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1205 loss: 1.45947 acc: 0.69727 | v_loss: 1.25538 v_acc: 0.71159 |  iteration: 12393 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1206 loss: 1.38960 acc: 0.70768 | v_loss: 1.54884 v_acc: 0.69303 |  iteration: 12394 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1207 loss: 1.36977 acc: 0.70085 | v_loss: 1.24614 v_acc: 0.69434 |  iteration: 12395 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1208 loss: 1.54596 acc: 0.69173 | v_loss: 1.33421 v_acc: 0.70378 |  iteration: 12396 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1209 loss: 1.39112 acc: 0.70443 | v_loss: 1.35245 v_acc: 0.69792 |  iteration: 12397 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1210 loss: 1.33372 acc: 0.71387 | v_loss: 1.30332 v_acc: 0.71029 |  iteration: 12398 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1211 loss: 1.37789 acc: 0.70508 | v_loss: 1.36781 v_acc: 0.69336 |  iteration: 12399 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1212 loss: 1.43804 acc: 0.69499 | v_loss: 1.48140 v_acc: 0.71224 |  iteration: 12400 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1213 loss: 1.42973 acc: 0.70410 | v_loss: 1.32186 v_acc: 0.72819 |  iteration: 12401 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1214 loss: 1.40175 acc: 0.70443 | v_loss: 1.46331 v_acc: 0.70312 |  iteration: 12402 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1215 loss: 1.40072 acc: 0.70508 | v_loss: 1.34703 v_acc: 0.70443 |  iteration: 12403 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1216 loss: 1.40927 acc: 0.70312 | v_loss: 1.34649 v_acc: 0.70671 |  iteration: 12404 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1217 loss: 1.51462 acc: 0.69629 | v_loss: 1.52592 v_acc: 0.69434 |  iteration: 12405 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1218 loss: 1.44687 acc: 0.70020 | v_loss: 1.30246 v_acc: 0.72103 |  iteration: 12406 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1219 loss: 1.49002 acc: 0.70605 | v_loss: 1.58483 v_acc: 0.68620 |  iteration: 12407 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1220 loss: 1.51110 acc: 0.69401 | v_loss: 1.43694 v_acc: 0.69987 |  iteration: 12408 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1221 loss: 1.49172 acc: 0.69434 | v_loss: 1.51412 v_acc: 0.68913 |  iteration: 12409 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1222 loss: 1.33111 acc: 0.71126 | v_loss: 1.37565 v_acc: 0.69922 |  iteration: 12410 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1223 loss: 1.41864 acc: 0.70475 | v_loss: 1.32351 v_acc: 0.70312 |  iteration: 12411 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1224 loss: 1.34926 acc: 0.71257 | v_loss: 1.33490 v_acc: 0.69889 |  iteration: 12412 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1225 loss: 1.46768 acc: 0.69954 | v_loss: 1.32804 v_acc: 0.71419 |  iteration: 12413 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1226 loss: 1.35262 acc: 0.70833 | v_loss: 1.52847 v_acc: 0.69173 |  iteration: 12414 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1227 loss: 1.48652 acc: 0.69824 | v_loss: 1.37804 v_acc: 0.70247 |  iteration: 12415 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1228 loss: 1.34002 acc: 0.71126 | v_loss: 1.35517 v_acc: 0.71126 |  iteration: 12416 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1229 loss: 1.45552 acc: 0.70410 | v_loss: 1.38561 v_acc: 0.71745 |  iteration: 12417 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1230 loss: 1.45654 acc: 0.69694 | v_loss: 1.27531 v_acc: 0.69759 |  iteration: 12418 teacher: 1 stage: sketch lr: 0.000397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1231 loss: 1.45221 acc: 0.69824 | v_loss: 1.43562 v_acc: 0.69466 |  iteration: 12419 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1232 loss: 1.42850 acc: 0.70117 | v_loss: 1.42862 v_acc: 0.71615 |  iteration: 12420 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1233 loss: 1.42495 acc: 0.70247 | v_loss: 1.28082 v_acc: 0.71712 |  iteration: 12421 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1234 loss: 1.50314 acc: 0.70052 | v_loss: 1.25563 v_acc: 0.72819 |  iteration: 12422 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1235 loss: 1.39889 acc: 0.69629 | v_loss: 1.39032 v_acc: 0.72266 |  iteration: 12423 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1236 loss: 1.42495 acc: 0.70475 | v_loss: 1.41627 v_acc: 0.70573 |  iteration: 12424 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 1237 loss: 1.40390 acc: 0.70931 | v_loss: 1.42868 v_acc: 0.70736 |  iteration: 12425 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 1238 loss: 1.41401 acc: 0.69629 | v_loss: 1.20916 v_acc: 0.72591 |  iteration: 12426 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 1239 loss: 1.41545 acc: 0.70540 | v_loss: 1.39841 v_acc: 0.73112 |  iteration: 12427 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 1240 loss: 1.40811 acc: 0.70410 | v_loss: 1.48899 v_acc: 0.69759 |  iteration: 12428 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 1241 loss: 1.41777 acc: 0.70508 | v_loss: 1.42970 v_acc: 0.72070 |  iteration: 12429 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 1242 loss: 1.40869 acc: 0.70378 | v_loss: 1.24439 v_acc: 0.72038 |  iteration: 12430 teacher: 0 stage: sketch lr: 0.000396\n",
      "epoch 9 loss: 1.43917 acc: 0.70270 | v_loss: 1.36853 v_acc: 0.71026 \n",
      "epoch: 10\n",
      "__________________________________________\n",
      "batch 0 loss: 1.41542 acc: 0.69596 | v_loss: 1.43575 v_acc: 0.70540 |  iteration: 12431 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 1 loss: 1.40023 acc: 0.70605 | v_loss: 1.42431 v_acc: 0.70475 |  iteration: 12432 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 2 loss: 1.47516 acc: 0.70215 | v_loss: 1.39920 v_acc: 0.70312 |  iteration: 12433 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 3 loss: 1.47608 acc: 0.70378 | v_loss: 1.26379 v_acc: 0.71257 |  iteration: 12434 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 4 loss: 1.30718 acc: 0.71940 | v_loss: 1.32975 v_acc: 0.72493 |  iteration: 12435 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 5 loss: 1.40551 acc: 0.70247 | v_loss: 1.20000 v_acc: 0.70671 |  iteration: 12436 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 6 loss: 1.36740 acc: 0.71973 | v_loss: 1.34536 v_acc: 0.70150 |  iteration: 12437 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 7 loss: 1.43091 acc: 0.71322 | v_loss: 1.49429 v_acc: 0.69987 |  iteration: 12438 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 8 loss: 1.49886 acc: 0.69141 | v_loss: 1.34544 v_acc: 0.70540 |  iteration: 12439 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 9 loss: 1.48833 acc: 0.70150 | v_loss: 1.35396 v_acc: 0.69368 |  iteration: 12440 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 10 loss: 1.49878 acc: 0.69792 | v_loss: 1.27005 v_acc: 0.70573 |  iteration: 12441 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 11 loss: 1.40682 acc: 0.70898 | v_loss: 1.25870 v_acc: 0.70215 |  iteration: 12442 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 12 loss: 1.35694 acc: 0.71615 | v_loss: 1.23640 v_acc: 0.73340 |  iteration: 12443 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 13 loss: 1.36567 acc: 0.70540 | v_loss: 1.27530 v_acc: 0.71647 |  iteration: 12444 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 14 loss: 1.34767 acc: 0.72103 | v_loss: 1.35139 v_acc: 0.74089 |  iteration: 12445 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 15 loss: 1.41011 acc: 0.71061 | v_loss: 1.27278 v_acc: 0.72005 |  iteration: 12446 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 16 loss: 1.50207 acc: 0.69727 | v_loss: 1.32910 v_acc: 0.71777 |  iteration: 12447 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 17 loss: 1.57600 acc: 0.68978 | v_loss: 1.44138 v_acc: 0.71419 |  iteration: 12448 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 18 loss: 1.38097 acc: 0.70671 | v_loss: 1.42030 v_acc: 0.71875 |  iteration: 12449 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 19 loss: 1.32689 acc: 0.71224 | v_loss: 1.49277 v_acc: 0.69792 |  iteration: 12450 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 20 loss: 1.39777 acc: 0.69987 | v_loss: 1.44430 v_acc: 0.71615 |  iteration: 12451 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 21 loss: 1.47367 acc: 0.69954 | v_loss: 1.17535 v_acc: 0.74447 |  iteration: 12452 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 22 loss: 1.46355 acc: 0.69889 | v_loss: 1.24302 v_acc: 0.71322 |  iteration: 12453 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 23 loss: 1.46549 acc: 0.70378 | v_loss: 1.52673 v_acc: 0.69987 |  iteration: 12454 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 24 loss: 1.31261 acc: 0.71387 | v_loss: 1.20292 v_acc: 0.70671 |  iteration: 12455 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 25 loss: 1.42548 acc: 0.70540 | v_loss: 1.33363 v_acc: 0.71257 |  iteration: 12456 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 26 loss: 1.50190 acc: 0.69206 | v_loss: 1.36637 v_acc: 0.69368 |  iteration: 12457 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 27 loss: 1.53884 acc: 0.69076 | v_loss: 1.29919 v_acc: 0.71842 |  iteration: 12458 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 28 loss: 1.43944 acc: 0.71126 | v_loss: 1.38044 v_acc: 0.70215 |  iteration: 12459 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 29 loss: 1.51731 acc: 0.70443 | v_loss: 1.45668 v_acc: 0.71517 |  iteration: 12460 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 30 loss: 1.35537 acc: 0.70703 | v_loss: 1.32063 v_acc: 0.72689 |  iteration: 12461 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 31 loss: 1.45971 acc: 0.70052 | v_loss: 1.43888 v_acc: 0.70443 |  iteration: 12462 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 32 loss: 1.44780 acc: 0.70508 | v_loss: 1.37047 v_acc: 0.69922 |  iteration: 12463 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 33 loss: 1.41876 acc: 0.69922 | v_loss: 1.33535 v_acc: 0.70898 |  iteration: 12464 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 34 loss: 1.49254 acc: 0.69759 | v_loss: 1.54728 v_acc: 0.68815 |  iteration: 12465 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 35 loss: 1.38750 acc: 0.69694 | v_loss: 1.29818 v_acc: 0.72005 |  iteration: 12466 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 36 loss: 1.51961 acc: 0.69694 | v_loss: 1.59552 v_acc: 0.68424 |  iteration: 12467 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 37 loss: 1.42511 acc: 0.69889 | v_loss: 1.44648 v_acc: 0.69792 |  iteration: 12468 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 38 loss: 1.36063 acc: 0.72038 | v_loss: 1.53242 v_acc: 0.69173 |  iteration: 12469 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 39 loss: 1.40906 acc: 0.71061 | v_loss: 1.36987 v_acc: 0.70182 |  iteration: 12470 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 40 loss: 1.45178 acc: 0.69954 | v_loss: 1.32654 v_acc: 0.70638 |  iteration: 12471 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 41 loss: 1.44645 acc: 0.69401 | v_loss: 1.32686 v_acc: 0.70410 |  iteration: 12472 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 42 loss: 1.35946 acc: 0.70996 | v_loss: 1.32888 v_acc: 0.71973 |  iteration: 12473 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 43 loss: 1.42961 acc: 0.70605 | v_loss: 1.55527 v_acc: 0.69076 |  iteration: 12474 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 44 loss: 1.40177 acc: 0.71615 | v_loss: 1.37785 v_acc: 0.70703 |  iteration: 12475 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 45 loss: 1.35223 acc: 0.71354 | v_loss: 1.34874 v_acc: 0.70833 |  iteration: 12476 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 46 loss: 1.54569 acc: 0.69629 | v_loss: 1.38657 v_acc: 0.71582 |  iteration: 12477 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 47 loss: 1.55912 acc: 0.68848 | v_loss: 1.29089 v_acc: 0.69759 |  iteration: 12478 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 48 loss: 1.51366 acc: 0.69303 | v_loss: 1.43090 v_acc: 0.69368 |  iteration: 12479 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 49 loss: 1.48146 acc: 0.69368 | v_loss: 1.41919 v_acc: 0.71777 |  iteration: 12480 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 50 loss: 1.40196 acc: 0.70280 | v_loss: 1.30282 v_acc: 0.71452 |  iteration: 12481 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 51 loss: 1.46907 acc: 0.70508 | v_loss: 1.26048 v_acc: 0.72526 |  iteration: 12482 teacher: 1 stage: sketch lr: 0.000396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 52 loss: 1.45061 acc: 0.69727 | v_loss: 1.37297 v_acc: 0.71647 |  iteration: 12483 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 53 loss: 1.44116 acc: 0.70898 | v_loss: 1.43361 v_acc: 0.70280 |  iteration: 12484 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 54 loss: 1.38790 acc: 0.71094 | v_loss: 1.43359 v_acc: 0.70312 |  iteration: 12485 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 55 loss: 1.35122 acc: 0.69922 | v_loss: 1.24285 v_acc: 0.71387 |  iteration: 12486 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 56 loss: 1.39989 acc: 0.70768 | v_loss: 1.40790 v_acc: 0.72201 |  iteration: 12487 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 57 loss: 1.46591 acc: 0.69694 | v_loss: 1.48161 v_acc: 0.69792 |  iteration: 12488 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 58 loss: 1.47421 acc: 0.69596 | v_loss: 1.41950 v_acc: 0.72201 |  iteration: 12489 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 59 loss: 1.41180 acc: 0.70768 | v_loss: 1.24224 v_acc: 0.72233 |  iteration: 12490 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 60 loss: 1.48047 acc: 0.70085 | v_loss: 1.19419 v_acc: 0.74447 |  iteration: 12491 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 61 loss: 1.39390 acc: 0.70540 | v_loss: 1.20720 v_acc: 0.72754 |  iteration: 12492 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 62 loss: 1.37413 acc: 0.70573 | v_loss: 1.28229 v_acc: 0.71257 |  iteration: 12493 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 63 loss: 1.50476 acc: 0.69759 | v_loss: 1.45378 v_acc: 0.70215 |  iteration: 12494 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 64 loss: 1.48719 acc: 0.69401 | v_loss: 1.27855 v_acc: 0.71322 |  iteration: 12495 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 65 loss: 1.42173 acc: 0.71061 | v_loss: 1.50790 v_acc: 0.70410 |  iteration: 12496 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 66 loss: 1.43404 acc: 0.70247 | v_loss: 1.67982 v_acc: 0.69238 |  iteration: 12497 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 67 loss: 1.42329 acc: 0.70345 | v_loss: 1.52251 v_acc: 0.69661 |  iteration: 12498 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 68 loss: 1.42684 acc: 0.70085 | v_loss: 1.29546 v_acc: 0.72135 |  iteration: 12499 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 69 loss: 1.51755 acc: 0.70410 | v_loss: 1.37220 v_acc: 0.70020 |  iteration: 12500 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 70 loss: 1.43173 acc: 0.70443 | v_loss: 1.22908 v_acc: 0.71615 |  iteration: 12501 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 71 loss: 1.39503 acc: 0.70736 | v_loss: 1.42987 v_acc: 0.69206 |  iteration: 12502 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 72 loss: 1.51450 acc: 0.69466 | v_loss: 1.36359 v_acc: 0.71029 |  iteration: 12503 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 73 loss: 1.37735 acc: 0.70508 | v_loss: 1.35458 v_acc: 0.72852 |  iteration: 12504 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 74 loss: 1.48595 acc: 0.69727 | v_loss: 1.35196 v_acc: 0.71582 |  iteration: 12505 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 75 loss: 1.35684 acc: 0.71061 | v_loss: 1.37527 v_acc: 0.70345 |  iteration: 12506 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 76 loss: 1.37904 acc: 0.70475 | v_loss: 1.28663 v_acc: 0.72233 |  iteration: 12507 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 77 loss: 1.45061 acc: 0.70150 | v_loss: 1.29985 v_acc: 0.72135 |  iteration: 12508 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 78 loss: 1.44300 acc: 0.69857 | v_loss: 1.49590 v_acc: 0.69368 |  iteration: 12509 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 79 loss: 1.39061 acc: 0.70833 | v_loss: 1.33306 v_acc: 0.71452 |  iteration: 12510 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 80 loss: 1.43311 acc: 0.70801 | v_loss: 1.28783 v_acc: 0.71777 |  iteration: 12511 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 81 loss: 1.37487 acc: 0.71615 | v_loss: 1.28817 v_acc: 0.71484 |  iteration: 12512 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 82 loss: 1.52323 acc: 0.69857 | v_loss: 1.44113 v_acc: 0.70540 |  iteration: 12513 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 83 loss: 1.56362 acc: 0.69661 | v_loss: 1.31402 v_acc: 0.73047 |  iteration: 12514 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 84 loss: 1.39408 acc: 0.71126 | v_loss: 1.54709 v_acc: 0.71452 |  iteration: 12515 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 85 loss: 1.48021 acc: 0.70117 | v_loss: 1.29323 v_acc: 0.69531 |  iteration: 12516 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 86 loss: 1.38254 acc: 0.70020 | v_loss: 1.28277 v_acc: 0.70117 |  iteration: 12517 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 87 loss: 1.38725 acc: 0.70703 | v_loss: 1.43685 v_acc: 0.70508 |  iteration: 12518 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 88 loss: 1.34166 acc: 0.72038 | v_loss: 1.47641 v_acc: 0.70768 |  iteration: 12519 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 89 loss: 1.53762 acc: 0.69401 | v_loss: 1.52645 v_acc: 0.68783 |  iteration: 12520 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 90 loss: 1.39597 acc: 0.71582 | v_loss: 1.45907 v_acc: 0.70410 |  iteration: 12521 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 91 loss: 1.37975 acc: 0.70703 | v_loss: 1.43229 v_acc: 0.71029 |  iteration: 12522 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 92 loss: 1.42544 acc: 0.71061 | v_loss: 1.41741 v_acc: 0.70475 |  iteration: 12523 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 93 loss: 1.41176 acc: 0.70964 | v_loss: 1.39925 v_acc: 0.70312 |  iteration: 12524 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 94 loss: 1.45795 acc: 0.69629 | v_loss: 1.27029 v_acc: 0.71257 |  iteration: 12525 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 95 loss: 1.46130 acc: 0.69336 | v_loss: 1.32148 v_acc: 0.72493 |  iteration: 12526 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 96 loss: 1.45878 acc: 0.70247 | v_loss: 1.18387 v_acc: 0.71517 |  iteration: 12527 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 97 loss: 1.41868 acc: 0.71094 | v_loss: 1.34478 v_acc: 0.70703 |  iteration: 12528 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 98 loss: 1.46426 acc: 0.71094 | v_loss: 1.49864 v_acc: 0.69987 |  iteration: 12529 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 99 loss: 1.47711 acc: 0.69727 | v_loss: 1.32663 v_acc: 0.70833 |  iteration: 12530 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 100 loss: 1.47965 acc: 0.70020 | v_loss: 1.34475 v_acc: 0.69727 |  iteration: 12531 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 101 loss: 1.39330 acc: 0.70866 | v_loss: 1.25777 v_acc: 0.71126 |  iteration: 12532 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 102 loss: 1.43515 acc: 0.70182 | v_loss: 1.24665 v_acc: 0.70410 |  iteration: 12533 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 103 loss: 1.51829 acc: 0.68913 | v_loss: 1.24036 v_acc: 0.73796 |  iteration: 12534 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 104 loss: 1.40636 acc: 0.70573 | v_loss: 1.27437 v_acc: 0.72233 |  iteration: 12535 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 105 loss: 1.46902 acc: 0.70443 | v_loss: 1.35091 v_acc: 0.73210 |  iteration: 12536 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 106 loss: 1.41677 acc: 0.69824 | v_loss: 1.26473 v_acc: 0.71940 |  iteration: 12537 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 107 loss: 1.39929 acc: 0.70215 | v_loss: 1.31558 v_acc: 0.72266 |  iteration: 12538 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 108 loss: 1.44284 acc: 0.69889 | v_loss: 1.42191 v_acc: 0.71354 |  iteration: 12539 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 109 loss: 1.47216 acc: 0.70020 | v_loss: 1.39603 v_acc: 0.72070 |  iteration: 12540 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 110 loss: 1.39487 acc: 0.70638 | v_loss: 1.48028 v_acc: 0.69954 |  iteration: 12541 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 111 loss: 1.33867 acc: 0.71257 | v_loss: 1.40995 v_acc: 0.71615 |  iteration: 12542 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 112 loss: 1.47932 acc: 0.69368 | v_loss: 1.17668 v_acc: 0.74544 |  iteration: 12543 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 113 loss: 1.37283 acc: 0.70898 | v_loss: 1.25842 v_acc: 0.70931 |  iteration: 12544 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 114 loss: 1.38707 acc: 0.70280 | v_loss: 1.51749 v_acc: 0.70247 |  iteration: 12545 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 115 loss: 1.43203 acc: 0.69987 | v_loss: 1.22187 v_acc: 0.70671 |  iteration: 12546 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 116 loss: 1.38439 acc: 0.70671 | v_loss: 1.32836 v_acc: 0.71257 |  iteration: 12547 teacher: 1 stage: sketch lr: 0.000395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 117 loss: 1.42788 acc: 0.70508 | v_loss: 1.36620 v_acc: 0.69368 |  iteration: 12548 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 118 loss: 1.40716 acc: 0.70964 | v_loss: 1.29565 v_acc: 0.71647 |  iteration: 12549 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 119 loss: 1.41006 acc: 0.69987 | v_loss: 1.36896 v_acc: 0.69629 |  iteration: 12550 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 120 loss: 1.39867 acc: 0.71615 | v_loss: 1.50570 v_acc: 0.70638 |  iteration: 12551 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 121 loss: 1.47298 acc: 0.69824 | v_loss: 1.33067 v_acc: 0.72363 |  iteration: 12552 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 122 loss: 1.43977 acc: 0.69792 | v_loss: 1.45722 v_acc: 0.70508 |  iteration: 12553 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 123 loss: 1.56519 acc: 0.69206 | v_loss: 1.36052 v_acc: 0.69922 |  iteration: 12554 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 124 loss: 1.44125 acc: 0.70182 | v_loss: 1.32248 v_acc: 0.70898 |  iteration: 12555 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 125 loss: 1.44507 acc: 0.69889 | v_loss: 1.55203 v_acc: 0.68750 |  iteration: 12556 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 126 loss: 1.48594 acc: 0.70638 | v_loss: 1.29595 v_acc: 0.72038 |  iteration: 12557 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 127 loss: 1.41678 acc: 0.70280 | v_loss: 1.59299 v_acc: 0.68392 |  iteration: 12558 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 128 loss: 1.46145 acc: 0.71126 | v_loss: 1.48314 v_acc: 0.69759 |  iteration: 12559 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 129 loss: 1.45005 acc: 0.69824 | v_loss: 1.52493 v_acc: 0.69076 |  iteration: 12560 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 130 loss: 1.51572 acc: 0.69531 | v_loss: 1.38486 v_acc: 0.70020 |  iteration: 12561 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 131 loss: 1.41641 acc: 0.70475 | v_loss: 1.33085 v_acc: 0.70215 |  iteration: 12562 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 132 loss: 1.33947 acc: 0.70638 | v_loss: 1.33604 v_acc: 0.69987 |  iteration: 12563 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 133 loss: 1.38016 acc: 0.70475 | v_loss: 1.33154 v_acc: 0.71484 |  iteration: 12564 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 134 loss: 1.46986 acc: 0.70508 | v_loss: 1.52809 v_acc: 0.68978 |  iteration: 12565 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 135 loss: 1.47227 acc: 0.69596 | v_loss: 1.37407 v_acc: 0.70443 |  iteration: 12566 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 136 loss: 1.44944 acc: 0.69141 | v_loss: 1.36716 v_acc: 0.71094 |  iteration: 12567 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 137 loss: 1.45841 acc: 0.69759 | v_loss: 1.38894 v_acc: 0.71452 |  iteration: 12568 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 138 loss: 1.42333 acc: 0.70378 | v_loss: 1.25967 v_acc: 0.70736 |  iteration: 12569 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 139 loss: 1.34866 acc: 0.71159 | v_loss: 1.43511 v_acc: 0.70052 |  iteration: 12570 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 140 loss: 1.39626 acc: 0.71615 | v_loss: 1.43220 v_acc: 0.71224 |  iteration: 12571 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 141 loss: 1.36448 acc: 0.71387 | v_loss: 1.28125 v_acc: 0.72201 |  iteration: 12572 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 142 loss: 1.45076 acc: 0.69596 | v_loss: 1.25737 v_acc: 0.72591 |  iteration: 12573 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 143 loss: 1.44359 acc: 0.69954 | v_loss: 1.37978 v_acc: 0.72266 |  iteration: 12574 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 144 loss: 1.55113 acc: 0.68978 | v_loss: 1.42403 v_acc: 0.70345 |  iteration: 12575 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 145 loss: 1.48494 acc: 0.70573 | v_loss: 1.42868 v_acc: 0.70508 |  iteration: 12576 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 146 loss: 1.41747 acc: 0.70638 | v_loss: 1.23522 v_acc: 0.71387 |  iteration: 12577 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 147 loss: 1.32964 acc: 0.71159 | v_loss: 1.38423 v_acc: 0.72819 |  iteration: 12578 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 148 loss: 1.43305 acc: 0.70312 | v_loss: 1.46707 v_acc: 0.69792 |  iteration: 12579 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 149 loss: 1.44271 acc: 0.69824 | v_loss: 1.40145 v_acc: 0.71842 |  iteration: 12580 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 150 loss: 1.31771 acc: 0.71842 | v_loss: 1.25704 v_acc: 0.71810 |  iteration: 12581 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 151 loss: 1.34599 acc: 0.71289 | v_loss: 1.21503 v_acc: 0.73535 |  iteration: 12582 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 152 loss: 1.40075 acc: 0.70866 | v_loss: 1.21441 v_acc: 0.72656 |  iteration: 12583 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 153 loss: 1.35861 acc: 0.70703 | v_loss: 1.28570 v_acc: 0.70703 |  iteration: 12584 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 154 loss: 1.35970 acc: 0.71191 | v_loss: 1.45393 v_acc: 0.69466 |  iteration: 12585 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 155 loss: 1.36451 acc: 0.71257 | v_loss: 1.27443 v_acc: 0.71484 |  iteration: 12586 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 156 loss: 1.35795 acc: 0.71289 | v_loss: 1.42987 v_acc: 0.72949 |  iteration: 12587 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 157 loss: 1.59306 acc: 0.68913 | v_loss: 1.65650 v_acc: 0.69466 |  iteration: 12588 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 158 loss: 1.38769 acc: 0.71973 | v_loss: 1.52225 v_acc: 0.70312 |  iteration: 12589 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 159 loss: 1.49759 acc: 0.69889 | v_loss: 1.29304 v_acc: 0.72363 |  iteration: 12590 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 160 loss: 1.42177 acc: 0.70052 | v_loss: 1.37405 v_acc: 0.70410 |  iteration: 12591 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 161 loss: 1.50436 acc: 0.69401 | v_loss: 1.22349 v_acc: 0.72201 |  iteration: 12592 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 162 loss: 1.45270 acc: 0.70182 | v_loss: 1.41725 v_acc: 0.70378 |  iteration: 12593 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 163 loss: 1.41124 acc: 0.70247 | v_loss: 1.36301 v_acc: 0.71810 |  iteration: 12594 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 164 loss: 1.44593 acc: 0.69661 | v_loss: 1.36462 v_acc: 0.72949 |  iteration: 12595 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 165 loss: 1.52678 acc: 0.69434 | v_loss: 1.35834 v_acc: 0.71810 |  iteration: 12596 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 166 loss: 1.49456 acc: 0.69694 | v_loss: 1.37310 v_acc: 0.70508 |  iteration: 12597 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 167 loss: 1.45439 acc: 0.70378 | v_loss: 1.29716 v_acc: 0.72363 |  iteration: 12598 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 168 loss: 1.49858 acc: 0.68913 | v_loss: 1.31555 v_acc: 0.72038 |  iteration: 12599 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 169 loss: 1.43268 acc: 0.71061 | v_loss: 1.50192 v_acc: 0.69206 |  iteration: 12600 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 170 loss: 1.35151 acc: 0.71224 | v_loss: 1.33999 v_acc: 0.70833 |  iteration: 12601 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 171 loss: 1.43864 acc: 0.69531 | v_loss: 1.28541 v_acc: 0.71582 |  iteration: 12602 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 172 loss: 1.38483 acc: 0.70573 | v_loss: 1.26996 v_acc: 0.72201 |  iteration: 12603 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 173 loss: 1.52889 acc: 0.70052 | v_loss: 1.42206 v_acc: 0.70768 |  iteration: 12604 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 174 loss: 1.48785 acc: 0.70475 | v_loss: 1.32468 v_acc: 0.73112 |  iteration: 12605 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 175 loss: 1.38077 acc: 0.71061 | v_loss: 1.55340 v_acc: 0.71452 |  iteration: 12606 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 176 loss: 1.45845 acc: 0.70638 | v_loss: 1.30185 v_acc: 0.69759 |  iteration: 12607 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 177 loss: 1.37492 acc: 0.71615 | v_loss: 1.30449 v_acc: 0.70443 |  iteration: 12608 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 178 loss: 1.52981 acc: 0.69434 | v_loss: 1.45560 v_acc: 0.70312 |  iteration: 12609 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 179 loss: 1.48358 acc: 0.70475 | v_loss: 1.47924 v_acc: 0.70378 |  iteration: 12610 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 180 loss: 1.44518 acc: 0.71061 | v_loss: 1.51992 v_acc: 0.68750 |  iteration: 12611 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 181 loss: 1.50474 acc: 0.70182 | v_loss: 1.47132 v_acc: 0.70215 |  iteration: 12612 teacher: 1 stage: sketch lr: 0.000394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 182 loss: 1.36212 acc: 0.70703 | v_loss: 1.41117 v_acc: 0.70573 |  iteration: 12613 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 183 loss: 1.46962 acc: 0.69043 | v_loss: 1.40569 v_acc: 0.70573 |  iteration: 12614 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 184 loss: 1.44203 acc: 0.70410 | v_loss: 1.40960 v_acc: 0.70573 |  iteration: 12615 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 185 loss: 1.48534 acc: 0.70182 | v_loss: 1.26890 v_acc: 0.71126 |  iteration: 12616 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 186 loss: 1.47994 acc: 0.70801 | v_loss: 1.34080 v_acc: 0.72331 |  iteration: 12617 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 187 loss: 1.42752 acc: 0.70508 | v_loss: 1.20752 v_acc: 0.70573 |  iteration: 12618 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 188 loss: 1.44351 acc: 0.69238 | v_loss: 1.35723 v_acc: 0.70150 |  iteration: 12619 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 189 loss: 1.32082 acc: 0.70801 | v_loss: 1.51078 v_acc: 0.69987 |  iteration: 12620 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 190 loss: 1.40324 acc: 0.70312 | v_loss: 1.34160 v_acc: 0.70833 |  iteration: 12621 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 191 loss: 1.37225 acc: 0.70052 | v_loss: 1.37771 v_acc: 0.69727 |  iteration: 12622 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 192 loss: 1.39756 acc: 0.70736 | v_loss: 1.24101 v_acc: 0.71680 |  iteration: 12623 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 193 loss: 1.48712 acc: 0.70671 | v_loss: 1.23630 v_acc: 0.70671 |  iteration: 12624 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 194 loss: 1.47006 acc: 0.69954 | v_loss: 1.27216 v_acc: 0.73568 |  iteration: 12625 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 195 loss: 1.53815 acc: 0.69434 | v_loss: 1.27144 v_acc: 0.72461 |  iteration: 12626 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 196 loss: 1.42165 acc: 0.69889 | v_loss: 1.33233 v_acc: 0.72689 |  iteration: 12627 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 197 loss: 1.39535 acc: 0.70182 | v_loss: 1.26311 v_acc: 0.72461 |  iteration: 12628 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 198 loss: 1.43449 acc: 0.70540 | v_loss: 1.29582 v_acc: 0.72005 |  iteration: 12629 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 199 loss: 1.50249 acc: 0.69499 | v_loss: 1.40406 v_acc: 0.71289 |  iteration: 12630 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 200 loss: 1.48716 acc: 0.70020 | v_loss: 1.38240 v_acc: 0.72298 |  iteration: 12631 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 201 loss: 1.43887 acc: 0.70345 | v_loss: 1.48827 v_acc: 0.70052 |  iteration: 12632 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 202 loss: 1.48906 acc: 0.69076 | v_loss: 1.41273 v_acc: 0.71875 |  iteration: 12633 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 203 loss: 1.43060 acc: 0.70475 | v_loss: 1.17612 v_acc: 0.74382 |  iteration: 12634 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 204 loss: 1.43489 acc: 0.70638 | v_loss: 1.26481 v_acc: 0.70280 |  iteration: 12635 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 205 loss: 1.42904 acc: 0.69954 | v_loss: 1.53111 v_acc: 0.70247 |  iteration: 12636 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 206 loss: 1.43804 acc: 0.69596 | v_loss: 1.21547 v_acc: 0.70866 |  iteration: 12637 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 207 loss: 1.48072 acc: 0.69466 | v_loss: 1.33756 v_acc: 0.71257 |  iteration: 12638 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 208 loss: 1.36486 acc: 0.71615 | v_loss: 1.38078 v_acc: 0.69368 |  iteration: 12639 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 209 loss: 1.53553 acc: 0.69596 | v_loss: 1.29037 v_acc: 0.71680 |  iteration: 12640 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 210 loss: 1.53834 acc: 0.69173 | v_loss: 1.38308 v_acc: 0.70247 |  iteration: 12641 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 211 loss: 1.42431 acc: 0.69922 | v_loss: 1.46680 v_acc: 0.72656 |  iteration: 12642 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 212 loss: 1.44123 acc: 0.70605 | v_loss: 1.33722 v_acc: 0.72786 |  iteration: 12643 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 213 loss: 1.45431 acc: 0.69434 | v_loss: 1.43858 v_acc: 0.70540 |  iteration: 12644 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 214 loss: 1.36169 acc: 0.71582 | v_loss: 1.36475 v_acc: 0.69922 |  iteration: 12645 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 215 loss: 1.35243 acc: 0.70540 | v_loss: 1.32696 v_acc: 0.70964 |  iteration: 12646 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 216 loss: 1.47820 acc: 0.70671 | v_loss: 1.54041 v_acc: 0.68913 |  iteration: 12647 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 217 loss: 1.42052 acc: 0.69694 | v_loss: 1.30829 v_acc: 0.72135 |  iteration: 12648 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 218 loss: 1.50030 acc: 0.70378 | v_loss: 1.58108 v_acc: 0.68294 |  iteration: 12649 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 219 loss: 1.49979 acc: 0.69694 | v_loss: 1.43966 v_acc: 0.69889 |  iteration: 12650 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 220 loss: 1.37173 acc: 0.70150 | v_loss: 1.52332 v_acc: 0.68978 |  iteration: 12651 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 221 loss: 1.31299 acc: 0.71582 | v_loss: 1.37192 v_acc: 0.69792 |  iteration: 12652 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 222 loss: 1.37255 acc: 0.71257 | v_loss: 1.32698 v_acc: 0.70312 |  iteration: 12653 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 223 loss: 1.47071 acc: 0.70020 | v_loss: 1.32877 v_acc: 0.70020 |  iteration: 12654 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 224 loss: 1.47454 acc: 0.69922 | v_loss: 1.33238 v_acc: 0.71842 |  iteration: 12655 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 225 loss: 1.48163 acc: 0.70410 | v_loss: 1.55695 v_acc: 0.69108 |  iteration: 12656 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 226 loss: 1.39686 acc: 0.69922 | v_loss: 1.38893 v_acc: 0.71126 |  iteration: 12657 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 227 loss: 1.44121 acc: 0.70117 | v_loss: 1.33305 v_acc: 0.71061 |  iteration: 12658 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 228 loss: 1.41799 acc: 0.70247 | v_loss: 1.38796 v_acc: 0.71582 |  iteration: 12659 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 229 loss: 1.37472 acc: 0.70638 | v_loss: 1.26993 v_acc: 0.70573 |  iteration: 12660 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 230 loss: 1.45318 acc: 0.70215 | v_loss: 1.43495 v_acc: 0.69792 |  iteration: 12661 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 231 loss: 1.46014 acc: 0.70215 | v_loss: 1.42735 v_acc: 0.71289 |  iteration: 12662 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 232 loss: 1.42194 acc: 0.70573 | v_loss: 1.28252 v_acc: 0.72038 |  iteration: 12663 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 233 loss: 1.40792 acc: 0.71191 | v_loss: 1.26424 v_acc: 0.72591 |  iteration: 12664 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 234 loss: 1.37000 acc: 0.70280 | v_loss: 1.38261 v_acc: 0.71908 |  iteration: 12665 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 235 loss: 1.31766 acc: 0.71029 | v_loss: 1.43686 v_acc: 0.70345 |  iteration: 12666 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 236 loss: 1.47417 acc: 0.70540 | v_loss: 1.44406 v_acc: 0.70410 |  iteration: 12667 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 237 loss: 1.46330 acc: 0.69108 | v_loss: 1.23006 v_acc: 0.71582 |  iteration: 12668 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 238 loss: 1.48879 acc: 0.69857 | v_loss: 1.40904 v_acc: 0.72884 |  iteration: 12669 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 239 loss: 1.42043 acc: 0.70605 | v_loss: 1.48600 v_acc: 0.69759 |  iteration: 12670 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 240 loss: 1.43391 acc: 0.69987 | v_loss: 1.41469 v_acc: 0.72201 |  iteration: 12671 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 241 loss: 1.41246 acc: 0.70247 | v_loss: 1.24294 v_acc: 0.72233 |  iteration: 12672 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 242 loss: 1.46374 acc: 0.69954 | v_loss: 1.19238 v_acc: 0.74447 |  iteration: 12673 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 243 loss: 1.45352 acc: 0.70508 | v_loss: 1.21337 v_acc: 0.72493 |  iteration: 12674 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 244 loss: 1.38459 acc: 0.71745 | v_loss: 1.27891 v_acc: 0.71126 |  iteration: 12675 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 245 loss: 1.43786 acc: 0.69368 | v_loss: 1.44471 v_acc: 0.70150 |  iteration: 12676 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 246 loss: 1.41492 acc: 0.70573 | v_loss: 1.27769 v_acc: 0.71322 |  iteration: 12677 teacher: 1 stage: sketch lr: 0.000393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 247 loss: 1.49030 acc: 0.69727 | v_loss: 1.44961 v_acc: 0.71680 |  iteration: 12678 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 248 loss: 1.41833 acc: 0.70540 | v_loss: 1.65692 v_acc: 0.69434 |  iteration: 12679 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 249 loss: 1.39283 acc: 0.71224 | v_loss: 1.52667 v_acc: 0.70052 |  iteration: 12680 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 250 loss: 1.37046 acc: 0.70215 | v_loss: 1.29502 v_acc: 0.72331 |  iteration: 12681 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 251 loss: 1.35613 acc: 0.70964 | v_loss: 1.38992 v_acc: 0.70052 |  iteration: 12682 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 252 loss: 1.44286 acc: 0.70052 | v_loss: 1.22650 v_acc: 0.72038 |  iteration: 12683 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 253 loss: 1.50193 acc: 0.69694 | v_loss: 1.44935 v_acc: 0.70150 |  iteration: 12684 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 254 loss: 1.33321 acc: 0.71517 | v_loss: 1.36651 v_acc: 0.71029 |  iteration: 12685 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 255 loss: 1.60285 acc: 0.68620 | v_loss: 1.36213 v_acc: 0.73079 |  iteration: 12686 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 256 loss: 1.52140 acc: 0.69564 | v_loss: 1.35758 v_acc: 0.71777 |  iteration: 12687 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 257 loss: 1.48408 acc: 0.69792 | v_loss: 1.36883 v_acc: 0.70410 |  iteration: 12688 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 258 loss: 1.43375 acc: 0.69271 | v_loss: 1.28724 v_acc: 0.72493 |  iteration: 12689 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 259 loss: 1.49739 acc: 0.69303 | v_loss: 1.29729 v_acc: 0.72038 |  iteration: 12690 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 260 loss: 1.47124 acc: 0.69954 | v_loss: 1.49055 v_acc: 0.69368 |  iteration: 12691 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 261 loss: 1.55126 acc: 0.69434 | v_loss: 1.33226 v_acc: 0.71452 |  iteration: 12692 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 262 loss: 1.41137 acc: 0.70768 | v_loss: 1.30389 v_acc: 0.71582 |  iteration: 12693 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 263 loss: 1.48858 acc: 0.69434 | v_loss: 1.29860 v_acc: 0.71094 |  iteration: 12694 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 264 loss: 1.42677 acc: 0.70150 | v_loss: 1.43486 v_acc: 0.70182 |  iteration: 12695 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 265 loss: 1.43892 acc: 0.69922 | v_loss: 1.31545 v_acc: 0.73210 |  iteration: 12696 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 266 loss: 1.42367 acc: 0.70052 | v_loss: 1.53949 v_acc: 0.71615 |  iteration: 12697 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 267 loss: 1.36970 acc: 0.70866 | v_loss: 1.27720 v_acc: 0.69922 |  iteration: 12698 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 268 loss: 1.49946 acc: 0.69889 | v_loss: 1.27361 v_acc: 0.70215 |  iteration: 12699 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 269 loss: 1.35717 acc: 0.70182 | v_loss: 1.45520 v_acc: 0.70410 |  iteration: 12700 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 270 loss: 1.33236 acc: 0.71387 | v_loss: 1.48810 v_acc: 0.70410 |  iteration: 12701 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 271 loss: 1.54111 acc: 0.70020 | v_loss: 1.53596 v_acc: 0.68945 |  iteration: 12702 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 272 loss: 1.44299 acc: 0.70280 | v_loss: 1.47006 v_acc: 0.70638 |  iteration: 12703 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 273 loss: 1.39658 acc: 0.71354 | v_loss: 1.42541 v_acc: 0.70410 |  iteration: 12704 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 274 loss: 1.34080 acc: 0.71224 | v_loss: 1.41159 v_acc: 0.70768 |  iteration: 12705 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 275 loss: 1.55438 acc: 0.69434 | v_loss: 1.40333 v_acc: 0.70540 |  iteration: 12706 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 276 loss: 1.49075 acc: 0.69824 | v_loss: 1.26583 v_acc: 0.71875 |  iteration: 12707 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 277 loss: 1.50320 acc: 0.69857 | v_loss: 1.32330 v_acc: 0.72493 |  iteration: 12708 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 278 loss: 1.40545 acc: 0.70312 | v_loss: 1.18698 v_acc: 0.71517 |  iteration: 12709 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 279 loss: 1.38464 acc: 0.70736 | v_loss: 1.34088 v_acc: 0.70703 |  iteration: 12710 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 280 loss: 1.44549 acc: 0.70312 | v_loss: 1.50093 v_acc: 0.70085 |  iteration: 12711 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 281 loss: 1.39172 acc: 0.70833 | v_loss: 1.34158 v_acc: 0.70736 |  iteration: 12712 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 282 loss: 1.40615 acc: 0.70964 | v_loss: 1.35089 v_acc: 0.69629 |  iteration: 12713 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 283 loss: 1.39579 acc: 0.70573 | v_loss: 1.25256 v_acc: 0.71126 |  iteration: 12714 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 284 loss: 1.46652 acc: 0.70573 | v_loss: 1.24734 v_acc: 0.70345 |  iteration: 12715 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 285 loss: 1.46765 acc: 0.70768 | v_loss: 1.23735 v_acc: 0.73503 |  iteration: 12716 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 286 loss: 1.43492 acc: 0.70312 | v_loss: 1.27488 v_acc: 0.72168 |  iteration: 12717 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 287 loss: 1.37035 acc: 0.70833 | v_loss: 1.32108 v_acc: 0.73145 |  iteration: 12718 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 288 loss: 1.42519 acc: 0.70150 | v_loss: 1.25744 v_acc: 0.72461 |  iteration: 12719 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 289 loss: 1.45928 acc: 0.70475 | v_loss: 1.30100 v_acc: 0.72005 |  iteration: 12720 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 290 loss: 1.41576 acc: 0.70410 | v_loss: 1.40962 v_acc: 0.71224 |  iteration: 12721 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 291 loss: 1.39392 acc: 0.70378 | v_loss: 1.39857 v_acc: 0.72070 |  iteration: 12722 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 292 loss: 1.36075 acc: 0.71029 | v_loss: 1.49566 v_acc: 0.69954 |  iteration: 12723 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 293 loss: 1.54622 acc: 0.69564 | v_loss: 1.42579 v_acc: 0.71615 |  iteration: 12724 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 294 loss: 1.55991 acc: 0.68750 | v_loss: 1.17692 v_acc: 0.74544 |  iteration: 12725 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 295 loss: 1.41543 acc: 0.70964 | v_loss: 1.24392 v_acc: 0.70898 |  iteration: 12726 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 296 loss: 1.38258 acc: 0.71029 | v_loss: 1.52092 v_acc: 0.70280 |  iteration: 12727 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 297 loss: 1.31336 acc: 0.71452 | v_loss: 1.20442 v_acc: 0.71647 |  iteration: 12728 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 298 loss: 1.38553 acc: 0.71908 | v_loss: 1.32862 v_acc: 0.71191 |  iteration: 12729 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 299 loss: 1.42350 acc: 0.70345 | v_loss: 1.37129 v_acc: 0.69076 |  iteration: 12730 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 300 loss: 1.51517 acc: 0.70182 | v_loss: 1.29656 v_acc: 0.70898 |  iteration: 12731 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 301 loss: 1.50239 acc: 0.69987 | v_loss: 1.37826 v_acc: 0.69173 |  iteration: 12732 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 302 loss: 1.45931 acc: 0.70052 | v_loss: 1.48832 v_acc: 0.70801 |  iteration: 12733 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 303 loss: 1.29154 acc: 0.71224 | v_loss: 1.32566 v_acc: 0.72819 |  iteration: 12734 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 304 loss: 1.44967 acc: 0.70215 | v_loss: 1.45809 v_acc: 0.70443 |  iteration: 12735 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 305 loss: 1.44080 acc: 0.69466 | v_loss: 1.35459 v_acc: 0.69922 |  iteration: 12736 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 306 loss: 1.55335 acc: 0.69271 | v_loss: 1.31964 v_acc: 0.70833 |  iteration: 12737 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 307 loss: 1.38536 acc: 0.71061 | v_loss: 1.56816 v_acc: 0.68522 |  iteration: 12738 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 308 loss: 1.56560 acc: 0.69271 | v_loss: 1.30036 v_acc: 0.72168 |  iteration: 12739 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 309 loss: 1.45233 acc: 0.70801 | v_loss: 1.61034 v_acc: 0.67448 |  iteration: 12740 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 310 loss: 1.45894 acc: 0.70931 | v_loss: 1.47169 v_acc: 0.69336 |  iteration: 12741 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 311 loss: 1.46348 acc: 0.69792 | v_loss: 1.52398 v_acc: 0.69238 |  iteration: 12742 teacher: 1 stage: sketch lr: 0.000392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 312 loss: 1.41033 acc: 0.70215 | v_loss: 1.37055 v_acc: 0.70182 |  iteration: 12743 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 313 loss: 1.57213 acc: 0.68978 | v_loss: 1.31899 v_acc: 0.70638 |  iteration: 12744 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 314 loss: 1.43068 acc: 0.70085 | v_loss: 1.33516 v_acc: 0.70020 |  iteration: 12745 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 315 loss: 1.42980 acc: 0.70215 | v_loss: 1.32972 v_acc: 0.71484 |  iteration: 12746 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 316 loss: 1.42731 acc: 0.70345 | v_loss: 1.53442 v_acc: 0.68978 |  iteration: 12747 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 317 loss: 1.46592 acc: 0.69792 | v_loss: 1.37969 v_acc: 0.70443 |  iteration: 12748 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 318 loss: 1.43868 acc: 0.70931 | v_loss: 1.35062 v_acc: 0.70898 |  iteration: 12749 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 319 loss: 1.45329 acc: 0.69954 | v_loss: 1.39323 v_acc: 0.71810 |  iteration: 12750 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 320 loss: 1.44937 acc: 0.70085 | v_loss: 1.27940 v_acc: 0.70215 |  iteration: 12751 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 321 loss: 1.43134 acc: 0.70085 | v_loss: 1.43186 v_acc: 0.69434 |  iteration: 12752 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 322 loss: 1.39675 acc: 0.70508 | v_loss: 1.42172 v_acc: 0.71452 |  iteration: 12753 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 323 loss: 1.43128 acc: 0.70020 | v_loss: 1.29240 v_acc: 0.71777 |  iteration: 12754 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 324 loss: 1.44440 acc: 0.70964 | v_loss: 1.25540 v_acc: 0.72754 |  iteration: 12755 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 325 loss: 1.29814 acc: 0.71094 | v_loss: 1.37666 v_acc: 0.71875 |  iteration: 12756 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 326 loss: 1.43536 acc: 0.70247 | v_loss: 1.42403 v_acc: 0.70345 |  iteration: 12757 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 327 loss: 1.44060 acc: 0.70378 | v_loss: 1.42458 v_acc: 0.70410 |  iteration: 12758 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 328 loss: 1.31703 acc: 0.71842 | v_loss: 1.22797 v_acc: 0.72070 |  iteration: 12759 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 329 loss: 1.46328 acc: 0.69629 | v_loss: 1.39941 v_acc: 0.73112 |  iteration: 12760 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 330 loss: 1.34199 acc: 0.71029 | v_loss: 1.48593 v_acc: 0.69759 |  iteration: 12761 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 331 loss: 1.47008 acc: 0.69434 | v_loss: 1.42723 v_acc: 0.72428 |  iteration: 12762 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 332 loss: 1.44000 acc: 0.69499 | v_loss: 1.24775 v_acc: 0.72201 |  iteration: 12763 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 333 loss: 1.42837 acc: 0.69792 | v_loss: 1.19425 v_acc: 0.74447 |  iteration: 12764 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 334 loss: 1.54345 acc: 0.68880 | v_loss: 1.20706 v_acc: 0.72721 |  iteration: 12765 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 335 loss: 1.45237 acc: 0.69954 | v_loss: 1.28008 v_acc: 0.70703 |  iteration: 12766 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 336 loss: 1.39121 acc: 0.70508 | v_loss: 1.45374 v_acc: 0.69694 |  iteration: 12767 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 337 loss: 1.39976 acc: 0.70605 | v_loss: 1.27852 v_acc: 0.71387 |  iteration: 12768 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 338 loss: 1.47357 acc: 0.70150 | v_loss: 1.43774 v_acc: 0.72949 |  iteration: 12769 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 339 loss: 1.52423 acc: 0.68750 | v_loss: 1.63772 v_acc: 0.69499 |  iteration: 12770 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 340 loss: 1.51715 acc: 0.69857 | v_loss: 1.50899 v_acc: 0.70475 |  iteration: 12771 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 341 loss: 1.43178 acc: 0.69629 | v_loss: 1.29438 v_acc: 0.72005 |  iteration: 12772 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 342 loss: 1.38711 acc: 0.70182 | v_loss: 1.37320 v_acc: 0.69987 |  iteration: 12773 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 343 loss: 1.39506 acc: 0.70117 | v_loss: 1.22650 v_acc: 0.71973 |  iteration: 12774 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 344 loss: 1.40818 acc: 0.70475 | v_loss: 1.41525 v_acc: 0.70150 |  iteration: 12775 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 345 loss: 1.44939 acc: 0.69857 | v_loss: 1.36696 v_acc: 0.71029 |  iteration: 12776 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 346 loss: 1.53764 acc: 0.69043 | v_loss: 1.35307 v_acc: 0.73079 |  iteration: 12777 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 347 loss: 1.47057 acc: 0.70052 | v_loss: 1.37078 v_acc: 0.71777 |  iteration: 12778 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 348 loss: 1.40446 acc: 0.70573 | v_loss: 1.37783 v_acc: 0.70410 |  iteration: 12779 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 349 loss: 1.41016 acc: 0.70378 | v_loss: 1.27858 v_acc: 0.72233 |  iteration: 12780 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 350 loss: 1.33023 acc: 0.70898 | v_loss: 1.29804 v_acc: 0.72135 |  iteration: 12781 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 351 loss: 1.50631 acc: 0.69271 | v_loss: 1.48144 v_acc: 0.69238 |  iteration: 12782 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 352 loss: 1.41725 acc: 0.70247 | v_loss: 1.32957 v_acc: 0.70833 |  iteration: 12783 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 353 loss: 1.50467 acc: 0.69922 | v_loss: 1.29347 v_acc: 0.71582 |  iteration: 12784 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 354 loss: 1.40113 acc: 0.71322 | v_loss: 1.28995 v_acc: 0.71842 |  iteration: 12785 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 355 loss: 1.45086 acc: 0.69629 | v_loss: 1.43247 v_acc: 0.70150 |  iteration: 12786 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 356 loss: 1.40566 acc: 0.70182 | v_loss: 1.31065 v_acc: 0.72786 |  iteration: 12787 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 357 loss: 1.44825 acc: 0.69141 | v_loss: 1.54272 v_acc: 0.71061 |  iteration: 12788 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 358 loss: 1.41566 acc: 0.70443 | v_loss: 1.28382 v_acc: 0.69954 |  iteration: 12789 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 359 loss: 1.50074 acc: 0.69824 | v_loss: 1.29073 v_acc: 0.70182 |  iteration: 12790 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 360 loss: 1.47479 acc: 0.69303 | v_loss: 1.43890 v_acc: 0.70280 |  iteration: 12791 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 361 loss: 1.37980 acc: 0.70964 | v_loss: 1.46754 v_acc: 0.70378 |  iteration: 12792 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 362 loss: 1.40806 acc: 0.70345 | v_loss: 1.51300 v_acc: 0.69368 |  iteration: 12793 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 363 loss: 1.45887 acc: 0.69271 | v_loss: 1.47823 v_acc: 0.70833 |  iteration: 12794 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 364 loss: 1.39053 acc: 0.70605 | v_loss: 1.43823 v_acc: 0.70085 |  iteration: 12795 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 365 loss: 1.51310 acc: 0.69824 | v_loss: 1.41188 v_acc: 0.70996 |  iteration: 12796 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 366 loss: 1.48569 acc: 0.69889 | v_loss: 1.38767 v_acc: 0.70898 |  iteration: 12797 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 367 loss: 1.42549 acc: 0.70150 | v_loss: 1.26668 v_acc: 0.71354 |  iteration: 12798 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 368 loss: 1.55964 acc: 0.70280 | v_loss: 1.31701 v_acc: 0.72949 |  iteration: 12799 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 369 loss: 1.37717 acc: 0.69922 | v_loss: 1.19912 v_acc: 0.71224 |  iteration: 12800 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 370 loss: 1.54347 acc: 0.69238 | v_loss: 1.34628 v_acc: 0.70215 |  iteration: 12801 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 371 loss: 1.39466 acc: 0.69954 | v_loss: 1.50257 v_acc: 0.70117 |  iteration: 12802 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 372 loss: 1.39368 acc: 0.70312 | v_loss: 1.36028 v_acc: 0.70475 |  iteration: 12803 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 373 loss: 1.42717 acc: 0.70410 | v_loss: 1.35715 v_acc: 0.69661 |  iteration: 12804 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 374 loss: 1.50151 acc: 0.69043 | v_loss: 1.26732 v_acc: 0.70573 |  iteration: 12805 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 375 loss: 1.39600 acc: 0.70247 | v_loss: 1.24312 v_acc: 0.70215 |  iteration: 12806 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 376 loss: 1.40668 acc: 0.70280 | v_loss: 1.25277 v_acc: 0.73503 |  iteration: 12807 teacher: 0 stage: sketch lr: 0.000391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 377 loss: 1.40666 acc: 0.70833 | v_loss: 1.26298 v_acc: 0.72168 |  iteration: 12808 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 378 loss: 1.39353 acc: 0.70801 | v_loss: 1.33805 v_acc: 0.73145 |  iteration: 12809 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 379 loss: 1.35203 acc: 0.70215 | v_loss: 1.25944 v_acc: 0.72786 |  iteration: 12810 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 380 loss: 1.48242 acc: 0.70410 | v_loss: 1.30702 v_acc: 0.72103 |  iteration: 12811 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 381 loss: 1.35691 acc: 0.70638 | v_loss: 1.41741 v_acc: 0.71354 |  iteration: 12812 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 382 loss: 1.43384 acc: 0.70671 | v_loss: 1.39667 v_acc: 0.72070 |  iteration: 12813 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 383 loss: 1.43572 acc: 0.70540 | v_loss: 1.49235 v_acc: 0.69922 |  iteration: 12814 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 384 loss: 1.39620 acc: 0.70345 | v_loss: 1.41198 v_acc: 0.71973 |  iteration: 12815 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 385 loss: 1.47053 acc: 0.70182 | v_loss: 1.17802 v_acc: 0.74349 |  iteration: 12816 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 386 loss: 1.61318 acc: 0.68457 | v_loss: 1.28085 v_acc: 0.70345 |  iteration: 12817 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 387 loss: 1.42162 acc: 0.70150 | v_loss: 1.50687 v_acc: 0.70898 |  iteration: 12818 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 388 loss: 1.55955 acc: 0.69531 | v_loss: 1.23358 v_acc: 0.73177 |  iteration: 12819 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 389 loss: 1.45987 acc: 0.70085 | v_loss: 1.31999 v_acc: 0.72103 |  iteration: 12820 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 390 loss: 1.46417 acc: 0.69889 | v_loss: 1.37414 v_acc: 0.69141 |  iteration: 12821 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 391 loss: 1.43527 acc: 0.70215 | v_loss: 1.31355 v_acc: 0.70801 |  iteration: 12822 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 392 loss: 1.39992 acc: 0.70833 | v_loss: 1.36856 v_acc: 0.69206 |  iteration: 12823 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 393 loss: 1.39003 acc: 0.71615 | v_loss: 1.45748 v_acc: 0.70931 |  iteration: 12824 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 394 loss: 1.51509 acc: 0.69824 | v_loss: 1.31555 v_acc: 0.72689 |  iteration: 12825 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 395 loss: 1.47069 acc: 0.69987 | v_loss: 1.43413 v_acc: 0.70443 |  iteration: 12826 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 396 loss: 1.48570 acc: 0.70345 | v_loss: 1.37999 v_acc: 0.69922 |  iteration: 12827 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 397 loss: 1.42486 acc: 0.70410 | v_loss: 1.31915 v_acc: 0.70898 |  iteration: 12828 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 398 loss: 1.47816 acc: 0.69889 | v_loss: 1.55752 v_acc: 0.68913 |  iteration: 12829 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 399 loss: 1.42715 acc: 0.69954 | v_loss: 1.30738 v_acc: 0.72135 |  iteration: 12830 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 400 loss: 1.45932 acc: 0.70475 | v_loss: 1.59381 v_acc: 0.68392 |  iteration: 12831 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 401 loss: 1.43921 acc: 0.70378 | v_loss: 1.46341 v_acc: 0.69694 |  iteration: 12832 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 402 loss: 1.47303 acc: 0.69401 | v_loss: 1.52529 v_acc: 0.68913 |  iteration: 12833 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 403 loss: 1.49660 acc: 0.69466 | v_loss: 1.37907 v_acc: 0.69792 |  iteration: 12834 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 404 loss: 1.51167 acc: 0.70312 | v_loss: 1.32605 v_acc: 0.70378 |  iteration: 12835 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 405 loss: 1.32809 acc: 0.71029 | v_loss: 1.33194 v_acc: 0.69759 |  iteration: 12836 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 406 loss: 1.33663 acc: 0.71940 | v_loss: 1.33199 v_acc: 0.71549 |  iteration: 12837 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 407 loss: 1.40974 acc: 0.71061 | v_loss: 1.52137 v_acc: 0.69401 |  iteration: 12838 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 408 loss: 1.54035 acc: 0.68848 | v_loss: 1.37419 v_acc: 0.69922 |  iteration: 12839 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 409 loss: 1.38730 acc: 0.69434 | v_loss: 1.35719 v_acc: 0.71126 |  iteration: 12840 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 410 loss: 1.41779 acc: 0.70312 | v_loss: 1.39341 v_acc: 0.71680 |  iteration: 12841 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 411 loss: 1.35476 acc: 0.70736 | v_loss: 1.25963 v_acc: 0.70736 |  iteration: 12842 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 412 loss: 1.42094 acc: 0.70117 | v_loss: 1.44244 v_acc: 0.70085 |  iteration: 12843 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 413 loss: 1.47987 acc: 0.69661 | v_loss: 1.44226 v_acc: 0.71094 |  iteration: 12844 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 414 loss: 1.43238 acc: 0.69792 | v_loss: 1.28151 v_acc: 0.71810 |  iteration: 12845 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 415 loss: 1.32970 acc: 0.70996 | v_loss: 1.25023 v_acc: 0.72298 |  iteration: 12846 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 416 loss: 1.54081 acc: 0.69727 | v_loss: 1.38113 v_acc: 0.72266 |  iteration: 12847 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 417 loss: 1.43847 acc: 0.69857 | v_loss: 1.40602 v_acc: 0.70378 |  iteration: 12848 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 418 loss: 1.54880 acc: 0.69564 | v_loss: 1.41543 v_acc: 0.70605 |  iteration: 12849 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 419 loss: 1.48179 acc: 0.69303 | v_loss: 1.23664 v_acc: 0.71615 |  iteration: 12850 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 420 loss: 1.42383 acc: 0.70671 | v_loss: 1.38196 v_acc: 0.72754 |  iteration: 12851 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 421 loss: 1.54561 acc: 0.69499 | v_loss: 1.46376 v_acc: 0.69531 |  iteration: 12852 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 422 loss: 1.38094 acc: 0.70085 | v_loss: 1.40610 v_acc: 0.72233 |  iteration: 12853 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 423 loss: 1.52085 acc: 0.70638 | v_loss: 1.25618 v_acc: 0.71810 |  iteration: 12854 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 424 loss: 1.41810 acc: 0.70410 | v_loss: 1.22223 v_acc: 0.73340 |  iteration: 12855 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 425 loss: 1.50975 acc: 0.69629 | v_loss: 1.21935 v_acc: 0.72559 |  iteration: 12856 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 426 loss: 1.41476 acc: 0.70020 | v_loss: 1.29886 v_acc: 0.70703 |  iteration: 12857 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 427 loss: 1.50575 acc: 0.69727 | v_loss: 1.45880 v_acc: 0.69466 |  iteration: 12858 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 428 loss: 1.47356 acc: 0.70410 | v_loss: 1.26898 v_acc: 0.71549 |  iteration: 12859 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 429 loss: 1.43365 acc: 0.69987 | v_loss: 1.41854 v_acc: 0.71647 |  iteration: 12860 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 430 loss: 1.41829 acc: 0.70410 | v_loss: 1.66157 v_acc: 0.69303 |  iteration: 12861 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 431 loss: 1.43062 acc: 0.70768 | v_loss: 1.51804 v_acc: 0.70117 |  iteration: 12862 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 432 loss: 1.46841 acc: 0.69661 | v_loss: 1.29352 v_acc: 0.72396 |  iteration: 12863 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 433 loss: 1.45477 acc: 0.70150 | v_loss: 1.36747 v_acc: 0.70996 |  iteration: 12864 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 434 loss: 1.47559 acc: 0.70736 | v_loss: 1.21366 v_acc: 0.72201 |  iteration: 12865 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 435 loss: 1.41510 acc: 0.70280 | v_loss: 1.41394 v_acc: 0.70378 |  iteration: 12866 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 436 loss: 1.35369 acc: 0.70638 | v_loss: 1.35393 v_acc: 0.71875 |  iteration: 12867 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 437 loss: 1.47452 acc: 0.70605 | v_loss: 1.35586 v_acc: 0.73047 |  iteration: 12868 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 438 loss: 1.43939 acc: 0.70052 | v_loss: 1.36585 v_acc: 0.72005 |  iteration: 12869 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 439 loss: 1.33630 acc: 0.70443 | v_loss: 1.37704 v_acc: 0.70833 |  iteration: 12870 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 440 loss: 1.46078 acc: 0.69596 | v_loss: 1.28528 v_acc: 0.72428 |  iteration: 12871 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 441 loss: 1.33300 acc: 0.71257 | v_loss: 1.29725 v_acc: 0.72005 |  iteration: 12872 teacher: 1 stage: sketch lr: 0.000390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 442 loss: 1.51581 acc: 0.69271 | v_loss: 1.48173 v_acc: 0.69206 |  iteration: 12873 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 443 loss: 1.52310 acc: 0.70475 | v_loss: 1.33251 v_acc: 0.70801 |  iteration: 12874 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 444 loss: 1.48858 acc: 0.69792 | v_loss: 1.29070 v_acc: 0.71777 |  iteration: 12875 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 445 loss: 1.53896 acc: 0.69368 | v_loss: 1.28960 v_acc: 0.71875 |  iteration: 12876 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 446 loss: 1.43156 acc: 0.71452 | v_loss: 1.42643 v_acc: 0.70573 |  iteration: 12877 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 447 loss: 1.47299 acc: 0.70345 | v_loss: 1.30435 v_acc: 0.73242 |  iteration: 12878 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 448 loss: 1.45663 acc: 0.69857 | v_loss: 1.53557 v_acc: 0.71484 |  iteration: 12879 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 449 loss: 1.37472 acc: 0.70605 | v_loss: 1.29457 v_acc: 0.69759 |  iteration: 12880 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 450 loss: 1.26083 acc: 0.71908 | v_loss: 1.28392 v_acc: 0.70443 |  iteration: 12881 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 451 loss: 1.48189 acc: 0.70052 | v_loss: 1.42738 v_acc: 0.70312 |  iteration: 12882 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 452 loss: 1.43105 acc: 0.70833 | v_loss: 1.46107 v_acc: 0.70378 |  iteration: 12883 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 453 loss: 1.48001 acc: 0.70117 | v_loss: 1.51291 v_acc: 0.68978 |  iteration: 12884 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 454 loss: 1.40371 acc: 0.71061 | v_loss: 1.47005 v_acc: 0.70638 |  iteration: 12885 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 455 loss: 1.45872 acc: 0.70052 | v_loss: 1.41352 v_acc: 0.70410 |  iteration: 12886 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 456 loss: 1.31682 acc: 0.70768 | v_loss: 1.40312 v_acc: 0.70768 |  iteration: 12887 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 457 loss: 1.47185 acc: 0.69889 | v_loss: 1.40359 v_acc: 0.70475 |  iteration: 12888 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 458 loss: 1.31316 acc: 0.71615 | v_loss: 1.26379 v_acc: 0.71452 |  iteration: 12889 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 459 loss: 1.41534 acc: 0.70964 | v_loss: 1.32579 v_acc: 0.72493 |  iteration: 12890 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 460 loss: 1.44159 acc: 0.71126 | v_loss: 1.19214 v_acc: 0.70671 |  iteration: 12891 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 461 loss: 1.47413 acc: 0.70508 | v_loss: 1.35034 v_acc: 0.70150 |  iteration: 12892 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 462 loss: 1.38541 acc: 0.70768 | v_loss: 1.50033 v_acc: 0.70215 |  iteration: 12893 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 463 loss: 1.37589 acc: 0.70508 | v_loss: 1.34149 v_acc: 0.70540 |  iteration: 12894 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 464 loss: 1.55739 acc: 0.68945 | v_loss: 1.34717 v_acc: 0.69629 |  iteration: 12895 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 465 loss: 1.41010 acc: 0.69824 | v_loss: 1.24932 v_acc: 0.70638 |  iteration: 12896 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 466 loss: 1.38922 acc: 0.70671 | v_loss: 1.23750 v_acc: 0.70410 |  iteration: 12897 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 467 loss: 1.43704 acc: 0.69987 | v_loss: 1.23490 v_acc: 0.73926 |  iteration: 12898 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 468 loss: 1.38721 acc: 0.70638 | v_loss: 1.25629 v_acc: 0.72201 |  iteration: 12899 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 469 loss: 1.42422 acc: 0.70182 | v_loss: 1.35759 v_acc: 0.72754 |  iteration: 12900 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 470 loss: 1.41882 acc: 0.70052 | v_loss: 1.26815 v_acc: 0.72559 |  iteration: 12901 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 471 loss: 1.40081 acc: 0.70573 | v_loss: 1.31002 v_acc: 0.72526 |  iteration: 12902 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 472 loss: 1.37609 acc: 0.70280 | v_loss: 1.42518 v_acc: 0.71549 |  iteration: 12903 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 473 loss: 1.56619 acc: 0.68848 | v_loss: 1.41034 v_acc: 0.71908 |  iteration: 12904 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 474 loss: 1.49641 acc: 0.69922 | v_loss: 1.48579 v_acc: 0.69954 |  iteration: 12905 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 475 loss: 1.37447 acc: 0.70768 | v_loss: 1.42839 v_acc: 0.71615 |  iteration: 12906 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 476 loss: 1.39720 acc: 0.71029 | v_loss: 1.17702 v_acc: 0.74544 |  iteration: 12907 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 477 loss: 1.48575 acc: 0.70345 | v_loss: 1.27251 v_acc: 0.70280 |  iteration: 12908 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 478 loss: 1.55679 acc: 0.68587 | v_loss: 1.50329 v_acc: 0.70280 |  iteration: 12909 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 479 loss: 1.46896 acc: 0.69824 | v_loss: 1.23423 v_acc: 0.71647 |  iteration: 12910 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 480 loss: 1.48785 acc: 0.69792 | v_loss: 1.31766 v_acc: 0.71484 |  iteration: 12911 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 481 loss: 1.48996 acc: 0.70215 | v_loss: 1.36503 v_acc: 0.69076 |  iteration: 12912 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 482 loss: 1.41772 acc: 0.70475 | v_loss: 1.30784 v_acc: 0.70898 |  iteration: 12913 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 483 loss: 1.42590 acc: 0.71029 | v_loss: 1.36633 v_acc: 0.69206 |  iteration: 12914 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 484 loss: 1.30972 acc: 0.72005 | v_loss: 1.48093 v_acc: 0.71517 |  iteration: 12915 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 485 loss: 1.42924 acc: 0.70020 | v_loss: 1.32210 v_acc: 0.72689 |  iteration: 12916 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 486 loss: 1.40118 acc: 0.70280 | v_loss: 1.47208 v_acc: 0.70443 |  iteration: 12917 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 487 loss: 1.40635 acc: 0.70638 | v_loss: 1.36068 v_acc: 0.69824 |  iteration: 12918 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 488 loss: 1.41522 acc: 0.70931 | v_loss: 1.33496 v_acc: 0.70768 |  iteration: 12919 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 489 loss: 1.59224 acc: 0.69141 | v_loss: 1.57232 v_acc: 0.68457 |  iteration: 12920 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 490 loss: 1.53589 acc: 0.69206 | v_loss: 1.31545 v_acc: 0.72135 |  iteration: 12921 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 491 loss: 1.39719 acc: 0.70605 | v_loss: 1.58150 v_acc: 0.68294 |  iteration: 12922 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 492 loss: 1.45783 acc: 0.70508 | v_loss: 1.44251 v_acc: 0.69889 |  iteration: 12923 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 493 loss: 1.39078 acc: 0.70996 | v_loss: 1.51256 v_acc: 0.68978 |  iteration: 12924 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 494 loss: 1.42392 acc: 0.70247 | v_loss: 1.38587 v_acc: 0.69792 |  iteration: 12925 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 495 loss: 1.43803 acc: 0.70345 | v_loss: 1.31378 v_acc: 0.70378 |  iteration: 12926 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 496 loss: 1.40078 acc: 0.70833 | v_loss: 1.33594 v_acc: 0.70215 |  iteration: 12927 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 497 loss: 1.28856 acc: 0.71419 | v_loss: 1.33100 v_acc: 0.71419 |  iteration: 12928 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 498 loss: 1.51493 acc: 0.68978 | v_loss: 1.53914 v_acc: 0.69173 |  iteration: 12929 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 499 loss: 1.39537 acc: 0.70964 | v_loss: 1.38754 v_acc: 0.70247 |  iteration: 12930 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 500 loss: 1.44444 acc: 0.70117 | v_loss: 1.36440 v_acc: 0.71126 |  iteration: 12931 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 501 loss: 1.28735 acc: 0.70768 | v_loss: 1.40068 v_acc: 0.71680 |  iteration: 12932 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 502 loss: 1.47112 acc: 0.70085 | v_loss: 1.27435 v_acc: 0.70573 |  iteration: 12933 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 503 loss: 1.45097 acc: 0.69694 | v_loss: 1.46426 v_acc: 0.69824 |  iteration: 12934 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 504 loss: 1.38311 acc: 0.71517 | v_loss: 1.47354 v_acc: 0.71224 |  iteration: 12935 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 505 loss: 1.56080 acc: 0.70052 | v_loss: 1.28346 v_acc: 0.72201 |  iteration: 12936 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 506 loss: 1.44160 acc: 0.70117 | v_loss: 1.28982 v_acc: 0.72591 |  iteration: 12937 teacher: 1 stage: sketch lr: 0.000389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 507 loss: 1.47224 acc: 0.70150 | v_loss: 1.39624 v_acc: 0.72266 |  iteration: 12938 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 508 loss: 1.54401 acc: 0.69889 | v_loss: 1.42604 v_acc: 0.70410 |  iteration: 12939 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 509 loss: 1.36847 acc: 0.71029 | v_loss: 1.42061 v_acc: 0.70410 |  iteration: 12940 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 510 loss: 1.45852 acc: 0.69694 | v_loss: 1.24054 v_acc: 0.71419 |  iteration: 12941 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 511 loss: 1.50059 acc: 0.70020 | v_loss: 1.38358 v_acc: 0.72819 |  iteration: 12942 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 512 loss: 1.44261 acc: 0.70768 | v_loss: 1.45842 v_acc: 0.70085 |  iteration: 12943 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 513 loss: 1.32975 acc: 0.71745 | v_loss: 1.38326 v_acc: 0.71908 |  iteration: 12944 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 514 loss: 1.47254 acc: 0.69596 | v_loss: 1.27207 v_acc: 0.71615 |  iteration: 12945 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 515 loss: 1.36914 acc: 0.71647 | v_loss: 1.23017 v_acc: 0.72819 |  iteration: 12946 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 516 loss: 1.43189 acc: 0.71777 | v_loss: 1.23194 v_acc: 0.72559 |  iteration: 12947 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 517 loss: 1.39810 acc: 0.70605 | v_loss: 1.31828 v_acc: 0.70671 |  iteration: 12948 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 518 loss: 1.44746 acc: 0.70898 | v_loss: 1.47955 v_acc: 0.69466 |  iteration: 12949 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 519 loss: 1.47044 acc: 0.70150 | v_loss: 1.27558 v_acc: 0.71452 |  iteration: 12950 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 520 loss: 1.41591 acc: 0.70150 | v_loss: 1.44703 v_acc: 0.71647 |  iteration: 12951 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 521 loss: 1.43176 acc: 0.71257 | v_loss: 1.69368 v_acc: 0.69303 |  iteration: 12952 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 522 loss: 1.44238 acc: 0.70443 | v_loss: 1.55243 v_acc: 0.69727 |  iteration: 12953 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 523 loss: 1.44082 acc: 0.69792 | v_loss: 1.29530 v_acc: 0.72396 |  iteration: 12954 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 524 loss: 1.46884 acc: 0.69141 | v_loss: 1.38246 v_acc: 0.70964 |  iteration: 12955 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 525 loss: 1.46003 acc: 0.70020 | v_loss: 1.22286 v_acc: 0.72168 |  iteration: 12956 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 526 loss: 1.51188 acc: 0.70117 | v_loss: 1.41368 v_acc: 0.70378 |  iteration: 12957 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 527 loss: 1.58208 acc: 0.68587 | v_loss: 1.36815 v_acc: 0.70866 |  iteration: 12958 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 528 loss: 1.43237 acc: 0.70215 | v_loss: 1.35549 v_acc: 0.72917 |  iteration: 12959 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 529 loss: 1.45960 acc: 0.70052 | v_loss: 1.35872 v_acc: 0.71810 |  iteration: 12960 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 530 loss: 1.50460 acc: 0.68783 | v_loss: 1.37932 v_acc: 0.70508 |  iteration: 12961 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 531 loss: 1.47939 acc: 0.69076 | v_loss: 1.30166 v_acc: 0.72266 |  iteration: 12962 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 532 loss: 1.41041 acc: 0.71257 | v_loss: 1.31464 v_acc: 0.71875 |  iteration: 12963 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 533 loss: 1.41351 acc: 0.70801 | v_loss: 1.49948 v_acc: 0.68717 |  iteration: 12964 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 534 loss: 1.49131 acc: 0.70573 | v_loss: 1.33518 v_acc: 0.71029 |  iteration: 12965 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 535 loss: 1.36356 acc: 0.71777 | v_loss: 1.30744 v_acc: 0.71257 |  iteration: 12966 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 536 loss: 1.44921 acc: 0.69889 | v_loss: 1.29005 v_acc: 0.72624 |  iteration: 12967 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 537 loss: 1.43077 acc: 0.70736 | v_loss: 1.41970 v_acc: 0.70703 |  iteration: 12968 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 538 loss: 1.45243 acc: 0.69889 | v_loss: 1.31590 v_acc: 0.73210 |  iteration: 12969 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 539 loss: 1.35041 acc: 0.71094 | v_loss: 1.55166 v_acc: 0.71452 |  iteration: 12970 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 540 loss: 1.41159 acc: 0.70736 | v_loss: 1.29644 v_acc: 0.69759 |  iteration: 12971 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 541 loss: 1.35621 acc: 0.70540 | v_loss: 1.29348 v_acc: 0.70443 |  iteration: 12972 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 542 loss: 1.43605 acc: 0.71842 | v_loss: 1.47488 v_acc: 0.70312 |  iteration: 12973 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 543 loss: 1.44004 acc: 0.70410 | v_loss: 1.50178 v_acc: 0.70378 |  iteration: 12974 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 544 loss: 1.42763 acc: 0.70736 | v_loss: 1.54795 v_acc: 0.69368 |  iteration: 12975 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 545 loss: 1.41108 acc: 0.71387 | v_loss: 1.48069 v_acc: 0.70833 |  iteration: 12976 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 546 loss: 1.35472 acc: 0.70150 | v_loss: 1.43737 v_acc: 0.70085 |  iteration: 12977 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 547 loss: 1.45793 acc: 0.70508 | v_loss: 1.42108 v_acc: 0.70801 |  iteration: 12978 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 548 loss: 1.39543 acc: 0.70898 | v_loss: 1.39043 v_acc: 0.71029 |  iteration: 12979 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 549 loss: 1.35444 acc: 0.70573 | v_loss: 1.25879 v_acc: 0.71191 |  iteration: 12980 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 550 loss: 1.49611 acc: 0.69889 | v_loss: 1.32330 v_acc: 0.72396 |  iteration: 12981 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 551 loss: 1.34301 acc: 0.70931 | v_loss: 1.19657 v_acc: 0.70638 |  iteration: 12982 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 552 loss: 1.44484 acc: 0.70410 | v_loss: 1.34485 v_acc: 0.70247 |  iteration: 12983 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 553 loss: 1.39406 acc: 0.70378 | v_loss: 1.50189 v_acc: 0.69987 |  iteration: 12984 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 554 loss: 1.35438 acc: 0.70898 | v_loss: 1.33558 v_acc: 0.70638 |  iteration: 12985 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 555 loss: 1.51800 acc: 0.69238 | v_loss: 1.35112 v_acc: 0.69727 |  iteration: 12986 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 556 loss: 1.49394 acc: 0.69857 | v_loss: 1.25744 v_acc: 0.71126 |  iteration: 12987 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 557 loss: 1.48811 acc: 0.69857 | v_loss: 1.25064 v_acc: 0.70345 |  iteration: 12988 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 558 loss: 1.41432 acc: 0.69792 | v_loss: 1.24479 v_acc: 0.73503 |  iteration: 12989 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 559 loss: 1.47807 acc: 0.69954 | v_loss: 1.28042 v_acc: 0.72168 |  iteration: 12990 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 560 loss: 1.35170 acc: 0.71061 | v_loss: 1.35852 v_acc: 0.73145 |  iteration: 12991 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 561 loss: 1.44667 acc: 0.70443 | v_loss: 1.26192 v_acc: 0.72852 |  iteration: 12992 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 562 loss: 1.53880 acc: 0.69173 | v_loss: 1.31317 v_acc: 0.72103 |  iteration: 12993 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 563 loss: 1.48895 acc: 0.69889 | v_loss: 1.42198 v_acc: 0.71354 |  iteration: 12994 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 564 loss: 1.44084 acc: 0.70768 | v_loss: 1.40742 v_acc: 0.72428 |  iteration: 12995 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 565 loss: 1.42614 acc: 0.70410 | v_loss: 1.48310 v_acc: 0.70182 |  iteration: 12996 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 566 loss: 1.52448 acc: 0.69824 | v_loss: 1.41782 v_acc: 0.71777 |  iteration: 12997 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 567 loss: 1.52755 acc: 0.69661 | v_loss: 1.17924 v_acc: 0.74447 |  iteration: 12998 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 568 loss: 1.43809 acc: 0.70247 | v_loss: 1.26034 v_acc: 0.70931 |  iteration: 12999 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 569 loss: 1.48155 acc: 0.69922 | v_loss: 1.50752 v_acc: 0.70280 |  iteration: 13000 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 570 loss: 1.38028 acc: 0.71029 | v_loss: 1.23905 v_acc: 0.70833 |  iteration: 13001 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 571 loss: 1.43638 acc: 0.70378 | v_loss: 1.32195 v_acc: 0.71777 |  iteration: 13002 teacher: 0 stage: sketch lr: 0.000388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 572 loss: 1.48346 acc: 0.69857 | v_loss: 1.36211 v_acc: 0.69596 |  iteration: 13003 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 573 loss: 1.51434 acc: 0.69368 | v_loss: 1.31989 v_acc: 0.70833 |  iteration: 13004 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 574 loss: 1.50244 acc: 0.70605 | v_loss: 1.37673 v_acc: 0.69076 |  iteration: 13005 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 575 loss: 1.36370 acc: 0.72005 | v_loss: 1.46935 v_acc: 0.70671 |  iteration: 13006 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 576 loss: 1.44304 acc: 0.69759 | v_loss: 1.31331 v_acc: 0.72070 |  iteration: 13007 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 577 loss: 1.51816 acc: 0.69368 | v_loss: 1.45410 v_acc: 0.70540 |  iteration: 13008 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 578 loss: 1.39840 acc: 0.71322 | v_loss: 1.36983 v_acc: 0.70052 |  iteration: 13009 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 579 loss: 1.44031 acc: 0.70768 | v_loss: 1.33729 v_acc: 0.70801 |  iteration: 13010 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 580 loss: 1.50556 acc: 0.69434 | v_loss: 1.55881 v_acc: 0.68815 |  iteration: 13011 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 581 loss: 1.37558 acc: 0.71615 | v_loss: 1.29985 v_acc: 0.72005 |  iteration: 13012 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 582 loss: 1.41486 acc: 0.71484 | v_loss: 1.59835 v_acc: 0.68424 |  iteration: 13013 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 583 loss: 1.44077 acc: 0.70931 | v_loss: 1.46252 v_acc: 0.69792 |  iteration: 13014 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 584 loss: 1.42005 acc: 0.70573 | v_loss: 1.52847 v_acc: 0.69173 |  iteration: 13015 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 585 loss: 1.40500 acc: 0.70475 | v_loss: 1.38029 v_acc: 0.70020 |  iteration: 13016 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 586 loss: 1.41340 acc: 0.70443 | v_loss: 1.32826 v_acc: 0.70312 |  iteration: 13017 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 587 loss: 1.53703 acc: 0.69987 | v_loss: 1.33966 v_acc: 0.70020 |  iteration: 13018 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 588 loss: 1.41227 acc: 0.70573 | v_loss: 1.33636 v_acc: 0.71484 |  iteration: 13019 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 589 loss: 1.33185 acc: 0.70996 | v_loss: 1.53090 v_acc: 0.68978 |  iteration: 13020 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 590 loss: 1.43212 acc: 0.70117 | v_loss: 1.37933 v_acc: 0.70443 |  iteration: 13021 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 591 loss: 1.54096 acc: 0.70410 | v_loss: 1.34489 v_acc: 0.71029 |  iteration: 13022 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 592 loss: 1.38552 acc: 0.70898 | v_loss: 1.38033 v_acc: 0.71680 |  iteration: 13023 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 593 loss: 1.38872 acc: 0.70280 | v_loss: 1.26618 v_acc: 0.70573 |  iteration: 13024 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 594 loss: 1.44378 acc: 0.69987 | v_loss: 1.43136 v_acc: 0.69792 |  iteration: 13025 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 595 loss: 1.44533 acc: 0.70378 | v_loss: 1.43422 v_acc: 0.71224 |  iteration: 13026 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 596 loss: 1.35198 acc: 0.71289 | v_loss: 1.30680 v_acc: 0.71615 |  iteration: 13027 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 597 loss: 1.37102 acc: 0.70801 | v_loss: 1.25831 v_acc: 0.72591 |  iteration: 13028 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 598 loss: 1.40294 acc: 0.70573 | v_loss: 1.37466 v_acc: 0.71647 |  iteration: 13029 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 599 loss: 1.35608 acc: 0.71322 | v_loss: 1.42783 v_acc: 0.70052 |  iteration: 13030 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 600 loss: 1.48747 acc: 0.70085 | v_loss: 1.42608 v_acc: 0.70312 |  iteration: 13031 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 601 loss: 1.42010 acc: 0.70475 | v_loss: 1.22376 v_acc: 0.71712 |  iteration: 13032 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 602 loss: 1.42580 acc: 0.70020 | v_loss: 1.39077 v_acc: 0.72786 |  iteration: 13033 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 603 loss: 1.45156 acc: 0.70182 | v_loss: 1.48260 v_acc: 0.69792 |  iteration: 13034 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 604 loss: 1.42919 acc: 0.70280 | v_loss: 1.44462 v_acc: 0.72070 |  iteration: 13035 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 605 loss: 1.53626 acc: 0.69336 | v_loss: 1.25256 v_acc: 0.72201 |  iteration: 13036 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 606 loss: 1.56044 acc: 0.69596 | v_loss: 1.20583 v_acc: 0.73438 |  iteration: 13037 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 607 loss: 1.52163 acc: 0.69596 | v_loss: 1.21164 v_acc: 0.72656 |  iteration: 13038 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 608 loss: 1.45231 acc: 0.70117 | v_loss: 1.27904 v_acc: 0.70768 |  iteration: 13039 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 609 loss: 1.39813 acc: 0.71745 | v_loss: 1.45586 v_acc: 0.69596 |  iteration: 13040 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 610 loss: 1.35994 acc: 0.70931 | v_loss: 1.28635 v_acc: 0.71322 |  iteration: 13041 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 611 loss: 1.41455 acc: 0.69922 | v_loss: 1.44777 v_acc: 0.72624 |  iteration: 13042 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 612 loss: 1.47873 acc: 0.70182 | v_loss: 1.65084 v_acc: 0.69531 |  iteration: 13043 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 613 loss: 1.47049 acc: 0.69629 | v_loss: 1.51376 v_acc: 0.70117 |  iteration: 13044 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 614 loss: 1.46254 acc: 0.69824 | v_loss: 1.29850 v_acc: 0.72363 |  iteration: 13045 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 615 loss: 1.41162 acc: 0.70182 | v_loss: 1.36411 v_acc: 0.70410 |  iteration: 13046 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 616 loss: 1.40645 acc: 0.70150 | v_loss: 1.22049 v_acc: 0.71973 |  iteration: 13047 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 617 loss: 1.55520 acc: 0.69206 | v_loss: 1.41106 v_acc: 0.70150 |  iteration: 13048 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 618 loss: 1.44485 acc: 0.70410 | v_loss: 1.36123 v_acc: 0.71029 |  iteration: 13049 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 619 loss: 1.45603 acc: 0.69857 | v_loss: 1.35181 v_acc: 0.73079 |  iteration: 13050 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 620 loss: 1.49600 acc: 0.70475 | v_loss: 1.36984 v_acc: 0.71777 |  iteration: 13051 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 621 loss: 1.34440 acc: 0.70801 | v_loss: 1.38289 v_acc: 0.70345 |  iteration: 13052 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 622 loss: 1.49832 acc: 0.69857 | v_loss: 1.28635 v_acc: 0.72201 |  iteration: 13053 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 623 loss: 1.46237 acc: 0.70996 | v_loss: 1.31169 v_acc: 0.72005 |  iteration: 13054 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 624 loss: 1.53137 acc: 0.69401 | v_loss: 1.45905 v_acc: 0.69043 |  iteration: 13055 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 625 loss: 1.50288 acc: 0.69759 | v_loss: 1.34542 v_acc: 0.70833 |  iteration: 13056 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 626 loss: 1.57535 acc: 0.68978 | v_loss: 1.28007 v_acc: 0.71582 |  iteration: 13057 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 627 loss: 1.42301 acc: 0.70443 | v_loss: 1.27931 v_acc: 0.72201 |  iteration: 13058 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 628 loss: 1.44248 acc: 0.69661 | v_loss: 1.42056 v_acc: 0.70768 |  iteration: 13059 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 629 loss: 1.40302 acc: 0.71257 | v_loss: 1.31070 v_acc: 0.73177 |  iteration: 13060 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 630 loss: 1.36195 acc: 0.70247 | v_loss: 1.54086 v_acc: 0.71615 |  iteration: 13061 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 631 loss: 1.33497 acc: 0.71810 | v_loss: 1.27728 v_acc: 0.69759 |  iteration: 13062 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 632 loss: 1.43639 acc: 0.69727 | v_loss: 1.27929 v_acc: 0.70443 |  iteration: 13063 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 633 loss: 1.46328 acc: 0.69076 | v_loss: 1.45062 v_acc: 0.70312 |  iteration: 13064 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 634 loss: 1.51812 acc: 0.69824 | v_loss: 1.48459 v_acc: 0.70378 |  iteration: 13065 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 635 loss: 1.46176 acc: 0.69922 | v_loss: 1.53165 v_acc: 0.68978 |  iteration: 13066 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 636 loss: 1.53459 acc: 0.69010 | v_loss: 1.47542 v_acc: 0.70638 |  iteration: 13067 teacher: 0 stage: sketch lr: 0.000387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 637 loss: 1.39501 acc: 0.70378 | v_loss: 1.42981 v_acc: 0.70410 |  iteration: 13068 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 638 loss: 1.39075 acc: 0.70736 | v_loss: 1.41027 v_acc: 0.70768 |  iteration: 13069 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 639 loss: 1.41083 acc: 0.70540 | v_loss: 1.40744 v_acc: 0.70703 |  iteration: 13070 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 640 loss: 1.46164 acc: 0.71354 | v_loss: 1.26318 v_acc: 0.71419 |  iteration: 13071 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 641 loss: 1.50955 acc: 0.69824 | v_loss: 1.32154 v_acc: 0.72461 |  iteration: 13072 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 642 loss: 1.43700 acc: 0.70638 | v_loss: 1.18574 v_acc: 0.71517 |  iteration: 13073 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 643 loss: 1.46524 acc: 0.70508 | v_loss: 1.34400 v_acc: 0.70703 |  iteration: 13074 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 644 loss: 1.46098 acc: 0.69857 | v_loss: 1.49835 v_acc: 0.69987 |  iteration: 13075 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 645 loss: 1.42303 acc: 0.70931 | v_loss: 1.33737 v_acc: 0.70540 |  iteration: 13076 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 646 loss: 1.32960 acc: 0.71615 | v_loss: 1.35656 v_acc: 0.69368 |  iteration: 13077 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 647 loss: 1.42942 acc: 0.70052 | v_loss: 1.26072 v_acc: 0.70671 |  iteration: 13078 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 648 loss: 1.49824 acc: 0.69368 | v_loss: 1.25174 v_acc: 0.70410 |  iteration: 13079 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 649 loss: 1.45708 acc: 0.70345 | v_loss: 1.23533 v_acc: 0.73926 |  iteration: 13080 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 650 loss: 1.39992 acc: 0.70508 | v_loss: 1.27073 v_acc: 0.71908 |  iteration: 13081 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 651 loss: 1.43254 acc: 0.70247 | v_loss: 1.34289 v_acc: 0.73112 |  iteration: 13082 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 652 loss: 1.50972 acc: 0.69043 | v_loss: 1.25894 v_acc: 0.71940 |  iteration: 13083 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 653 loss: 1.39802 acc: 0.71419 | v_loss: 1.30158 v_acc: 0.72396 |  iteration: 13084 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 654 loss: 1.52034 acc: 0.69043 | v_loss: 1.41096 v_acc: 0.71354 |  iteration: 13085 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 655 loss: 1.41675 acc: 0.70020 | v_loss: 1.40291 v_acc: 0.72428 |  iteration: 13086 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 656 loss: 1.40142 acc: 0.69987 | v_loss: 1.49405 v_acc: 0.70182 |  iteration: 13087 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 657 loss: 1.44494 acc: 0.70312 | v_loss: 1.43766 v_acc: 0.71777 |  iteration: 13088 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 658 loss: 1.39988 acc: 0.70182 | v_loss: 1.17761 v_acc: 0.74447 |  iteration: 13089 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 659 loss: 1.32465 acc: 0.71159 | v_loss: 1.25083 v_acc: 0.71322 |  iteration: 13090 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 660 loss: 1.41509 acc: 0.70085 | v_loss: 1.53427 v_acc: 0.69987 |  iteration: 13091 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 661 loss: 1.40313 acc: 0.71094 | v_loss: 1.20836 v_acc: 0.70866 |  iteration: 13092 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 662 loss: 1.37542 acc: 0.71061 | v_loss: 1.32426 v_acc: 0.71159 |  iteration: 13093 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 663 loss: 1.30699 acc: 0.70280 | v_loss: 1.36353 v_acc: 0.69336 |  iteration: 13094 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 664 loss: 1.40268 acc: 0.69889 | v_loss: 1.29258 v_acc: 0.71191 |  iteration: 13095 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 665 loss: 1.45581 acc: 0.70573 | v_loss: 1.35974 v_acc: 0.69206 |  iteration: 13096 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 666 loss: 1.31915 acc: 0.70638 | v_loss: 1.47832 v_acc: 0.70931 |  iteration: 13097 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 667 loss: 1.53653 acc: 0.69954 | v_loss: 1.31904 v_acc: 0.72363 |  iteration: 13098 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 668 loss: 1.42282 acc: 0.71159 | v_loss: 1.45447 v_acc: 0.70117 |  iteration: 13099 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 669 loss: 1.42155 acc: 0.70117 | v_loss: 1.35821 v_acc: 0.70085 |  iteration: 13100 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 670 loss: 1.48944 acc: 0.70215 | v_loss: 1.32577 v_acc: 0.70703 |  iteration: 13101 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 671 loss: 1.31334 acc: 0.71191 | v_loss: 1.54456 v_acc: 0.68880 |  iteration: 13102 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 672 loss: 1.46255 acc: 0.70247 | v_loss: 1.29915 v_acc: 0.72103 |  iteration: 13103 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 673 loss: 1.43799 acc: 0.69792 | v_loss: 1.58657 v_acc: 0.68424 |  iteration: 13104 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 674 loss: 1.53148 acc: 0.69889 | v_loss: 1.46125 v_acc: 0.69792 |  iteration: 13105 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 675 loss: 1.42127 acc: 0.69596 | v_loss: 1.52352 v_acc: 0.69173 |  iteration: 13106 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 676 loss: 1.45830 acc: 0.69987 | v_loss: 1.38587 v_acc: 0.70020 |  iteration: 13107 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 677 loss: 1.34595 acc: 0.71419 | v_loss: 1.32113 v_acc: 0.70312 |  iteration: 13108 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 678 loss: 1.54712 acc: 0.69010 | v_loss: 1.33595 v_acc: 0.69889 |  iteration: 13109 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 679 loss: 1.39718 acc: 0.69303 | v_loss: 1.33165 v_acc: 0.71419 |  iteration: 13110 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 680 loss: 1.37509 acc: 0.70475 | v_loss: 1.53280 v_acc: 0.69173 |  iteration: 13111 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 681 loss: 1.57311 acc: 0.68880 | v_loss: 1.37647 v_acc: 0.69922 |  iteration: 13112 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 682 loss: 1.53471 acc: 0.69206 | v_loss: 1.35172 v_acc: 0.71322 |  iteration: 13113 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 683 loss: 1.38339 acc: 0.70345 | v_loss: 1.38212 v_acc: 0.71777 |  iteration: 13114 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 684 loss: 1.39811 acc: 0.70215 | v_loss: 1.27524 v_acc: 0.70215 |  iteration: 13115 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 685 loss: 1.45693 acc: 0.69922 | v_loss: 1.42677 v_acc: 0.69434 |  iteration: 13116 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 686 loss: 1.45921 acc: 0.71094 | v_loss: 1.42427 v_acc: 0.71452 |  iteration: 13117 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 687 loss: 1.43526 acc: 0.70345 | v_loss: 1.29082 v_acc: 0.71875 |  iteration: 13118 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 688 loss: 1.30094 acc: 0.70703 | v_loss: 1.25458 v_acc: 0.72754 |  iteration: 13119 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 689 loss: 1.37378 acc: 0.69987 | v_loss: 1.37957 v_acc: 0.71940 |  iteration: 13120 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 690 loss: 1.37847 acc: 0.71061 | v_loss: 1.42943 v_acc: 0.70345 |  iteration: 13121 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 691 loss: 1.45963 acc: 0.70703 | v_loss: 1.44021 v_acc: 0.70833 |  iteration: 13122 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 692 loss: 1.24918 acc: 0.72038 | v_loss: 1.23118 v_acc: 0.72591 |  iteration: 13123 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 693 loss: 1.47861 acc: 0.69857 | v_loss: 1.40820 v_acc: 0.73112 |  iteration: 13124 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 694 loss: 1.44291 acc: 0.70573 | v_loss: 1.48345 v_acc: 0.69759 |  iteration: 13125 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 695 loss: 1.48126 acc: 0.70475 | v_loss: 1.42168 v_acc: 0.72201 |  iteration: 13126 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 696 loss: 1.41827 acc: 0.70378 | v_loss: 1.25035 v_acc: 0.72103 |  iteration: 13127 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 697 loss: 1.39197 acc: 0.70378 | v_loss: 1.20191 v_acc: 0.74023 |  iteration: 13128 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 698 loss: 1.42922 acc: 0.70020 | v_loss: 1.21323 v_acc: 0.72559 |  iteration: 13129 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 699 loss: 1.66435 acc: 0.68945 | v_loss: 1.28183 v_acc: 0.70703 |  iteration: 13130 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 700 loss: 1.53056 acc: 0.69271 | v_loss: 1.44623 v_acc: 0.69466 |  iteration: 13131 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 701 loss: 1.39431 acc: 0.71257 | v_loss: 1.27740 v_acc: 0.71484 |  iteration: 13132 teacher: 0 stage: sketch lr: 0.000386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 702 loss: 1.42085 acc: 0.69629 | v_loss: 1.43882 v_acc: 0.72949 |  iteration: 13133 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 703 loss: 1.40078 acc: 0.71061 | v_loss: 1.63931 v_acc: 0.69466 |  iteration: 13134 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 704 loss: 1.41644 acc: 0.70931 | v_loss: 1.51389 v_acc: 0.70378 |  iteration: 13135 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 705 loss: 1.34889 acc: 0.71191 | v_loss: 1.29461 v_acc: 0.72103 |  iteration: 13136 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 706 loss: 1.44140 acc: 0.69857 | v_loss: 1.37649 v_acc: 0.70410 |  iteration: 13137 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 707 loss: 1.36899 acc: 0.71159 | v_loss: 1.22067 v_acc: 0.71973 |  iteration: 13138 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 708 loss: 1.40166 acc: 0.70378 | v_loss: 1.42095 v_acc: 0.70312 |  iteration: 13139 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 709 loss: 1.38852 acc: 0.70345 | v_loss: 1.35351 v_acc: 0.71810 |  iteration: 13140 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 710 loss: 1.40274 acc: 0.69954 | v_loss: 1.35863 v_acc: 0.72982 |  iteration: 13141 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 711 loss: 1.42860 acc: 0.70508 | v_loss: 1.38062 v_acc: 0.71842 |  iteration: 13142 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 712 loss: 1.34899 acc: 0.71419 | v_loss: 1.37291 v_acc: 0.71452 |  iteration: 13143 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 713 loss: 1.64480 acc: 0.68848 | v_loss: 1.28660 v_acc: 0.72493 |  iteration: 13144 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 714 loss: 1.43238 acc: 0.70280 | v_loss: 1.30199 v_acc: 0.72038 |  iteration: 13145 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 715 loss: 1.57683 acc: 0.68913 | v_loss: 1.50580 v_acc: 0.69368 |  iteration: 13146 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 716 loss: 1.36890 acc: 0.70996 | v_loss: 1.33078 v_acc: 0.71159 |  iteration: 13147 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 717 loss: 1.47707 acc: 0.70247 | v_loss: 1.30215 v_acc: 0.71549 |  iteration: 13148 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 718 loss: 1.41957 acc: 0.70410 | v_loss: 1.29786 v_acc: 0.72201 |  iteration: 13149 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 719 loss: 1.33388 acc: 0.71647 | v_loss: 1.43460 v_acc: 0.70703 |  iteration: 13150 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 720 loss: 1.44911 acc: 0.70150 | v_loss: 1.30740 v_acc: 0.73145 |  iteration: 13151 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 721 loss: 1.34778 acc: 0.71289 | v_loss: 1.53110 v_acc: 0.71647 |  iteration: 13152 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 722 loss: 1.49623 acc: 0.69368 | v_loss: 1.28761 v_acc: 0.69759 |  iteration: 13153 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 723 loss: 1.49630 acc: 0.69661 | v_loss: 1.27953 v_acc: 0.70703 |  iteration: 13154 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 724 loss: 1.49881 acc: 0.69499 | v_loss: 1.43885 v_acc: 0.70475 |  iteration: 13155 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 725 loss: 1.43348 acc: 0.70247 | v_loss: 1.46996 v_acc: 0.70378 |  iteration: 13156 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 726 loss: 1.48838 acc: 0.69336 | v_loss: 1.51897 v_acc: 0.68978 |  iteration: 13157 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 727 loss: 1.48078 acc: 0.70312 | v_loss: 1.47036 v_acc: 0.70833 |  iteration: 13158 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 728 loss: 1.51904 acc: 0.69271 | v_loss: 1.42382 v_acc: 0.70085 |  iteration: 13159 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 729 loss: 1.44182 acc: 0.70410 | v_loss: 1.41526 v_acc: 0.70931 |  iteration: 13160 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 730 loss: 1.47317 acc: 0.69596 | v_loss: 1.40708 v_acc: 0.70703 |  iteration: 13161 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 731 loss: 1.40494 acc: 0.70638 | v_loss: 1.25957 v_acc: 0.71875 |  iteration: 13162 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 732 loss: 1.46495 acc: 0.69564 | v_loss: 1.32220 v_acc: 0.72331 |  iteration: 13163 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 733 loss: 1.46241 acc: 0.70378 | v_loss: 1.18652 v_acc: 0.71582 |  iteration: 13164 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 734 loss: 1.38585 acc: 0.70280 | v_loss: 1.34307 v_acc: 0.70703 |  iteration: 13165 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 735 loss: 1.46694 acc: 0.70150 | v_loss: 1.49418 v_acc: 0.69987 |  iteration: 13166 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 736 loss: 1.49384 acc: 0.69727 | v_loss: 1.32442 v_acc: 0.70703 |  iteration: 13167 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 737 loss: 1.43260 acc: 0.70410 | v_loss: 1.35698 v_acc: 0.69759 |  iteration: 13168 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 738 loss: 1.50547 acc: 0.69531 | v_loss: 1.24676 v_acc: 0.71061 |  iteration: 13169 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 739 loss: 1.44665 acc: 0.70573 | v_loss: 1.25342 v_acc: 0.70215 |  iteration: 13170 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 740 loss: 1.41230 acc: 0.70703 | v_loss: 1.23864 v_acc: 0.73665 |  iteration: 13171 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 741 loss: 1.41321 acc: 0.70378 | v_loss: 1.27854 v_acc: 0.71712 |  iteration: 13172 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 742 loss: 1.50478 acc: 0.70215 | v_loss: 1.33725 v_acc: 0.73633 |  iteration: 13173 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 743 loss: 1.48952 acc: 0.70020 | v_loss: 1.25761 v_acc: 0.72298 |  iteration: 13174 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 744 loss: 1.33024 acc: 0.70931 | v_loss: 1.29834 v_acc: 0.71680 |  iteration: 13175 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 745 loss: 1.36186 acc: 0.70345 | v_loss: 1.40618 v_acc: 0.71224 |  iteration: 13176 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 746 loss: 1.46315 acc: 0.69564 | v_loss: 1.37752 v_acc: 0.72038 |  iteration: 13177 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 747 loss: 1.37545 acc: 0.70736 | v_loss: 1.48687 v_acc: 0.69661 |  iteration: 13178 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 748 loss: 1.45873 acc: 0.70703 | v_loss: 1.40881 v_acc: 0.71745 |  iteration: 13179 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 749 loss: 1.50580 acc: 0.69954 | v_loss: 1.17330 v_acc: 0.74382 |  iteration: 13180 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 750 loss: 1.58356 acc: 0.69661 | v_loss: 1.25482 v_acc: 0.70280 |  iteration: 13181 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 751 loss: 1.47577 acc: 0.69694 | v_loss: 1.51154 v_acc: 0.70280 |  iteration: 13182 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 752 loss: 1.40658 acc: 0.71126 | v_loss: 1.22704 v_acc: 0.71647 |  iteration: 13183 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 753 loss: 1.36753 acc: 0.70312 | v_loss: 1.33086 v_acc: 0.71191 |  iteration: 13184 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 754 loss: 1.50736 acc: 0.69531 | v_loss: 1.36812 v_acc: 0.69076 |  iteration: 13185 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 755 loss: 1.30407 acc: 0.71322 | v_loss: 1.29931 v_acc: 0.71061 |  iteration: 13186 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 756 loss: 1.45765 acc: 0.70182 | v_loss: 1.36637 v_acc: 0.69596 |  iteration: 13187 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 757 loss: 1.45708 acc: 0.70605 | v_loss: 1.46849 v_acc: 0.71517 |  iteration: 13188 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 758 loss: 1.38316 acc: 0.70833 | v_loss: 1.31261 v_acc: 0.72689 |  iteration: 13189 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 759 loss: 1.38333 acc: 0.70410 | v_loss: 1.44680 v_acc: 0.70443 |  iteration: 13190 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 760 loss: 1.32554 acc: 0.71029 | v_loss: 1.35768 v_acc: 0.69922 |  iteration: 13191 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 761 loss: 1.49903 acc: 0.69596 | v_loss: 1.33530 v_acc: 0.70898 |  iteration: 13192 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 762 loss: 1.42517 acc: 0.70475 | v_loss: 1.54382 v_acc: 0.68815 |  iteration: 13193 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 763 loss: 1.34760 acc: 0.70768 | v_loss: 1.30664 v_acc: 0.72005 |  iteration: 13194 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 764 loss: 1.42728 acc: 0.70671 | v_loss: 1.60017 v_acc: 0.67969 |  iteration: 13195 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 765 loss: 1.37669 acc: 0.71191 | v_loss: 1.46800 v_acc: 0.69661 |  iteration: 13196 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 766 loss: 1.43331 acc: 0.69629 | v_loss: 1.53811 v_acc: 0.69238 |  iteration: 13197 teacher: 1 stage: sketch lr: 0.000385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 767 loss: 1.49485 acc: 0.69987 | v_loss: 1.37532 v_acc: 0.70085 |  iteration: 13198 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 768 loss: 1.53066 acc: 0.69694 | v_loss: 1.31917 v_acc: 0.70312 |  iteration: 13199 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 769 loss: 1.46457 acc: 0.69271 | v_loss: 1.33062 v_acc: 0.70020 |  iteration: 13200 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 770 loss: 1.49316 acc: 0.70540 | v_loss: 1.32745 v_acc: 0.71484 |  iteration: 13201 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 771 loss: 1.39469 acc: 0.70345 | v_loss: 1.54012 v_acc: 0.68978 |  iteration: 13202 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 772 loss: 1.40228 acc: 0.70573 | v_loss: 1.38563 v_acc: 0.70443 |  iteration: 13203 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 773 loss: 1.39735 acc: 0.69792 | v_loss: 1.33755 v_acc: 0.71029 |  iteration: 13204 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 774 loss: 1.46777 acc: 0.69401 | v_loss: 1.38317 v_acc: 0.71680 |  iteration: 13205 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 775 loss: 1.45427 acc: 0.70312 | v_loss: 1.26751 v_acc: 0.70573 |  iteration: 13206 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 776 loss: 1.36768 acc: 0.71842 | v_loss: 1.42959 v_acc: 0.69792 |  iteration: 13207 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 777 loss: 1.40209 acc: 0.69954 | v_loss: 1.43158 v_acc: 0.71452 |  iteration: 13208 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 778 loss: 1.45948 acc: 0.69792 | v_loss: 1.30397 v_acc: 0.71647 |  iteration: 13209 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 779 loss: 1.41222 acc: 0.70573 | v_loss: 1.27350 v_acc: 0.72591 |  iteration: 13210 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 780 loss: 1.54657 acc: 0.70085 | v_loss: 1.38901 v_acc: 0.71517 |  iteration: 13211 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 781 loss: 1.37862 acc: 0.69889 | v_loss: 1.44226 v_acc: 0.70085 |  iteration: 13212 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 782 loss: 1.44824 acc: 0.70150 | v_loss: 1.43789 v_acc: 0.70280 |  iteration: 13213 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 783 loss: 1.48211 acc: 0.69857 | v_loss: 1.24105 v_acc: 0.71419 |  iteration: 13214 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 784 loss: 1.47700 acc: 0.69466 | v_loss: 1.38593 v_acc: 0.72819 |  iteration: 13215 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 785 loss: 1.42054 acc: 0.70378 | v_loss: 1.46230 v_acc: 0.69889 |  iteration: 13216 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 786 loss: 1.50728 acc: 0.69694 | v_loss: 1.41096 v_acc: 0.72233 |  iteration: 13217 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 787 loss: 1.40915 acc: 0.70247 | v_loss: 1.26281 v_acc: 0.71810 |  iteration: 13218 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 788 loss: 1.45280 acc: 0.70671 | v_loss: 1.21131 v_acc: 0.73633 |  iteration: 13219 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 789 loss: 1.44805 acc: 0.69857 | v_loss: 1.21273 v_acc: 0.72656 |  iteration: 13220 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 790 loss: 1.46526 acc: 0.70378 | v_loss: 1.29635 v_acc: 0.70768 |  iteration: 13221 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 791 loss: 1.50847 acc: 0.69954 | v_loss: 1.44639 v_acc: 0.69596 |  iteration: 13222 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 792 loss: 1.42078 acc: 0.71126 | v_loss: 1.27899 v_acc: 0.71289 |  iteration: 13223 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 793 loss: 1.38446 acc: 0.70964 | v_loss: 1.43208 v_acc: 0.72819 |  iteration: 13224 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 794 loss: 1.49568 acc: 0.70312 | v_loss: 1.65754 v_acc: 0.69499 |  iteration: 13225 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 795 loss: 1.34237 acc: 0.70833 | v_loss: 1.52403 v_acc: 0.70085 |  iteration: 13226 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 796 loss: 1.39908 acc: 0.70443 | v_loss: 1.29669 v_acc: 0.72331 |  iteration: 13227 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 797 loss: 1.48788 acc: 0.69661 | v_loss: 1.38677 v_acc: 0.70052 |  iteration: 13228 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 798 loss: 1.39698 acc: 0.70443 | v_loss: 1.22571 v_acc: 0.72070 |  iteration: 13229 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 799 loss: 1.50188 acc: 0.69173 | v_loss: 1.43464 v_acc: 0.70150 |  iteration: 13230 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 800 loss: 1.47354 acc: 0.70020 | v_loss: 1.35811 v_acc: 0.71029 |  iteration: 13231 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 801 loss: 1.45513 acc: 0.69336 | v_loss: 1.35495 v_acc: 0.73014 |  iteration: 13232 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 802 loss: 1.40224 acc: 0.70410 | v_loss: 1.35567 v_acc: 0.72005 |  iteration: 13233 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 803 loss: 1.44038 acc: 0.69564 | v_loss: 1.36922 v_acc: 0.71061 |  iteration: 13234 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 804 loss: 1.56828 acc: 0.69076 | v_loss: 1.29453 v_acc: 0.72233 |  iteration: 13235 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 805 loss: 1.42257 acc: 0.70964 | v_loss: 1.29974 v_acc: 0.72038 |  iteration: 13236 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 806 loss: 1.45900 acc: 0.69466 | v_loss: 1.50768 v_acc: 0.69173 |  iteration: 13237 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 807 loss: 1.36856 acc: 0.70215 | v_loss: 1.32775 v_acc: 0.71126 |  iteration: 13238 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 808 loss: 1.46470 acc: 0.70801 | v_loss: 1.28910 v_acc: 0.71615 |  iteration: 13239 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 809 loss: 1.39626 acc: 0.70866 | v_loss: 1.27833 v_acc: 0.72201 |  iteration: 13240 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 810 loss: 1.41540 acc: 0.70736 | v_loss: 1.42314 v_acc: 0.70768 |  iteration: 13241 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 811 loss: 1.50329 acc: 0.70410 | v_loss: 1.32036 v_acc: 0.73210 |  iteration: 13242 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 812 loss: 1.43074 acc: 0.70410 | v_loss: 1.54587 v_acc: 0.71322 |  iteration: 13243 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 813 loss: 1.52323 acc: 0.69857 | v_loss: 1.29770 v_acc: 0.69531 |  iteration: 13244 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 814 loss: 1.44974 acc: 0.69889 | v_loss: 1.28773 v_acc: 0.70117 |  iteration: 13245 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 815 loss: 1.39361 acc: 0.70573 | v_loss: 1.44678 v_acc: 0.70508 |  iteration: 13246 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 816 loss: 1.47606 acc: 0.69922 | v_loss: 1.47683 v_acc: 0.70573 |  iteration: 13247 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 817 loss: 1.40555 acc: 0.70638 | v_loss: 1.52392 v_acc: 0.68978 |  iteration: 13248 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 818 loss: 1.38692 acc: 0.70540 | v_loss: 1.46171 v_acc: 0.70540 |  iteration: 13249 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 819 loss: 1.45409 acc: 0.69824 | v_loss: 1.42018 v_acc: 0.70540 |  iteration: 13250 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 820 loss: 1.40068 acc: 0.70671 | v_loss: 1.40814 v_acc: 0.70540 |  iteration: 13251 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 821 loss: 1.38160 acc: 0.70736 | v_loss: 1.40377 v_acc: 0.70443 |  iteration: 13252 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 822 loss: 1.42357 acc: 0.69368 | v_loss: 1.27085 v_acc: 0.71126 |  iteration: 13253 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 823 loss: 1.46056 acc: 0.70312 | v_loss: 1.31895 v_acc: 0.72461 |  iteration: 13254 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 824 loss: 1.48576 acc: 0.69466 | v_loss: 1.19197 v_acc: 0.71517 |  iteration: 13255 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 825 loss: 1.35690 acc: 0.71680 | v_loss: 1.34066 v_acc: 0.70703 |  iteration: 13256 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 826 loss: 1.30887 acc: 0.72005 | v_loss: 1.50638 v_acc: 0.70020 |  iteration: 13257 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 827 loss: 1.46663 acc: 0.69922 | v_loss: 1.35005 v_acc: 0.70833 |  iteration: 13258 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 828 loss: 1.44540 acc: 0.70540 | v_loss: 1.35072 v_acc: 0.69759 |  iteration: 13259 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 829 loss: 1.41718 acc: 0.70378 | v_loss: 1.25596 v_acc: 0.71126 |  iteration: 13260 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 830 loss: 1.45285 acc: 0.69694 | v_loss: 1.23800 v_acc: 0.70378 |  iteration: 13261 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 831 loss: 1.51901 acc: 0.68978 | v_loss: 1.24131 v_acc: 0.73503 |  iteration: 13262 teacher: 0 stage: sketch lr: 0.000384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 832 loss: 1.42265 acc: 0.70703 | v_loss: 1.27342 v_acc: 0.72168 |  iteration: 13263 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 833 loss: 1.39159 acc: 0.70540 | v_loss: 1.33486 v_acc: 0.73145 |  iteration: 13264 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 834 loss: 1.47374 acc: 0.70573 | v_loss: 1.25937 v_acc: 0.71973 |  iteration: 13265 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 835 loss: 1.57956 acc: 0.69141 | v_loss: 1.29805 v_acc: 0.71582 |  iteration: 13266 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 836 loss: 1.47318 acc: 0.69759 | v_loss: 1.40946 v_acc: 0.71322 |  iteration: 13267 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 837 loss: 1.37185 acc: 0.70052 | v_loss: 1.37619 v_acc: 0.72103 |  iteration: 13268 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 838 loss: 1.26621 acc: 0.71322 | v_loss: 1.48006 v_acc: 0.69922 |  iteration: 13269 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 839 loss: 1.36473 acc: 0.70964 | v_loss: 1.41833 v_acc: 0.71908 |  iteration: 13270 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 840 loss: 1.37307 acc: 0.70508 | v_loss: 1.18134 v_acc: 0.74219 |  iteration: 13271 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 841 loss: 1.43610 acc: 0.69824 | v_loss: 1.25326 v_acc: 0.70280 |  iteration: 13272 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 842 loss: 1.46144 acc: 0.70312 | v_loss: 1.53859 v_acc: 0.70247 |  iteration: 13273 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 843 loss: 1.33513 acc: 0.71224 | v_loss: 1.20983 v_acc: 0.70866 |  iteration: 13274 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 844 loss: 1.38118 acc: 0.70378 | v_loss: 1.33048 v_acc: 0.71257 |  iteration: 13275 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 845 loss: 1.44990 acc: 0.69759 | v_loss: 1.37982 v_acc: 0.69368 |  iteration: 13276 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 846 loss: 1.54873 acc: 0.69727 | v_loss: 1.28862 v_acc: 0.71842 |  iteration: 13277 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 847 loss: 1.46310 acc: 0.70768 | v_loss: 1.36475 v_acc: 0.70215 |  iteration: 13278 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 848 loss: 1.58290 acc: 0.69173 | v_loss: 1.47210 v_acc: 0.71940 |  iteration: 13279 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 849 loss: 1.41022 acc: 0.70475 | v_loss: 1.31966 v_acc: 0.72689 |  iteration: 13280 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 850 loss: 1.44009 acc: 0.70996 | v_loss: 1.43418 v_acc: 0.70117 |  iteration: 13281 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 851 loss: 1.44387 acc: 0.70833 | v_loss: 1.36410 v_acc: 0.70085 |  iteration: 13282 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 852 loss: 1.42185 acc: 0.69238 | v_loss: 1.33195 v_acc: 0.70703 |  iteration: 13283 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 853 loss: 1.47799 acc: 0.69889 | v_loss: 1.52752 v_acc: 0.69238 |  iteration: 13284 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 854 loss: 1.57618 acc: 0.68652 | v_loss: 1.30486 v_acc: 0.72233 |  iteration: 13285 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 855 loss: 1.35891 acc: 0.69564 | v_loss: 1.57005 v_acc: 0.69043 |  iteration: 13286 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 856 loss: 1.36602 acc: 0.71419 | v_loss: 1.42737 v_acc: 0.69987 |  iteration: 13287 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 857 loss: 1.44507 acc: 0.70345 | v_loss: 1.51477 v_acc: 0.68913 |  iteration: 13288 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 858 loss: 1.51415 acc: 0.69043 | v_loss: 1.37118 v_acc: 0.69759 |  iteration: 13289 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 859 loss: 1.46696 acc: 0.70182 | v_loss: 1.32911 v_acc: 0.70312 |  iteration: 13290 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 860 loss: 1.43433 acc: 0.70833 | v_loss: 1.33796 v_acc: 0.70020 |  iteration: 13291 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 861 loss: 1.42026 acc: 0.70671 | v_loss: 1.34901 v_acc: 0.71484 |  iteration: 13292 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 862 loss: 1.40153 acc: 0.69954 | v_loss: 1.53195 v_acc: 0.68978 |  iteration: 13293 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 863 loss: 1.46580 acc: 0.69987 | v_loss: 1.38909 v_acc: 0.70443 |  iteration: 13294 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 864 loss: 1.42008 acc: 0.70605 | v_loss: 1.33411 v_acc: 0.71029 |  iteration: 13295 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 865 loss: 1.46759 acc: 0.69694 | v_loss: 1.38557 v_acc: 0.71680 |  iteration: 13296 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 866 loss: 1.47430 acc: 0.69661 | v_loss: 1.26911 v_acc: 0.70573 |  iteration: 13297 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 867 loss: 1.45630 acc: 0.70182 | v_loss: 1.42941 v_acc: 0.69434 |  iteration: 13298 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 868 loss: 1.34724 acc: 0.71159 | v_loss: 1.42793 v_acc: 0.71452 |  iteration: 13299 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 869 loss: 1.40291 acc: 0.70378 | v_loss: 1.28999 v_acc: 0.71615 |  iteration: 13300 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 870 loss: 1.38857 acc: 0.70898 | v_loss: 1.26235 v_acc: 0.72526 |  iteration: 13301 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 871 loss: 1.45628 acc: 0.69434 | v_loss: 1.37908 v_acc: 0.71647 |  iteration: 13302 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 872 loss: 1.51763 acc: 0.69271 | v_loss: 1.41855 v_acc: 0.70052 |  iteration: 13303 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 873 loss: 1.48786 acc: 0.70085 | v_loss: 1.41995 v_acc: 0.70312 |  iteration: 13304 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 874 loss: 1.36005 acc: 0.71452 | v_loss: 1.22500 v_acc: 0.71452 |  iteration: 13305 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 875 loss: 1.41489 acc: 0.70475 | v_loss: 1.38009 v_acc: 0.72819 |  iteration: 13306 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 876 loss: 1.36200 acc: 0.70866 | v_loss: 1.47267 v_acc: 0.69759 |  iteration: 13307 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 877 loss: 1.33070 acc: 0.70638 | v_loss: 1.44321 v_acc: 0.72396 |  iteration: 13308 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 878 loss: 1.39171 acc: 0.70833 | v_loss: 1.24597 v_acc: 0.72005 |  iteration: 13309 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 879 loss: 1.41380 acc: 0.71387 | v_loss: 1.18947 v_acc: 0.74447 |  iteration: 13310 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 880 loss: 1.43646 acc: 0.69694 | v_loss: 1.20649 v_acc: 0.72493 |  iteration: 13311 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 881 loss: 1.46008 acc: 0.69141 | v_loss: 1.26781 v_acc: 0.71126 |  iteration: 13312 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 882 loss: 1.46192 acc: 0.69824 | v_loss: 1.45898 v_acc: 0.70671 |  iteration: 13313 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 883 loss: 1.45399 acc: 0.70898 | v_loss: 1.27551 v_acc: 0.71549 |  iteration: 13314 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 884 loss: 1.47317 acc: 0.70378 | v_loss: 1.44606 v_acc: 0.71647 |  iteration: 13315 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 885 loss: 1.41911 acc: 0.70150 | v_loss: 1.66804 v_acc: 0.69401 |  iteration: 13316 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 886 loss: 1.36384 acc: 0.72526 | v_loss: 1.51149 v_acc: 0.70410 |  iteration: 13317 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 887 loss: 1.39901 acc: 0.70768 | v_loss: 1.29473 v_acc: 0.72005 |  iteration: 13318 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 888 loss: 1.40877 acc: 0.70573 | v_loss: 1.37502 v_acc: 0.69987 |  iteration: 13319 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 889 loss: 1.44247 acc: 0.69076 | v_loss: 1.22402 v_acc: 0.71615 |  iteration: 13320 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 890 loss: 1.34996 acc: 0.70866 | v_loss: 1.42628 v_acc: 0.70085 |  iteration: 13321 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 891 loss: 1.47501 acc: 0.69466 | v_loss: 1.35862 v_acc: 0.71029 |  iteration: 13322 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 892 loss: 1.55112 acc: 0.69499 | v_loss: 1.35589 v_acc: 0.73079 |  iteration: 13323 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 893 loss: 1.52611 acc: 0.68490 | v_loss: 1.35426 v_acc: 0.71777 |  iteration: 13324 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 894 loss: 1.43575 acc: 0.70052 | v_loss: 1.37017 v_acc: 0.70410 |  iteration: 13325 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 895 loss: 1.39037 acc: 0.70345 | v_loss: 1.29101 v_acc: 0.72363 |  iteration: 13326 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 896 loss: 1.51666 acc: 0.69173 | v_loss: 1.30157 v_acc: 0.72201 |  iteration: 13327 teacher: 0 stage: sketch lr: 0.000383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 897 loss: 1.55415 acc: 0.68522 | v_loss: 1.50277 v_acc: 0.69206 |  iteration: 13328 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 898 loss: 1.47913 acc: 0.68848 | v_loss: 1.33102 v_acc: 0.71419 |  iteration: 13329 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 899 loss: 1.40404 acc: 0.70378 | v_loss: 1.28425 v_acc: 0.71777 |  iteration: 13330 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 900 loss: 1.33610 acc: 0.70378 | v_loss: 1.28230 v_acc: 0.71973 |  iteration: 13331 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 901 loss: 1.47345 acc: 0.69596 | v_loss: 1.42964 v_acc: 0.70573 |  iteration: 13332 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 902 loss: 1.53728 acc: 0.68750 | v_loss: 1.32104 v_acc: 0.72982 |  iteration: 13333 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 903 loss: 1.40279 acc: 0.70052 | v_loss: 1.54464 v_acc: 0.71322 |  iteration: 13334 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 904 loss: 1.55859 acc: 0.69401 | v_loss: 1.29061 v_acc: 0.69531 |  iteration: 13335 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 905 loss: 1.50170 acc: 0.70247 | v_loss: 1.29077 v_acc: 0.70117 |  iteration: 13336 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 906 loss: 1.32403 acc: 0.70898 | v_loss: 1.43509 v_acc: 0.70508 |  iteration: 13337 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 907 loss: 1.53882 acc: 0.69694 | v_loss: 1.46081 v_acc: 0.70573 |  iteration: 13338 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 908 loss: 1.46465 acc: 0.69727 | v_loss: 1.50822 v_acc: 0.68978 |  iteration: 13339 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 909 loss: 1.48953 acc: 0.69108 | v_loss: 1.46037 v_acc: 0.70540 |  iteration: 13340 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 910 loss: 1.47637 acc: 0.70117 | v_loss: 1.41634 v_acc: 0.70671 |  iteration: 13341 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 911 loss: 1.42030 acc: 0.71061 | v_loss: 1.40035 v_acc: 0.70703 |  iteration: 13342 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 912 loss: 1.37803 acc: 0.70866 | v_loss: 1.40314 v_acc: 0.70443 |  iteration: 13343 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 913 loss: 1.53232 acc: 0.69238 | v_loss: 1.26591 v_acc: 0.71159 |  iteration: 13344 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 914 loss: 1.45700 acc: 0.70898 | v_loss: 1.32822 v_acc: 0.72396 |  iteration: 13345 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 915 loss: 1.50784 acc: 0.70117 | v_loss: 1.19999 v_acc: 0.70638 |  iteration: 13346 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 916 loss: 1.62217 acc: 0.68490 | v_loss: 1.34201 v_acc: 0.70247 |  iteration: 13347 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 917 loss: 1.39859 acc: 0.71257 | v_loss: 1.49869 v_acc: 0.69987 |  iteration: 13348 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 918 loss: 1.38987 acc: 0.70247 | v_loss: 1.34339 v_acc: 0.70638 |  iteration: 13349 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 919 loss: 1.44611 acc: 0.69824 | v_loss: 1.35724 v_acc: 0.69727 |  iteration: 13350 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 920 loss: 1.37681 acc: 0.71061 | v_loss: 1.24879 v_acc: 0.71126 |  iteration: 13351 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 921 loss: 1.48754 acc: 0.70215 | v_loss: 1.25260 v_acc: 0.70345 |  iteration: 13352 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 922 loss: 1.42418 acc: 0.70475 | v_loss: 1.24129 v_acc: 0.73503 |  iteration: 13353 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 923 loss: 1.35260 acc: 0.70801 | v_loss: 1.26938 v_acc: 0.72168 |  iteration: 13354 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 924 loss: 1.41491 acc: 0.69824 | v_loss: 1.33789 v_acc: 0.73145 |  iteration: 13355 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 925 loss: 1.38784 acc: 0.70410 | v_loss: 1.26038 v_acc: 0.72461 |  iteration: 13356 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 926 loss: 1.46896 acc: 0.70508 | v_loss: 1.30695 v_acc: 0.72005 |  iteration: 13357 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 927 loss: 1.42115 acc: 0.70768 | v_loss: 1.41887 v_acc: 0.71224 |  iteration: 13358 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 928 loss: 1.45012 acc: 0.69987 | v_loss: 1.39067 v_acc: 0.72070 |  iteration: 13359 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 929 loss: 1.42020 acc: 0.70312 | v_loss: 1.48556 v_acc: 0.69987 |  iteration: 13360 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 930 loss: 1.44491 acc: 0.70508 | v_loss: 1.40752 v_acc: 0.71810 |  iteration: 13361 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 931 loss: 1.41740 acc: 0.70345 | v_loss: 1.17462 v_acc: 0.74479 |  iteration: 13362 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 932 loss: 1.54003 acc: 0.69466 | v_loss: 1.25755 v_acc: 0.70866 |  iteration: 13363 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 933 loss: 1.43151 acc: 0.69010 | v_loss: 1.51787 v_acc: 0.70247 |  iteration: 13364 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 934 loss: 1.52194 acc: 0.70085 | v_loss: 1.21417 v_acc: 0.70866 |  iteration: 13365 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 935 loss: 1.39225 acc: 0.71322 | v_loss: 1.32352 v_acc: 0.71094 |  iteration: 13366 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 936 loss: 1.38666 acc: 0.70247 | v_loss: 1.36390 v_acc: 0.69368 |  iteration: 13367 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 937 loss: 1.38691 acc: 0.70898 | v_loss: 1.28929 v_acc: 0.71842 |  iteration: 13368 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 938 loss: 1.42405 acc: 0.70801 | v_loss: 1.35745 v_acc: 0.70215 |  iteration: 13369 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 939 loss: 1.41518 acc: 0.70020 | v_loss: 1.47436 v_acc: 0.72005 |  iteration: 13370 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 940 loss: 1.43365 acc: 0.70052 | v_loss: 1.31891 v_acc: 0.72786 |  iteration: 13371 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 941 loss: 1.30264 acc: 0.71777 | v_loss: 1.45421 v_acc: 0.70443 |  iteration: 13372 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 942 loss: 1.37442 acc: 0.71126 | v_loss: 1.35587 v_acc: 0.69922 |  iteration: 13373 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 943 loss: 1.40921 acc: 0.69987 | v_loss: 1.33553 v_acc: 0.70898 |  iteration: 13374 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 944 loss: 1.45532 acc: 0.69759 | v_loss: 1.54401 v_acc: 0.68848 |  iteration: 13375 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 945 loss: 1.38953 acc: 0.70638 | v_loss: 1.31509 v_acc: 0.71810 |  iteration: 13376 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 946 loss: 1.42496 acc: 0.70215 | v_loss: 1.59333 v_acc: 0.68359 |  iteration: 13377 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 947 loss: 1.35976 acc: 0.70312 | v_loss: 1.43842 v_acc: 0.69694 |  iteration: 13378 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 948 loss: 1.44633 acc: 0.70117 | v_loss: 1.53822 v_acc: 0.68913 |  iteration: 13379 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 949 loss: 1.47103 acc: 0.69206 | v_loss: 1.37353 v_acc: 0.69792 |  iteration: 13380 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 950 loss: 1.44182 acc: 0.71126 | v_loss: 1.32182 v_acc: 0.70345 |  iteration: 13381 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 951 loss: 1.44716 acc: 0.69857 | v_loss: 1.33090 v_acc: 0.70052 |  iteration: 13382 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 952 loss: 1.39249 acc: 0.71257 | v_loss: 1.32919 v_acc: 0.71549 |  iteration: 13383 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 953 loss: 1.44990 acc: 0.70540 | v_loss: 1.54535 v_acc: 0.69043 |  iteration: 13384 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 954 loss: 1.57347 acc: 0.69336 | v_loss: 1.40026 v_acc: 0.70247 |  iteration: 13385 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 955 loss: 1.45937 acc: 0.69954 | v_loss: 1.34033 v_acc: 0.71126 |  iteration: 13386 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 956 loss: 1.40357 acc: 0.70117 | v_loss: 1.38620 v_acc: 0.71810 |  iteration: 13387 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 957 loss: 1.57666 acc: 0.69076 | v_loss: 1.27401 v_acc: 0.70215 |  iteration: 13388 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 958 loss: 1.45660 acc: 0.69759 | v_loss: 1.43218 v_acc: 0.69792 |  iteration: 13389 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 959 loss: 1.50768 acc: 0.69727 | v_loss: 1.42882 v_acc: 0.71289 |  iteration: 13390 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 960 loss: 1.52983 acc: 0.68913 | v_loss: 1.29079 v_acc: 0.71875 |  iteration: 13391 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 961 loss: 1.30523 acc: 0.70996 | v_loss: 1.27454 v_acc: 0.72754 |  iteration: 13392 teacher: 0 stage: sketch lr: 0.000382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 962 loss: 1.25410 acc: 0.71094 | v_loss: 1.39898 v_acc: 0.72266 |  iteration: 13393 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 963 loss: 1.44939 acc: 0.69792 | v_loss: 1.45126 v_acc: 0.70410 |  iteration: 13394 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 964 loss: 1.54026 acc: 0.69010 | v_loss: 1.45572 v_acc: 0.70736 |  iteration: 13395 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 965 loss: 1.40876 acc: 0.70150 | v_loss: 1.23267 v_acc: 0.71712 |  iteration: 13396 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 966 loss: 1.44944 acc: 0.70345 | v_loss: 1.41097 v_acc: 0.72786 |  iteration: 13397 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 967 loss: 1.38915 acc: 0.70866 | v_loss: 1.47831 v_acc: 0.69792 |  iteration: 13398 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 968 loss: 1.46274 acc: 0.69792 | v_loss: 1.40120 v_acc: 0.71842 |  iteration: 13399 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 969 loss: 1.47673 acc: 0.70117 | v_loss: 1.25444 v_acc: 0.71810 |  iteration: 13400 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 970 loss: 1.33931 acc: 0.71875 | v_loss: 1.21695 v_acc: 0.73535 |  iteration: 13401 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 971 loss: 1.34759 acc: 0.70410 | v_loss: 1.22124 v_acc: 0.72656 |  iteration: 13402 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 972 loss: 1.36736 acc: 0.71126 | v_loss: 1.29834 v_acc: 0.70703 |  iteration: 13403 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 973 loss: 1.34773 acc: 0.70671 | v_loss: 1.45930 v_acc: 0.69466 |  iteration: 13404 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 974 loss: 1.51345 acc: 0.68945 | v_loss: 1.28014 v_acc: 0.71549 |  iteration: 13405 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 975 loss: 1.49062 acc: 0.70508 | v_loss: 1.44804 v_acc: 0.72624 |  iteration: 13406 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 976 loss: 1.38183 acc: 0.70508 | v_loss: 1.67204 v_acc: 0.69368 |  iteration: 13407 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 977 loss: 1.46495 acc: 0.69596 | v_loss: 1.52658 v_acc: 0.69922 |  iteration: 13408 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 978 loss: 1.47866 acc: 0.69922 | v_loss: 1.29436 v_acc: 0.72233 |  iteration: 13409 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 979 loss: 1.39867 acc: 0.70150 | v_loss: 1.37129 v_acc: 0.70215 |  iteration: 13410 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 980 loss: 1.56742 acc: 0.69531 | v_loss: 1.22089 v_acc: 0.71973 |  iteration: 13411 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 981 loss: 1.47385 acc: 0.70280 | v_loss: 1.41509 v_acc: 0.70150 |  iteration: 13412 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 982 loss: 1.38895 acc: 0.69954 | v_loss: 1.35789 v_acc: 0.70964 |  iteration: 13413 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 983 loss: 1.37856 acc: 0.70638 | v_loss: 1.35191 v_acc: 0.73079 |  iteration: 13414 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 984 loss: 1.32853 acc: 0.71257 | v_loss: 1.36261 v_acc: 0.71777 |  iteration: 13415 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 985 loss: 1.44910 acc: 0.70247 | v_loss: 1.37693 v_acc: 0.70410 |  iteration: 13416 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 986 loss: 1.52099 acc: 0.69043 | v_loss: 1.28608 v_acc: 0.72233 |  iteration: 13417 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 987 loss: 1.44944 acc: 0.69922 | v_loss: 1.29940 v_acc: 0.72135 |  iteration: 13418 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 988 loss: 1.42834 acc: 0.70378 | v_loss: 1.49556 v_acc: 0.69303 |  iteration: 13419 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 989 loss: 1.32296 acc: 0.71908 | v_loss: 1.33172 v_acc: 0.71159 |  iteration: 13420 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 990 loss: 1.38881 acc: 0.70605 | v_loss: 1.29742 v_acc: 0.71549 |  iteration: 13421 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 991 loss: 1.44520 acc: 0.69368 | v_loss: 1.28462 v_acc: 0.71973 |  iteration: 13422 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 992 loss: 1.39888 acc: 0.70898 | v_loss: 1.42551 v_acc: 0.70573 |  iteration: 13423 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 993 loss: 1.41341 acc: 0.70573 | v_loss: 1.31258 v_acc: 0.73112 |  iteration: 13424 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 994 loss: 1.44961 acc: 0.70020 | v_loss: 1.55213 v_acc: 0.71452 |  iteration: 13425 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 995 loss: 1.44535 acc: 0.70703 | v_loss: 1.26722 v_acc: 0.69759 |  iteration: 13426 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 996 loss: 1.42192 acc: 0.70215 | v_loss: 1.26897 v_acc: 0.70475 |  iteration: 13427 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 997 loss: 1.48203 acc: 0.69401 | v_loss: 1.43906 v_acc: 0.70540 |  iteration: 13428 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 998 loss: 1.38668 acc: 0.70671 | v_loss: 1.47642 v_acc: 0.70312 |  iteration: 13429 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 999 loss: 1.41137 acc: 0.70671 | v_loss: 1.51624 v_acc: 0.69564 |  iteration: 13430 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1000 loss: 1.48191 acc: 0.69596 | v_loss: 1.47341 v_acc: 0.70964 |  iteration: 13431 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1001 loss: 1.36738 acc: 0.70703 | v_loss: 1.41187 v_acc: 0.70085 |  iteration: 13432 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1002 loss: 1.55323 acc: 0.69336 | v_loss: 1.39927 v_acc: 0.70931 |  iteration: 13433 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1003 loss: 1.41710 acc: 0.70312 | v_loss: 1.40207 v_acc: 0.70703 |  iteration: 13434 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1004 loss: 1.39328 acc: 0.69987 | v_loss: 1.26350 v_acc: 0.71875 |  iteration: 13435 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1005 loss: 1.42600 acc: 0.70964 | v_loss: 1.31997 v_acc: 0.72331 |  iteration: 13436 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1006 loss: 1.47670 acc: 0.69824 | v_loss: 1.17921 v_acc: 0.71517 |  iteration: 13437 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1007 loss: 1.38090 acc: 0.70443 | v_loss: 1.34726 v_acc: 0.70378 |  iteration: 13438 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1008 loss: 1.45078 acc: 0.70150 | v_loss: 1.49334 v_acc: 0.69987 |  iteration: 13439 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1009 loss: 1.38430 acc: 0.70833 | v_loss: 1.34177 v_acc: 0.70540 |  iteration: 13440 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1010 loss: 1.31984 acc: 0.71452 | v_loss: 1.35909 v_acc: 0.69368 |  iteration: 13441 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1011 loss: 1.36789 acc: 0.70638 | v_loss: 1.25476 v_acc: 0.70573 |  iteration: 13442 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1012 loss: 1.45146 acc: 0.69889 | v_loss: 1.24049 v_acc: 0.70215 |  iteration: 13443 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1013 loss: 1.47494 acc: 0.69987 | v_loss: 1.25519 v_acc: 0.73340 |  iteration: 13444 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1014 loss: 1.48038 acc: 0.70215 | v_loss: 1.27343 v_acc: 0.72168 |  iteration: 13445 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1015 loss: 1.43356 acc: 0.70833 | v_loss: 1.35439 v_acc: 0.73145 |  iteration: 13446 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1016 loss: 1.54894 acc: 0.69434 | v_loss: 1.26095 v_acc: 0.72461 |  iteration: 13447 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1017 loss: 1.45394 acc: 0.70085 | v_loss: 1.30157 v_acc: 0.72005 |  iteration: 13448 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1018 loss: 1.29922 acc: 0.71452 | v_loss: 1.41674 v_acc: 0.71224 |  iteration: 13449 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1019 loss: 1.43334 acc: 0.69694 | v_loss: 1.38876 v_acc: 0.72070 |  iteration: 13450 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1020 loss: 1.49818 acc: 0.70508 | v_loss: 1.48690 v_acc: 0.69954 |  iteration: 13451 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1021 loss: 1.56447 acc: 0.69336 | v_loss: 1.42591 v_acc: 0.71615 |  iteration: 13452 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1022 loss: 1.48453 acc: 0.69889 | v_loss: 1.18073 v_acc: 0.74447 |  iteration: 13453 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1023 loss: 1.38119 acc: 0.70866 | v_loss: 1.26607 v_acc: 0.71322 |  iteration: 13454 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1024 loss: 1.39844 acc: 0.69889 | v_loss: 1.51964 v_acc: 0.69987 |  iteration: 13455 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1025 loss: 1.41371 acc: 0.70638 | v_loss: 1.22684 v_acc: 0.70671 |  iteration: 13456 teacher: 0 stage: sketch lr: 0.000381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1026 loss: 1.36228 acc: 0.70833 | v_loss: 1.32671 v_acc: 0.71159 |  iteration: 13457 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1027 loss: 1.52943 acc: 0.69727 | v_loss: 1.35852 v_acc: 0.69336 |  iteration: 13458 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1028 loss: 1.49123 acc: 0.69076 | v_loss: 1.30255 v_acc: 0.71094 |  iteration: 13459 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1029 loss: 1.51296 acc: 0.69206 | v_loss: 1.36588 v_acc: 0.69661 |  iteration: 13460 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1030 loss: 1.51537 acc: 0.69792 | v_loss: 1.45920 v_acc: 0.71322 |  iteration: 13461 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1031 loss: 1.33441 acc: 0.70964 | v_loss: 1.31254 v_acc: 0.72396 |  iteration: 13462 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1032 loss: 1.50716 acc: 0.69596 | v_loss: 1.43672 v_acc: 0.70540 |  iteration: 13463 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1033 loss: 1.33387 acc: 0.71354 | v_loss: 1.35699 v_acc: 0.69954 |  iteration: 13464 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1034 loss: 1.36363 acc: 0.71582 | v_loss: 1.33005 v_acc: 0.70931 |  iteration: 13465 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1035 loss: 1.45467 acc: 0.69629 | v_loss: 1.54176 v_acc: 0.68815 |  iteration: 13466 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1036 loss: 1.36960 acc: 0.71257 | v_loss: 1.30210 v_acc: 0.72005 |  iteration: 13467 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1037 loss: 1.36275 acc: 0.70866 | v_loss: 1.58822 v_acc: 0.68424 |  iteration: 13468 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1038 loss: 1.38086 acc: 0.71354 | v_loss: 1.44084 v_acc: 0.69792 |  iteration: 13469 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1039 loss: 1.45710 acc: 0.70345 | v_loss: 1.54189 v_acc: 0.69173 |  iteration: 13470 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1040 loss: 1.49672 acc: 0.69401 | v_loss: 1.37081 v_acc: 0.70020 |  iteration: 13471 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1041 loss: 1.49282 acc: 0.70410 | v_loss: 1.32591 v_acc: 0.70312 |  iteration: 13472 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1042 loss: 1.53083 acc: 0.69271 | v_loss: 1.32980 v_acc: 0.70020 |  iteration: 13473 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1043 loss: 1.48081 acc: 0.69629 | v_loss: 1.33587 v_acc: 0.71842 |  iteration: 13474 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1044 loss: 1.37987 acc: 0.70475 | v_loss: 1.55585 v_acc: 0.69108 |  iteration: 13475 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1045 loss: 1.42707 acc: 0.70215 | v_loss: 1.39774 v_acc: 0.71126 |  iteration: 13476 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1046 loss: 1.46659 acc: 0.69336 | v_loss: 1.32903 v_acc: 0.71061 |  iteration: 13477 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1047 loss: 1.49907 acc: 0.69922 | v_loss: 1.38150 v_acc: 0.71452 |  iteration: 13478 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1048 loss: 1.44132 acc: 0.70312 | v_loss: 1.27081 v_acc: 0.70378 |  iteration: 13479 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1049 loss: 1.37319 acc: 0.70280 | v_loss: 1.43069 v_acc: 0.69792 |  iteration: 13480 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1050 loss: 1.45003 acc: 0.69564 | v_loss: 1.41981 v_acc: 0.71582 |  iteration: 13481 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1051 loss: 1.45459 acc: 0.70020 | v_loss: 1.28775 v_acc: 0.71712 |  iteration: 13482 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1052 loss: 1.44410 acc: 0.70410 | v_loss: 1.25168 v_acc: 0.72428 |  iteration: 13483 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1053 loss: 1.52051 acc: 0.69010 | v_loss: 1.38292 v_acc: 0.71387 |  iteration: 13484 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1054 loss: 1.40370 acc: 0.70378 | v_loss: 1.42263 v_acc: 0.70182 |  iteration: 13485 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1055 loss: 1.45943 acc: 0.69922 | v_loss: 1.43118 v_acc: 0.70540 |  iteration: 13486 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1056 loss: 1.52901 acc: 0.69466 | v_loss: 1.23130 v_acc: 0.71712 |  iteration: 13487 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1057 loss: 1.42388 acc: 0.70182 | v_loss: 1.40239 v_acc: 0.72786 |  iteration: 13488 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1058 loss: 1.45654 acc: 0.70508 | v_loss: 1.47148 v_acc: 0.69759 |  iteration: 13489 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1059 loss: 1.41499 acc: 0.70378 | v_loss: 1.41672 v_acc: 0.72201 |  iteration: 13490 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1060 loss: 1.48589 acc: 0.69727 | v_loss: 1.24537 v_acc: 0.72233 |  iteration: 13491 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1061 loss: 1.52198 acc: 0.69889 | v_loss: 1.19977 v_acc: 0.74447 |  iteration: 13492 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1062 loss: 1.47306 acc: 0.69954 | v_loss: 1.21435 v_acc: 0.72493 |  iteration: 13493 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1063 loss: 1.39536 acc: 0.71029 | v_loss: 1.29063 v_acc: 0.71126 |  iteration: 13494 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1064 loss: 1.37652 acc: 0.70182 | v_loss: 1.45836 v_acc: 0.70052 |  iteration: 13495 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1065 loss: 1.33269 acc: 0.70931 | v_loss: 1.26960 v_acc: 0.71452 |  iteration: 13496 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1066 loss: 1.43119 acc: 0.69727 | v_loss: 1.43428 v_acc: 0.71647 |  iteration: 13497 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1067 loss: 1.41261 acc: 0.70410 | v_loss: 1.66541 v_acc: 0.69368 |  iteration: 13498 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1068 loss: 1.37285 acc: 0.71354 | v_loss: 1.52802 v_acc: 0.70117 |  iteration: 13499 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1069 loss: 1.50634 acc: 0.69271 | v_loss: 1.29339 v_acc: 0.72363 |  iteration: 13500 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1070 loss: 1.43468 acc: 0.70215 | v_loss: 1.36972 v_acc: 0.70996 |  iteration: 13501 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1071 loss: 1.42606 acc: 0.69661 | v_loss: 1.21581 v_acc: 0.72201 |  iteration: 13502 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1072 loss: 1.53955 acc: 0.68848 | v_loss: 1.41631 v_acc: 0.70378 |  iteration: 13503 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1073 loss: 1.46883 acc: 0.69987 | v_loss: 1.36012 v_acc: 0.71810 |  iteration: 13504 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1074 loss: 1.39285 acc: 0.71126 | v_loss: 1.35356 v_acc: 0.73014 |  iteration: 13505 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1075 loss: 1.42184 acc: 0.70150 | v_loss: 1.35846 v_acc: 0.71777 |  iteration: 13506 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1076 loss: 1.36513 acc: 0.70085 | v_loss: 1.37172 v_acc: 0.70345 |  iteration: 13507 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1077 loss: 1.43826 acc: 0.70443 | v_loss: 1.28502 v_acc: 0.72201 |  iteration: 13508 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1078 loss: 1.33404 acc: 0.71257 | v_loss: 1.30420 v_acc: 0.72005 |  iteration: 13509 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1079 loss: 1.42629 acc: 0.69954 | v_loss: 1.47846 v_acc: 0.68783 |  iteration: 13510 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1080 loss: 1.47208 acc: 0.70475 | v_loss: 1.34168 v_acc: 0.70931 |  iteration: 13511 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1081 loss: 1.40560 acc: 0.69303 | v_loss: 1.28689 v_acc: 0.71257 |  iteration: 13512 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1082 loss: 1.47045 acc: 0.69596 | v_loss: 1.28689 v_acc: 0.72005 |  iteration: 13513 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1083 loss: 1.54659 acc: 0.69368 | v_loss: 1.43203 v_acc: 0.70475 |  iteration: 13514 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1084 loss: 1.34142 acc: 0.71615 | v_loss: 1.31015 v_acc: 0.73210 |  iteration: 13515 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1085 loss: 1.38735 acc: 0.70117 | v_loss: 1.54483 v_acc: 0.71615 |  iteration: 13516 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1086 loss: 1.44181 acc: 0.70703 | v_loss: 1.27837 v_acc: 0.69824 |  iteration: 13517 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1087 loss: 1.38611 acc: 0.70638 | v_loss: 1.27804 v_acc: 0.70443 |  iteration: 13518 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1088 loss: 1.40076 acc: 0.71842 | v_loss: 1.42104 v_acc: 0.70378 |  iteration: 13519 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1089 loss: 1.38941 acc: 0.70638 | v_loss: 1.45816 v_acc: 0.70312 |  iteration: 13520 teacher: 1 stage: sketch lr: 0.000380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1090 loss: 1.54789 acc: 0.69889 | v_loss: 1.50151 v_acc: 0.69010 |  iteration: 13521 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1091 loss: 1.42727 acc: 0.70215 | v_loss: 1.46609 v_acc: 0.70768 |  iteration: 13522 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1092 loss: 1.33751 acc: 0.71354 | v_loss: 1.41746 v_acc: 0.70410 |  iteration: 13523 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1093 loss: 1.44621 acc: 0.70020 | v_loss: 1.40542 v_acc: 0.70931 |  iteration: 13524 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1094 loss: 1.44035 acc: 0.70182 | v_loss: 1.39782 v_acc: 0.70410 |  iteration: 13525 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1095 loss: 1.38791 acc: 0.70573 | v_loss: 1.25339 v_acc: 0.71354 |  iteration: 13526 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1096 loss: 1.36859 acc: 0.71289 | v_loss: 1.33808 v_acc: 0.72135 |  iteration: 13527 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1097 loss: 1.39629 acc: 0.70020 | v_loss: 1.18009 v_acc: 0.70801 |  iteration: 13528 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1098 loss: 1.48522 acc: 0.69434 | v_loss: 1.33476 v_acc: 0.70605 |  iteration: 13529 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1099 loss: 1.39928 acc: 0.69368 | v_loss: 1.50513 v_acc: 0.69987 |  iteration: 13530 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1100 loss: 1.59098 acc: 0.68945 | v_loss: 1.33977 v_acc: 0.70671 |  iteration: 13531 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1101 loss: 1.44196 acc: 0.69173 | v_loss: 1.34538 v_acc: 0.69629 |  iteration: 13532 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1102 loss: 1.38132 acc: 0.69889 | v_loss: 1.25163 v_acc: 0.71061 |  iteration: 13533 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1103 loss: 1.51717 acc: 0.68848 | v_loss: 1.24632 v_acc: 0.70508 |  iteration: 13534 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1104 loss: 1.42686 acc: 0.71322 | v_loss: 1.23001 v_acc: 0.73470 |  iteration: 13535 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1105 loss: 1.39967 acc: 0.70280 | v_loss: 1.27436 v_acc: 0.72168 |  iteration: 13536 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1106 loss: 1.44246 acc: 0.70996 | v_loss: 1.33124 v_acc: 0.73145 |  iteration: 13537 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1107 loss: 1.41022 acc: 0.71419 | v_loss: 1.25650 v_acc: 0.72461 |  iteration: 13538 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1108 loss: 1.42509 acc: 0.71159 | v_loss: 1.29621 v_acc: 0.72005 |  iteration: 13539 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1109 loss: 1.34771 acc: 0.71517 | v_loss: 1.40907 v_acc: 0.71224 |  iteration: 13540 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1110 loss: 1.44155 acc: 0.70736 | v_loss: 1.38786 v_acc: 0.72005 |  iteration: 13541 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1111 loss: 1.44985 acc: 0.69596 | v_loss: 1.48193 v_acc: 0.69922 |  iteration: 13542 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1112 loss: 1.37542 acc: 0.70573 | v_loss: 1.43012 v_acc: 0.71908 |  iteration: 13543 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1113 loss: 1.42892 acc: 0.70964 | v_loss: 1.18049 v_acc: 0.74284 |  iteration: 13544 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1114 loss: 1.44639 acc: 0.70801 | v_loss: 1.25650 v_acc: 0.70280 |  iteration: 13545 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1115 loss: 1.39668 acc: 0.70150 | v_loss: 1.54115 v_acc: 0.70280 |  iteration: 13546 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1116 loss: 1.41831 acc: 0.70443 | v_loss: 1.19537 v_acc: 0.70866 |  iteration: 13547 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1117 loss: 1.43848 acc: 0.70312 | v_loss: 1.32781 v_acc: 0.71191 |  iteration: 13548 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1118 loss: 1.41112 acc: 0.71908 | v_loss: 1.37140 v_acc: 0.69368 |  iteration: 13549 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1119 loss: 1.40675 acc: 0.71387 | v_loss: 1.28718 v_acc: 0.71842 |  iteration: 13550 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1120 loss: 1.37412 acc: 0.71419 | v_loss: 1.36047 v_acc: 0.70215 |  iteration: 13551 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1121 loss: 1.40081 acc: 0.69922 | v_loss: 1.46930 v_acc: 0.72005 |  iteration: 13552 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1122 loss: 1.36711 acc: 0.70996 | v_loss: 1.32165 v_acc: 0.72786 |  iteration: 13553 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1123 loss: 1.38403 acc: 0.70866 | v_loss: 1.44338 v_acc: 0.70540 |  iteration: 13554 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1124 loss: 1.37579 acc: 0.70443 | v_loss: 1.35997 v_acc: 0.69857 |  iteration: 13555 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1125 loss: 1.36553 acc: 0.71387 | v_loss: 1.32015 v_acc: 0.70833 |  iteration: 13556 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1126 loss: 1.47741 acc: 0.70150 | v_loss: 1.55763 v_acc: 0.68555 |  iteration: 13557 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1127 loss: 1.38326 acc: 0.71257 | v_loss: 1.30687 v_acc: 0.72005 |  iteration: 13558 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1128 loss: 1.48937 acc: 0.70215 | v_loss: 1.58534 v_acc: 0.68424 |  iteration: 13559 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1129 loss: 1.39828 acc: 0.70540 | v_loss: 1.44981 v_acc: 0.69792 |  iteration: 13560 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1130 loss: 1.51361 acc: 0.70312 | v_loss: 1.52888 v_acc: 0.69173 |  iteration: 13561 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1131 loss: 1.45223 acc: 0.70475 | v_loss: 1.37327 v_acc: 0.69889 |  iteration: 13562 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1132 loss: 1.46774 acc: 0.69889 | v_loss: 1.32174 v_acc: 0.70215 |  iteration: 13563 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1133 loss: 1.51093 acc: 0.69661 | v_loss: 1.33343 v_acc: 0.69889 |  iteration: 13564 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1134 loss: 1.41536 acc: 0.70605 | v_loss: 1.32896 v_acc: 0.71419 |  iteration: 13565 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1135 loss: 1.44247 acc: 0.70410 | v_loss: 1.52844 v_acc: 0.69173 |  iteration: 13566 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1136 loss: 1.44127 acc: 0.70410 | v_loss: 1.38851 v_acc: 0.70378 |  iteration: 13567 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1137 loss: 1.39205 acc: 0.70833 | v_loss: 1.35454 v_acc: 0.70833 |  iteration: 13568 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1138 loss: 1.43544 acc: 0.71029 | v_loss: 1.38631 v_acc: 0.71810 |  iteration: 13569 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1139 loss: 1.34865 acc: 0.70964 | v_loss: 1.28613 v_acc: 0.70215 |  iteration: 13570 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1140 loss: 1.49528 acc: 0.70312 | v_loss: 1.42315 v_acc: 0.69434 |  iteration: 13571 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1141 loss: 1.45219 acc: 0.69401 | v_loss: 1.42331 v_acc: 0.71517 |  iteration: 13572 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1142 loss: 1.41145 acc: 0.69531 | v_loss: 1.29865 v_acc: 0.71745 |  iteration: 13573 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1143 loss: 1.49545 acc: 0.70052 | v_loss: 1.25245 v_acc: 0.72852 |  iteration: 13574 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1144 loss: 1.38463 acc: 0.70410 | v_loss: 1.37208 v_acc: 0.71777 |  iteration: 13575 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1145 loss: 1.40917 acc: 0.70931 | v_loss: 1.42699 v_acc: 0.70508 |  iteration: 13576 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1146 loss: 1.41683 acc: 0.69889 | v_loss: 1.43455 v_acc: 0.70866 |  iteration: 13577 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1147 loss: 1.45377 acc: 0.69499 | v_loss: 1.23372 v_acc: 0.71777 |  iteration: 13578 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1148 loss: 1.56028 acc: 0.69466 | v_loss: 1.40349 v_acc: 0.73112 |  iteration: 13579 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1149 loss: 1.45848 acc: 0.69629 | v_loss: 1.47353 v_acc: 0.69857 |  iteration: 13580 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1150 loss: 1.34992 acc: 0.71061 | v_loss: 1.42956 v_acc: 0.72103 |  iteration: 13581 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1151 loss: 1.36849 acc: 0.69629 | v_loss: 1.24428 v_acc: 0.72103 |  iteration: 13582 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1152 loss: 1.56108 acc: 0.68815 | v_loss: 1.18814 v_acc: 0.74316 |  iteration: 13583 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1153 loss: 1.42777 acc: 0.69596 | v_loss: 1.21048 v_acc: 0.72461 |  iteration: 13584 teacher: 1 stage: sketch lr: 0.000379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1154 loss: 1.43958 acc: 0.69368 | v_loss: 1.26151 v_acc: 0.71126 |  iteration: 13585 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1155 loss: 1.40612 acc: 0.70410 | v_loss: 1.44444 v_acc: 0.70573 |  iteration: 13586 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1156 loss: 1.40548 acc: 0.70312 | v_loss: 1.27655 v_acc: 0.71387 |  iteration: 13587 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1157 loss: 1.45760 acc: 0.69043 | v_loss: 1.45526 v_acc: 0.71289 |  iteration: 13588 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1158 loss: 1.45478 acc: 0.69727 | v_loss: 1.67378 v_acc: 0.69303 |  iteration: 13589 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1159 loss: 1.45917 acc: 0.69824 | v_loss: 1.52801 v_acc: 0.70117 |  iteration: 13590 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1160 loss: 1.37687 acc: 0.70898 | v_loss: 1.29348 v_acc: 0.72363 |  iteration: 13591 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1161 loss: 1.51926 acc: 0.69336 | v_loss: 1.38609 v_acc: 0.70410 |  iteration: 13592 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1162 loss: 1.45222 acc: 0.69954 | v_loss: 1.21926 v_acc: 0.71973 |  iteration: 13593 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1163 loss: 1.50324 acc: 0.70247 | v_loss: 1.43594 v_acc: 0.70150 |  iteration: 13594 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1164 loss: 1.48326 acc: 0.70052 | v_loss: 1.36471 v_acc: 0.71029 |  iteration: 13595 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1165 loss: 1.43933 acc: 0.70085 | v_loss: 1.35172 v_acc: 0.73079 |  iteration: 13596 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1166 loss: 1.48749 acc: 0.69401 | v_loss: 1.35728 v_acc: 0.71777 |  iteration: 13597 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1167 loss: 1.45956 acc: 0.69824 | v_loss: 1.37485 v_acc: 0.70410 |  iteration: 13598 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1168 loss: 1.47984 acc: 0.69954 | v_loss: 1.28601 v_acc: 0.72233 |  iteration: 13599 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1169 loss: 1.42896 acc: 0.69759 | v_loss: 1.30060 v_acc: 0.72135 |  iteration: 13600 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1170 loss: 1.48252 acc: 0.70540 | v_loss: 1.50799 v_acc: 0.69303 |  iteration: 13601 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1171 loss: 1.58815 acc: 0.69336 | v_loss: 1.33337 v_acc: 0.71159 |  iteration: 13602 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1172 loss: 1.43034 acc: 0.70540 | v_loss: 1.29664 v_acc: 0.71549 |  iteration: 13603 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1173 loss: 1.43882 acc: 0.70508 | v_loss: 1.28546 v_acc: 0.71973 |  iteration: 13604 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1174 loss: 1.43460 acc: 0.70898 | v_loss: 1.42672 v_acc: 0.70573 |  iteration: 13605 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1175 loss: 1.43443 acc: 0.70736 | v_loss: 1.30683 v_acc: 0.73112 |  iteration: 13606 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1176 loss: 1.36744 acc: 0.70443 | v_loss: 1.55343 v_acc: 0.71517 |  iteration: 13607 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1177 loss: 1.48111 acc: 0.69857 | v_loss: 1.27714 v_acc: 0.70117 |  iteration: 13608 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1178 loss: 1.33691 acc: 0.70312 | v_loss: 1.27733 v_acc: 0.70671 |  iteration: 13609 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1179 loss: 1.48973 acc: 0.69792 | v_loss: 1.43555 v_acc: 0.70508 |  iteration: 13610 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1180 loss: 1.43654 acc: 0.69336 | v_loss: 1.47562 v_acc: 0.70312 |  iteration: 13611 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1181 loss: 1.40962 acc: 0.69954 | v_loss: 1.51594 v_acc: 0.69499 |  iteration: 13612 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1182 loss: 1.41132 acc: 0.70475 | v_loss: 1.47074 v_acc: 0.70768 |  iteration: 13613 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1183 loss: 1.37897 acc: 0.69987 | v_loss: 1.42559 v_acc: 0.70312 |  iteration: 13614 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1184 loss: 1.48811 acc: 0.69857 | v_loss: 1.41121 v_acc: 0.70833 |  iteration: 13615 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1185 loss: 1.45030 acc: 0.70182 | v_loss: 1.38854 v_acc: 0.70736 |  iteration: 13616 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1186 loss: 1.46949 acc: 0.69954 | v_loss: 1.24980 v_acc: 0.71354 |  iteration: 13617 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1187 loss: 1.43519 acc: 0.70117 | v_loss: 1.32827 v_acc: 0.72461 |  iteration: 13618 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1188 loss: 1.30124 acc: 0.71582 | v_loss: 1.17843 v_acc: 0.71517 |  iteration: 13619 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1189 loss: 1.43692 acc: 0.69564 | v_loss: 1.34052 v_acc: 0.70443 |  iteration: 13620 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1190 loss: 1.36109 acc: 0.70573 | v_loss: 1.50180 v_acc: 0.69987 |  iteration: 13621 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1191 loss: 1.39676 acc: 0.71191 | v_loss: 1.33035 v_acc: 0.70833 |  iteration: 13622 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1192 loss: 1.40413 acc: 0.70540 | v_loss: 1.36159 v_acc: 0.69727 |  iteration: 13623 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1193 loss: 1.37379 acc: 0.71647 | v_loss: 1.24908 v_acc: 0.71126 |  iteration: 13624 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1194 loss: 1.39968 acc: 0.70833 | v_loss: 1.24126 v_acc: 0.70345 |  iteration: 13625 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1195 loss: 1.35707 acc: 0.71224 | v_loss: 1.23902 v_acc: 0.73503 |  iteration: 13626 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1196 loss: 1.46051 acc: 0.70117 | v_loss: 1.27151 v_acc: 0.72135 |  iteration: 13627 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1197 loss: 1.45852 acc: 0.70345 | v_loss: 1.32947 v_acc: 0.73047 |  iteration: 13628 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1198 loss: 1.46027 acc: 0.70345 | v_loss: 1.25493 v_acc: 0.72461 |  iteration: 13629 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1199 loss: 1.45515 acc: 0.70280 | v_loss: 1.29865 v_acc: 0.72005 |  iteration: 13630 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1200 loss: 1.35432 acc: 0.71094 | v_loss: 1.40285 v_acc: 0.71224 |  iteration: 13631 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1201 loss: 1.52023 acc: 0.69076 | v_loss: 1.38658 v_acc: 0.72103 |  iteration: 13632 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1202 loss: 1.46386 acc: 0.69824 | v_loss: 1.48903 v_acc: 0.69922 |  iteration: 13633 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1203 loss: 1.41484 acc: 0.70312 | v_loss: 1.41385 v_acc: 0.71615 |  iteration: 13634 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 1204 loss: 1.48984 acc: 0.69694 | v_loss: 1.17644 v_acc: 0.74544 |  iteration: 13635 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 1205 loss: 1.43562 acc: 0.70410 | v_loss: 1.25548 v_acc: 0.70931 |  iteration: 13636 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 1206 loss: 1.44984 acc: 0.69629 | v_loss: 1.51299 v_acc: 0.70247 |  iteration: 13637 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 1207 loss: 1.33572 acc: 0.70671 | v_loss: 1.21032 v_acc: 0.70866 |  iteration: 13638 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 1208 loss: 1.35719 acc: 0.70443 | v_loss: 1.32389 v_acc: 0.71159 |  iteration: 13639 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 1209 loss: 1.49682 acc: 0.69108 | v_loss: 1.36347 v_acc: 0.69336 |  iteration: 13640 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 1210 loss: 1.37202 acc: 0.70605 | v_loss: 1.28845 v_acc: 0.71387 |  iteration: 13641 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 1211 loss: 1.41822 acc: 0.71289 | v_loss: 1.36740 v_acc: 0.69922 |  iteration: 13642 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 1212 loss: 1.44907 acc: 0.70182 | v_loss: 1.48550 v_acc: 0.71745 |  iteration: 13643 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 1213 loss: 1.39989 acc: 0.70443 | v_loss: 1.32159 v_acc: 0.72689 |  iteration: 13644 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 1214 loss: 1.43025 acc: 0.70215 | v_loss: 1.45585 v_acc: 0.70443 |  iteration: 13645 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 1215 loss: 1.48132 acc: 0.69499 | v_loss: 1.35306 v_acc: 0.69987 |  iteration: 13646 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 1216 loss: 1.49921 acc: 0.70312 | v_loss: 1.32073 v_acc: 0.70996 |  iteration: 13647 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 1217 loss: 1.47290 acc: 0.70443 | v_loss: 1.53940 v_acc: 0.69076 |  iteration: 13648 teacher: 0 stage: sketch lr: 0.000378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1218 loss: 1.38767 acc: 0.71745 | v_loss: 1.30400 v_acc: 0.72201 |  iteration: 13649 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 1219 loss: 1.51087 acc: 0.70736 | v_loss: 1.56940 v_acc: 0.69043 |  iteration: 13650 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 1220 loss: 1.46244 acc: 0.70573 | v_loss: 1.43215 v_acc: 0.70215 |  iteration: 13651 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 1221 loss: 1.42012 acc: 0.70475 | v_loss: 1.50672 v_acc: 0.68750 |  iteration: 13652 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 1222 loss: 1.53337 acc: 0.69661 | v_loss: 1.38676 v_acc: 0.69824 |  iteration: 13653 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 1223 loss: 1.43472 acc: 0.71029 | v_loss: 1.32629 v_acc: 0.70247 |  iteration: 13654 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 1224 loss: 1.40655 acc: 0.71094 | v_loss: 1.34089 v_acc: 0.70020 |  iteration: 13655 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 1225 loss: 1.43625 acc: 0.69922 | v_loss: 1.33602 v_acc: 0.71680 |  iteration: 13656 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 1226 loss: 1.47283 acc: 0.69889 | v_loss: 1.54428 v_acc: 0.68978 |  iteration: 13657 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 1227 loss: 1.43098 acc: 0.69466 | v_loss: 1.38609 v_acc: 0.71126 |  iteration: 13658 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 1228 loss: 1.44955 acc: 0.70280 | v_loss: 1.33783 v_acc: 0.71061 |  iteration: 13659 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 1229 loss: 1.53503 acc: 0.70052 | v_loss: 1.39232 v_acc: 0.71452 |  iteration: 13660 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 1230 loss: 1.38295 acc: 0.70508 | v_loss: 1.26071 v_acc: 0.70736 |  iteration: 13661 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 1231 loss: 1.43650 acc: 0.70605 | v_loss: 1.43434 v_acc: 0.70020 |  iteration: 13662 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 1232 loss: 1.41397 acc: 0.70638 | v_loss: 1.42730 v_acc: 0.71289 |  iteration: 13663 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 1233 loss: 1.40201 acc: 0.70247 | v_loss: 1.28657 v_acc: 0.71875 |  iteration: 13664 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 1234 loss: 1.40780 acc: 0.70605 | v_loss: 1.25866 v_acc: 0.72917 |  iteration: 13665 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 1235 loss: 1.26377 acc: 0.71712 | v_loss: 1.37644 v_acc: 0.71680 |  iteration: 13666 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 1236 loss: 1.50874 acc: 0.69824 | v_loss: 1.42503 v_acc: 0.70312 |  iteration: 13667 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 1237 loss: 1.49783 acc: 0.70605 | v_loss: 1.42369 v_acc: 0.70312 |  iteration: 13668 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 1238 loss: 1.35661 acc: 0.69759 | v_loss: 1.24192 v_acc: 0.71257 |  iteration: 13669 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 1239 loss: 1.38013 acc: 0.70378 | v_loss: 1.38859 v_acc: 0.72819 |  iteration: 13670 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 1240 loss: 1.37617 acc: 0.71354 | v_loss: 1.47575 v_acc: 0.69792 |  iteration: 13671 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 1241 loss: 1.45206 acc: 0.70085 | v_loss: 1.41663 v_acc: 0.72070 |  iteration: 13672 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 1242 loss: 1.37695 acc: 0.71484 | v_loss: 1.24302 v_acc: 0.72201 |  iteration: 13673 teacher: 0 stage: sketch lr: 0.000378\n",
      "epoch 10 loss: 1.43683 acc: 0.70273 | v_loss: 1.36701 v_acc: 0.71050 \n",
      "epoch: 11\n",
      "__________________________________________\n",
      "batch 0 loss: 1.40690 acc: 0.70312 | v_loss: 1.42301 v_acc: 0.70410 |  iteration: 13674 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 1 loss: 1.41127 acc: 0.71061 | v_loss: 1.40301 v_acc: 0.70866 |  iteration: 13675 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 2 loss: 1.43498 acc: 0.70638 | v_loss: 1.40028 v_acc: 0.70703 |  iteration: 13676 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 3 loss: 1.43192 acc: 0.70605 | v_loss: 1.26156 v_acc: 0.71875 |  iteration: 13677 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 4 loss: 1.42515 acc: 0.70020 | v_loss: 1.31783 v_acc: 0.72428 |  iteration: 13678 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 5 loss: 1.49953 acc: 0.69368 | v_loss: 1.19436 v_acc: 0.70801 |  iteration: 13679 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 6 loss: 1.41089 acc: 0.69987 | v_loss: 1.34529 v_acc: 0.70247 |  iteration: 13680 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 7 loss: 1.49611 acc: 0.69564 | v_loss: 1.49877 v_acc: 0.69987 |  iteration: 13681 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 8 loss: 1.41619 acc: 0.70312 | v_loss: 1.34075 v_acc: 0.70638 |  iteration: 13682 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 9 loss: 1.37531 acc: 0.70410 | v_loss: 1.33443 v_acc: 0.69661 |  iteration: 13683 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 10 loss: 1.44034 acc: 0.70117 | v_loss: 1.26346 v_acc: 0.70768 |  iteration: 13684 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 11 loss: 1.33092 acc: 0.70833 | v_loss: 1.23789 v_acc: 0.70671 |  iteration: 13685 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 12 loss: 1.45839 acc: 0.69824 | v_loss: 1.23802 v_acc: 0.73665 |  iteration: 13686 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 13 loss: 1.34097 acc: 0.71191 | v_loss: 1.26309 v_acc: 0.72168 |  iteration: 13687 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 14 loss: 1.37243 acc: 0.70443 | v_loss: 1.34265 v_acc: 0.73145 |  iteration: 13688 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 15 loss: 1.43813 acc: 0.70247 | v_loss: 1.26474 v_acc: 0.72852 |  iteration: 13689 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 16 loss: 1.41049 acc: 0.69434 | v_loss: 1.32211 v_acc: 0.72103 |  iteration: 13690 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 17 loss: 1.52821 acc: 0.69596 | v_loss: 1.44249 v_acc: 0.71354 |  iteration: 13691 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 18 loss: 1.52744 acc: 0.68945 | v_loss: 1.42913 v_acc: 0.72363 |  iteration: 13692 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 19 loss: 1.45173 acc: 0.70703 | v_loss: 1.49035 v_acc: 0.69922 |  iteration: 13693 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 20 loss: 1.50749 acc: 0.69727 | v_loss: 1.43315 v_acc: 0.71615 |  iteration: 13694 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 21 loss: 1.37549 acc: 0.71322 | v_loss: 1.18946 v_acc: 0.74382 |  iteration: 13695 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 22 loss: 1.54263 acc: 0.70410 | v_loss: 1.27228 v_acc: 0.70182 |  iteration: 13696 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 23 loss: 1.39323 acc: 0.71159 | v_loss: 1.49508 v_acc: 0.70898 |  iteration: 13697 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 24 loss: 1.37883 acc: 0.70703 | v_loss: 1.22411 v_acc: 0.73177 |  iteration: 13698 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 25 loss: 1.38944 acc: 0.70638 | v_loss: 1.31866 v_acc: 0.72103 |  iteration: 13699 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 26 loss: 1.46073 acc: 0.69792 | v_loss: 1.36006 v_acc: 0.69108 |  iteration: 13700 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 27 loss: 1.52891 acc: 0.69466 | v_loss: 1.30443 v_acc: 0.70898 |  iteration: 13701 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 28 loss: 1.47227 acc: 0.69857 | v_loss: 1.36128 v_acc: 0.69629 |  iteration: 13702 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 29 loss: 1.38858 acc: 0.70736 | v_loss: 1.47620 v_acc: 0.71517 |  iteration: 13703 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 30 loss: 1.48460 acc: 0.70150 | v_loss: 1.32038 v_acc: 0.72689 |  iteration: 13704 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 31 loss: 1.44988 acc: 0.69954 | v_loss: 1.47228 v_acc: 0.70540 |  iteration: 13705 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 32 loss: 1.30414 acc: 0.71191 | v_loss: 1.34604 v_acc: 0.70085 |  iteration: 13706 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 33 loss: 1.46882 acc: 0.70443 | v_loss: 1.33851 v_acc: 0.70410 |  iteration: 13707 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 34 loss: 1.35601 acc: 0.70866 | v_loss: 1.57222 v_acc: 0.68750 |  iteration: 13708 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 35 loss: 1.43458 acc: 0.69987 | v_loss: 1.32039 v_acc: 0.72168 |  iteration: 13709 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 36 loss: 1.39143 acc: 0.70703 | v_loss: 1.59771 v_acc: 0.67969 |  iteration: 13710 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 37 loss: 1.39499 acc: 0.70378 | v_loss: 1.44886 v_acc: 0.69792 |  iteration: 13711 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 38 loss: 1.43033 acc: 0.70345 | v_loss: 1.53234 v_acc: 0.69173 |  iteration: 13712 teacher: 0 stage: sketch lr: 0.000377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 39 loss: 1.35566 acc: 0.70866 | v_loss: 1.37948 v_acc: 0.70020 |  iteration: 13713 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 40 loss: 1.39114 acc: 0.71289 | v_loss: 1.32710 v_acc: 0.70215 |  iteration: 13714 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 41 loss: 1.44508 acc: 0.69271 | v_loss: 1.32873 v_acc: 0.69889 |  iteration: 13715 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 42 loss: 1.49543 acc: 0.70280 | v_loss: 1.33265 v_acc: 0.71419 |  iteration: 13716 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 43 loss: 1.42982 acc: 0.70801 | v_loss: 1.52456 v_acc: 0.69173 |  iteration: 13717 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 44 loss: 1.41854 acc: 0.70801 | v_loss: 1.37671 v_acc: 0.70247 |  iteration: 13718 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 45 loss: 1.40860 acc: 0.70768 | v_loss: 1.34979 v_acc: 0.71029 |  iteration: 13719 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 46 loss: 1.52921 acc: 0.69987 | v_loss: 1.38531 v_acc: 0.71680 |  iteration: 13720 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 47 loss: 1.46655 acc: 0.69401 | v_loss: 1.27858 v_acc: 0.70573 |  iteration: 13721 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 48 loss: 1.46492 acc: 0.70182 | v_loss: 1.43994 v_acc: 0.69759 |  iteration: 13722 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 49 loss: 1.40325 acc: 0.70736 | v_loss: 1.43211 v_acc: 0.71289 |  iteration: 13723 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 50 loss: 1.42668 acc: 0.70020 | v_loss: 1.28992 v_acc: 0.71680 |  iteration: 13724 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 51 loss: 1.39631 acc: 0.70768 | v_loss: 1.26258 v_acc: 0.72526 |  iteration: 13725 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 52 loss: 1.48504 acc: 0.69629 | v_loss: 1.37197 v_acc: 0.71647 |  iteration: 13726 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 53 loss: 1.34702 acc: 0.71484 | v_loss: 1.43025 v_acc: 0.70052 |  iteration: 13727 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 54 loss: 1.46423 acc: 0.71061 | v_loss: 1.43239 v_acc: 0.70312 |  iteration: 13728 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 55 loss: 1.43394 acc: 0.71061 | v_loss: 1.22623 v_acc: 0.71615 |  iteration: 13729 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 56 loss: 1.41513 acc: 0.70312 | v_loss: 1.40118 v_acc: 0.72819 |  iteration: 13730 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 57 loss: 1.47634 acc: 0.70117 | v_loss: 1.47837 v_acc: 0.69792 |  iteration: 13731 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 58 loss: 1.42288 acc: 0.70736 | v_loss: 1.41408 v_acc: 0.72070 |  iteration: 13732 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 59 loss: 1.38216 acc: 0.70996 | v_loss: 1.25074 v_acc: 0.72201 |  iteration: 13733 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 60 loss: 1.38080 acc: 0.70443 | v_loss: 1.20613 v_acc: 0.74023 |  iteration: 13734 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 61 loss: 1.35718 acc: 0.71191 | v_loss: 1.21766 v_acc: 0.72559 |  iteration: 13735 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 62 loss: 1.51315 acc: 0.69531 | v_loss: 1.29863 v_acc: 0.70638 |  iteration: 13736 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 63 loss: 1.53104 acc: 0.69434 | v_loss: 1.47097 v_acc: 0.69661 |  iteration: 13737 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 64 loss: 1.38683 acc: 0.70508 | v_loss: 1.28047 v_acc: 0.71387 |  iteration: 13738 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 65 loss: 1.48483 acc: 0.69857 | v_loss: 1.45137 v_acc: 0.71582 |  iteration: 13739 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 66 loss: 1.42786 acc: 0.70215 | v_loss: 1.66035 v_acc: 0.69368 |  iteration: 13740 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 67 loss: 1.40635 acc: 0.70020 | v_loss: 1.51731 v_acc: 0.70117 |  iteration: 13741 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 68 loss: 1.31953 acc: 0.71354 | v_loss: 1.29345 v_acc: 0.72363 |  iteration: 13742 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 69 loss: 1.36623 acc: 0.70150 | v_loss: 1.37393 v_acc: 0.70410 |  iteration: 13743 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 70 loss: 1.47962 acc: 0.70085 | v_loss: 1.22931 v_acc: 0.71973 |  iteration: 13744 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 71 loss: 1.42874 acc: 0.70215 | v_loss: 1.42263 v_acc: 0.70150 |  iteration: 13745 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 72 loss: 1.35789 acc: 0.71257 | v_loss: 1.36218 v_acc: 0.71029 |  iteration: 13746 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 73 loss: 1.41632 acc: 0.69987 | v_loss: 1.35727 v_acc: 0.73079 |  iteration: 13747 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 74 loss: 1.40433 acc: 0.69922 | v_loss: 1.37262 v_acc: 0.71777 |  iteration: 13748 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 75 loss: 1.37316 acc: 0.70378 | v_loss: 1.38604 v_acc: 0.70410 |  iteration: 13749 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 76 loss: 1.37970 acc: 0.70378 | v_loss: 1.29385 v_acc: 0.72233 |  iteration: 13750 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 77 loss: 1.43794 acc: 0.70247 | v_loss: 1.31877 v_acc: 0.71973 |  iteration: 13751 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 78 loss: 1.46462 acc: 0.69206 | v_loss: 1.47963 v_acc: 0.69368 |  iteration: 13752 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 79 loss: 1.62284 acc: 0.68978 | v_loss: 1.33521 v_acc: 0.71452 |  iteration: 13753 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 80 loss: 1.36302 acc: 0.71354 | v_loss: 1.28139 v_acc: 0.71777 |  iteration: 13754 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 81 loss: 1.45388 acc: 0.70150 | v_loss: 1.27707 v_acc: 0.71484 |  iteration: 13755 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 82 loss: 1.41146 acc: 0.70801 | v_loss: 1.42517 v_acc: 0.70638 |  iteration: 13756 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 83 loss: 1.41243 acc: 0.70020 | v_loss: 1.30489 v_acc: 0.73242 |  iteration: 13757 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 84 loss: 1.45884 acc: 0.70280 | v_loss: 1.53009 v_acc: 0.71615 |  iteration: 13758 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 85 loss: 1.44037 acc: 0.70605 | v_loss: 1.29029 v_acc: 0.69759 |  iteration: 13759 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 86 loss: 1.41672 acc: 0.70280 | v_loss: 1.28446 v_acc: 0.70671 |  iteration: 13760 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 87 loss: 1.46546 acc: 0.70052 | v_loss: 1.44252 v_acc: 0.70703 |  iteration: 13761 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 88 loss: 1.49251 acc: 0.70117 | v_loss: 1.46897 v_acc: 0.70866 |  iteration: 13762 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 89 loss: 1.33922 acc: 0.71257 | v_loss: 1.51856 v_acc: 0.68783 |  iteration: 13763 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 90 loss: 1.42045 acc: 0.70085 | v_loss: 1.47066 v_acc: 0.70378 |  iteration: 13764 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 91 loss: 1.43547 acc: 0.69987 | v_loss: 1.42190 v_acc: 0.70410 |  iteration: 13765 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 92 loss: 1.46550 acc: 0.70215 | v_loss: 1.41754 v_acc: 0.70703 |  iteration: 13766 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 93 loss: 1.50614 acc: 0.69759 | v_loss: 1.38931 v_acc: 0.70443 |  iteration: 13767 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 94 loss: 1.36236 acc: 0.70508 | v_loss: 1.25532 v_acc: 0.71875 |  iteration: 13768 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 95 loss: 1.52115 acc: 0.70215 | v_loss: 1.33078 v_acc: 0.72331 |  iteration: 13769 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 96 loss: 1.45235 acc: 0.70540 | v_loss: 1.16122 v_acc: 0.71615 |  iteration: 13770 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 97 loss: 1.61423 acc: 0.68490 | v_loss: 1.34582 v_acc: 0.71126 |  iteration: 13771 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 98 loss: 1.47906 acc: 0.70052 | v_loss: 1.49928 v_acc: 0.69954 |  iteration: 13772 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 99 loss: 1.41448 acc: 0.70768 | v_loss: 1.32236 v_acc: 0.70833 |  iteration: 13773 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 100 loss: 1.36794 acc: 0.70638 | v_loss: 1.35811 v_acc: 0.69629 |  iteration: 13774 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 101 loss: 1.37900 acc: 0.70898 | v_loss: 1.25212 v_acc: 0.70573 |  iteration: 13775 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 102 loss: 1.41282 acc: 0.69824 | v_loss: 1.25559 v_acc: 0.70280 |  iteration: 13776 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 103 loss: 1.36502 acc: 0.71126 | v_loss: 1.24373 v_acc: 0.73372 |  iteration: 13777 teacher: 0 stage: sketch lr: 0.000377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 104 loss: 1.53103 acc: 0.68913 | v_loss: 1.27862 v_acc: 0.71680 |  iteration: 13778 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 105 loss: 1.44266 acc: 0.70475 | v_loss: 1.33396 v_acc: 0.74089 |  iteration: 13779 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 106 loss: 1.38900 acc: 0.71322 | v_loss: 1.26146 v_acc: 0.72005 |  iteration: 13780 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 107 loss: 1.44544 acc: 0.69759 | v_loss: 1.30113 v_acc: 0.71582 |  iteration: 13781 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 108 loss: 1.36280 acc: 0.71029 | v_loss: 1.41438 v_acc: 0.71224 |  iteration: 13782 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 109 loss: 1.45791 acc: 0.70703 | v_loss: 1.39061 v_acc: 0.72070 |  iteration: 13783 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 110 loss: 1.42091 acc: 0.70508 | v_loss: 1.49297 v_acc: 0.69954 |  iteration: 13784 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 111 loss: 1.36235 acc: 0.71191 | v_loss: 1.42251 v_acc: 0.71615 |  iteration: 13785 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 112 loss: 1.49585 acc: 0.69824 | v_loss: 1.17543 v_acc: 0.74544 |  iteration: 13786 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 113 loss: 1.43972 acc: 0.70247 | v_loss: 1.26338 v_acc: 0.70931 |  iteration: 13787 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 114 loss: 1.39269 acc: 0.70996 | v_loss: 1.53104 v_acc: 0.70215 |  iteration: 13788 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 115 loss: 1.43641 acc: 0.70280 | v_loss: 1.23141 v_acc: 0.70898 |  iteration: 13789 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 116 loss: 1.54004 acc: 0.69759 | v_loss: 1.32533 v_acc: 0.71257 |  iteration: 13790 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 117 loss: 1.47156 acc: 0.69792 | v_loss: 1.35933 v_acc: 0.69466 |  iteration: 13791 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 118 loss: 1.38423 acc: 0.70573 | v_loss: 1.29331 v_acc: 0.71029 |  iteration: 13792 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 119 loss: 1.47373 acc: 0.69792 | v_loss: 1.36423 v_acc: 0.69596 |  iteration: 13793 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 120 loss: 1.38880 acc: 0.70866 | v_loss: 1.46098 v_acc: 0.71647 |  iteration: 13794 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 121 loss: 1.42161 acc: 0.71322 | v_loss: 1.31963 v_acc: 0.72786 |  iteration: 13795 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 122 loss: 1.53258 acc: 0.68587 | v_loss: 1.43065 v_acc: 0.70540 |  iteration: 13796 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 123 loss: 1.43525 acc: 0.70052 | v_loss: 1.37920 v_acc: 0.69824 |  iteration: 13797 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 124 loss: 1.43270 acc: 0.69499 | v_loss: 1.31184 v_acc: 0.70833 |  iteration: 13798 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 125 loss: 1.39672 acc: 0.70703 | v_loss: 1.55969 v_acc: 0.68522 |  iteration: 13799 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 126 loss: 1.43332 acc: 0.70540 | v_loss: 1.30453 v_acc: 0.72233 |  iteration: 13800 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 127 loss: 1.41830 acc: 0.70898 | v_loss: 1.59115 v_acc: 0.67969 |  iteration: 13801 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 128 loss: 1.36573 acc: 0.70898 | v_loss: 1.46076 v_acc: 0.69661 |  iteration: 13802 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 129 loss: 1.38049 acc: 0.70378 | v_loss: 1.55045 v_acc: 0.69238 |  iteration: 13803 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 130 loss: 1.45201 acc: 0.69922 | v_loss: 1.36883 v_acc: 0.70182 |  iteration: 13804 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 131 loss: 1.43574 acc: 0.69987 | v_loss: 1.33091 v_acc: 0.70508 |  iteration: 13805 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 132 loss: 1.50159 acc: 0.69336 | v_loss: 1.33027 v_acc: 0.70345 |  iteration: 13806 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 133 loss: 1.52558 acc: 0.70443 | v_loss: 1.33191 v_acc: 0.71452 |  iteration: 13807 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 134 loss: 1.44373 acc: 0.69499 | v_loss: 1.54234 v_acc: 0.68978 |  iteration: 13808 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 135 loss: 1.43648 acc: 0.70280 | v_loss: 1.38801 v_acc: 0.70443 |  iteration: 13809 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 136 loss: 1.45050 acc: 0.70866 | v_loss: 1.33832 v_acc: 0.71029 |  iteration: 13810 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 137 loss: 1.46745 acc: 0.69824 | v_loss: 1.38852 v_acc: 0.71777 |  iteration: 13811 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 138 loss: 1.39998 acc: 0.71484 | v_loss: 1.28278 v_acc: 0.70215 |  iteration: 13812 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 139 loss: 1.48344 acc: 0.69401 | v_loss: 1.42788 v_acc: 0.69401 |  iteration: 13813 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 140 loss: 1.42684 acc: 0.70540 | v_loss: 1.42672 v_acc: 0.71777 |  iteration: 13814 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 141 loss: 1.46896 acc: 0.70475 | v_loss: 1.30948 v_acc: 0.71777 |  iteration: 13815 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 142 loss: 1.39058 acc: 0.71517 | v_loss: 1.26513 v_acc: 0.72168 |  iteration: 13816 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 143 loss: 1.45685 acc: 0.70182 | v_loss: 1.37262 v_acc: 0.71712 |  iteration: 13817 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 144 loss: 1.43049 acc: 0.69987 | v_loss: 1.42725 v_acc: 0.70020 |  iteration: 13818 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 145 loss: 1.48363 acc: 0.70443 | v_loss: 1.42417 v_acc: 0.70508 |  iteration: 13819 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 146 loss: 1.42643 acc: 0.71322 | v_loss: 1.24119 v_acc: 0.71126 |  iteration: 13820 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 147 loss: 1.48639 acc: 0.69954 | v_loss: 1.38737 v_acc: 0.73047 |  iteration: 13821 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 148 loss: 1.40034 acc: 0.71191 | v_loss: 1.46062 v_acc: 0.69792 |  iteration: 13822 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 149 loss: 1.44676 acc: 0.70150 | v_loss: 1.40045 v_acc: 0.72233 |  iteration: 13823 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 150 loss: 1.40371 acc: 0.70866 | v_loss: 1.25500 v_acc: 0.71810 |  iteration: 13824 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 151 loss: 1.45241 acc: 0.69759 | v_loss: 1.20954 v_acc: 0.73665 |  iteration: 13825 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 152 loss: 1.42509 acc: 0.70508 | v_loss: 1.21361 v_acc: 0.72624 |  iteration: 13826 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 153 loss: 1.41352 acc: 0.70736 | v_loss: 1.29173 v_acc: 0.70638 |  iteration: 13827 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 154 loss: 1.38312 acc: 0.71289 | v_loss: 1.46045 v_acc: 0.70052 |  iteration: 13828 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 155 loss: 1.40049 acc: 0.70508 | v_loss: 1.28013 v_acc: 0.71549 |  iteration: 13829 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 156 loss: 1.52243 acc: 0.69466 | v_loss: 1.48466 v_acc: 0.70671 |  iteration: 13830 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 157 loss: 1.43243 acc: 0.70866 | v_loss: 1.67566 v_acc: 0.69368 |  iteration: 13831 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 158 loss: 1.44521 acc: 0.70443 | v_loss: 1.52462 v_acc: 0.70117 |  iteration: 13832 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 159 loss: 1.42232 acc: 0.70247 | v_loss: 1.29327 v_acc: 0.72363 |  iteration: 13833 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 160 loss: 1.47032 acc: 0.70280 | v_loss: 1.36741 v_acc: 0.70410 |  iteration: 13834 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 161 loss: 1.51079 acc: 0.69922 | v_loss: 1.23455 v_acc: 0.71940 |  iteration: 13835 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 162 loss: 1.39132 acc: 0.71061 | v_loss: 1.41183 v_acc: 0.70150 |  iteration: 13836 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 163 loss: 1.40671 acc: 0.71029 | v_loss: 1.35559 v_acc: 0.70996 |  iteration: 13837 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 164 loss: 1.45818 acc: 0.70052 | v_loss: 1.34977 v_acc: 0.72949 |  iteration: 13838 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 165 loss: 1.44980 acc: 0.69954 | v_loss: 1.35970 v_acc: 0.71680 |  iteration: 13839 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 166 loss: 1.63033 acc: 0.68359 | v_loss: 1.37918 v_acc: 0.70345 |  iteration: 13840 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 167 loss: 1.44768 acc: 0.70247 | v_loss: 1.28013 v_acc: 0.72233 |  iteration: 13841 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 168 loss: 1.49317 acc: 0.69206 | v_loss: 1.30059 v_acc: 0.72135 |  iteration: 13842 teacher: 0 stage: sketch lr: 0.000376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 169 loss: 1.47770 acc: 0.69759 | v_loss: 1.46339 v_acc: 0.69303 |  iteration: 13843 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 170 loss: 1.44358 acc: 0.71224 | v_loss: 1.33587 v_acc: 0.71159 |  iteration: 13844 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 171 loss: 1.43606 acc: 0.69792 | v_loss: 1.28560 v_acc: 0.71777 |  iteration: 13845 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 172 loss: 1.44175 acc: 0.70801 | v_loss: 1.28339 v_acc: 0.71484 |  iteration: 13846 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 173 loss: 1.37844 acc: 0.71322 | v_loss: 1.43569 v_acc: 0.70540 |  iteration: 13847 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 174 loss: 1.39416 acc: 0.70801 | v_loss: 1.31260 v_acc: 0.73112 |  iteration: 13848 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 175 loss: 1.51208 acc: 0.69954 | v_loss: 1.53787 v_acc: 0.71452 |  iteration: 13849 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 176 loss: 1.40782 acc: 0.70475 | v_loss: 1.29868 v_acc: 0.69759 |  iteration: 13850 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 177 loss: 1.47306 acc: 0.69466 | v_loss: 1.28406 v_acc: 0.70443 |  iteration: 13851 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 178 loss: 1.32279 acc: 0.70475 | v_loss: 1.45188 v_acc: 0.70312 |  iteration: 13852 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 179 loss: 1.47508 acc: 0.69727 | v_loss: 1.48448 v_acc: 0.70378 |  iteration: 13853 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 180 loss: 1.42614 acc: 0.71029 | v_loss: 1.53586 v_acc: 0.68978 |  iteration: 13854 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 181 loss: 1.34798 acc: 0.71680 | v_loss: 1.46633 v_acc: 0.70638 |  iteration: 13855 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 182 loss: 1.43479 acc: 0.70085 | v_loss: 1.42416 v_acc: 0.70410 |  iteration: 13856 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 183 loss: 1.36550 acc: 0.70117 | v_loss: 1.41640 v_acc: 0.70931 |  iteration: 13857 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 184 loss: 1.48220 acc: 0.70215 | v_loss: 1.39248 v_acc: 0.70703 |  iteration: 13858 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 185 loss: 1.45613 acc: 0.69694 | v_loss: 1.25045 v_acc: 0.71875 |  iteration: 13859 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 186 loss: 1.47156 acc: 0.69922 | v_loss: 1.32592 v_acc: 0.72331 |  iteration: 13860 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 187 loss: 1.58141 acc: 0.68880 | v_loss: 1.17117 v_acc: 0.71615 |  iteration: 13861 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 188 loss: 1.42925 acc: 0.69727 | v_loss: 1.33067 v_acc: 0.71126 |  iteration: 13862 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 189 loss: 1.39771 acc: 0.70247 | v_loss: 1.49971 v_acc: 0.69987 |  iteration: 13863 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 190 loss: 1.55376 acc: 0.68978 | v_loss: 1.32608 v_acc: 0.70833 |  iteration: 13864 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 191 loss: 1.55294 acc: 0.68294 | v_loss: 1.35764 v_acc: 0.69727 |  iteration: 13865 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 192 loss: 1.45472 acc: 0.70117 | v_loss: 1.23750 v_acc: 0.71126 |  iteration: 13866 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 193 loss: 1.55323 acc: 0.69987 | v_loss: 1.25129 v_acc: 0.70345 |  iteration: 13867 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 194 loss: 1.48601 acc: 0.69694 | v_loss: 1.25137 v_acc: 0.73503 |  iteration: 13868 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 195 loss: 1.49905 acc: 0.69531 | v_loss: 1.28031 v_acc: 0.71647 |  iteration: 13869 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 196 loss: 1.39212 acc: 0.70866 | v_loss: 1.32681 v_acc: 0.75488 |  iteration: 13870 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 197 loss: 1.45977 acc: 0.69889 | v_loss: 1.26422 v_acc: 0.72005 |  iteration: 13871 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 198 loss: 1.55173 acc: 0.69727 | v_loss: 1.31326 v_acc: 0.71745 |  iteration: 13872 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 199 loss: 1.41381 acc: 0.69596 | v_loss: 1.41683 v_acc: 0.71224 |  iteration: 13873 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 200 loss: 1.37519 acc: 0.71322 | v_loss: 1.38940 v_acc: 0.72070 |  iteration: 13874 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 201 loss: 1.41976 acc: 0.70703 | v_loss: 1.48450 v_acc: 0.69954 |  iteration: 13875 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 202 loss: 1.41994 acc: 0.70898 | v_loss: 1.41525 v_acc: 0.71615 |  iteration: 13876 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 203 loss: 1.44956 acc: 0.70345 | v_loss: 1.17686 v_acc: 0.74447 |  iteration: 13877 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 204 loss: 1.44968 acc: 0.69889 | v_loss: 1.27226 v_acc: 0.70736 |  iteration: 13878 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 205 loss: 1.34226 acc: 0.70833 | v_loss: 1.51628 v_acc: 0.70280 |  iteration: 13879 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 206 loss: 1.39788 acc: 0.70410 | v_loss: 1.23818 v_acc: 0.70833 |  iteration: 13880 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 207 loss: 1.38832 acc: 0.70182 | v_loss: 1.33230 v_acc: 0.71354 |  iteration: 13881 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 208 loss: 1.37710 acc: 0.70475 | v_loss: 1.36347 v_acc: 0.69531 |  iteration: 13882 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 209 loss: 1.45650 acc: 0.70605 | v_loss: 1.29266 v_acc: 0.71680 |  iteration: 13883 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 210 loss: 1.39682 acc: 0.70801 | v_loss: 1.36548 v_acc: 0.70117 |  iteration: 13884 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 211 loss: 1.42862 acc: 0.69889 | v_loss: 1.48387 v_acc: 0.72331 |  iteration: 13885 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 212 loss: 1.40638 acc: 0.71094 | v_loss: 1.32576 v_acc: 0.72819 |  iteration: 13886 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 213 loss: 1.36084 acc: 0.71289 | v_loss: 1.44224 v_acc: 0.70508 |  iteration: 13887 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 214 loss: 1.43639 acc: 0.70085 | v_loss: 1.37313 v_acc: 0.69889 |  iteration: 13888 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 215 loss: 1.41541 acc: 0.70345 | v_loss: 1.32172 v_acc: 0.70898 |  iteration: 13889 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 216 loss: 1.45826 acc: 0.69727 | v_loss: 1.55658 v_acc: 0.68815 |  iteration: 13890 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 217 loss: 1.47632 acc: 0.69922 | v_loss: 1.30854 v_acc: 0.72005 |  iteration: 13891 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 218 loss: 1.49436 acc: 0.69694 | v_loss: 1.58268 v_acc: 0.68424 |  iteration: 13892 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 219 loss: 1.39244 acc: 0.71680 | v_loss: 1.45133 v_acc: 0.69792 |  iteration: 13893 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 220 loss: 1.46522 acc: 0.71354 | v_loss: 1.52316 v_acc: 0.69173 |  iteration: 13894 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 221 loss: 1.35268 acc: 0.72135 | v_loss: 1.37214 v_acc: 0.70020 |  iteration: 13895 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 222 loss: 1.39454 acc: 0.70638 | v_loss: 1.32215 v_acc: 0.70312 |  iteration: 13896 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 223 loss: 1.45730 acc: 0.69792 | v_loss: 1.32949 v_acc: 0.70020 |  iteration: 13897 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 224 loss: 1.45296 acc: 0.69824 | v_loss: 1.32781 v_acc: 0.71484 |  iteration: 13898 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 225 loss: 1.37319 acc: 0.71029 | v_loss: 1.53794 v_acc: 0.68978 |  iteration: 13899 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 226 loss: 1.42096 acc: 0.70605 | v_loss: 1.37756 v_acc: 0.70443 |  iteration: 13900 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 227 loss: 1.40919 acc: 0.70801 | v_loss: 1.35422 v_acc: 0.71029 |  iteration: 13901 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 228 loss: 1.40980 acc: 0.70410 | v_loss: 1.38949 v_acc: 0.71777 |  iteration: 13902 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 229 loss: 1.37559 acc: 0.70182 | v_loss: 1.26916 v_acc: 0.70638 |  iteration: 13903 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 230 loss: 1.48380 acc: 0.69076 | v_loss: 1.43196 v_acc: 0.69824 |  iteration: 13904 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 231 loss: 1.39041 acc: 0.70964 | v_loss: 1.43464 v_acc: 0.71224 |  iteration: 13905 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 232 loss: 1.43448 acc: 0.70312 | v_loss: 1.28862 v_acc: 0.71875 |  iteration: 13906 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 233 loss: 1.44393 acc: 0.69564 | v_loss: 1.25736 v_acc: 0.72754 |  iteration: 13907 teacher: 1 stage: sketch lr: 0.000375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 234 loss: 1.39869 acc: 0.70117 | v_loss: 1.37552 v_acc: 0.71875 |  iteration: 13908 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 235 loss: 1.42202 acc: 0.69759 | v_loss: 1.42108 v_acc: 0.70247 |  iteration: 13909 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 236 loss: 1.34433 acc: 0.70768 | v_loss: 1.42847 v_acc: 0.70378 |  iteration: 13910 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 237 loss: 1.39458 acc: 0.70898 | v_loss: 1.21981 v_acc: 0.71712 |  iteration: 13911 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 238 loss: 1.47497 acc: 0.70508 | v_loss: 1.39201 v_acc: 0.72786 |  iteration: 13912 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 239 loss: 1.45257 acc: 0.69564 | v_loss: 1.47429 v_acc: 0.69792 |  iteration: 13913 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 240 loss: 1.38156 acc: 0.70898 | v_loss: 1.42426 v_acc: 0.72070 |  iteration: 13914 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 241 loss: 1.52714 acc: 0.69108 | v_loss: 1.24805 v_acc: 0.72201 |  iteration: 13915 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 242 loss: 1.39752 acc: 0.70703 | v_loss: 1.19343 v_acc: 0.74023 |  iteration: 13916 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 243 loss: 1.45645 acc: 0.70020 | v_loss: 1.20775 v_acc: 0.72559 |  iteration: 13917 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 244 loss: 1.35373 acc: 0.71061 | v_loss: 1.28427 v_acc: 0.70638 |  iteration: 13918 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 245 loss: 1.41966 acc: 0.69857 | v_loss: 1.46400 v_acc: 0.70671 |  iteration: 13919 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 246 loss: 1.40325 acc: 0.70638 | v_loss: 1.27442 v_acc: 0.71549 |  iteration: 13920 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 247 loss: 1.48049 acc: 0.69596 | v_loss: 1.48453 v_acc: 0.70475 |  iteration: 13921 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 248 loss: 1.63010 acc: 0.67871 | v_loss: 1.68798 v_acc: 0.69368 |  iteration: 13922 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 249 loss: 1.40558 acc: 0.69727 | v_loss: 1.53906 v_acc: 0.70117 |  iteration: 13923 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 250 loss: 1.37294 acc: 0.70475 | v_loss: 1.29478 v_acc: 0.72363 |  iteration: 13924 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 251 loss: 1.43308 acc: 0.70638 | v_loss: 1.37330 v_acc: 0.70410 |  iteration: 13925 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 252 loss: 1.45951 acc: 0.70150 | v_loss: 1.21748 v_acc: 0.71973 |  iteration: 13926 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 253 loss: 1.37084 acc: 0.70345 | v_loss: 1.42315 v_acc: 0.70150 |  iteration: 13927 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 254 loss: 1.46840 acc: 0.69694 | v_loss: 1.35527 v_acc: 0.71029 |  iteration: 13928 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 255 loss: 1.44180 acc: 0.70150 | v_loss: 1.35574 v_acc: 0.72949 |  iteration: 13929 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 256 loss: 1.41521 acc: 0.71387 | v_loss: 1.36484 v_acc: 0.71745 |  iteration: 13930 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 257 loss: 1.43903 acc: 0.69987 | v_loss: 1.37206 v_acc: 0.70378 |  iteration: 13931 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 258 loss: 1.46512 acc: 0.70410 | v_loss: 1.28482 v_acc: 0.72201 |  iteration: 13932 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 259 loss: 1.48945 acc: 0.69629 | v_loss: 1.30622 v_acc: 0.72005 |  iteration: 13933 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 260 loss: 1.46199 acc: 0.69434 | v_loss: 1.46460 v_acc: 0.69303 |  iteration: 13934 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 261 loss: 1.45940 acc: 0.69727 | v_loss: 1.33191 v_acc: 0.71159 |  iteration: 13935 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 262 loss: 1.49852 acc: 0.69173 | v_loss: 1.28800 v_acc: 0.71549 |  iteration: 13936 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 263 loss: 1.38823 acc: 0.70605 | v_loss: 1.27314 v_acc: 0.71973 |  iteration: 13937 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 264 loss: 1.46194 acc: 0.70768 | v_loss: 1.43341 v_acc: 0.70540 |  iteration: 13938 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 265 loss: 1.40776 acc: 0.71029 | v_loss: 1.31102 v_acc: 0.73047 |  iteration: 13939 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 266 loss: 1.49354 acc: 0.70508 | v_loss: 1.53881 v_acc: 0.71452 |  iteration: 13940 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 267 loss: 1.44311 acc: 0.69759 | v_loss: 1.29233 v_acc: 0.69759 |  iteration: 13941 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 268 loss: 1.49850 acc: 0.70150 | v_loss: 1.28153 v_acc: 0.70443 |  iteration: 13942 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 269 loss: 1.37292 acc: 0.70085 | v_loss: 1.42251 v_acc: 0.70280 |  iteration: 13943 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 270 loss: 1.46646 acc: 0.69564 | v_loss: 1.45727 v_acc: 0.70671 |  iteration: 13944 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 271 loss: 1.49261 acc: 0.69694 | v_loss: 1.50288 v_acc: 0.69108 |  iteration: 13945 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 272 loss: 1.38014 acc: 0.70378 | v_loss: 1.47214 v_acc: 0.70508 |  iteration: 13946 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 273 loss: 1.38865 acc: 0.70833 | v_loss: 1.41045 v_acc: 0.70866 |  iteration: 13947 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 274 loss: 1.59782 acc: 0.69596 | v_loss: 1.39819 v_acc: 0.70573 |  iteration: 13948 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 275 loss: 1.42498 acc: 0.69889 | v_loss: 1.43395 v_acc: 0.70410 |  iteration: 13949 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 276 loss: 1.45294 acc: 0.70475 | v_loss: 1.28313 v_acc: 0.71224 |  iteration: 13950 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 277 loss: 1.45990 acc: 0.70020 | v_loss: 1.31764 v_acc: 0.72396 |  iteration: 13951 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 278 loss: 1.45505 acc: 0.69922 | v_loss: 1.21574 v_acc: 0.70638 |  iteration: 13952 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 279 loss: 1.53644 acc: 0.69629 | v_loss: 1.34887 v_acc: 0.70247 |  iteration: 13953 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 280 loss: 1.42431 acc: 0.70150 | v_loss: 1.49915 v_acc: 0.70020 |  iteration: 13954 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 281 loss: 1.51438 acc: 0.69889 | v_loss: 1.32520 v_acc: 0.70703 |  iteration: 13955 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 282 loss: 1.36933 acc: 0.71094 | v_loss: 1.33396 v_acc: 0.70247 |  iteration: 13956 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 283 loss: 1.32809 acc: 0.70508 | v_loss: 1.25004 v_acc: 0.71647 |  iteration: 13957 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 284 loss: 1.42605 acc: 0.70768 | v_loss: 1.24455 v_acc: 0.70345 |  iteration: 13958 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 285 loss: 1.45779 acc: 0.70605 | v_loss: 1.23982 v_acc: 0.73600 |  iteration: 13959 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 286 loss: 1.42366 acc: 0.69792 | v_loss: 1.26832 v_acc: 0.72168 |  iteration: 13960 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 287 loss: 1.36852 acc: 0.70020 | v_loss: 1.35597 v_acc: 0.73177 |  iteration: 13961 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 288 loss: 1.40784 acc: 0.70996 | v_loss: 1.26866 v_acc: 0.72298 |  iteration: 13962 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 289 loss: 1.34861 acc: 0.70508 | v_loss: 1.31466 v_acc: 0.72005 |  iteration: 13963 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 290 loss: 1.38270 acc: 0.71517 | v_loss: 1.43056 v_acc: 0.71224 |  iteration: 13964 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 291 loss: 1.35015 acc: 0.70573 | v_loss: 1.41402 v_acc: 0.72070 |  iteration: 13965 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 292 loss: 1.56956 acc: 0.69010 | v_loss: 1.49449 v_acc: 0.69954 |  iteration: 13966 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 293 loss: 1.50468 acc: 0.69564 | v_loss: 1.43681 v_acc: 0.71615 |  iteration: 13967 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 294 loss: 1.52071 acc: 0.69987 | v_loss: 1.18593 v_acc: 0.74544 |  iteration: 13968 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 295 loss: 1.46969 acc: 0.69564 | v_loss: 1.25258 v_acc: 0.70931 |  iteration: 13969 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 296 loss: 1.51214 acc: 0.71061 | v_loss: 1.52436 v_acc: 0.70247 |  iteration: 13970 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 297 loss: 1.53735 acc: 0.69010 | v_loss: 1.22430 v_acc: 0.70866 |  iteration: 13971 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 298 loss: 1.36554 acc: 0.70573 | v_loss: 1.32013 v_acc: 0.71159 |  iteration: 13972 teacher: 0 stage: sketch lr: 0.000374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 299 loss: 1.50942 acc: 0.69108 | v_loss: 1.36205 v_acc: 0.69336 |  iteration: 13973 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 300 loss: 1.41179 acc: 0.70540 | v_loss: 1.29765 v_acc: 0.71191 |  iteration: 13974 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 301 loss: 1.38436 acc: 0.71191 | v_loss: 1.36735 v_acc: 0.69629 |  iteration: 13975 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 302 loss: 1.32603 acc: 0.71224 | v_loss: 1.46957 v_acc: 0.70931 |  iteration: 13976 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 303 loss: 1.35598 acc: 0.71875 | v_loss: 1.31704 v_acc: 0.72363 |  iteration: 13977 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 304 loss: 1.50623 acc: 0.69434 | v_loss: 1.46585 v_acc: 0.70117 |  iteration: 13978 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 305 loss: 1.56010 acc: 0.69824 | v_loss: 1.36169 v_acc: 0.70085 |  iteration: 13979 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 306 loss: 1.46535 acc: 0.69694 | v_loss: 1.33656 v_acc: 0.70866 |  iteration: 13980 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 307 loss: 1.42337 acc: 0.70052 | v_loss: 1.55463 v_acc: 0.68815 |  iteration: 13981 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 308 loss: 1.39696 acc: 0.70540 | v_loss: 1.30213 v_acc: 0.72005 |  iteration: 13982 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 309 loss: 1.51673 acc: 0.70247 | v_loss: 1.59511 v_acc: 0.68424 |  iteration: 13983 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 310 loss: 1.43244 acc: 0.69596 | v_loss: 1.45535 v_acc: 0.69792 |  iteration: 13984 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 311 loss: 1.51237 acc: 0.69108 | v_loss: 1.50609 v_acc: 0.68978 |  iteration: 13985 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 312 loss: 1.41643 acc: 0.70150 | v_loss: 1.37950 v_acc: 0.69987 |  iteration: 13986 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 313 loss: 1.40996 acc: 0.70540 | v_loss: 1.31069 v_acc: 0.70703 |  iteration: 13987 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 314 loss: 1.47883 acc: 0.70020 | v_loss: 1.32611 v_acc: 0.70605 |  iteration: 13988 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 315 loss: 1.39983 acc: 0.70768 | v_loss: 1.32952 v_acc: 0.71647 |  iteration: 13989 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 316 loss: 1.40974 acc: 0.71224 | v_loss: 1.54396 v_acc: 0.68945 |  iteration: 13990 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 317 loss: 1.43243 acc: 0.70475 | v_loss: 1.38461 v_acc: 0.70638 |  iteration: 13991 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 318 loss: 1.42810 acc: 0.70378 | v_loss: 1.34628 v_acc: 0.71029 |  iteration: 13992 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 319 loss: 1.35314 acc: 0.70898 | v_loss: 1.38624 v_acc: 0.71680 |  iteration: 13993 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 320 loss: 1.40089 acc: 0.70573 | v_loss: 1.27466 v_acc: 0.70573 |  iteration: 13994 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 321 loss: 1.46770 acc: 0.69759 | v_loss: 1.44423 v_acc: 0.69792 |  iteration: 13995 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 322 loss: 1.50946 acc: 0.69076 | v_loss: 1.44054 v_acc: 0.71289 |  iteration: 13996 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 323 loss: 1.46446 acc: 0.70052 | v_loss: 1.29085 v_acc: 0.71875 |  iteration: 13997 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 324 loss: 1.51471 acc: 0.69434 | v_loss: 1.26492 v_acc: 0.72754 |  iteration: 13998 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 325 loss: 1.40283 acc: 0.71029 | v_loss: 1.38535 v_acc: 0.72266 |  iteration: 13999 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 326 loss: 1.42240 acc: 0.70150 | v_loss: 1.41792 v_acc: 0.70410 |  iteration: 14000 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 327 loss: 1.50762 acc: 0.69661 | v_loss: 1.42233 v_acc: 0.70833 |  iteration: 14001 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 328 loss: 1.46764 acc: 0.69954 | v_loss: 1.21906 v_acc: 0.72591 |  iteration: 14002 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 329 loss: 1.46203 acc: 0.70443 | v_loss: 1.38018 v_acc: 0.73112 |  iteration: 14003 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 330 loss: 1.40394 acc: 0.70247 | v_loss: 1.46619 v_acc: 0.69792 |  iteration: 14004 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 331 loss: 1.46664 acc: 0.70150 | v_loss: 1.41952 v_acc: 0.72038 |  iteration: 14005 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 332 loss: 1.43143 acc: 0.70801 | v_loss: 1.26117 v_acc: 0.71973 |  iteration: 14006 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 333 loss: 1.43475 acc: 0.69694 | v_loss: 1.21044 v_acc: 0.73503 |  iteration: 14007 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 334 loss: 1.52271 acc: 0.69596 | v_loss: 1.21414 v_acc: 0.72917 |  iteration: 14008 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 335 loss: 1.43728 acc: 0.70475 | v_loss: 1.29899 v_acc: 0.70898 |  iteration: 14009 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 336 loss: 1.52614 acc: 0.69368 | v_loss: 1.45669 v_acc: 0.69629 |  iteration: 14010 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 337 loss: 1.49015 acc: 0.69466 | v_loss: 1.28261 v_acc: 0.71126 |  iteration: 14011 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 338 loss: 1.44322 acc: 0.70573 | v_loss: 1.44774 v_acc: 0.71647 |  iteration: 14012 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 339 loss: 1.47942 acc: 0.69987 | v_loss: 1.65844 v_acc: 0.69499 |  iteration: 14013 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 340 loss: 1.35581 acc: 0.71615 | v_loss: 1.51920 v_acc: 0.70117 |  iteration: 14014 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 341 loss: 1.46708 acc: 0.70703 | v_loss: 1.29531 v_acc: 0.72526 |  iteration: 14015 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 342 loss: 1.43368 acc: 0.70312 | v_loss: 1.37679 v_acc: 0.70410 |  iteration: 14016 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 343 loss: 1.29415 acc: 0.71061 | v_loss: 1.22491 v_acc: 0.72038 |  iteration: 14017 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 344 loss: 1.40662 acc: 0.70605 | v_loss: 1.44329 v_acc: 0.69889 |  iteration: 14018 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 345 loss: 1.36082 acc: 0.70671 | v_loss: 1.36201 v_acc: 0.70736 |  iteration: 14019 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 346 loss: 1.48457 acc: 0.69661 | v_loss: 1.36509 v_acc: 0.73079 |  iteration: 14020 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 347 loss: 1.43970 acc: 0.70605 | v_loss: 1.36862 v_acc: 0.71908 |  iteration: 14021 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 348 loss: 1.39400 acc: 0.70475 | v_loss: 1.37927 v_acc: 0.70964 |  iteration: 14022 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 349 loss: 1.35675 acc: 0.71061 | v_loss: 1.27821 v_acc: 0.72526 |  iteration: 14023 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 350 loss: 1.47081 acc: 0.69792 | v_loss: 1.28712 v_acc: 0.72298 |  iteration: 14024 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 351 loss: 1.40839 acc: 0.69922 | v_loss: 1.44540 v_acc: 0.69043 |  iteration: 14025 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 352 loss: 1.45515 acc: 0.69759 | v_loss: 1.33248 v_acc: 0.71191 |  iteration: 14026 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 353 loss: 1.50629 acc: 0.69368 | v_loss: 1.29298 v_acc: 0.71842 |  iteration: 14027 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 354 loss: 1.38806 acc: 0.70215 | v_loss: 1.28906 v_acc: 0.71517 |  iteration: 14028 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 355 loss: 1.37730 acc: 0.71029 | v_loss: 1.44003 v_acc: 0.70475 |  iteration: 14029 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 356 loss: 1.46454 acc: 0.69368 | v_loss: 1.31795 v_acc: 0.73210 |  iteration: 14030 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 357 loss: 1.31776 acc: 0.71745 | v_loss: 1.55501 v_acc: 0.71452 |  iteration: 14031 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 358 loss: 1.43726 acc: 0.70085 | v_loss: 1.28109 v_acc: 0.69531 |  iteration: 14032 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 359 loss: 1.45915 acc: 0.69010 | v_loss: 1.27724 v_acc: 0.70117 |  iteration: 14033 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 360 loss: 1.40079 acc: 0.70117 | v_loss: 1.46002 v_acc: 0.70312 |  iteration: 14034 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 361 loss: 1.39134 acc: 0.69824 | v_loss: 1.48720 v_acc: 0.70378 |  iteration: 14035 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 362 loss: 1.37306 acc: 0.71452 | v_loss: 1.53084 v_acc: 0.68978 |  iteration: 14036 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 363 loss: 1.41745 acc: 0.71322 | v_loss: 1.47283 v_acc: 0.70638 |  iteration: 14037 teacher: 1 stage: sketch lr: 0.000373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 364 loss: 1.49010 acc: 0.69792 | v_loss: 1.42247 v_acc: 0.70410 |  iteration: 14038 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 365 loss: 1.28400 acc: 0.70736 | v_loss: 1.40697 v_acc: 0.70768 |  iteration: 14039 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 366 loss: 1.51505 acc: 0.69889 | v_loss: 1.39981 v_acc: 0.70475 |  iteration: 14040 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 367 loss: 1.47684 acc: 0.70215 | v_loss: 1.26208 v_acc: 0.71354 |  iteration: 14041 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 368 loss: 1.48971 acc: 0.69238 | v_loss: 1.32280 v_acc: 0.72461 |  iteration: 14042 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 369 loss: 1.37957 acc: 0.69987 | v_loss: 1.17612 v_acc: 0.71517 |  iteration: 14043 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 370 loss: 1.56912 acc: 0.69401 | v_loss: 1.33817 v_acc: 0.70410 |  iteration: 14044 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 371 loss: 1.36743 acc: 0.71126 | v_loss: 1.50025 v_acc: 0.69987 |  iteration: 14045 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 372 loss: 1.47338 acc: 0.69596 | v_loss: 1.33077 v_acc: 0.70638 |  iteration: 14046 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 373 loss: 1.35954 acc: 0.71191 | v_loss: 1.34786 v_acc: 0.69629 |  iteration: 14047 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 374 loss: 1.46335 acc: 0.69759 | v_loss: 1.25509 v_acc: 0.70508 |  iteration: 14048 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 375 loss: 1.40056 acc: 0.70671 | v_loss: 1.24815 v_acc: 0.70605 |  iteration: 14049 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 376 loss: 1.39021 acc: 0.70638 | v_loss: 1.24320 v_acc: 0.73861 |  iteration: 14050 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 377 loss: 1.40356 acc: 0.70052 | v_loss: 1.27409 v_acc: 0.71810 |  iteration: 14051 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 378 loss: 1.47071 acc: 0.69824 | v_loss: 1.33900 v_acc: 0.73079 |  iteration: 14052 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 379 loss: 1.52066 acc: 0.69499 | v_loss: 1.25846 v_acc: 0.72363 |  iteration: 14053 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 380 loss: 1.47208 acc: 0.70638 | v_loss: 1.29713 v_acc: 0.71908 |  iteration: 14054 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 381 loss: 1.43849 acc: 0.69759 | v_loss: 1.39388 v_acc: 0.71289 |  iteration: 14055 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 382 loss: 1.39750 acc: 0.70508 | v_loss: 1.38502 v_acc: 0.72428 |  iteration: 14056 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 383 loss: 1.46773 acc: 0.69857 | v_loss: 1.49425 v_acc: 0.69954 |  iteration: 14057 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 384 loss: 1.46549 acc: 0.69499 | v_loss: 1.40972 v_acc: 0.71615 |  iteration: 14058 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 385 loss: 1.41006 acc: 0.70540 | v_loss: 1.17569 v_acc: 0.74544 |  iteration: 14059 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 386 loss: 1.36645 acc: 0.70996 | v_loss: 1.26120 v_acc: 0.70931 |  iteration: 14060 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 387 loss: 1.37409 acc: 0.70671 | v_loss: 1.51823 v_acc: 0.70247 |  iteration: 14061 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 388 loss: 1.44778 acc: 0.69889 | v_loss: 1.21439 v_acc: 0.70866 |  iteration: 14062 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 389 loss: 1.33775 acc: 0.71712 | v_loss: 1.32729 v_acc: 0.71159 |  iteration: 14063 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 390 loss: 1.50563 acc: 0.69987 | v_loss: 1.37780 v_acc: 0.69141 |  iteration: 14064 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 391 loss: 1.45178 acc: 0.70378 | v_loss: 1.29612 v_acc: 0.71094 |  iteration: 14065 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 392 loss: 1.44407 acc: 0.69954 | v_loss: 1.36808 v_acc: 0.69499 |  iteration: 14066 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 393 loss: 1.42393 acc: 0.69889 | v_loss: 1.50956 v_acc: 0.71517 |  iteration: 14067 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 394 loss: 1.36373 acc: 0.71322 | v_loss: 1.32888 v_acc: 0.72689 |  iteration: 14068 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 395 loss: 1.50516 acc: 0.69499 | v_loss: 1.45931 v_acc: 0.70443 |  iteration: 14069 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 396 loss: 1.52905 acc: 0.71354 | v_loss: 1.37825 v_acc: 0.69922 |  iteration: 14070 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 397 loss: 1.42549 acc: 0.69694 | v_loss: 1.31890 v_acc: 0.70898 |  iteration: 14071 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 398 loss: 1.46976 acc: 0.70833 | v_loss: 1.56174 v_acc: 0.68815 |  iteration: 14072 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 399 loss: 1.51677 acc: 0.69759 | v_loss: 1.29401 v_acc: 0.72038 |  iteration: 14073 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 400 loss: 1.47750 acc: 0.70020 | v_loss: 1.59598 v_acc: 0.68392 |  iteration: 14074 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 401 loss: 1.44832 acc: 0.70540 | v_loss: 1.48655 v_acc: 0.69759 |  iteration: 14075 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 402 loss: 1.42826 acc: 0.69954 | v_loss: 1.51502 v_acc: 0.69076 |  iteration: 14076 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 403 loss: 1.52157 acc: 0.69466 | v_loss: 1.39474 v_acc: 0.69759 |  iteration: 14077 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 404 loss: 1.52898 acc: 0.69434 | v_loss: 1.32733 v_acc: 0.70215 |  iteration: 14078 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 405 loss: 1.43576 acc: 0.70866 | v_loss: 1.33939 v_acc: 0.69759 |  iteration: 14079 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 406 loss: 1.44416 acc: 0.69596 | v_loss: 1.33183 v_acc: 0.71549 |  iteration: 14080 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 407 loss: 1.41961 acc: 0.71126 | v_loss: 1.50779 v_acc: 0.69401 |  iteration: 14081 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 408 loss: 1.40266 acc: 0.69922 | v_loss: 1.36956 v_acc: 0.69922 |  iteration: 14082 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 409 loss: 1.31137 acc: 0.71875 | v_loss: 1.36961 v_acc: 0.71126 |  iteration: 14083 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 410 loss: 1.38865 acc: 0.69694 | v_loss: 1.39790 v_acc: 0.71419 |  iteration: 14084 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 411 loss: 1.44809 acc: 0.70020 | v_loss: 1.27357 v_acc: 0.70573 |  iteration: 14085 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 412 loss: 1.38396 acc: 0.70312 | v_loss: 1.43018 v_acc: 0.69792 |  iteration: 14086 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 413 loss: 1.44029 acc: 0.69629 | v_loss: 1.43010 v_acc: 0.71289 |  iteration: 14087 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 414 loss: 1.41917 acc: 0.70638 | v_loss: 1.28329 v_acc: 0.71875 |  iteration: 14088 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 415 loss: 1.38454 acc: 0.70540 | v_loss: 1.25694 v_acc: 0.72591 |  iteration: 14089 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 416 loss: 1.48839 acc: 0.69141 | v_loss: 1.38202 v_acc: 0.72266 |  iteration: 14090 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 417 loss: 1.48012 acc: 0.69792 | v_loss: 1.41833 v_acc: 0.70312 |  iteration: 14091 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 418 loss: 1.45835 acc: 0.69792 | v_loss: 1.42146 v_acc: 0.70475 |  iteration: 14092 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 419 loss: 1.58019 acc: 0.69076 | v_loss: 1.23673 v_acc: 0.71452 |  iteration: 14093 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 420 loss: 1.57399 acc: 0.69010 | v_loss: 1.38080 v_acc: 0.72819 |  iteration: 14094 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 421 loss: 1.58556 acc: 0.68750 | v_loss: 1.45767 v_acc: 0.70052 |  iteration: 14095 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 422 loss: 1.47968 acc: 0.69694 | v_loss: 1.40151 v_acc: 0.72233 |  iteration: 14096 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 423 loss: 1.39611 acc: 0.70345 | v_loss: 1.26568 v_acc: 0.71647 |  iteration: 14097 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 424 loss: 1.42550 acc: 0.69889 | v_loss: 1.22479 v_acc: 0.72819 |  iteration: 14098 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 425 loss: 1.43535 acc: 0.70410 | v_loss: 1.21948 v_acc: 0.72559 |  iteration: 14099 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 426 loss: 1.47083 acc: 0.70117 | v_loss: 1.30043 v_acc: 0.70540 |  iteration: 14100 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 427 loss: 1.32866 acc: 0.71191 | v_loss: 1.45443 v_acc: 0.69466 |  iteration: 14101 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 428 loss: 1.53638 acc: 0.69596 | v_loss: 1.27172 v_acc: 0.71484 |  iteration: 14102 teacher: 1 stage: sketch lr: 0.000372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 429 loss: 1.49281 acc: 0.69727 | v_loss: 1.42271 v_acc: 0.72949 |  iteration: 14103 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 430 loss: 1.38221 acc: 0.70540 | v_loss: 1.66940 v_acc: 0.69173 |  iteration: 14104 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 431 loss: 1.40662 acc: 0.70215 | v_loss: 1.53009 v_acc: 0.69987 |  iteration: 14105 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 432 loss: 1.51187 acc: 0.69303 | v_loss: 1.29340 v_acc: 0.72298 |  iteration: 14106 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 433 loss: 1.40229 acc: 0.71354 | v_loss: 1.37689 v_acc: 0.70410 |  iteration: 14107 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 434 loss: 1.39516 acc: 0.70508 | v_loss: 1.21326 v_acc: 0.71973 |  iteration: 14108 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 435 loss: 1.54364 acc: 0.68783 | v_loss: 1.41952 v_acc: 0.70150 |  iteration: 14109 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 436 loss: 1.33491 acc: 0.71159 | v_loss: 1.35887 v_acc: 0.71810 |  iteration: 14110 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 437 loss: 1.43394 acc: 0.70736 | v_loss: 1.35846 v_acc: 0.73014 |  iteration: 14111 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 438 loss: 1.35777 acc: 0.71484 | v_loss: 1.36740 v_acc: 0.71973 |  iteration: 14112 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 439 loss: 1.43246 acc: 0.70410 | v_loss: 1.37880 v_acc: 0.70964 |  iteration: 14113 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 440 loss: 1.46066 acc: 0.70085 | v_loss: 1.27729 v_acc: 0.72493 |  iteration: 14114 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 441 loss: 1.36744 acc: 0.70475 | v_loss: 1.28626 v_acc: 0.72038 |  iteration: 14115 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 442 loss: 1.41379 acc: 0.70931 | v_loss: 1.46129 v_acc: 0.69368 |  iteration: 14116 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 443 loss: 1.44612 acc: 0.69922 | v_loss: 1.33131 v_acc: 0.71452 |  iteration: 14117 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 444 loss: 1.48015 acc: 0.69954 | v_loss: 1.30009 v_acc: 0.71777 |  iteration: 14118 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 445 loss: 1.52768 acc: 0.69954 | v_loss: 1.29395 v_acc: 0.71484 |  iteration: 14119 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 446 loss: 1.31341 acc: 0.71387 | v_loss: 1.44543 v_acc: 0.70540 |  iteration: 14120 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 447 loss: 1.38978 acc: 0.70801 | v_loss: 1.31557 v_acc: 0.73047 |  iteration: 14121 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 448 loss: 1.47394 acc: 0.69564 | v_loss: 1.54935 v_acc: 0.71452 |  iteration: 14122 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 449 loss: 1.49243 acc: 0.70703 | v_loss: 1.27909 v_acc: 0.69759 |  iteration: 14123 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 450 loss: 1.42234 acc: 0.70085 | v_loss: 1.27132 v_acc: 0.70443 |  iteration: 14124 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 451 loss: 1.49891 acc: 0.69694 | v_loss: 1.43937 v_acc: 0.70312 |  iteration: 14125 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 452 loss: 1.41707 acc: 0.70247 | v_loss: 1.46863 v_acc: 0.70378 |  iteration: 14126 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 453 loss: 1.37930 acc: 0.70931 | v_loss: 1.51465 v_acc: 0.68978 |  iteration: 14127 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 454 loss: 1.41598 acc: 0.71029 | v_loss: 1.46618 v_acc: 0.70638 |  iteration: 14128 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 455 loss: 1.42135 acc: 0.70215 | v_loss: 1.42136 v_acc: 0.70410 |  iteration: 14129 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 456 loss: 1.45147 acc: 0.70736 | v_loss: 1.40493 v_acc: 0.70768 |  iteration: 14130 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 457 loss: 1.37122 acc: 0.71419 | v_loss: 1.40738 v_acc: 0.70475 |  iteration: 14131 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 458 loss: 1.45659 acc: 0.70410 | v_loss: 1.27007 v_acc: 0.71354 |  iteration: 14132 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 459 loss: 1.41243 acc: 0.70280 | v_loss: 1.31922 v_acc: 0.72461 |  iteration: 14133 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 460 loss: 1.46596 acc: 0.70312 | v_loss: 1.20013 v_acc: 0.71582 |  iteration: 14134 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 461 loss: 1.45894 acc: 0.71191 | v_loss: 1.34773 v_acc: 0.70475 |  iteration: 14135 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 462 loss: 1.48573 acc: 0.69108 | v_loss: 1.49670 v_acc: 0.69759 |  iteration: 14136 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 463 loss: 1.34759 acc: 0.70898 | v_loss: 1.33393 v_acc: 0.70540 |  iteration: 14137 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 464 loss: 1.40188 acc: 0.70443 | v_loss: 1.35272 v_acc: 0.69694 |  iteration: 14138 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 465 loss: 1.44327 acc: 0.70182 | v_loss: 1.26460 v_acc: 0.70345 |  iteration: 14139 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 466 loss: 1.40178 acc: 0.70345 | v_loss: 1.25242 v_acc: 0.70280 |  iteration: 14140 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 467 loss: 1.34424 acc: 0.70964 | v_loss: 1.24327 v_acc: 0.74219 |  iteration: 14141 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 468 loss: 1.53940 acc: 0.69108 | v_loss: 1.27457 v_acc: 0.71842 |  iteration: 14142 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 469 loss: 1.49370 acc: 0.70898 | v_loss: 1.37089 v_acc: 0.73112 |  iteration: 14143 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 470 loss: 1.48707 acc: 0.69108 | v_loss: 1.26916 v_acc: 0.71940 |  iteration: 14144 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 471 loss: 1.48012 acc: 0.70345 | v_loss: 1.31464 v_acc: 0.72266 |  iteration: 14145 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 472 loss: 1.47088 acc: 0.70410 | v_loss: 1.43140 v_acc: 0.71354 |  iteration: 14146 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 473 loss: 1.38414 acc: 0.70085 | v_loss: 1.40818 v_acc: 0.72428 |  iteration: 14147 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 474 loss: 1.47379 acc: 0.70117 | v_loss: 1.48354 v_acc: 0.70182 |  iteration: 14148 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 475 loss: 1.41906 acc: 0.70768 | v_loss: 1.43401 v_acc: 0.71777 |  iteration: 14149 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 476 loss: 1.51840 acc: 0.71029 | v_loss: 1.18318 v_acc: 0.74447 |  iteration: 14150 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 477 loss: 1.54885 acc: 0.68848 | v_loss: 1.25877 v_acc: 0.71322 |  iteration: 14151 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 478 loss: 1.41426 acc: 0.70345 | v_loss: 1.51770 v_acc: 0.70247 |  iteration: 14152 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 479 loss: 1.40888 acc: 0.70768 | v_loss: 1.23734 v_acc: 0.70833 |  iteration: 14153 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 480 loss: 1.41981 acc: 0.70508 | v_loss: 1.32299 v_acc: 0.71191 |  iteration: 14154 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 481 loss: 1.40804 acc: 0.70117 | v_loss: 1.36549 v_acc: 0.69076 |  iteration: 14155 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 482 loss: 1.50050 acc: 0.69564 | v_loss: 1.31812 v_acc: 0.70801 |  iteration: 14156 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 483 loss: 1.34837 acc: 0.70312 | v_loss: 1.37019 v_acc: 0.69271 |  iteration: 14157 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 484 loss: 1.39192 acc: 0.70801 | v_loss: 1.46463 v_acc: 0.70866 |  iteration: 14158 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 485 loss: 1.40782 acc: 0.70540 | v_loss: 1.31179 v_acc: 0.72070 |  iteration: 14159 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 486 loss: 1.50456 acc: 0.68945 | v_loss: 1.43963 v_acc: 0.70280 |  iteration: 14160 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 487 loss: 1.54493 acc: 0.70215 | v_loss: 1.37484 v_acc: 0.69922 |  iteration: 14161 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 488 loss: 1.44358 acc: 0.70410 | v_loss: 1.32398 v_acc: 0.70508 |  iteration: 14162 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 489 loss: 1.45679 acc: 0.70020 | v_loss: 1.56614 v_acc: 0.68555 |  iteration: 14163 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 490 loss: 1.52754 acc: 0.69401 | v_loss: 1.30304 v_acc: 0.72103 |  iteration: 14164 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 491 loss: 1.48743 acc: 0.69238 | v_loss: 1.60821 v_acc: 0.67871 |  iteration: 14165 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 492 loss: 1.48059 acc: 0.69857 | v_loss: 1.46905 v_acc: 0.69661 |  iteration: 14166 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 493 loss: 1.52589 acc: 0.69043 | v_loss: 1.53679 v_acc: 0.69238 |  iteration: 14167 teacher: 1 stage: sketch lr: 0.000371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 494 loss: 1.40621 acc: 0.71191 | v_loss: 1.37071 v_acc: 0.70182 |  iteration: 14168 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 495 loss: 1.37396 acc: 0.71159 | v_loss: 1.33124 v_acc: 0.70638 |  iteration: 14169 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 496 loss: 1.46227 acc: 0.70345 | v_loss: 1.32875 v_acc: 0.70020 |  iteration: 14170 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 497 loss: 1.51657 acc: 0.69824 | v_loss: 1.32749 v_acc: 0.71484 |  iteration: 14171 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 498 loss: 1.34272 acc: 0.70703 | v_loss: 1.52263 v_acc: 0.68978 |  iteration: 14172 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 499 loss: 1.49835 acc: 0.69531 | v_loss: 1.37780 v_acc: 0.70443 |  iteration: 14173 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 500 loss: 1.39522 acc: 0.70410 | v_loss: 1.36895 v_acc: 0.71029 |  iteration: 14174 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 501 loss: 1.42117 acc: 0.69922 | v_loss: 1.38166 v_acc: 0.71680 |  iteration: 14175 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 502 loss: 1.35315 acc: 0.71322 | v_loss: 1.28150 v_acc: 0.70573 |  iteration: 14176 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 503 loss: 1.33783 acc: 0.71908 | v_loss: 1.43967 v_acc: 0.69792 |  iteration: 14177 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 504 loss: 1.31472 acc: 0.71191 | v_loss: 1.43347 v_acc: 0.71289 |  iteration: 14178 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 505 loss: 1.46299 acc: 0.70215 | v_loss: 1.30121 v_acc: 0.71875 |  iteration: 14179 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 506 loss: 1.39648 acc: 0.70801 | v_loss: 1.25105 v_acc: 0.72754 |  iteration: 14180 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 507 loss: 1.47579 acc: 0.70931 | v_loss: 1.37716 v_acc: 0.71940 |  iteration: 14181 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 508 loss: 1.45729 acc: 0.70931 | v_loss: 1.42905 v_acc: 0.70345 |  iteration: 14182 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 509 loss: 1.41021 acc: 0.70247 | v_loss: 1.43626 v_acc: 0.70410 |  iteration: 14183 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 510 loss: 1.46710 acc: 0.70085 | v_loss: 1.22320 v_acc: 0.71712 |  iteration: 14184 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 511 loss: 1.44886 acc: 0.70638 | v_loss: 1.38980 v_acc: 0.72786 |  iteration: 14185 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 512 loss: 1.37231 acc: 0.70736 | v_loss: 1.47814 v_acc: 0.69792 |  iteration: 14186 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 513 loss: 1.35063 acc: 0.70410 | v_loss: 1.43536 v_acc: 0.72266 |  iteration: 14187 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 514 loss: 1.41323 acc: 0.70964 | v_loss: 1.25278 v_acc: 0.72038 |  iteration: 14188 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 515 loss: 1.29379 acc: 0.71126 | v_loss: 1.19846 v_acc: 0.74023 |  iteration: 14189 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 516 loss: 1.42388 acc: 0.69564 | v_loss: 1.21101 v_acc: 0.72559 |  iteration: 14190 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 517 loss: 1.42393 acc: 0.69010 | v_loss: 1.27404 v_acc: 0.70638 |  iteration: 14191 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 518 loss: 1.48922 acc: 0.69987 | v_loss: 1.46421 v_acc: 0.70052 |  iteration: 14192 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 519 loss: 1.50814 acc: 0.69173 | v_loss: 1.27658 v_acc: 0.71452 |  iteration: 14193 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 520 loss: 1.43292 acc: 0.70312 | v_loss: 1.43707 v_acc: 0.71615 |  iteration: 14194 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 521 loss: 1.35630 acc: 0.71224 | v_loss: 1.67428 v_acc: 0.69368 |  iteration: 14195 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 522 loss: 1.41441 acc: 0.70020 | v_loss: 1.53323 v_acc: 0.70117 |  iteration: 14196 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 523 loss: 1.45747 acc: 0.69596 | v_loss: 1.29312 v_acc: 0.72363 |  iteration: 14197 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 524 loss: 1.38922 acc: 0.71322 | v_loss: 1.37133 v_acc: 0.70410 |  iteration: 14198 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 525 loss: 1.31793 acc: 0.71029 | v_loss: 1.22289 v_acc: 0.72005 |  iteration: 14199 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 526 loss: 1.39199 acc: 0.71322 | v_loss: 1.42833 v_acc: 0.70150 |  iteration: 14200 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 527 loss: 1.37395 acc: 0.70605 | v_loss: 1.35199 v_acc: 0.70964 |  iteration: 14201 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 528 loss: 1.42587 acc: 0.69727 | v_loss: 1.35629 v_acc: 0.73079 |  iteration: 14202 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 529 loss: 1.35111 acc: 0.70931 | v_loss: 1.36516 v_acc: 0.71777 |  iteration: 14203 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 530 loss: 1.38611 acc: 0.70085 | v_loss: 1.37454 v_acc: 0.70410 |  iteration: 14204 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 531 loss: 1.33811 acc: 0.70931 | v_loss: 1.28401 v_acc: 0.72233 |  iteration: 14205 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 532 loss: 1.40872 acc: 0.70410 | v_loss: 1.30568 v_acc: 0.72103 |  iteration: 14206 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 533 loss: 1.41205 acc: 0.70182 | v_loss: 1.49778 v_acc: 0.69043 |  iteration: 14207 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 534 loss: 1.31284 acc: 0.70703 | v_loss: 1.33190 v_acc: 0.70898 |  iteration: 14208 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 535 loss: 1.39874 acc: 0.70540 | v_loss: 1.30339 v_acc: 0.71354 |  iteration: 14209 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 536 loss: 1.37114 acc: 0.70605 | v_loss: 1.29444 v_acc: 0.71940 |  iteration: 14210 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 537 loss: 1.36297 acc: 0.70052 | v_loss: 1.43947 v_acc: 0.70573 |  iteration: 14211 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 538 loss: 1.42253 acc: 0.70247 | v_loss: 1.31217 v_acc: 0.73112 |  iteration: 14212 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 539 loss: 1.49594 acc: 0.70020 | v_loss: 1.55876 v_acc: 0.71452 |  iteration: 14213 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 540 loss: 1.48586 acc: 0.69857 | v_loss: 1.27651 v_acc: 0.69759 |  iteration: 14214 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 541 loss: 1.48809 acc: 0.69596 | v_loss: 1.27512 v_acc: 0.70443 |  iteration: 14215 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 542 loss: 1.34131 acc: 0.70312 | v_loss: 1.44206 v_acc: 0.70312 |  iteration: 14216 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 543 loss: 1.38584 acc: 0.71354 | v_loss: 1.47620 v_acc: 0.70605 |  iteration: 14217 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 544 loss: 1.36502 acc: 0.71777 | v_loss: 1.52102 v_acc: 0.68978 |  iteration: 14218 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 545 loss: 1.39706 acc: 0.69954 | v_loss: 1.47333 v_acc: 0.70638 |  iteration: 14219 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 546 loss: 1.45896 acc: 0.69499 | v_loss: 1.41337 v_acc: 0.70410 |  iteration: 14220 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 547 loss: 1.42048 acc: 0.70931 | v_loss: 1.40465 v_acc: 0.70768 |  iteration: 14221 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 548 loss: 1.39300 acc: 0.70931 | v_loss: 1.40689 v_acc: 0.70475 |  iteration: 14222 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 549 loss: 1.38158 acc: 0.70443 | v_loss: 1.26132 v_acc: 0.71875 |  iteration: 14223 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 550 loss: 1.34782 acc: 0.70410 | v_loss: 1.33097 v_acc: 0.72331 |  iteration: 14224 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 551 loss: 1.55828 acc: 0.68880 | v_loss: 1.15365 v_acc: 0.71615 |  iteration: 14225 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 552 loss: 1.52530 acc: 0.69434 | v_loss: 1.33804 v_acc: 0.71126 |  iteration: 14226 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 553 loss: 1.47172 acc: 0.70410 | v_loss: 1.51760 v_acc: 0.69954 |  iteration: 14227 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 554 loss: 1.43379 acc: 0.69759 | v_loss: 1.32089 v_acc: 0.71484 |  iteration: 14228 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 555 loss: 1.51168 acc: 0.69661 | v_loss: 1.35266 v_acc: 0.69661 |  iteration: 14229 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 556 loss: 1.43901 acc: 0.69694 | v_loss: 1.25019 v_acc: 0.70638 |  iteration: 14230 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 557 loss: 1.41399 acc: 0.70052 | v_loss: 1.23566 v_acc: 0.70410 |  iteration: 14231 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 558 loss: 1.32876 acc: 0.70931 | v_loss: 1.25242 v_acc: 0.73926 |  iteration: 14232 teacher: 0 stage: sketch lr: 0.000370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 559 loss: 1.39657 acc: 0.70866 | v_loss: 1.26950 v_acc: 0.71908 |  iteration: 14233 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 560 loss: 1.52447 acc: 0.69596 | v_loss: 1.35825 v_acc: 0.73112 |  iteration: 14234 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 561 loss: 1.36546 acc: 0.70866 | v_loss: 1.26829 v_acc: 0.72038 |  iteration: 14235 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 562 loss: 1.32994 acc: 0.70605 | v_loss: 1.31311 v_acc: 0.72005 |  iteration: 14236 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 563 loss: 1.37940 acc: 0.70671 | v_loss: 1.42498 v_acc: 0.71224 |  iteration: 14237 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 564 loss: 1.53814 acc: 0.69759 | v_loss: 1.40737 v_acc: 0.72070 |  iteration: 14238 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 565 loss: 1.37729 acc: 0.70898 | v_loss: 1.49029 v_acc: 0.69954 |  iteration: 14239 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 566 loss: 1.43713 acc: 0.69596 | v_loss: 1.43098 v_acc: 0.71615 |  iteration: 14240 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 567 loss: 1.46931 acc: 0.69954 | v_loss: 1.18173 v_acc: 0.74544 |  iteration: 14241 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 568 loss: 1.28863 acc: 0.71615 | v_loss: 1.25095 v_acc: 0.70931 |  iteration: 14242 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 569 loss: 1.53391 acc: 0.69141 | v_loss: 1.52535 v_acc: 0.70247 |  iteration: 14243 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 570 loss: 1.40057 acc: 0.70215 | v_loss: 1.20908 v_acc: 0.70866 |  iteration: 14244 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 571 loss: 1.47618 acc: 0.69629 | v_loss: 1.32687 v_acc: 0.71159 |  iteration: 14245 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 572 loss: 1.32709 acc: 0.71354 | v_loss: 1.36002 v_acc: 0.69336 |  iteration: 14246 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 573 loss: 1.49235 acc: 0.68750 | v_loss: 1.28911 v_acc: 0.70964 |  iteration: 14247 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 574 loss: 1.45394 acc: 0.70312 | v_loss: 1.36068 v_acc: 0.69434 |  iteration: 14248 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 575 loss: 1.61136 acc: 0.68978 | v_loss: 1.47873 v_acc: 0.71224 |  iteration: 14249 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 576 loss: 1.37488 acc: 0.70215 | v_loss: 1.31927 v_acc: 0.72819 |  iteration: 14250 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 577 loss: 1.42525 acc: 0.70312 | v_loss: 1.45310 v_acc: 0.70312 |  iteration: 14251 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 578 loss: 1.42542 acc: 0.69694 | v_loss: 1.34774 v_acc: 0.69954 |  iteration: 14252 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 579 loss: 1.46127 acc: 0.70150 | v_loss: 1.32906 v_acc: 0.70964 |  iteration: 14253 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 580 loss: 1.40920 acc: 0.70573 | v_loss: 1.53676 v_acc: 0.68913 |  iteration: 14254 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 581 loss: 1.47816 acc: 0.69271 | v_loss: 1.30393 v_acc: 0.72168 |  iteration: 14255 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 582 loss: 1.39414 acc: 0.70117 | v_loss: 1.58370 v_acc: 0.68424 |  iteration: 14256 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 583 loss: 1.39896 acc: 0.70833 | v_loss: 1.44536 v_acc: 0.69792 |  iteration: 14257 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 584 loss: 1.45426 acc: 0.70605 | v_loss: 1.54386 v_acc: 0.69238 |  iteration: 14258 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 585 loss: 1.48346 acc: 0.69727 | v_loss: 1.36895 v_acc: 0.70182 |  iteration: 14259 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 586 loss: 1.36659 acc: 0.70866 | v_loss: 1.32471 v_acc: 0.70638 |  iteration: 14260 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 587 loss: 1.53094 acc: 0.68978 | v_loss: 1.32725 v_acc: 0.70410 |  iteration: 14261 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 588 loss: 1.39608 acc: 0.70508 | v_loss: 1.32643 v_acc: 0.71842 |  iteration: 14262 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 589 loss: 1.33614 acc: 0.70996 | v_loss: 1.55079 v_acc: 0.69108 |  iteration: 14263 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 590 loss: 1.43514 acc: 0.69889 | v_loss: 1.37825 v_acc: 0.71126 |  iteration: 14264 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 591 loss: 1.45290 acc: 0.70573 | v_loss: 1.35719 v_acc: 0.71029 |  iteration: 14265 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 592 loss: 1.51309 acc: 0.69368 | v_loss: 1.38415 v_acc: 0.71680 |  iteration: 14266 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 593 loss: 1.50726 acc: 0.69987 | v_loss: 1.27104 v_acc: 0.70573 |  iteration: 14267 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 594 loss: 1.36039 acc: 0.69922 | v_loss: 1.43556 v_acc: 0.69792 |  iteration: 14268 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 595 loss: 1.40909 acc: 0.71061 | v_loss: 1.43139 v_acc: 0.71289 |  iteration: 14269 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 596 loss: 1.32208 acc: 0.71387 | v_loss: 1.29415 v_acc: 0.71875 |  iteration: 14270 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 597 loss: 1.46825 acc: 0.70410 | v_loss: 1.25996 v_acc: 0.72754 |  iteration: 14271 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 598 loss: 1.50388 acc: 0.69303 | v_loss: 1.37890 v_acc: 0.71940 |  iteration: 14272 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 599 loss: 1.44903 acc: 0.69694 | v_loss: 1.43384 v_acc: 0.70345 |  iteration: 14273 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 600 loss: 1.36023 acc: 0.70768 | v_loss: 1.43295 v_acc: 0.70410 |  iteration: 14274 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 601 loss: 1.37329 acc: 0.70996 | v_loss: 1.22680 v_acc: 0.71745 |  iteration: 14275 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 602 loss: 1.41683 acc: 0.69759 | v_loss: 1.39754 v_acc: 0.73112 |  iteration: 14276 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 603 loss: 1.48322 acc: 0.69857 | v_loss: 1.47761 v_acc: 0.69759 |  iteration: 14277 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 604 loss: 1.37620 acc: 0.69303 | v_loss: 1.42947 v_acc: 0.72201 |  iteration: 14278 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 605 loss: 1.27999 acc: 0.71842 | v_loss: 1.23624 v_acc: 0.72233 |  iteration: 14279 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 606 loss: 1.52360 acc: 0.69206 | v_loss: 1.18515 v_acc: 0.74447 |  iteration: 14280 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 607 loss: 1.52793 acc: 0.70182 | v_loss: 1.20948 v_acc: 0.72493 |  iteration: 14281 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 608 loss: 1.40153 acc: 0.70540 | v_loss: 1.27510 v_acc: 0.70768 |  iteration: 14282 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 609 loss: 1.44956 acc: 0.69857 | v_loss: 1.44851 v_acc: 0.69596 |  iteration: 14283 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 610 loss: 1.52963 acc: 0.68587 | v_loss: 1.27775 v_acc: 0.71224 |  iteration: 14284 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 611 loss: 1.54798 acc: 0.69271 | v_loss: 1.45200 v_acc: 0.71582 |  iteration: 14285 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 612 loss: 1.53681 acc: 0.69466 | v_loss: 1.65280 v_acc: 0.69401 |  iteration: 14286 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 613 loss: 1.43307 acc: 0.70215 | v_loss: 1.51508 v_acc: 0.69922 |  iteration: 14287 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 614 loss: 1.51803 acc: 0.70150 | v_loss: 1.29938 v_acc: 0.72135 |  iteration: 14288 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 615 loss: 1.49677 acc: 0.69141 | v_loss: 1.37117 v_acc: 0.69987 |  iteration: 14289 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 616 loss: 1.46816 acc: 0.69922 | v_loss: 1.23627 v_acc: 0.71712 |  iteration: 14290 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 617 loss: 1.43658 acc: 0.70443 | v_loss: 1.40557 v_acc: 0.69857 |  iteration: 14291 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 618 loss: 1.42976 acc: 0.70443 | v_loss: 1.36198 v_acc: 0.70866 |  iteration: 14292 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 619 loss: 1.43381 acc: 0.69531 | v_loss: 1.34219 v_acc: 0.73079 |  iteration: 14293 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 620 loss: 1.45696 acc: 0.69238 | v_loss: 1.36847 v_acc: 0.71973 |  iteration: 14294 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 621 loss: 1.48103 acc: 0.69368 | v_loss: 1.37502 v_acc: 0.70964 |  iteration: 14295 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 622 loss: 1.40637 acc: 0.70215 | v_loss: 1.28620 v_acc: 0.72493 |  iteration: 14296 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 623 loss: 1.35973 acc: 0.70378 | v_loss: 1.29917 v_acc: 0.72038 |  iteration: 14297 teacher: 1 stage: sketch lr: 0.000370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 624 loss: 1.37786 acc: 0.70605 | v_loss: 1.49242 v_acc: 0.69368 |  iteration: 14298 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 625 loss: 1.32999 acc: 0.70931 | v_loss: 1.33688 v_acc: 0.71452 |  iteration: 14299 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 626 loss: 1.51099 acc: 0.70345 | v_loss: 1.29081 v_acc: 0.71615 |  iteration: 14300 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 627 loss: 1.45938 acc: 0.70085 | v_loss: 1.28936 v_acc: 0.71973 |  iteration: 14301 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 628 loss: 1.46659 acc: 0.69694 | v_loss: 1.42698 v_acc: 0.70540 |  iteration: 14302 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 629 loss: 1.46134 acc: 0.70410 | v_loss: 1.31046 v_acc: 0.73210 |  iteration: 14303 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 630 loss: 1.38553 acc: 0.70410 | v_loss: 1.53994 v_acc: 0.71615 |  iteration: 14304 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 631 loss: 1.47664 acc: 0.69954 | v_loss: 1.28564 v_acc: 0.69759 |  iteration: 14305 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 632 loss: 1.49553 acc: 0.69336 | v_loss: 1.27696 v_acc: 0.70703 |  iteration: 14306 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 633 loss: 1.33335 acc: 0.71061 | v_loss: 1.42719 v_acc: 0.70475 |  iteration: 14307 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 634 loss: 1.45315 acc: 0.70052 | v_loss: 1.46186 v_acc: 0.70443 |  iteration: 14308 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 635 loss: 1.50730 acc: 0.69141 | v_loss: 1.50735 v_acc: 0.69108 |  iteration: 14309 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 636 loss: 1.41726 acc: 0.71061 | v_loss: 1.46950 v_acc: 0.70866 |  iteration: 14310 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 637 loss: 1.38698 acc: 0.70508 | v_loss: 1.41268 v_acc: 0.70085 |  iteration: 14311 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 638 loss: 1.51140 acc: 0.69987 | v_loss: 1.40594 v_acc: 0.70931 |  iteration: 14312 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 639 loss: 1.47212 acc: 0.69727 | v_loss: 1.40731 v_acc: 0.70605 |  iteration: 14313 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 640 loss: 1.49451 acc: 0.69727 | v_loss: 1.25944 v_acc: 0.71224 |  iteration: 14314 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 641 loss: 1.43499 acc: 0.69954 | v_loss: 1.32956 v_acc: 0.72461 |  iteration: 14315 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 642 loss: 1.37526 acc: 0.70573 | v_loss: 1.19550 v_acc: 0.70573 |  iteration: 14316 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 643 loss: 1.36795 acc: 0.70833 | v_loss: 1.34358 v_acc: 0.70280 |  iteration: 14317 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 644 loss: 1.40738 acc: 0.70508 | v_loss: 1.49497 v_acc: 0.70052 |  iteration: 14318 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 645 loss: 1.46814 acc: 0.69661 | v_loss: 1.32313 v_acc: 0.70703 |  iteration: 14319 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 646 loss: 1.40545 acc: 0.70020 | v_loss: 1.35211 v_acc: 0.69727 |  iteration: 14320 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 647 loss: 1.32348 acc: 0.71354 | v_loss: 1.24024 v_acc: 0.71126 |  iteration: 14321 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 648 loss: 1.46161 acc: 0.69694 | v_loss: 1.24646 v_acc: 0.70345 |  iteration: 14322 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 649 loss: 1.50597 acc: 0.69564 | v_loss: 1.23932 v_acc: 0.73861 |  iteration: 14323 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 650 loss: 1.46403 acc: 0.69434 | v_loss: 1.26674 v_acc: 0.71973 |  iteration: 14324 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 651 loss: 1.44355 acc: 0.69889 | v_loss: 1.33887 v_acc: 0.73112 |  iteration: 14325 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 652 loss: 1.44655 acc: 0.70150 | v_loss: 1.25520 v_acc: 0.71940 |  iteration: 14326 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 653 loss: 1.32771 acc: 0.71029 | v_loss: 1.29892 v_acc: 0.72135 |  iteration: 14327 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 654 loss: 1.43431 acc: 0.70150 | v_loss: 1.40534 v_acc: 0.71354 |  iteration: 14328 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 655 loss: 1.41409 acc: 0.69792 | v_loss: 1.39742 v_acc: 0.72428 |  iteration: 14329 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 656 loss: 1.39346 acc: 0.70508 | v_loss: 1.49160 v_acc: 0.70215 |  iteration: 14330 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 657 loss: 1.42450 acc: 0.70312 | v_loss: 1.41116 v_acc: 0.71973 |  iteration: 14331 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 658 loss: 1.48531 acc: 0.69238 | v_loss: 1.17414 v_acc: 0.74544 |  iteration: 14332 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 659 loss: 1.50143 acc: 0.70703 | v_loss: 1.26123 v_acc: 0.70508 |  iteration: 14333 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 660 loss: 1.43604 acc: 0.70085 | v_loss: 1.51066 v_acc: 0.70312 |  iteration: 14334 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 661 loss: 1.61802 acc: 0.68652 | v_loss: 1.21704 v_acc: 0.70964 |  iteration: 14335 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 662 loss: 1.53256 acc: 0.69466 | v_loss: 1.32689 v_acc: 0.71094 |  iteration: 14336 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 663 loss: 1.43954 acc: 0.69987 | v_loss: 1.35832 v_acc: 0.69434 |  iteration: 14337 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 664 loss: 1.38242 acc: 0.70964 | v_loss: 1.30333 v_acc: 0.70931 |  iteration: 14338 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 665 loss: 1.38863 acc: 0.70215 | v_loss: 1.36163 v_acc: 0.69434 |  iteration: 14339 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 666 loss: 1.36471 acc: 0.70573 | v_loss: 1.48200 v_acc: 0.71094 |  iteration: 14340 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 667 loss: 1.43627 acc: 0.70247 | v_loss: 1.31944 v_acc: 0.72689 |  iteration: 14341 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 668 loss: 1.53277 acc: 0.69564 | v_loss: 1.47230 v_acc: 0.70443 |  iteration: 14342 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 669 loss: 1.49587 acc: 0.69889 | v_loss: 1.35480 v_acc: 0.69922 |  iteration: 14343 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 670 loss: 1.52379 acc: 0.68945 | v_loss: 1.33426 v_acc: 0.70898 |  iteration: 14344 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 671 loss: 1.43217 acc: 0.70280 | v_loss: 1.54576 v_acc: 0.68815 |  iteration: 14345 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 672 loss: 1.34875 acc: 0.71745 | v_loss: 1.30036 v_acc: 0.72005 |  iteration: 14346 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 673 loss: 1.39901 acc: 0.70475 | v_loss: 1.58201 v_acc: 0.68327 |  iteration: 14347 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 674 loss: 1.39427 acc: 0.70931 | v_loss: 1.45816 v_acc: 0.69792 |  iteration: 14348 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 675 loss: 1.34429 acc: 0.71191 | v_loss: 1.51677 v_acc: 0.69173 |  iteration: 14349 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 676 loss: 1.44211 acc: 0.70345 | v_loss: 1.37928 v_acc: 0.70020 |  iteration: 14350 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 677 loss: 1.37244 acc: 0.71159 | v_loss: 1.31651 v_acc: 0.70378 |  iteration: 14351 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 678 loss: 1.57114 acc: 0.69141 | v_loss: 1.33366 v_acc: 0.70215 |  iteration: 14352 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 679 loss: 1.43628 acc: 0.71224 | v_loss: 1.32810 v_acc: 0.71615 |  iteration: 14353 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 680 loss: 1.44465 acc: 0.69727 | v_loss: 1.54309 v_acc: 0.68945 |  iteration: 14354 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 681 loss: 1.48989 acc: 0.69922 | v_loss: 1.38107 v_acc: 0.70703 |  iteration: 14355 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 682 loss: 1.40977 acc: 0.70410 | v_loss: 1.33834 v_acc: 0.70833 |  iteration: 14356 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 683 loss: 1.45935 acc: 0.70605 | v_loss: 1.38567 v_acc: 0.71582 |  iteration: 14357 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 684 loss: 1.46159 acc: 0.70508 | v_loss: 1.26847 v_acc: 0.70443 |  iteration: 14358 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 685 loss: 1.30182 acc: 0.71224 | v_loss: 1.43543 v_acc: 0.69922 |  iteration: 14359 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 686 loss: 1.50023 acc: 0.69922 | v_loss: 1.43196 v_acc: 0.71615 |  iteration: 14360 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 687 loss: 1.39952 acc: 0.70801 | v_loss: 1.27790 v_acc: 0.71875 |  iteration: 14361 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 688 loss: 1.48300 acc: 0.70020 | v_loss: 1.25998 v_acc: 0.72721 |  iteration: 14362 teacher: 0 stage: sketch lr: 0.000369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 689 loss: 1.55095 acc: 0.68880 | v_loss: 1.38802 v_acc: 0.72266 |  iteration: 14363 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 690 loss: 1.51274 acc: 0.70378 | v_loss: 1.41546 v_acc: 0.70410 |  iteration: 14364 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 691 loss: 1.40128 acc: 0.70703 | v_loss: 1.41809 v_acc: 0.70833 |  iteration: 14365 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 692 loss: 1.44037 acc: 0.70280 | v_loss: 1.22014 v_acc: 0.72591 |  iteration: 14366 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 693 loss: 1.46081 acc: 0.70052 | v_loss: 1.37671 v_acc: 0.72786 |  iteration: 14367 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 694 loss: 1.41902 acc: 0.70345 | v_loss: 1.46296 v_acc: 0.69792 |  iteration: 14368 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 695 loss: 1.39714 acc: 0.70215 | v_loss: 1.41496 v_acc: 0.72070 |  iteration: 14369 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 696 loss: 1.42539 acc: 0.71126 | v_loss: 1.26227 v_acc: 0.71973 |  iteration: 14370 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 697 loss: 1.34363 acc: 0.70801 | v_loss: 1.21143 v_acc: 0.73503 |  iteration: 14371 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 698 loss: 1.34720 acc: 0.71061 | v_loss: 1.21318 v_acc: 0.72656 |  iteration: 14372 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 699 loss: 1.55589 acc: 0.69076 | v_loss: 1.29387 v_acc: 0.70768 |  iteration: 14373 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 700 loss: 1.49039 acc: 0.70312 | v_loss: 1.46469 v_acc: 0.69596 |  iteration: 14374 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 701 loss: 1.37723 acc: 0.70801 | v_loss: 1.27771 v_acc: 0.71224 |  iteration: 14375 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 702 loss: 1.46367 acc: 0.70052 | v_loss: 1.43894 v_acc: 0.71582 |  iteration: 14376 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 703 loss: 1.45920 acc: 0.69564 | v_loss: 1.67463 v_acc: 0.69401 |  iteration: 14377 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 704 loss: 1.38639 acc: 0.70475 | v_loss: 1.53091 v_acc: 0.69922 |  iteration: 14378 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 705 loss: 1.38487 acc: 0.70020 | v_loss: 1.29570 v_acc: 0.72135 |  iteration: 14379 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 706 loss: 1.36137 acc: 0.70605 | v_loss: 1.38044 v_acc: 0.70280 |  iteration: 14380 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 707 loss: 1.41944 acc: 0.70182 | v_loss: 1.21822 v_acc: 0.72070 |  iteration: 14381 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 708 loss: 1.40559 acc: 0.71647 | v_loss: 1.44450 v_acc: 0.69954 |  iteration: 14382 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 709 loss: 1.40835 acc: 0.70573 | v_loss: 1.35914 v_acc: 0.70833 |  iteration: 14383 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 710 loss: 1.48561 acc: 0.69629 | v_loss: 1.36195 v_acc: 0.73079 |  iteration: 14384 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 711 loss: 1.39147 acc: 0.71387 | v_loss: 1.37483 v_acc: 0.71973 |  iteration: 14385 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 712 loss: 1.46961 acc: 0.70638 | v_loss: 1.37714 v_acc: 0.70964 |  iteration: 14386 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 713 loss: 1.45683 acc: 0.70020 | v_loss: 1.27647 v_acc: 0.72493 |  iteration: 14387 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 714 loss: 1.52296 acc: 0.69238 | v_loss: 1.28914 v_acc: 0.72038 |  iteration: 14388 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 715 loss: 1.50029 acc: 0.69727 | v_loss: 1.50090 v_acc: 0.69303 |  iteration: 14389 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 716 loss: 1.39347 acc: 0.70475 | v_loss: 1.32523 v_acc: 0.71159 |  iteration: 14390 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 717 loss: 1.51724 acc: 0.69271 | v_loss: 1.31227 v_acc: 0.71452 |  iteration: 14391 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 718 loss: 1.48403 acc: 0.69238 | v_loss: 1.30670 v_acc: 0.71940 |  iteration: 14392 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 719 loss: 1.48293 acc: 0.69987 | v_loss: 1.43749 v_acc: 0.70150 |  iteration: 14393 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 720 loss: 1.47528 acc: 0.69173 | v_loss: 1.30524 v_acc: 0.72917 |  iteration: 14394 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 721 loss: 1.41440 acc: 0.70312 | v_loss: 1.53342 v_acc: 0.71354 |  iteration: 14395 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 722 loss: 1.33384 acc: 0.71452 | v_loss: 1.28872 v_acc: 0.69922 |  iteration: 14396 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 723 loss: 1.44030 acc: 0.70150 | v_loss: 1.28022 v_acc: 0.70215 |  iteration: 14397 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 724 loss: 1.42679 acc: 0.69987 | v_loss: 1.42900 v_acc: 0.70410 |  iteration: 14398 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 725 loss: 1.38139 acc: 0.70182 | v_loss: 1.46998 v_acc: 0.70312 |  iteration: 14399 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 726 loss: 1.39455 acc: 0.69954 | v_loss: 1.52642 v_acc: 0.68978 |  iteration: 14400 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 727 loss: 1.42684 acc: 0.70410 | v_loss: 1.47855 v_acc: 0.70638 |  iteration: 14401 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 728 loss: 1.46495 acc: 0.69368 | v_loss: 1.44368 v_acc: 0.70085 |  iteration: 14402 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 729 loss: 1.28859 acc: 0.70573 | v_loss: 1.44486 v_acc: 0.70931 |  iteration: 14403 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 730 loss: 1.45014 acc: 0.70247 | v_loss: 1.38907 v_acc: 0.70703 |  iteration: 14404 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 731 loss: 1.43120 acc: 0.70280 | v_loss: 1.24647 v_acc: 0.71875 |  iteration: 14405 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 732 loss: 1.52799 acc: 0.70378 | v_loss: 1.34731 v_acc: 0.72331 |  iteration: 14406 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 733 loss: 1.38115 acc: 0.70540 | v_loss: 1.15628 v_acc: 0.71615 |  iteration: 14407 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 734 loss: 1.43277 acc: 0.69401 | v_loss: 1.33815 v_acc: 0.70768 |  iteration: 14408 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 735 loss: 1.41862 acc: 0.71419 | v_loss: 1.50498 v_acc: 0.69987 |  iteration: 14409 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 736 loss: 1.47647 acc: 0.69727 | v_loss: 1.33583 v_acc: 0.70638 |  iteration: 14410 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 737 loss: 1.50544 acc: 0.70801 | v_loss: 1.34800 v_acc: 0.69661 |  iteration: 14411 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 738 loss: 1.38892 acc: 0.71224 | v_loss: 1.27472 v_acc: 0.70443 |  iteration: 14412 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 739 loss: 1.53134 acc: 0.69466 | v_loss: 1.26766 v_acc: 0.70247 |  iteration: 14413 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 740 loss: 1.40723 acc: 0.70703 | v_loss: 1.22445 v_acc: 0.74056 |  iteration: 14414 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 741 loss: 1.42500 acc: 0.70215 | v_loss: 1.29313 v_acc: 0.71484 |  iteration: 14415 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 742 loss: 1.43935 acc: 0.70410 | v_loss: 1.32307 v_acc: 0.72461 |  iteration: 14416 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 743 loss: 1.52360 acc: 0.69271 | v_loss: 1.27134 v_acc: 0.71615 |  iteration: 14417 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 744 loss: 1.45303 acc: 0.69857 | v_loss: 1.30137 v_acc: 0.71777 |  iteration: 14418 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 745 loss: 1.48215 acc: 0.70508 | v_loss: 1.39716 v_acc: 0.71159 |  iteration: 14419 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 746 loss: 1.33382 acc: 0.70573 | v_loss: 1.38500 v_acc: 0.71810 |  iteration: 14420 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 747 loss: 1.40877 acc: 0.70475 | v_loss: 1.49206 v_acc: 0.69857 |  iteration: 14421 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 748 loss: 1.50502 acc: 0.69499 | v_loss: 1.42641 v_acc: 0.71745 |  iteration: 14422 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 749 loss: 1.46063 acc: 0.69759 | v_loss: 1.17639 v_acc: 0.74479 |  iteration: 14423 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 750 loss: 1.45785 acc: 0.70150 | v_loss: 1.24984 v_acc: 0.70508 |  iteration: 14424 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 751 loss: 1.45448 acc: 0.70215 | v_loss: 1.53349 v_acc: 0.70312 |  iteration: 14425 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 752 loss: 1.57820 acc: 0.69108 | v_loss: 1.20468 v_acc: 0.70671 |  iteration: 14426 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 753 loss: 1.38175 acc: 0.70150 | v_loss: 1.33335 v_acc: 0.71257 |  iteration: 14427 teacher: 0 stage: sketch lr: 0.000368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 754 loss: 1.37814 acc: 0.70736 | v_loss: 1.37153 v_acc: 0.69368 |  iteration: 14428 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 755 loss: 1.48643 acc: 0.69824 | v_loss: 1.28889 v_acc: 0.71842 |  iteration: 14429 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 756 loss: 1.52801 acc: 0.69141 | v_loss: 1.35708 v_acc: 0.69629 |  iteration: 14430 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 757 loss: 1.35877 acc: 0.71354 | v_loss: 1.46805 v_acc: 0.71419 |  iteration: 14431 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 758 loss: 1.45315 acc: 0.69629 | v_loss: 1.31319 v_acc: 0.72884 |  iteration: 14432 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 759 loss: 1.41569 acc: 0.70996 | v_loss: 1.44952 v_acc: 0.70117 |  iteration: 14433 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 760 loss: 1.37829 acc: 0.70150 | v_loss: 1.35938 v_acc: 0.70085 |  iteration: 14434 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 761 loss: 1.45081 acc: 0.70182 | v_loss: 1.33181 v_acc: 0.70703 |  iteration: 14435 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 762 loss: 1.46060 acc: 0.70540 | v_loss: 1.53676 v_acc: 0.68880 |  iteration: 14436 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 763 loss: 1.42606 acc: 0.70215 | v_loss: 1.29380 v_acc: 0.72201 |  iteration: 14437 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 764 loss: 1.41856 acc: 0.70736 | v_loss: 1.59494 v_acc: 0.68424 |  iteration: 14438 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 765 loss: 1.54170 acc: 0.70150 | v_loss: 1.45323 v_acc: 0.69792 |  iteration: 14439 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 766 loss: 1.36023 acc: 0.70768 | v_loss: 1.52155 v_acc: 0.69173 |  iteration: 14440 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 767 loss: 1.39464 acc: 0.70508 | v_loss: 1.37870 v_acc: 0.70020 |  iteration: 14441 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 768 loss: 1.45567 acc: 0.69466 | v_loss: 1.32085 v_acc: 0.70312 |  iteration: 14442 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 769 loss: 1.41872 acc: 0.71647 | v_loss: 1.32961 v_acc: 0.70247 |  iteration: 14443 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 770 loss: 1.41009 acc: 0.70085 | v_loss: 1.32663 v_acc: 0.71973 |  iteration: 14444 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 771 loss: 1.43020 acc: 0.69857 | v_loss: 1.55890 v_acc: 0.69076 |  iteration: 14445 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 772 loss: 1.37954 acc: 0.70443 | v_loss: 1.37896 v_acc: 0.71387 |  iteration: 14446 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 773 loss: 1.44638 acc: 0.70898 | v_loss: 1.34938 v_acc: 0.70964 |  iteration: 14447 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 774 loss: 1.45779 acc: 0.69076 | v_loss: 1.39054 v_acc: 0.71452 |  iteration: 14448 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 775 loss: 1.39607 acc: 0.70931 | v_loss: 1.26225 v_acc: 0.70443 |  iteration: 14449 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 776 loss: 1.49140 acc: 0.69368 | v_loss: 1.42626 v_acc: 0.69922 |  iteration: 14450 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 777 loss: 1.51477 acc: 0.68945 | v_loss: 1.43209 v_acc: 0.71289 |  iteration: 14451 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 778 loss: 1.44986 acc: 0.69694 | v_loss: 1.28010 v_acc: 0.71875 |  iteration: 14452 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 779 loss: 1.40625 acc: 0.70443 | v_loss: 1.26096 v_acc: 0.72591 |  iteration: 14453 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 780 loss: 1.47191 acc: 0.69629 | v_loss: 1.37888 v_acc: 0.72266 |  iteration: 14454 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 781 loss: 1.45873 acc: 0.70280 | v_loss: 1.41602 v_acc: 0.70410 |  iteration: 14455 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 782 loss: 1.48185 acc: 0.69661 | v_loss: 1.42580 v_acc: 0.70833 |  iteration: 14456 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 783 loss: 1.40918 acc: 0.70605 | v_loss: 1.22713 v_acc: 0.72591 |  iteration: 14457 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 784 loss: 1.32665 acc: 0.70996 | v_loss: 1.38375 v_acc: 0.73047 |  iteration: 14458 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 785 loss: 1.40584 acc: 0.70117 | v_loss: 1.46521 v_acc: 0.69792 |  iteration: 14459 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 786 loss: 1.54597 acc: 0.68652 | v_loss: 1.40637 v_acc: 0.72070 |  iteration: 14460 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 787 loss: 1.43350 acc: 0.70996 | v_loss: 1.25285 v_acc: 0.72038 |  iteration: 14461 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 788 loss: 1.49689 acc: 0.69922 | v_loss: 1.20319 v_acc: 0.73828 |  iteration: 14462 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 789 loss: 1.42948 acc: 0.70475 | v_loss: 1.21425 v_acc: 0.72624 |  iteration: 14463 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 790 loss: 1.37336 acc: 0.70443 | v_loss: 1.29117 v_acc: 0.70703 |  iteration: 14464 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 791 loss: 1.46736 acc: 0.69010 | v_loss: 1.45065 v_acc: 0.69466 |  iteration: 14465 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 792 loss: 1.52978 acc: 0.69108 | v_loss: 1.27065 v_acc: 0.71484 |  iteration: 14466 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 793 loss: 1.35737 acc: 0.70085 | v_loss: 1.43376 v_acc: 0.71647 |  iteration: 14467 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 794 loss: 1.45412 acc: 0.69824 | v_loss: 1.67254 v_acc: 0.69303 |  iteration: 14468 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 795 loss: 1.39635 acc: 0.70768 | v_loss: 1.52713 v_acc: 0.70117 |  iteration: 14469 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 796 loss: 1.44154 acc: 0.70508 | v_loss: 1.29204 v_acc: 0.72396 |  iteration: 14470 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 797 loss: 1.41234 acc: 0.71191 | v_loss: 1.37283 v_acc: 0.70996 |  iteration: 14471 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 798 loss: 1.32626 acc: 0.71191 | v_loss: 1.21727 v_acc: 0.72201 |  iteration: 14472 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 799 loss: 1.41519 acc: 0.70573 | v_loss: 1.41064 v_acc: 0.70378 |  iteration: 14473 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 800 loss: 1.48387 acc: 0.70801 | v_loss: 1.35855 v_acc: 0.71810 |  iteration: 14474 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 801 loss: 1.48240 acc: 0.70410 | v_loss: 1.35162 v_acc: 0.73014 |  iteration: 14475 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 802 loss: 1.41390 acc: 0.70671 | v_loss: 1.37114 v_acc: 0.71973 |  iteration: 14476 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 803 loss: 1.39637 acc: 0.70443 | v_loss: 1.37320 v_acc: 0.70475 |  iteration: 14477 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 804 loss: 1.45361 acc: 0.70931 | v_loss: 1.28313 v_acc: 0.72559 |  iteration: 14478 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 805 loss: 1.47394 acc: 0.70117 | v_loss: 1.29320 v_acc: 0.72005 |  iteration: 14479 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 806 loss: 1.51068 acc: 0.69173 | v_loss: 1.49149 v_acc: 0.69043 |  iteration: 14480 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 807 loss: 1.37231 acc: 0.70345 | v_loss: 1.33052 v_acc: 0.71224 |  iteration: 14481 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 808 loss: 1.39964 acc: 0.69596 | v_loss: 1.29524 v_acc: 0.71191 |  iteration: 14482 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 809 loss: 1.48218 acc: 0.70052 | v_loss: 1.29803 v_acc: 0.71452 |  iteration: 14483 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 810 loss: 1.50052 acc: 0.69857 | v_loss: 1.43227 v_acc: 0.70475 |  iteration: 14484 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 811 loss: 1.38026 acc: 0.69857 | v_loss: 1.31351 v_acc: 0.73210 |  iteration: 14485 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 812 loss: 1.47658 acc: 0.69173 | v_loss: 1.54238 v_acc: 0.71419 |  iteration: 14486 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 813 loss: 1.40626 acc: 0.69759 | v_loss: 1.26718 v_acc: 0.70150 |  iteration: 14487 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 814 loss: 1.48975 acc: 0.69792 | v_loss: 1.27204 v_acc: 0.70573 |  iteration: 14488 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 815 loss: 1.36775 acc: 0.70931 | v_loss: 1.44210 v_acc: 0.70378 |  iteration: 14489 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 816 loss: 1.42575 acc: 0.70475 | v_loss: 1.47812 v_acc: 0.70150 |  iteration: 14490 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 817 loss: 1.44941 acc: 0.69824 | v_loss: 1.51324 v_acc: 0.69368 |  iteration: 14491 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 818 loss: 1.32566 acc: 0.70833 | v_loss: 1.47346 v_acc: 0.70931 |  iteration: 14492 teacher: 0 stage: sketch lr: 0.000367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 819 loss: 1.32923 acc: 0.71224 | v_loss: 1.41649 v_acc: 0.70085 |  iteration: 14493 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 820 loss: 1.38109 acc: 0.70833 | v_loss: 1.40564 v_acc: 0.70931 |  iteration: 14494 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 821 loss: 1.48981 acc: 0.71126 | v_loss: 1.40488 v_acc: 0.70703 |  iteration: 14495 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 822 loss: 1.36371 acc: 0.70312 | v_loss: 1.25739 v_acc: 0.71875 |  iteration: 14496 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 823 loss: 1.41590 acc: 0.71126 | v_loss: 1.32113 v_acc: 0.72461 |  iteration: 14497 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 824 loss: 1.41363 acc: 0.70540 | v_loss: 1.18710 v_acc: 0.71517 |  iteration: 14498 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 825 loss: 1.50635 acc: 0.69922 | v_loss: 1.34862 v_acc: 0.70247 |  iteration: 14499 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 826 loss: 1.40451 acc: 0.70410 | v_loss: 1.50720 v_acc: 0.69792 |  iteration: 14500 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 827 loss: 1.48955 acc: 0.70605 | v_loss: 1.33775 v_acc: 0.70671 |  iteration: 14501 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 828 loss: 1.49703 acc: 0.68978 | v_loss: 1.34377 v_acc: 0.69759 |  iteration: 14502 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 829 loss: 1.44609 acc: 0.70638 | v_loss: 1.26435 v_acc: 0.71061 |  iteration: 14503 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 830 loss: 1.46624 acc: 0.69857 | v_loss: 1.25791 v_acc: 0.70215 |  iteration: 14504 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 831 loss: 1.33932 acc: 0.70410 | v_loss: 1.22566 v_acc: 0.73730 |  iteration: 14505 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 832 loss: 1.43877 acc: 0.69564 | v_loss: 1.27529 v_acc: 0.71908 |  iteration: 14506 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 833 loss: 1.42142 acc: 0.70085 | v_loss: 1.32071 v_acc: 0.73145 |  iteration: 14507 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 834 loss: 1.44227 acc: 0.69466 | v_loss: 1.25438 v_acc: 0.72526 |  iteration: 14508 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 835 loss: 1.48977 acc: 0.69727 | v_loss: 1.29814 v_acc: 0.72103 |  iteration: 14509 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 836 loss: 1.36996 acc: 0.70736 | v_loss: 1.40455 v_acc: 0.71354 |  iteration: 14510 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 837 loss: 1.36990 acc: 0.70345 | v_loss: 1.40205 v_acc: 0.72428 |  iteration: 14511 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 838 loss: 1.49528 acc: 0.69564 | v_loss: 1.48783 v_acc: 0.70182 |  iteration: 14512 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 839 loss: 1.45061 acc: 0.69694 | v_loss: 1.42820 v_acc: 0.71615 |  iteration: 14513 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 840 loss: 1.48862 acc: 0.69596 | v_loss: 1.17913 v_acc: 0.74544 |  iteration: 14514 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 841 loss: 1.40830 acc: 0.70475 | v_loss: 1.25232 v_acc: 0.70931 |  iteration: 14515 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 842 loss: 1.40265 acc: 0.71191 | v_loss: 1.52195 v_acc: 0.70247 |  iteration: 14516 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 843 loss: 1.41107 acc: 0.69336 | v_loss: 1.22248 v_acc: 0.70866 |  iteration: 14517 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 844 loss: 1.46257 acc: 0.70085 | v_loss: 1.32528 v_acc: 0.71289 |  iteration: 14518 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 845 loss: 1.45306 acc: 0.69889 | v_loss: 1.35622 v_acc: 0.69564 |  iteration: 14519 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 846 loss: 1.37982 acc: 0.69922 | v_loss: 1.29692 v_acc: 0.71224 |  iteration: 14520 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 847 loss: 1.35397 acc: 0.70768 | v_loss: 1.36854 v_acc: 0.69629 |  iteration: 14521 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 848 loss: 1.48798 acc: 0.70052 | v_loss: 1.46295 v_acc: 0.71517 |  iteration: 14522 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 849 loss: 1.44714 acc: 0.70768 | v_loss: 1.31376 v_acc: 0.72526 |  iteration: 14523 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 850 loss: 1.45188 acc: 0.69824 | v_loss: 1.44386 v_acc: 0.70410 |  iteration: 14524 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 851 loss: 1.57145 acc: 0.69434 | v_loss: 1.37375 v_acc: 0.70085 |  iteration: 14525 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 852 loss: 1.48137 acc: 0.69629 | v_loss: 1.32762 v_acc: 0.70703 |  iteration: 14526 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 853 loss: 1.38067 acc: 0.71582 | v_loss: 1.54211 v_acc: 0.68880 |  iteration: 14527 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 854 loss: 1.35414 acc: 0.71061 | v_loss: 1.29810 v_acc: 0.72103 |  iteration: 14528 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 855 loss: 1.38786 acc: 0.70410 | v_loss: 1.57923 v_acc: 0.68620 |  iteration: 14529 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 856 loss: 1.41415 acc: 0.70768 | v_loss: 1.42784 v_acc: 0.69987 |  iteration: 14530 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 857 loss: 1.52212 acc: 0.69954 | v_loss: 1.51846 v_acc: 0.68945 |  iteration: 14531 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 858 loss: 1.43200 acc: 0.71484 | v_loss: 1.37415 v_acc: 0.70020 |  iteration: 14532 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 859 loss: 1.36547 acc: 0.70280 | v_loss: 1.32583 v_acc: 0.70312 |  iteration: 14533 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 860 loss: 1.52823 acc: 0.69206 | v_loss: 1.33248 v_acc: 0.70020 |  iteration: 14534 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 861 loss: 1.41252 acc: 0.70280 | v_loss: 1.32477 v_acc: 0.71484 |  iteration: 14535 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 862 loss: 1.31897 acc: 0.71810 | v_loss: 1.53455 v_acc: 0.68978 |  iteration: 14536 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 863 loss: 1.46850 acc: 0.70345 | v_loss: 1.37524 v_acc: 0.70443 |  iteration: 14537 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 864 loss: 1.43568 acc: 0.69954 | v_loss: 1.34441 v_acc: 0.71029 |  iteration: 14538 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 865 loss: 1.48723 acc: 0.69987 | v_loss: 1.38644 v_acc: 0.71680 |  iteration: 14539 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 866 loss: 1.40325 acc: 0.70378 | v_loss: 1.26747 v_acc: 0.70573 |  iteration: 14540 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 867 loss: 1.44408 acc: 0.69889 | v_loss: 1.43463 v_acc: 0.69889 |  iteration: 14541 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 868 loss: 1.38544 acc: 0.70605 | v_loss: 1.43046 v_acc: 0.71615 |  iteration: 14542 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 869 loss: 1.51913 acc: 0.70312 | v_loss: 1.29088 v_acc: 0.71712 |  iteration: 14543 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 870 loss: 1.43812 acc: 0.70866 | v_loss: 1.25328 v_acc: 0.72982 |  iteration: 14544 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 871 loss: 1.44115 acc: 0.69987 | v_loss: 1.37494 v_acc: 0.71615 |  iteration: 14545 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 872 loss: 1.47607 acc: 0.69954 | v_loss: 1.41457 v_acc: 0.70540 |  iteration: 14546 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 873 loss: 1.49026 acc: 0.70508 | v_loss: 1.41692 v_acc: 0.70508 |  iteration: 14547 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 874 loss: 1.52530 acc: 0.69043 | v_loss: 1.23046 v_acc: 0.71452 |  iteration: 14548 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 875 loss: 1.61143 acc: 0.69141 | v_loss: 1.37686 v_acc: 0.72754 |  iteration: 14549 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 876 loss: 1.44005 acc: 0.70312 | v_loss: 1.47381 v_acc: 0.69531 |  iteration: 14550 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 877 loss: 1.44471 acc: 0.71257 | v_loss: 1.42425 v_acc: 0.72233 |  iteration: 14551 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 878 loss: 1.44442 acc: 0.70312 | v_loss: 1.26115 v_acc: 0.71940 |  iteration: 14552 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 879 loss: 1.43082 acc: 0.70085 | v_loss: 1.21199 v_acc: 0.73438 |  iteration: 14553 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 880 loss: 1.46007 acc: 0.70150 | v_loss: 1.21304 v_acc: 0.72982 |  iteration: 14554 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 881 loss: 1.40058 acc: 0.70443 | v_loss: 1.29510 v_acc: 0.70801 |  iteration: 14555 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 882 loss: 1.41039 acc: 0.70573 | v_loss: 1.45765 v_acc: 0.70052 |  iteration: 14556 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 883 loss: 1.39092 acc: 0.70964 | v_loss: 1.27040 v_acc: 0.71452 |  iteration: 14557 teacher: 1 stage: sketch lr: 0.000366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 884 loss: 1.41544 acc: 0.69824 | v_loss: 1.47732 v_acc: 0.70475 |  iteration: 14558 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 885 loss: 1.42923 acc: 0.70247 | v_loss: 1.69641 v_acc: 0.69141 |  iteration: 14559 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 886 loss: 1.42733 acc: 0.71029 | v_loss: 1.54919 v_acc: 0.69531 |  iteration: 14560 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 887 loss: 1.53998 acc: 0.69531 | v_loss: 1.29088 v_acc: 0.72526 |  iteration: 14561 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 888 loss: 1.39953 acc: 0.70247 | v_loss: 1.36963 v_acc: 0.70996 |  iteration: 14562 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 889 loss: 1.40417 acc: 0.70085 | v_loss: 1.21551 v_acc: 0.72201 |  iteration: 14563 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 890 loss: 1.49029 acc: 0.69368 | v_loss: 1.41887 v_acc: 0.70378 |  iteration: 14564 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 891 loss: 1.55816 acc: 0.70475 | v_loss: 1.35163 v_acc: 0.71224 |  iteration: 14565 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 892 loss: 1.42888 acc: 0.70052 | v_loss: 1.34800 v_acc: 0.72949 |  iteration: 14566 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 893 loss: 1.40803 acc: 0.70312 | v_loss: 1.34919 v_acc: 0.71810 |  iteration: 14567 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 894 loss: 1.39828 acc: 0.70605 | v_loss: 1.37384 v_acc: 0.70508 |  iteration: 14568 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 895 loss: 1.53258 acc: 0.69857 | v_loss: 1.28336 v_acc: 0.72201 |  iteration: 14569 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 896 loss: 1.34723 acc: 0.70508 | v_loss: 1.29601 v_acc: 0.71973 |  iteration: 14570 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 897 loss: 1.45451 acc: 0.69824 | v_loss: 1.49429 v_acc: 0.69206 |  iteration: 14571 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 898 loss: 1.49759 acc: 0.69401 | v_loss: 1.32619 v_acc: 0.70931 |  iteration: 14572 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 899 loss: 1.41221 acc: 0.70801 | v_loss: 1.29596 v_acc: 0.71452 |  iteration: 14573 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 900 loss: 1.68183 acc: 0.68132 | v_loss: 1.29398 v_acc: 0.71940 |  iteration: 14574 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 901 loss: 1.41009 acc: 0.70898 | v_loss: 1.42719 v_acc: 0.70573 |  iteration: 14575 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 902 loss: 1.38466 acc: 0.70833 | v_loss: 1.30456 v_acc: 0.73242 |  iteration: 14576 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 903 loss: 1.40140 acc: 0.70345 | v_loss: 1.53574 v_acc: 0.71387 |  iteration: 14577 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 904 loss: 1.64211 acc: 0.68132 | v_loss: 1.28241 v_acc: 0.70052 |  iteration: 14578 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 905 loss: 1.53924 acc: 0.69922 | v_loss: 1.28762 v_acc: 0.70215 |  iteration: 14579 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 906 loss: 1.52079 acc: 0.69531 | v_loss: 1.43149 v_acc: 0.70638 |  iteration: 14580 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 907 loss: 1.42010 acc: 0.70150 | v_loss: 1.46181 v_acc: 0.70573 |  iteration: 14581 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 908 loss: 1.46710 acc: 0.69759 | v_loss: 1.50570 v_acc: 0.68978 |  iteration: 14582 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 909 loss: 1.46664 acc: 0.70312 | v_loss: 1.45963 v_acc: 0.70638 |  iteration: 14583 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 910 loss: 1.58707 acc: 0.68880 | v_loss: 1.41551 v_acc: 0.70540 |  iteration: 14584 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 911 loss: 1.50767 acc: 0.70117 | v_loss: 1.39940 v_acc: 0.70638 |  iteration: 14585 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 912 loss: 1.40414 acc: 0.71029 | v_loss: 1.41376 v_acc: 0.70443 |  iteration: 14586 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 913 loss: 1.45528 acc: 0.70182 | v_loss: 1.27441 v_acc: 0.71159 |  iteration: 14587 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 914 loss: 1.43814 acc: 0.70280 | v_loss: 1.31683 v_acc: 0.72396 |  iteration: 14588 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 915 loss: 1.40169 acc: 0.70052 | v_loss: 1.19897 v_acc: 0.70833 |  iteration: 14589 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 916 loss: 1.44027 acc: 0.70508 | v_loss: 1.33965 v_acc: 0.70703 |  iteration: 14590 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 917 loss: 1.38181 acc: 0.70605 | v_loss: 1.50982 v_acc: 0.69922 |  iteration: 14591 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 918 loss: 1.48463 acc: 0.69922 | v_loss: 1.34872 v_acc: 0.71484 |  iteration: 14592 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 919 loss: 1.45322 acc: 0.69727 | v_loss: 1.35282 v_acc: 0.70312 |  iteration: 14593 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 920 loss: 1.40747 acc: 0.71029 | v_loss: 1.24769 v_acc: 0.71680 |  iteration: 14594 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 921 loss: 1.46807 acc: 0.70736 | v_loss: 1.23190 v_acc: 0.70638 |  iteration: 14595 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 922 loss: 1.51124 acc: 0.69564 | v_loss: 1.24150 v_acc: 0.73600 |  iteration: 14596 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 923 loss: 1.28071 acc: 0.72559 | v_loss: 1.26399 v_acc: 0.72103 |  iteration: 14597 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 924 loss: 1.42058 acc: 0.70898 | v_loss: 1.32798 v_acc: 0.73145 |  iteration: 14598 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 925 loss: 1.47917 acc: 0.69076 | v_loss: 1.26161 v_acc: 0.72461 |  iteration: 14599 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 926 loss: 1.50843 acc: 0.70150 | v_loss: 1.29970 v_acc: 0.71680 |  iteration: 14600 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 927 loss: 1.41270 acc: 0.70020 | v_loss: 1.40812 v_acc: 0.71224 |  iteration: 14601 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 928 loss: 1.37367 acc: 0.71322 | v_loss: 1.38002 v_acc: 0.72038 |  iteration: 14602 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 929 loss: 1.37293 acc: 0.70247 | v_loss: 1.48546 v_acc: 0.69661 |  iteration: 14603 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 930 loss: 1.38975 acc: 0.70475 | v_loss: 1.40486 v_acc: 0.71615 |  iteration: 14604 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 931 loss: 1.44063 acc: 0.70475 | v_loss: 1.17106 v_acc: 0.74544 |  iteration: 14605 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 932 loss: 1.47139 acc: 0.70801 | v_loss: 1.25326 v_acc: 0.70931 |  iteration: 14606 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 933 loss: 1.54493 acc: 0.69531 | v_loss: 1.51127 v_acc: 0.70280 |  iteration: 14607 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 934 loss: 1.43973 acc: 0.69564 | v_loss: 1.22818 v_acc: 0.70866 |  iteration: 14608 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 935 loss: 1.49915 acc: 0.70085 | v_loss: 1.32806 v_acc: 0.71257 |  iteration: 14609 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 936 loss: 1.45788 acc: 0.70150 | v_loss: 1.35446 v_acc: 0.69499 |  iteration: 14610 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 937 loss: 1.37555 acc: 0.70345 | v_loss: 1.31073 v_acc: 0.70996 |  iteration: 14611 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 938 loss: 1.47157 acc: 0.70573 | v_loss: 1.37026 v_acc: 0.69596 |  iteration: 14612 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 939 loss: 1.45748 acc: 0.69564 | v_loss: 1.47481 v_acc: 0.70833 |  iteration: 14613 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 940 loss: 1.45829 acc: 0.69596 | v_loss: 1.31678 v_acc: 0.72363 |  iteration: 14614 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 941 loss: 1.34022 acc: 0.70540 | v_loss: 1.45296 v_acc: 0.70280 |  iteration: 14615 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 942 loss: 1.37852 acc: 0.71354 | v_loss: 1.35660 v_acc: 0.69857 |  iteration: 14616 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 943 loss: 1.37752 acc: 0.71387 | v_loss: 1.32581 v_acc: 0.70833 |  iteration: 14617 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 944 loss: 1.41353 acc: 0.70475 | v_loss: 1.56272 v_acc: 0.68522 |  iteration: 14618 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 945 loss: 1.52243 acc: 0.68652 | v_loss: 1.30530 v_acc: 0.72168 |  iteration: 14619 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 946 loss: 1.32219 acc: 0.71224 | v_loss: 1.60167 v_acc: 0.67969 |  iteration: 14620 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 947 loss: 1.43218 acc: 0.70475 | v_loss: 1.46253 v_acc: 0.69661 |  iteration: 14621 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 948 loss: 1.38306 acc: 0.71517 | v_loss: 1.54320 v_acc: 0.69238 |  iteration: 14622 teacher: 0 stage: sketch lr: 0.000365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 949 loss: 1.50814 acc: 0.69694 | v_loss: 1.37223 v_acc: 0.70182 |  iteration: 14623 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 950 loss: 1.36947 acc: 0.70931 | v_loss: 1.32576 v_acc: 0.70638 |  iteration: 14624 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 951 loss: 1.42670 acc: 0.70117 | v_loss: 1.32330 v_acc: 0.70410 |  iteration: 14625 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 952 loss: 1.46339 acc: 0.70020 | v_loss: 1.31958 v_acc: 0.71842 |  iteration: 14626 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 953 loss: 1.42094 acc: 0.70736 | v_loss: 1.55310 v_acc: 0.68848 |  iteration: 14627 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 954 loss: 1.55428 acc: 0.69564 | v_loss: 1.38920 v_acc: 0.70573 |  iteration: 14628 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 955 loss: 1.50865 acc: 0.70312 | v_loss: 1.36482 v_acc: 0.70866 |  iteration: 14629 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 956 loss: 1.41972 acc: 0.70378 | v_loss: 1.37921 v_acc: 0.71191 |  iteration: 14630 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 957 loss: 1.48010 acc: 0.70117 | v_loss: 1.28318 v_acc: 0.70150 |  iteration: 14631 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 958 loss: 1.40984 acc: 0.69564 | v_loss: 1.42253 v_acc: 0.69889 |  iteration: 14632 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 959 loss: 1.43379 acc: 0.70247 | v_loss: 1.41627 v_acc: 0.71387 |  iteration: 14633 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 960 loss: 1.35304 acc: 0.71126 | v_loss: 1.29557 v_acc: 0.71940 |  iteration: 14634 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 961 loss: 1.50193 acc: 0.69499 | v_loss: 1.24476 v_acc: 0.72721 |  iteration: 14635 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 962 loss: 1.38706 acc: 0.70833 | v_loss: 1.37465 v_acc: 0.72038 |  iteration: 14636 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 963 loss: 1.42603 acc: 0.70703 | v_loss: 1.41291 v_acc: 0.70605 |  iteration: 14637 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 964 loss: 1.47702 acc: 0.70443 | v_loss: 1.41868 v_acc: 0.70475 |  iteration: 14638 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 965 loss: 1.38556 acc: 0.70345 | v_loss: 1.22671 v_acc: 0.71452 |  iteration: 14639 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 966 loss: 1.40342 acc: 0.70703 | v_loss: 1.38826 v_acc: 0.72819 |  iteration: 14640 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 967 loss: 1.44371 acc: 0.69661 | v_loss: 1.47364 v_acc: 0.69857 |  iteration: 14641 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 968 loss: 1.33538 acc: 0.70736 | v_loss: 1.40816 v_acc: 0.71973 |  iteration: 14642 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 969 loss: 1.35398 acc: 0.70996 | v_loss: 1.25509 v_acc: 0.71810 |  iteration: 14643 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 970 loss: 1.47823 acc: 0.69792 | v_loss: 1.21487 v_acc: 0.73438 |  iteration: 14644 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 971 loss: 1.44036 acc: 0.69499 | v_loss: 1.21241 v_acc: 0.72656 |  iteration: 14645 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 972 loss: 1.37425 acc: 0.70443 | v_loss: 1.27941 v_acc: 0.70671 |  iteration: 14646 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 973 loss: 1.45847 acc: 0.70150 | v_loss: 1.45349 v_acc: 0.69499 |  iteration: 14647 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 974 loss: 1.45449 acc: 0.69727 | v_loss: 1.28305 v_acc: 0.71224 |  iteration: 14648 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 975 loss: 1.38511 acc: 0.70996 | v_loss: 1.47829 v_acc: 0.70833 |  iteration: 14649 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 976 loss: 1.43349 acc: 0.70345 | v_loss: 1.68828 v_acc: 0.69238 |  iteration: 14650 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 977 loss: 1.50610 acc: 0.69141 | v_loss: 1.53232 v_acc: 0.69531 |  iteration: 14651 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 978 loss: 1.34289 acc: 0.71126 | v_loss: 1.29850 v_acc: 0.72168 |  iteration: 14652 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 979 loss: 1.51777 acc: 0.69141 | v_loss: 1.35686 v_acc: 0.70866 |  iteration: 14653 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 980 loss: 1.36032 acc: 0.70833 | v_loss: 1.21101 v_acc: 0.72331 |  iteration: 14654 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 981 loss: 1.29714 acc: 0.71387 | v_loss: 1.41028 v_acc: 0.70247 |  iteration: 14655 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 982 loss: 1.50521 acc: 0.69336 | v_loss: 1.36180 v_acc: 0.71224 |  iteration: 14656 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 983 loss: 1.47091 acc: 0.69173 | v_loss: 1.35974 v_acc: 0.72819 |  iteration: 14657 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 984 loss: 1.46067 acc: 0.69531 | v_loss: 1.36974 v_acc: 0.72135 |  iteration: 14658 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 985 loss: 1.34751 acc: 0.70801 | v_loss: 1.37490 v_acc: 0.70573 |  iteration: 14659 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 986 loss: 1.32094 acc: 0.71647 | v_loss: 1.30368 v_acc: 0.72005 |  iteration: 14660 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 987 loss: 1.40224 acc: 0.70475 | v_loss: 1.31225 v_acc: 0.71810 |  iteration: 14661 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 988 loss: 1.43919 acc: 0.70085 | v_loss: 1.53974 v_acc: 0.69043 |  iteration: 14662 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 989 loss: 1.38911 acc: 0.71257 | v_loss: 1.32613 v_acc: 0.71094 |  iteration: 14663 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 990 loss: 1.47653 acc: 0.70410 | v_loss: 1.30198 v_acc: 0.71549 |  iteration: 14664 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 991 loss: 1.44366 acc: 0.70085 | v_loss: 1.27939 v_acc: 0.71973 |  iteration: 14665 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 992 loss: 1.43388 acc: 0.69206 | v_loss: 1.42594 v_acc: 0.70573 |  iteration: 14666 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 993 loss: 1.37703 acc: 0.70866 | v_loss: 1.31210 v_acc: 0.73112 |  iteration: 14667 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 994 loss: 1.42027 acc: 0.70898 | v_loss: 1.54726 v_acc: 0.71647 |  iteration: 14668 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 995 loss: 1.37517 acc: 0.71029 | v_loss: 1.28563 v_acc: 0.70150 |  iteration: 14669 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 996 loss: 1.51215 acc: 0.68717 | v_loss: 1.27431 v_acc: 0.70573 |  iteration: 14670 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 997 loss: 1.45271 acc: 0.70182 | v_loss: 1.44286 v_acc: 0.70378 |  iteration: 14671 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 998 loss: 1.51381 acc: 0.69727 | v_loss: 1.47437 v_acc: 0.70150 |  iteration: 14672 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 999 loss: 1.45317 acc: 0.70052 | v_loss: 1.51997 v_acc: 0.69368 |  iteration: 14673 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1000 loss: 1.38019 acc: 0.70671 | v_loss: 1.47244 v_acc: 0.70833 |  iteration: 14674 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 1001 loss: 1.49116 acc: 0.69336 | v_loss: 1.41714 v_acc: 0.70085 |  iteration: 14675 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1002 loss: 1.53861 acc: 0.70182 | v_loss: 1.40904 v_acc: 0.70964 |  iteration: 14676 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1003 loss: 1.41637 acc: 0.70866 | v_loss: 1.39875 v_acc: 0.70443 |  iteration: 14677 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 1004 loss: 1.46991 acc: 0.70605 | v_loss: 1.26452 v_acc: 0.71159 |  iteration: 14678 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 1005 loss: 1.41415 acc: 0.70410 | v_loss: 1.31909 v_acc: 0.72396 |  iteration: 14679 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1006 loss: 1.43899 acc: 0.70605 | v_loss: 1.21058 v_acc: 0.70638 |  iteration: 14680 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 1007 loss: 1.46809 acc: 0.70280 | v_loss: 1.35121 v_acc: 0.70312 |  iteration: 14681 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1008 loss: 1.45576 acc: 0.70280 | v_loss: 1.50353 v_acc: 0.69889 |  iteration: 14682 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1009 loss: 1.43183 acc: 0.70247 | v_loss: 1.35127 v_acc: 0.70671 |  iteration: 14683 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 1010 loss: 1.44094 acc: 0.70215 | v_loss: 1.35416 v_acc: 0.69759 |  iteration: 14684 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 1011 loss: 1.46261 acc: 0.70573 | v_loss: 1.25682 v_acc: 0.71094 |  iteration: 14685 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1012 loss: 1.55914 acc: 0.69661 | v_loss: 1.25203 v_acc: 0.70345 |  iteration: 14686 teacher: 0 stage: sketch lr: 0.000365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1013 loss: 1.40175 acc: 0.71061 | v_loss: 1.25281 v_acc: 0.73503 |  iteration: 14687 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1014 loss: 1.39485 acc: 0.71159 | v_loss: 1.27930 v_acc: 0.72168 |  iteration: 14688 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 1015 loss: 1.51174 acc: 0.69141 | v_loss: 1.34588 v_acc: 0.73145 |  iteration: 14689 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1016 loss: 1.43811 acc: 0.70573 | v_loss: 1.26200 v_acc: 0.72461 |  iteration: 14690 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1017 loss: 1.53415 acc: 0.69824 | v_loss: 1.31401 v_acc: 0.72005 |  iteration: 14691 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 1018 loss: 1.44091 acc: 0.70443 | v_loss: 1.42107 v_acc: 0.71224 |  iteration: 14692 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 1019 loss: 1.44958 acc: 0.70443 | v_loss: 1.39679 v_acc: 0.72070 |  iteration: 14693 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1020 loss: 1.43858 acc: 0.71289 | v_loss: 1.47793 v_acc: 0.69661 |  iteration: 14694 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1021 loss: 1.44004 acc: 0.70573 | v_loss: 1.40941 v_acc: 0.71745 |  iteration: 14695 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 1022 loss: 1.44966 acc: 0.70703 | v_loss: 1.18042 v_acc: 0.74382 |  iteration: 14696 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1023 loss: 1.42699 acc: 0.70638 | v_loss: 1.26766 v_acc: 0.70182 |  iteration: 14697 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1024 loss: 1.43749 acc: 0.70638 | v_loss: 1.50789 v_acc: 0.70866 |  iteration: 14698 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1025 loss: 1.35122 acc: 0.71419 | v_loss: 1.22510 v_acc: 0.72363 |  iteration: 14699 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1026 loss: 1.50844 acc: 0.70150 | v_loss: 1.32140 v_acc: 0.71517 |  iteration: 14700 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1027 loss: 1.40186 acc: 0.70410 | v_loss: 1.36622 v_acc: 0.69499 |  iteration: 14701 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1028 loss: 1.46985 acc: 0.70345 | v_loss: 1.30673 v_acc: 0.70996 |  iteration: 14702 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1029 loss: 1.47695 acc: 0.69271 | v_loss: 1.37372 v_acc: 0.69434 |  iteration: 14703 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1030 loss: 1.43040 acc: 0.69531 | v_loss: 1.46798 v_acc: 0.71712 |  iteration: 14704 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1031 loss: 1.33887 acc: 0.70833 | v_loss: 1.32797 v_acc: 0.72786 |  iteration: 14705 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1032 loss: 1.45990 acc: 0.70020 | v_loss: 1.43755 v_acc: 0.70085 |  iteration: 14706 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1033 loss: 1.46702 acc: 0.69434 | v_loss: 1.37302 v_acc: 0.69076 |  iteration: 14707 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1034 loss: 1.41682 acc: 0.70215 | v_loss: 1.30712 v_acc: 0.71029 |  iteration: 14708 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1035 loss: 1.46683 acc: 0.69661 | v_loss: 1.59392 v_acc: 0.68066 |  iteration: 14709 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1036 loss: 1.44631 acc: 0.69727 | v_loss: 1.30680 v_acc: 0.71842 |  iteration: 14710 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1037 loss: 1.44673 acc: 0.69271 | v_loss: 1.62633 v_acc: 0.67513 |  iteration: 14711 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1038 loss: 1.42241 acc: 0.69401 | v_loss: 1.48461 v_acc: 0.69401 |  iteration: 14712 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1039 loss: 1.36243 acc: 0.70768 | v_loss: 1.53791 v_acc: 0.69206 |  iteration: 14713 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1040 loss: 1.49919 acc: 0.69173 | v_loss: 1.38153 v_acc: 0.70085 |  iteration: 14714 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1041 loss: 1.40310 acc: 0.70671 | v_loss: 1.32807 v_acc: 0.70540 |  iteration: 14715 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1042 loss: 1.35366 acc: 0.70736 | v_loss: 1.32498 v_acc: 0.70443 |  iteration: 14716 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1043 loss: 1.42958 acc: 0.69889 | v_loss: 1.33497 v_acc: 0.71842 |  iteration: 14717 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1044 loss: 1.40644 acc: 0.70605 | v_loss: 1.54265 v_acc: 0.69108 |  iteration: 14718 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1045 loss: 1.46222 acc: 0.70508 | v_loss: 1.36955 v_acc: 0.71126 |  iteration: 14719 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1046 loss: 1.43965 acc: 0.70638 | v_loss: 1.35939 v_acc: 0.70996 |  iteration: 14720 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1047 loss: 1.33655 acc: 0.70475 | v_loss: 1.39120 v_acc: 0.71680 |  iteration: 14721 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1048 loss: 1.51760 acc: 0.70182 | v_loss: 1.27932 v_acc: 0.70573 |  iteration: 14722 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1049 loss: 1.51825 acc: 0.71094 | v_loss: 1.44210 v_acc: 0.69434 |  iteration: 14723 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1050 loss: 1.46578 acc: 0.70768 | v_loss: 1.43004 v_acc: 0.71582 |  iteration: 14724 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1051 loss: 1.48947 acc: 0.70150 | v_loss: 1.30193 v_acc: 0.71777 |  iteration: 14725 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1052 loss: 1.42538 acc: 0.70410 | v_loss: 1.26698 v_acc: 0.72168 |  iteration: 14726 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1053 loss: 1.41660 acc: 0.70475 | v_loss: 1.36967 v_acc: 0.71582 |  iteration: 14727 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1054 loss: 1.50618 acc: 0.70020 | v_loss: 1.42364 v_acc: 0.69759 |  iteration: 14728 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1055 loss: 1.47942 acc: 0.71289 | v_loss: 1.42379 v_acc: 0.70280 |  iteration: 14729 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1056 loss: 1.47301 acc: 0.69629 | v_loss: 1.24401 v_acc: 0.71419 |  iteration: 14730 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1057 loss: 1.42902 acc: 0.70898 | v_loss: 1.38105 v_acc: 0.72754 |  iteration: 14731 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1058 loss: 1.43257 acc: 0.68913 | v_loss: 1.46953 v_acc: 0.69759 |  iteration: 14732 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1059 loss: 1.41969 acc: 0.70150 | v_loss: 1.39819 v_acc: 0.72233 |  iteration: 14733 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1060 loss: 1.44482 acc: 0.70117 | v_loss: 1.25187 v_acc: 0.71810 |  iteration: 14734 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1061 loss: 1.55189 acc: 0.70150 | v_loss: 1.20743 v_acc: 0.73861 |  iteration: 14735 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1062 loss: 1.46773 acc: 0.70052 | v_loss: 1.21636 v_acc: 0.72559 |  iteration: 14736 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1063 loss: 1.45223 acc: 0.70638 | v_loss: 1.27249 v_acc: 0.71029 |  iteration: 14737 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1064 loss: 1.46446 acc: 0.69661 | v_loss: 1.44282 v_acc: 0.70671 |  iteration: 14738 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1065 loss: 1.44482 acc: 0.69564 | v_loss: 1.28036 v_acc: 0.71549 |  iteration: 14739 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1066 loss: 1.49606 acc: 0.69173 | v_loss: 1.49324 v_acc: 0.70475 |  iteration: 14740 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1067 loss: 1.47073 acc: 0.70117 | v_loss: 1.67934 v_acc: 0.69141 |  iteration: 14741 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1068 loss: 1.44175 acc: 0.70085 | v_loss: 1.53338 v_acc: 0.69596 |  iteration: 14742 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1069 loss: 1.28879 acc: 0.71419 | v_loss: 1.29705 v_acc: 0.72266 |  iteration: 14743 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1070 loss: 1.37769 acc: 0.70215 | v_loss: 1.36463 v_acc: 0.70312 |  iteration: 14744 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1071 loss: 1.45471 acc: 0.69987 | v_loss: 1.22802 v_acc: 0.72103 |  iteration: 14745 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1072 loss: 1.31008 acc: 0.70931 | v_loss: 1.41421 v_acc: 0.70020 |  iteration: 14746 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1073 loss: 1.38735 acc: 0.69336 | v_loss: 1.35504 v_acc: 0.71094 |  iteration: 14747 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1074 loss: 1.43093 acc: 0.70215 | v_loss: 1.35645 v_acc: 0.72949 |  iteration: 14748 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1075 loss: 1.49708 acc: 0.70215 | v_loss: 1.36855 v_acc: 0.71810 |  iteration: 14749 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1076 loss: 1.48514 acc: 0.70215 | v_loss: 1.37864 v_acc: 0.70443 |  iteration: 14750 teacher: 1 stage: sketch lr: 0.000364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1077 loss: 1.47840 acc: 0.69954 | v_loss: 1.28296 v_acc: 0.72233 |  iteration: 14751 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1078 loss: 1.43132 acc: 0.69466 | v_loss: 1.30317 v_acc: 0.72135 |  iteration: 14752 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1079 loss: 1.43640 acc: 0.70801 | v_loss: 1.48567 v_acc: 0.69303 |  iteration: 14753 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1080 loss: 1.45474 acc: 0.70573 | v_loss: 1.32853 v_acc: 0.71159 |  iteration: 14754 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1081 loss: 1.38969 acc: 0.71224 | v_loss: 1.30679 v_acc: 0.71549 |  iteration: 14755 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1082 loss: 1.44755 acc: 0.69889 | v_loss: 1.28771 v_acc: 0.72070 |  iteration: 14756 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1083 loss: 1.37620 acc: 0.71191 | v_loss: 1.43675 v_acc: 0.70540 |  iteration: 14757 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1084 loss: 1.45449 acc: 0.70052 | v_loss: 1.30749 v_acc: 0.73112 |  iteration: 14758 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1085 loss: 1.36631 acc: 0.71257 | v_loss: 1.53884 v_acc: 0.71452 |  iteration: 14759 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1086 loss: 1.40253 acc: 0.70605 | v_loss: 1.28823 v_acc: 0.69824 |  iteration: 14760 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1087 loss: 1.56195 acc: 0.69824 | v_loss: 1.28119 v_acc: 0.70703 |  iteration: 14761 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1088 loss: 1.42447 acc: 0.69889 | v_loss: 1.42594 v_acc: 0.70475 |  iteration: 14762 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1089 loss: 1.52678 acc: 0.68359 | v_loss: 1.45745 v_acc: 0.70443 |  iteration: 14763 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1090 loss: 1.46528 acc: 0.70378 | v_loss: 1.50065 v_acc: 0.69076 |  iteration: 14764 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1091 loss: 1.39522 acc: 0.71029 | v_loss: 1.46607 v_acc: 0.70605 |  iteration: 14765 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1092 loss: 1.48537 acc: 0.69499 | v_loss: 1.41364 v_acc: 0.70736 |  iteration: 14766 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1093 loss: 1.39405 acc: 0.70312 | v_loss: 1.40016 v_acc: 0.70866 |  iteration: 14767 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1094 loss: 1.40244 acc: 0.69889 | v_loss: 1.39714 v_acc: 0.70671 |  iteration: 14768 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1095 loss: 1.50390 acc: 0.70182 | v_loss: 1.26520 v_acc: 0.71322 |  iteration: 14769 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1096 loss: 1.51980 acc: 0.69368 | v_loss: 1.31942 v_acc: 0.72461 |  iteration: 14770 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1097 loss: 1.38490 acc: 0.70671 | v_loss: 1.18578 v_acc: 0.71549 |  iteration: 14771 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1098 loss: 1.40469 acc: 0.70703 | v_loss: 1.34185 v_acc: 0.70833 |  iteration: 14772 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1099 loss: 1.36882 acc: 0.71159 | v_loss: 1.50329 v_acc: 0.69954 |  iteration: 14773 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1100 loss: 1.40603 acc: 0.71094 | v_loss: 1.32376 v_acc: 0.71484 |  iteration: 14774 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1101 loss: 1.48264 acc: 0.70638 | v_loss: 1.34379 v_acc: 0.70312 |  iteration: 14775 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1102 loss: 1.40611 acc: 0.70605 | v_loss: 1.25169 v_acc: 0.71126 |  iteration: 14776 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1103 loss: 1.45238 acc: 0.70215 | v_loss: 1.25971 v_acc: 0.70443 |  iteration: 14777 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1104 loss: 1.45732 acc: 0.70378 | v_loss: 1.21880 v_acc: 0.73926 |  iteration: 14778 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1105 loss: 1.48173 acc: 0.69303 | v_loss: 1.27153 v_acc: 0.71908 |  iteration: 14779 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1106 loss: 1.36990 acc: 0.71257 | v_loss: 1.32607 v_acc: 0.73112 |  iteration: 14780 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1107 loss: 1.51596 acc: 0.69954 | v_loss: 1.26595 v_acc: 0.71940 |  iteration: 14781 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1108 loss: 1.37467 acc: 0.71354 | v_loss: 1.29978 v_acc: 0.72396 |  iteration: 14782 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1109 loss: 1.42347 acc: 0.71582 | v_loss: 1.39960 v_acc: 0.71419 |  iteration: 14783 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1110 loss: 1.43448 acc: 0.70247 | v_loss: 1.37950 v_acc: 0.72363 |  iteration: 14784 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1111 loss: 1.38125 acc: 0.71159 | v_loss: 1.49086 v_acc: 0.69857 |  iteration: 14785 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1112 loss: 1.36701 acc: 0.71191 | v_loss: 1.40715 v_acc: 0.71745 |  iteration: 14786 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1113 loss: 1.40640 acc: 0.70247 | v_loss: 1.17144 v_acc: 0.74414 |  iteration: 14787 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1114 loss: 1.34203 acc: 0.71484 | v_loss: 1.25600 v_acc: 0.70931 |  iteration: 14788 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1115 loss: 1.47758 acc: 0.70410 | v_loss: 1.53145 v_acc: 0.69954 |  iteration: 14789 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1116 loss: 1.44475 acc: 0.69857 | v_loss: 1.20989 v_acc: 0.70671 |  iteration: 14790 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1117 loss: 1.47528 acc: 0.70345 | v_loss: 1.33808 v_acc: 0.71257 |  iteration: 14791 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1118 loss: 1.45213 acc: 0.71517 | v_loss: 1.37979 v_acc: 0.69303 |  iteration: 14792 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1119 loss: 1.46724 acc: 0.69759 | v_loss: 1.28794 v_acc: 0.71777 |  iteration: 14793 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1120 loss: 1.38159 acc: 0.70475 | v_loss: 1.36816 v_acc: 0.70215 |  iteration: 14794 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1121 loss: 1.36406 acc: 0.70605 | v_loss: 1.47927 v_acc: 0.72005 |  iteration: 14795 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1122 loss: 1.41428 acc: 0.70280 | v_loss: 1.32058 v_acc: 0.72786 |  iteration: 14796 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1123 loss: 1.47157 acc: 0.70215 | v_loss: 1.44673 v_acc: 0.70540 |  iteration: 14797 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1124 loss: 1.48712 acc: 0.70508 | v_loss: 1.36618 v_acc: 0.69857 |  iteration: 14798 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1125 loss: 1.32916 acc: 0.71680 | v_loss: 1.31807 v_acc: 0.70931 |  iteration: 14799 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1126 loss: 1.41261 acc: 0.70638 | v_loss: 1.54628 v_acc: 0.68848 |  iteration: 14800 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1127 loss: 1.51348 acc: 0.69792 | v_loss: 1.29477 v_acc: 0.71940 |  iteration: 14801 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1128 loss: 1.39675 acc: 0.70540 | v_loss: 1.59241 v_acc: 0.68392 |  iteration: 14802 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1129 loss: 1.40760 acc: 0.70964 | v_loss: 1.47524 v_acc: 0.69759 |  iteration: 14803 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1130 loss: 1.46018 acc: 0.69368 | v_loss: 1.51448 v_acc: 0.68978 |  iteration: 14804 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1131 loss: 1.41903 acc: 0.70540 | v_loss: 1.37736 v_acc: 0.69792 |  iteration: 14805 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1132 loss: 1.45790 acc: 0.70605 | v_loss: 1.31694 v_acc: 0.70378 |  iteration: 14806 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1133 loss: 1.46890 acc: 0.70150 | v_loss: 1.33245 v_acc: 0.70215 |  iteration: 14807 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1134 loss: 1.40488 acc: 0.70052 | v_loss: 1.32301 v_acc: 0.71615 |  iteration: 14808 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1135 loss: 1.52103 acc: 0.69629 | v_loss: 1.53557 v_acc: 0.68945 |  iteration: 14809 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1136 loss: 1.48976 acc: 0.70996 | v_loss: 1.37339 v_acc: 0.70475 |  iteration: 14810 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1137 loss: 1.44627 acc: 0.71419 | v_loss: 1.35687 v_acc: 0.70996 |  iteration: 14811 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1138 loss: 1.36774 acc: 0.70671 | v_loss: 1.38945 v_acc: 0.71680 |  iteration: 14812 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1139 loss: 1.39135 acc: 0.71354 | v_loss: 1.26744 v_acc: 0.70573 |  iteration: 14813 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1140 loss: 1.57502 acc: 0.69238 | v_loss: 1.42507 v_acc: 0.69792 |  iteration: 14814 teacher: 0 stage: sketch lr: 0.000363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1141 loss: 1.38314 acc: 0.70768 | v_loss: 1.42799 v_acc: 0.71289 |  iteration: 14815 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1142 loss: 1.48772 acc: 0.69271 | v_loss: 1.28710 v_acc: 0.71875 |  iteration: 14816 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1143 loss: 1.48645 acc: 0.70410 | v_loss: 1.25819 v_acc: 0.72754 |  iteration: 14817 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1144 loss: 1.40527 acc: 0.70996 | v_loss: 1.37008 v_acc: 0.71810 |  iteration: 14818 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1145 loss: 1.47836 acc: 0.69076 | v_loss: 1.42597 v_acc: 0.70182 |  iteration: 14819 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1146 loss: 1.46409 acc: 0.70671 | v_loss: 1.43045 v_acc: 0.70345 |  iteration: 14820 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1147 loss: 1.40467 acc: 0.71094 | v_loss: 1.25467 v_acc: 0.71126 |  iteration: 14821 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1148 loss: 1.43986 acc: 0.70345 | v_loss: 1.39188 v_acc: 0.72689 |  iteration: 14822 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1149 loss: 1.43278 acc: 0.70280 | v_loss: 1.46965 v_acc: 0.69759 |  iteration: 14823 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1150 loss: 1.47997 acc: 0.70638 | v_loss: 1.39729 v_acc: 0.72070 |  iteration: 14824 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1151 loss: 1.54005 acc: 0.69271 | v_loss: 1.25135 v_acc: 0.72201 |  iteration: 14825 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1152 loss: 1.45597 acc: 0.70150 | v_loss: 1.20000 v_acc: 0.74023 |  iteration: 14826 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1153 loss: 1.33627 acc: 0.70866 | v_loss: 1.21004 v_acc: 0.72559 |  iteration: 14827 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1154 loss: 1.36666 acc: 0.71257 | v_loss: 1.28168 v_acc: 0.71126 |  iteration: 14828 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1155 loss: 1.51634 acc: 0.70801 | v_loss: 1.44462 v_acc: 0.70671 |  iteration: 14829 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1156 loss: 1.40924 acc: 0.70638 | v_loss: 1.27589 v_acc: 0.71419 |  iteration: 14830 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1157 loss: 1.33638 acc: 0.70671 | v_loss: 1.44766 v_acc: 0.71582 |  iteration: 14831 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1158 loss: 1.30837 acc: 0.70671 | v_loss: 1.65990 v_acc: 0.69401 |  iteration: 14832 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1159 loss: 1.34064 acc: 0.71452 | v_loss: 1.52678 v_acc: 0.69922 |  iteration: 14833 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1160 loss: 1.43601 acc: 0.69889 | v_loss: 1.30097 v_acc: 0.71582 |  iteration: 14834 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1161 loss: 1.48653 acc: 0.68978 | v_loss: 1.37672 v_acc: 0.70410 |  iteration: 14835 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1162 loss: 1.35085 acc: 0.70378 | v_loss: 1.21978 v_acc: 0.72070 |  iteration: 14836 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1163 loss: 1.44802 acc: 0.70150 | v_loss: 1.43064 v_acc: 0.70247 |  iteration: 14837 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1164 loss: 1.41754 acc: 0.70736 | v_loss: 1.35663 v_acc: 0.71973 |  iteration: 14838 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1165 loss: 1.37816 acc: 0.70508 | v_loss: 1.36432 v_acc: 0.72852 |  iteration: 14839 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1166 loss: 1.33989 acc: 0.70443 | v_loss: 1.36385 v_acc: 0.71875 |  iteration: 14840 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1167 loss: 1.46553 acc: 0.69564 | v_loss: 1.37384 v_acc: 0.70508 |  iteration: 14841 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1168 loss: 1.35063 acc: 0.70866 | v_loss: 1.28014 v_acc: 0.72135 |  iteration: 14842 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1169 loss: 1.40747 acc: 0.70801 | v_loss: 1.30043 v_acc: 0.72005 |  iteration: 14843 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1170 loss: 1.43295 acc: 0.70736 | v_loss: 1.49749 v_acc: 0.69076 |  iteration: 14844 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1171 loss: 1.38285 acc: 0.70996 | v_loss: 1.32962 v_acc: 0.70833 |  iteration: 14845 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1172 loss: 1.35881 acc: 0.72168 | v_loss: 1.30845 v_acc: 0.71680 |  iteration: 14846 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1173 loss: 1.35565 acc: 0.71191 | v_loss: 1.29459 v_acc: 0.72168 |  iteration: 14847 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1174 loss: 1.50796 acc: 0.69238 | v_loss: 1.43415 v_acc: 0.70768 |  iteration: 14848 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1175 loss: 1.41040 acc: 0.70020 | v_loss: 1.31069 v_acc: 0.73177 |  iteration: 14849 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1176 loss: 1.46641 acc: 0.69954 | v_loss: 1.54467 v_acc: 0.71615 |  iteration: 14850 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1177 loss: 1.44091 acc: 0.70475 | v_loss: 1.28298 v_acc: 0.69759 |  iteration: 14851 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1178 loss: 1.44377 acc: 0.70052 | v_loss: 1.28090 v_acc: 0.70443 |  iteration: 14852 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1179 loss: 1.44052 acc: 0.70247 | v_loss: 1.42938 v_acc: 0.70312 |  iteration: 14853 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1180 loss: 1.46619 acc: 0.69889 | v_loss: 1.46256 v_acc: 0.70150 |  iteration: 14854 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1181 loss: 1.44855 acc: 0.69108 | v_loss: 1.50730 v_acc: 0.69368 |  iteration: 14855 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1182 loss: 1.42003 acc: 0.69759 | v_loss: 1.47063 v_acc: 0.70833 |  iteration: 14856 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1183 loss: 1.36433 acc: 0.70801 | v_loss: 1.41788 v_acc: 0.70247 |  iteration: 14857 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1184 loss: 1.36119 acc: 0.70964 | v_loss: 1.40913 v_acc: 0.70866 |  iteration: 14858 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1185 loss: 1.34157 acc: 0.71094 | v_loss: 1.39665 v_acc: 0.70475 |  iteration: 14859 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1186 loss: 1.48999 acc: 0.68652 | v_loss: 1.25589 v_acc: 0.71159 |  iteration: 14860 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1187 loss: 1.39980 acc: 0.70150 | v_loss: 1.33172 v_acc: 0.72396 |  iteration: 14861 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1188 loss: 1.32472 acc: 0.70150 | v_loss: 1.18681 v_acc: 0.70638 |  iteration: 14862 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1189 loss: 1.41244 acc: 0.70312 | v_loss: 1.34102 v_acc: 0.70247 |  iteration: 14863 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1190 loss: 1.42069 acc: 0.69922 | v_loss: 1.51071 v_acc: 0.70020 |  iteration: 14864 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1191 loss: 1.52974 acc: 0.69206 | v_loss: 1.34238 v_acc: 0.70833 |  iteration: 14865 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1192 loss: 1.43510 acc: 0.70182 | v_loss: 1.34937 v_acc: 0.69727 |  iteration: 14866 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1193 loss: 1.30622 acc: 0.72168 | v_loss: 1.25348 v_acc: 0.71126 |  iteration: 14867 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1194 loss: 1.54802 acc: 0.69238 | v_loss: 1.23743 v_acc: 0.70345 |  iteration: 14868 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1195 loss: 1.33228 acc: 0.70931 | v_loss: 1.24716 v_acc: 0.73503 |  iteration: 14869 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1196 loss: 1.35298 acc: 0.70736 | v_loss: 1.27454 v_acc: 0.72168 |  iteration: 14870 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1197 loss: 1.37741 acc: 0.70964 | v_loss: 1.33654 v_acc: 0.73145 |  iteration: 14871 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1198 loss: 1.38744 acc: 0.69889 | v_loss: 1.26207 v_acc: 0.72461 |  iteration: 14872 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1199 loss: 1.40060 acc: 0.70345 | v_loss: 1.30716 v_acc: 0.71973 |  iteration: 14873 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1200 loss: 1.38539 acc: 0.69889 | v_loss: 1.42268 v_acc: 0.71224 |  iteration: 14874 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1201 loss: 1.46095 acc: 0.70052 | v_loss: 1.41669 v_acc: 0.72428 |  iteration: 14875 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1202 loss: 1.45982 acc: 0.70573 | v_loss: 1.49625 v_acc: 0.70182 |  iteration: 14876 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1203 loss: 1.26926 acc: 0.72038 | v_loss: 1.43161 v_acc: 0.71712 |  iteration: 14877 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1204 loss: 1.49010 acc: 0.70020 | v_loss: 1.17450 v_acc: 0.74056 |  iteration: 14878 teacher: 0 stage: sketch lr: 0.000362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1205 loss: 1.45142 acc: 0.70801 | v_loss: 1.25605 v_acc: 0.70996 |  iteration: 14879 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1206 loss: 1.44889 acc: 0.68913 | v_loss: 1.53486 v_acc: 0.69336 |  iteration: 14880 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1207 loss: 1.39416 acc: 0.69564 | v_loss: 1.23185 v_acc: 0.69043 |  iteration: 14881 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1208 loss: 1.44625 acc: 0.69694 | v_loss: 1.32888 v_acc: 0.70247 |  iteration: 14882 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1209 loss: 1.36611 acc: 0.70247 | v_loss: 1.35302 v_acc: 0.69661 |  iteration: 14883 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1210 loss: 1.47728 acc: 0.70247 | v_loss: 1.29957 v_acc: 0.71126 |  iteration: 14884 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1211 loss: 1.38813 acc: 0.70117 | v_loss: 1.36438 v_acc: 0.69759 |  iteration: 14885 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1212 loss: 1.45604 acc: 0.70020 | v_loss: 1.48735 v_acc: 0.71224 |  iteration: 14886 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1213 loss: 1.43761 acc: 0.70443 | v_loss: 1.31615 v_acc: 0.72819 |  iteration: 14887 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1214 loss: 1.56392 acc: 0.68945 | v_loss: 1.44562 v_acc: 0.70312 |  iteration: 14888 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1215 loss: 1.32503 acc: 0.70801 | v_loss: 1.35218 v_acc: 0.69954 |  iteration: 14889 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1216 loss: 1.47264 acc: 0.69889 | v_loss: 1.33076 v_acc: 0.70703 |  iteration: 14890 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1217 loss: 1.45059 acc: 0.70703 | v_loss: 1.53602 v_acc: 0.68880 |  iteration: 14891 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1218 loss: 1.33128 acc: 0.70833 | v_loss: 1.29570 v_acc: 0.72038 |  iteration: 14892 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1219 loss: 1.40883 acc: 0.70605 | v_loss: 1.58874 v_acc: 0.68392 |  iteration: 14893 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1220 loss: 1.44377 acc: 0.70052 | v_loss: 1.45407 v_acc: 0.69759 |  iteration: 14894 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1221 loss: 1.56375 acc: 0.68197 | v_loss: 1.52270 v_acc: 0.69076 |  iteration: 14895 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1222 loss: 1.49398 acc: 0.69987 | v_loss: 1.37504 v_acc: 0.69889 |  iteration: 14896 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1223 loss: 1.40670 acc: 0.71289 | v_loss: 1.32050 v_acc: 0.70378 |  iteration: 14897 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1224 loss: 1.46851 acc: 0.70540 | v_loss: 1.33777 v_acc: 0.70215 |  iteration: 14898 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1225 loss: 1.47121 acc: 0.69661 | v_loss: 1.32596 v_acc: 0.71615 |  iteration: 14899 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1226 loss: 1.37036 acc: 0.70605 | v_loss: 1.54234 v_acc: 0.68945 |  iteration: 14900 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1227 loss: 1.30549 acc: 0.70671 | v_loss: 1.37984 v_acc: 0.70703 |  iteration: 14901 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1228 loss: 1.36987 acc: 0.70964 | v_loss: 1.36302 v_acc: 0.70833 |  iteration: 14902 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1229 loss: 1.51143 acc: 0.70475 | v_loss: 1.39006 v_acc: 0.71582 |  iteration: 14903 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1230 loss: 1.39540 acc: 0.69792 | v_loss: 1.26930 v_acc: 0.70475 |  iteration: 14904 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1231 loss: 1.45479 acc: 0.69857 | v_loss: 1.42500 v_acc: 0.69792 |  iteration: 14905 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1232 loss: 1.38644 acc: 0.70475 | v_loss: 1.43027 v_acc: 0.71289 |  iteration: 14906 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1233 loss: 1.41529 acc: 0.70345 | v_loss: 1.28897 v_acc: 0.72201 |  iteration: 14907 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1234 loss: 1.40173 acc: 0.70247 | v_loss: 1.25471 v_acc: 0.72559 |  iteration: 14908 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1235 loss: 1.45467 acc: 0.69889 | v_loss: 1.37804 v_acc: 0.71061 |  iteration: 14909 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1236 loss: 1.31739 acc: 0.72103 | v_loss: 1.43099 v_acc: 0.70182 |  iteration: 14910 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1237 loss: 1.40400 acc: 0.70866 | v_loss: 1.44260 v_acc: 0.70736 |  iteration: 14911 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1238 loss: 1.40534 acc: 0.70247 | v_loss: 1.22802 v_acc: 0.72591 |  iteration: 14912 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1239 loss: 1.43138 acc: 0.70671 | v_loss: 1.39904 v_acc: 0.73112 |  iteration: 14913 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1240 loss: 1.42925 acc: 0.70312 | v_loss: 1.47843 v_acc: 0.69759 |  iteration: 14914 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1241 loss: 1.42204 acc: 0.71094 | v_loss: 1.42452 v_acc: 0.72201 |  iteration: 14915 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1242 loss: 1.43865 acc: 0.70117 | v_loss: 1.24895 v_acc: 0.72396 |  iteration: 14916 teacher: 1 stage: sketch lr: 0.000362\n",
      "epoch 11 loss: 1.43557 acc: 0.70262 | v_loss: 1.36659 v_acc: 0.71047 \n",
      "epoch: 12\n",
      "__________________________________________\n",
      "batch 0 loss: 1.43994 acc: 0.70345 | v_loss: 1.41903 v_acc: 0.70736 |  iteration: 14917 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1 loss: 1.40094 acc: 0.70020 | v_loss: 1.40565 v_acc: 0.70703 |  iteration: 14918 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 2 loss: 1.37196 acc: 0.70833 | v_loss: 1.41136 v_acc: 0.70443 |  iteration: 14919 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 3 loss: 1.45872 acc: 0.70020 | v_loss: 1.25951 v_acc: 0.71159 |  iteration: 14920 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 4 loss: 1.46885 acc: 0.69922 | v_loss: 1.32836 v_acc: 0.72396 |  iteration: 14921 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 5 loss: 1.39610 acc: 0.70312 | v_loss: 1.20072 v_acc: 0.70605 |  iteration: 14922 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 6 loss: 1.35653 acc: 0.70475 | v_loss: 1.34178 v_acc: 0.70247 |  iteration: 14923 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 7 loss: 1.46034 acc: 0.70540 | v_loss: 1.51043 v_acc: 0.69987 |  iteration: 14924 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 8 loss: 1.45641 acc: 0.69401 | v_loss: 1.34051 v_acc: 0.70638 |  iteration: 14925 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 9 loss: 1.42463 acc: 0.70150 | v_loss: 1.35111 v_acc: 0.69596 |  iteration: 14926 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 10 loss: 1.44716 acc: 0.70052 | v_loss: 1.24690 v_acc: 0.71224 |  iteration: 14927 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 11 loss: 1.35251 acc: 0.70215 | v_loss: 1.24723 v_acc: 0.70345 |  iteration: 14928 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 12 loss: 1.47289 acc: 0.69694 | v_loss: 1.23668 v_acc: 0.73503 |  iteration: 14929 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 13 loss: 1.50535 acc: 0.70215 | v_loss: 1.25911 v_acc: 0.72461 |  iteration: 14930 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 14 loss: 1.40143 acc: 0.70508 | v_loss: 1.30538 v_acc: 0.72689 |  iteration: 14931 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 15 loss: 1.51985 acc: 0.69857 | v_loss: 1.25668 v_acc: 0.72852 |  iteration: 14932 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 16 loss: 1.42942 acc: 0.70605 | v_loss: 1.29879 v_acc: 0.72103 |  iteration: 14933 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 17 loss: 1.37522 acc: 0.71322 | v_loss: 1.40596 v_acc: 0.71224 |  iteration: 14934 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 18 loss: 1.39930 acc: 0.70052 | v_loss: 1.38792 v_acc: 0.72070 |  iteration: 14935 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 19 loss: 1.49180 acc: 0.70247 | v_loss: 1.48297 v_acc: 0.69954 |  iteration: 14936 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 20 loss: 1.42244 acc: 0.69792 | v_loss: 1.41245 v_acc: 0.71777 |  iteration: 14937 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 21 loss: 1.38822 acc: 0.69922 | v_loss: 1.17851 v_acc: 0.74544 |  iteration: 14938 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 22 loss: 1.49327 acc: 0.69010 | v_loss: 1.26005 v_acc: 0.70801 |  iteration: 14939 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 23 loss: 1.35933 acc: 0.70020 | v_loss: 1.53427 v_acc: 0.70150 |  iteration: 14940 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 24 loss: 1.47108 acc: 0.69629 | v_loss: 1.22096 v_acc: 0.70801 |  iteration: 14941 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 25 loss: 1.40711 acc: 0.69987 | v_loss: 1.32864 v_acc: 0.71159 |  iteration: 14942 teacher: 1 stage: sketch lr: 0.000362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 26 loss: 1.46915 acc: 0.70182 | v_loss: 1.36572 v_acc: 0.69336 |  iteration: 14943 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 27 loss: 1.42901 acc: 0.69596 | v_loss: 1.28778 v_acc: 0.71191 |  iteration: 14944 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 28 loss: 1.41070 acc: 0.71419 | v_loss: 1.35657 v_acc: 0.69629 |  iteration: 14945 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 29 loss: 1.31422 acc: 0.70280 | v_loss: 1.48232 v_acc: 0.71517 |  iteration: 14946 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 30 loss: 1.54051 acc: 0.69076 | v_loss: 1.31647 v_acc: 0.72689 |  iteration: 14947 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 31 loss: 1.59237 acc: 0.68457 | v_loss: 1.44633 v_acc: 0.70443 |  iteration: 14948 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 32 loss: 1.52091 acc: 0.69987 | v_loss: 1.36796 v_acc: 0.69922 |  iteration: 14949 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 33 loss: 1.35119 acc: 0.70605 | v_loss: 1.31658 v_acc: 0.70898 |  iteration: 14950 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 34 loss: 1.37258 acc: 0.70508 | v_loss: 1.55255 v_acc: 0.68815 |  iteration: 14951 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 35 loss: 1.47793 acc: 0.70345 | v_loss: 1.29606 v_acc: 0.72005 |  iteration: 14952 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 36 loss: 1.45925 acc: 0.70085 | v_loss: 1.59333 v_acc: 0.68424 |  iteration: 14953 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 37 loss: 1.39985 acc: 0.69987 | v_loss: 1.46243 v_acc: 0.69792 |  iteration: 14954 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 38 loss: 1.51681 acc: 0.69401 | v_loss: 1.51899 v_acc: 0.69141 |  iteration: 14955 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 39 loss: 1.43974 acc: 0.70085 | v_loss: 1.38066 v_acc: 0.69824 |  iteration: 14956 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 40 loss: 1.40568 acc: 0.70671 | v_loss: 1.32678 v_acc: 0.70312 |  iteration: 14957 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 41 loss: 1.36896 acc: 0.69271 | v_loss: 1.33687 v_acc: 0.70052 |  iteration: 14958 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 42 loss: 1.52448 acc: 0.69694 | v_loss: 1.33886 v_acc: 0.71647 |  iteration: 14959 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 43 loss: 1.35124 acc: 0.71387 | v_loss: 1.53161 v_acc: 0.68978 |  iteration: 14960 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 44 loss: 1.47229 acc: 0.69271 | v_loss: 1.37480 v_acc: 0.70443 |  iteration: 14961 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 45 loss: 1.45585 acc: 0.69466 | v_loss: 1.35071 v_acc: 0.71029 |  iteration: 14962 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 46 loss: 1.43169 acc: 0.70410 | v_loss: 1.39028 v_acc: 0.71680 |  iteration: 14963 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 47 loss: 1.41337 acc: 0.69824 | v_loss: 1.27264 v_acc: 0.70573 |  iteration: 14964 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 48 loss: 1.33337 acc: 0.71029 | v_loss: 1.43771 v_acc: 0.69792 |  iteration: 14965 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 49 loss: 1.46707 acc: 0.69434 | v_loss: 1.44067 v_acc: 0.71289 |  iteration: 14966 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 50 loss: 1.41909 acc: 0.71029 | v_loss: 1.28397 v_acc: 0.71875 |  iteration: 14967 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 51 loss: 1.32710 acc: 0.71029 | v_loss: 1.26766 v_acc: 0.72591 |  iteration: 14968 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 52 loss: 1.58552 acc: 0.68783 | v_loss: 1.38256 v_acc: 0.72266 |  iteration: 14969 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 53 loss: 1.35952 acc: 0.71647 | v_loss: 1.42311 v_acc: 0.70378 |  iteration: 14970 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 54 loss: 1.45878 acc: 0.70801 | v_loss: 1.42645 v_acc: 0.70410 |  iteration: 14971 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 55 loss: 1.44535 acc: 0.70410 | v_loss: 1.23010 v_acc: 0.71452 |  iteration: 14972 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 56 loss: 1.47794 acc: 0.69922 | v_loss: 1.38148 v_acc: 0.72819 |  iteration: 14973 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 57 loss: 1.38088 acc: 0.70312 | v_loss: 1.46598 v_acc: 0.69759 |  iteration: 14974 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 58 loss: 1.50961 acc: 0.70215 | v_loss: 1.40327 v_acc: 0.72331 |  iteration: 14975 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 59 loss: 1.38933 acc: 0.70671 | v_loss: 1.25648 v_acc: 0.71615 |  iteration: 14976 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 60 loss: 1.44439 acc: 0.70964 | v_loss: 1.21833 v_acc: 0.73177 |  iteration: 14977 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 61 loss: 1.39993 acc: 0.70410 | v_loss: 1.21518 v_acc: 0.72949 |  iteration: 14978 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 62 loss: 1.48031 acc: 0.70247 | v_loss: 1.30503 v_acc: 0.70508 |  iteration: 14979 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 63 loss: 1.48599 acc: 0.70182 | v_loss: 1.46272 v_acc: 0.69629 |  iteration: 14980 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 64 loss: 1.49714 acc: 0.70378 | v_loss: 1.28262 v_acc: 0.71126 |  iteration: 14981 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 65 loss: 1.53205 acc: 0.69987 | v_loss: 1.45638 v_acc: 0.71615 |  iteration: 14982 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 66 loss: 1.55997 acc: 0.68359 | v_loss: 1.65782 v_acc: 0.69206 |  iteration: 14983 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 67 loss: 1.38677 acc: 0.70964 | v_loss: 1.52280 v_acc: 0.69987 |  iteration: 14984 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 68 loss: 1.39039 acc: 0.70215 | v_loss: 1.29087 v_acc: 0.72331 |  iteration: 14985 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 69 loss: 1.47632 acc: 0.69987 | v_loss: 1.37961 v_acc: 0.70410 |  iteration: 14986 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 70 loss: 1.41293 acc: 0.70312 | v_loss: 1.22023 v_acc: 0.72201 |  iteration: 14987 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 71 loss: 1.42390 acc: 0.70605 | v_loss: 1.42482 v_acc: 0.70378 |  iteration: 14988 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 72 loss: 1.40326 acc: 0.70475 | v_loss: 1.35538 v_acc: 0.71810 |  iteration: 14989 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 73 loss: 1.40027 acc: 0.70052 | v_loss: 1.36135 v_acc: 0.73014 |  iteration: 14990 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 74 loss: 1.42866 acc: 0.70475 | v_loss: 1.37259 v_acc: 0.71973 |  iteration: 14991 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 75 loss: 1.43165 acc: 0.70866 | v_loss: 1.38069 v_acc: 0.70964 |  iteration: 14992 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 76 loss: 1.53821 acc: 0.70150 | v_loss: 1.27326 v_acc: 0.72493 |  iteration: 14993 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 77 loss: 1.44413 acc: 0.70150 | v_loss: 1.29133 v_acc: 0.72135 |  iteration: 14994 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 78 loss: 1.43201 acc: 0.71257 | v_loss: 1.47560 v_acc: 0.69303 |  iteration: 14995 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 79 loss: 1.44486 acc: 0.70508 | v_loss: 1.33077 v_acc: 0.70931 |  iteration: 14996 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 80 loss: 1.42990 acc: 0.70605 | v_loss: 1.29336 v_acc: 0.71517 |  iteration: 14997 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 81 loss: 1.42985 acc: 0.70443 | v_loss: 1.28772 v_acc: 0.72168 |  iteration: 14998 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 82 loss: 1.33626 acc: 0.70833 | v_loss: 1.43577 v_acc: 0.70443 |  iteration: 14999 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 83 loss: 1.49403 acc: 0.69499 | v_loss: 1.30731 v_acc: 0.73145 |  iteration: 15000 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 84 loss: 1.38465 acc: 0.70638 | v_loss: 1.54570 v_acc: 0.71452 |  iteration: 15001 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 85 loss: 1.46019 acc: 0.69954 | v_loss: 1.28084 v_acc: 0.69759 |  iteration: 15002 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 86 loss: 1.43346 acc: 0.70736 | v_loss: 1.27702 v_acc: 0.70443 |  iteration: 15003 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 87 loss: 1.44335 acc: 0.69824 | v_loss: 1.44364 v_acc: 0.70312 |  iteration: 15004 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 88 loss: 1.33128 acc: 0.71875 | v_loss: 1.47559 v_acc: 0.70378 |  iteration: 15005 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 89 loss: 1.35082 acc: 0.71126 | v_loss: 1.52056 v_acc: 0.68945 |  iteration: 15006 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 90 loss: 1.46166 acc: 0.70410 | v_loss: 1.46975 v_acc: 0.70638 |  iteration: 15007 teacher: 0 stage: sketch lr: 0.000361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 91 loss: 1.34611 acc: 0.70150 | v_loss: 1.42670 v_acc: 0.70410 |  iteration: 15008 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 92 loss: 1.42113 acc: 0.70866 | v_loss: 1.41337 v_acc: 0.70768 |  iteration: 15009 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 93 loss: 1.34056 acc: 0.71647 | v_loss: 1.39154 v_acc: 0.70475 |  iteration: 15010 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 94 loss: 1.41637 acc: 0.70508 | v_loss: 1.25988 v_acc: 0.71354 |  iteration: 15011 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 95 loss: 1.44888 acc: 0.70247 | v_loss: 1.32377 v_acc: 0.72461 |  iteration: 15012 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 96 loss: 1.40469 acc: 0.71191 | v_loss: 1.17764 v_acc: 0.71517 |  iteration: 15013 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 97 loss: 1.56445 acc: 0.69922 | v_loss: 1.34610 v_acc: 0.70703 |  iteration: 15014 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 98 loss: 1.43310 acc: 0.70833 | v_loss: 1.50510 v_acc: 0.69987 |  iteration: 15015 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 99 loss: 1.33308 acc: 0.71484 | v_loss: 1.32283 v_acc: 0.70833 |  iteration: 15016 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 100 loss: 1.47901 acc: 0.70443 | v_loss: 1.36411 v_acc: 0.69727 |  iteration: 15017 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 101 loss: 1.54285 acc: 0.69010 | v_loss: 1.24369 v_acc: 0.71126 |  iteration: 15018 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 102 loss: 1.43717 acc: 0.69792 | v_loss: 1.25348 v_acc: 0.70443 |  iteration: 15019 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 103 loss: 1.49595 acc: 0.69076 | v_loss: 1.23585 v_acc: 0.73926 |  iteration: 15020 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 104 loss: 1.49226 acc: 0.70020 | v_loss: 1.26771 v_acc: 0.71908 |  iteration: 15021 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 105 loss: 1.45088 acc: 0.69889 | v_loss: 1.33175 v_acc: 0.73112 |  iteration: 15022 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 106 loss: 1.40720 acc: 0.70833 | v_loss: 1.25869 v_acc: 0.71940 |  iteration: 15023 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 107 loss: 1.52285 acc: 0.68945 | v_loss: 1.30398 v_acc: 0.72266 |  iteration: 15024 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 108 loss: 1.47429 acc: 0.70085 | v_loss: 1.40942 v_acc: 0.71289 |  iteration: 15025 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 109 loss: 1.32298 acc: 0.71257 | v_loss: 1.38771 v_acc: 0.72135 |  iteration: 15026 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 110 loss: 1.49344 acc: 0.70052 | v_loss: 1.48385 v_acc: 0.69661 |  iteration: 15027 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 111 loss: 1.38787 acc: 0.71029 | v_loss: 1.42235 v_acc: 0.71745 |  iteration: 15028 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 112 loss: 1.45984 acc: 0.69271 | v_loss: 1.17870 v_acc: 0.74382 |  iteration: 15029 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 113 loss: 1.42082 acc: 0.70638 | v_loss: 1.26689 v_acc: 0.70931 |  iteration: 15030 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 114 loss: 1.36886 acc: 0.72005 | v_loss: 1.52204 v_acc: 0.70247 |  iteration: 15031 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 115 loss: 1.39895 acc: 0.69824 | v_loss: 1.22824 v_acc: 0.70866 |  iteration: 15032 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 116 loss: 1.45450 acc: 0.70215 | v_loss: 1.33182 v_acc: 0.71257 |  iteration: 15033 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 117 loss: 1.40286 acc: 0.71159 | v_loss: 1.37507 v_acc: 0.69368 |  iteration: 15034 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 118 loss: 1.44817 acc: 0.69499 | v_loss: 1.30253 v_acc: 0.71842 |  iteration: 15035 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 119 loss: 1.55048 acc: 0.69336 | v_loss: 1.37073 v_acc: 0.70215 |  iteration: 15036 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 120 loss: 1.54135 acc: 0.69661 | v_loss: 1.45264 v_acc: 0.72005 |  iteration: 15037 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 121 loss: 1.43234 acc: 0.70866 | v_loss: 1.31459 v_acc: 0.72819 |  iteration: 15038 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 122 loss: 1.37082 acc: 0.71582 | v_loss: 1.42640 v_acc: 0.70312 |  iteration: 15039 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 123 loss: 1.32203 acc: 0.71582 | v_loss: 1.38548 v_acc: 0.69954 |  iteration: 15040 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 124 loss: 1.38740 acc: 0.70508 | v_loss: 1.31925 v_acc: 0.70964 |  iteration: 15041 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 125 loss: 1.42658 acc: 0.69759 | v_loss: 1.54722 v_acc: 0.68913 |  iteration: 15042 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 126 loss: 1.49007 acc: 0.69564 | v_loss: 1.29481 v_acc: 0.72135 |  iteration: 15043 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 127 loss: 1.36785 acc: 0.70801 | v_loss: 1.59184 v_acc: 0.68294 |  iteration: 15044 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 128 loss: 1.37432 acc: 0.70801 | v_loss: 1.44896 v_acc: 0.69889 |  iteration: 15045 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 129 loss: 1.33056 acc: 0.70801 | v_loss: 1.54053 v_acc: 0.68783 |  iteration: 15046 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 130 loss: 1.46587 acc: 0.70117 | v_loss: 1.37549 v_acc: 0.69466 |  iteration: 15047 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 131 loss: 1.39066 acc: 0.70638 | v_loss: 1.33861 v_acc: 0.70312 |  iteration: 15048 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 132 loss: 1.37343 acc: 0.70443 | v_loss: 1.32760 v_acc: 0.69824 |  iteration: 15049 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 133 loss: 1.43534 acc: 0.69954 | v_loss: 1.32689 v_acc: 0.71777 |  iteration: 15050 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 134 loss: 1.47426 acc: 0.70215 | v_loss: 1.54218 v_acc: 0.68978 |  iteration: 15051 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 135 loss: 1.49475 acc: 0.69531 | v_loss: 1.37565 v_acc: 0.70443 |  iteration: 15052 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 136 loss: 1.37553 acc: 0.70508 | v_loss: 1.34361 v_acc: 0.71029 |  iteration: 15053 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 137 loss: 1.50343 acc: 0.70312 | v_loss: 1.38083 v_acc: 0.71615 |  iteration: 15054 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 138 loss: 1.43662 acc: 0.69173 | v_loss: 1.26482 v_acc: 0.70736 |  iteration: 15055 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 139 loss: 1.44000 acc: 0.70280 | v_loss: 1.43742 v_acc: 0.70052 |  iteration: 15056 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 140 loss: 1.46301 acc: 0.69727 | v_loss: 1.42510 v_acc: 0.71224 |  iteration: 15057 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 141 loss: 1.34030 acc: 0.71582 | v_loss: 1.27991 v_acc: 0.72201 |  iteration: 15058 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 142 loss: 1.40855 acc: 0.70280 | v_loss: 1.24980 v_acc: 0.72591 |  iteration: 15059 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 143 loss: 1.25631 acc: 0.71582 | v_loss: 1.37438 v_acc: 0.72266 |  iteration: 15060 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 144 loss: 1.36306 acc: 0.69661 | v_loss: 1.41679 v_acc: 0.70410 |  iteration: 15061 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 145 loss: 1.46294 acc: 0.70247 | v_loss: 1.44094 v_acc: 0.70768 |  iteration: 15062 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 146 loss: 1.49079 acc: 0.70020 | v_loss: 1.22719 v_acc: 0.71322 |  iteration: 15063 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 147 loss: 1.38365 acc: 0.70768 | v_loss: 1.41259 v_acc: 0.72266 |  iteration: 15064 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 148 loss: 1.39270 acc: 0.70378 | v_loss: 1.49043 v_acc: 0.69271 |  iteration: 15065 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 149 loss: 1.41479 acc: 0.71257 | v_loss: 1.40798 v_acc: 0.72168 |  iteration: 15066 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 150 loss: 1.37555 acc: 0.70605 | v_loss: 1.24738 v_acc: 0.72201 |  iteration: 15067 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 151 loss: 1.44161 acc: 0.69629 | v_loss: 1.20204 v_acc: 0.73991 |  iteration: 15068 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 152 loss: 1.49649 acc: 0.69792 | v_loss: 1.21475 v_acc: 0.72656 |  iteration: 15069 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 153 loss: 1.47139 acc: 0.69759 | v_loss: 1.28472 v_acc: 0.70638 |  iteration: 15070 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 154 loss: 1.34876 acc: 0.70540 | v_loss: 1.44371 v_acc: 0.70052 |  iteration: 15071 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 155 loss: 1.43958 acc: 0.70052 | v_loss: 1.27594 v_acc: 0.71452 |  iteration: 15072 teacher: 0 stage: sketch lr: 0.000360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 156 loss: 1.36112 acc: 0.71061 | v_loss: 1.43528 v_acc: 0.71647 |  iteration: 15073 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 157 loss: 1.37179 acc: 0.70378 | v_loss: 1.66590 v_acc: 0.69303 |  iteration: 15074 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 158 loss: 1.43405 acc: 0.69694 | v_loss: 1.52751 v_acc: 0.69857 |  iteration: 15075 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 159 loss: 1.52368 acc: 0.69889 | v_loss: 1.29179 v_acc: 0.72396 |  iteration: 15076 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 160 loss: 1.39426 acc: 0.70736 | v_loss: 1.37047 v_acc: 0.70931 |  iteration: 15077 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 161 loss: 1.29736 acc: 0.72201 | v_loss: 1.22166 v_acc: 0.71973 |  iteration: 15078 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 162 loss: 1.33362 acc: 0.70996 | v_loss: 1.42481 v_acc: 0.70182 |  iteration: 15079 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 163 loss: 1.41441 acc: 0.69987 | v_loss: 1.36006 v_acc: 0.71810 |  iteration: 15080 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 164 loss: 1.41612 acc: 0.69857 | v_loss: 1.36177 v_acc: 0.73014 |  iteration: 15081 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 165 loss: 1.44495 acc: 0.70573 | v_loss: 1.37641 v_acc: 0.71908 |  iteration: 15082 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 166 loss: 1.50825 acc: 0.68978 | v_loss: 1.37673 v_acc: 0.70996 |  iteration: 15083 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 167 loss: 1.41874 acc: 0.70280 | v_loss: 1.28344 v_acc: 0.72461 |  iteration: 15084 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 168 loss: 1.42781 acc: 0.69792 | v_loss: 1.29338 v_acc: 0.71908 |  iteration: 15085 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 169 loss: 1.44805 acc: 0.69759 | v_loss: 1.47961 v_acc: 0.69271 |  iteration: 15086 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 170 loss: 1.45518 acc: 0.69922 | v_loss: 1.32364 v_acc: 0.71224 |  iteration: 15087 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 171 loss: 1.41793 acc: 0.70833 | v_loss: 1.30062 v_acc: 0.71680 |  iteration: 15088 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 172 loss: 1.35937 acc: 0.70280 | v_loss: 1.30250 v_acc: 0.71452 |  iteration: 15089 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 173 loss: 1.44889 acc: 0.69857 | v_loss: 1.45699 v_acc: 0.70312 |  iteration: 15090 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 174 loss: 1.44404 acc: 0.70605 | v_loss: 1.30708 v_acc: 0.73014 |  iteration: 15091 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 175 loss: 1.50346 acc: 0.69499 | v_loss: 1.55528 v_acc: 0.71549 |  iteration: 15092 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 176 loss: 1.53826 acc: 0.68685 | v_loss: 1.26832 v_acc: 0.70150 |  iteration: 15093 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 177 loss: 1.38702 acc: 0.70736 | v_loss: 1.27096 v_acc: 0.70443 |  iteration: 15094 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 178 loss: 1.58775 acc: 0.68522 | v_loss: 1.45603 v_acc: 0.70312 |  iteration: 15095 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 179 loss: 1.56445 acc: 0.69466 | v_loss: 1.48990 v_acc: 0.70378 |  iteration: 15096 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 180 loss: 1.44077 acc: 0.69368 | v_loss: 1.53427 v_acc: 0.68978 |  iteration: 15097 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 181 loss: 1.50296 acc: 0.69596 | v_loss: 1.46535 v_acc: 0.70638 |  iteration: 15098 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 182 loss: 1.30828 acc: 0.71224 | v_loss: 1.43064 v_acc: 0.70410 |  iteration: 15099 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 183 loss: 1.34708 acc: 0.70964 | v_loss: 1.42040 v_acc: 0.70768 |  iteration: 15100 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 184 loss: 1.40060 acc: 0.70117 | v_loss: 1.39453 v_acc: 0.70703 |  iteration: 15101 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 185 loss: 1.40040 acc: 0.70085 | v_loss: 1.25541 v_acc: 0.71875 |  iteration: 15102 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 186 loss: 1.47515 acc: 0.70312 | v_loss: 1.32776 v_acc: 0.72331 |  iteration: 15103 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 187 loss: 1.43010 acc: 0.71159 | v_loss: 1.16512 v_acc: 0.71615 |  iteration: 15104 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 188 loss: 1.44087 acc: 0.70508 | v_loss: 1.34087 v_acc: 0.71126 |  iteration: 15105 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 189 loss: 1.46917 acc: 0.69368 | v_loss: 1.50832 v_acc: 0.69954 |  iteration: 15106 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 190 loss: 1.45111 acc: 0.70117 | v_loss: 1.32131 v_acc: 0.71484 |  iteration: 15107 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 191 loss: 1.43291 acc: 0.70150 | v_loss: 1.35084 v_acc: 0.70247 |  iteration: 15108 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 192 loss: 1.46472 acc: 0.69922 | v_loss: 1.24091 v_acc: 0.71191 |  iteration: 15109 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 193 loss: 1.41301 acc: 0.70801 | v_loss: 1.23868 v_acc: 0.70736 |  iteration: 15110 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 194 loss: 1.42858 acc: 0.69824 | v_loss: 1.23677 v_acc: 0.73991 |  iteration: 15111 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 195 loss: 1.44717 acc: 0.69564 | v_loss: 1.26355 v_acc: 0.72201 |  iteration: 15112 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 196 loss: 1.42214 acc: 0.70182 | v_loss: 1.34999 v_acc: 0.72656 |  iteration: 15113 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 197 loss: 1.40483 acc: 0.70182 | v_loss: 1.25954 v_acc: 0.72331 |  iteration: 15114 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 198 loss: 1.43378 acc: 0.70345 | v_loss: 1.30300 v_acc: 0.72103 |  iteration: 15115 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 199 loss: 1.48563 acc: 0.69889 | v_loss: 1.41303 v_acc: 0.71322 |  iteration: 15116 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 200 loss: 1.49398 acc: 0.69727 | v_loss: 1.39136 v_acc: 0.72070 |  iteration: 15117 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 201 loss: 1.37348 acc: 0.71810 | v_loss: 1.48959 v_acc: 0.69954 |  iteration: 15118 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 202 loss: 1.40390 acc: 0.70345 | v_loss: 1.41571 v_acc: 0.71615 |  iteration: 15119 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 203 loss: 1.47726 acc: 0.69596 | v_loss: 1.17269 v_acc: 0.74544 |  iteration: 15120 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 204 loss: 1.33639 acc: 0.71159 | v_loss: 1.26573 v_acc: 0.70866 |  iteration: 15121 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 205 loss: 1.43173 acc: 0.70150 | v_loss: 1.50418 v_acc: 0.70280 |  iteration: 15122 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 206 loss: 1.40501 acc: 0.70931 | v_loss: 1.22555 v_acc: 0.71615 |  iteration: 15123 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 207 loss: 1.40203 acc: 0.70573 | v_loss: 1.33535 v_acc: 0.71257 |  iteration: 15124 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 208 loss: 1.37464 acc: 0.70801 | v_loss: 1.36888 v_acc: 0.69238 |  iteration: 15125 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 209 loss: 1.53330 acc: 0.69661 | v_loss: 1.29754 v_acc: 0.70996 |  iteration: 15126 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 210 loss: 1.39877 acc: 0.70215 | v_loss: 1.36784 v_acc: 0.69434 |  iteration: 15127 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 211 loss: 1.44254 acc: 0.70703 | v_loss: 1.47523 v_acc: 0.71191 |  iteration: 15128 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 212 loss: 1.45143 acc: 0.69857 | v_loss: 1.31770 v_acc: 0.72689 |  iteration: 15129 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 213 loss: 1.41654 acc: 0.70345 | v_loss: 1.45391 v_acc: 0.70443 |  iteration: 15130 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 214 loss: 1.37713 acc: 0.71094 | v_loss: 1.36230 v_acc: 0.69922 |  iteration: 15131 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 215 loss: 1.44553 acc: 0.69987 | v_loss: 1.32382 v_acc: 0.70833 |  iteration: 15132 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 216 loss: 1.51470 acc: 0.69759 | v_loss: 1.56907 v_acc: 0.68522 |  iteration: 15133 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 217 loss: 1.40097 acc: 0.69889 | v_loss: 1.31106 v_acc: 0.72168 |  iteration: 15134 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 218 loss: 1.46053 acc: 0.69727 | v_loss: 1.60165 v_acc: 0.67969 |  iteration: 15135 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 219 loss: 1.42224 acc: 0.71061 | v_loss: 1.46021 v_acc: 0.69661 |  iteration: 15136 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 220 loss: 1.46465 acc: 0.69987 | v_loss: 1.54721 v_acc: 0.69238 |  iteration: 15137 teacher: 1 stage: sketch lr: 0.000359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 221 loss: 1.26766 acc: 0.71745 | v_loss: 1.36934 v_acc: 0.70182 |  iteration: 15138 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 222 loss: 1.42087 acc: 0.70736 | v_loss: 1.33146 v_acc: 0.70638 |  iteration: 15139 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 223 loss: 1.48013 acc: 0.70150 | v_loss: 1.33953 v_acc: 0.70117 |  iteration: 15140 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 224 loss: 1.31988 acc: 0.70866 | v_loss: 1.33482 v_acc: 0.71484 |  iteration: 15141 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 225 loss: 1.56290 acc: 0.69076 | v_loss: 1.54065 v_acc: 0.68978 |  iteration: 15142 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 226 loss: 1.42704 acc: 0.69466 | v_loss: 1.38842 v_acc: 0.70443 |  iteration: 15143 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 227 loss: 1.53922 acc: 0.69824 | v_loss: 1.34291 v_acc: 0.70898 |  iteration: 15144 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 228 loss: 1.41552 acc: 0.70508 | v_loss: 1.37942 v_acc: 0.71582 |  iteration: 15145 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 229 loss: 1.44379 acc: 0.70410 | v_loss: 1.27482 v_acc: 0.70443 |  iteration: 15146 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 230 loss: 1.45784 acc: 0.69108 | v_loss: 1.42849 v_acc: 0.69889 |  iteration: 15147 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 231 loss: 1.51700 acc: 0.70443 | v_loss: 1.42257 v_acc: 0.71712 |  iteration: 15148 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 232 loss: 1.46064 acc: 0.70215 | v_loss: 1.30201 v_acc: 0.71647 |  iteration: 15149 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 233 loss: 1.50747 acc: 0.69499 | v_loss: 1.25032 v_acc: 0.72721 |  iteration: 15150 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 234 loss: 1.39242 acc: 0.71029 | v_loss: 1.37305 v_acc: 0.71647 |  iteration: 15151 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 235 loss: 1.51734 acc: 0.69238 | v_loss: 1.41452 v_acc: 0.70540 |  iteration: 15152 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 236 loss: 1.40351 acc: 0.70898 | v_loss: 1.41780 v_acc: 0.70443 |  iteration: 15153 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 237 loss: 1.50844 acc: 0.69661 | v_loss: 1.22741 v_acc: 0.71712 |  iteration: 15154 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 238 loss: 1.37727 acc: 0.70866 | v_loss: 1.38102 v_acc: 0.72786 |  iteration: 15155 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 239 loss: 1.46666 acc: 0.69889 | v_loss: 1.47222 v_acc: 0.69792 |  iteration: 15156 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 240 loss: 1.49660 acc: 0.69792 | v_loss: 1.43040 v_acc: 0.72070 |  iteration: 15157 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 241 loss: 1.47006 acc: 0.70085 | v_loss: 1.25495 v_acc: 0.72201 |  iteration: 15158 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 242 loss: 1.35787 acc: 0.70801 | v_loss: 1.20418 v_acc: 0.73991 |  iteration: 15159 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 243 loss: 1.37078 acc: 0.70931 | v_loss: 1.21155 v_acc: 0.72526 |  iteration: 15160 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 244 loss: 1.29799 acc: 0.71842 | v_loss: 1.26496 v_acc: 0.70638 |  iteration: 15161 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 245 loss: 1.45515 acc: 0.69857 | v_loss: 1.44580 v_acc: 0.70052 |  iteration: 15162 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 246 loss: 1.43480 acc: 0.69368 | v_loss: 1.28204 v_acc: 0.71452 |  iteration: 15163 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 247 loss: 1.48695 acc: 0.69824 | v_loss: 1.45389 v_acc: 0.71582 |  iteration: 15164 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 248 loss: 1.51939 acc: 0.70671 | v_loss: 1.66837 v_acc: 0.69401 |  iteration: 15165 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 249 loss: 1.47206 acc: 0.69238 | v_loss: 1.52194 v_acc: 0.69922 |  iteration: 15166 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 250 loss: 1.32326 acc: 0.70898 | v_loss: 1.29484 v_acc: 0.72135 |  iteration: 15167 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 251 loss: 1.42666 acc: 0.71061 | v_loss: 1.36341 v_acc: 0.70280 |  iteration: 15168 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 252 loss: 1.37359 acc: 0.71191 | v_loss: 1.21592 v_acc: 0.72103 |  iteration: 15169 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 253 loss: 1.60384 acc: 0.68815 | v_loss: 1.41585 v_acc: 0.70020 |  iteration: 15170 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 254 loss: 1.30076 acc: 0.71615 | v_loss: 1.35357 v_acc: 0.71094 |  iteration: 15171 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 255 loss: 1.41409 acc: 0.70964 | v_loss: 1.35149 v_acc: 0.72949 |  iteration: 15172 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 256 loss: 1.62647 acc: 0.69076 | v_loss: 1.35162 v_acc: 0.71810 |  iteration: 15173 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 257 loss: 1.56839 acc: 0.69792 | v_loss: 1.37091 v_acc: 0.70508 |  iteration: 15174 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 258 loss: 1.38196 acc: 0.71257 | v_loss: 1.28964 v_acc: 0.72233 |  iteration: 15175 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 259 loss: 1.50360 acc: 0.69922 | v_loss: 1.30444 v_acc: 0.72135 |  iteration: 15176 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 260 loss: 1.46955 acc: 0.70117 | v_loss: 1.51598 v_acc: 0.69303 |  iteration: 15177 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 261 loss: 1.48458 acc: 0.69531 | v_loss: 1.33492 v_acc: 0.71159 |  iteration: 15178 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 262 loss: 1.45096 acc: 0.70540 | v_loss: 1.29945 v_acc: 0.71549 |  iteration: 15179 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 263 loss: 1.44172 acc: 0.70378 | v_loss: 1.28119 v_acc: 0.71973 |  iteration: 15180 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 264 loss: 1.48843 acc: 0.70475 | v_loss: 1.42946 v_acc: 0.70573 |  iteration: 15181 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 265 loss: 1.42303 acc: 0.70605 | v_loss: 1.30770 v_acc: 0.73112 |  iteration: 15182 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 266 loss: 1.55812 acc: 0.69206 | v_loss: 1.52970 v_acc: 0.71452 |  iteration: 15183 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 267 loss: 1.49990 acc: 0.69401 | v_loss: 1.29644 v_acc: 0.69759 |  iteration: 15184 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 268 loss: 1.52263 acc: 0.68913 | v_loss: 1.28045 v_acc: 0.70443 |  iteration: 15185 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 269 loss: 1.42533 acc: 0.71094 | v_loss: 1.43237 v_acc: 0.70280 |  iteration: 15186 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 270 loss: 1.43622 acc: 0.70540 | v_loss: 1.46161 v_acc: 0.70085 |  iteration: 15187 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 271 loss: 1.51640 acc: 0.69466 | v_loss: 1.50591 v_acc: 0.69466 |  iteration: 15188 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 272 loss: 1.43551 acc: 0.69889 | v_loss: 1.45897 v_acc: 0.70801 |  iteration: 15189 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 273 loss: 1.42812 acc: 0.70280 | v_loss: 1.41801 v_acc: 0.70410 |  iteration: 15190 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 274 loss: 1.44867 acc: 0.69889 | v_loss: 1.40842 v_acc: 0.70866 |  iteration: 15191 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 275 loss: 1.38788 acc: 0.71354 | v_loss: 1.39102 v_acc: 0.70573 |  iteration: 15192 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 276 loss: 1.33450 acc: 0.71257 | v_loss: 1.25664 v_acc: 0.71191 |  iteration: 15193 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 277 loss: 1.43341 acc: 0.70964 | v_loss: 1.32729 v_acc: 0.72428 |  iteration: 15194 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 278 loss: 1.29824 acc: 0.71647 | v_loss: 1.18549 v_acc: 0.71484 |  iteration: 15195 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 279 loss: 1.41975 acc: 0.70280 | v_loss: 1.34269 v_acc: 0.70671 |  iteration: 15196 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 280 loss: 1.36008 acc: 0.70475 | v_loss: 1.52686 v_acc: 0.70052 |  iteration: 15197 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 281 loss: 1.47115 acc: 0.69987 | v_loss: 1.37128 v_acc: 0.70508 |  iteration: 15198 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 282 loss: 1.36902 acc: 0.71647 | v_loss: 1.36550 v_acc: 0.69629 |  iteration: 15199 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 283 loss: 1.51228 acc: 0.69336 | v_loss: 1.26169 v_acc: 0.70703 |  iteration: 15200 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 284 loss: 1.50870 acc: 0.69434 | v_loss: 1.23819 v_acc: 0.70443 |  iteration: 15201 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 285 loss: 1.44549 acc: 0.70540 | v_loss: 1.24255 v_acc: 0.73926 |  iteration: 15202 teacher: 1 stage: sketch lr: 0.000358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 286 loss: 1.44392 acc: 0.70345 | v_loss: 1.27538 v_acc: 0.71908 |  iteration: 15203 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 287 loss: 1.37781 acc: 0.71322 | v_loss: 1.34146 v_acc: 0.73112 |  iteration: 15204 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 288 loss: 1.32001 acc: 0.72201 | v_loss: 1.25965 v_acc: 0.71973 |  iteration: 15205 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 289 loss: 1.40983 acc: 0.71940 | v_loss: 1.29869 v_acc: 0.72266 |  iteration: 15206 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 290 loss: 1.40620 acc: 0.71126 | v_loss: 1.40138 v_acc: 0.71419 |  iteration: 15207 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 291 loss: 1.36858 acc: 0.70866 | v_loss: 1.37995 v_acc: 0.72103 |  iteration: 15208 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 292 loss: 1.45393 acc: 0.70410 | v_loss: 1.48852 v_acc: 0.69661 |  iteration: 15209 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 293 loss: 1.52375 acc: 0.69987 | v_loss: 1.40475 v_acc: 0.71745 |  iteration: 15210 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 294 loss: 1.48529 acc: 0.70605 | v_loss: 1.17511 v_acc: 0.74349 |  iteration: 15211 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 295 loss: 1.43175 acc: 0.70540 | v_loss: 1.26575 v_acc: 0.70182 |  iteration: 15212 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 296 loss: 1.44419 acc: 0.69759 | v_loss: 1.51060 v_acc: 0.70280 |  iteration: 15213 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 297 loss: 1.47924 acc: 0.69922 | v_loss: 1.22479 v_acc: 0.71419 |  iteration: 15214 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 298 loss: 1.48116 acc: 0.69694 | v_loss: 1.32921 v_acc: 0.71159 |  iteration: 15215 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 299 loss: 1.40694 acc: 0.70247 | v_loss: 1.37207 v_acc: 0.69336 |  iteration: 15216 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 300 loss: 1.50095 acc: 0.69108 | v_loss: 1.29989 v_acc: 0.71191 |  iteration: 15217 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 301 loss: 1.45849 acc: 0.70020 | v_loss: 1.36615 v_acc: 0.69661 |  iteration: 15218 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 302 loss: 1.48068 acc: 0.69987 | v_loss: 1.45550 v_acc: 0.72005 |  iteration: 15219 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 303 loss: 1.43897 acc: 0.69694 | v_loss: 1.31578 v_acc: 0.72786 |  iteration: 15220 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 304 loss: 1.46402 acc: 0.70052 | v_loss: 1.43251 v_acc: 0.70540 |  iteration: 15221 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 305 loss: 1.32731 acc: 0.71517 | v_loss: 1.36920 v_acc: 0.69922 |  iteration: 15222 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 306 loss: 1.38374 acc: 0.71387 | v_loss: 1.31975 v_acc: 0.70964 |  iteration: 15223 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 307 loss: 1.44824 acc: 0.70410 | v_loss: 1.54016 v_acc: 0.68913 |  iteration: 15224 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 308 loss: 1.45668 acc: 0.70638 | v_loss: 1.30328 v_acc: 0.72135 |  iteration: 15225 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 309 loss: 1.46755 acc: 0.70931 | v_loss: 1.58247 v_acc: 0.68294 |  iteration: 15226 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 310 loss: 1.44072 acc: 0.70020 | v_loss: 1.44512 v_acc: 0.69889 |  iteration: 15227 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 311 loss: 1.40378 acc: 0.70768 | v_loss: 1.52280 v_acc: 0.68848 |  iteration: 15228 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 312 loss: 1.49334 acc: 0.69434 | v_loss: 1.37116 v_acc: 0.69792 |  iteration: 15229 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 313 loss: 1.37800 acc: 0.70475 | v_loss: 1.32418 v_acc: 0.70378 |  iteration: 15230 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 314 loss: 1.37510 acc: 0.72201 | v_loss: 1.33271 v_acc: 0.70215 |  iteration: 15231 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 315 loss: 1.42773 acc: 0.70378 | v_loss: 1.32495 v_acc: 0.71615 |  iteration: 15232 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 316 loss: 1.39426 acc: 0.70964 | v_loss: 1.55140 v_acc: 0.68945 |  iteration: 15233 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 317 loss: 1.43959 acc: 0.70085 | v_loss: 1.39096 v_acc: 0.70703 |  iteration: 15234 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 318 loss: 1.32436 acc: 0.71029 | v_loss: 1.35376 v_acc: 0.70833 |  iteration: 15235 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 319 loss: 1.48612 acc: 0.70182 | v_loss: 1.38397 v_acc: 0.71484 |  iteration: 15236 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 320 loss: 1.45324 acc: 0.70540 | v_loss: 1.26430 v_acc: 0.70573 |  iteration: 15237 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 321 loss: 1.52613 acc: 0.69889 | v_loss: 1.43186 v_acc: 0.70117 |  iteration: 15238 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 322 loss: 1.36950 acc: 0.71029 | v_loss: 1.42243 v_acc: 0.71549 |  iteration: 15239 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 323 loss: 1.49309 acc: 0.69596 | v_loss: 1.28349 v_acc: 0.72038 |  iteration: 15240 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 324 loss: 1.43747 acc: 0.70443 | v_loss: 1.25230 v_acc: 0.72819 |  iteration: 15241 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 325 loss: 1.35736 acc: 0.71842 | v_loss: 1.36933 v_acc: 0.71615 |  iteration: 15242 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 326 loss: 1.51463 acc: 0.70443 | v_loss: 1.41610 v_acc: 0.70540 |  iteration: 15243 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 327 loss: 1.49807 acc: 0.69629 | v_loss: 1.42293 v_acc: 0.70508 |  iteration: 15244 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 328 loss: 1.33281 acc: 0.71029 | v_loss: 1.22664 v_acc: 0.71452 |  iteration: 15245 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 329 loss: 1.53003 acc: 0.69596 | v_loss: 1.38552 v_acc: 0.72819 |  iteration: 15246 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 330 loss: 1.39857 acc: 0.70443 | v_loss: 1.46465 v_acc: 0.69759 |  iteration: 15247 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 331 loss: 1.54156 acc: 0.70345 | v_loss: 1.40060 v_acc: 0.72005 |  iteration: 15248 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 332 loss: 1.47650 acc: 0.69694 | v_loss: 1.26233 v_acc: 0.71908 |  iteration: 15249 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 333 loss: 1.59202 acc: 0.69206 | v_loss: 1.22509 v_acc: 0.73470 |  iteration: 15250 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 334 loss: 1.45046 acc: 0.69368 | v_loss: 1.21940 v_acc: 0.72624 |  iteration: 15251 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 335 loss: 1.34834 acc: 0.71354 | v_loss: 1.30482 v_acc: 0.70638 |  iteration: 15252 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 336 loss: 1.43361 acc: 0.70833 | v_loss: 1.45478 v_acc: 0.70052 |  iteration: 15253 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 337 loss: 1.37241 acc: 0.71777 | v_loss: 1.27837 v_acc: 0.71452 |  iteration: 15254 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 338 loss: 1.42708 acc: 0.70443 | v_loss: 1.43448 v_acc: 0.71647 |  iteration: 15255 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 339 loss: 1.39070 acc: 0.71159 | v_loss: 1.66512 v_acc: 0.69303 |  iteration: 15256 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 340 loss: 1.42814 acc: 0.69727 | v_loss: 1.51872 v_acc: 0.70117 |  iteration: 15257 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 341 loss: 1.52602 acc: 0.69368 | v_loss: 1.29260 v_acc: 0.72363 |  iteration: 15258 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 342 loss: 1.32125 acc: 0.72005 | v_loss: 1.37501 v_acc: 0.70378 |  iteration: 15259 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 343 loss: 1.39021 acc: 0.70898 | v_loss: 1.22543 v_acc: 0.71777 |  iteration: 15260 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 344 loss: 1.33406 acc: 0.70964 | v_loss: 1.42916 v_acc: 0.70020 |  iteration: 15261 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 345 loss: 1.36323 acc: 0.70736 | v_loss: 1.35742 v_acc: 0.71061 |  iteration: 15262 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 346 loss: 1.51434 acc: 0.70833 | v_loss: 1.35515 v_acc: 0.72949 |  iteration: 15263 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 347 loss: 1.50401 acc: 0.69173 | v_loss: 1.36546 v_acc: 0.71810 |  iteration: 15264 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 348 loss: 1.53377 acc: 0.69792 | v_loss: 1.37705 v_acc: 0.70508 |  iteration: 15265 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 349 loss: 1.38498 acc: 0.70410 | v_loss: 1.27458 v_acc: 0.72201 |  iteration: 15266 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 350 loss: 1.50784 acc: 0.70117 | v_loss: 1.29269 v_acc: 0.72005 |  iteration: 15267 teacher: 1 stage: sketch lr: 0.000358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 351 loss: 1.45001 acc: 0.70410 | v_loss: 1.47009 v_acc: 0.69206 |  iteration: 15268 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 352 loss: 1.60133 acc: 0.69173 | v_loss: 1.32791 v_acc: 0.70931 |  iteration: 15269 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 353 loss: 1.57478 acc: 0.68164 | v_loss: 1.30158 v_acc: 0.71452 |  iteration: 15270 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 354 loss: 1.52998 acc: 0.69629 | v_loss: 1.29560 v_acc: 0.71940 |  iteration: 15271 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 355 loss: 1.43441 acc: 0.70117 | v_loss: 1.43039 v_acc: 0.70475 |  iteration: 15272 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 356 loss: 1.50244 acc: 0.69499 | v_loss: 1.30460 v_acc: 0.73210 |  iteration: 15273 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 357 loss: 1.45822 acc: 0.70410 | v_loss: 1.52773 v_acc: 0.71582 |  iteration: 15274 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 358 loss: 1.49253 acc: 0.69792 | v_loss: 1.28786 v_acc: 0.69759 |  iteration: 15275 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 359 loss: 1.53593 acc: 0.69043 | v_loss: 1.28366 v_acc: 0.70443 |  iteration: 15276 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 360 loss: 1.38241 acc: 0.71126 | v_loss: 1.44549 v_acc: 0.70312 |  iteration: 15277 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 361 loss: 1.58185 acc: 0.68587 | v_loss: 1.48407 v_acc: 0.70378 |  iteration: 15278 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 362 loss: 1.46299 acc: 0.69889 | v_loss: 1.53496 v_acc: 0.68913 |  iteration: 15279 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 363 loss: 1.49464 acc: 0.69857 | v_loss: 1.46591 v_acc: 0.70540 |  iteration: 15280 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 364 loss: 1.40226 acc: 0.70215 | v_loss: 1.43318 v_acc: 0.70540 |  iteration: 15281 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 365 loss: 1.46874 acc: 0.69043 | v_loss: 1.41971 v_acc: 0.70540 |  iteration: 15282 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 366 loss: 1.45246 acc: 0.69531 | v_loss: 1.40295 v_acc: 0.70443 |  iteration: 15283 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 367 loss: 1.37547 acc: 0.70150 | v_loss: 1.26343 v_acc: 0.71354 |  iteration: 15284 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 368 loss: 1.50040 acc: 0.69401 | v_loss: 1.31985 v_acc: 0.72461 |  iteration: 15285 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 369 loss: 1.45845 acc: 0.69141 | v_loss: 1.19073 v_acc: 0.71289 |  iteration: 15286 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 370 loss: 1.46719 acc: 0.71061 | v_loss: 1.34596 v_acc: 0.70280 |  iteration: 15287 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 371 loss: 1.38835 acc: 0.70898 | v_loss: 1.49953 v_acc: 0.69954 |  iteration: 15288 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 372 loss: 1.56185 acc: 0.69043 | v_loss: 1.31961 v_acc: 0.71289 |  iteration: 15289 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 373 loss: 1.42678 acc: 0.70443 | v_loss: 1.34616 v_acc: 0.70247 |  iteration: 15290 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 374 loss: 1.46105 acc: 0.69271 | v_loss: 1.25955 v_acc: 0.71191 |  iteration: 15291 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 375 loss: 1.43283 acc: 0.70475 | v_loss: 1.24084 v_acc: 0.70280 |  iteration: 15292 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 376 loss: 1.41911 acc: 0.70703 | v_loss: 1.24156 v_acc: 0.74056 |  iteration: 15293 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 377 loss: 1.41465 acc: 0.71159 | v_loss: 1.27677 v_acc: 0.71289 |  iteration: 15294 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 378 loss: 1.33369 acc: 0.71224 | v_loss: 1.38060 v_acc: 0.69792 |  iteration: 15295 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 379 loss: 1.48601 acc: 0.69661 | v_loss: 1.26868 v_acc: 0.71712 |  iteration: 15296 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 380 loss: 1.43861 acc: 0.70573 | v_loss: 1.30482 v_acc: 0.72135 |  iteration: 15297 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 381 loss: 1.37074 acc: 0.70931 | v_loss: 1.41315 v_acc: 0.71289 |  iteration: 15298 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 382 loss: 1.43095 acc: 0.70247 | v_loss: 1.38401 v_acc: 0.72298 |  iteration: 15299 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 383 loss: 1.40238 acc: 0.70605 | v_loss: 1.49812 v_acc: 0.69987 |  iteration: 15300 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 384 loss: 1.39814 acc: 0.70312 | v_loss: 1.42045 v_acc: 0.71647 |  iteration: 15301 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 385 loss: 1.46251 acc: 0.69564 | v_loss: 1.17051 v_acc: 0.74447 |  iteration: 15302 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 386 loss: 1.46629 acc: 0.70703 | v_loss: 1.25110 v_acc: 0.71322 |  iteration: 15303 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 387 loss: 1.38788 acc: 0.70703 | v_loss: 1.53596 v_acc: 0.69987 |  iteration: 15304 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 388 loss: 1.53846 acc: 0.69141 | v_loss: 1.22052 v_acc: 0.70475 |  iteration: 15305 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 389 loss: 1.39700 acc: 0.70605 | v_loss: 1.33532 v_acc: 0.71257 |  iteration: 15306 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 390 loss: 1.36296 acc: 0.71191 | v_loss: 1.37475 v_acc: 0.69368 |  iteration: 15307 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 391 loss: 1.55974 acc: 0.69694 | v_loss: 1.29249 v_acc: 0.71842 |  iteration: 15308 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 392 loss: 1.45426 acc: 0.70508 | v_loss: 1.36430 v_acc: 0.69954 |  iteration: 15309 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 393 loss: 1.45051 acc: 0.69596 | v_loss: 1.46611 v_acc: 0.71289 |  iteration: 15310 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 394 loss: 1.43279 acc: 0.69987 | v_loss: 1.31530 v_acc: 0.72819 |  iteration: 15311 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 395 loss: 1.42459 acc: 0.70345 | v_loss: 1.43738 v_acc: 0.70312 |  iteration: 15312 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 396 loss: 1.36274 acc: 0.71029 | v_loss: 1.36235 v_acc: 0.70117 |  iteration: 15313 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 397 loss: 1.47471 acc: 0.70280 | v_loss: 1.32896 v_acc: 0.70573 |  iteration: 15314 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 398 loss: 1.48132 acc: 0.69076 | v_loss: 1.53210 v_acc: 0.68848 |  iteration: 15315 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 399 loss: 1.34202 acc: 0.71745 | v_loss: 1.29261 v_acc: 0.72135 |  iteration: 15316 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 400 loss: 1.38378 acc: 0.70898 | v_loss: 1.58424 v_acc: 0.68294 |  iteration: 15317 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 401 loss: 1.50061 acc: 0.70150 | v_loss: 1.44759 v_acc: 0.69889 |  iteration: 15318 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 402 loss: 1.39811 acc: 0.70671 | v_loss: 1.51974 v_acc: 0.69173 |  iteration: 15319 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 403 loss: 1.44606 acc: 0.69954 | v_loss: 1.38143 v_acc: 0.70020 |  iteration: 15320 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 404 loss: 1.31712 acc: 0.70996 | v_loss: 1.32552 v_acc: 0.70638 |  iteration: 15321 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 405 loss: 1.50226 acc: 0.69238 | v_loss: 1.35018 v_acc: 0.70378 |  iteration: 15322 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 406 loss: 1.44762 acc: 0.70182 | v_loss: 1.33959 v_acc: 0.72038 |  iteration: 15323 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 407 loss: 1.51999 acc: 0.70085 | v_loss: 1.59681 v_acc: 0.68978 |  iteration: 15324 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 408 loss: 1.48655 acc: 0.69401 | v_loss: 1.39585 v_acc: 0.71257 |  iteration: 15325 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 409 loss: 1.41398 acc: 0.71126 | v_loss: 1.34474 v_acc: 0.71061 |  iteration: 15326 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 410 loss: 1.40110 acc: 0.70768 | v_loss: 1.38615 v_acc: 0.71452 |  iteration: 15327 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 411 loss: 1.41090 acc: 0.70150 | v_loss: 1.27019 v_acc: 0.70443 |  iteration: 15328 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 412 loss: 1.33189 acc: 0.71484 | v_loss: 1.42325 v_acc: 0.69889 |  iteration: 15329 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 413 loss: 1.44280 acc: 0.70345 | v_loss: 1.41886 v_acc: 0.71647 |  iteration: 15330 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 414 loss: 1.41186 acc: 0.70378 | v_loss: 1.29605 v_acc: 0.71745 |  iteration: 15331 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 415 loss: 1.35231 acc: 0.70475 | v_loss: 1.25243 v_acc: 0.72689 |  iteration: 15332 teacher: 1 stage: sketch lr: 0.000357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 416 loss: 1.49628 acc: 0.69824 | v_loss: 1.36619 v_acc: 0.71582 |  iteration: 15333 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 417 loss: 1.31591 acc: 0.72526 | v_loss: 1.41795 v_acc: 0.70410 |  iteration: 15334 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 418 loss: 1.33616 acc: 0.71029 | v_loss: 1.41968 v_acc: 0.70508 |  iteration: 15335 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 419 loss: 1.39807 acc: 0.70964 | v_loss: 1.22502 v_acc: 0.71712 |  iteration: 15336 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 420 loss: 1.39766 acc: 0.70898 | v_loss: 1.39112 v_acc: 0.72917 |  iteration: 15337 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 421 loss: 1.36514 acc: 0.70671 | v_loss: 1.48212 v_acc: 0.69759 |  iteration: 15338 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 422 loss: 1.38369 acc: 0.71647 | v_loss: 1.43656 v_acc: 0.72201 |  iteration: 15339 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 423 loss: 1.46282 acc: 0.70475 | v_loss: 1.24936 v_acc: 0.72233 |  iteration: 15340 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 424 loss: 1.48037 acc: 0.69727 | v_loss: 1.20041 v_acc: 0.74414 |  iteration: 15341 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 425 loss: 1.39180 acc: 0.70345 | v_loss: 1.21912 v_acc: 0.72559 |  iteration: 15342 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 426 loss: 1.36685 acc: 0.70312 | v_loss: 1.27266 v_acc: 0.70638 |  iteration: 15343 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 427 loss: 1.36841 acc: 0.71159 | v_loss: 1.45983 v_acc: 0.70052 |  iteration: 15344 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 428 loss: 1.37320 acc: 0.70931 | v_loss: 1.27617 v_acc: 0.71452 |  iteration: 15345 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 429 loss: 1.42630 acc: 0.70150 | v_loss: 1.45007 v_acc: 0.71647 |  iteration: 15346 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 430 loss: 1.37626 acc: 0.71354 | v_loss: 1.68617 v_acc: 0.69336 |  iteration: 15347 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 431 loss: 1.34920 acc: 0.71029 | v_loss: 1.53634 v_acc: 0.69922 |  iteration: 15348 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 432 loss: 1.37429 acc: 0.70540 | v_loss: 1.29124 v_acc: 0.72135 |  iteration: 15349 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 433 loss: 1.43059 acc: 0.70312 | v_loss: 1.37345 v_acc: 0.70280 |  iteration: 15350 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 434 loss: 1.45697 acc: 0.69954 | v_loss: 1.21829 v_acc: 0.72103 |  iteration: 15351 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 435 loss: 1.46696 acc: 0.70150 | v_loss: 1.42486 v_acc: 0.70020 |  iteration: 15352 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 436 loss: 1.36522 acc: 0.69694 | v_loss: 1.35387 v_acc: 0.71094 |  iteration: 15353 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 437 loss: 1.46438 acc: 0.70768 | v_loss: 1.35219 v_acc: 0.73014 |  iteration: 15354 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 438 loss: 1.38113 acc: 0.70996 | v_loss: 1.35597 v_acc: 0.71810 |  iteration: 15355 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 439 loss: 1.47109 acc: 0.70638 | v_loss: 1.36974 v_acc: 0.70508 |  iteration: 15356 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 440 loss: 1.38028 acc: 0.70801 | v_loss: 1.28781 v_acc: 0.72201 |  iteration: 15357 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 441 loss: 1.46120 acc: 0.69889 | v_loss: 1.29805 v_acc: 0.72070 |  iteration: 15358 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 442 loss: 1.47608 acc: 0.69661 | v_loss: 1.51041 v_acc: 0.69206 |  iteration: 15359 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 443 loss: 1.50144 acc: 0.69759 | v_loss: 1.33063 v_acc: 0.70898 |  iteration: 15360 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 444 loss: 1.36098 acc: 0.70801 | v_loss: 1.30277 v_acc: 0.71615 |  iteration: 15361 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 445 loss: 1.42193 acc: 0.70182 | v_loss: 1.29553 v_acc: 0.71973 |  iteration: 15362 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 446 loss: 1.43011 acc: 0.70540 | v_loss: 1.43743 v_acc: 0.70508 |  iteration: 15363 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 447 loss: 1.43507 acc: 0.70182 | v_loss: 1.31266 v_acc: 0.73047 |  iteration: 15364 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 448 loss: 1.47378 acc: 0.70638 | v_loss: 1.53717 v_acc: 0.71322 |  iteration: 15365 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 449 loss: 1.46768 acc: 0.70801 | v_loss: 1.28839 v_acc: 0.69727 |  iteration: 15366 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 450 loss: 1.43136 acc: 0.70345 | v_loss: 1.28311 v_acc: 0.70247 |  iteration: 15367 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 451 loss: 1.49782 acc: 0.70378 | v_loss: 1.43259 v_acc: 0.70345 |  iteration: 15368 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 452 loss: 1.43972 acc: 0.69954 | v_loss: 1.46471 v_acc: 0.70378 |  iteration: 15369 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 453 loss: 1.45389 acc: 0.69987 | v_loss: 1.51088 v_acc: 0.68978 |  iteration: 15370 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 454 loss: 1.61210 acc: 0.68424 | v_loss: 1.46487 v_acc: 0.70638 |  iteration: 15371 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 455 loss: 1.42056 acc: 0.69824 | v_loss: 1.41648 v_acc: 0.70410 |  iteration: 15372 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 456 loss: 1.43189 acc: 0.70117 | v_loss: 1.40424 v_acc: 0.70703 |  iteration: 15373 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 457 loss: 1.31675 acc: 0.70866 | v_loss: 1.40517 v_acc: 0.70443 |  iteration: 15374 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 458 loss: 1.54531 acc: 0.68945 | v_loss: 1.25994 v_acc: 0.71159 |  iteration: 15375 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 459 loss: 1.51597 acc: 0.69727 | v_loss: 1.33704 v_acc: 0.72396 |  iteration: 15376 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 460 loss: 1.42477 acc: 0.70020 | v_loss: 1.20324 v_acc: 0.70508 |  iteration: 15377 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 461 loss: 1.41215 acc: 0.71191 | v_loss: 1.34107 v_acc: 0.70052 |  iteration: 15378 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 462 loss: 1.40133 acc: 0.69661 | v_loss: 1.50407 v_acc: 0.69727 |  iteration: 15379 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 463 loss: 1.41360 acc: 0.70475 | v_loss: 1.35554 v_acc: 0.70443 |  iteration: 15380 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 464 loss: 1.44374 acc: 0.71322 | v_loss: 1.34490 v_acc: 0.69661 |  iteration: 15381 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 465 loss: 1.36888 acc: 0.70443 | v_loss: 1.26202 v_acc: 0.70638 |  iteration: 15382 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 466 loss: 1.48165 acc: 0.70085 | v_loss: 1.24511 v_acc: 0.70410 |  iteration: 15383 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 467 loss: 1.47611 acc: 0.70345 | v_loss: 1.23096 v_acc: 0.73503 |  iteration: 15384 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 468 loss: 1.47413 acc: 0.70215 | v_loss: 1.26810 v_acc: 0.72168 |  iteration: 15385 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 469 loss: 1.38633 acc: 0.70866 | v_loss: 1.32436 v_acc: 0.73145 |  iteration: 15386 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 470 loss: 1.46232 acc: 0.70443 | v_loss: 1.25395 v_acc: 0.72461 |  iteration: 15387 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 471 loss: 1.33183 acc: 0.69792 | v_loss: 1.29877 v_acc: 0.72005 |  iteration: 15388 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 472 loss: 1.40782 acc: 0.70475 | v_loss: 1.40984 v_acc: 0.71224 |  iteration: 15389 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 473 loss: 1.50343 acc: 0.69759 | v_loss: 1.39568 v_acc: 0.72070 |  iteration: 15390 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 474 loss: 1.46395 acc: 0.69401 | v_loss: 1.49086 v_acc: 0.69954 |  iteration: 15391 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 475 loss: 1.47724 acc: 0.70605 | v_loss: 1.42105 v_acc: 0.71615 |  iteration: 15392 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 476 loss: 1.34034 acc: 0.71029 | v_loss: 1.17910 v_acc: 0.74512 |  iteration: 15393 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 477 loss: 1.38932 acc: 0.70150 | v_loss: 1.24823 v_acc: 0.71322 |  iteration: 15394 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 478 loss: 1.32796 acc: 0.70378 | v_loss: 1.54268 v_acc: 0.69987 |  iteration: 15395 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 479 loss: 1.40610 acc: 0.71126 | v_loss: 1.20742 v_acc: 0.70671 |  iteration: 15396 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 480 loss: 1.38355 acc: 0.69857 | v_loss: 1.33793 v_acc: 0.71257 |  iteration: 15397 teacher: 0 stage: sketch lr: 0.000356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 481 loss: 1.49385 acc: 0.69889 | v_loss: 1.36825 v_acc: 0.69368 |  iteration: 15398 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 482 loss: 1.37852 acc: 0.70052 | v_loss: 1.28889 v_acc: 0.71842 |  iteration: 15399 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 483 loss: 1.39880 acc: 0.69824 | v_loss: 1.36229 v_acc: 0.70215 |  iteration: 15400 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 484 loss: 1.40496 acc: 0.70931 | v_loss: 1.48043 v_acc: 0.72005 |  iteration: 15401 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 485 loss: 1.35015 acc: 0.71549 | v_loss: 1.31818 v_acc: 0.72689 |  iteration: 15402 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 486 loss: 1.38323 acc: 0.69173 | v_loss: 1.45462 v_acc: 0.70443 |  iteration: 15403 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 487 loss: 1.38617 acc: 0.69954 | v_loss: 1.35652 v_acc: 0.69922 |  iteration: 15404 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 488 loss: 1.61625 acc: 0.69173 | v_loss: 1.32424 v_acc: 0.70898 |  iteration: 15405 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 489 loss: 1.41562 acc: 0.71322 | v_loss: 1.54394 v_acc: 0.68815 |  iteration: 15406 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 490 loss: 1.44539 acc: 0.70540 | v_loss: 1.30331 v_acc: 0.72005 |  iteration: 15407 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 491 loss: 1.49858 acc: 0.69661 | v_loss: 1.58777 v_acc: 0.68294 |  iteration: 15408 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 492 loss: 1.41858 acc: 0.70247 | v_loss: 1.44573 v_acc: 0.69922 |  iteration: 15409 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 493 loss: 1.47567 acc: 0.70020 | v_loss: 1.51343 v_acc: 0.68978 |  iteration: 15410 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 494 loss: 1.33890 acc: 0.70247 | v_loss: 1.37700 v_acc: 0.69857 |  iteration: 15411 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 495 loss: 1.41969 acc: 0.70215 | v_loss: 1.31565 v_acc: 0.70280 |  iteration: 15412 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 496 loss: 1.42390 acc: 0.70085 | v_loss: 1.33275 v_acc: 0.70052 |  iteration: 15413 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 497 loss: 1.49192 acc: 0.69792 | v_loss: 1.32777 v_acc: 0.71615 |  iteration: 15414 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 498 loss: 1.38466 acc: 0.71322 | v_loss: 1.54617 v_acc: 0.68945 |  iteration: 15415 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 499 loss: 1.46587 acc: 0.69694 | v_loss: 1.38632 v_acc: 0.70703 |  iteration: 15416 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 500 loss: 1.40158 acc: 0.69303 | v_loss: 1.34195 v_acc: 0.70833 |  iteration: 15417 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 501 loss: 1.44084 acc: 0.69759 | v_loss: 1.38616 v_acc: 0.71680 |  iteration: 15418 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 502 loss: 1.41498 acc: 0.70801 | v_loss: 1.25611 v_acc: 0.70736 |  iteration: 15419 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 503 loss: 1.32503 acc: 0.72135 | v_loss: 1.43575 v_acc: 0.70052 |  iteration: 15420 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 504 loss: 1.51584 acc: 0.70150 | v_loss: 1.44111 v_acc: 0.71094 |  iteration: 15421 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 505 loss: 1.46765 acc: 0.70312 | v_loss: 1.26999 v_acc: 0.71810 |  iteration: 15422 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 506 loss: 1.48238 acc: 0.70378 | v_loss: 1.26504 v_acc: 0.72266 |  iteration: 15423 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 507 loss: 1.48565 acc: 0.69661 | v_loss: 1.38759 v_acc: 0.72266 |  iteration: 15424 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 508 loss: 1.56343 acc: 0.69857 | v_loss: 1.42065 v_acc: 0.70443 |  iteration: 15425 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 509 loss: 1.47582 acc: 0.70671 | v_loss: 1.41724 v_acc: 0.70443 |  iteration: 15426 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 510 loss: 1.45791 acc: 0.70247 | v_loss: 1.23597 v_acc: 0.71452 |  iteration: 15427 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 511 loss: 1.39224 acc: 0.70768 | v_loss: 1.37206 v_acc: 0.72884 |  iteration: 15428 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 512 loss: 1.44738 acc: 0.70085 | v_loss: 1.46084 v_acc: 0.70052 |  iteration: 15429 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 513 loss: 1.48242 acc: 0.69759 | v_loss: 1.39853 v_acc: 0.72298 |  iteration: 15430 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 514 loss: 1.51336 acc: 0.70378 | v_loss: 1.26843 v_acc: 0.71615 |  iteration: 15431 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 515 loss: 1.46318 acc: 0.70443 | v_loss: 1.22158 v_acc: 0.72884 |  iteration: 15432 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 516 loss: 1.45126 acc: 0.69759 | v_loss: 1.21743 v_acc: 0.72559 |  iteration: 15433 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 517 loss: 1.52768 acc: 0.69531 | v_loss: 1.29472 v_acc: 0.70768 |  iteration: 15434 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 518 loss: 1.40799 acc: 0.70508 | v_loss: 1.45330 v_acc: 0.69661 |  iteration: 15435 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 519 loss: 1.42923 acc: 0.69922 | v_loss: 1.27600 v_acc: 0.71452 |  iteration: 15436 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 520 loss: 1.35161 acc: 0.70964 | v_loss: 1.43079 v_acc: 0.71647 |  iteration: 15437 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 521 loss: 1.48914 acc: 0.69108 | v_loss: 1.67552 v_acc: 0.69303 |  iteration: 15438 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 522 loss: 1.36468 acc: 0.72038 | v_loss: 1.53390 v_acc: 0.70117 |  iteration: 15439 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 523 loss: 1.50755 acc: 0.71061 | v_loss: 1.29973 v_acc: 0.72363 |  iteration: 15440 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 524 loss: 1.44868 acc: 0.69889 | v_loss: 1.38276 v_acc: 0.70410 |  iteration: 15441 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 525 loss: 1.37767 acc: 0.70312 | v_loss: 1.21600 v_acc: 0.71973 |  iteration: 15442 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 526 loss: 1.40947 acc: 0.71354 | v_loss: 1.43073 v_acc: 0.70150 |  iteration: 15443 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 527 loss: 1.48056 acc: 0.70736 | v_loss: 1.35437 v_acc: 0.71029 |  iteration: 15444 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 528 loss: 1.51635 acc: 0.69759 | v_loss: 1.35189 v_acc: 0.72917 |  iteration: 15445 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 529 loss: 1.39429 acc: 0.70638 | v_loss: 1.35109 v_acc: 0.71777 |  iteration: 15446 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 530 loss: 1.34259 acc: 0.71159 | v_loss: 1.36835 v_acc: 0.70508 |  iteration: 15447 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 531 loss: 1.46139 acc: 0.70312 | v_loss: 1.27948 v_acc: 0.72201 |  iteration: 15448 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 532 loss: 1.44424 acc: 0.70280 | v_loss: 1.29813 v_acc: 0.72005 |  iteration: 15449 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 533 loss: 1.37649 acc: 0.71484 | v_loss: 1.46662 v_acc: 0.69206 |  iteration: 15450 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 534 loss: 1.47566 acc: 0.70052 | v_loss: 1.34056 v_acc: 0.70931 |  iteration: 15451 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 535 loss: 1.44875 acc: 0.70247 | v_loss: 1.29606 v_acc: 0.71452 |  iteration: 15452 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 536 loss: 1.49711 acc: 0.69401 | v_loss: 1.29170 v_acc: 0.71940 |  iteration: 15453 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 537 loss: 1.45574 acc: 0.69173 | v_loss: 1.43202 v_acc: 0.70475 |  iteration: 15454 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 538 loss: 1.49827 acc: 0.69434 | v_loss: 1.31104 v_acc: 0.73210 |  iteration: 15455 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 539 loss: 1.40891 acc: 0.70052 | v_loss: 1.55348 v_acc: 0.71745 |  iteration: 15456 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 540 loss: 1.41528 acc: 0.70540 | v_loss: 1.27603 v_acc: 0.70150 |  iteration: 15457 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 541 loss: 1.48704 acc: 0.70605 | v_loss: 1.27570 v_acc: 0.70736 |  iteration: 15458 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 542 loss: 1.38992 acc: 0.70931 | v_loss: 1.43985 v_acc: 0.70378 |  iteration: 15459 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 543 loss: 1.42734 acc: 0.69401 | v_loss: 1.48372 v_acc: 0.70150 |  iteration: 15460 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 544 loss: 1.32688 acc: 0.71973 | v_loss: 1.53105 v_acc: 0.69368 |  iteration: 15461 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 545 loss: 1.48131 acc: 0.69889 | v_loss: 1.47119 v_acc: 0.70833 |  iteration: 15462 teacher: 0 stage: sketch lr: 0.000355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 546 loss: 1.35024 acc: 0.70931 | v_loss: 1.43773 v_acc: 0.70085 |  iteration: 15463 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 547 loss: 1.46784 acc: 0.70052 | v_loss: 1.41834 v_acc: 0.70931 |  iteration: 15464 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 548 loss: 1.61379 acc: 0.68197 | v_loss: 1.39442 v_acc: 0.70703 |  iteration: 15465 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 549 loss: 1.38456 acc: 0.70768 | v_loss: 1.25733 v_acc: 0.71875 |  iteration: 15466 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 550 loss: 1.37231 acc: 0.71419 | v_loss: 1.31882 v_acc: 0.72331 |  iteration: 15467 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 551 loss: 1.42355 acc: 0.71061 | v_loss: 1.19803 v_acc: 0.71517 |  iteration: 15468 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 552 loss: 1.44318 acc: 0.69727 | v_loss: 1.34103 v_acc: 0.70703 |  iteration: 15469 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 553 loss: 1.37311 acc: 0.70410 | v_loss: 1.49950 v_acc: 0.69987 |  iteration: 15470 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 554 loss: 1.47923 acc: 0.69238 | v_loss: 1.34215 v_acc: 0.70703 |  iteration: 15471 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 555 loss: 1.47559 acc: 0.69466 | v_loss: 1.35336 v_acc: 0.69694 |  iteration: 15472 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 556 loss: 1.39724 acc: 0.70475 | v_loss: 1.25458 v_acc: 0.70866 |  iteration: 15473 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 557 loss: 1.65841 acc: 0.67741 | v_loss: 1.24950 v_acc: 0.70215 |  iteration: 15474 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 558 loss: 1.42618 acc: 0.70671 | v_loss: 1.25015 v_acc: 0.73275 |  iteration: 15475 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 559 loss: 1.38921 acc: 0.70931 | v_loss: 1.27667 v_acc: 0.71647 |  iteration: 15476 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 560 loss: 1.39983 acc: 0.70866 | v_loss: 1.35590 v_acc: 0.74089 |  iteration: 15477 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 561 loss: 1.44422 acc: 0.70410 | v_loss: 1.26313 v_acc: 0.72461 |  iteration: 15478 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 562 loss: 1.51388 acc: 0.69857 | v_loss: 1.30886 v_acc: 0.72005 |  iteration: 15479 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 563 loss: 1.44641 acc: 0.69759 | v_loss: 1.42318 v_acc: 0.71224 |  iteration: 15480 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 564 loss: 1.41464 acc: 0.70736 | v_loss: 1.39206 v_acc: 0.72070 |  iteration: 15481 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 565 loss: 1.44225 acc: 0.70085 | v_loss: 1.48603 v_acc: 0.70182 |  iteration: 15482 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 566 loss: 1.51054 acc: 0.70801 | v_loss: 1.41469 v_acc: 0.71777 |  iteration: 15483 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 567 loss: 1.42912 acc: 0.70345 | v_loss: 1.17254 v_acc: 0.74447 |  iteration: 15484 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 568 loss: 1.50393 acc: 0.70052 | v_loss: 1.25051 v_acc: 0.71322 |  iteration: 15485 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 569 loss: 1.50552 acc: 0.69206 | v_loss: 1.50587 v_acc: 0.70247 |  iteration: 15486 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 570 loss: 1.49174 acc: 0.68620 | v_loss: 1.22645 v_acc: 0.70866 |  iteration: 15487 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 571 loss: 1.32431 acc: 0.71419 | v_loss: 1.32465 v_acc: 0.71289 |  iteration: 15488 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 572 loss: 1.38139 acc: 0.70605 | v_loss: 1.36265 v_acc: 0.69499 |  iteration: 15489 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 573 loss: 1.58185 acc: 0.68587 | v_loss: 1.30587 v_acc: 0.70996 |  iteration: 15490 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 574 loss: 1.49071 acc: 0.69727 | v_loss: 1.36733 v_acc: 0.69076 |  iteration: 15491 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 575 loss: 1.46248 acc: 0.69792 | v_loss: 1.48435 v_acc: 0.70801 |  iteration: 15492 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 576 loss: 1.41499 acc: 0.70638 | v_loss: 1.31868 v_acc: 0.72819 |  iteration: 15493 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 577 loss: 1.42664 acc: 0.70345 | v_loss: 1.46844 v_acc: 0.69922 |  iteration: 15494 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 578 loss: 1.44718 acc: 0.70280 | v_loss: 1.34921 v_acc: 0.69954 |  iteration: 15495 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 579 loss: 1.47436 acc: 0.70052 | v_loss: 1.33706 v_acc: 0.70898 |  iteration: 15496 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 580 loss: 1.39602 acc: 0.69954 | v_loss: 1.54013 v_acc: 0.68815 |  iteration: 15497 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 581 loss: 1.33424 acc: 0.71908 | v_loss: 1.30079 v_acc: 0.72168 |  iteration: 15498 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 582 loss: 1.42910 acc: 0.70964 | v_loss: 1.60339 v_acc: 0.67969 |  iteration: 15499 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 583 loss: 1.33971 acc: 0.71387 | v_loss: 1.46866 v_acc: 0.69661 |  iteration: 15500 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 584 loss: 1.45273 acc: 0.70215 | v_loss: 1.52690 v_acc: 0.69238 |  iteration: 15501 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 585 loss: 1.47352 acc: 0.69987 | v_loss: 1.38727 v_acc: 0.70117 |  iteration: 15502 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 586 loss: 1.46655 acc: 0.70085 | v_loss: 1.32177 v_acc: 0.70638 |  iteration: 15503 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 587 loss: 1.43124 acc: 0.70443 | v_loss: 1.33363 v_acc: 0.70410 |  iteration: 15504 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 588 loss: 1.42739 acc: 0.70020 | v_loss: 1.33092 v_acc: 0.71484 |  iteration: 15505 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 589 loss: 1.41818 acc: 0.69368 | v_loss: 1.53988 v_acc: 0.68945 |  iteration: 15506 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 590 loss: 1.46702 acc: 0.70475 | v_loss: 1.37638 v_acc: 0.70703 |  iteration: 15507 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 591 loss: 1.42139 acc: 0.70443 | v_loss: 1.36742 v_acc: 0.70866 |  iteration: 15508 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 592 loss: 1.38399 acc: 0.70605 | v_loss: 1.39131 v_acc: 0.70898 |  iteration: 15509 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 593 loss: 1.44272 acc: 0.69727 | v_loss: 1.27353 v_acc: 0.70443 |  iteration: 15510 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 594 loss: 1.41122 acc: 0.69889 | v_loss: 1.42657 v_acc: 0.69889 |  iteration: 15511 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 595 loss: 1.43713 acc: 0.70182 | v_loss: 1.42669 v_acc: 0.71615 |  iteration: 15512 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 596 loss: 1.45712 acc: 0.70671 | v_loss: 1.29108 v_acc: 0.71712 |  iteration: 15513 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 597 loss: 1.40355 acc: 0.70898 | v_loss: 1.25110 v_acc: 0.72982 |  iteration: 15514 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 598 loss: 1.40760 acc: 0.71126 | v_loss: 1.36665 v_acc: 0.71842 |  iteration: 15515 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 599 loss: 1.38688 acc: 0.70671 | v_loss: 1.41509 v_acc: 0.70345 |  iteration: 15516 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 600 loss: 1.52813 acc: 0.69857 | v_loss: 1.42141 v_acc: 0.70410 |  iteration: 15517 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 601 loss: 1.53658 acc: 0.69108 | v_loss: 1.22596 v_acc: 0.71712 |  iteration: 15518 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 602 loss: 1.48918 acc: 0.70117 | v_loss: 1.37667 v_acc: 0.72852 |  iteration: 15519 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 603 loss: 1.49609 acc: 0.69889 | v_loss: 1.46467 v_acc: 0.69792 |  iteration: 15520 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 604 loss: 1.42601 acc: 0.69889 | v_loss: 1.40154 v_acc: 0.71842 |  iteration: 15521 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 605 loss: 1.50238 acc: 0.69661 | v_loss: 1.27023 v_acc: 0.71810 |  iteration: 15522 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 606 loss: 1.42345 acc: 0.71061 | v_loss: 1.22657 v_acc: 0.73665 |  iteration: 15523 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 607 loss: 1.50628 acc: 0.69987 | v_loss: 1.21958 v_acc: 0.72526 |  iteration: 15524 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 608 loss: 1.43931 acc: 0.69824 | v_loss: 1.28620 v_acc: 0.70996 |  iteration: 15525 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 609 loss: 1.53275 acc: 0.68848 | v_loss: 1.44688 v_acc: 0.69694 |  iteration: 15526 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 610 loss: 1.32472 acc: 0.71549 | v_loss: 1.27710 v_acc: 0.71126 |  iteration: 15527 teacher: 1 stage: sketch lr: 0.000355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 611 loss: 1.40524 acc: 0.70052 | v_loss: 1.43727 v_acc: 0.71647 |  iteration: 15528 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 612 loss: 1.42751 acc: 0.69303 | v_loss: 1.66963 v_acc: 0.69271 |  iteration: 15529 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 613 loss: 1.52005 acc: 0.68945 | v_loss: 1.52693 v_acc: 0.70117 |  iteration: 15530 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 614 loss: 1.44559 acc: 0.70736 | v_loss: 1.29348 v_acc: 0.72363 |  iteration: 15531 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 615 loss: 1.44557 acc: 0.69987 | v_loss: 1.38007 v_acc: 0.70410 |  iteration: 15532 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 616 loss: 1.44258 acc: 0.70345 | v_loss: 1.23254 v_acc: 0.71973 |  iteration: 15533 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 617 loss: 1.40921 acc: 0.70703 | v_loss: 1.42774 v_acc: 0.70150 |  iteration: 15534 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 618 loss: 1.44138 acc: 0.70085 | v_loss: 1.35438 v_acc: 0.71094 |  iteration: 15535 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 619 loss: 1.47973 acc: 0.70638 | v_loss: 1.35392 v_acc: 0.72949 |  iteration: 15536 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 620 loss: 1.38506 acc: 0.69694 | v_loss: 1.35947 v_acc: 0.71745 |  iteration: 15537 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 621 loss: 1.30691 acc: 0.70801 | v_loss: 1.37717 v_acc: 0.70964 |  iteration: 15538 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 622 loss: 1.43174 acc: 0.70150 | v_loss: 1.28088 v_acc: 0.72493 |  iteration: 15539 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 623 loss: 1.44265 acc: 0.69694 | v_loss: 1.28952 v_acc: 0.71973 |  iteration: 15540 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 624 loss: 1.38965 acc: 0.70508 | v_loss: 1.48402 v_acc: 0.69271 |  iteration: 15541 teacher: 1 stage: sketch lr: 0.000355\n",
      "batch 625 loss: 1.47315 acc: 0.70703 | v_loss: 1.32590 v_acc: 0.71224 |  iteration: 15542 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 626 loss: 1.38731 acc: 0.71257 | v_loss: 1.29691 v_acc: 0.71484 |  iteration: 15543 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 627 loss: 1.48066 acc: 0.69922 | v_loss: 1.29599 v_acc: 0.71940 |  iteration: 15544 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 628 loss: 1.43168 acc: 0.71191 | v_loss: 1.43915 v_acc: 0.70475 |  iteration: 15545 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 629 loss: 1.40664 acc: 0.69694 | v_loss: 1.30420 v_acc: 0.73210 |  iteration: 15546 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 630 loss: 1.42130 acc: 0.70898 | v_loss: 1.54626 v_acc: 0.71615 |  iteration: 15547 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 631 loss: 1.53551 acc: 0.69531 | v_loss: 1.28848 v_acc: 0.69759 |  iteration: 15548 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 632 loss: 1.40872 acc: 0.70833 | v_loss: 1.27814 v_acc: 0.70703 |  iteration: 15549 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 633 loss: 1.48508 acc: 0.70085 | v_loss: 1.43730 v_acc: 0.70475 |  iteration: 15550 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 634 loss: 1.39129 acc: 0.71029 | v_loss: 1.47515 v_acc: 0.70443 |  iteration: 15551 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 635 loss: 1.45612 acc: 0.69694 | v_loss: 1.52622 v_acc: 0.69010 |  iteration: 15552 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 636 loss: 1.45967 acc: 0.69694 | v_loss: 1.46545 v_acc: 0.70638 |  iteration: 15553 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 637 loss: 1.27109 acc: 0.72135 | v_loss: 1.42628 v_acc: 0.70410 |  iteration: 15554 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 638 loss: 1.33464 acc: 0.71549 | v_loss: 1.41428 v_acc: 0.70931 |  iteration: 15555 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 639 loss: 1.32664 acc: 0.70215 | v_loss: 1.40094 v_acc: 0.70703 |  iteration: 15556 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 640 loss: 1.43862 acc: 0.70638 | v_loss: 1.25714 v_acc: 0.71875 |  iteration: 15557 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 641 loss: 1.36347 acc: 0.70768 | v_loss: 1.32501 v_acc: 0.72298 |  iteration: 15558 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 642 loss: 1.41628 acc: 0.69531 | v_loss: 1.16802 v_acc: 0.71615 |  iteration: 15559 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 643 loss: 1.46203 acc: 0.70508 | v_loss: 1.33576 v_acc: 0.71126 |  iteration: 15560 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 644 loss: 1.43538 acc: 0.70475 | v_loss: 1.50833 v_acc: 0.69954 |  iteration: 15561 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 645 loss: 1.41838 acc: 0.69727 | v_loss: 1.32381 v_acc: 0.70833 |  iteration: 15562 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 646 loss: 1.46378 acc: 0.69499 | v_loss: 1.35519 v_acc: 0.69727 |  iteration: 15563 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 647 loss: 1.49945 acc: 0.69173 | v_loss: 1.24329 v_acc: 0.70671 |  iteration: 15564 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 648 loss: 1.37216 acc: 0.70736 | v_loss: 1.25782 v_acc: 0.70410 |  iteration: 15565 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 649 loss: 1.34986 acc: 0.70117 | v_loss: 1.23415 v_acc: 0.73926 |  iteration: 15566 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 650 loss: 1.48130 acc: 0.69857 | v_loss: 1.26413 v_acc: 0.71908 |  iteration: 15567 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 651 loss: 1.54193 acc: 0.69824 | v_loss: 1.33234 v_acc: 0.73112 |  iteration: 15568 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 652 loss: 1.51551 acc: 0.69889 | v_loss: 1.25683 v_acc: 0.71940 |  iteration: 15569 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 653 loss: 1.39503 acc: 0.70475 | v_loss: 1.29903 v_acc: 0.72266 |  iteration: 15570 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 654 loss: 1.45647 acc: 0.70964 | v_loss: 1.40464 v_acc: 0.71289 |  iteration: 15571 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 655 loss: 1.35473 acc: 0.71126 | v_loss: 1.38447 v_acc: 0.72298 |  iteration: 15572 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 656 loss: 1.42289 acc: 0.69629 | v_loss: 1.48312 v_acc: 0.69824 |  iteration: 15573 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 657 loss: 1.47823 acc: 0.69889 | v_loss: 1.43173 v_acc: 0.71647 |  iteration: 15574 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 658 loss: 1.53092 acc: 0.69596 | v_loss: 1.18559 v_acc: 0.73893 |  iteration: 15575 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 659 loss: 1.37939 acc: 0.70671 | v_loss: 1.27526 v_acc: 0.70182 |  iteration: 15576 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 660 loss: 1.41683 acc: 0.70052 | v_loss: 1.52557 v_acc: 0.69824 |  iteration: 15577 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 661 loss: 1.41553 acc: 0.69629 | v_loss: 1.23705 v_acc: 0.70833 |  iteration: 15578 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 662 loss: 1.37983 acc: 0.70182 | v_loss: 1.32480 v_acc: 0.71257 |  iteration: 15579 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 663 loss: 1.51292 acc: 0.69889 | v_loss: 1.36558 v_acc: 0.69466 |  iteration: 15580 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 664 loss: 1.41633 acc: 0.70898 | v_loss: 1.29269 v_acc: 0.71680 |  iteration: 15581 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 665 loss: 1.47198 acc: 0.69629 | v_loss: 1.36407 v_acc: 0.70117 |  iteration: 15582 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 666 loss: 1.45758 acc: 0.70443 | v_loss: 1.46146 v_acc: 0.71680 |  iteration: 15583 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 667 loss: 1.42278 acc: 0.71419 | v_loss: 1.31568 v_acc: 0.72819 |  iteration: 15584 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 668 loss: 1.41683 acc: 0.70052 | v_loss: 1.43285 v_acc: 0.70312 |  iteration: 15585 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 669 loss: 1.50447 acc: 0.68880 | v_loss: 1.36933 v_acc: 0.69954 |  iteration: 15586 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 670 loss: 1.34705 acc: 0.71354 | v_loss: 1.31840 v_acc: 0.70964 |  iteration: 15587 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 671 loss: 1.48015 acc: 0.70540 | v_loss: 1.54151 v_acc: 0.68913 |  iteration: 15588 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 672 loss: 1.40219 acc: 0.70866 | v_loss: 1.30469 v_acc: 0.72135 |  iteration: 15589 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 673 loss: 1.56156 acc: 0.68913 | v_loss: 1.58271 v_acc: 0.68294 |  iteration: 15590 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 674 loss: 1.45504 acc: 0.69792 | v_loss: 1.44316 v_acc: 0.69857 |  iteration: 15591 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 675 loss: 1.43277 acc: 0.70052 | v_loss: 1.53325 v_acc: 0.69173 |  iteration: 15592 teacher: 1 stage: sketch lr: 0.000354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 676 loss: 1.46216 acc: 0.70833 | v_loss: 1.36486 v_acc: 0.70020 |  iteration: 15593 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 677 loss: 1.45392 acc: 0.70833 | v_loss: 1.32254 v_acc: 0.70312 |  iteration: 15594 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 678 loss: 1.57816 acc: 0.68815 | v_loss: 1.32544 v_acc: 0.70020 |  iteration: 15595 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 679 loss: 1.46373 acc: 0.69499 | v_loss: 1.32206 v_acc: 0.71484 |  iteration: 15596 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 680 loss: 1.43446 acc: 0.69727 | v_loss: 1.53484 v_acc: 0.68978 |  iteration: 15597 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 681 loss: 1.45415 acc: 0.70736 | v_loss: 1.38495 v_acc: 0.70443 |  iteration: 15598 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 682 loss: 1.47763 acc: 0.70345 | v_loss: 1.34447 v_acc: 0.71029 |  iteration: 15599 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 683 loss: 1.38267 acc: 0.71029 | v_loss: 1.38316 v_acc: 0.71680 |  iteration: 15600 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 684 loss: 1.39859 acc: 0.70117 | v_loss: 1.27098 v_acc: 0.70573 |  iteration: 15601 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 685 loss: 1.45284 acc: 0.70475 | v_loss: 1.42614 v_acc: 0.69922 |  iteration: 15602 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 686 loss: 1.37470 acc: 0.70410 | v_loss: 1.43457 v_acc: 0.71289 |  iteration: 15603 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 687 loss: 1.41710 acc: 0.70182 | v_loss: 1.28753 v_acc: 0.71875 |  iteration: 15604 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 688 loss: 1.36392 acc: 0.69987 | v_loss: 1.26865 v_acc: 0.72754 |  iteration: 15605 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 689 loss: 1.52793 acc: 0.69596 | v_loss: 1.38927 v_acc: 0.71549 |  iteration: 15606 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 690 loss: 1.44787 acc: 0.69629 | v_loss: 1.44222 v_acc: 0.70247 |  iteration: 15607 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 691 loss: 1.45660 acc: 0.69434 | v_loss: 1.44731 v_acc: 0.70671 |  iteration: 15608 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 692 loss: 1.42503 acc: 0.70150 | v_loss: 1.23465 v_acc: 0.71745 |  iteration: 15609 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 693 loss: 1.47470 acc: 0.69531 | v_loss: 1.40696 v_acc: 0.72786 |  iteration: 15610 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 694 loss: 1.46609 acc: 0.69173 | v_loss: 1.48043 v_acc: 0.69824 |  iteration: 15611 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 695 loss: 1.45143 acc: 0.69727 | v_loss: 1.41267 v_acc: 0.72201 |  iteration: 15612 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 696 loss: 1.42807 acc: 0.70020 | v_loss: 1.23784 v_acc: 0.72233 |  iteration: 15613 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 697 loss: 1.43771 acc: 0.70378 | v_loss: 1.18854 v_acc: 0.74447 |  iteration: 15614 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 698 loss: 1.43181 acc: 0.70475 | v_loss: 1.21701 v_acc: 0.72493 |  iteration: 15615 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 699 loss: 1.40571 acc: 0.70540 | v_loss: 1.27540 v_acc: 0.71126 |  iteration: 15616 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 700 loss: 1.39514 acc: 0.70378 | v_loss: 1.44645 v_acc: 0.70671 |  iteration: 15617 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 701 loss: 1.38443 acc: 0.70931 | v_loss: 1.27316 v_acc: 0.71549 |  iteration: 15618 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 702 loss: 1.48430 acc: 0.69759 | v_loss: 1.47892 v_acc: 0.70475 |  iteration: 15619 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 703 loss: 1.49761 acc: 0.69206 | v_loss: 1.68865 v_acc: 0.69141 |  iteration: 15620 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 704 loss: 1.44062 acc: 0.69661 | v_loss: 1.52218 v_acc: 0.69954 |  iteration: 15621 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 705 loss: 1.41468 acc: 0.70052 | v_loss: 1.29558 v_acc: 0.72103 |  iteration: 15622 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 706 loss: 1.54585 acc: 0.68978 | v_loss: 1.37385 v_acc: 0.70085 |  iteration: 15623 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 707 loss: 1.47847 acc: 0.69401 | v_loss: 1.21999 v_acc: 0.71842 |  iteration: 15624 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 708 loss: 1.39870 acc: 0.70703 | v_loss: 1.42799 v_acc: 0.69368 |  iteration: 15625 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 709 loss: 1.45526 acc: 0.69661 | v_loss: 1.36561 v_acc: 0.70898 |  iteration: 15626 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 710 loss: 1.40762 acc: 0.70410 | v_loss: 1.36316 v_acc: 0.72396 |  iteration: 15627 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 711 loss: 1.38225 acc: 0.70020 | v_loss: 1.35540 v_acc: 0.71875 |  iteration: 15628 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 712 loss: 1.41833 acc: 0.70475 | v_loss: 1.36790 v_acc: 0.70508 |  iteration: 15629 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 713 loss: 1.41329 acc: 0.69629 | v_loss: 1.28187 v_acc: 0.72233 |  iteration: 15630 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 714 loss: 1.42298 acc: 0.70150 | v_loss: 1.29691 v_acc: 0.72135 |  iteration: 15631 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 715 loss: 1.43929 acc: 0.69466 | v_loss: 1.46887 v_acc: 0.69303 |  iteration: 15632 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 716 loss: 1.42199 acc: 0.72428 | v_loss: 1.35249 v_acc: 0.71159 |  iteration: 15633 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 717 loss: 1.47662 acc: 0.70215 | v_loss: 1.28435 v_acc: 0.71549 |  iteration: 15634 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 718 loss: 1.35222 acc: 0.70964 | v_loss: 1.26797 v_acc: 0.71973 |  iteration: 15635 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 719 loss: 1.39940 acc: 0.70410 | v_loss: 1.40886 v_acc: 0.70768 |  iteration: 15636 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 720 loss: 1.39782 acc: 0.70736 | v_loss: 1.32533 v_acc: 0.73210 |  iteration: 15637 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 721 loss: 1.38509 acc: 0.70182 | v_loss: 1.53665 v_acc: 0.71322 |  iteration: 15638 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 722 loss: 1.54017 acc: 0.69076 | v_loss: 1.30000 v_acc: 0.69531 |  iteration: 15639 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 723 loss: 1.45651 acc: 0.70345 | v_loss: 1.28198 v_acc: 0.70117 |  iteration: 15640 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 724 loss: 1.50097 acc: 0.70020 | v_loss: 1.44675 v_acc: 0.70508 |  iteration: 15641 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 725 loss: 1.48794 acc: 0.70085 | v_loss: 1.47437 v_acc: 0.70443 |  iteration: 15642 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 726 loss: 1.55922 acc: 0.69401 | v_loss: 1.51750 v_acc: 0.69076 |  iteration: 15643 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 727 loss: 1.39206 acc: 0.71680 | v_loss: 1.46523 v_acc: 0.70605 |  iteration: 15644 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 728 loss: 1.46331 acc: 0.70703 | v_loss: 1.42410 v_acc: 0.70736 |  iteration: 15645 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 729 loss: 1.43098 acc: 0.70996 | v_loss: 1.41165 v_acc: 0.70703 |  iteration: 15646 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 730 loss: 1.46737 acc: 0.70475 | v_loss: 1.40126 v_acc: 0.70443 |  iteration: 15647 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 731 loss: 1.45437 acc: 0.70768 | v_loss: 1.27619 v_acc: 0.71159 |  iteration: 15648 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 732 loss: 1.45490 acc: 0.70540 | v_loss: 1.31358 v_acc: 0.72461 |  iteration: 15649 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 733 loss: 1.53535 acc: 0.69043 | v_loss: 1.20150 v_acc: 0.71517 |  iteration: 15650 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 734 loss: 1.38996 acc: 0.71549 | v_loss: 1.35020 v_acc: 0.70703 |  iteration: 15651 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 735 loss: 1.37362 acc: 0.70638 | v_loss: 1.50567 v_acc: 0.69954 |  iteration: 15652 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 736 loss: 1.43187 acc: 0.70768 | v_loss: 1.32874 v_acc: 0.71484 |  iteration: 15653 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 737 loss: 1.36843 acc: 0.70605 | v_loss: 1.36991 v_acc: 0.70312 |  iteration: 15654 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 738 loss: 1.44198 acc: 0.70573 | v_loss: 1.24491 v_acc: 0.71680 |  iteration: 15655 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 739 loss: 1.41149 acc: 0.70443 | v_loss: 1.24863 v_acc: 0.70671 |  iteration: 15656 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 740 loss: 1.38982 acc: 0.70964 | v_loss: 1.26928 v_acc: 0.73568 |  iteration: 15657 teacher: 0 stage: sketch lr: 0.000353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 741 loss: 1.46932 acc: 0.71159 | v_loss: 1.26781 v_acc: 0.72461 |  iteration: 15658 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 742 loss: 1.42217 acc: 0.70182 | v_loss: 1.35580 v_acc: 0.72689 |  iteration: 15659 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 743 loss: 1.49070 acc: 0.69727 | v_loss: 1.26680 v_acc: 0.72461 |  iteration: 15660 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 744 loss: 1.48690 acc: 0.70085 | v_loss: 1.31233 v_acc: 0.72005 |  iteration: 15661 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 745 loss: 1.42204 acc: 0.70540 | v_loss: 1.42378 v_acc: 0.71289 |  iteration: 15662 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 746 loss: 1.50078 acc: 0.70117 | v_loss: 1.38589 v_acc: 0.72298 |  iteration: 15663 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 747 loss: 1.56029 acc: 0.69596 | v_loss: 1.47963 v_acc: 0.69922 |  iteration: 15664 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 748 loss: 1.50174 acc: 0.69434 | v_loss: 1.39836 v_acc: 0.71973 |  iteration: 15665 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 749 loss: 1.40027 acc: 0.70573 | v_loss: 1.18401 v_acc: 0.74316 |  iteration: 15666 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 750 loss: 1.44701 acc: 0.69238 | v_loss: 1.27571 v_acc: 0.70443 |  iteration: 15667 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 751 loss: 1.44674 acc: 0.70052 | v_loss: 1.50475 v_acc: 0.70312 |  iteration: 15668 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 752 loss: 1.56222 acc: 0.69629 | v_loss: 1.25283 v_acc: 0.70833 |  iteration: 15669 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 753 loss: 1.39643 acc: 0.70312 | v_loss: 1.32647 v_acc: 0.71257 |  iteration: 15670 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 754 loss: 1.43301 acc: 0.70703 | v_loss: 1.36102 v_acc: 0.69499 |  iteration: 15671 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 755 loss: 1.41668 acc: 0.70671 | v_loss: 1.30541 v_acc: 0.70996 |  iteration: 15672 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 756 loss: 1.41084 acc: 0.70638 | v_loss: 1.37199 v_acc: 0.70215 |  iteration: 15673 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 757 loss: 1.49872 acc: 0.69629 | v_loss: 1.45960 v_acc: 0.72005 |  iteration: 15674 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 758 loss: 1.44383 acc: 0.69759 | v_loss: 1.31486 v_acc: 0.72786 |  iteration: 15675 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 759 loss: 1.37431 acc: 0.70833 | v_loss: 1.43746 v_acc: 0.70540 |  iteration: 15676 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 760 loss: 1.44174 acc: 0.70703 | v_loss: 1.38659 v_acc: 0.69857 |  iteration: 15677 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 761 loss: 1.40757 acc: 0.70378 | v_loss: 1.31561 v_acc: 0.70833 |  iteration: 15678 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 762 loss: 1.47577 acc: 0.69792 | v_loss: 1.55243 v_acc: 0.68815 |  iteration: 15679 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 763 loss: 1.40581 acc: 0.69954 | v_loss: 1.29487 v_acc: 0.72005 |  iteration: 15680 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 764 loss: 1.63002 acc: 0.68327 | v_loss: 1.59154 v_acc: 0.68424 |  iteration: 15681 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 765 loss: 1.45628 acc: 0.69857 | v_loss: 1.44393 v_acc: 0.69889 |  iteration: 15682 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 766 loss: 1.45046 acc: 0.69368 | v_loss: 1.51970 v_acc: 0.68978 |  iteration: 15683 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 767 loss: 1.35194 acc: 0.70443 | v_loss: 1.36740 v_acc: 0.69792 |  iteration: 15684 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 768 loss: 1.45827 acc: 0.69629 | v_loss: 1.32378 v_acc: 0.70378 |  iteration: 15685 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 769 loss: 1.51121 acc: 0.69661 | v_loss: 1.32496 v_acc: 0.70247 |  iteration: 15686 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 770 loss: 1.38335 acc: 0.70866 | v_loss: 1.32478 v_acc: 0.71745 |  iteration: 15687 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 771 loss: 1.33729 acc: 0.70866 | v_loss: 1.52761 v_acc: 0.68945 |  iteration: 15688 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 772 loss: 1.33033 acc: 0.72005 | v_loss: 1.37870 v_acc: 0.70443 |  iteration: 15689 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 773 loss: 1.41938 acc: 0.70345 | v_loss: 1.34363 v_acc: 0.71029 |  iteration: 15690 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 774 loss: 1.37594 acc: 0.71094 | v_loss: 1.38984 v_acc: 0.71680 |  iteration: 15691 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 775 loss: 1.31179 acc: 0.71387 | v_loss: 1.26703 v_acc: 0.70573 |  iteration: 15692 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 776 loss: 1.36967 acc: 0.70801 | v_loss: 1.44426 v_acc: 0.69792 |  iteration: 15693 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 777 loss: 1.44318 acc: 0.70801 | v_loss: 1.44441 v_acc: 0.71289 |  iteration: 15694 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 778 loss: 1.48037 acc: 0.70020 | v_loss: 1.28161 v_acc: 0.71875 |  iteration: 15695 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 779 loss: 1.43909 acc: 0.70150 | v_loss: 1.26884 v_acc: 0.72754 |  iteration: 15696 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 780 loss: 1.45845 acc: 0.69531 | v_loss: 1.38929 v_acc: 0.71940 |  iteration: 15697 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 781 loss: 1.45909 acc: 0.70117 | v_loss: 1.43508 v_acc: 0.70345 |  iteration: 15698 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 782 loss: 1.41625 acc: 0.70085 | v_loss: 1.42872 v_acc: 0.70378 |  iteration: 15699 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 783 loss: 1.46026 acc: 0.69596 | v_loss: 1.23187 v_acc: 0.71452 |  iteration: 15700 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 784 loss: 1.47755 acc: 0.69141 | v_loss: 1.38506 v_acc: 0.72819 |  iteration: 15701 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 785 loss: 1.44938 acc: 0.69954 | v_loss: 1.46769 v_acc: 0.69759 |  iteration: 15702 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 786 loss: 1.41028 acc: 0.70247 | v_loss: 1.41077 v_acc: 0.72233 |  iteration: 15703 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 787 loss: 1.47863 acc: 0.69564 | v_loss: 1.24957 v_acc: 0.71810 |  iteration: 15704 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 788 loss: 1.37017 acc: 0.70801 | v_loss: 1.20449 v_acc: 0.73600 |  iteration: 15705 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 789 loss: 1.43327 acc: 0.70052 | v_loss: 1.21218 v_acc: 0.72656 |  iteration: 15706 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 790 loss: 1.52374 acc: 0.70280 | v_loss: 1.28294 v_acc: 0.70768 |  iteration: 15707 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 791 loss: 1.33564 acc: 0.71712 | v_loss: 1.45063 v_acc: 0.69596 |  iteration: 15708 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 792 loss: 1.41670 acc: 0.69889 | v_loss: 1.27102 v_acc: 0.71224 |  iteration: 15709 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 793 loss: 1.41064 acc: 0.70312 | v_loss: 1.44643 v_acc: 0.71647 |  iteration: 15710 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 794 loss: 1.48155 acc: 0.69792 | v_loss: 1.66999 v_acc: 0.69303 |  iteration: 15711 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 795 loss: 1.43083 acc: 0.69661 | v_loss: 1.52185 v_acc: 0.69987 |  iteration: 15712 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 796 loss: 1.48939 acc: 0.69629 | v_loss: 1.29275 v_acc: 0.72331 |  iteration: 15713 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 797 loss: 1.45818 acc: 0.69336 | v_loss: 1.37771 v_acc: 0.70052 |  iteration: 15714 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 798 loss: 1.35722 acc: 0.70898 | v_loss: 1.21973 v_acc: 0.71973 |  iteration: 15715 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 799 loss: 1.51423 acc: 0.70117 | v_loss: 1.42633 v_acc: 0.70150 |  iteration: 15716 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 800 loss: 1.45361 acc: 0.70052 | v_loss: 1.36126 v_acc: 0.71029 |  iteration: 15717 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 801 loss: 1.40735 acc: 0.69792 | v_loss: 1.35213 v_acc: 0.72949 |  iteration: 15718 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 802 loss: 1.44869 acc: 0.69694 | v_loss: 1.35802 v_acc: 0.71680 |  iteration: 15719 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 803 loss: 1.53763 acc: 0.69238 | v_loss: 1.37958 v_acc: 0.70345 |  iteration: 15720 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 804 loss: 1.49741 acc: 0.69922 | v_loss: 1.27866 v_acc: 0.72201 |  iteration: 15721 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 805 loss: 1.31854 acc: 0.70866 | v_loss: 1.29770 v_acc: 0.72135 |  iteration: 15722 teacher: 1 stage: sketch lr: 0.000352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 806 loss: 1.45304 acc: 0.70117 | v_loss: 1.45141 v_acc: 0.69303 |  iteration: 15723 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 807 loss: 1.39930 acc: 0.70215 | v_loss: 1.34500 v_acc: 0.71452 |  iteration: 15724 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 808 loss: 1.36717 acc: 0.70931 | v_loss: 1.28088 v_acc: 0.71777 |  iteration: 15725 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 809 loss: 1.50738 acc: 0.70280 | v_loss: 1.27617 v_acc: 0.71484 |  iteration: 15726 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 810 loss: 1.42483 acc: 0.70768 | v_loss: 1.43581 v_acc: 0.70540 |  iteration: 15727 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 811 loss: 1.33035 acc: 0.71452 | v_loss: 1.31866 v_acc: 0.73047 |  iteration: 15728 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 812 loss: 1.34553 acc: 0.72201 | v_loss: 1.56293 v_acc: 0.71615 |  iteration: 15729 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 813 loss: 1.43912 acc: 0.70475 | v_loss: 1.28256 v_acc: 0.69759 |  iteration: 15730 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 814 loss: 1.39299 acc: 0.70801 | v_loss: 1.28671 v_acc: 0.70703 |  iteration: 15731 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 815 loss: 1.39537 acc: 0.70410 | v_loss: 1.43601 v_acc: 0.70345 |  iteration: 15732 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 816 loss: 1.36877 acc: 0.70410 | v_loss: 1.47240 v_acc: 0.70247 |  iteration: 15733 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 817 loss: 1.46705 acc: 0.70117 | v_loss: 1.52195 v_acc: 0.69076 |  iteration: 15734 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 818 loss: 1.39456 acc: 0.71191 | v_loss: 1.47901 v_acc: 0.70605 |  iteration: 15735 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 819 loss: 1.38686 acc: 0.71810 | v_loss: 1.42155 v_acc: 0.70410 |  iteration: 15736 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 820 loss: 1.45052 acc: 0.69922 | v_loss: 1.40611 v_acc: 0.70866 |  iteration: 15737 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 821 loss: 1.43113 acc: 0.70671 | v_loss: 1.41049 v_acc: 0.70671 |  iteration: 15738 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 822 loss: 1.42994 acc: 0.70638 | v_loss: 1.27242 v_acc: 0.71126 |  iteration: 15739 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 823 loss: 1.43326 acc: 0.70508 | v_loss: 1.31857 v_acc: 0.72461 |  iteration: 15740 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 824 loss: 1.49690 acc: 0.69596 | v_loss: 1.19531 v_acc: 0.71517 |  iteration: 15741 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 825 loss: 1.46429 acc: 0.69954 | v_loss: 1.34254 v_acc: 0.70703 |  iteration: 15742 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 826 loss: 1.47539 acc: 0.69206 | v_loss: 1.50454 v_acc: 0.69987 |  iteration: 15743 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 827 loss: 1.38639 acc: 0.70150 | v_loss: 1.33539 v_acc: 0.70833 |  iteration: 15744 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 828 loss: 1.34441 acc: 0.70768 | v_loss: 1.36381 v_acc: 0.69727 |  iteration: 15745 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 829 loss: 1.48825 acc: 0.69694 | v_loss: 1.24038 v_acc: 0.71126 |  iteration: 15746 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 830 loss: 1.37384 acc: 0.70866 | v_loss: 1.24400 v_acc: 0.70345 |  iteration: 15747 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 831 loss: 1.41689 acc: 0.70085 | v_loss: 1.25458 v_acc: 0.73568 |  iteration: 15748 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 832 loss: 1.43041 acc: 0.69987 | v_loss: 1.26092 v_acc: 0.72461 |  iteration: 15749 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 833 loss: 1.31717 acc: 0.70703 | v_loss: 1.36372 v_acc: 0.72689 |  iteration: 15750 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 834 loss: 1.53157 acc: 0.69141 | v_loss: 1.27088 v_acc: 0.72852 |  iteration: 15751 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 835 loss: 1.45442 acc: 0.69661 | v_loss: 1.31185 v_acc: 0.72103 |  iteration: 15752 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 836 loss: 1.49796 acc: 0.68913 | v_loss: 1.42708 v_acc: 0.71354 |  iteration: 15753 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 837 loss: 1.35975 acc: 0.71549 | v_loss: 1.40992 v_acc: 0.72428 |  iteration: 15754 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 838 loss: 1.45725 acc: 0.70150 | v_loss: 1.48689 v_acc: 0.70182 |  iteration: 15755 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 839 loss: 1.41630 acc: 0.69954 | v_loss: 1.42073 v_acc: 0.71777 |  iteration: 15756 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 840 loss: 1.60051 acc: 0.68945 | v_loss: 1.17533 v_acc: 0.74479 |  iteration: 15757 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 841 loss: 1.45498 acc: 0.69596 | v_loss: 1.24720 v_acc: 0.70931 |  iteration: 15758 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 842 loss: 1.40939 acc: 0.71191 | v_loss: 1.50948 v_acc: 0.70247 |  iteration: 15759 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 843 loss: 1.45333 acc: 0.70117 | v_loss: 1.21885 v_acc: 0.70866 |  iteration: 15760 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 844 loss: 1.37311 acc: 0.71029 | v_loss: 1.32609 v_acc: 0.71159 |  iteration: 15761 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 845 loss: 1.36485 acc: 0.69889 | v_loss: 1.36479 v_acc: 0.69336 |  iteration: 15762 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 846 loss: 1.45032 acc: 0.69564 | v_loss: 1.29371 v_acc: 0.71191 |  iteration: 15763 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 847 loss: 1.43943 acc: 0.70247 | v_loss: 1.35980 v_acc: 0.69629 |  iteration: 15764 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 848 loss: 1.32885 acc: 0.71484 | v_loss: 1.47945 v_acc: 0.71517 |  iteration: 15765 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 849 loss: 1.50558 acc: 0.69987 | v_loss: 1.31848 v_acc: 0.72689 |  iteration: 15766 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 850 loss: 1.47784 acc: 0.69857 | v_loss: 1.45566 v_acc: 0.70443 |  iteration: 15767 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 851 loss: 1.34056 acc: 0.70996 | v_loss: 1.36181 v_acc: 0.69922 |  iteration: 15768 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 852 loss: 1.39911 acc: 0.70215 | v_loss: 1.32722 v_acc: 0.70898 |  iteration: 15769 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 853 loss: 1.40024 acc: 0.71289 | v_loss: 1.55106 v_acc: 0.68815 |  iteration: 15770 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 854 loss: 1.31611 acc: 0.71354 | v_loss: 1.29974 v_acc: 0.72005 |  iteration: 15771 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 855 loss: 1.49786 acc: 0.69889 | v_loss: 1.59050 v_acc: 0.68424 |  iteration: 15772 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 856 loss: 1.48434 acc: 0.70085 | v_loss: 1.45698 v_acc: 0.69792 |  iteration: 15773 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 857 loss: 1.40620 acc: 0.71289 | v_loss: 1.52093 v_acc: 0.69173 |  iteration: 15774 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 858 loss: 1.45124 acc: 0.69368 | v_loss: 1.38104 v_acc: 0.69792 |  iteration: 15775 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 859 loss: 1.35456 acc: 0.70736 | v_loss: 1.32205 v_acc: 0.70378 |  iteration: 15776 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 860 loss: 1.48997 acc: 0.69564 | v_loss: 1.33935 v_acc: 0.70215 |  iteration: 15777 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 861 loss: 1.47028 acc: 0.69434 | v_loss: 1.33082 v_acc: 0.71615 |  iteration: 15778 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 862 loss: 1.51497 acc: 0.69303 | v_loss: 1.54246 v_acc: 0.68945 |  iteration: 15779 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 863 loss: 1.42160 acc: 0.70345 | v_loss: 1.38324 v_acc: 0.70703 |  iteration: 15780 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 864 loss: 1.37673 acc: 0.70540 | v_loss: 1.33901 v_acc: 0.70833 |  iteration: 15781 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 865 loss: 1.38836 acc: 0.70931 | v_loss: 1.38829 v_acc: 0.71582 |  iteration: 15782 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 866 loss: 1.44401 acc: 0.70345 | v_loss: 1.26822 v_acc: 0.70443 |  iteration: 15783 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 867 loss: 1.50508 acc: 0.69922 | v_loss: 1.42059 v_acc: 0.69889 |  iteration: 15784 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 868 loss: 1.51389 acc: 0.69661 | v_loss: 1.42087 v_acc: 0.71615 |  iteration: 15785 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 869 loss: 1.42502 acc: 0.70768 | v_loss: 1.28675 v_acc: 0.71712 |  iteration: 15786 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 870 loss: 1.39417 acc: 0.70150 | v_loss: 1.25099 v_acc: 0.72754 |  iteration: 15787 teacher: 1 stage: sketch lr: 0.000352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 871 loss: 1.44584 acc: 0.70508 | v_loss: 1.37183 v_acc: 0.71940 |  iteration: 15788 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 872 loss: 1.35429 acc: 0.70247 | v_loss: 1.41530 v_acc: 0.70345 |  iteration: 15789 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 873 loss: 1.47383 acc: 0.69466 | v_loss: 1.41840 v_acc: 0.70410 |  iteration: 15790 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 874 loss: 1.41637 acc: 0.69596 | v_loss: 1.22409 v_acc: 0.71712 |  iteration: 15791 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 875 loss: 1.40314 acc: 0.70117 | v_loss: 1.38346 v_acc: 0.72786 |  iteration: 15792 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 876 loss: 1.47650 acc: 0.69824 | v_loss: 1.46640 v_acc: 0.69792 |  iteration: 15793 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 877 loss: 1.46121 acc: 0.69954 | v_loss: 1.41337 v_acc: 0.72233 |  iteration: 15794 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 878 loss: 1.44117 acc: 0.70280 | v_loss: 1.25683 v_acc: 0.71810 |  iteration: 15795 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 879 loss: 1.44789 acc: 0.70703 | v_loss: 1.21096 v_acc: 0.73600 |  iteration: 15796 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 880 loss: 1.44010 acc: 0.70378 | v_loss: 1.20895 v_acc: 0.72721 |  iteration: 15797 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 881 loss: 1.38618 acc: 0.70508 | v_loss: 1.28562 v_acc: 0.70768 |  iteration: 15798 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 882 loss: 1.31219 acc: 0.71322 | v_loss: 1.45070 v_acc: 0.69596 |  iteration: 15799 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 883 loss: 1.33478 acc: 0.70833 | v_loss: 1.27757 v_acc: 0.71224 |  iteration: 15800 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 884 loss: 1.38477 acc: 0.70996 | v_loss: 1.44605 v_acc: 0.71582 |  iteration: 15801 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 885 loss: 1.46950 acc: 0.69499 | v_loss: 1.68686 v_acc: 0.69303 |  iteration: 15802 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 886 loss: 1.38525 acc: 0.70280 | v_loss: 1.53840 v_acc: 0.70117 |  iteration: 15803 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 887 loss: 1.41175 acc: 0.71029 | v_loss: 1.29512 v_acc: 0.72396 |  iteration: 15804 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 888 loss: 1.56038 acc: 0.69564 | v_loss: 1.37861 v_acc: 0.70996 |  iteration: 15805 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 889 loss: 1.41775 acc: 0.70605 | v_loss: 1.22204 v_acc: 0.72201 |  iteration: 15806 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 890 loss: 1.50851 acc: 0.68913 | v_loss: 1.42303 v_acc: 0.70378 |  iteration: 15807 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 891 loss: 1.41353 acc: 0.70150 | v_loss: 1.35876 v_acc: 0.71810 |  iteration: 15808 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 892 loss: 1.45919 acc: 0.69987 | v_loss: 1.35322 v_acc: 0.73079 |  iteration: 15809 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 893 loss: 1.46959 acc: 0.70508 | v_loss: 1.36341 v_acc: 0.71777 |  iteration: 15810 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 894 loss: 1.43099 acc: 0.70801 | v_loss: 1.37842 v_acc: 0.70345 |  iteration: 15811 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 895 loss: 1.50574 acc: 0.69629 | v_loss: 1.28596 v_acc: 0.72201 |  iteration: 15812 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 896 loss: 1.39953 acc: 0.70410 | v_loss: 1.30198 v_acc: 0.72005 |  iteration: 15813 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 897 loss: 1.40294 acc: 0.70508 | v_loss: 1.48750 v_acc: 0.69043 |  iteration: 15814 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 898 loss: 1.39811 acc: 0.70573 | v_loss: 1.33236 v_acc: 0.70866 |  iteration: 15815 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 899 loss: 1.42834 acc: 0.69824 | v_loss: 1.30232 v_acc: 0.71126 |  iteration: 15816 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 900 loss: 1.46610 acc: 0.69629 | v_loss: 1.29333 v_acc: 0.72135 |  iteration: 15817 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 901 loss: 1.35336 acc: 0.70508 | v_loss: 1.43495 v_acc: 0.70573 |  iteration: 15818 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 902 loss: 1.46954 acc: 0.70117 | v_loss: 1.30682 v_acc: 0.73112 |  iteration: 15819 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 903 loss: 1.54973 acc: 0.69368 | v_loss: 1.54282 v_acc: 0.71452 |  iteration: 15820 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 904 loss: 1.40983 acc: 0.70247 | v_loss: 1.27555 v_acc: 0.70150 |  iteration: 15821 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 905 loss: 1.40780 acc: 0.70833 | v_loss: 1.27336 v_acc: 0.70573 |  iteration: 15822 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 906 loss: 1.42534 acc: 0.70410 | v_loss: 1.44782 v_acc: 0.70378 |  iteration: 15823 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 907 loss: 1.48739 acc: 0.69564 | v_loss: 1.48561 v_acc: 0.70150 |  iteration: 15824 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 908 loss: 1.40342 acc: 0.70182 | v_loss: 1.52152 v_acc: 0.69368 |  iteration: 15825 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 909 loss: 1.47969 acc: 0.69824 | v_loss: 1.46896 v_acc: 0.70833 |  iteration: 15826 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 910 loss: 1.50878 acc: 0.69434 | v_loss: 1.41839 v_acc: 0.70085 |  iteration: 15827 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 911 loss: 1.47246 acc: 0.68978 | v_loss: 1.40311 v_acc: 0.70931 |  iteration: 15828 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 912 loss: 1.55490 acc: 0.69043 | v_loss: 1.40244 v_acc: 0.70703 |  iteration: 15829 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 913 loss: 1.41159 acc: 0.70247 | v_loss: 1.25902 v_acc: 0.71680 |  iteration: 15830 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 914 loss: 1.47860 acc: 0.69564 | v_loss: 1.31901 v_acc: 0.72396 |  iteration: 15831 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 915 loss: 1.40689 acc: 0.69922 | v_loss: 1.19540 v_acc: 0.70638 |  iteration: 15832 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 916 loss: 1.48569 acc: 0.70964 | v_loss: 1.34566 v_acc: 0.70247 |  iteration: 15833 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 917 loss: 1.36422 acc: 0.71549 | v_loss: 1.49492 v_acc: 0.69987 |  iteration: 15834 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 918 loss: 1.35029 acc: 0.70182 | v_loss: 1.33210 v_acc: 0.70638 |  iteration: 15835 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 919 loss: 1.46655 acc: 0.70605 | v_loss: 1.34534 v_acc: 0.69694 |  iteration: 15836 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 920 loss: 1.47143 acc: 0.69824 | v_loss: 1.25124 v_acc: 0.70638 |  iteration: 15837 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 921 loss: 1.41265 acc: 0.71191 | v_loss: 1.25581 v_acc: 0.70215 |  iteration: 15838 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 922 loss: 1.51761 acc: 0.69922 | v_loss: 1.23583 v_acc: 0.73503 |  iteration: 15839 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 923 loss: 1.44783 acc: 0.70410 | v_loss: 1.26926 v_acc: 0.72168 |  iteration: 15840 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 924 loss: 1.45305 acc: 0.70736 | v_loss: 1.33529 v_acc: 0.73145 |  iteration: 15841 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 925 loss: 1.46076 acc: 0.70475 | v_loss: 1.25680 v_acc: 0.72461 |  iteration: 15842 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 926 loss: 1.33561 acc: 0.71582 | v_loss: 1.29954 v_acc: 0.72005 |  iteration: 15843 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 927 loss: 1.30630 acc: 0.71484 | v_loss: 1.41444 v_acc: 0.71224 |  iteration: 15844 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 928 loss: 1.59064 acc: 0.68913 | v_loss: 1.39659 v_acc: 0.72070 |  iteration: 15845 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 929 loss: 1.44730 acc: 0.69922 | v_loss: 1.49129 v_acc: 0.69954 |  iteration: 15846 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 930 loss: 1.44681 acc: 0.70280 | v_loss: 1.42332 v_acc: 0.71615 |  iteration: 15847 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 931 loss: 1.48870 acc: 0.69694 | v_loss: 1.17398 v_acc: 0.74544 |  iteration: 15848 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 932 loss: 1.39602 acc: 0.71615 | v_loss: 1.25352 v_acc: 0.70931 |  iteration: 15849 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 933 loss: 1.41983 acc: 0.69564 | v_loss: 1.51449 v_acc: 0.70247 |  iteration: 15850 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 934 loss: 1.34306 acc: 0.71191 | v_loss: 1.21345 v_acc: 0.70866 |  iteration: 15851 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 935 loss: 1.47624 acc: 0.70182 | v_loss: 1.32699 v_acc: 0.71159 |  iteration: 15852 teacher: 1 stage: sketch lr: 0.000351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 936 loss: 1.43772 acc: 0.70280 | v_loss: 1.36091 v_acc: 0.69336 |  iteration: 15853 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 937 loss: 1.58021 acc: 0.69043 | v_loss: 1.29200 v_acc: 0.71191 |  iteration: 15854 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 938 loss: 1.50676 acc: 0.69141 | v_loss: 1.36294 v_acc: 0.69629 |  iteration: 15855 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 939 loss: 1.43938 acc: 0.70182 | v_loss: 1.46848 v_acc: 0.71126 |  iteration: 15856 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 940 loss: 1.33687 acc: 0.70736 | v_loss: 1.31902 v_acc: 0.72689 |  iteration: 15857 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 941 loss: 1.38632 acc: 0.70768 | v_loss: 1.44644 v_acc: 0.70443 |  iteration: 15858 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 942 loss: 1.46189 acc: 0.70020 | v_loss: 1.35962 v_acc: 0.69922 |  iteration: 15859 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 943 loss: 1.51573 acc: 0.69954 | v_loss: 1.31883 v_acc: 0.70898 |  iteration: 15860 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 944 loss: 1.55232 acc: 0.69238 | v_loss: 1.54415 v_acc: 0.68815 |  iteration: 15861 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 945 loss: 1.41052 acc: 0.70150 | v_loss: 1.29544 v_acc: 0.71908 |  iteration: 15862 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 946 loss: 1.40971 acc: 0.70378 | v_loss: 1.58525 v_acc: 0.68294 |  iteration: 15863 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 947 loss: 1.43229 acc: 0.69531 | v_loss: 1.44362 v_acc: 0.69889 |  iteration: 15864 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 948 loss: 1.46063 acc: 0.69759 | v_loss: 1.52443 v_acc: 0.68978 |  iteration: 15865 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 949 loss: 1.37739 acc: 0.70410 | v_loss: 1.37079 v_acc: 0.69889 |  iteration: 15866 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 950 loss: 1.34332 acc: 0.71094 | v_loss: 1.32913 v_acc: 0.70182 |  iteration: 15867 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 951 loss: 1.34683 acc: 0.71029 | v_loss: 1.33556 v_acc: 0.69987 |  iteration: 15868 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 952 loss: 1.48969 acc: 0.69596 | v_loss: 1.33347 v_acc: 0.71484 |  iteration: 15869 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 953 loss: 1.51390 acc: 0.69824 | v_loss: 1.54223 v_acc: 0.68978 |  iteration: 15870 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 954 loss: 1.44110 acc: 0.70020 | v_loss: 1.38353 v_acc: 0.70443 |  iteration: 15871 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 955 loss: 1.36885 acc: 0.72005 | v_loss: 1.33226 v_acc: 0.71029 |  iteration: 15872 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 956 loss: 1.38855 acc: 0.71159 | v_loss: 1.38341 v_acc: 0.71680 |  iteration: 15873 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 957 loss: 1.38998 acc: 0.71387 | v_loss: 1.27399 v_acc: 0.70540 |  iteration: 15874 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 958 loss: 1.44242 acc: 0.69629 | v_loss: 1.44779 v_acc: 0.69596 |  iteration: 15875 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 959 loss: 1.44411 acc: 0.70833 | v_loss: 1.42812 v_acc: 0.71289 |  iteration: 15876 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 960 loss: 1.44608 acc: 0.69922 | v_loss: 1.28082 v_acc: 0.71875 |  iteration: 15877 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 961 loss: 1.44280 acc: 0.70410 | v_loss: 1.25425 v_acc: 0.72949 |  iteration: 15878 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 962 loss: 1.42468 acc: 0.69401 | v_loss: 1.37736 v_acc: 0.71615 |  iteration: 15879 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 963 loss: 1.54217 acc: 0.69499 | v_loss: 1.41506 v_acc: 0.70540 |  iteration: 15880 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 964 loss: 1.43433 acc: 0.70345 | v_loss: 1.42244 v_acc: 0.70508 |  iteration: 15881 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 965 loss: 1.42548 acc: 0.69043 | v_loss: 1.22648 v_acc: 0.71615 |  iteration: 15882 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 966 loss: 1.46059 acc: 0.69857 | v_loss: 1.39377 v_acc: 0.72786 |  iteration: 15883 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 967 loss: 1.44423 acc: 0.70117 | v_loss: 1.47489 v_acc: 0.69792 |  iteration: 15884 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 968 loss: 1.42831 acc: 0.70247 | v_loss: 1.41630 v_acc: 0.72070 |  iteration: 15885 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 969 loss: 1.52614 acc: 0.69466 | v_loss: 1.23897 v_acc: 0.72233 |  iteration: 15886 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 970 loss: 1.43200 acc: 0.70117 | v_loss: 1.18830 v_acc: 0.74447 |  iteration: 15887 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 971 loss: 1.34822 acc: 0.70345 | v_loss: 1.21108 v_acc: 0.72493 |  iteration: 15888 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 972 loss: 1.41467 acc: 0.70020 | v_loss: 1.26968 v_acc: 0.71126 |  iteration: 15889 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 973 loss: 1.35783 acc: 0.70605 | v_loss: 1.44897 v_acc: 0.70671 |  iteration: 15890 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 974 loss: 1.41662 acc: 0.72461 | v_loss: 1.26980 v_acc: 0.71549 |  iteration: 15891 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 975 loss: 1.46066 acc: 0.69954 | v_loss: 1.48180 v_acc: 0.70475 |  iteration: 15892 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 976 loss: 1.45156 acc: 0.69922 | v_loss: 1.67087 v_acc: 0.69303 |  iteration: 15893 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 977 loss: 1.41163 acc: 0.69694 | v_loss: 1.52459 v_acc: 0.70117 |  iteration: 15894 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 978 loss: 1.56608 acc: 0.69759 | v_loss: 1.29317 v_acc: 0.72331 |  iteration: 15895 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 979 loss: 1.41236 acc: 0.70280 | v_loss: 1.36744 v_acc: 0.70280 |  iteration: 15896 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 980 loss: 1.38894 acc: 0.70312 | v_loss: 1.22607 v_acc: 0.72103 |  iteration: 15897 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 981 loss: 1.44837 acc: 0.70247 | v_loss: 1.40379 v_acc: 0.70020 |  iteration: 15898 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 982 loss: 1.53533 acc: 0.68717 | v_loss: 1.35891 v_acc: 0.71094 |  iteration: 15899 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 983 loss: 1.40432 acc: 0.71061 | v_loss: 1.34325 v_acc: 0.72949 |  iteration: 15900 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 984 loss: 1.42313 acc: 0.70410 | v_loss: 1.35435 v_acc: 0.71810 |  iteration: 15901 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 985 loss: 1.52803 acc: 0.69531 | v_loss: 1.37547 v_acc: 0.70508 |  iteration: 15902 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 986 loss: 1.52889 acc: 0.68880 | v_loss: 1.28799 v_acc: 0.72201 |  iteration: 15903 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 987 loss: 1.45026 acc: 0.70540 | v_loss: 1.29438 v_acc: 0.72005 |  iteration: 15904 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 988 loss: 1.44266 acc: 0.70117 | v_loss: 1.50703 v_acc: 0.69043 |  iteration: 15905 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 989 loss: 1.36234 acc: 0.70605 | v_loss: 1.33202 v_acc: 0.70996 |  iteration: 15906 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 990 loss: 1.44257 acc: 0.70443 | v_loss: 1.29472 v_acc: 0.71419 |  iteration: 15907 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 991 loss: 1.56276 acc: 0.69564 | v_loss: 1.28710 v_acc: 0.71745 |  iteration: 15908 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 992 loss: 1.41985 acc: 0.70345 | v_loss: 1.41989 v_acc: 0.70573 |  iteration: 15909 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 993 loss: 1.42297 acc: 0.70768 | v_loss: 1.31210 v_acc: 0.73112 |  iteration: 15910 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 994 loss: 1.52035 acc: 0.68620 | v_loss: 1.53730 v_acc: 0.71452 |  iteration: 15911 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 995 loss: 1.37277 acc: 0.71419 | v_loss: 1.29356 v_acc: 0.69759 |  iteration: 15912 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 996 loss: 1.38735 acc: 0.69792 | v_loss: 1.28279 v_acc: 0.70443 |  iteration: 15913 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 997 loss: 1.44468 acc: 0.69238 | v_loss: 1.43478 v_acc: 0.70312 |  iteration: 15914 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 998 loss: 1.47791 acc: 0.69922 | v_loss: 1.47005 v_acc: 0.70378 |  iteration: 15915 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 999 loss: 1.49274 acc: 0.70182 | v_loss: 1.51350 v_acc: 0.68978 |  iteration: 15916 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1000 loss: 1.46681 acc: 0.69043 | v_loss: 1.46439 v_acc: 0.70638 |  iteration: 15917 teacher: 0 stage: sketch lr: 0.000350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1001 loss: 1.37564 acc: 0.70573 | v_loss: 1.41848 v_acc: 0.70345 |  iteration: 15918 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1002 loss: 1.50094 acc: 0.69629 | v_loss: 1.40428 v_acc: 0.70703 |  iteration: 15919 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1003 loss: 1.39847 acc: 0.70475 | v_loss: 1.39558 v_acc: 0.70443 |  iteration: 15920 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1004 loss: 1.35108 acc: 0.70703 | v_loss: 1.25755 v_acc: 0.71615 |  iteration: 15921 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1005 loss: 1.40428 acc: 0.70345 | v_loss: 1.32220 v_acc: 0.72461 |  iteration: 15922 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1006 loss: 1.35626 acc: 0.71061 | v_loss: 1.17853 v_acc: 0.71517 |  iteration: 15923 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1007 loss: 1.27344 acc: 0.71615 | v_loss: 1.34335 v_acc: 0.70703 |  iteration: 15924 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1008 loss: 1.48680 acc: 0.70052 | v_loss: 1.51496 v_acc: 0.69987 |  iteration: 15925 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1009 loss: 1.40972 acc: 0.71257 | v_loss: 1.33110 v_acc: 0.70931 |  iteration: 15926 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1010 loss: 1.44194 acc: 0.70215 | v_loss: 1.36931 v_acc: 0.70312 |  iteration: 15927 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1011 loss: 1.43605 acc: 0.69857 | v_loss: 1.24112 v_acc: 0.71680 |  iteration: 15928 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1012 loss: 1.43799 acc: 0.70540 | v_loss: 1.23747 v_acc: 0.70410 |  iteration: 15929 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1013 loss: 1.48192 acc: 0.70182 | v_loss: 1.24891 v_acc: 0.73503 |  iteration: 15930 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1014 loss: 1.39523 acc: 0.71680 | v_loss: 1.27020 v_acc: 0.72168 |  iteration: 15931 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1015 loss: 1.40366 acc: 0.70215 | v_loss: 1.33576 v_acc: 0.73145 |  iteration: 15932 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1016 loss: 1.35873 acc: 0.71354 | v_loss: 1.25859 v_acc: 0.72461 |  iteration: 15933 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1017 loss: 1.28146 acc: 0.71647 | v_loss: 1.29932 v_acc: 0.72005 |  iteration: 15934 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1018 loss: 1.44922 acc: 0.70801 | v_loss: 1.40818 v_acc: 0.71224 |  iteration: 15935 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1019 loss: 1.43471 acc: 0.70443 | v_loss: 1.38918 v_acc: 0.72070 |  iteration: 15936 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1020 loss: 1.36029 acc: 0.71680 | v_loss: 1.49317 v_acc: 0.69954 |  iteration: 15937 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1021 loss: 1.44870 acc: 0.69954 | v_loss: 1.41714 v_acc: 0.71615 |  iteration: 15938 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1022 loss: 1.37224 acc: 0.70768 | v_loss: 1.17164 v_acc: 0.74544 |  iteration: 15939 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1023 loss: 1.41879 acc: 0.70671 | v_loss: 1.24689 v_acc: 0.70931 |  iteration: 15940 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1024 loss: 1.40693 acc: 0.70508 | v_loss: 1.52965 v_acc: 0.70247 |  iteration: 15941 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1025 loss: 1.34193 acc: 0.70345 | v_loss: 1.19725 v_acc: 0.70671 |  iteration: 15942 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1026 loss: 1.43707 acc: 0.70638 | v_loss: 1.33568 v_acc: 0.71257 |  iteration: 15943 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1027 loss: 1.47226 acc: 0.70215 | v_loss: 1.37417 v_acc: 0.69368 |  iteration: 15944 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1028 loss: 1.45595 acc: 0.69922 | v_loss: 1.28686 v_acc: 0.71842 |  iteration: 15945 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1029 loss: 1.48992 acc: 0.69368 | v_loss: 1.36366 v_acc: 0.70215 |  iteration: 15946 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1030 loss: 1.39505 acc: 0.70052 | v_loss: 1.46697 v_acc: 0.72005 |  iteration: 15947 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1031 loss: 1.36237 acc: 0.72005 | v_loss: 1.31846 v_acc: 0.72689 |  iteration: 15948 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1032 loss: 1.31348 acc: 0.71257 | v_loss: 1.42981 v_acc: 0.70443 |  iteration: 15949 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1033 loss: 1.46015 acc: 0.69629 | v_loss: 1.37390 v_acc: 0.69954 |  iteration: 15950 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1034 loss: 1.37601 acc: 0.71191 | v_loss: 1.32105 v_acc: 0.70964 |  iteration: 15951 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1035 loss: 1.45472 acc: 0.71191 | v_loss: 1.54604 v_acc: 0.68945 |  iteration: 15952 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1036 loss: 1.53689 acc: 0.69043 | v_loss: 1.29539 v_acc: 0.72005 |  iteration: 15953 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1037 loss: 1.46586 acc: 0.69857 | v_loss: 1.59655 v_acc: 0.68490 |  iteration: 15954 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1038 loss: 1.41595 acc: 0.69857 | v_loss: 1.46175 v_acc: 0.69499 |  iteration: 15955 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1039 loss: 1.35610 acc: 0.70866 | v_loss: 1.51489 v_acc: 0.68978 |  iteration: 15956 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1040 loss: 1.51718 acc: 0.68652 | v_loss: 1.38129 v_acc: 0.69792 |  iteration: 15957 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1041 loss: 1.40065 acc: 0.70605 | v_loss: 1.31881 v_acc: 0.70378 |  iteration: 15958 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1042 loss: 1.42670 acc: 0.69499 | v_loss: 1.33055 v_acc: 0.70020 |  iteration: 15959 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1043 loss: 1.44621 acc: 0.70052 | v_loss: 1.32800 v_acc: 0.71484 |  iteration: 15960 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1044 loss: 1.54106 acc: 0.69401 | v_loss: 1.54556 v_acc: 0.68978 |  iteration: 15961 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1045 loss: 1.48658 acc: 0.69206 | v_loss: 1.37684 v_acc: 0.70443 |  iteration: 15962 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1046 loss: 1.58626 acc: 0.68229 | v_loss: 1.35932 v_acc: 0.71029 |  iteration: 15963 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1047 loss: 1.39833 acc: 0.70508 | v_loss: 1.38978 v_acc: 0.71517 |  iteration: 15964 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1048 loss: 1.46620 acc: 0.70703 | v_loss: 1.26703 v_acc: 0.70605 |  iteration: 15965 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1049 loss: 1.35435 acc: 0.71159 | v_loss: 1.42379 v_acc: 0.69824 |  iteration: 15966 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1050 loss: 1.44539 acc: 0.70052 | v_loss: 1.43308 v_acc: 0.71257 |  iteration: 15967 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1051 loss: 1.44714 acc: 0.69792 | v_loss: 1.28324 v_acc: 0.71875 |  iteration: 15968 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1052 loss: 1.48981 acc: 0.69336 | v_loss: 1.26395 v_acc: 0.72754 |  iteration: 15969 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1053 loss: 1.48571 acc: 0.70117 | v_loss: 1.37132 v_acc: 0.71940 |  iteration: 15970 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1054 loss: 1.44775 acc: 0.70280 | v_loss: 1.42159 v_acc: 0.70345 |  iteration: 15971 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1055 loss: 1.38124 acc: 0.70020 | v_loss: 1.42903 v_acc: 0.70410 |  iteration: 15972 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1056 loss: 1.47154 acc: 0.70378 | v_loss: 1.23091 v_acc: 0.71712 |  iteration: 15973 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1057 loss: 1.43967 acc: 0.69922 | v_loss: 1.39217 v_acc: 0.72786 |  iteration: 15974 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1058 loss: 1.43137 acc: 0.70508 | v_loss: 1.47766 v_acc: 0.69792 |  iteration: 15975 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1059 loss: 1.48830 acc: 0.70345 | v_loss: 1.40862 v_acc: 0.72070 |  iteration: 15976 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1060 loss: 1.39257 acc: 0.71061 | v_loss: 1.25308 v_acc: 0.71810 |  iteration: 15977 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1061 loss: 1.37018 acc: 0.71712 | v_loss: 1.19950 v_acc: 0.73600 |  iteration: 15978 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1062 loss: 1.37873 acc: 0.70117 | v_loss: 1.20961 v_acc: 0.72493 |  iteration: 15979 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1063 loss: 1.35843 acc: 0.70638 | v_loss: 1.27934 v_acc: 0.70638 |  iteration: 15980 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1064 loss: 1.52075 acc: 0.69141 | v_loss: 1.45017 v_acc: 0.69857 |  iteration: 15981 teacher: 0 stage: sketch lr: 0.000350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1065 loss: 1.43131 acc: 0.70247 | v_loss: 1.27507 v_acc: 0.71549 |  iteration: 15982 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1066 loss: 1.38938 acc: 0.70540 | v_loss: 1.48834 v_acc: 0.70215 |  iteration: 15983 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1067 loss: 1.30174 acc: 0.70475 | v_loss: 1.72078 v_acc: 0.68913 |  iteration: 15984 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 1068 loss: 1.44041 acc: 0.70215 | v_loss: 1.55504 v_acc: 0.69531 |  iteration: 15985 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1069 loss: 1.46924 acc: 0.70443 | v_loss: 1.29496 v_acc: 0.72396 |  iteration: 15986 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1070 loss: 1.47325 acc: 0.69792 | v_loss: 1.36516 v_acc: 0.70866 |  iteration: 15987 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1071 loss: 1.50425 acc: 0.69564 | v_loss: 1.22181 v_acc: 0.71842 |  iteration: 15988 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1072 loss: 1.34256 acc: 0.71289 | v_loss: 1.40931 v_acc: 0.70247 |  iteration: 15989 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 1073 loss: 1.46368 acc: 0.70150 | v_loss: 1.35589 v_acc: 0.70703 |  iteration: 15990 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1074 loss: 1.38805 acc: 0.70540 | v_loss: 1.34611 v_acc: 0.72949 |  iteration: 15991 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1075 loss: 1.44265 acc: 0.70020 | v_loss: 1.34824 v_acc: 0.71582 |  iteration: 15992 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1076 loss: 1.44535 acc: 0.70573 | v_loss: 1.37376 v_acc: 0.70052 |  iteration: 15993 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1077 loss: 1.42170 acc: 0.70182 | v_loss: 1.29169 v_acc: 0.72363 |  iteration: 15994 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1078 loss: 1.40457 acc: 0.70638 | v_loss: 1.30666 v_acc: 0.71973 |  iteration: 15995 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1079 loss: 1.44633 acc: 0.70378 | v_loss: 1.50494 v_acc: 0.68685 |  iteration: 15996 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1080 loss: 1.41327 acc: 0.70150 | v_loss: 1.34252 v_acc: 0.70931 |  iteration: 15997 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1081 loss: 1.39697 acc: 0.70671 | v_loss: 1.30017 v_acc: 0.71257 |  iteration: 15998 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1082 loss: 1.37657 acc: 0.71354 | v_loss: 1.27744 v_acc: 0.72624 |  iteration: 15999 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1083 loss: 1.42216 acc: 0.70703 | v_loss: 1.41072 v_acc: 0.70508 |  iteration: 16000 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1084 loss: 1.53345 acc: 0.70085 | v_loss: 1.31590 v_acc: 0.73177 |  iteration: 16001 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1085 loss: 1.42462 acc: 0.70117 | v_loss: 1.55507 v_acc: 0.71452 |  iteration: 16002 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1086 loss: 1.44935 acc: 0.69889 | v_loss: 1.27835 v_acc: 0.69792 |  iteration: 16003 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1087 loss: 1.37966 acc: 0.71029 | v_loss: 1.27555 v_acc: 0.70573 |  iteration: 16004 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1088 loss: 1.40601 acc: 0.69727 | v_loss: 1.43820 v_acc: 0.70345 |  iteration: 16005 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1089 loss: 1.43350 acc: 0.70117 | v_loss: 1.47632 v_acc: 0.70345 |  iteration: 16006 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1090 loss: 1.37099 acc: 0.70703 | v_loss: 1.53213 v_acc: 0.68913 |  iteration: 16007 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1091 loss: 1.44209 acc: 0.69466 | v_loss: 1.47720 v_acc: 0.70638 |  iteration: 16008 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1092 loss: 1.43090 acc: 0.70345 | v_loss: 1.42715 v_acc: 0.70410 |  iteration: 16009 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1093 loss: 1.39647 acc: 0.69596 | v_loss: 1.41573 v_acc: 0.70768 |  iteration: 16010 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1094 loss: 1.35435 acc: 0.70996 | v_loss: 1.39235 v_acc: 0.70703 |  iteration: 16011 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1095 loss: 1.49995 acc: 0.70605 | v_loss: 1.25346 v_acc: 0.71875 |  iteration: 16012 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1096 loss: 1.38398 acc: 0.70215 | v_loss: 1.32760 v_acc: 0.72331 |  iteration: 16013 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1097 loss: 1.37832 acc: 0.71322 | v_loss: 1.15903 v_acc: 0.71615 |  iteration: 16014 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1098 loss: 1.41765 acc: 0.70378 | v_loss: 1.34124 v_acc: 0.71126 |  iteration: 16015 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1099 loss: 1.53209 acc: 0.68978 | v_loss: 1.50656 v_acc: 0.70085 |  iteration: 16016 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1100 loss: 1.40345 acc: 0.69889 | v_loss: 1.32479 v_acc: 0.70833 |  iteration: 16017 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1101 loss: 1.46461 acc: 0.69661 | v_loss: 1.36338 v_acc: 0.69727 |  iteration: 16018 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1102 loss: 1.44048 acc: 0.70280 | v_loss: 1.24069 v_acc: 0.71126 |  iteration: 16019 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1103 loss: 1.34116 acc: 0.70996 | v_loss: 1.24190 v_acc: 0.70215 |  iteration: 16020 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1104 loss: 1.47240 acc: 0.69531 | v_loss: 1.25300 v_acc: 0.73568 |  iteration: 16021 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1105 loss: 1.46712 acc: 0.69076 | v_loss: 1.27770 v_acc: 0.71615 |  iteration: 16022 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1106 loss: 1.41450 acc: 0.68685 | v_loss: 1.36863 v_acc: 0.73470 |  iteration: 16023 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1107 loss: 1.54553 acc: 0.68913 | v_loss: 1.27110 v_acc: 0.71908 |  iteration: 16024 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1108 loss: 1.43206 acc: 0.70475 | v_loss: 1.31094 v_acc: 0.72005 |  iteration: 16025 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1109 loss: 1.46671 acc: 0.70410 | v_loss: 1.42357 v_acc: 0.71224 |  iteration: 16026 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1110 loss: 1.56629 acc: 0.68555 | v_loss: 1.40333 v_acc: 0.72070 |  iteration: 16027 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1111 loss: 1.39817 acc: 0.70638 | v_loss: 1.49209 v_acc: 0.69954 |  iteration: 16028 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1112 loss: 1.43069 acc: 0.69759 | v_loss: 1.41761 v_acc: 0.71615 |  iteration: 16029 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1113 loss: 1.46835 acc: 0.70280 | v_loss: 1.17726 v_acc: 0.74544 |  iteration: 16030 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1114 loss: 1.44342 acc: 0.70085 | v_loss: 1.24465 v_acc: 0.70931 |  iteration: 16031 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1115 loss: 1.34040 acc: 0.71322 | v_loss: 1.50893 v_acc: 0.70280 |  iteration: 16032 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1116 loss: 1.34426 acc: 0.71387 | v_loss: 1.20204 v_acc: 0.71647 |  iteration: 16033 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1117 loss: 1.29691 acc: 0.71094 | v_loss: 1.32489 v_acc: 0.72005 |  iteration: 16034 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1118 loss: 1.44098 acc: 0.70085 | v_loss: 1.37819 v_acc: 0.69141 |  iteration: 16035 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1119 loss: 1.52225 acc: 0.69401 | v_loss: 1.29378 v_acc: 0.70801 |  iteration: 16036 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1120 loss: 1.39799 acc: 0.70410 | v_loss: 1.35999 v_acc: 0.69206 |  iteration: 16037 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1121 loss: 1.49514 acc: 0.69792 | v_loss: 1.50423 v_acc: 0.70768 |  iteration: 16038 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1122 loss: 1.48937 acc: 0.69759 | v_loss: 1.32002 v_acc: 0.72201 |  iteration: 16039 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1123 loss: 1.37375 acc: 0.70573 | v_loss: 1.47233 v_acc: 0.70508 |  iteration: 16040 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1124 loss: 1.39612 acc: 0.70345 | v_loss: 1.34454 v_acc: 0.69954 |  iteration: 16041 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1125 loss: 1.50926 acc: 0.69466 | v_loss: 1.32716 v_acc: 0.70964 |  iteration: 16042 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1126 loss: 1.46993 acc: 0.70182 | v_loss: 1.53844 v_acc: 0.68913 |  iteration: 16043 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1127 loss: 1.38611 acc: 0.70638 | v_loss: 1.29683 v_acc: 0.72233 |  iteration: 16044 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1128 loss: 1.57614 acc: 0.69401 | v_loss: 1.60047 v_acc: 0.67839 |  iteration: 16045 teacher: 1 stage: sketch lr: 0.000349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1129 loss: 1.38790 acc: 0.71126 | v_loss: 1.46994 v_acc: 0.69629 |  iteration: 16046 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1130 loss: 1.45862 acc: 0.69857 | v_loss: 1.51689 v_acc: 0.69108 |  iteration: 16047 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1131 loss: 1.48110 acc: 0.70443 | v_loss: 1.38299 v_acc: 0.69629 |  iteration: 16048 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1132 loss: 1.39563 acc: 0.71126 | v_loss: 1.31834 v_acc: 0.70378 |  iteration: 16049 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1133 loss: 1.48996 acc: 0.69954 | v_loss: 1.33055 v_acc: 0.70215 |  iteration: 16050 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1134 loss: 1.43938 acc: 0.70182 | v_loss: 1.32677 v_acc: 0.71582 |  iteration: 16051 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1135 loss: 1.32378 acc: 0.71908 | v_loss: 1.54015 v_acc: 0.68978 |  iteration: 16052 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1136 loss: 1.47777 acc: 0.69889 | v_loss: 1.38205 v_acc: 0.70378 |  iteration: 16053 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1137 loss: 1.39698 acc: 0.71094 | v_loss: 1.35351 v_acc: 0.70801 |  iteration: 16054 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1138 loss: 1.43068 acc: 0.70215 | v_loss: 1.39531 v_acc: 0.71484 |  iteration: 16055 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1139 loss: 1.47581 acc: 0.69303 | v_loss: 1.27242 v_acc: 0.70410 |  iteration: 16056 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1140 loss: 1.47000 acc: 0.69434 | v_loss: 1.43751 v_acc: 0.69792 |  iteration: 16057 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1141 loss: 1.39818 acc: 0.69661 | v_loss: 1.43543 v_acc: 0.71289 |  iteration: 16058 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1142 loss: 1.50183 acc: 0.69661 | v_loss: 1.27942 v_acc: 0.71875 |  iteration: 16059 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1143 loss: 1.37065 acc: 0.70671 | v_loss: 1.26101 v_acc: 0.72591 |  iteration: 16060 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1144 loss: 1.51263 acc: 0.70052 | v_loss: 1.37621 v_acc: 0.72266 |  iteration: 16061 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1145 loss: 1.39756 acc: 0.71061 | v_loss: 1.41486 v_acc: 0.70410 |  iteration: 16062 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1146 loss: 1.41738 acc: 0.70280 | v_loss: 1.42866 v_acc: 0.70833 |  iteration: 16063 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1147 loss: 1.49339 acc: 0.69661 | v_loss: 1.21730 v_acc: 0.72591 |  iteration: 16064 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1148 loss: 1.52298 acc: 0.69434 | v_loss: 1.38327 v_acc: 0.72852 |  iteration: 16065 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1149 loss: 1.36018 acc: 0.70117 | v_loss: 1.46900 v_acc: 0.69792 |  iteration: 16066 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1150 loss: 1.48320 acc: 0.69596 | v_loss: 1.40806 v_acc: 0.72070 |  iteration: 16067 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1151 loss: 1.55313 acc: 0.68978 | v_loss: 1.25225 v_acc: 0.72201 |  iteration: 16068 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1152 loss: 1.49859 acc: 0.69564 | v_loss: 1.20853 v_acc: 0.74023 |  iteration: 16069 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1153 loss: 1.43789 acc: 0.70605 | v_loss: 1.21485 v_acc: 0.72461 |  iteration: 16070 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1154 loss: 1.41864 acc: 0.70866 | v_loss: 1.29175 v_acc: 0.70638 |  iteration: 16071 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1155 loss: 1.41156 acc: 0.70768 | v_loss: 1.45534 v_acc: 0.70052 |  iteration: 16072 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1156 loss: 1.41992 acc: 0.70768 | v_loss: 1.28307 v_acc: 0.71452 |  iteration: 16073 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1157 loss: 1.47634 acc: 0.69922 | v_loss: 1.44301 v_acc: 0.71647 |  iteration: 16074 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1158 loss: 1.37696 acc: 0.70671 | v_loss: 1.67251 v_acc: 0.69303 |  iteration: 16075 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1159 loss: 1.39622 acc: 0.71419 | v_loss: 1.52759 v_acc: 0.70117 |  iteration: 16076 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1160 loss: 1.46205 acc: 0.71061 | v_loss: 1.29247 v_acc: 0.72363 |  iteration: 16077 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1161 loss: 1.45125 acc: 0.70215 | v_loss: 1.37455 v_acc: 0.70410 |  iteration: 16078 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 1162 loss: 1.43292 acc: 0.70605 | v_loss: 1.22222 v_acc: 0.71973 |  iteration: 16079 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1163 loss: 1.51494 acc: 0.70280 | v_loss: 1.42281 v_acc: 0.70150 |  iteration: 16080 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1164 loss: 1.48404 acc: 0.70443 | v_loss: 1.35473 v_acc: 0.71029 |  iteration: 16081 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 1165 loss: 1.45147 acc: 0.70020 | v_loss: 1.34864 v_acc: 0.73079 |  iteration: 16082 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1166 loss: 1.48758 acc: 0.70410 | v_loss: 1.35924 v_acc: 0.71777 |  iteration: 16083 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1167 loss: 1.48318 acc: 0.69401 | v_loss: 1.37054 v_acc: 0.70410 |  iteration: 16084 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1168 loss: 1.51078 acc: 0.69368 | v_loss: 1.28611 v_acc: 0.72233 |  iteration: 16085 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1169 loss: 1.38515 acc: 0.70801 | v_loss: 1.29973 v_acc: 0.72135 |  iteration: 16086 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1170 loss: 1.34575 acc: 0.71094 | v_loss: 1.49262 v_acc: 0.69206 |  iteration: 16087 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1171 loss: 1.35369 acc: 0.70638 | v_loss: 1.32498 v_acc: 0.70931 |  iteration: 16088 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1172 loss: 1.47753 acc: 0.69954 | v_loss: 1.28960 v_acc: 0.71452 |  iteration: 16089 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1173 loss: 1.50240 acc: 0.69434 | v_loss: 1.28932 v_acc: 0.71940 |  iteration: 16090 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1174 loss: 1.42461 acc: 0.69954 | v_loss: 1.42276 v_acc: 0.70475 |  iteration: 16091 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1175 loss: 1.34058 acc: 0.71257 | v_loss: 1.30504 v_acc: 0.73210 |  iteration: 16092 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1176 loss: 1.39515 acc: 0.71387 | v_loss: 1.53462 v_acc: 0.71452 |  iteration: 16093 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1177 loss: 1.42773 acc: 0.69857 | v_loss: 1.28362 v_acc: 0.69759 |  iteration: 16094 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1178 loss: 1.41762 acc: 0.69661 | v_loss: 1.27317 v_acc: 0.70443 |  iteration: 16095 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1179 loss: 1.46437 acc: 0.71061 | v_loss: 1.43878 v_acc: 0.70312 |  iteration: 16096 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1180 loss: 1.44975 acc: 0.70150 | v_loss: 1.47081 v_acc: 0.70378 |  iteration: 16097 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1181 loss: 1.50319 acc: 0.69629 | v_loss: 1.51480 v_acc: 0.68978 |  iteration: 16098 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1182 loss: 1.40192 acc: 0.71257 | v_loss: 1.46952 v_acc: 0.70638 |  iteration: 16099 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1183 loss: 1.31118 acc: 0.71908 | v_loss: 1.42030 v_acc: 0.70410 |  iteration: 16100 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1184 loss: 1.30040 acc: 0.72038 | v_loss: 1.41063 v_acc: 0.70768 |  iteration: 16101 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1185 loss: 1.39463 acc: 0.71094 | v_loss: 1.40063 v_acc: 0.70475 |  iteration: 16102 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1186 loss: 1.42653 acc: 0.70736 | v_loss: 1.26334 v_acc: 0.71322 |  iteration: 16103 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1187 loss: 1.39365 acc: 0.70312 | v_loss: 1.32313 v_acc: 0.72461 |  iteration: 16104 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1188 loss: 1.31668 acc: 0.71745 | v_loss: 1.18540 v_acc: 0.71517 |  iteration: 16105 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1189 loss: 1.38019 acc: 0.70638 | v_loss: 1.34897 v_acc: 0.70703 |  iteration: 16106 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1190 loss: 1.42378 acc: 0.70573 | v_loss: 1.51363 v_acc: 0.69987 |  iteration: 16107 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1191 loss: 1.40693 acc: 0.69857 | v_loss: 1.33227 v_acc: 0.70833 |  iteration: 16108 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1192 loss: 1.40280 acc: 0.70247 | v_loss: 1.35520 v_acc: 0.69727 |  iteration: 16109 teacher: 0 stage: sketch lr: 0.000348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1193 loss: 1.45521 acc: 0.70312 | v_loss: 1.24026 v_acc: 0.71517 |  iteration: 16110 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1194 loss: 1.43266 acc: 0.69792 | v_loss: 1.22959 v_acc: 0.70638 |  iteration: 16111 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1195 loss: 1.59687 acc: 0.69303 | v_loss: 1.24429 v_acc: 0.73796 |  iteration: 16112 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1196 loss: 1.42992 acc: 0.71517 | v_loss: 1.25700 v_acc: 0.72266 |  iteration: 16113 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1197 loss: 1.44958 acc: 0.70540 | v_loss: 1.34307 v_acc: 0.73112 |  iteration: 16114 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1198 loss: 1.44108 acc: 0.70443 | v_loss: 1.25675 v_acc: 0.71940 |  iteration: 16115 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1199 loss: 1.46687 acc: 0.69629 | v_loss: 1.30450 v_acc: 0.72266 |  iteration: 16116 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1200 loss: 1.52555 acc: 0.68750 | v_loss: 1.41990 v_acc: 0.71289 |  iteration: 16117 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1201 loss: 1.35178 acc: 0.72038 | v_loss: 1.38634 v_acc: 0.72103 |  iteration: 16118 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1202 loss: 1.46774 acc: 0.70475 | v_loss: 1.48068 v_acc: 0.69954 |  iteration: 16119 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1203 loss: 1.41829 acc: 0.69792 | v_loss: 1.41830 v_acc: 0.71615 |  iteration: 16120 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1204 loss: 1.46839 acc: 0.70150 | v_loss: 1.17609 v_acc: 0.74544 |  iteration: 16121 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1205 loss: 1.40087 acc: 0.70931 | v_loss: 1.26025 v_acc: 0.70931 |  iteration: 16122 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1206 loss: 1.37911 acc: 0.70768 | v_loss: 1.51886 v_acc: 0.70247 |  iteration: 16123 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1207 loss: 1.41304 acc: 0.70247 | v_loss: 1.22936 v_acc: 0.70866 |  iteration: 16124 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1208 loss: 1.33660 acc: 0.70768 | v_loss: 1.32956 v_acc: 0.71159 |  iteration: 16125 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1209 loss: 1.39694 acc: 0.71159 | v_loss: 1.36841 v_acc: 0.69336 |  iteration: 16126 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1210 loss: 1.50959 acc: 0.69499 | v_loss: 1.29562 v_acc: 0.71191 |  iteration: 16127 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1211 loss: 1.39952 acc: 0.71257 | v_loss: 1.36603 v_acc: 0.69629 |  iteration: 16128 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1212 loss: 1.39860 acc: 0.70801 | v_loss: 1.47692 v_acc: 0.71224 |  iteration: 16129 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1213 loss: 1.40250 acc: 0.70117 | v_loss: 1.31900 v_acc: 0.72689 |  iteration: 16130 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1214 loss: 1.34236 acc: 0.70866 | v_loss: 1.45553 v_acc: 0.70443 |  iteration: 16131 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1215 loss: 1.38725 acc: 0.71322 | v_loss: 1.36403 v_acc: 0.69922 |  iteration: 16132 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1216 loss: 1.56465 acc: 0.69238 | v_loss: 1.32029 v_acc: 0.70898 |  iteration: 16133 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1217 loss: 1.36839 acc: 0.70736 | v_loss: 1.55287 v_acc: 0.68815 |  iteration: 16134 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1218 loss: 1.28628 acc: 0.71484 | v_loss: 1.31118 v_acc: 0.72168 |  iteration: 16135 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1219 loss: 1.45906 acc: 0.70378 | v_loss: 1.60199 v_acc: 0.67969 |  iteration: 16136 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1220 loss: 1.33828 acc: 0.70736 | v_loss: 1.47231 v_acc: 0.69661 |  iteration: 16137 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1221 loss: 1.38726 acc: 0.70573 | v_loss: 1.55446 v_acc: 0.69727 |  iteration: 16138 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1222 loss: 1.37929 acc: 0.70866 | v_loss: 1.38621 v_acc: 0.70247 |  iteration: 16139 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1223 loss: 1.41112 acc: 0.70605 | v_loss: 1.32177 v_acc: 0.70508 |  iteration: 16140 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1224 loss: 1.53149 acc: 0.69987 | v_loss: 1.32947 v_acc: 0.70410 |  iteration: 16141 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1225 loss: 1.42040 acc: 0.70182 | v_loss: 1.33363 v_acc: 0.71484 |  iteration: 16142 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1226 loss: 1.43701 acc: 0.70020 | v_loss: 1.54668 v_acc: 0.69010 |  iteration: 16143 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1227 loss: 1.34942 acc: 0.71289 | v_loss: 1.39176 v_acc: 0.70703 |  iteration: 16144 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1228 loss: 1.44769 acc: 0.69954 | v_loss: 1.33594 v_acc: 0.70833 |  iteration: 16145 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1229 loss: 1.38487 acc: 0.70671 | v_loss: 1.38894 v_acc: 0.71549 |  iteration: 16146 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1230 loss: 1.38111 acc: 0.71322 | v_loss: 1.27972 v_acc: 0.70345 |  iteration: 16147 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1231 loss: 1.45007 acc: 0.70150 | v_loss: 1.43537 v_acc: 0.69889 |  iteration: 16148 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1232 loss: 1.43656 acc: 0.70085 | v_loss: 1.42527 v_acc: 0.71354 |  iteration: 16149 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1233 loss: 1.41951 acc: 0.70247 | v_loss: 1.29162 v_acc: 0.72103 |  iteration: 16150 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1234 loss: 1.44973 acc: 0.70280 | v_loss: 1.25507 v_acc: 0.72754 |  iteration: 16151 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1235 loss: 1.42875 acc: 0.70768 | v_loss: 1.37972 v_acc: 0.71940 |  iteration: 16152 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1236 loss: 1.34149 acc: 0.71061 | v_loss: 1.43661 v_acc: 0.70345 |  iteration: 16153 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1237 loss: 1.47224 acc: 0.70215 | v_loss: 1.44380 v_acc: 0.70410 |  iteration: 16154 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1238 loss: 1.44572 acc: 0.70833 | v_loss: 1.22776 v_acc: 0.71712 |  iteration: 16155 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1239 loss: 1.33743 acc: 0.70150 | v_loss: 1.41385 v_acc: 0.72917 |  iteration: 16156 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 1240 loss: 1.42440 acc: 0.70150 | v_loss: 1.49349 v_acc: 0.69759 |  iteration: 16157 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1241 loss: 1.45358 acc: 0.70573 | v_loss: 1.42809 v_acc: 0.72201 |  iteration: 16158 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1242 loss: 1.45748 acc: 0.70540 | v_loss: 1.23910 v_acc: 0.72233 |  iteration: 16159 teacher: 0 stage: sketch lr: 0.000348\n",
      "epoch 12 loss: 1.43506 acc: 0.70274 | v_loss: 1.36600 v_acc: 0.71048 \n",
      "epoch: 13\n",
      "__________________________________________\n",
      "batch 0 loss: 1.54279 acc: 0.70085 | v_loss: 1.42710 v_acc: 0.70085 |  iteration: 16160 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 1 loss: 1.33659 acc: 0.71745 | v_loss: 1.41325 v_acc: 0.70931 |  iteration: 16161 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 2 loss: 1.42167 acc: 0.71061 | v_loss: 1.40294 v_acc: 0.70475 |  iteration: 16162 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 3 loss: 1.43609 acc: 0.71061 | v_loss: 1.26928 v_acc: 0.71354 |  iteration: 16163 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 4 loss: 1.49581 acc: 0.70410 | v_loss: 1.32020 v_acc: 0.72493 |  iteration: 16164 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 5 loss: 1.42186 acc: 0.70280 | v_loss: 1.22318 v_acc: 0.70671 |  iteration: 16165 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 6 loss: 1.44767 acc: 0.70345 | v_loss: 1.36236 v_acc: 0.70150 |  iteration: 16166 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 7 loss: 1.45576 acc: 0.70247 | v_loss: 1.48797 v_acc: 0.70312 |  iteration: 16167 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 8 loss: 1.42395 acc: 0.70866 | v_loss: 1.34584 v_acc: 0.70443 |  iteration: 16168 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 9 loss: 1.41183 acc: 0.70605 | v_loss: 1.35358 v_acc: 0.69596 |  iteration: 16169 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 10 loss: 1.48677 acc: 0.69043 | v_loss: 1.26287 v_acc: 0.70768 |  iteration: 16170 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 11 loss: 1.45729 acc: 0.70117 | v_loss: 1.26101 v_acc: 0.70215 |  iteration: 16171 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 12 loss: 1.56801 acc: 0.69531 | v_loss: 1.23634 v_acc: 0.73665 |  iteration: 16172 teacher: 1 stage: sketch lr: 0.000348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 13 loss: 1.37674 acc: 0.69954 | v_loss: 1.27366 v_acc: 0.72070 |  iteration: 16173 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 14 loss: 1.38998 acc: 0.70020 | v_loss: 1.34293 v_acc: 0.73145 |  iteration: 16174 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 15 loss: 1.50026 acc: 0.69076 | v_loss: 1.25958 v_acc: 0.72461 |  iteration: 16175 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 16 loss: 1.49429 acc: 0.69727 | v_loss: 1.30569 v_acc: 0.72103 |  iteration: 16176 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 17 loss: 1.33806 acc: 0.71289 | v_loss: 1.40843 v_acc: 0.71354 |  iteration: 16177 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 18 loss: 1.54174 acc: 0.68978 | v_loss: 1.39376 v_acc: 0.72428 |  iteration: 16178 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 19 loss: 1.36628 acc: 0.70378 | v_loss: 1.48823 v_acc: 0.70182 |  iteration: 16179 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 20 loss: 1.38011 acc: 0.71224 | v_loss: 1.41687 v_acc: 0.71777 |  iteration: 16180 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 21 loss: 1.35579 acc: 0.70768 | v_loss: 1.17432 v_acc: 0.74447 |  iteration: 16181 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 22 loss: 1.46839 acc: 0.69271 | v_loss: 1.25253 v_acc: 0.71322 |  iteration: 16182 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 23 loss: 1.46457 acc: 0.70443 | v_loss: 1.51397 v_acc: 0.69987 |  iteration: 16183 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 24 loss: 1.39167 acc: 0.70410 | v_loss: 1.20800 v_acc: 0.70671 |  iteration: 16184 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 25 loss: 1.55842 acc: 0.68913 | v_loss: 1.32896 v_acc: 0.71257 |  iteration: 16185 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 26 loss: 1.47272 acc: 0.70345 | v_loss: 1.35679 v_acc: 0.69499 |  iteration: 16186 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 27 loss: 1.53677 acc: 0.68880 | v_loss: 1.29697 v_acc: 0.70996 |  iteration: 16187 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 28 loss: 1.35225 acc: 0.70996 | v_loss: 1.36418 v_acc: 0.69434 |  iteration: 16188 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 29 loss: 1.37635 acc: 0.70866 | v_loss: 1.47701 v_acc: 0.71061 |  iteration: 16189 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 30 loss: 1.46230 acc: 0.69889 | v_loss: 1.31508 v_acc: 0.72656 |  iteration: 16190 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 31 loss: 1.58586 acc: 0.68783 | v_loss: 1.44943 v_acc: 0.70508 |  iteration: 16191 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 32 loss: 1.33167 acc: 0.70378 | v_loss: 1.36091 v_acc: 0.70312 |  iteration: 16192 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 33 loss: 1.34088 acc: 0.71257 | v_loss: 1.32456 v_acc: 0.70996 |  iteration: 16193 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 34 loss: 1.41669 acc: 0.69954 | v_loss: 1.54715 v_acc: 0.68815 |  iteration: 16194 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 35 loss: 1.39422 acc: 0.71094 | v_loss: 1.29975 v_acc: 0.72005 |  iteration: 16195 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 36 loss: 1.39148 acc: 0.70052 | v_loss: 1.59505 v_acc: 0.68424 |  iteration: 16196 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 37 loss: 1.40997 acc: 0.70768 | v_loss: 1.44934 v_acc: 0.69889 |  iteration: 16197 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 38 loss: 1.51742 acc: 0.70020 | v_loss: 1.53431 v_acc: 0.69238 |  iteration: 16198 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 39 loss: 1.38642 acc: 0.70703 | v_loss: 1.37642 v_acc: 0.70182 |  iteration: 16199 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 40 loss: 1.41597 acc: 0.70150 | v_loss: 1.31658 v_acc: 0.70638 |  iteration: 16200 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 41 loss: 1.49510 acc: 0.69434 | v_loss: 1.32658 v_acc: 0.70475 |  iteration: 16201 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 42 loss: 1.44155 acc: 0.70052 | v_loss: 1.31811 v_acc: 0.71484 |  iteration: 16202 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 43 loss: 1.46164 acc: 0.70182 | v_loss: 1.54827 v_acc: 0.68945 |  iteration: 16203 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 44 loss: 1.44438 acc: 0.70475 | v_loss: 1.38658 v_acc: 0.70703 |  iteration: 16204 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 45 loss: 1.53479 acc: 0.69076 | v_loss: 1.36573 v_acc: 0.70833 |  iteration: 16205 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 46 loss: 1.48773 acc: 0.70020 | v_loss: 1.38540 v_acc: 0.71582 |  iteration: 16206 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 47 loss: 1.35763 acc: 0.70215 | v_loss: 1.28148 v_acc: 0.70052 |  iteration: 16207 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 48 loss: 1.32743 acc: 0.71647 | v_loss: 1.42128 v_acc: 0.69889 |  iteration: 16208 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 49 loss: 1.40133 acc: 0.70443 | v_loss: 1.41876 v_acc: 0.71615 |  iteration: 16209 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 50 loss: 1.42444 acc: 0.70801 | v_loss: 1.29013 v_acc: 0.71712 |  iteration: 16210 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 51 loss: 1.48945 acc: 0.69987 | v_loss: 1.24999 v_acc: 0.72982 |  iteration: 16211 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 52 loss: 1.37844 acc: 0.70443 | v_loss: 1.36976 v_acc: 0.71810 |  iteration: 16212 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 53 loss: 1.48350 acc: 0.70052 | v_loss: 1.41717 v_acc: 0.70345 |  iteration: 16213 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 54 loss: 1.44159 acc: 0.70345 | v_loss: 1.42321 v_acc: 0.70410 |  iteration: 16214 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 55 loss: 1.42317 acc: 0.69727 | v_loss: 1.22192 v_acc: 0.71712 |  iteration: 16215 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 56 loss: 1.41281 acc: 0.70345 | v_loss: 1.38492 v_acc: 0.72786 |  iteration: 16216 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 57 loss: 1.38859 acc: 0.70573 | v_loss: 1.47381 v_acc: 0.69792 |  iteration: 16217 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 58 loss: 1.46430 acc: 0.70247 | v_loss: 1.41531 v_acc: 0.71973 |  iteration: 16218 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 59 loss: 1.49180 acc: 0.69303 | v_loss: 1.25494 v_acc: 0.71810 |  iteration: 16219 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 60 loss: 1.52008 acc: 0.69271 | v_loss: 1.21351 v_acc: 0.73600 |  iteration: 16220 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 61 loss: 1.36181 acc: 0.71322 | v_loss: 1.21401 v_acc: 0.72656 |  iteration: 16221 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 62 loss: 1.46314 acc: 0.69434 | v_loss: 1.29235 v_acc: 0.70768 |  iteration: 16222 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 63 loss: 1.52970 acc: 0.69271 | v_loss: 1.45724 v_acc: 0.69596 |  iteration: 16223 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 64 loss: 1.55761 acc: 0.69238 | v_loss: 1.27763 v_acc: 0.71224 |  iteration: 16224 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 65 loss: 1.42406 acc: 0.70215 | v_loss: 1.43654 v_acc: 0.71582 |  iteration: 16225 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 66 loss: 1.43142 acc: 0.70312 | v_loss: 1.65216 v_acc: 0.69401 |  iteration: 16226 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 67 loss: 1.33923 acc: 0.70475 | v_loss: 1.51319 v_acc: 0.69889 |  iteration: 16227 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 68 loss: 1.44424 acc: 0.70866 | v_loss: 1.29327 v_acc: 0.72363 |  iteration: 16228 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 69 loss: 1.38765 acc: 0.70703 | v_loss: 1.36430 v_acc: 0.70410 |  iteration: 16229 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 70 loss: 1.37590 acc: 0.70443 | v_loss: 1.21455 v_acc: 0.71973 |  iteration: 16230 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 71 loss: 1.43404 acc: 0.70247 | v_loss: 1.42772 v_acc: 0.70150 |  iteration: 16231 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 72 loss: 1.51590 acc: 0.69661 | v_loss: 1.36009 v_acc: 0.71029 |  iteration: 16232 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 73 loss: 1.39970 acc: 0.70638 | v_loss: 1.36101 v_acc: 0.73079 |  iteration: 16233 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 74 loss: 1.37522 acc: 0.71549 | v_loss: 1.35913 v_acc: 0.71777 |  iteration: 16234 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 75 loss: 1.42088 acc: 0.70182 | v_loss: 1.37199 v_acc: 0.70410 |  iteration: 16235 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 76 loss: 1.45507 acc: 0.69889 | v_loss: 1.28936 v_acc: 0.72233 |  iteration: 16236 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 77 loss: 1.48900 acc: 0.69661 | v_loss: 1.30705 v_acc: 0.72135 |  iteration: 16237 teacher: 0 stage: sketch lr: 0.000347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 78 loss: 1.39469 acc: 0.69922 | v_loss: 1.51217 v_acc: 0.69303 |  iteration: 16238 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 79 loss: 1.37668 acc: 0.70898 | v_loss: 1.33336 v_acc: 0.71159 |  iteration: 16239 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 80 loss: 1.41594 acc: 0.71191 | v_loss: 1.28992 v_acc: 0.71549 |  iteration: 16240 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 81 loss: 1.43696 acc: 0.70573 | v_loss: 1.28336 v_acc: 0.71973 |  iteration: 16241 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 82 loss: 1.36343 acc: 0.70410 | v_loss: 1.42585 v_acc: 0.70573 |  iteration: 16242 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 83 loss: 1.48533 acc: 0.70150 | v_loss: 1.30477 v_acc: 0.73079 |  iteration: 16243 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 84 loss: 1.42579 acc: 0.70443 | v_loss: 1.54788 v_acc: 0.71582 |  iteration: 16244 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 85 loss: 1.42085 acc: 0.70768 | v_loss: 1.27779 v_acc: 0.70150 |  iteration: 16245 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 86 loss: 1.44791 acc: 0.69987 | v_loss: 1.27426 v_acc: 0.70573 |  iteration: 16246 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 87 loss: 1.39175 acc: 0.70247 | v_loss: 1.43656 v_acc: 0.70378 |  iteration: 16247 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 88 loss: 1.43231 acc: 0.70247 | v_loss: 1.47106 v_acc: 0.70215 |  iteration: 16248 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 89 loss: 1.34400 acc: 0.70736 | v_loss: 1.51341 v_acc: 0.69661 |  iteration: 16249 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 90 loss: 1.39763 acc: 0.70898 | v_loss: 1.47546 v_acc: 0.70931 |  iteration: 16250 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 91 loss: 1.39472 acc: 0.71224 | v_loss: 1.42195 v_acc: 0.69954 |  iteration: 16251 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 92 loss: 1.44047 acc: 0.70540 | v_loss: 1.40937 v_acc: 0.70931 |  iteration: 16252 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 93 loss: 1.39935 acc: 0.70996 | v_loss: 1.39931 v_acc: 0.70703 |  iteration: 16253 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 94 loss: 1.36322 acc: 0.70117 | v_loss: 1.25387 v_acc: 0.71875 |  iteration: 16254 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 95 loss: 1.43034 acc: 0.69954 | v_loss: 1.32543 v_acc: 0.72461 |  iteration: 16255 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 96 loss: 1.45170 acc: 0.70736 | v_loss: 1.18603 v_acc: 0.71517 |  iteration: 16256 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 97 loss: 1.41595 acc: 0.70703 | v_loss: 1.34270 v_acc: 0.70703 |  iteration: 16257 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 98 loss: 1.59930 acc: 0.69206 | v_loss: 1.50512 v_acc: 0.69987 |  iteration: 16258 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 99 loss: 1.35095 acc: 0.70996 | v_loss: 1.32971 v_acc: 0.70833 |  iteration: 16259 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 100 loss: 1.37073 acc: 0.70964 | v_loss: 1.36458 v_acc: 0.69727 |  iteration: 16260 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 101 loss: 1.43405 acc: 0.70866 | v_loss: 1.24226 v_acc: 0.71126 |  iteration: 16261 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 102 loss: 1.42559 acc: 0.70833 | v_loss: 1.26245 v_acc: 0.70345 |  iteration: 16262 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 103 loss: 1.38804 acc: 0.70703 | v_loss: 1.23677 v_acc: 0.73503 |  iteration: 16263 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 104 loss: 1.49506 acc: 0.69336 | v_loss: 1.26838 v_acc: 0.72168 |  iteration: 16264 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 105 loss: 1.40207 acc: 0.71191 | v_loss: 1.33630 v_acc: 0.73145 |  iteration: 16265 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 106 loss: 1.43537 acc: 0.69466 | v_loss: 1.25863 v_acc: 0.72461 |  iteration: 16266 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 107 loss: 1.45747 acc: 0.70540 | v_loss: 1.30338 v_acc: 0.72005 |  iteration: 16267 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 108 loss: 1.43561 acc: 0.69596 | v_loss: 1.42062 v_acc: 0.71224 |  iteration: 16268 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 109 loss: 1.44030 acc: 0.69499 | v_loss: 1.39453 v_acc: 0.72070 |  iteration: 16269 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 110 loss: 1.51868 acc: 0.69303 | v_loss: 1.48590 v_acc: 0.69954 |  iteration: 16270 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 111 loss: 1.35975 acc: 0.70378 | v_loss: 1.41672 v_acc: 0.71973 |  iteration: 16271 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 112 loss: 1.41506 acc: 0.70182 | v_loss: 1.17524 v_acc: 0.74544 |  iteration: 16272 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 113 loss: 1.51190 acc: 0.69076 | v_loss: 1.24472 v_acc: 0.70605 |  iteration: 16273 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 114 loss: 1.40920 acc: 0.70085 | v_loss: 1.52280 v_acc: 0.70378 |  iteration: 16274 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 115 loss: 1.35614 acc: 0.71419 | v_loss: 1.20175 v_acc: 0.70605 |  iteration: 16275 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 116 loss: 1.46470 acc: 0.70312 | v_loss: 1.33361 v_acc: 0.71257 |  iteration: 16276 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 117 loss: 1.47110 acc: 0.70182 | v_loss: 1.36864 v_acc: 0.69368 |  iteration: 16277 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 118 loss: 1.48088 acc: 0.70280 | v_loss: 1.30029 v_acc: 0.71842 |  iteration: 16278 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 119 loss: 1.39903 acc: 0.70508 | v_loss: 1.36880 v_acc: 0.70020 |  iteration: 16279 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 120 loss: 1.49627 acc: 0.69661 | v_loss: 1.45094 v_acc: 0.70964 |  iteration: 16280 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 121 loss: 1.39244 acc: 0.70540 | v_loss: 1.31166 v_acc: 0.72819 |  iteration: 16281 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 122 loss: 1.48722 acc: 0.69434 | v_loss: 1.43378 v_acc: 0.70312 |  iteration: 16282 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 123 loss: 1.49495 acc: 0.69824 | v_loss: 1.35965 v_acc: 0.69954 |  iteration: 16283 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 124 loss: 1.48278 acc: 0.69792 | v_loss: 1.33382 v_acc: 0.70931 |  iteration: 16284 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 125 loss: 1.39747 acc: 0.70443 | v_loss: 1.51973 v_acc: 0.69564 |  iteration: 16285 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 126 loss: 1.44897 acc: 0.69727 | v_loss: 1.29535 v_acc: 0.72461 |  iteration: 16286 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 127 loss: 1.45410 acc: 0.70768 | v_loss: 1.57415 v_acc: 0.69043 |  iteration: 16287 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 128 loss: 1.39535 acc: 0.71387 | v_loss: 1.42032 v_acc: 0.70443 |  iteration: 16288 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 129 loss: 1.58569 acc: 0.69466 | v_loss: 1.52359 v_acc: 0.68913 |  iteration: 16289 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 130 loss: 1.39136 acc: 0.70964 | v_loss: 1.38015 v_acc: 0.70020 |  iteration: 16290 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 131 loss: 1.48241 acc: 0.69889 | v_loss: 1.34139 v_acc: 0.70312 |  iteration: 16291 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 132 loss: 1.43217 acc: 0.70638 | v_loss: 1.34225 v_acc: 0.70020 |  iteration: 16292 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 133 loss: 1.48790 acc: 0.69466 | v_loss: 1.34020 v_acc: 0.71484 |  iteration: 16293 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 134 loss: 1.37759 acc: 0.69987 | v_loss: 1.54572 v_acc: 0.69108 |  iteration: 16294 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 135 loss: 1.41351 acc: 0.71224 | v_loss: 1.38238 v_acc: 0.71126 |  iteration: 16295 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 136 loss: 1.51303 acc: 0.69238 | v_loss: 1.33691 v_acc: 0.71061 |  iteration: 16296 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 137 loss: 1.44042 acc: 0.70898 | v_loss: 1.38322 v_acc: 0.71452 |  iteration: 16297 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 138 loss: 1.51403 acc: 0.69206 | v_loss: 1.26446 v_acc: 0.70736 |  iteration: 16298 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 139 loss: 1.37559 acc: 0.70117 | v_loss: 1.42678 v_acc: 0.70020 |  iteration: 16299 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 140 loss: 1.42298 acc: 0.69499 | v_loss: 1.41854 v_acc: 0.71452 |  iteration: 16300 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 141 loss: 1.52271 acc: 0.69792 | v_loss: 1.28508 v_acc: 0.72038 |  iteration: 16301 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 142 loss: 1.42300 acc: 0.69792 | v_loss: 1.24777 v_acc: 0.72819 |  iteration: 16302 teacher: 1 stage: sketch lr: 0.000346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 143 loss: 1.44437 acc: 0.70052 | v_loss: 1.37063 v_acc: 0.71615 |  iteration: 16303 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 144 loss: 1.39929 acc: 0.70410 | v_loss: 1.40916 v_acc: 0.70540 |  iteration: 16304 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 145 loss: 1.45173 acc: 0.70085 | v_loss: 1.42253 v_acc: 0.70508 |  iteration: 16305 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 146 loss: 1.45145 acc: 0.70671 | v_loss: 1.22837 v_acc: 0.71452 |  iteration: 16306 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 147 loss: 1.44035 acc: 0.70280 | v_loss: 1.37655 v_acc: 0.72819 |  iteration: 16307 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 148 loss: 1.41116 acc: 0.70508 | v_loss: 1.46845 v_acc: 0.69759 |  iteration: 16308 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 149 loss: 1.38704 acc: 0.70801 | v_loss: 1.41608 v_acc: 0.72070 |  iteration: 16309 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 150 loss: 1.36250 acc: 0.70898 | v_loss: 1.25516 v_acc: 0.72201 |  iteration: 16310 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 151 loss: 1.42427 acc: 0.69661 | v_loss: 1.20209 v_acc: 0.74023 |  iteration: 16311 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 152 loss: 1.46102 acc: 0.70280 | v_loss: 1.20781 v_acc: 0.72559 |  iteration: 16312 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 153 loss: 1.42314 acc: 0.70410 | v_loss: 1.27592 v_acc: 0.70638 |  iteration: 16313 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 154 loss: 1.49915 acc: 0.69531 | v_loss: 1.43920 v_acc: 0.70052 |  iteration: 16314 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 155 loss: 1.41617 acc: 0.70312 | v_loss: 1.28458 v_acc: 0.71452 |  iteration: 16315 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 156 loss: 1.35576 acc: 0.70964 | v_loss: 1.45222 v_acc: 0.71647 |  iteration: 16316 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 157 loss: 1.49030 acc: 0.69596 | v_loss: 1.66982 v_acc: 0.69303 |  iteration: 16317 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 158 loss: 1.35159 acc: 0.70931 | v_loss: 1.51968 v_acc: 0.70117 |  iteration: 16318 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 159 loss: 1.57149 acc: 0.69336 | v_loss: 1.29011 v_acc: 0.72363 |  iteration: 16319 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 160 loss: 1.45617 acc: 0.70280 | v_loss: 1.36762 v_acc: 0.70410 |  iteration: 16320 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 161 loss: 1.42006 acc: 0.70671 | v_loss: 1.22026 v_acc: 0.72070 |  iteration: 16321 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 162 loss: 1.47205 acc: 0.69499 | v_loss: 1.41568 v_acc: 0.70020 |  iteration: 16322 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 163 loss: 1.43045 acc: 0.71094 | v_loss: 1.35660 v_acc: 0.71647 |  iteration: 16323 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 164 loss: 1.44438 acc: 0.69596 | v_loss: 1.35614 v_acc: 0.72884 |  iteration: 16324 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 165 loss: 1.42335 acc: 0.70247 | v_loss: 1.36416 v_acc: 0.72103 |  iteration: 16325 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 166 loss: 1.43408 acc: 0.71257 | v_loss: 1.37468 v_acc: 0.70964 |  iteration: 16326 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 167 loss: 1.34945 acc: 0.70117 | v_loss: 1.28051 v_acc: 0.72461 |  iteration: 16327 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 168 loss: 1.43204 acc: 0.70117 | v_loss: 1.28951 v_acc: 0.72135 |  iteration: 16328 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 169 loss: 1.36258 acc: 0.70866 | v_loss: 1.48367 v_acc: 0.69303 |  iteration: 16329 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 170 loss: 1.41667 acc: 0.71647 | v_loss: 1.33192 v_acc: 0.71159 |  iteration: 16330 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 171 loss: 1.39557 acc: 0.70801 | v_loss: 1.29617 v_acc: 0.71549 |  iteration: 16331 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 172 loss: 1.45158 acc: 0.70052 | v_loss: 1.28763 v_acc: 0.71973 |  iteration: 16332 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 173 loss: 1.41405 acc: 0.70117 | v_loss: 1.42656 v_acc: 0.70573 |  iteration: 16333 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 174 loss: 1.55897 acc: 0.70345 | v_loss: 1.31053 v_acc: 0.73177 |  iteration: 16334 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 175 loss: 1.42902 acc: 0.69694 | v_loss: 1.53914 v_acc: 0.71257 |  iteration: 16335 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 176 loss: 1.49260 acc: 0.70540 | v_loss: 1.28960 v_acc: 0.69759 |  iteration: 16336 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 177 loss: 1.52658 acc: 0.69141 | v_loss: 1.28675 v_acc: 0.70443 |  iteration: 16337 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 178 loss: 1.36039 acc: 0.70378 | v_loss: 1.43473 v_acc: 0.70312 |  iteration: 16338 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 179 loss: 1.45142 acc: 0.69824 | v_loss: 1.46844 v_acc: 0.70378 |  iteration: 16339 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 180 loss: 1.46413 acc: 0.70085 | v_loss: 1.51635 v_acc: 0.68978 |  iteration: 16340 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 181 loss: 1.40289 acc: 0.70964 | v_loss: 1.46780 v_acc: 0.70703 |  iteration: 16341 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 182 loss: 1.33560 acc: 0.71029 | v_loss: 1.41123 v_acc: 0.70736 |  iteration: 16342 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 183 loss: 1.41388 acc: 0.70671 | v_loss: 1.39899 v_acc: 0.70703 |  iteration: 16343 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 184 loss: 1.51479 acc: 0.69076 | v_loss: 1.41702 v_acc: 0.70443 |  iteration: 16344 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 185 loss: 1.54749 acc: 0.69303 | v_loss: 1.27578 v_acc: 0.71126 |  iteration: 16345 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 186 loss: 1.60703 acc: 0.68913 | v_loss: 1.31699 v_acc: 0.72168 |  iteration: 16346 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 187 loss: 1.50220 acc: 0.69401 | v_loss: 1.21950 v_acc: 0.70573 |  iteration: 16347 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 188 loss: 1.42007 acc: 0.70052 | v_loss: 1.34794 v_acc: 0.70247 |  iteration: 16348 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 189 loss: 1.49545 acc: 0.70117 | v_loss: 1.49410 v_acc: 0.69987 |  iteration: 16349 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 190 loss: 1.40576 acc: 0.70833 | v_loss: 1.34001 v_acc: 0.70833 |  iteration: 16350 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 191 loss: 1.49915 acc: 0.69922 | v_loss: 1.35073 v_acc: 0.69727 |  iteration: 16351 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 192 loss: 1.48395 acc: 0.69141 | v_loss: 1.24838 v_acc: 0.71387 |  iteration: 16352 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 193 loss: 1.38611 acc: 0.71582 | v_loss: 1.24958 v_acc: 0.70671 |  iteration: 16353 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 194 loss: 1.45012 acc: 0.70052 | v_loss: 1.24271 v_acc: 0.73568 |  iteration: 16354 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 195 loss: 1.38808 acc: 0.71029 | v_loss: 1.26873 v_acc: 0.72461 |  iteration: 16355 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 196 loss: 1.38294 acc: 0.71094 | v_loss: 1.33537 v_acc: 0.72689 |  iteration: 16356 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 197 loss: 1.47377 acc: 0.69564 | v_loss: 1.26684 v_acc: 0.72656 |  iteration: 16357 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 198 loss: 1.44270 acc: 0.70475 | v_loss: 1.31463 v_acc: 0.72005 |  iteration: 16358 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 199 loss: 1.43199 acc: 0.70540 | v_loss: 1.41900 v_acc: 0.71224 |  iteration: 16359 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 200 loss: 1.48942 acc: 0.69824 | v_loss: 1.39745 v_acc: 0.72070 |  iteration: 16360 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 201 loss: 1.39475 acc: 0.70605 | v_loss: 1.48653 v_acc: 0.69922 |  iteration: 16361 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 202 loss: 1.42088 acc: 0.69303 | v_loss: 1.41341 v_acc: 0.71973 |  iteration: 16362 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 203 loss: 1.50864 acc: 0.68848 | v_loss: 1.17035 v_acc: 0.74544 |  iteration: 16363 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 204 loss: 1.37720 acc: 0.70638 | v_loss: 1.24900 v_acc: 0.70573 |  iteration: 16364 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 205 loss: 1.45673 acc: 0.69173 | v_loss: 1.51311 v_acc: 0.70280 |  iteration: 16365 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 206 loss: 1.40243 acc: 0.70052 | v_loss: 1.19994 v_acc: 0.70866 |  iteration: 16366 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 207 loss: 1.43402 acc: 0.71061 | v_loss: 1.33366 v_acc: 0.71224 |  iteration: 16367 teacher: 0 stage: sketch lr: 0.000345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 208 loss: 1.42016 acc: 0.69954 | v_loss: 1.36469 v_acc: 0.69368 |  iteration: 16368 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 209 loss: 1.37310 acc: 0.70703 | v_loss: 1.28598 v_acc: 0.71842 |  iteration: 16369 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 210 loss: 1.54192 acc: 0.68945 | v_loss: 1.36056 v_acc: 0.70215 |  iteration: 16370 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 211 loss: 1.30462 acc: 0.70898 | v_loss: 1.48789 v_acc: 0.72005 |  iteration: 16371 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 212 loss: 1.44750 acc: 0.70540 | v_loss: 1.32717 v_acc: 0.72786 |  iteration: 16372 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 213 loss: 1.43136 acc: 0.70833 | v_loss: 1.46048 v_acc: 0.70540 |  iteration: 16373 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 214 loss: 1.38499 acc: 0.71257 | v_loss: 1.35942 v_acc: 0.69954 |  iteration: 16374 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 215 loss: 1.42420 acc: 0.70410 | v_loss: 1.32306 v_acc: 0.70898 |  iteration: 16375 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 216 loss: 1.42511 acc: 0.71289 | v_loss: 1.55078 v_acc: 0.68815 |  iteration: 16376 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 217 loss: 1.43341 acc: 0.70150 | v_loss: 1.29803 v_acc: 0.72135 |  iteration: 16377 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 218 loss: 1.49863 acc: 0.69564 | v_loss: 1.59211 v_acc: 0.68294 |  iteration: 16378 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 219 loss: 1.38926 acc: 0.71712 | v_loss: 1.45539 v_acc: 0.69889 |  iteration: 16379 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 220 loss: 1.31488 acc: 0.70964 | v_loss: 1.51833 v_acc: 0.68978 |  iteration: 16380 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 221 loss: 1.47245 acc: 0.70378 | v_loss: 1.38705 v_acc: 0.69694 |  iteration: 16381 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 222 loss: 1.47832 acc: 0.69857 | v_loss: 1.32334 v_acc: 0.70345 |  iteration: 16382 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 223 loss: 1.44208 acc: 0.70247 | v_loss: 1.33551 v_acc: 0.70052 |  iteration: 16383 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 224 loss: 1.42619 acc: 0.70378 | v_loss: 1.33207 v_acc: 0.71680 |  iteration: 16384 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 225 loss: 1.44864 acc: 0.70052 | v_loss: 1.53564 v_acc: 0.69173 |  iteration: 16385 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 226 loss: 1.49150 acc: 0.69564 | v_loss: 1.38264 v_acc: 0.70247 |  iteration: 16386 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 227 loss: 1.42127 acc: 0.70898 | v_loss: 1.34900 v_acc: 0.71126 |  iteration: 16387 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 228 loss: 1.46416 acc: 0.70020 | v_loss: 1.38563 v_acc: 0.71680 |  iteration: 16388 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 229 loss: 1.45964 acc: 0.70801 | v_loss: 1.27135 v_acc: 0.70573 |  iteration: 16389 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 230 loss: 1.40747 acc: 0.70020 | v_loss: 1.43091 v_acc: 0.69792 |  iteration: 16390 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 231 loss: 1.42836 acc: 0.70768 | v_loss: 1.42767 v_acc: 0.71289 |  iteration: 16391 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 232 loss: 1.43603 acc: 0.70020 | v_loss: 1.27973 v_acc: 0.71875 |  iteration: 16392 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 233 loss: 1.46600 acc: 0.70182 | v_loss: 1.26342 v_acc: 0.72754 |  iteration: 16393 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 234 loss: 1.40831 acc: 0.70117 | v_loss: 1.38263 v_acc: 0.72266 |  iteration: 16394 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 235 loss: 1.44575 acc: 0.69792 | v_loss: 1.41698 v_acc: 0.70410 |  iteration: 16395 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 236 loss: 1.40100 acc: 0.69531 | v_loss: 1.42440 v_acc: 0.70833 |  iteration: 16396 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 237 loss: 1.42453 acc: 0.70671 | v_loss: 1.21693 v_acc: 0.72591 |  iteration: 16397 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 238 loss: 1.56307 acc: 0.68880 | v_loss: 1.38092 v_acc: 0.72754 |  iteration: 16398 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 239 loss: 1.39022 acc: 0.70150 | v_loss: 1.46431 v_acc: 0.69759 |  iteration: 16399 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 240 loss: 1.50490 acc: 0.69857 | v_loss: 1.40200 v_acc: 0.72233 |  iteration: 16400 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 241 loss: 1.41507 acc: 0.69987 | v_loss: 1.25571 v_acc: 0.71810 |  iteration: 16401 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 242 loss: 1.39232 acc: 0.70866 | v_loss: 1.21055 v_acc: 0.73600 |  iteration: 16402 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 243 loss: 1.36186 acc: 0.70768 | v_loss: 1.21066 v_acc: 0.72656 |  iteration: 16403 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 244 loss: 1.46288 acc: 0.70117 | v_loss: 1.29596 v_acc: 0.70768 |  iteration: 16404 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 245 loss: 1.47644 acc: 0.70247 | v_loss: 1.45737 v_acc: 0.69596 |  iteration: 16405 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 246 loss: 1.41160 acc: 0.70443 | v_loss: 1.27983 v_acc: 0.71224 |  iteration: 16406 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 247 loss: 1.38947 acc: 0.70378 | v_loss: 1.45223 v_acc: 0.71647 |  iteration: 16407 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 248 loss: 1.46038 acc: 0.69531 | v_loss: 1.68408 v_acc: 0.69303 |  iteration: 16408 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 249 loss: 1.39979 acc: 0.71615 | v_loss: 1.54046 v_acc: 0.69954 |  iteration: 16409 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 250 loss: 1.44204 acc: 0.69889 | v_loss: 1.29356 v_acc: 0.72363 |  iteration: 16410 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 251 loss: 1.42062 acc: 0.70052 | v_loss: 1.37660 v_acc: 0.70801 |  iteration: 16411 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 252 loss: 1.47041 acc: 0.69466 | v_loss: 1.21884 v_acc: 0.72135 |  iteration: 16412 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 253 loss: 1.49820 acc: 0.69434 | v_loss: 1.41810 v_acc: 0.70215 |  iteration: 16413 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 254 loss: 1.32749 acc: 0.70671 | v_loss: 1.36150 v_acc: 0.71191 |  iteration: 16414 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 255 loss: 1.42374 acc: 0.69661 | v_loss: 1.35950 v_acc: 0.73014 |  iteration: 16415 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 256 loss: 1.30382 acc: 0.70475 | v_loss: 1.38139 v_acc: 0.71875 |  iteration: 16416 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 257 loss: 1.40496 acc: 0.70508 | v_loss: 1.38470 v_acc: 0.70964 |  iteration: 16417 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 258 loss: 1.35885 acc: 0.70378 | v_loss: 1.27042 v_acc: 0.72396 |  iteration: 16418 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 259 loss: 1.39228 acc: 0.70117 | v_loss: 1.29376 v_acc: 0.72038 |  iteration: 16419 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 260 loss: 1.46203 acc: 0.70378 | v_loss: 1.45172 v_acc: 0.69303 |  iteration: 16420 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 261 loss: 1.44319 acc: 0.70085 | v_loss: 1.34184 v_acc: 0.71126 |  iteration: 16421 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 262 loss: 1.47636 acc: 0.69759 | v_loss: 1.28249 v_acc: 0.71615 |  iteration: 16422 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 263 loss: 1.29700 acc: 0.70996 | v_loss: 1.27196 v_acc: 0.72201 |  iteration: 16423 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 264 loss: 1.42448 acc: 0.70247 | v_loss: 1.41287 v_acc: 0.70768 |  iteration: 16424 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 265 loss: 1.35864 acc: 0.71354 | v_loss: 1.31276 v_acc: 0.73210 |  iteration: 16425 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 266 loss: 1.55838 acc: 0.68750 | v_loss: 1.53391 v_acc: 0.71322 |  iteration: 16426 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 267 loss: 1.46046 acc: 0.69661 | v_loss: 1.28767 v_acc: 0.69531 |  iteration: 16427 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 268 loss: 1.38920 acc: 0.70964 | v_loss: 1.28183 v_acc: 0.70378 |  iteration: 16428 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 269 loss: 1.49316 acc: 0.69076 | v_loss: 1.42708 v_acc: 0.70312 |  iteration: 16429 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 270 loss: 1.47472 acc: 0.69727 | v_loss: 1.45767 v_acc: 0.70378 |  iteration: 16430 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 271 loss: 1.59831 acc: 0.68229 | v_loss: 1.50279 v_acc: 0.68978 |  iteration: 16431 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 272 loss: 1.41053 acc: 0.70540 | v_loss: 1.46758 v_acc: 0.70638 |  iteration: 16432 teacher: 1 stage: sketch lr: 0.000345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 273 loss: 1.42259 acc: 0.70931 | v_loss: 1.41540 v_acc: 0.70410 |  iteration: 16433 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 274 loss: 1.42097 acc: 0.70215 | v_loss: 1.39976 v_acc: 0.70768 |  iteration: 16434 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 275 loss: 1.46059 acc: 0.69564 | v_loss: 1.39467 v_acc: 0.70475 |  iteration: 16435 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 276 loss: 1.37072 acc: 0.71322 | v_loss: 1.26460 v_acc: 0.71354 |  iteration: 16436 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 277 loss: 1.45914 acc: 0.69336 | v_loss: 1.32012 v_acc: 0.72461 |  iteration: 16437 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 278 loss: 1.38802 acc: 0.70898 | v_loss: 1.18051 v_acc: 0.71517 |  iteration: 16438 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 279 loss: 1.40129 acc: 0.70247 | v_loss: 1.34653 v_acc: 0.70703 |  iteration: 16439 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 280 loss: 1.44255 acc: 0.69727 | v_loss: 1.50587 v_acc: 0.69987 |  iteration: 16440 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 281 loss: 1.43765 acc: 0.70573 | v_loss: 1.32570 v_acc: 0.70833 |  iteration: 16441 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 282 loss: 1.40077 acc: 0.70345 | v_loss: 1.36022 v_acc: 0.69727 |  iteration: 16442 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 283 loss: 1.44826 acc: 0.70345 | v_loss: 1.24028 v_acc: 0.71126 |  iteration: 16443 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 284 loss: 1.43005 acc: 0.70605 | v_loss: 1.25069 v_acc: 0.70345 |  iteration: 16444 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 285 loss: 1.52012 acc: 0.69987 | v_loss: 1.23398 v_acc: 0.73503 |  iteration: 16445 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 286 loss: 1.41424 acc: 0.70605 | v_loss: 1.26965 v_acc: 0.71908 |  iteration: 16446 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 287 loss: 1.40514 acc: 0.69922 | v_loss: 1.32608 v_acc: 0.73112 |  iteration: 16447 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 288 loss: 1.42614 acc: 0.70378 | v_loss: 1.25986 v_acc: 0.71940 |  iteration: 16448 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 289 loss: 1.47273 acc: 0.69727 | v_loss: 1.29294 v_acc: 0.72266 |  iteration: 16449 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 290 loss: 1.51549 acc: 0.69564 | v_loss: 1.39890 v_acc: 0.71289 |  iteration: 16450 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 291 loss: 1.46413 acc: 0.69857 | v_loss: 1.37335 v_acc: 0.72266 |  iteration: 16451 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 292 loss: 1.34394 acc: 0.71647 | v_loss: 1.49190 v_acc: 0.70117 |  iteration: 16452 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 293 loss: 1.48638 acc: 0.69271 | v_loss: 1.39639 v_acc: 0.72168 |  iteration: 16453 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 294 loss: 1.42358 acc: 0.70443 | v_loss: 1.17631 v_acc: 0.74349 |  iteration: 16454 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 295 loss: 1.46828 acc: 0.70085 | v_loss: 1.27482 v_acc: 0.70312 |  iteration: 16455 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 296 loss: 1.49730 acc: 0.70117 | v_loss: 1.49004 v_acc: 0.70866 |  iteration: 16456 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 297 loss: 1.51530 acc: 0.69922 | v_loss: 1.22583 v_acc: 0.72363 |  iteration: 16457 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 298 loss: 1.47721 acc: 0.68815 | v_loss: 1.32985 v_acc: 0.71387 |  iteration: 16458 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 299 loss: 1.50442 acc: 0.69401 | v_loss: 1.36737 v_acc: 0.68913 |  iteration: 16459 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 300 loss: 1.50583 acc: 0.69694 | v_loss: 1.30401 v_acc: 0.70866 |  iteration: 16460 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 301 loss: 1.37660 acc: 0.70020 | v_loss: 1.37733 v_acc: 0.69238 |  iteration: 16461 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 302 loss: 1.42006 acc: 0.69759 | v_loss: 1.46648 v_acc: 0.71517 |  iteration: 16462 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 303 loss: 1.34383 acc: 0.70671 | v_loss: 1.32156 v_acc: 0.72754 |  iteration: 16463 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 304 loss: 1.43427 acc: 0.70378 | v_loss: 1.43665 v_acc: 0.70540 |  iteration: 16464 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 305 loss: 1.47579 acc: 0.69466 | v_loss: 1.36665 v_acc: 0.69889 |  iteration: 16465 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 306 loss: 1.39836 acc: 0.70671 | v_loss: 1.31884 v_acc: 0.70898 |  iteration: 16466 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 307 loss: 1.46880 acc: 0.70020 | v_loss: 1.54350 v_acc: 0.68815 |  iteration: 16467 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 308 loss: 1.36362 acc: 0.70736 | v_loss: 1.29223 v_acc: 0.72005 |  iteration: 16468 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 309 loss: 1.47477 acc: 0.69661 | v_loss: 1.59310 v_acc: 0.68424 |  iteration: 16469 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 310 loss: 1.35195 acc: 0.72526 | v_loss: 1.42433 v_acc: 0.70182 |  iteration: 16470 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 311 loss: 1.53946 acc: 0.70280 | v_loss: 1.52379 v_acc: 0.68913 |  iteration: 16471 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 312 loss: 1.44314 acc: 0.70150 | v_loss: 1.37061 v_acc: 0.69889 |  iteration: 16472 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 313 loss: 1.43272 acc: 0.70345 | v_loss: 1.33226 v_acc: 0.70215 |  iteration: 16473 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 314 loss: 1.47310 acc: 0.70052 | v_loss: 1.33297 v_acc: 0.69694 |  iteration: 16474 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 315 loss: 1.49572 acc: 0.70150 | v_loss: 1.32624 v_acc: 0.71419 |  iteration: 16475 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 316 loss: 1.45115 acc: 0.70443 | v_loss: 1.53018 v_acc: 0.69076 |  iteration: 16476 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 317 loss: 1.41476 acc: 0.70671 | v_loss: 1.38150 v_acc: 0.70443 |  iteration: 16477 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 318 loss: 1.39564 acc: 0.69922 | v_loss: 1.34944 v_acc: 0.71029 |  iteration: 16478 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 319 loss: 1.36871 acc: 0.70898 | v_loss: 1.38510 v_acc: 0.71680 |  iteration: 16479 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 320 loss: 1.55723 acc: 0.69336 | v_loss: 1.27506 v_acc: 0.70573 |  iteration: 16480 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 321 loss: 1.38266 acc: 0.71452 | v_loss: 1.42570 v_acc: 0.69954 |  iteration: 16481 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 322 loss: 1.40373 acc: 0.71387 | v_loss: 1.42146 v_acc: 0.71289 |  iteration: 16482 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 323 loss: 1.47209 acc: 0.69238 | v_loss: 1.28554 v_acc: 0.71875 |  iteration: 16483 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 324 loss: 1.58956 acc: 0.68327 | v_loss: 1.24742 v_acc: 0.72754 |  iteration: 16484 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 325 loss: 1.39289 acc: 0.70345 | v_loss: 1.36662 v_acc: 0.71615 |  iteration: 16485 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 326 loss: 1.45101 acc: 0.70312 | v_loss: 1.41203 v_acc: 0.70280 |  iteration: 16486 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 327 loss: 1.37467 acc: 0.70833 | v_loss: 1.42321 v_acc: 0.70638 |  iteration: 16487 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 328 loss: 1.56935 acc: 0.69954 | v_loss: 1.22028 v_acc: 0.72298 |  iteration: 16488 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 329 loss: 1.43889 acc: 0.70215 | v_loss: 1.38892 v_acc: 0.72917 |  iteration: 16489 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 330 loss: 1.33462 acc: 0.71126 | v_loss: 1.47668 v_acc: 0.69954 |  iteration: 16490 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 331 loss: 1.44041 acc: 0.69564 | v_loss: 1.41471 v_acc: 0.72135 |  iteration: 16491 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 332 loss: 1.44178 acc: 0.68717 | v_loss: 1.24340 v_acc: 0.72168 |  iteration: 16492 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 333 loss: 1.48937 acc: 0.69857 | v_loss: 1.19862 v_acc: 0.74284 |  iteration: 16493 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 334 loss: 1.54301 acc: 0.69173 | v_loss: 1.21303 v_acc: 0.72526 |  iteration: 16494 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 335 loss: 1.41991 acc: 0.69759 | v_loss: 1.28394 v_acc: 0.70638 |  iteration: 16495 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 336 loss: 1.34517 acc: 0.71061 | v_loss: 1.45229 v_acc: 0.70052 |  iteration: 16496 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 337 loss: 1.44173 acc: 0.70573 | v_loss: 1.27000 v_acc: 0.71452 |  iteration: 16497 teacher: 0 stage: sketch lr: 0.000344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 338 loss: 1.46522 acc: 0.69531 | v_loss: 1.43803 v_acc: 0.71680 |  iteration: 16498 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 339 loss: 1.46225 acc: 0.70247 | v_loss: 1.67164 v_acc: 0.69336 |  iteration: 16499 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 340 loss: 1.40984 acc: 0.70931 | v_loss: 1.52477 v_acc: 0.69759 |  iteration: 16500 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 341 loss: 1.43630 acc: 0.71191 | v_loss: 1.29006 v_acc: 0.72396 |  iteration: 16501 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 342 loss: 1.43671 acc: 0.70605 | v_loss: 1.36690 v_acc: 0.70996 |  iteration: 16502 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 343 loss: 1.43216 acc: 0.70410 | v_loss: 1.21779 v_acc: 0.72168 |  iteration: 16503 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 344 loss: 1.38674 acc: 0.70638 | v_loss: 1.41885 v_acc: 0.70378 |  iteration: 16504 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 345 loss: 1.32886 acc: 0.71224 | v_loss: 1.35364 v_acc: 0.71810 |  iteration: 16505 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 346 loss: 1.45848 acc: 0.70150 | v_loss: 1.36080 v_acc: 0.73014 |  iteration: 16506 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 347 loss: 1.47891 acc: 0.69661 | v_loss: 1.37915 v_acc: 0.71973 |  iteration: 16507 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 348 loss: 1.40792 acc: 0.70052 | v_loss: 1.38156 v_acc: 0.70964 |  iteration: 16508 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 349 loss: 1.46262 acc: 0.70671 | v_loss: 1.27590 v_acc: 0.72493 |  iteration: 16509 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 350 loss: 1.50258 acc: 0.69792 | v_loss: 1.29430 v_acc: 0.72103 |  iteration: 16510 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 351 loss: 1.39050 acc: 0.71224 | v_loss: 1.48650 v_acc: 0.69303 |  iteration: 16511 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 352 loss: 1.39989 acc: 0.70931 | v_loss: 1.33528 v_acc: 0.71159 |  iteration: 16512 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 353 loss: 1.40165 acc: 0.70247 | v_loss: 1.29140 v_acc: 0.71452 |  iteration: 16513 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 354 loss: 1.38015 acc: 0.70801 | v_loss: 1.29215 v_acc: 0.71940 |  iteration: 16514 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 355 loss: 1.32765 acc: 0.71159 | v_loss: 1.43372 v_acc: 0.70475 |  iteration: 16515 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 356 loss: 1.38981 acc: 0.70312 | v_loss: 1.30834 v_acc: 0.73112 |  iteration: 16516 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 357 loss: 1.43720 acc: 0.70443 | v_loss: 1.54334 v_acc: 0.71452 |  iteration: 16517 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 358 loss: 1.41031 acc: 0.70150 | v_loss: 1.28034 v_acc: 0.69759 |  iteration: 16518 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 359 loss: 1.50054 acc: 0.70247 | v_loss: 1.27917 v_acc: 0.70508 |  iteration: 16519 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 360 loss: 1.39747 acc: 0.70312 | v_loss: 1.43433 v_acc: 0.70410 |  iteration: 16520 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 361 loss: 1.50252 acc: 0.69466 | v_loss: 1.46918 v_acc: 0.70150 |  iteration: 16521 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 362 loss: 1.43781 acc: 0.70736 | v_loss: 1.50523 v_acc: 0.69368 |  iteration: 16522 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 363 loss: 1.39669 acc: 0.70312 | v_loss: 1.47163 v_acc: 0.70833 |  iteration: 16523 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 364 loss: 1.49454 acc: 0.69954 | v_loss: 1.41661 v_acc: 0.70085 |  iteration: 16524 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 365 loss: 1.42617 acc: 0.70736 | v_loss: 1.40229 v_acc: 0.70768 |  iteration: 16525 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 366 loss: 1.53548 acc: 0.69629 | v_loss: 1.40900 v_acc: 0.70443 |  iteration: 16526 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 367 loss: 1.40079 acc: 0.69727 | v_loss: 1.26235 v_acc: 0.71159 |  iteration: 16527 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 368 loss: 1.40795 acc: 0.70866 | v_loss: 1.32272 v_acc: 0.72396 |  iteration: 16528 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 369 loss: 1.46636 acc: 0.70020 | v_loss: 1.19454 v_acc: 0.71517 |  iteration: 16529 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 370 loss: 1.44487 acc: 0.69661 | v_loss: 1.34181 v_acc: 0.70703 |  iteration: 16530 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 371 loss: 1.45962 acc: 0.70150 | v_loss: 1.49974 v_acc: 0.69987 |  iteration: 16531 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 372 loss: 1.34108 acc: 0.71029 | v_loss: 1.33480 v_acc: 0.70833 |  iteration: 16532 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 373 loss: 1.53282 acc: 0.69661 | v_loss: 1.35316 v_acc: 0.69727 |  iteration: 16533 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 374 loss: 1.38207 acc: 0.70020 | v_loss: 1.24659 v_acc: 0.71126 |  iteration: 16534 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 375 loss: 1.46866 acc: 0.70280 | v_loss: 1.25022 v_acc: 0.70345 |  iteration: 16535 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 376 loss: 1.51630 acc: 0.69564 | v_loss: 1.23551 v_acc: 0.73503 |  iteration: 16536 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 377 loss: 1.48344 acc: 0.69922 | v_loss: 1.27232 v_acc: 0.72168 |  iteration: 16537 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 378 loss: 1.44666 acc: 0.70312 | v_loss: 1.34597 v_acc: 0.73145 |  iteration: 16538 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 379 loss: 1.41623 acc: 0.70605 | v_loss: 1.25911 v_acc: 0.72461 |  iteration: 16539 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 380 loss: 1.46652 acc: 0.69434 | v_loss: 1.30204 v_acc: 0.72005 |  iteration: 16540 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 381 loss: 1.41857 acc: 0.70443 | v_loss: 1.41498 v_acc: 0.71224 |  iteration: 16541 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 382 loss: 1.41886 acc: 0.70247 | v_loss: 1.39447 v_acc: 0.72070 |  iteration: 16542 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 383 loss: 1.50364 acc: 0.70312 | v_loss: 1.48552 v_acc: 0.69954 |  iteration: 16543 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 384 loss: 1.45019 acc: 0.70345 | v_loss: 1.41462 v_acc: 0.71615 |  iteration: 16544 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 385 loss: 1.47974 acc: 0.69694 | v_loss: 1.17521 v_acc: 0.74544 |  iteration: 16545 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 386 loss: 1.41996 acc: 0.70703 | v_loss: 1.25200 v_acc: 0.70736 |  iteration: 16546 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 387 loss: 1.41306 acc: 0.70117 | v_loss: 1.50757 v_acc: 0.70443 |  iteration: 16547 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 388 loss: 1.46860 acc: 0.70280 | v_loss: 1.20417 v_acc: 0.71387 |  iteration: 16548 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 389 loss: 1.42617 acc: 0.70508 | v_loss: 1.33721 v_acc: 0.71126 |  iteration: 16549 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 390 loss: 1.30681 acc: 0.71289 | v_loss: 1.37565 v_acc: 0.69336 |  iteration: 16550 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 391 loss: 1.37792 acc: 0.70443 | v_loss: 1.28441 v_acc: 0.71191 |  iteration: 16551 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 392 loss: 1.42017 acc: 0.70540 | v_loss: 1.36151 v_acc: 0.70085 |  iteration: 16552 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 393 loss: 1.43154 acc: 0.70768 | v_loss: 1.49095 v_acc: 0.72005 |  iteration: 16553 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 394 loss: 1.53089 acc: 0.68848 | v_loss: 1.33314 v_acc: 0.72786 |  iteration: 16554 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 395 loss: 1.42525 acc: 0.70996 | v_loss: 1.46609 v_acc: 0.70540 |  iteration: 16555 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 396 loss: 1.49074 acc: 0.69564 | v_loss: 1.35062 v_acc: 0.69857 |  iteration: 16556 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 397 loss: 1.46111 acc: 0.70573 | v_loss: 1.32362 v_acc: 0.70833 |  iteration: 16557 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 398 loss: 1.31923 acc: 0.70898 | v_loss: 1.56236 v_acc: 0.68522 |  iteration: 16558 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 399 loss: 1.42157 acc: 0.70508 | v_loss: 1.30510 v_acc: 0.72168 |  iteration: 16559 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 400 loss: 1.46973 acc: 0.69889 | v_loss: 1.59520 v_acc: 0.67969 |  iteration: 16560 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 401 loss: 1.40839 acc: 0.70280 | v_loss: 1.45860 v_acc: 0.69661 |  iteration: 16561 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 402 loss: 1.31055 acc: 0.71061 | v_loss: 1.52812 v_acc: 0.69173 |  iteration: 16562 teacher: 1 stage: sketch lr: 0.000343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 403 loss: 1.35692 acc: 0.70540 | v_loss: 1.37464 v_acc: 0.70150 |  iteration: 16563 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 404 loss: 1.51424 acc: 0.69694 | v_loss: 1.32668 v_acc: 0.70312 |  iteration: 16564 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 405 loss: 1.37245 acc: 0.70573 | v_loss: 1.33028 v_acc: 0.70020 |  iteration: 16565 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 406 loss: 1.37685 acc: 0.70964 | v_loss: 1.33028 v_acc: 0.71484 |  iteration: 16566 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 407 loss: 1.40982 acc: 0.70768 | v_loss: 1.54220 v_acc: 0.68978 |  iteration: 16567 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 408 loss: 1.48481 acc: 0.70312 | v_loss: 1.38083 v_acc: 0.70443 |  iteration: 16568 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 409 loss: 1.55807 acc: 0.68978 | v_loss: 1.33855 v_acc: 0.71029 |  iteration: 16569 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 410 loss: 1.55105 acc: 0.69759 | v_loss: 1.38793 v_acc: 0.71680 |  iteration: 16570 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 411 loss: 1.31984 acc: 0.71354 | v_loss: 1.27387 v_acc: 0.70573 |  iteration: 16571 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 412 loss: 1.55947 acc: 0.69629 | v_loss: 1.43195 v_acc: 0.69792 |  iteration: 16572 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 413 loss: 1.44191 acc: 0.70931 | v_loss: 1.42405 v_acc: 0.71452 |  iteration: 16573 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 414 loss: 1.46235 acc: 0.70605 | v_loss: 1.29383 v_acc: 0.71680 |  iteration: 16574 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 415 loss: 1.45451 acc: 0.69889 | v_loss: 1.26058 v_acc: 0.72428 |  iteration: 16575 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 416 loss: 1.42243 acc: 0.70768 | v_loss: 1.36482 v_acc: 0.71582 |  iteration: 16576 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 417 loss: 1.42429 acc: 0.70768 | v_loss: 1.42828 v_acc: 0.70182 |  iteration: 16577 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 418 loss: 1.44025 acc: 0.70312 | v_loss: 1.43240 v_acc: 0.70410 |  iteration: 16578 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 419 loss: 1.45923 acc: 0.69889 | v_loss: 1.23060 v_acc: 0.71712 |  iteration: 16579 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 420 loss: 1.42670 acc: 0.70215 | v_loss: 1.40104 v_acc: 0.72786 |  iteration: 16580 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 421 loss: 1.36713 acc: 0.70052 | v_loss: 1.47510 v_acc: 0.69792 |  iteration: 16581 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 422 loss: 1.39286 acc: 0.70605 | v_loss: 1.41512 v_acc: 0.72135 |  iteration: 16582 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 423 loss: 1.44264 acc: 0.70345 | v_loss: 1.24283 v_acc: 0.72233 |  iteration: 16583 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 424 loss: 1.32247 acc: 0.71777 | v_loss: 1.19412 v_acc: 0.74447 |  iteration: 16584 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 425 loss: 1.36474 acc: 0.70020 | v_loss: 1.21823 v_acc: 0.72493 |  iteration: 16585 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 426 loss: 1.46317 acc: 0.69336 | v_loss: 1.26854 v_acc: 0.71126 |  iteration: 16586 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 427 loss: 1.54180 acc: 0.69661 | v_loss: 1.45897 v_acc: 0.70671 |  iteration: 16587 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 428 loss: 1.40057 acc: 0.70378 | v_loss: 1.27207 v_acc: 0.71549 |  iteration: 16588 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 429 loss: 1.53942 acc: 0.69857 | v_loss: 1.47462 v_acc: 0.70410 |  iteration: 16589 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 430 loss: 1.42727 acc: 0.70443 | v_loss: 1.66896 v_acc: 0.69434 |  iteration: 16590 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 431 loss: 1.37564 acc: 0.70540 | v_loss: 1.52388 v_acc: 0.69922 |  iteration: 16591 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 432 loss: 1.64203 acc: 0.68294 | v_loss: 1.29253 v_acc: 0.72135 |  iteration: 16592 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 433 loss: 1.40181 acc: 0.70215 | v_loss: 1.36768 v_acc: 0.70475 |  iteration: 16593 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 434 loss: 1.51217 acc: 0.69043 | v_loss: 1.22000 v_acc: 0.72103 |  iteration: 16594 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 435 loss: 1.40968 acc: 0.69271 | v_loss: 1.41449 v_acc: 0.70020 |  iteration: 16595 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 436 loss: 1.53107 acc: 0.69434 | v_loss: 1.35369 v_acc: 0.71582 |  iteration: 16596 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 437 loss: 1.48143 acc: 0.70052 | v_loss: 1.35119 v_acc: 0.73047 |  iteration: 16597 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 438 loss: 1.48516 acc: 0.69987 | v_loss: 1.36270 v_acc: 0.71973 |  iteration: 16598 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 439 loss: 1.40377 acc: 0.71289 | v_loss: 1.37168 v_acc: 0.70964 |  iteration: 16599 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 440 loss: 1.44396 acc: 0.70150 | v_loss: 1.28644 v_acc: 0.72493 |  iteration: 16600 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 441 loss: 1.43008 acc: 0.70312 | v_loss: 1.29291 v_acc: 0.72038 |  iteration: 16601 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 442 loss: 1.42576 acc: 0.70703 | v_loss: 1.49376 v_acc: 0.69368 |  iteration: 16602 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 443 loss: 1.42881 acc: 0.70215 | v_loss: 1.34234 v_acc: 0.71159 |  iteration: 16603 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 444 loss: 1.44391 acc: 0.70833 | v_loss: 1.29238 v_acc: 0.71354 |  iteration: 16604 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 445 loss: 1.44577 acc: 0.70052 | v_loss: 1.28746 v_acc: 0.71712 |  iteration: 16605 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 446 loss: 1.35258 acc: 0.71712 | v_loss: 1.41766 v_acc: 0.70540 |  iteration: 16606 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 447 loss: 1.59909 acc: 0.68945 | v_loss: 1.31282 v_acc: 0.72982 |  iteration: 16607 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 448 loss: 1.46194 acc: 0.70833 | v_loss: 1.54354 v_acc: 0.70964 |  iteration: 16608 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 449 loss: 1.49464 acc: 0.70117 | v_loss: 1.29355 v_acc: 0.69792 |  iteration: 16609 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 450 loss: 1.28596 acc: 0.71777 | v_loss: 1.28867 v_acc: 0.70117 |  iteration: 16610 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 451 loss: 1.42689 acc: 0.70605 | v_loss: 1.45982 v_acc: 0.70410 |  iteration: 16611 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 452 loss: 1.46494 acc: 0.71452 | v_loss: 1.48951 v_acc: 0.70378 |  iteration: 16612 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 453 loss: 1.51940 acc: 0.69629 | v_loss: 1.53653 v_acc: 0.68978 |  iteration: 16613 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 454 loss: 1.45631 acc: 0.70280 | v_loss: 1.46346 v_acc: 0.70638 |  iteration: 16614 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 455 loss: 1.49486 acc: 0.70215 | v_loss: 1.42190 v_acc: 0.70215 |  iteration: 16615 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 456 loss: 1.40423 acc: 0.70312 | v_loss: 1.40412 v_acc: 0.70931 |  iteration: 16616 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 457 loss: 1.39411 acc: 0.70508 | v_loss: 1.40709 v_acc: 0.70703 |  iteration: 16617 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 458 loss: 1.43724 acc: 0.70182 | v_loss: 1.26603 v_acc: 0.71875 |  iteration: 16618 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 459 loss: 1.44492 acc: 0.70443 | v_loss: 1.31914 v_acc: 0.72428 |  iteration: 16619 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 460 loss: 1.46034 acc: 0.70247 | v_loss: 1.18518 v_acc: 0.70768 |  iteration: 16620 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 461 loss: 1.40848 acc: 0.70801 | v_loss: 1.33763 v_acc: 0.70671 |  iteration: 16621 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 462 loss: 1.40967 acc: 0.70573 | v_loss: 1.50342 v_acc: 0.70052 |  iteration: 16622 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 463 loss: 1.41712 acc: 0.70052 | v_loss: 1.33977 v_acc: 0.70638 |  iteration: 16623 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 464 loss: 1.37797 acc: 0.70605 | v_loss: 1.35189 v_acc: 0.69661 |  iteration: 16624 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 465 loss: 1.37948 acc: 0.70996 | v_loss: 1.25405 v_acc: 0.70638 |  iteration: 16625 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 466 loss: 1.52884 acc: 0.69141 | v_loss: 1.24220 v_acc: 0.70508 |  iteration: 16626 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 467 loss: 1.40874 acc: 0.70605 | v_loss: 1.24425 v_acc: 0.73926 |  iteration: 16627 teacher: 1 stage: sketch lr: 0.000343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 468 loss: 1.41649 acc: 0.69792 | v_loss: 1.26995 v_acc: 0.71908 |  iteration: 16628 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 469 loss: 1.36906 acc: 0.72038 | v_loss: 1.34790 v_acc: 0.73145 |  iteration: 16629 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 470 loss: 1.49270 acc: 0.69987 | v_loss: 1.26052 v_acc: 0.72461 |  iteration: 16630 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 471 loss: 1.42632 acc: 0.70443 | v_loss: 1.30982 v_acc: 0.72005 |  iteration: 16631 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 472 loss: 1.33880 acc: 0.70345 | v_loss: 1.42313 v_acc: 0.71224 |  iteration: 16632 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 473 loss: 1.43266 acc: 0.70280 | v_loss: 1.38977 v_acc: 0.72070 |  iteration: 16633 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 474 loss: 1.58570 acc: 0.69238 | v_loss: 1.48644 v_acc: 0.69954 |  iteration: 16634 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 475 loss: 1.39315 acc: 0.70280 | v_loss: 1.40147 v_acc: 0.71615 |  iteration: 16635 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 476 loss: 1.47720 acc: 0.70410 | v_loss: 1.17857 v_acc: 0.74577 |  iteration: 16636 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 477 loss: 1.40054 acc: 0.69954 | v_loss: 1.26277 v_acc: 0.70931 |  iteration: 16637 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 478 loss: 1.41471 acc: 0.70215 | v_loss: 1.49806 v_acc: 0.70247 |  iteration: 16638 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 479 loss: 1.51679 acc: 0.69629 | v_loss: 1.22725 v_acc: 0.70866 |  iteration: 16639 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 480 loss: 1.55380 acc: 0.68978 | v_loss: 1.32570 v_acc: 0.71029 |  iteration: 16640 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 481 loss: 1.44184 acc: 0.70247 | v_loss: 1.36204 v_acc: 0.69303 |  iteration: 16641 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 482 loss: 1.46424 acc: 0.69629 | v_loss: 1.30502 v_acc: 0.70931 |  iteration: 16642 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 483 loss: 1.38777 acc: 0.70410 | v_loss: 1.36837 v_acc: 0.69303 |  iteration: 16643 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 484 loss: 1.43961 acc: 0.70475 | v_loss: 1.48244 v_acc: 0.70768 |  iteration: 16644 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 485 loss: 1.40954 acc: 0.70638 | v_loss: 1.31459 v_acc: 0.72201 |  iteration: 16645 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 486 loss: 1.60267 acc: 0.68750 | v_loss: 1.46506 v_acc: 0.70312 |  iteration: 16646 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 487 loss: 1.64978 acc: 0.68945 | v_loss: 1.35231 v_acc: 0.70443 |  iteration: 16647 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 488 loss: 1.52711 acc: 0.69206 | v_loss: 1.34253 v_acc: 0.70671 |  iteration: 16648 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 489 loss: 1.44167 acc: 0.70768 | v_loss: 1.51544 v_acc: 0.69434 |  iteration: 16649 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 490 loss: 1.36334 acc: 0.70280 | v_loss: 1.29932 v_acc: 0.72461 |  iteration: 16650 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 491 loss: 1.33443 acc: 0.71419 | v_loss: 1.56580 v_acc: 0.68978 |  iteration: 16651 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 492 loss: 1.46711 acc: 0.70085 | v_loss: 1.42360 v_acc: 0.69987 |  iteration: 16652 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 493 loss: 1.40565 acc: 0.70215 | v_loss: 1.52124 v_acc: 0.69108 |  iteration: 16653 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 494 loss: 1.43445 acc: 0.69466 | v_loss: 1.36939 v_acc: 0.70117 |  iteration: 16654 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 495 loss: 1.41058 acc: 0.70475 | v_loss: 1.32256 v_acc: 0.70638 |  iteration: 16655 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 496 loss: 1.44539 acc: 0.71029 | v_loss: 1.32786 v_acc: 0.70410 |  iteration: 16656 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 497 loss: 1.34535 acc: 0.70866 | v_loss: 1.33314 v_acc: 0.71908 |  iteration: 16657 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 498 loss: 1.41128 acc: 0.70280 | v_loss: 1.57125 v_acc: 0.68978 |  iteration: 16658 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 499 loss: 1.45740 acc: 0.69694 | v_loss: 1.38580 v_acc: 0.71257 |  iteration: 16659 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 500 loss: 1.38908 acc: 0.70996 | v_loss: 1.33925 v_acc: 0.70638 |  iteration: 16660 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 501 loss: 1.34806 acc: 0.70964 | v_loss: 1.39634 v_acc: 0.70931 |  iteration: 16661 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 502 loss: 1.41962 acc: 0.69857 | v_loss: 1.26153 v_acc: 0.70833 |  iteration: 16662 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 503 loss: 1.49810 acc: 0.69271 | v_loss: 1.43254 v_acc: 0.70150 |  iteration: 16663 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 504 loss: 1.42221 acc: 0.70508 | v_loss: 1.41926 v_acc: 0.71549 |  iteration: 16664 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 505 loss: 1.34498 acc: 0.71354 | v_loss: 1.27658 v_acc: 0.72038 |  iteration: 16665 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 506 loss: 1.39951 acc: 0.69922 | v_loss: 1.25039 v_acc: 0.72819 |  iteration: 16666 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 507 loss: 1.32190 acc: 0.71061 | v_loss: 1.37606 v_acc: 0.71615 |  iteration: 16667 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 508 loss: 1.43699 acc: 0.69303 | v_loss: 1.41851 v_acc: 0.70540 |  iteration: 16668 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 509 loss: 1.32744 acc: 0.70671 | v_loss: 1.42371 v_acc: 0.70508 |  iteration: 16669 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 510 loss: 1.50203 acc: 0.70182 | v_loss: 1.22770 v_acc: 0.71452 |  iteration: 16670 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 511 loss: 1.60342 acc: 0.68490 | v_loss: 1.39432 v_acc: 0.72819 |  iteration: 16671 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 512 loss: 1.41360 acc: 0.69759 | v_loss: 1.47857 v_acc: 0.69759 |  iteration: 16672 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 513 loss: 1.45915 acc: 0.71029 | v_loss: 1.41089 v_acc: 0.71973 |  iteration: 16673 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 514 loss: 1.45723 acc: 0.69824 | v_loss: 1.24968 v_acc: 0.71777 |  iteration: 16674 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 515 loss: 1.48432 acc: 0.69694 | v_loss: 1.21167 v_acc: 0.73535 |  iteration: 16675 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 516 loss: 1.39773 acc: 0.69759 | v_loss: 1.20978 v_acc: 0.72559 |  iteration: 16676 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 517 loss: 1.43609 acc: 0.69759 | v_loss: 1.28042 v_acc: 0.70638 |  iteration: 16677 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 518 loss: 1.51120 acc: 0.69499 | v_loss: 1.44271 v_acc: 0.70410 |  iteration: 16678 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 519 loss: 1.35184 acc: 0.71224 | v_loss: 1.27724 v_acc: 0.71517 |  iteration: 16679 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 520 loss: 1.39999 acc: 0.70671 | v_loss: 1.47128 v_acc: 0.70475 |  iteration: 16680 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 521 loss: 1.60356 acc: 0.68392 | v_loss: 1.66870 v_acc: 0.69401 |  iteration: 16681 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 522 loss: 1.48060 acc: 0.70052 | v_loss: 1.52019 v_acc: 0.69824 |  iteration: 16682 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 523 loss: 1.39900 acc: 0.70312 | v_loss: 1.28747 v_acc: 0.72363 |  iteration: 16683 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 524 loss: 1.49729 acc: 0.69108 | v_loss: 1.37443 v_acc: 0.70410 |  iteration: 16684 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 525 loss: 1.44149 acc: 0.69759 | v_loss: 1.22999 v_acc: 0.71940 |  iteration: 16685 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 526 loss: 1.56479 acc: 0.69238 | v_loss: 1.43056 v_acc: 0.69857 |  iteration: 16686 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 527 loss: 1.48074 acc: 0.69824 | v_loss: 1.35076 v_acc: 0.70964 |  iteration: 16687 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 528 loss: 1.31687 acc: 0.71257 | v_loss: 1.35585 v_acc: 0.72949 |  iteration: 16688 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 529 loss: 1.53846 acc: 0.69401 | v_loss: 1.35706 v_acc: 0.71647 |  iteration: 16689 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 530 loss: 1.50897 acc: 0.70703 | v_loss: 1.37264 v_acc: 0.70280 |  iteration: 16690 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 531 loss: 1.34395 acc: 0.70833 | v_loss: 1.27983 v_acc: 0.72266 |  iteration: 16691 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 532 loss: 1.40528 acc: 0.70866 | v_loss: 1.29447 v_acc: 0.72005 |  iteration: 16692 teacher: 0 stage: sketch lr: 0.000342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 533 loss: 1.38018 acc: 0.71094 | v_loss: 1.48555 v_acc: 0.69206 |  iteration: 16693 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 534 loss: 1.37447 acc: 0.71647 | v_loss: 1.33333 v_acc: 0.70931 |  iteration: 16694 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 535 loss: 1.35706 acc: 0.71322 | v_loss: 1.29067 v_acc: 0.71549 |  iteration: 16695 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 536 loss: 1.38313 acc: 0.70964 | v_loss: 1.27962 v_acc: 0.71973 |  iteration: 16696 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 537 loss: 1.44994 acc: 0.70736 | v_loss: 1.42579 v_acc: 0.70573 |  iteration: 16697 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 538 loss: 1.47745 acc: 0.69531 | v_loss: 1.30744 v_acc: 0.73112 |  iteration: 16698 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 539 loss: 1.38338 acc: 0.70736 | v_loss: 1.54515 v_acc: 0.71452 |  iteration: 16699 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 540 loss: 1.56855 acc: 0.69954 | v_loss: 1.28414 v_acc: 0.69759 |  iteration: 16700 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 541 loss: 1.53355 acc: 0.69629 | v_loss: 1.28334 v_acc: 0.70443 |  iteration: 16701 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 542 loss: 1.56590 acc: 0.69889 | v_loss: 1.43866 v_acc: 0.70540 |  iteration: 16702 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 543 loss: 1.44986 acc: 0.69368 | v_loss: 1.46751 v_acc: 0.70443 |  iteration: 16703 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 544 loss: 1.45797 acc: 0.69661 | v_loss: 1.51140 v_acc: 0.69076 |  iteration: 16704 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 545 loss: 1.36200 acc: 0.70931 | v_loss: 1.46354 v_acc: 0.70605 |  iteration: 16705 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 546 loss: 1.45550 acc: 0.69596 | v_loss: 1.41376 v_acc: 0.70703 |  iteration: 16706 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 547 loss: 1.49712 acc: 0.70833 | v_loss: 1.39951 v_acc: 0.70703 |  iteration: 16707 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 548 loss: 1.47467 acc: 0.70280 | v_loss: 1.40660 v_acc: 0.70443 |  iteration: 16708 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 549 loss: 1.48181 acc: 0.70182 | v_loss: 1.28226 v_acc: 0.71159 |  iteration: 16709 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 550 loss: 1.48022 acc: 0.70085 | v_loss: 1.31127 v_acc: 0.72396 |  iteration: 16710 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 551 loss: 1.44420 acc: 0.70247 | v_loss: 1.20582 v_acc: 0.70638 |  iteration: 16711 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 552 loss: 1.50871 acc: 0.69792 | v_loss: 1.35177 v_acc: 0.70703 |  iteration: 16712 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 553 loss: 1.42583 acc: 0.69759 | v_loss: 1.49153 v_acc: 0.69987 |  iteration: 16713 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 554 loss: 1.45415 acc: 0.70410 | v_loss: 1.32013 v_acc: 0.70833 |  iteration: 16714 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 555 loss: 1.48245 acc: 0.69792 | v_loss: 1.34986 v_acc: 0.69727 |  iteration: 16715 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 556 loss: 1.43858 acc: 0.70182 | v_loss: 1.25539 v_acc: 0.71126 |  iteration: 16716 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 557 loss: 1.45066 acc: 0.69466 | v_loss: 1.25679 v_acc: 0.70345 |  iteration: 16717 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 558 loss: 1.42652 acc: 0.70573 | v_loss: 1.23631 v_acc: 0.73503 |  iteration: 16718 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 559 loss: 1.47117 acc: 0.69857 | v_loss: 1.27317 v_acc: 0.72168 |  iteration: 16719 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 560 loss: 1.39030 acc: 0.70150 | v_loss: 1.34424 v_acc: 0.73470 |  iteration: 16720 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 561 loss: 1.36847 acc: 0.71647 | v_loss: 1.26638 v_acc: 0.72559 |  iteration: 16721 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 562 loss: 1.45516 acc: 0.70475 | v_loss: 1.32007 v_acc: 0.72005 |  iteration: 16722 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 563 loss: 1.48334 acc: 0.70508 | v_loss: 1.43619 v_acc: 0.71224 |  iteration: 16723 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 564 loss: 1.47358 acc: 0.70117 | v_loss: 1.39611 v_acc: 0.72070 |  iteration: 16724 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 565 loss: 1.36912 acc: 0.70801 | v_loss: 1.48775 v_acc: 0.69954 |  iteration: 16725 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 566 loss: 1.30163 acc: 0.72917 | v_loss: 1.41905 v_acc: 0.71615 |  iteration: 16726 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 567 loss: 1.36200 acc: 0.71387 | v_loss: 1.17480 v_acc: 0.74544 |  iteration: 16727 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 568 loss: 1.43662 acc: 0.70866 | v_loss: 1.25140 v_acc: 0.70931 |  iteration: 16728 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 569 loss: 1.38759 acc: 0.70703 | v_loss: 1.51025 v_acc: 0.70540 |  iteration: 16729 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 570 loss: 1.41623 acc: 0.71191 | v_loss: 1.21748 v_acc: 0.72298 |  iteration: 16730 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 571 loss: 1.41988 acc: 0.69792 | v_loss: 1.33005 v_acc: 0.71908 |  iteration: 16731 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 572 loss: 1.36929 acc: 0.70931 | v_loss: 1.37901 v_acc: 0.69141 |  iteration: 16732 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 573 loss: 1.39001 acc: 0.71159 | v_loss: 1.29773 v_acc: 0.70931 |  iteration: 16733 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 574 loss: 1.40474 acc: 0.70996 | v_loss: 1.36674 v_acc: 0.69336 |  iteration: 16734 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 575 loss: 1.37645 acc: 0.70378 | v_loss: 1.48238 v_acc: 0.71419 |  iteration: 16735 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 576 loss: 1.40285 acc: 0.70150 | v_loss: 1.32539 v_acc: 0.72786 |  iteration: 16736 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 577 loss: 1.34123 acc: 0.71549 | v_loss: 1.45477 v_acc: 0.70443 |  iteration: 16737 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 578 loss: 1.55529 acc: 0.68913 | v_loss: 1.37425 v_acc: 0.69857 |  iteration: 16738 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 579 loss: 1.44126 acc: 0.70312 | v_loss: 1.31806 v_acc: 0.70833 |  iteration: 16739 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 580 loss: 1.42734 acc: 0.70280 | v_loss: 1.56594 v_acc: 0.68490 |  iteration: 16740 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 581 loss: 1.43729 acc: 0.70150 | v_loss: 1.30016 v_acc: 0.72168 |  iteration: 16741 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 582 loss: 1.36285 acc: 0.70866 | v_loss: 1.59393 v_acc: 0.67969 |  iteration: 16742 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 583 loss: 1.37519 acc: 0.71322 | v_loss: 1.45985 v_acc: 0.69661 |  iteration: 16743 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 584 loss: 1.46516 acc: 0.70964 | v_loss: 1.53497 v_acc: 0.69141 |  iteration: 16744 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 585 loss: 1.41461 acc: 0.70475 | v_loss: 1.37134 v_acc: 0.70085 |  iteration: 16745 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 586 loss: 1.41574 acc: 0.70052 | v_loss: 1.33045 v_acc: 0.70312 |  iteration: 16746 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 587 loss: 1.35320 acc: 0.70605 | v_loss: 1.32548 v_acc: 0.70020 |  iteration: 16747 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 588 loss: 1.48503 acc: 0.69922 | v_loss: 1.32437 v_acc: 0.71484 |  iteration: 16748 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 589 loss: 1.51772 acc: 0.69173 | v_loss: 1.53265 v_acc: 0.68978 |  iteration: 16749 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 590 loss: 1.44456 acc: 0.70833 | v_loss: 1.37848 v_acc: 0.70443 |  iteration: 16750 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 591 loss: 1.46004 acc: 0.69368 | v_loss: 1.35070 v_acc: 0.71029 |  iteration: 16751 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 592 loss: 1.27503 acc: 0.72656 | v_loss: 1.38067 v_acc: 0.71680 |  iteration: 16752 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 593 loss: 1.43539 acc: 0.69987 | v_loss: 1.27374 v_acc: 0.70605 |  iteration: 16753 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 594 loss: 1.46482 acc: 0.70736 | v_loss: 1.43237 v_acc: 0.69922 |  iteration: 16754 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 595 loss: 1.43586 acc: 0.70573 | v_loss: 1.42258 v_acc: 0.71322 |  iteration: 16755 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 596 loss: 1.54242 acc: 0.69238 | v_loss: 1.28986 v_acc: 0.71875 |  iteration: 16756 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 597 loss: 1.43564 acc: 0.69629 | v_loss: 1.25360 v_acc: 0.72754 |  iteration: 16757 teacher: 1 stage: sketch lr: 0.000341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 598 loss: 1.37554 acc: 0.71354 | v_loss: 1.37505 v_acc: 0.71940 |  iteration: 16758 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 599 loss: 1.42123 acc: 0.69727 | v_loss: 1.42228 v_acc: 0.70345 |  iteration: 16759 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 600 loss: 1.40284 acc: 0.70443 | v_loss: 1.42411 v_acc: 0.70312 |  iteration: 16760 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 601 loss: 1.40501 acc: 0.70117 | v_loss: 1.23690 v_acc: 0.71289 |  iteration: 16761 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 602 loss: 1.48379 acc: 0.69824 | v_loss: 1.40108 v_acc: 0.72656 |  iteration: 16762 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 603 loss: 1.45046 acc: 0.70150 | v_loss: 1.47776 v_acc: 0.69889 |  iteration: 16763 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 604 loss: 1.31171 acc: 0.70996 | v_loss: 1.40488 v_acc: 0.72103 |  iteration: 16764 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 605 loss: 1.46815 acc: 0.69792 | v_loss: 1.24356 v_acc: 0.71908 |  iteration: 16765 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 606 loss: 1.45394 acc: 0.70085 | v_loss: 1.20091 v_acc: 0.73079 |  iteration: 16766 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 607 loss: 1.42605 acc: 0.70801 | v_loss: 1.22289 v_acc: 0.72689 |  iteration: 16767 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 608 loss: 1.50291 acc: 0.69889 | v_loss: 1.28780 v_acc: 0.70703 |  iteration: 16768 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 609 loss: 1.40546 acc: 0.70182 | v_loss: 1.46211 v_acc: 0.69466 |  iteration: 16769 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 610 loss: 1.46740 acc: 0.69889 | v_loss: 1.26623 v_acc: 0.71419 |  iteration: 16770 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 611 loss: 1.49683 acc: 0.69564 | v_loss: 1.42157 v_acc: 0.72917 |  iteration: 16771 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 612 loss: 1.44327 acc: 0.69401 | v_loss: 1.67268 v_acc: 0.69303 |  iteration: 16772 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 613 loss: 1.47005 acc: 0.70573 | v_loss: 1.53248 v_acc: 0.69824 |  iteration: 16773 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 614 loss: 1.40388 acc: 0.70605 | v_loss: 1.29419 v_acc: 0.72396 |  iteration: 16774 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 615 loss: 1.42201 acc: 0.70020 | v_loss: 1.36844 v_acc: 0.70996 |  iteration: 16775 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 616 loss: 1.43282 acc: 0.70573 | v_loss: 1.21551 v_acc: 0.72201 |  iteration: 16776 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 617 loss: 1.42913 acc: 0.70573 | v_loss: 1.41161 v_acc: 0.70312 |  iteration: 16777 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 618 loss: 1.42167 acc: 0.70345 | v_loss: 1.35625 v_acc: 0.71484 |  iteration: 16778 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 619 loss: 1.36372 acc: 0.70703 | v_loss: 1.34653 v_acc: 0.72949 |  iteration: 16779 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 620 loss: 1.41513 acc: 0.70182 | v_loss: 1.35874 v_acc: 0.71810 |  iteration: 16780 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 621 loss: 1.49678 acc: 0.69271 | v_loss: 1.37336 v_acc: 0.70508 |  iteration: 16781 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 622 loss: 1.41091 acc: 0.69857 | v_loss: 1.27888 v_acc: 0.72266 |  iteration: 16782 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 623 loss: 1.50749 acc: 0.69238 | v_loss: 1.29512 v_acc: 0.71973 |  iteration: 16783 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 624 loss: 1.38796 acc: 0.69661 | v_loss: 1.48536 v_acc: 0.68848 |  iteration: 16784 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 625 loss: 1.44724 acc: 0.69661 | v_loss: 1.33771 v_acc: 0.71029 |  iteration: 16785 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 626 loss: 1.47715 acc: 0.70312 | v_loss: 1.28408 v_acc: 0.71452 |  iteration: 16786 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 627 loss: 1.46090 acc: 0.70247 | v_loss: 1.27854 v_acc: 0.71940 |  iteration: 16787 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 628 loss: 1.40658 acc: 0.70215 | v_loss: 1.41698 v_acc: 0.70475 |  iteration: 16788 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 629 loss: 1.37391 acc: 0.70508 | v_loss: 1.31433 v_acc: 0.73079 |  iteration: 16789 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 630 loss: 1.43266 acc: 0.70150 | v_loss: 1.56080 v_acc: 0.71582 |  iteration: 16790 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 631 loss: 1.43873 acc: 0.69792 | v_loss: 1.28345 v_acc: 0.70117 |  iteration: 16791 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 632 loss: 1.44014 acc: 0.70312 | v_loss: 1.27900 v_acc: 0.70573 |  iteration: 16792 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 633 loss: 1.49752 acc: 0.69466 | v_loss: 1.42214 v_acc: 0.70378 |  iteration: 16793 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 634 loss: 1.50343 acc: 0.69629 | v_loss: 1.45787 v_acc: 0.70475 |  iteration: 16794 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 635 loss: 1.50151 acc: 0.70345 | v_loss: 1.49888 v_acc: 0.69076 |  iteration: 16795 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 636 loss: 1.33588 acc: 0.71517 | v_loss: 1.46294 v_acc: 0.70605 |  iteration: 16796 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 637 loss: 1.43299 acc: 0.70508 | v_loss: 1.40431 v_acc: 0.70736 |  iteration: 16797 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 638 loss: 1.49515 acc: 0.69173 | v_loss: 1.38848 v_acc: 0.70703 |  iteration: 16798 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 639 loss: 1.45533 acc: 0.70378 | v_loss: 1.42157 v_acc: 0.70508 |  iteration: 16799 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 640 loss: 1.48287 acc: 0.68945 | v_loss: 1.28309 v_acc: 0.71061 |  iteration: 16800 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 641 loss: 1.36018 acc: 0.70736 | v_loss: 1.31344 v_acc: 0.72363 |  iteration: 16801 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 642 loss: 1.37964 acc: 0.71419 | v_loss: 1.21406 v_acc: 0.70736 |  iteration: 16802 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 643 loss: 1.28102 acc: 0.72559 | v_loss: 1.34611 v_acc: 0.70117 |  iteration: 16803 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 644 loss: 1.43071 acc: 0.69889 | v_loss: 1.50589 v_acc: 0.69987 |  iteration: 16804 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 645 loss: 1.38564 acc: 0.70866 | v_loss: 1.33087 v_acc: 0.70833 |  iteration: 16805 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 646 loss: 1.36093 acc: 0.70768 | v_loss: 1.35429 v_acc: 0.69727 |  iteration: 16806 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 647 loss: 1.47872 acc: 0.69401 | v_loss: 1.24091 v_acc: 0.71126 |  iteration: 16807 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 648 loss: 1.39223 acc: 0.70833 | v_loss: 1.24455 v_acc: 0.70345 |  iteration: 16808 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 649 loss: 1.38355 acc: 0.70378 | v_loss: 1.25884 v_acc: 0.73568 |  iteration: 16809 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 650 loss: 1.43795 acc: 0.69889 | v_loss: 1.25944 v_acc: 0.72461 |  iteration: 16810 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 651 loss: 1.33813 acc: 0.71159 | v_loss: 1.35505 v_acc: 0.72721 |  iteration: 16811 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 652 loss: 1.50500 acc: 0.69303 | v_loss: 1.27372 v_acc: 0.72721 |  iteration: 16812 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 653 loss: 1.44873 acc: 0.69792 | v_loss: 1.31651 v_acc: 0.71875 |  iteration: 16813 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 654 loss: 1.42945 acc: 0.70215 | v_loss: 1.43407 v_acc: 0.71354 |  iteration: 16814 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 655 loss: 1.26650 acc: 0.71615 | v_loss: 1.41692 v_acc: 0.72298 |  iteration: 16815 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 656 loss: 1.45367 acc: 0.69661 | v_loss: 1.48758 v_acc: 0.69857 |  iteration: 16816 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 657 loss: 1.43126 acc: 0.69531 | v_loss: 1.43116 v_acc: 0.71973 |  iteration: 16817 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 658 loss: 1.39781 acc: 0.70345 | v_loss: 1.17962 v_acc: 0.74447 |  iteration: 16818 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 659 loss: 1.45922 acc: 0.69792 | v_loss: 1.24277 v_acc: 0.71159 |  iteration: 16819 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 660 loss: 1.46948 acc: 0.69922 | v_loss: 1.52678 v_acc: 0.69987 |  iteration: 16820 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 661 loss: 1.52912 acc: 0.69466 | v_loss: 1.19804 v_acc: 0.70671 |  iteration: 16821 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 662 loss: 1.41821 acc: 0.70117 | v_loss: 1.32636 v_acc: 0.71257 |  iteration: 16822 teacher: 1 stage: sketch lr: 0.000341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 663 loss: 1.40945 acc: 0.70996 | v_loss: 1.36225 v_acc: 0.69368 |  iteration: 16823 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 664 loss: 1.37315 acc: 0.71712 | v_loss: 1.28829 v_acc: 0.71810 |  iteration: 16824 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 665 loss: 1.42153 acc: 0.71061 | v_loss: 1.35929 v_acc: 0.69629 |  iteration: 16825 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 666 loss: 1.37674 acc: 0.71289 | v_loss: 1.47371 v_acc: 0.71517 |  iteration: 16826 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 667 loss: 1.41685 acc: 0.70736 | v_loss: 1.31842 v_acc: 0.72689 |  iteration: 16827 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 668 loss: 1.48844 acc: 0.69727 | v_loss: 1.44805 v_acc: 0.70443 |  iteration: 16828 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 669 loss: 1.43661 acc: 0.69889 | v_loss: 1.36000 v_acc: 0.69889 |  iteration: 16829 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 670 loss: 1.40206 acc: 0.70638 | v_loss: 1.32948 v_acc: 0.70866 |  iteration: 16830 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 671 loss: 1.39121 acc: 0.70443 | v_loss: 1.54399 v_acc: 0.68913 |  iteration: 16831 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 672 loss: 1.43190 acc: 0.70964 | v_loss: 1.29503 v_acc: 0.72135 |  iteration: 16832 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 673 loss: 1.42674 acc: 0.71224 | v_loss: 1.59984 v_acc: 0.68294 |  iteration: 16833 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 674 loss: 1.34324 acc: 0.71061 | v_loss: 1.45532 v_acc: 0.69889 |  iteration: 16834 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 675 loss: 1.48610 acc: 0.70085 | v_loss: 1.51325 v_acc: 0.68978 |  iteration: 16835 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 676 loss: 1.48914 acc: 0.69889 | v_loss: 1.38747 v_acc: 0.69792 |  iteration: 16836 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 677 loss: 1.39199 acc: 0.70117 | v_loss: 1.31980 v_acc: 0.70378 |  iteration: 16837 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 678 loss: 1.44416 acc: 0.70085 | v_loss: 1.33248 v_acc: 0.70215 |  iteration: 16838 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 679 loss: 1.43753 acc: 0.69824 | v_loss: 1.33000 v_acc: 0.71615 |  iteration: 16839 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 680 loss: 1.57419 acc: 0.69694 | v_loss: 1.54480 v_acc: 0.68945 |  iteration: 16840 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 681 loss: 1.57169 acc: 0.69531 | v_loss: 1.38634 v_acc: 0.70703 |  iteration: 16841 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 682 loss: 1.44820 acc: 0.70085 | v_loss: 1.34618 v_acc: 0.70833 |  iteration: 16842 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 683 loss: 1.42063 acc: 0.70150 | v_loss: 1.38760 v_acc: 0.71582 |  iteration: 16843 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 684 loss: 1.31503 acc: 0.71029 | v_loss: 1.28130 v_acc: 0.70443 |  iteration: 16844 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 685 loss: 1.39530 acc: 0.70312 | v_loss: 1.42386 v_acc: 0.69661 |  iteration: 16845 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 686 loss: 1.40466 acc: 0.69824 | v_loss: 1.42833 v_acc: 0.71452 |  iteration: 16846 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 687 loss: 1.41681 acc: 0.69824 | v_loss: 1.29033 v_acc: 0.71875 |  iteration: 16847 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 688 loss: 1.42727 acc: 0.69694 | v_loss: 1.26124 v_acc: 0.72754 |  iteration: 16848 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 689 loss: 1.41733 acc: 0.71126 | v_loss: 1.37493 v_acc: 0.71940 |  iteration: 16849 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 690 loss: 1.52558 acc: 0.69043 | v_loss: 1.42704 v_acc: 0.70345 |  iteration: 16850 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 691 loss: 1.53619 acc: 0.68685 | v_loss: 1.43417 v_acc: 0.70833 |  iteration: 16851 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 692 loss: 1.38711 acc: 0.69889 | v_loss: 1.21348 v_acc: 0.72591 |  iteration: 16852 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 693 loss: 1.44101 acc: 0.70410 | v_loss: 1.39472 v_acc: 0.73112 |  iteration: 16853 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 694 loss: 1.44847 acc: 0.70703 | v_loss: 1.47997 v_acc: 0.69759 |  iteration: 16854 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 695 loss: 1.39517 acc: 0.70475 | v_loss: 1.43201 v_acc: 0.72201 |  iteration: 16855 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 696 loss: 1.41742 acc: 0.69857 | v_loss: 1.24166 v_acc: 0.72201 |  iteration: 16856 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 697 loss: 1.50521 acc: 0.69889 | v_loss: 1.19479 v_acc: 0.73600 |  iteration: 16857 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 698 loss: 1.34453 acc: 0.70280 | v_loss: 1.20806 v_acc: 0.72656 |  iteration: 16858 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 699 loss: 1.38660 acc: 0.69499 | v_loss: 1.27048 v_acc: 0.70768 |  iteration: 16859 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 700 loss: 1.41696 acc: 0.70020 | v_loss: 1.44884 v_acc: 0.69596 |  iteration: 16860 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 701 loss: 1.39893 acc: 0.70247 | v_loss: 1.27218 v_acc: 0.71224 |  iteration: 16861 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 702 loss: 1.32851 acc: 0.71680 | v_loss: 1.44173 v_acc: 0.71582 |  iteration: 16862 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 703 loss: 1.38482 acc: 0.70475 | v_loss: 1.68289 v_acc: 0.69303 |  iteration: 16863 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 704 loss: 1.39508 acc: 0.70443 | v_loss: 1.53260 v_acc: 0.70117 |  iteration: 16864 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 705 loss: 1.43045 acc: 0.70378 | v_loss: 1.29202 v_acc: 0.72201 |  iteration: 16865 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 706 loss: 1.47358 acc: 0.70085 | v_loss: 1.37586 v_acc: 0.70964 |  iteration: 16866 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 707 loss: 1.42106 acc: 0.70443 | v_loss: 1.21295 v_acc: 0.72168 |  iteration: 16867 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 708 loss: 1.45188 acc: 0.70085 | v_loss: 1.42386 v_acc: 0.70280 |  iteration: 16868 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 709 loss: 1.46364 acc: 0.70020 | v_loss: 1.35457 v_acc: 0.71029 |  iteration: 16869 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 710 loss: 1.29969 acc: 0.71387 | v_loss: 1.35316 v_acc: 0.73079 |  iteration: 16870 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 711 loss: 1.42105 acc: 0.71126 | v_loss: 1.36003 v_acc: 0.71777 |  iteration: 16871 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 712 loss: 1.35052 acc: 0.70605 | v_loss: 1.36699 v_acc: 0.70508 |  iteration: 16872 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 713 loss: 1.35802 acc: 0.71159 | v_loss: 1.28540 v_acc: 0.72201 |  iteration: 16873 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 714 loss: 1.41719 acc: 0.70605 | v_loss: 1.29612 v_acc: 0.72005 |  iteration: 16874 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 715 loss: 1.51653 acc: 0.69434 | v_loss: 1.48870 v_acc: 0.69206 |  iteration: 16875 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 716 loss: 1.43562 acc: 0.70671 | v_loss: 1.32753 v_acc: 0.70931 |  iteration: 16876 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 717 loss: 1.42374 acc: 0.70117 | v_loss: 1.30284 v_acc: 0.71452 |  iteration: 16877 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 718 loss: 1.41047 acc: 0.70475 | v_loss: 1.29361 v_acc: 0.71940 |  iteration: 16878 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 719 loss: 1.45625 acc: 0.70736 | v_loss: 1.43483 v_acc: 0.70475 |  iteration: 16879 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 720 loss: 1.41629 acc: 0.69954 | v_loss: 1.30501 v_acc: 0.73210 |  iteration: 16880 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 721 loss: 1.43952 acc: 0.70508 | v_loss: 1.53383 v_acc: 0.71517 |  iteration: 16881 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 722 loss: 1.39743 acc: 0.69922 | v_loss: 1.29328 v_acc: 0.69694 |  iteration: 16882 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 723 loss: 1.41961 acc: 0.70703 | v_loss: 1.28444 v_acc: 0.70280 |  iteration: 16883 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 724 loss: 1.37203 acc: 0.70573 | v_loss: 1.44029 v_acc: 0.70312 |  iteration: 16884 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 725 loss: 1.40378 acc: 0.70866 | v_loss: 1.48281 v_acc: 0.70378 |  iteration: 16885 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 726 loss: 1.47116 acc: 0.69303 | v_loss: 1.53630 v_acc: 0.68978 |  iteration: 16886 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 727 loss: 1.47679 acc: 0.69824 | v_loss: 1.47844 v_acc: 0.70866 |  iteration: 16887 teacher: 1 stage: sketch lr: 0.000340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 728 loss: 1.42841 acc: 0.70150 | v_loss: 1.42727 v_acc: 0.70215 |  iteration: 16888 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 729 loss: 1.41277 acc: 0.70215 | v_loss: 1.41111 v_acc: 0.70931 |  iteration: 16889 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 730 loss: 1.35026 acc: 0.71387 | v_loss: 1.40497 v_acc: 0.70703 |  iteration: 16890 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 731 loss: 1.40257 acc: 0.70638 | v_loss: 1.25985 v_acc: 0.71875 |  iteration: 16891 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 732 loss: 1.39862 acc: 0.70247 | v_loss: 1.31699 v_acc: 0.72331 |  iteration: 16892 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 733 loss: 1.42591 acc: 0.70182 | v_loss: 1.17255 v_acc: 0.71615 |  iteration: 16893 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 734 loss: 1.31422 acc: 0.70768 | v_loss: 1.34308 v_acc: 0.71126 |  iteration: 16894 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 735 loss: 1.45084 acc: 0.69759 | v_loss: 1.50995 v_acc: 0.69954 |  iteration: 16895 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 736 loss: 1.44979 acc: 0.69727 | v_loss: 1.31511 v_acc: 0.71452 |  iteration: 16896 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 737 loss: 1.40665 acc: 0.70443 | v_loss: 1.35384 v_acc: 0.69727 |  iteration: 16897 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 738 loss: 1.40726 acc: 0.70671 | v_loss: 1.23895 v_acc: 0.71126 |  iteration: 16898 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 739 loss: 1.39217 acc: 0.70898 | v_loss: 1.24976 v_acc: 0.70345 |  iteration: 16899 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 740 loss: 1.39351 acc: 0.71224 | v_loss: 1.23691 v_acc: 0.73503 |  iteration: 16900 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 741 loss: 1.45235 acc: 0.70475 | v_loss: 1.26802 v_acc: 0.72168 |  iteration: 16901 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 742 loss: 1.56198 acc: 0.70475 | v_loss: 1.31552 v_acc: 0.74967 |  iteration: 16902 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 743 loss: 1.52314 acc: 0.70736 | v_loss: 1.25916 v_acc: 0.72005 |  iteration: 16903 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 744 loss: 1.42664 acc: 0.70475 | v_loss: 1.29694 v_acc: 0.71745 |  iteration: 16904 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 745 loss: 1.46283 acc: 0.70280 | v_loss: 1.40394 v_acc: 0.71354 |  iteration: 16905 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 746 loss: 1.40823 acc: 0.70605 | v_loss: 1.37127 v_acc: 0.72103 |  iteration: 16906 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 747 loss: 1.45174 acc: 0.69271 | v_loss: 1.48128 v_acc: 0.69922 |  iteration: 16907 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 748 loss: 1.42020 acc: 0.70475 | v_loss: 1.40811 v_acc: 0.71712 |  iteration: 16908 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 749 loss: 1.36208 acc: 0.71061 | v_loss: 1.17288 v_acc: 0.74544 |  iteration: 16909 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 750 loss: 1.35780 acc: 0.70703 | v_loss: 1.25086 v_acc: 0.70931 |  iteration: 16910 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 751 loss: 1.36907 acc: 0.70280 | v_loss: 1.52391 v_acc: 0.70247 |  iteration: 16911 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 752 loss: 1.44901 acc: 0.70020 | v_loss: 1.20579 v_acc: 0.70866 |  iteration: 16912 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 753 loss: 1.44797 acc: 0.69368 | v_loss: 1.33447 v_acc: 0.71257 |  iteration: 16913 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 754 loss: 1.37272 acc: 0.70931 | v_loss: 1.36873 v_acc: 0.69368 |  iteration: 16914 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 755 loss: 1.61483 acc: 0.68229 | v_loss: 1.28815 v_acc: 0.71842 |  iteration: 16915 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 756 loss: 1.42553 acc: 0.70833 | v_loss: 1.36489 v_acc: 0.70215 |  iteration: 16916 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 757 loss: 1.37932 acc: 0.70638 | v_loss: 1.47925 v_acc: 0.71842 |  iteration: 16917 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 758 loss: 1.38304 acc: 0.70833 | v_loss: 1.32233 v_acc: 0.72917 |  iteration: 16918 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 759 loss: 1.41496 acc: 0.70703 | v_loss: 1.44361 v_acc: 0.70345 |  iteration: 16919 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 760 loss: 1.32634 acc: 0.70833 | v_loss: 1.35145 v_acc: 0.69954 |  iteration: 16920 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 761 loss: 1.43440 acc: 0.69564 | v_loss: 1.32676 v_acc: 0.70964 |  iteration: 16921 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 762 loss: 1.35171 acc: 0.70508 | v_loss: 1.53894 v_acc: 0.68913 |  iteration: 16922 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 763 loss: 1.48479 acc: 0.69173 | v_loss: 1.30875 v_acc: 0.72135 |  iteration: 16923 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 764 loss: 1.48075 acc: 0.69857 | v_loss: 1.58959 v_acc: 0.68294 |  iteration: 16924 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 765 loss: 1.40772 acc: 0.69824 | v_loss: 1.43580 v_acc: 0.69954 |  iteration: 16925 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 766 loss: 1.51221 acc: 0.69596 | v_loss: 1.53378 v_acc: 0.69238 |  iteration: 16926 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 767 loss: 1.45416 acc: 0.70215 | v_loss: 1.36763 v_acc: 0.70182 |  iteration: 16927 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 768 loss: 1.37358 acc: 0.71224 | v_loss: 1.31998 v_acc: 0.70638 |  iteration: 16928 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 769 loss: 1.44122 acc: 0.69303 | v_loss: 1.31656 v_acc: 0.70410 |  iteration: 16929 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 770 loss: 1.41414 acc: 0.70150 | v_loss: 1.32942 v_acc: 0.71842 |  iteration: 16930 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 771 loss: 1.41609 acc: 0.70475 | v_loss: 1.54343 v_acc: 0.69108 |  iteration: 16931 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 772 loss: 1.31306 acc: 0.71289 | v_loss: 1.37171 v_acc: 0.71126 |  iteration: 16932 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 773 loss: 1.44707 acc: 0.70378 | v_loss: 1.34284 v_acc: 0.71061 |  iteration: 16933 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 774 loss: 1.39246 acc: 0.71191 | v_loss: 1.38945 v_acc: 0.71452 |  iteration: 16934 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 775 loss: 1.43723 acc: 0.70150 | v_loss: 1.25785 v_acc: 0.70736 |  iteration: 16935 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 776 loss: 1.32910 acc: 0.72038 | v_loss: 1.43290 v_acc: 0.70052 |  iteration: 16936 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 777 loss: 1.49239 acc: 0.69434 | v_loss: 1.44042 v_acc: 0.71224 |  iteration: 16937 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 778 loss: 1.37072 acc: 0.71061 | v_loss: 1.28121 v_acc: 0.72233 |  iteration: 16938 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 779 loss: 1.47171 acc: 0.70475 | v_loss: 1.26604 v_acc: 0.72591 |  iteration: 16939 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 780 loss: 1.41878 acc: 0.71224 | v_loss: 1.38119 v_acc: 0.72266 |  iteration: 16940 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 781 loss: 1.42447 acc: 0.70085 | v_loss: 1.42847 v_acc: 0.70345 |  iteration: 16941 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 782 loss: 1.42234 acc: 0.70801 | v_loss: 1.42952 v_acc: 0.70410 |  iteration: 16942 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 783 loss: 1.34244 acc: 0.70833 | v_loss: 1.22905 v_acc: 0.71712 |  iteration: 16943 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 784 loss: 1.53524 acc: 0.69564 | v_loss: 1.38819 v_acc: 0.72786 |  iteration: 16944 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 785 loss: 1.45536 acc: 0.70671 | v_loss: 1.46749 v_acc: 0.69792 |  iteration: 16945 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 786 loss: 1.42120 acc: 0.70703 | v_loss: 1.41082 v_acc: 0.72070 |  iteration: 16946 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 787 loss: 1.45434 acc: 0.69922 | v_loss: 1.25423 v_acc: 0.71810 |  iteration: 16947 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 788 loss: 1.46266 acc: 0.70703 | v_loss: 1.19998 v_acc: 0.73600 |  iteration: 16948 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 789 loss: 1.48929 acc: 0.70020 | v_loss: 1.20926 v_acc: 0.72656 |  iteration: 16949 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 790 loss: 1.49338 acc: 0.69694 | v_loss: 1.28172 v_acc: 0.70931 |  iteration: 16950 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 791 loss: 1.33814 acc: 0.71549 | v_loss: 1.43580 v_acc: 0.69629 |  iteration: 16951 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 792 loss: 1.47816 acc: 0.69824 | v_loss: 1.28771 v_acc: 0.71257 |  iteration: 16952 teacher: 1 stage: sketch lr: 0.000339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 793 loss: 1.51494 acc: 0.69076 | v_loss: 1.44308 v_acc: 0.71582 |  iteration: 16953 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 794 loss: 1.52803 acc: 0.68978 | v_loss: 1.64866 v_acc: 0.69401 |  iteration: 16954 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 795 loss: 1.44886 acc: 0.70508 | v_loss: 1.51249 v_acc: 0.69922 |  iteration: 16955 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 796 loss: 1.51456 acc: 0.69661 | v_loss: 1.29002 v_acc: 0.72135 |  iteration: 16956 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 797 loss: 1.40122 acc: 0.69889 | v_loss: 1.36555 v_acc: 0.70410 |  iteration: 16957 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 798 loss: 1.48673 acc: 0.69206 | v_loss: 1.22135 v_acc: 0.71973 |  iteration: 16958 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 799 loss: 1.39296 acc: 0.70345 | v_loss: 1.41262 v_acc: 0.70150 |  iteration: 16959 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 800 loss: 1.50081 acc: 0.69922 | v_loss: 1.36037 v_acc: 0.71159 |  iteration: 16960 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 801 loss: 1.46391 acc: 0.68424 | v_loss: 1.35254 v_acc: 0.73047 |  iteration: 16961 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 802 loss: 1.38780 acc: 0.69987 | v_loss: 1.36470 v_acc: 0.71973 |  iteration: 16962 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 803 loss: 1.39252 acc: 0.70573 | v_loss: 1.37066 v_acc: 0.70964 |  iteration: 16963 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 804 loss: 1.42225 acc: 0.69499 | v_loss: 1.27800 v_acc: 0.72493 |  iteration: 16964 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 805 loss: 1.41461 acc: 0.69857 | v_loss: 1.28974 v_acc: 0.72038 |  iteration: 16965 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 806 loss: 1.39844 acc: 0.70540 | v_loss: 1.46102 v_acc: 0.69368 |  iteration: 16966 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 807 loss: 1.40060 acc: 0.70605 | v_loss: 1.34181 v_acc: 0.71419 |  iteration: 16967 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 808 loss: 1.39145 acc: 0.70378 | v_loss: 1.28540 v_acc: 0.71549 |  iteration: 16968 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 809 loss: 1.32722 acc: 0.70768 | v_loss: 1.27839 v_acc: 0.71973 |  iteration: 16969 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 810 loss: 1.48627 acc: 0.69368 | v_loss: 1.43286 v_acc: 0.70671 |  iteration: 16970 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 811 loss: 1.42450 acc: 0.71126 | v_loss: 1.32194 v_acc: 0.72884 |  iteration: 16971 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 812 loss: 1.39587 acc: 0.70866 | v_loss: 1.54504 v_acc: 0.71224 |  iteration: 16972 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 813 loss: 1.42985 acc: 0.70736 | v_loss: 1.29458 v_acc: 0.69596 |  iteration: 16973 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 814 loss: 1.41555 acc: 0.70573 | v_loss: 1.28202 v_acc: 0.70052 |  iteration: 16974 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 815 loss: 1.46418 acc: 0.69629 | v_loss: 1.45826 v_acc: 0.70671 |  iteration: 16975 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 816 loss: 1.37758 acc: 0.71191 | v_loss: 1.48500 v_acc: 0.70638 |  iteration: 16976 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 817 loss: 1.46676 acc: 0.69889 | v_loss: 1.52813 v_acc: 0.68880 |  iteration: 16977 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 818 loss: 1.36947 acc: 0.71582 | v_loss: 1.47245 v_acc: 0.70638 |  iteration: 16978 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 819 loss: 1.44489 acc: 0.69792 | v_loss: 1.42073 v_acc: 0.70736 |  iteration: 16979 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 820 loss: 1.42246 acc: 0.70117 | v_loss: 1.40408 v_acc: 0.70703 |  iteration: 16980 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 821 loss: 1.37926 acc: 0.71484 | v_loss: 1.41119 v_acc: 0.70671 |  iteration: 16981 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 822 loss: 1.41036 acc: 0.70150 | v_loss: 1.26000 v_acc: 0.71875 |  iteration: 16982 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 823 loss: 1.35130 acc: 0.71257 | v_loss: 1.32242 v_acc: 0.72331 |  iteration: 16983 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 824 loss: 1.43465 acc: 0.69629 | v_loss: 1.17285 v_acc: 0.71810 |  iteration: 16984 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 825 loss: 1.35678 acc: 0.71159 | v_loss: 1.33581 v_acc: 0.71094 |  iteration: 16985 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 826 loss: 1.56807 acc: 0.68587 | v_loss: 1.53037 v_acc: 0.69141 |  iteration: 16986 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 827 loss: 1.43134 acc: 0.69987 | v_loss: 1.33579 v_acc: 0.71387 |  iteration: 16987 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 828 loss: 1.46779 acc: 0.69987 | v_loss: 1.35416 v_acc: 0.70182 |  iteration: 16988 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 829 loss: 1.47737 acc: 0.68392 | v_loss: 1.24089 v_acc: 0.71126 |  iteration: 16989 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 830 loss: 1.45479 acc: 0.70475 | v_loss: 1.22937 v_acc: 0.70931 |  iteration: 16990 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 831 loss: 1.44278 acc: 0.69010 | v_loss: 1.25806 v_acc: 0.73307 |  iteration: 16991 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 832 loss: 1.43234 acc: 0.69727 | v_loss: 1.26643 v_acc: 0.72168 |  iteration: 16992 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 833 loss: 1.39864 acc: 0.70345 | v_loss: 1.34945 v_acc: 0.73145 |  iteration: 16993 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 834 loss: 1.37520 acc: 0.70508 | v_loss: 1.26944 v_acc: 0.72461 |  iteration: 16994 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 835 loss: 1.36901 acc: 0.71810 | v_loss: 1.31222 v_acc: 0.72005 |  iteration: 16995 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 836 loss: 1.52638 acc: 0.69368 | v_loss: 1.41653 v_acc: 0.71224 |  iteration: 16996 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 837 loss: 1.43578 acc: 0.70215 | v_loss: 1.39382 v_acc: 0.72070 |  iteration: 16997 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 838 loss: 1.39257 acc: 0.70605 | v_loss: 1.48118 v_acc: 0.69954 |  iteration: 16998 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 839 loss: 1.39332 acc: 0.71419 | v_loss: 1.41422 v_acc: 0.71615 |  iteration: 16999 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 840 loss: 1.36172 acc: 0.70280 | v_loss: 1.17407 v_acc: 0.74544 |  iteration: 17000 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 841 loss: 1.43692 acc: 0.69661 | v_loss: 1.24395 v_acc: 0.70931 |  iteration: 17001 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 842 loss: 1.35818 acc: 0.71322 | v_loss: 1.51947 v_acc: 0.70247 |  iteration: 17002 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 843 loss: 1.47657 acc: 0.69987 | v_loss: 1.20016 v_acc: 0.70866 |  iteration: 17003 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 844 loss: 1.45143 acc: 0.69889 | v_loss: 1.33426 v_acc: 0.71159 |  iteration: 17004 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 845 loss: 1.36149 acc: 0.71354 | v_loss: 1.37375 v_acc: 0.69336 |  iteration: 17005 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 846 loss: 1.32289 acc: 0.71094 | v_loss: 1.28823 v_acc: 0.71712 |  iteration: 17006 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 847 loss: 1.35824 acc: 0.71517 | v_loss: 1.36383 v_acc: 0.69629 |  iteration: 17007 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 848 loss: 1.43656 acc: 0.70508 | v_loss: 1.48067 v_acc: 0.71517 |  iteration: 17008 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 849 loss: 1.39904 acc: 0.70247 | v_loss: 1.32390 v_acc: 0.72689 |  iteration: 17009 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 850 loss: 1.58651 acc: 0.69271 | v_loss: 1.46955 v_acc: 0.70443 |  iteration: 17010 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 851 loss: 1.39946 acc: 0.71549 | v_loss: 1.35093 v_acc: 0.69922 |  iteration: 17011 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 852 loss: 1.44841 acc: 0.69987 | v_loss: 1.33377 v_acc: 0.70964 |  iteration: 17012 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 853 loss: 1.40127 acc: 0.70247 | v_loss: 1.53959 v_acc: 0.68913 |  iteration: 17013 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 854 loss: 1.41489 acc: 0.70964 | v_loss: 1.30970 v_acc: 0.72135 |  iteration: 17014 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 855 loss: 1.42626 acc: 0.69759 | v_loss: 1.57902 v_acc: 0.68294 |  iteration: 17015 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 856 loss: 1.51934 acc: 0.69661 | v_loss: 1.43657 v_acc: 0.69889 |  iteration: 17016 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 857 loss: 1.31593 acc: 0.71712 | v_loss: 1.51600 v_acc: 0.68978 |  iteration: 17017 teacher: 1 stage: sketch lr: 0.000339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 858 loss: 1.35712 acc: 0.70671 | v_loss: 1.37010 v_acc: 0.70182 |  iteration: 17018 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 859 loss: 1.42861 acc: 0.70540 | v_loss: 1.31483 v_acc: 0.70638 |  iteration: 17019 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 860 loss: 1.39608 acc: 0.70833 | v_loss: 1.32462 v_acc: 0.70410 |  iteration: 17020 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 861 loss: 1.49961 acc: 0.69564 | v_loss: 1.33105 v_acc: 0.71842 |  iteration: 17021 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 862 loss: 1.43319 acc: 0.69759 | v_loss: 1.57610 v_acc: 0.68978 |  iteration: 17022 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 863 loss: 1.46692 acc: 0.69889 | v_loss: 1.39219 v_acc: 0.71257 |  iteration: 17023 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 864 loss: 1.38050 acc: 0.70443 | v_loss: 1.33274 v_acc: 0.70866 |  iteration: 17024 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 865 loss: 1.50261 acc: 0.68848 | v_loss: 1.38988 v_acc: 0.71452 |  iteration: 17025 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 866 loss: 1.40958 acc: 0.69629 | v_loss: 1.26443 v_acc: 0.70605 |  iteration: 17026 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 867 loss: 1.53030 acc: 0.68913 | v_loss: 1.42849 v_acc: 0.70150 |  iteration: 17027 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 868 loss: 1.49335 acc: 0.70052 | v_loss: 1.43647 v_acc: 0.71322 |  iteration: 17028 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 869 loss: 1.38218 acc: 0.69987 | v_loss: 1.29312 v_acc: 0.71549 |  iteration: 17029 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 870 loss: 1.41809 acc: 0.69629 | v_loss: 1.26127 v_acc: 0.72721 |  iteration: 17030 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 871 loss: 1.42954 acc: 0.70247 | v_loss: 1.37939 v_acc: 0.71615 |  iteration: 17031 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 872 loss: 1.41177 acc: 0.70801 | v_loss: 1.42844 v_acc: 0.70540 |  iteration: 17032 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 873 loss: 1.38756 acc: 0.70833 | v_loss: 1.43526 v_acc: 0.70508 |  iteration: 17033 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 874 loss: 1.59578 acc: 0.68880 | v_loss: 1.23020 v_acc: 0.71712 |  iteration: 17034 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 875 loss: 1.40487 acc: 0.70736 | v_loss: 1.39675 v_acc: 0.72786 |  iteration: 17035 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 876 loss: 1.52019 acc: 0.69596 | v_loss: 1.47350 v_acc: 0.69792 |  iteration: 17036 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 877 loss: 1.51593 acc: 0.70020 | v_loss: 1.40790 v_acc: 0.72070 |  iteration: 17037 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 878 loss: 1.35494 acc: 0.71387 | v_loss: 1.24874 v_acc: 0.72201 |  iteration: 17038 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 879 loss: 1.53813 acc: 0.69173 | v_loss: 1.20643 v_acc: 0.74023 |  iteration: 17039 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 880 loss: 1.46513 acc: 0.69466 | v_loss: 1.21709 v_acc: 0.72493 |  iteration: 17040 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 881 loss: 1.47549 acc: 0.69499 | v_loss: 1.28213 v_acc: 0.71061 |  iteration: 17041 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 882 loss: 1.41796 acc: 0.70931 | v_loss: 1.45038 v_acc: 0.70671 |  iteration: 17042 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 883 loss: 1.38488 acc: 0.71224 | v_loss: 1.27192 v_acc: 0.71549 |  iteration: 17043 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 884 loss: 1.38972 acc: 0.70312 | v_loss: 1.44553 v_acc: 0.71647 |  iteration: 17044 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 885 loss: 1.47000 acc: 0.70703 | v_loss: 1.65134 v_acc: 0.69401 |  iteration: 17045 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 886 loss: 1.43365 acc: 0.69271 | v_loss: 1.51722 v_acc: 0.69922 |  iteration: 17046 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 887 loss: 1.40011 acc: 0.70931 | v_loss: 1.29070 v_acc: 0.72135 |  iteration: 17047 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 888 loss: 1.44281 acc: 0.69401 | v_loss: 1.37009 v_acc: 0.70215 |  iteration: 17048 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 889 loss: 1.42186 acc: 0.69531 | v_loss: 1.22639 v_acc: 0.72038 |  iteration: 17049 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 890 loss: 1.42916 acc: 0.69759 | v_loss: 1.42052 v_acc: 0.70020 |  iteration: 17050 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 891 loss: 1.46724 acc: 0.69987 | v_loss: 1.35465 v_acc: 0.71094 |  iteration: 17051 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 892 loss: 1.42908 acc: 0.69076 | v_loss: 1.35896 v_acc: 0.72852 |  iteration: 17052 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 893 loss: 1.48843 acc: 0.69368 | v_loss: 1.37624 v_acc: 0.71940 |  iteration: 17053 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 894 loss: 1.37343 acc: 0.71094 | v_loss: 1.37809 v_acc: 0.70964 |  iteration: 17054 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 895 loss: 1.48836 acc: 0.70410 | v_loss: 1.27842 v_acc: 0.72493 |  iteration: 17055 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 896 loss: 1.30250 acc: 0.71419 | v_loss: 1.29101 v_acc: 0.72038 |  iteration: 17056 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 897 loss: 1.47250 acc: 0.70605 | v_loss: 1.46914 v_acc: 0.69303 |  iteration: 17057 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 898 loss: 1.42698 acc: 0.70443 | v_loss: 1.33411 v_acc: 0.71159 |  iteration: 17058 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 899 loss: 1.44577 acc: 0.70280 | v_loss: 1.29288 v_acc: 0.71549 |  iteration: 17059 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 900 loss: 1.41764 acc: 0.69661 | v_loss: 1.27819 v_acc: 0.71940 |  iteration: 17060 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 901 loss: 1.54468 acc: 0.70117 | v_loss: 1.42658 v_acc: 0.70703 |  iteration: 17061 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 902 loss: 1.44889 acc: 0.70312 | v_loss: 1.31298 v_acc: 0.73047 |  iteration: 17062 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 903 loss: 1.41205 acc: 0.70671 | v_loss: 1.54025 v_acc: 0.71680 |  iteration: 17063 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 904 loss: 1.38849 acc: 0.70052 | v_loss: 1.28347 v_acc: 0.69727 |  iteration: 17064 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 905 loss: 1.36593 acc: 0.70671 | v_loss: 1.27917 v_acc: 0.70443 |  iteration: 17065 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 906 loss: 1.47985 acc: 0.70475 | v_loss: 1.45322 v_acc: 0.70312 |  iteration: 17066 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 907 loss: 1.51731 acc: 0.69889 | v_loss: 1.48299 v_acc: 0.70378 |  iteration: 17067 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 908 loss: 1.35415 acc: 0.70671 | v_loss: 1.53160 v_acc: 0.68978 |  iteration: 17068 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 909 loss: 1.51220 acc: 0.70475 | v_loss: 1.46554 v_acc: 0.70638 |  iteration: 17069 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 910 loss: 1.50030 acc: 0.69824 | v_loss: 1.42864 v_acc: 0.70410 |  iteration: 17070 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 911 loss: 1.27242 acc: 0.72201 | v_loss: 1.42020 v_acc: 0.70768 |  iteration: 17071 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 912 loss: 1.52320 acc: 0.68424 | v_loss: 1.38502 v_acc: 0.70475 |  iteration: 17072 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 913 loss: 1.41247 acc: 0.71061 | v_loss: 1.25198 v_acc: 0.71354 |  iteration: 17073 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 914 loss: 1.51695 acc: 0.69922 | v_loss: 1.32917 v_acc: 0.72461 |  iteration: 17074 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 915 loss: 1.47202 acc: 0.69499 | v_loss: 1.18260 v_acc: 0.71517 |  iteration: 17075 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 916 loss: 1.40143 acc: 0.69792 | v_loss: 1.33968 v_acc: 0.70703 |  iteration: 17076 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 917 loss: 1.37273 acc: 0.70671 | v_loss: 1.50787 v_acc: 0.70020 |  iteration: 17077 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 918 loss: 1.42596 acc: 0.70052 | v_loss: 1.32424 v_acc: 0.71419 |  iteration: 17078 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 919 loss: 1.36270 acc: 0.70833 | v_loss: 1.35788 v_acc: 0.70312 |  iteration: 17079 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 920 loss: 1.35676 acc: 0.70866 | v_loss: 1.24267 v_acc: 0.71680 |  iteration: 17080 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 921 loss: 1.53003 acc: 0.70020 | v_loss: 1.24372 v_acc: 0.70671 |  iteration: 17081 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 922 loss: 1.38846 acc: 0.70671 | v_loss: 1.23932 v_acc: 0.73503 |  iteration: 17082 teacher: 0 stage: sketch lr: 0.000338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 923 loss: 1.46953 acc: 0.69694 | v_loss: 1.26109 v_acc: 0.72168 |  iteration: 17083 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 924 loss: 1.41654 acc: 0.69922 | v_loss: 1.34655 v_acc: 0.73145 |  iteration: 17084 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 925 loss: 1.37933 acc: 0.71842 | v_loss: 1.26434 v_acc: 0.72070 |  iteration: 17085 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 926 loss: 1.42029 acc: 0.70410 | v_loss: 1.31526 v_acc: 0.71419 |  iteration: 17086 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 927 loss: 1.46136 acc: 0.70996 | v_loss: 1.42621 v_acc: 0.71289 |  iteration: 17087 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 928 loss: 1.42117 acc: 0.69954 | v_loss: 1.40620 v_acc: 0.71680 |  iteration: 17088 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 929 loss: 1.46964 acc: 0.70150 | v_loss: 1.49038 v_acc: 0.69792 |  iteration: 17089 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 930 loss: 1.37038 acc: 0.71289 | v_loss: 1.42578 v_acc: 0.71973 |  iteration: 17090 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 931 loss: 1.43227 acc: 0.70410 | v_loss: 1.17561 v_acc: 0.74544 |  iteration: 17091 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 932 loss: 1.47779 acc: 0.70573 | v_loss: 1.26031 v_acc: 0.70573 |  iteration: 17092 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 933 loss: 1.29417 acc: 0.70964 | v_loss: 1.51550 v_acc: 0.70182 |  iteration: 17093 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 934 loss: 1.41456 acc: 0.70117 | v_loss: 1.22003 v_acc: 0.70866 |  iteration: 17094 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 935 loss: 1.46338 acc: 0.70247 | v_loss: 1.32418 v_acc: 0.71159 |  iteration: 17095 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 936 loss: 1.45372 acc: 0.69596 | v_loss: 1.36253 v_acc: 0.69336 |  iteration: 17096 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 937 loss: 1.46422 acc: 0.70345 | v_loss: 1.29045 v_acc: 0.71191 |  iteration: 17097 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 938 loss: 1.47828 acc: 0.69206 | v_loss: 1.35328 v_acc: 0.69629 |  iteration: 17098 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 939 loss: 1.52194 acc: 0.69694 | v_loss: 1.47654 v_acc: 0.71647 |  iteration: 17099 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 940 loss: 1.47576 acc: 0.70671 | v_loss: 1.32156 v_acc: 0.72852 |  iteration: 17100 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 941 loss: 1.45076 acc: 0.70703 | v_loss: 1.45909 v_acc: 0.70508 |  iteration: 17101 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 942 loss: 1.41406 acc: 0.70280 | v_loss: 1.35718 v_acc: 0.69954 |  iteration: 17102 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 943 loss: 1.44599 acc: 0.69596 | v_loss: 1.32245 v_acc: 0.70833 |  iteration: 17103 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 944 loss: 1.41597 acc: 0.70378 | v_loss: 1.53967 v_acc: 0.68848 |  iteration: 17104 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 945 loss: 1.41592 acc: 0.70833 | v_loss: 1.30551 v_acc: 0.72005 |  iteration: 17105 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 946 loss: 1.42956 acc: 0.69694 | v_loss: 1.57835 v_acc: 0.68424 |  iteration: 17106 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 947 loss: 1.42757 acc: 0.69596 | v_loss: 1.43303 v_acc: 0.69889 |  iteration: 17107 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 948 loss: 1.48478 acc: 0.69206 | v_loss: 1.52529 v_acc: 0.68978 |  iteration: 17108 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 949 loss: 1.47050 acc: 0.69336 | v_loss: 1.36495 v_acc: 0.69792 |  iteration: 17109 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 950 loss: 1.37644 acc: 0.71061 | v_loss: 1.31841 v_acc: 0.70345 |  iteration: 17110 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 951 loss: 1.49493 acc: 0.70182 | v_loss: 1.32069 v_acc: 0.70410 |  iteration: 17111 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 952 loss: 1.38008 acc: 0.71061 | v_loss: 1.32659 v_acc: 0.71842 |  iteration: 17112 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 953 loss: 1.54369 acc: 0.69661 | v_loss: 1.55745 v_acc: 0.69108 |  iteration: 17113 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 954 loss: 1.32108 acc: 0.71777 | v_loss: 1.38722 v_acc: 0.71126 |  iteration: 17114 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 955 loss: 1.40874 acc: 0.70638 | v_loss: 1.33709 v_acc: 0.71029 |  iteration: 17115 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 956 loss: 1.56913 acc: 0.69010 | v_loss: 1.38725 v_acc: 0.71680 |  iteration: 17116 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 957 loss: 1.59253 acc: 0.69564 | v_loss: 1.26935 v_acc: 0.70540 |  iteration: 17117 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 958 loss: 1.41053 acc: 0.70150 | v_loss: 1.43433 v_acc: 0.69792 |  iteration: 17118 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 959 loss: 1.51548 acc: 0.71126 | v_loss: 1.43130 v_acc: 0.71289 |  iteration: 17119 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 960 loss: 1.40388 acc: 0.70638 | v_loss: 1.28098 v_acc: 0.71810 |  iteration: 17120 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 961 loss: 1.41714 acc: 0.70475 | v_loss: 1.26101 v_acc: 0.72754 |  iteration: 17121 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 962 loss: 1.36428 acc: 0.70378 | v_loss: 1.37534 v_acc: 0.71973 |  iteration: 17122 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 963 loss: 1.48688 acc: 0.69824 | v_loss: 1.42462 v_acc: 0.70345 |  iteration: 17123 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 964 loss: 1.34221 acc: 0.70866 | v_loss: 1.43042 v_acc: 0.70410 |  iteration: 17124 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 965 loss: 1.41707 acc: 0.69564 | v_loss: 1.23228 v_acc: 0.71712 |  iteration: 17125 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 966 loss: 1.36040 acc: 0.70931 | v_loss: 1.40081 v_acc: 0.72786 |  iteration: 17126 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 967 loss: 1.39858 acc: 0.69531 | v_loss: 1.47971 v_acc: 0.69792 |  iteration: 17127 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 968 loss: 1.44850 acc: 0.69824 | v_loss: 1.41407 v_acc: 0.72070 |  iteration: 17128 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 969 loss: 1.45615 acc: 0.69857 | v_loss: 1.23777 v_acc: 0.72233 |  iteration: 17129 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 970 loss: 1.42892 acc: 0.70150 | v_loss: 1.18387 v_acc: 0.74447 |  iteration: 17130 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 971 loss: 1.55780 acc: 0.68783 | v_loss: 1.20787 v_acc: 0.72493 |  iteration: 17131 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 972 loss: 1.35713 acc: 0.70768 | v_loss: 1.27277 v_acc: 0.71126 |  iteration: 17132 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 973 loss: 1.49164 acc: 0.70150 | v_loss: 1.44271 v_acc: 0.70671 |  iteration: 17133 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 974 loss: 1.41148 acc: 0.70345 | v_loss: 1.27699 v_acc: 0.71549 |  iteration: 17134 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 975 loss: 1.47711 acc: 0.70150 | v_loss: 1.47275 v_acc: 0.70866 |  iteration: 17135 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 976 loss: 1.41398 acc: 0.70475 | v_loss: 1.66991 v_acc: 0.69303 |  iteration: 17136 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 977 loss: 1.48246 acc: 0.70052 | v_loss: 1.52104 v_acc: 0.70117 |  iteration: 17137 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 978 loss: 1.38166 acc: 0.70508 | v_loss: 1.29011 v_acc: 0.72363 |  iteration: 17138 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 979 loss: 1.51755 acc: 0.68750 | v_loss: 1.37079 v_acc: 0.70280 |  iteration: 17139 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 980 loss: 1.48768 acc: 0.69043 | v_loss: 1.22320 v_acc: 0.72135 |  iteration: 17140 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 981 loss: 1.40319 acc: 0.70117 | v_loss: 1.41707 v_acc: 0.70020 |  iteration: 17141 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 982 loss: 1.46282 acc: 0.70410 | v_loss: 1.35594 v_acc: 0.71094 |  iteration: 17142 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 983 loss: 1.38731 acc: 0.70280 | v_loss: 1.34754 v_acc: 0.72949 |  iteration: 17143 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 984 loss: 1.41489 acc: 0.70833 | v_loss: 1.35459 v_acc: 0.71810 |  iteration: 17144 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 985 loss: 1.39026 acc: 0.69889 | v_loss: 1.36800 v_acc: 0.70508 |  iteration: 17145 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 986 loss: 1.50847 acc: 0.69141 | v_loss: 1.28245 v_acc: 0.72201 |  iteration: 17146 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 987 loss: 1.36180 acc: 0.71224 | v_loss: 1.29078 v_acc: 0.72005 |  iteration: 17147 teacher: 0 stage: sketch lr: 0.000337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 988 loss: 1.39594 acc: 0.70638 | v_loss: 1.49231 v_acc: 0.69271 |  iteration: 17148 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 989 loss: 1.41317 acc: 0.71452 | v_loss: 1.32563 v_acc: 0.71419 |  iteration: 17149 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 990 loss: 1.42464 acc: 0.69434 | v_loss: 1.29708 v_acc: 0.71777 |  iteration: 17150 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 991 loss: 1.49602 acc: 0.69076 | v_loss: 1.29234 v_acc: 0.71484 |  iteration: 17151 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 992 loss: 1.43513 acc: 0.69661 | v_loss: 1.43508 v_acc: 0.70508 |  iteration: 17152 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 993 loss: 1.28773 acc: 0.70443 | v_loss: 1.31383 v_acc: 0.73047 |  iteration: 17153 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 994 loss: 1.54049 acc: 0.69694 | v_loss: 1.55671 v_acc: 0.71582 |  iteration: 17154 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 995 loss: 1.40387 acc: 0.69661 | v_loss: 1.27781 v_acc: 0.69922 |  iteration: 17155 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 996 loss: 1.46968 acc: 0.69271 | v_loss: 1.27355 v_acc: 0.70443 |  iteration: 17156 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 997 loss: 1.43364 acc: 0.70703 | v_loss: 1.45422 v_acc: 0.70312 |  iteration: 17157 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 998 loss: 1.47320 acc: 0.69629 | v_loss: 1.48235 v_acc: 0.70378 |  iteration: 17158 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 999 loss: 1.45258 acc: 0.70378 | v_loss: 1.52275 v_acc: 0.68978 |  iteration: 17159 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1000 loss: 1.40324 acc: 0.71029 | v_loss: 1.46279 v_acc: 0.70638 |  iteration: 17160 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1001 loss: 1.40304 acc: 0.70117 | v_loss: 1.41671 v_acc: 0.70703 |  iteration: 17161 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1002 loss: 1.38688 acc: 0.70247 | v_loss: 1.40641 v_acc: 0.70638 |  iteration: 17162 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1003 loss: 1.45025 acc: 0.69531 | v_loss: 1.40283 v_acc: 0.70736 |  iteration: 17163 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1004 loss: 1.40559 acc: 0.70573 | v_loss: 1.26701 v_acc: 0.71029 |  iteration: 17164 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1005 loss: 1.41741 acc: 0.70345 | v_loss: 1.32237 v_acc: 0.72298 |  iteration: 17165 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1006 loss: 1.40149 acc: 0.69889 | v_loss: 1.19187 v_acc: 0.70638 |  iteration: 17166 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1007 loss: 1.45708 acc: 0.69564 | v_loss: 1.34009 v_acc: 0.70247 |  iteration: 17167 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1008 loss: 1.47011 acc: 0.69759 | v_loss: 1.51061 v_acc: 0.69987 |  iteration: 17168 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1009 loss: 1.36679 acc: 0.70443 | v_loss: 1.33040 v_acc: 0.71029 |  iteration: 17169 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1010 loss: 1.44702 acc: 0.70020 | v_loss: 1.36824 v_acc: 0.70312 |  iteration: 17170 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1011 loss: 1.36449 acc: 0.70247 | v_loss: 1.23300 v_acc: 0.71680 |  iteration: 17171 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1012 loss: 1.39442 acc: 0.71029 | v_loss: 1.24332 v_acc: 0.70671 |  iteration: 17172 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1013 loss: 1.45487 acc: 0.68620 | v_loss: 1.24478 v_acc: 0.73568 |  iteration: 17173 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1014 loss: 1.46538 acc: 0.69857 | v_loss: 1.25535 v_acc: 0.72461 |  iteration: 17174 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1015 loss: 1.44389 acc: 0.69922 | v_loss: 1.33303 v_acc: 0.72884 |  iteration: 17175 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1016 loss: 1.40678 acc: 0.70931 | v_loss: 1.25630 v_acc: 0.72461 |  iteration: 17176 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1017 loss: 1.42685 acc: 0.70378 | v_loss: 1.29954 v_acc: 0.72135 |  iteration: 17177 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1018 loss: 1.48000 acc: 0.70020 | v_loss: 1.40596 v_acc: 0.71289 |  iteration: 17178 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1019 loss: 1.37423 acc: 0.70996 | v_loss: 1.38636 v_acc: 0.72298 |  iteration: 17179 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1020 loss: 1.43472 acc: 0.70215 | v_loss: 1.48872 v_acc: 0.69922 |  iteration: 17180 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1021 loss: 1.39601 acc: 0.70312 | v_loss: 1.42047 v_acc: 0.71973 |  iteration: 17181 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1022 loss: 1.49793 acc: 0.69564 | v_loss: 1.17827 v_acc: 0.74316 |  iteration: 17182 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1023 loss: 1.42240 acc: 0.71257 | v_loss: 1.27407 v_acc: 0.70247 |  iteration: 17183 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1024 loss: 1.46706 acc: 0.69238 | v_loss: 1.49791 v_acc: 0.70866 |  iteration: 17184 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1025 loss: 1.47551 acc: 0.69531 | v_loss: 1.22061 v_acc: 0.72363 |  iteration: 17185 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1026 loss: 1.38504 acc: 0.70410 | v_loss: 1.31953 v_acc: 0.71745 |  iteration: 17186 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1027 loss: 1.43587 acc: 0.71094 | v_loss: 1.36071 v_acc: 0.69303 |  iteration: 17187 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1028 loss: 1.44268 acc: 0.69954 | v_loss: 1.30354 v_acc: 0.71191 |  iteration: 17188 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1029 loss: 1.42996 acc: 0.70801 | v_loss: 1.36428 v_acc: 0.69629 |  iteration: 17189 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1030 loss: 1.40970 acc: 0.69954 | v_loss: 1.45599 v_acc: 0.71517 |  iteration: 17190 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1031 loss: 1.35989 acc: 0.71126 | v_loss: 1.31223 v_acc: 0.72689 |  iteration: 17191 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1032 loss: 1.50289 acc: 0.69303 | v_loss: 1.43601 v_acc: 0.70540 |  iteration: 17192 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1033 loss: 1.32802 acc: 0.71289 | v_loss: 1.37241 v_acc: 0.69857 |  iteration: 17193 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1034 loss: 1.41043 acc: 0.70280 | v_loss: 1.31493 v_acc: 0.70833 |  iteration: 17194 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1035 loss: 1.47283 acc: 0.69824 | v_loss: 1.55096 v_acc: 0.68848 |  iteration: 17195 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1036 loss: 1.48077 acc: 0.69889 | v_loss: 1.30694 v_acc: 0.72005 |  iteration: 17196 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1037 loss: 1.50174 acc: 0.70312 | v_loss: 1.59279 v_acc: 0.68424 |  iteration: 17197 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1038 loss: 1.39324 acc: 0.70768 | v_loss: 1.45170 v_acc: 0.69792 |  iteration: 17198 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1039 loss: 1.37909 acc: 0.70475 | v_loss: 1.53247 v_acc: 0.69173 |  iteration: 17199 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1040 loss: 1.42466 acc: 0.71419 | v_loss: 1.37660 v_acc: 0.70020 |  iteration: 17200 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1041 loss: 1.37954 acc: 0.69792 | v_loss: 1.32781 v_acc: 0.70345 |  iteration: 17201 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1042 loss: 1.50744 acc: 0.69922 | v_loss: 1.33045 v_acc: 0.70020 |  iteration: 17202 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1043 loss: 1.37784 acc: 0.70703 | v_loss: 1.32571 v_acc: 0.71484 |  iteration: 17203 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1044 loss: 1.40890 acc: 0.70866 | v_loss: 1.54228 v_acc: 0.68978 |  iteration: 17204 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1045 loss: 1.40024 acc: 0.72266 | v_loss: 1.38219 v_acc: 0.70443 |  iteration: 17205 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1046 loss: 1.47453 acc: 0.70117 | v_loss: 1.35311 v_acc: 0.71029 |  iteration: 17206 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1047 loss: 1.44442 acc: 0.70020 | v_loss: 1.38235 v_acc: 0.71452 |  iteration: 17207 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1048 loss: 1.43970 acc: 0.70150 | v_loss: 1.26564 v_acc: 0.70736 |  iteration: 17208 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1049 loss: 1.28478 acc: 0.72005 | v_loss: 1.43625 v_acc: 0.70052 |  iteration: 17209 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1050 loss: 1.44862 acc: 0.70117 | v_loss: 1.42952 v_acc: 0.71257 |  iteration: 17210 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1051 loss: 1.48191 acc: 0.70410 | v_loss: 1.28168 v_acc: 0.72201 |  iteration: 17211 teacher: 1 stage: sketch lr: 0.000337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1052 loss: 1.48730 acc: 0.69531 | v_loss: 1.25004 v_acc: 0.72591 |  iteration: 17212 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1053 loss: 1.40388 acc: 0.71615 | v_loss: 1.37131 v_acc: 0.71940 |  iteration: 17213 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1054 loss: 1.46892 acc: 0.70215 | v_loss: 1.41960 v_acc: 0.70345 |  iteration: 17214 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1055 loss: 1.42657 acc: 0.71029 | v_loss: 1.42614 v_acc: 0.70410 |  iteration: 17215 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1056 loss: 1.43287 acc: 0.70117 | v_loss: 1.22637 v_acc: 0.71712 |  iteration: 17216 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1057 loss: 1.33673 acc: 0.70475 | v_loss: 1.38732 v_acc: 0.72786 |  iteration: 17217 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1058 loss: 1.36883 acc: 0.71517 | v_loss: 1.47479 v_acc: 0.69792 |  iteration: 17218 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1059 loss: 1.43155 acc: 0.69727 | v_loss: 1.41854 v_acc: 0.72070 |  iteration: 17219 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1060 loss: 1.42108 acc: 0.70508 | v_loss: 1.24187 v_acc: 0.72201 |  iteration: 17220 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1061 loss: 1.51118 acc: 0.69922 | v_loss: 1.19117 v_acc: 0.74023 |  iteration: 17221 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1062 loss: 1.45095 acc: 0.69661 | v_loss: 1.20669 v_acc: 0.72559 |  iteration: 17222 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1063 loss: 1.48692 acc: 0.69629 | v_loss: 1.27635 v_acc: 0.70638 |  iteration: 17223 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1064 loss: 1.31312 acc: 0.71257 | v_loss: 1.45140 v_acc: 0.70671 |  iteration: 17224 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1065 loss: 1.51025 acc: 0.69759 | v_loss: 1.27474 v_acc: 0.71549 |  iteration: 17225 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1066 loss: 1.51881 acc: 0.69401 | v_loss: 1.48140 v_acc: 0.70605 |  iteration: 17226 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1067 loss: 1.46007 acc: 0.69759 | v_loss: 1.67673 v_acc: 0.69141 |  iteration: 17227 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1068 loss: 1.51982 acc: 0.69401 | v_loss: 1.51603 v_acc: 0.69922 |  iteration: 17228 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1069 loss: 1.41314 acc: 0.70801 | v_loss: 1.29358 v_acc: 0.72135 |  iteration: 17229 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1070 loss: 1.46103 acc: 0.69792 | v_loss: 1.36170 v_acc: 0.70280 |  iteration: 17230 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1071 loss: 1.48429 acc: 0.70345 | v_loss: 1.22355 v_acc: 0.72070 |  iteration: 17231 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1072 loss: 1.44588 acc: 0.70964 | v_loss: 1.40915 v_acc: 0.69596 |  iteration: 17232 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1073 loss: 1.35823 acc: 0.70833 | v_loss: 1.36187 v_acc: 0.70768 |  iteration: 17233 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1074 loss: 1.49587 acc: 0.69466 | v_loss: 1.34660 v_acc: 0.72852 |  iteration: 17234 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1075 loss: 1.50284 acc: 0.69531 | v_loss: 1.34629 v_acc: 0.71582 |  iteration: 17235 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1076 loss: 1.44784 acc: 0.70378 | v_loss: 1.37346 v_acc: 0.70052 |  iteration: 17236 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1077 loss: 1.37592 acc: 0.71647 | v_loss: 1.29333 v_acc: 0.72363 |  iteration: 17237 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1078 loss: 1.44520 acc: 0.70801 | v_loss: 1.30025 v_acc: 0.72005 |  iteration: 17238 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1079 loss: 1.46125 acc: 0.70540 | v_loss: 1.50803 v_acc: 0.69303 |  iteration: 17239 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1080 loss: 1.46794 acc: 0.70052 | v_loss: 1.33212 v_acc: 0.71159 |  iteration: 17240 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1081 loss: 1.43691 acc: 0.69629 | v_loss: 1.29353 v_acc: 0.71549 |  iteration: 17241 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1082 loss: 1.40256 acc: 0.70866 | v_loss: 1.28131 v_acc: 0.71973 |  iteration: 17242 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1083 loss: 1.34159 acc: 0.70605 | v_loss: 1.43200 v_acc: 0.70508 |  iteration: 17243 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1084 loss: 1.41792 acc: 0.71159 | v_loss: 1.31379 v_acc: 0.73047 |  iteration: 17244 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1085 loss: 1.47007 acc: 0.70801 | v_loss: 1.55436 v_acc: 0.71582 |  iteration: 17245 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1086 loss: 1.36425 acc: 0.71191 | v_loss: 1.27720 v_acc: 0.70150 |  iteration: 17246 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1087 loss: 1.53693 acc: 0.69661 | v_loss: 1.26811 v_acc: 0.70573 |  iteration: 17247 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 1088 loss: 1.37311 acc: 0.71224 | v_loss: 1.43589 v_acc: 0.70378 |  iteration: 17248 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 1089 loss: 1.43194 acc: 0.69824 | v_loss: 1.47082 v_acc: 0.70150 |  iteration: 17249 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1090 loss: 1.49139 acc: 0.68945 | v_loss: 1.50747 v_acc: 0.69466 |  iteration: 17250 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1091 loss: 1.38060 acc: 0.70671 | v_loss: 1.46387 v_acc: 0.70605 |  iteration: 17251 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1092 loss: 1.45096 acc: 0.70345 | v_loss: 1.41369 v_acc: 0.70736 |  iteration: 17252 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1093 loss: 1.45794 acc: 0.70573 | v_loss: 1.39736 v_acc: 0.70703 |  iteration: 17253 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1094 loss: 1.39164 acc: 0.70801 | v_loss: 1.41571 v_acc: 0.70443 |  iteration: 17254 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1095 loss: 1.28674 acc: 0.71257 | v_loss: 1.26929 v_acc: 0.71159 |  iteration: 17255 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1096 loss: 1.38930 acc: 0.70573 | v_loss: 1.31270 v_acc: 0.72396 |  iteration: 17256 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1097 loss: 1.32268 acc: 0.71419 | v_loss: 1.19806 v_acc: 0.71224 |  iteration: 17257 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1098 loss: 1.42022 acc: 0.69857 | v_loss: 1.34447 v_acc: 0.70703 |  iteration: 17258 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1099 loss: 1.41066 acc: 0.70801 | v_loss: 1.50937 v_acc: 0.69987 |  iteration: 17259 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1100 loss: 1.40512 acc: 0.70378 | v_loss: 1.33730 v_acc: 0.70833 |  iteration: 17260 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1101 loss: 1.46161 acc: 0.70280 | v_loss: 1.35348 v_acc: 0.69727 |  iteration: 17261 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1102 loss: 1.47475 acc: 0.70085 | v_loss: 1.24474 v_acc: 0.71126 |  iteration: 17262 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1103 loss: 1.40429 acc: 0.70866 | v_loss: 1.23992 v_acc: 0.70671 |  iteration: 17263 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1104 loss: 1.45806 acc: 0.70150 | v_loss: 1.23891 v_acc: 0.73568 |  iteration: 17264 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1105 loss: 1.42715 acc: 0.70052 | v_loss: 1.25904 v_acc: 0.72461 |  iteration: 17265 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1106 loss: 1.48699 acc: 0.69531 | v_loss: 1.35067 v_acc: 0.72689 |  iteration: 17266 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1107 loss: 1.41638 acc: 0.70247 | v_loss: 1.26047 v_acc: 0.72852 |  iteration: 17267 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1108 loss: 1.44565 acc: 0.70573 | v_loss: 1.30161 v_acc: 0.72103 |  iteration: 17268 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1109 loss: 1.36839 acc: 0.70964 | v_loss: 1.41127 v_acc: 0.71354 |  iteration: 17269 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1110 loss: 1.39632 acc: 0.70671 | v_loss: 1.39569 v_acc: 0.72428 |  iteration: 17270 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1111 loss: 1.53333 acc: 0.68880 | v_loss: 1.48135 v_acc: 0.70182 |  iteration: 17271 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1112 loss: 1.45003 acc: 0.70150 | v_loss: 1.41022 v_acc: 0.71777 |  iteration: 17272 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1113 loss: 1.42766 acc: 0.70833 | v_loss: 1.17382 v_acc: 0.74447 |  iteration: 17273 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1114 loss: 1.36164 acc: 0.70736 | v_loss: 1.24895 v_acc: 0.71354 |  iteration: 17274 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1115 loss: 1.47379 acc: 0.70345 | v_loss: 1.50885 v_acc: 0.70247 |  iteration: 17275 teacher: 0 stage: sketch lr: 0.000336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1116 loss: 1.49764 acc: 0.70052 | v_loss: 1.21345 v_acc: 0.70833 |  iteration: 17276 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1117 loss: 1.48333 acc: 0.69922 | v_loss: 1.32902 v_acc: 0.71159 |  iteration: 17277 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1118 loss: 1.47581 acc: 0.70052 | v_loss: 1.36704 v_acc: 0.69336 |  iteration: 17278 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1119 loss: 1.48412 acc: 0.70736 | v_loss: 1.29528 v_acc: 0.71191 |  iteration: 17279 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1120 loss: 1.50037 acc: 0.70703 | v_loss: 1.37145 v_acc: 0.69629 |  iteration: 17280 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1121 loss: 1.35795 acc: 0.70605 | v_loss: 1.47088 v_acc: 0.71517 |  iteration: 17281 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1122 loss: 1.47919 acc: 0.69629 | v_loss: 1.31713 v_acc: 0.72689 |  iteration: 17282 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1123 loss: 1.39617 acc: 0.71680 | v_loss: 1.43862 v_acc: 0.70508 |  iteration: 17283 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1124 loss: 1.43894 acc: 0.70736 | v_loss: 1.36355 v_acc: 0.70052 |  iteration: 17284 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1125 loss: 1.47033 acc: 0.69336 | v_loss: 1.32478 v_acc: 0.70898 |  iteration: 17285 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1126 loss: 1.38776 acc: 0.70866 | v_loss: 1.54187 v_acc: 0.68815 |  iteration: 17286 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1127 loss: 1.40529 acc: 0.70312 | v_loss: 1.29277 v_acc: 0.72005 |  iteration: 17287 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1128 loss: 1.45601 acc: 0.70247 | v_loss: 1.59455 v_acc: 0.68424 |  iteration: 17288 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1129 loss: 1.35112 acc: 0.70182 | v_loss: 1.46780 v_acc: 0.69661 |  iteration: 17289 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1130 loss: 1.47218 acc: 0.69629 | v_loss: 1.53398 v_acc: 0.69466 |  iteration: 17290 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1131 loss: 1.43900 acc: 0.70215 | v_loss: 1.38682 v_acc: 0.70020 |  iteration: 17291 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1132 loss: 1.37288 acc: 0.70703 | v_loss: 1.32720 v_acc: 0.70540 |  iteration: 17292 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1133 loss: 1.40994 acc: 0.70508 | v_loss: 1.33212 v_acc: 0.70280 |  iteration: 17293 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1134 loss: 1.43929 acc: 0.70801 | v_loss: 1.33878 v_acc: 0.72038 |  iteration: 17294 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1135 loss: 1.47410 acc: 0.70182 | v_loss: 1.54737 v_acc: 0.69108 |  iteration: 17295 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1136 loss: 1.50173 acc: 0.69238 | v_loss: 1.37588 v_acc: 0.71029 |  iteration: 17296 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1137 loss: 1.48571 acc: 0.69499 | v_loss: 1.34128 v_acc: 0.71029 |  iteration: 17297 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1138 loss: 1.43399 acc: 0.69759 | v_loss: 1.38561 v_acc: 0.71680 |  iteration: 17298 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1139 loss: 1.41967 acc: 0.70020 | v_loss: 1.27614 v_acc: 0.70443 |  iteration: 17299 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1140 loss: 1.31576 acc: 0.72201 | v_loss: 1.42111 v_acc: 0.69596 |  iteration: 17300 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1141 loss: 1.51008 acc: 0.69629 | v_loss: 1.43483 v_acc: 0.71549 |  iteration: 17301 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1142 loss: 1.33671 acc: 0.70768 | v_loss: 1.31493 v_acc: 0.71647 |  iteration: 17302 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1143 loss: 1.50303 acc: 0.70931 | v_loss: 1.25808 v_acc: 0.72201 |  iteration: 17303 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1144 loss: 1.43029 acc: 0.70931 | v_loss: 1.36474 v_acc: 0.71549 |  iteration: 17304 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1145 loss: 1.40092 acc: 0.70638 | v_loss: 1.42400 v_acc: 0.70215 |  iteration: 17305 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1146 loss: 1.53927 acc: 0.69401 | v_loss: 1.42924 v_acc: 0.70573 |  iteration: 17306 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1147 loss: 1.42303 acc: 0.71159 | v_loss: 1.24187 v_acc: 0.71777 |  iteration: 17307 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1148 loss: 1.35552 acc: 0.70671 | v_loss: 1.38294 v_acc: 0.72786 |  iteration: 17308 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1149 loss: 1.47239 acc: 0.69857 | v_loss: 1.47076 v_acc: 0.69792 |  iteration: 17309 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1150 loss: 1.52309 acc: 0.69727 | v_loss: 1.42521 v_acc: 0.72201 |  iteration: 17310 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1151 loss: 1.52147 acc: 0.70215 | v_loss: 1.25192 v_acc: 0.72233 |  iteration: 17311 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1152 loss: 1.45872 acc: 0.70345 | v_loss: 1.19631 v_acc: 0.74349 |  iteration: 17312 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1153 loss: 1.52682 acc: 0.70215 | v_loss: 1.20795 v_acc: 0.72396 |  iteration: 17313 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1154 loss: 1.43852 acc: 0.69629 | v_loss: 1.27317 v_acc: 0.71126 |  iteration: 17314 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1155 loss: 1.52900 acc: 0.69434 | v_loss: 1.44358 v_acc: 0.70215 |  iteration: 17315 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1156 loss: 1.38985 acc: 0.70866 | v_loss: 1.28712 v_acc: 0.71224 |  iteration: 17316 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1157 loss: 1.39325 acc: 0.70378 | v_loss: 1.45900 v_acc: 0.71517 |  iteration: 17317 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1158 loss: 1.41206 acc: 0.69857 | v_loss: 1.66894 v_acc: 0.68978 |  iteration: 17318 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1159 loss: 1.41476 acc: 0.69792 | v_loss: 1.53354 v_acc: 0.69694 |  iteration: 17319 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1160 loss: 1.44318 acc: 0.69596 | v_loss: 1.29152 v_acc: 0.72233 |  iteration: 17320 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1161 loss: 1.39388 acc: 0.69792 | v_loss: 1.37883 v_acc: 0.70215 |  iteration: 17321 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1162 loss: 1.39076 acc: 0.69954 | v_loss: 1.23482 v_acc: 0.72005 |  iteration: 17322 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1163 loss: 1.45318 acc: 0.70833 | v_loss: 1.43604 v_acc: 0.70150 |  iteration: 17323 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1164 loss: 1.48216 acc: 0.70378 | v_loss: 1.36083 v_acc: 0.71029 |  iteration: 17324 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1165 loss: 1.43873 acc: 0.69401 | v_loss: 1.35997 v_acc: 0.73079 |  iteration: 17325 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1166 loss: 1.48765 acc: 0.69010 | v_loss: 1.37071 v_acc: 0.71777 |  iteration: 17326 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1167 loss: 1.44209 acc: 0.69629 | v_loss: 1.37263 v_acc: 0.70964 |  iteration: 17327 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1168 loss: 1.48353 acc: 0.69727 | v_loss: 1.28997 v_acc: 0.72461 |  iteration: 17328 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1169 loss: 1.44784 acc: 0.70215 | v_loss: 1.30892 v_acc: 0.72103 |  iteration: 17329 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1170 loss: 1.37214 acc: 0.70768 | v_loss: 1.51066 v_acc: 0.69368 |  iteration: 17330 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1171 loss: 1.40699 acc: 0.70703 | v_loss: 1.33014 v_acc: 0.71159 |  iteration: 17331 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1172 loss: 1.44108 acc: 0.69661 | v_loss: 1.29409 v_acc: 0.71549 |  iteration: 17332 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1173 loss: 1.54392 acc: 0.69466 | v_loss: 1.28247 v_acc: 0.71940 |  iteration: 17333 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1174 loss: 1.31310 acc: 0.71159 | v_loss: 1.42447 v_acc: 0.70475 |  iteration: 17334 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1175 loss: 1.49601 acc: 0.69596 | v_loss: 1.30478 v_acc: 0.73210 |  iteration: 17335 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1176 loss: 1.31780 acc: 0.71647 | v_loss: 1.52458 v_acc: 0.71680 |  iteration: 17336 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1177 loss: 1.40684 acc: 0.71257 | v_loss: 1.29429 v_acc: 0.69661 |  iteration: 17337 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1178 loss: 1.40471 acc: 0.70508 | v_loss: 1.28334 v_acc: 0.70638 |  iteration: 17338 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1179 loss: 1.42612 acc: 0.70052 | v_loss: 1.44360 v_acc: 0.70573 |  iteration: 17339 teacher: 1 stage: sketch lr: 0.000336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1180 loss: 1.42673 acc: 0.71257 | v_loss: 1.47142 v_acc: 0.70768 |  iteration: 17340 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1181 loss: 1.45869 acc: 0.69922 | v_loss: 1.51209 v_acc: 0.68815 |  iteration: 17341 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1182 loss: 1.44035 acc: 0.71061 | v_loss: 1.45843 v_acc: 0.70378 |  iteration: 17342 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1183 loss: 1.45612 acc: 0.69857 | v_loss: 1.42638 v_acc: 0.71029 |  iteration: 17343 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1184 loss: 1.41794 acc: 0.70703 | v_loss: 1.41232 v_acc: 0.70605 |  iteration: 17344 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1185 loss: 1.41774 acc: 0.70247 | v_loss: 1.40681 v_acc: 0.70703 |  iteration: 17345 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1186 loss: 1.50040 acc: 0.70052 | v_loss: 1.26596 v_acc: 0.71159 |  iteration: 17346 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1187 loss: 1.40372 acc: 0.70475 | v_loss: 1.31660 v_acc: 0.72331 |  iteration: 17347 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1188 loss: 1.35995 acc: 0.70573 | v_loss: 1.19076 v_acc: 0.70638 |  iteration: 17348 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1189 loss: 1.47038 acc: 0.69889 | v_loss: 1.34308 v_acc: 0.70247 |  iteration: 17349 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1190 loss: 1.40138 acc: 0.70475 | v_loss: 1.50377 v_acc: 0.69954 |  iteration: 17350 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 1191 loss: 1.46621 acc: 0.69954 | v_loss: 1.33194 v_acc: 0.71289 |  iteration: 17351 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 1192 loss: 1.42141 acc: 0.70410 | v_loss: 1.33339 v_acc: 0.70247 |  iteration: 17352 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1193 loss: 1.38952 acc: 0.70964 | v_loss: 1.24726 v_acc: 0.71224 |  iteration: 17353 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 1194 loss: 1.42219 acc: 0.69759 | v_loss: 1.23682 v_acc: 0.70833 |  iteration: 17354 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1195 loss: 1.45820 acc: 0.69759 | v_loss: 1.24048 v_acc: 0.73372 |  iteration: 17355 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1196 loss: 1.43807 acc: 0.69824 | v_loss: 1.25134 v_acc: 0.72135 |  iteration: 17356 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 1197 loss: 1.49523 acc: 0.69954 | v_loss: 1.34551 v_acc: 0.72689 |  iteration: 17357 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1198 loss: 1.48521 acc: 0.69629 | v_loss: 1.26249 v_acc: 0.72852 |  iteration: 17358 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 1199 loss: 1.55500 acc: 0.69368 | v_loss: 1.30196 v_acc: 0.72005 |  iteration: 17359 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1200 loss: 1.36871 acc: 0.71810 | v_loss: 1.41310 v_acc: 0.71224 |  iteration: 17360 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 1201 loss: 1.53245 acc: 0.69727 | v_loss: 1.38654 v_acc: 0.72038 |  iteration: 17361 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1202 loss: 1.40970 acc: 0.70964 | v_loss: 1.48286 v_acc: 0.69954 |  iteration: 17362 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1203 loss: 1.47709 acc: 0.70378 | v_loss: 1.40877 v_acc: 0.71647 |  iteration: 17363 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 1204 loss: 1.47330 acc: 0.69824 | v_loss: 1.17784 v_acc: 0.74219 |  iteration: 17364 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 1205 loss: 1.45093 acc: 0.69759 | v_loss: 1.26127 v_acc: 0.70182 |  iteration: 17365 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 1206 loss: 1.36868 acc: 0.71484 | v_loss: 1.50973 v_acc: 0.70247 |  iteration: 17366 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1207 loss: 1.46257 acc: 0.70150 | v_loss: 1.21069 v_acc: 0.70866 |  iteration: 17367 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 1208 loss: 1.44263 acc: 0.70866 | v_loss: 1.32942 v_acc: 0.71159 |  iteration: 17368 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1209 loss: 1.43432 acc: 0.71061 | v_loss: 1.37554 v_acc: 0.69336 |  iteration: 17369 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 1210 loss: 1.40690 acc: 0.70247 | v_loss: 1.30063 v_acc: 0.71191 |  iteration: 17370 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 1211 loss: 1.46845 acc: 0.70020 | v_loss: 1.36684 v_acc: 0.69629 |  iteration: 17371 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1212 loss: 1.34765 acc: 0.70768 | v_loss: 1.46133 v_acc: 0.71517 |  iteration: 17372 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1213 loss: 1.27453 acc: 0.71615 | v_loss: 1.31243 v_acc: 0.72689 |  iteration: 17373 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1214 loss: 1.42023 acc: 0.70117 | v_loss: 1.44763 v_acc: 0.70540 |  iteration: 17374 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 1215 loss: 1.37614 acc: 0.71354 | v_loss: 1.36247 v_acc: 0.69857 |  iteration: 17375 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1216 loss: 1.39488 acc: 0.70638 | v_loss: 1.32260 v_acc: 0.70833 |  iteration: 17376 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1217 loss: 1.47482 acc: 0.70345 | v_loss: 1.56595 v_acc: 0.68490 |  iteration: 17377 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 1218 loss: 1.41597 acc: 0.71159 | v_loss: 1.30422 v_acc: 0.72070 |  iteration: 17378 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1219 loss: 1.35098 acc: 0.71061 | v_loss: 1.59833 v_acc: 0.68424 |  iteration: 17379 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 1220 loss: 1.44984 acc: 0.70964 | v_loss: 1.45241 v_acc: 0.69792 |  iteration: 17380 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1221 loss: 1.46748 acc: 0.70150 | v_loss: 1.52543 v_acc: 0.69173 |  iteration: 17381 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1222 loss: 1.31078 acc: 0.70866 | v_loss: 1.37775 v_acc: 0.70020 |  iteration: 17382 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1223 loss: 1.45689 acc: 0.70833 | v_loss: 1.32653 v_acc: 0.70312 |  iteration: 17383 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1224 loss: 1.38570 acc: 0.70215 | v_loss: 1.33399 v_acc: 0.70020 |  iteration: 17384 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1225 loss: 1.56648 acc: 0.69759 | v_loss: 1.32978 v_acc: 0.71484 |  iteration: 17385 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1226 loss: 1.36153 acc: 0.70638 | v_loss: 1.54489 v_acc: 0.68978 |  iteration: 17386 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 1227 loss: 1.45301 acc: 0.70378 | v_loss: 1.38644 v_acc: 0.70443 |  iteration: 17387 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 1228 loss: 1.43206 acc: 0.71029 | v_loss: 1.34171 v_acc: 0.71029 |  iteration: 17388 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1229 loss: 1.40230 acc: 0.70898 | v_loss: 1.38544 v_acc: 0.71680 |  iteration: 17389 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1230 loss: 1.39844 acc: 0.70117 | v_loss: 1.27900 v_acc: 0.70573 |  iteration: 17390 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 1231 loss: 1.45242 acc: 0.69857 | v_loss: 1.43635 v_acc: 0.69792 |  iteration: 17391 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1232 loss: 1.46589 acc: 0.69531 | v_loss: 1.43041 v_acc: 0.71289 |  iteration: 17392 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 1233 loss: 1.35491 acc: 0.70768 | v_loss: 1.28490 v_acc: 0.71875 |  iteration: 17393 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1234 loss: 1.40550 acc: 0.71094 | v_loss: 1.25274 v_acc: 0.72754 |  iteration: 17394 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1235 loss: 1.43263 acc: 0.70182 | v_loss: 1.37187 v_acc: 0.72005 |  iteration: 17395 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1236 loss: 1.48256 acc: 0.69987 | v_loss: 1.41205 v_acc: 0.70443 |  iteration: 17396 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 1237 loss: 1.42330 acc: 0.70410 | v_loss: 1.42243 v_acc: 0.70833 |  iteration: 17397 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1238 loss: 1.36702 acc: 0.70475 | v_loss: 1.21375 v_acc: 0.72591 |  iteration: 17398 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 1239 loss: 1.40139 acc: 0.70182 | v_loss: 1.38605 v_acc: 0.72982 |  iteration: 17399 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 1240 loss: 1.39031 acc: 0.70703 | v_loss: 1.48007 v_acc: 0.69661 |  iteration: 17400 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1241 loss: 1.46963 acc: 0.69694 | v_loss: 1.45215 v_acc: 0.71908 |  iteration: 17401 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1242 loss: 1.44256 acc: 0.69824 | v_loss: 1.24477 v_acc: 0.71908 |  iteration: 17402 teacher: 0 stage: sketch lr: 0.000335\n",
      "epoch 13 loss: 1.43399 acc: 0.70267 | v_loss: 1.36483 v_acc: 0.71079 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14\n",
      "__________________________________________\n",
      "batch 0 loss: 1.35002 acc: 0.70703 | v_loss: 1.41850 v_acc: 0.69759 |  iteration: 17403 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 1 loss: 1.48638 acc: 0.69824 | v_loss: 1.40772 v_acc: 0.70996 |  iteration: 17404 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 2 loss: 1.39398 acc: 0.69499 | v_loss: 1.39771 v_acc: 0.70703 |  iteration: 17405 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 3 loss: 1.52716 acc: 0.69531 | v_loss: 1.25114 v_acc: 0.71875 |  iteration: 17406 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 4 loss: 1.42035 acc: 0.70215 | v_loss: 1.33256 v_acc: 0.72331 |  iteration: 17407 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 5 loss: 1.52269 acc: 0.70573 | v_loss: 1.16731 v_acc: 0.71615 |  iteration: 17408 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 6 loss: 1.47122 acc: 0.69987 | v_loss: 1.33904 v_acc: 0.71061 |  iteration: 17409 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 7 loss: 1.45861 acc: 0.69759 | v_loss: 1.50977 v_acc: 0.69889 |  iteration: 17410 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 8 loss: 1.45025 acc: 0.70052 | v_loss: 1.33597 v_acc: 0.70833 |  iteration: 17411 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 9 loss: 1.44729 acc: 0.70833 | v_loss: 1.36055 v_acc: 0.69727 |  iteration: 17412 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 10 loss: 1.39581 acc: 0.70898 | v_loss: 1.24357 v_acc: 0.71126 |  iteration: 17413 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 11 loss: 1.34914 acc: 0.70801 | v_loss: 1.25249 v_acc: 0.70345 |  iteration: 17414 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 12 loss: 1.41126 acc: 0.70931 | v_loss: 1.23678 v_acc: 0.73503 |  iteration: 17415 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 13 loss: 1.46886 acc: 0.70150 | v_loss: 1.27108 v_acc: 0.72168 |  iteration: 17416 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 14 loss: 1.26928 acc: 0.71484 | v_loss: 1.32803 v_acc: 0.73145 |  iteration: 17417 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 15 loss: 1.46315 acc: 0.70736 | v_loss: 1.25658 v_acc: 0.72461 |  iteration: 17418 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 16 loss: 1.40295 acc: 0.70378 | v_loss: 1.29579 v_acc: 0.72005 |  iteration: 17419 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 17 loss: 1.47383 acc: 0.69922 | v_loss: 1.40623 v_acc: 0.71224 |  iteration: 17420 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 18 loss: 1.42392 acc: 0.71061 | v_loss: 1.37837 v_acc: 0.72298 |  iteration: 17421 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 19 loss: 1.46656 acc: 0.71029 | v_loss: 1.49162 v_acc: 0.69922 |  iteration: 17422 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 20 loss: 1.41862 acc: 0.69596 | v_loss: 1.40550 v_acc: 0.71973 |  iteration: 17423 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 21 loss: 1.34160 acc: 0.71712 | v_loss: 1.16958 v_acc: 0.74544 |  iteration: 17424 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 22 loss: 1.35750 acc: 0.71191 | v_loss: 1.27026 v_acc: 0.70573 |  iteration: 17425 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 23 loss: 1.61128 acc: 0.68978 | v_loss: 1.51211 v_acc: 0.70247 |  iteration: 17426 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 24 loss: 1.45071 acc: 0.71517 | v_loss: 1.24399 v_acc: 0.70833 |  iteration: 17427 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 25 loss: 1.38604 acc: 0.70085 | v_loss: 1.33019 v_acc: 0.71257 |  iteration: 17428 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 26 loss: 1.45664 acc: 0.70247 | v_loss: 1.36033 v_acc: 0.69499 |  iteration: 17429 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 27 loss: 1.44507 acc: 0.70703 | v_loss: 1.30718 v_acc: 0.71029 |  iteration: 17430 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 28 loss: 1.48638 acc: 0.69954 | v_loss: 1.36945 v_acc: 0.69629 |  iteration: 17431 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 29 loss: 1.48330 acc: 0.69889 | v_loss: 1.45093 v_acc: 0.71777 |  iteration: 17432 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 30 loss: 1.43040 acc: 0.70117 | v_loss: 1.31215 v_acc: 0.72917 |  iteration: 17433 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 31 loss: 1.39041 acc: 0.71289 | v_loss: 1.43208 v_acc: 0.70443 |  iteration: 17434 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 32 loss: 1.58310 acc: 0.69499 | v_loss: 1.37272 v_acc: 0.69922 |  iteration: 17435 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 33 loss: 1.48576 acc: 0.69824 | v_loss: 1.32443 v_acc: 0.70898 |  iteration: 17436 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 34 loss: 1.62376 acc: 0.68457 | v_loss: 1.54029 v_acc: 0.68815 |  iteration: 17437 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 35 loss: 1.43699 acc: 0.70768 | v_loss: 1.28705 v_acc: 0.72005 |  iteration: 17438 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 36 loss: 1.55489 acc: 0.69857 | v_loss: 1.58896 v_acc: 0.68424 |  iteration: 17439 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 37 loss: 1.49934 acc: 0.69401 | v_loss: 1.45107 v_acc: 0.69792 |  iteration: 17440 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 38 loss: 1.38826 acc: 0.71322 | v_loss: 1.50862 v_acc: 0.69173 |  iteration: 17441 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 39 loss: 1.38838 acc: 0.70508 | v_loss: 1.37569 v_acc: 0.69987 |  iteration: 17442 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 40 loss: 1.45319 acc: 0.70215 | v_loss: 1.32720 v_acc: 0.70280 |  iteration: 17443 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 41 loss: 1.44613 acc: 0.69954 | v_loss: 1.34212 v_acc: 0.70020 |  iteration: 17444 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 42 loss: 1.47622 acc: 0.69694 | v_loss: 1.33134 v_acc: 0.71484 |  iteration: 17445 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 43 loss: 1.39402 acc: 0.70312 | v_loss: 1.54440 v_acc: 0.68978 |  iteration: 17446 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 44 loss: 1.43953 acc: 0.70378 | v_loss: 1.38118 v_acc: 0.70443 |  iteration: 17447 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 45 loss: 1.38932 acc: 0.70150 | v_loss: 1.34508 v_acc: 0.71061 |  iteration: 17448 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 46 loss: 1.36204 acc: 0.70312 | v_loss: 1.40057 v_acc: 0.70833 |  iteration: 17449 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 47 loss: 1.40632 acc: 0.70410 | v_loss: 1.26167 v_acc: 0.71191 |  iteration: 17450 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 48 loss: 1.45982 acc: 0.69531 | v_loss: 1.43297 v_acc: 0.70020 |  iteration: 17451 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 49 loss: 1.41856 acc: 0.70182 | v_loss: 1.43565 v_acc: 0.71094 |  iteration: 17452 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 50 loss: 1.40854 acc: 0.70833 | v_loss: 1.27388 v_acc: 0.71810 |  iteration: 17453 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 51 loss: 1.46172 acc: 0.69727 | v_loss: 1.25318 v_acc: 0.72559 |  iteration: 17454 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 52 loss: 1.41221 acc: 0.69368 | v_loss: 1.38763 v_acc: 0.71615 |  iteration: 17455 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 53 loss: 1.34699 acc: 0.71322 | v_loss: 1.41690 v_acc: 0.70605 |  iteration: 17456 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 54 loss: 1.38597 acc: 0.69629 | v_loss: 1.43408 v_acc: 0.70931 |  iteration: 17457 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 55 loss: 1.47240 acc: 0.69759 | v_loss: 1.21777 v_acc: 0.72331 |  iteration: 17458 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 56 loss: 1.50518 acc: 0.69076 | v_loss: 1.38561 v_acc: 0.72819 |  iteration: 17459 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 57 loss: 1.42582 acc: 0.70117 | v_loss: 1.47532 v_acc: 0.69759 |  iteration: 17460 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 58 loss: 1.48926 acc: 0.69434 | v_loss: 1.41630 v_acc: 0.72233 |  iteration: 17461 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 59 loss: 1.40610 acc: 0.70215 | v_loss: 1.24644 v_acc: 0.72201 |  iteration: 17462 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 60 loss: 1.44718 acc: 0.69466 | v_loss: 1.19897 v_acc: 0.74023 |  iteration: 17463 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 61 loss: 1.44279 acc: 0.70573 | v_loss: 1.21014 v_acc: 0.72559 |  iteration: 17464 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 62 loss: 1.43301 acc: 0.70085 | v_loss: 1.27330 v_acc: 0.70638 |  iteration: 17465 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 63 loss: 1.31156 acc: 0.72461 | v_loss: 1.44742 v_acc: 0.70052 |  iteration: 17466 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 64 loss: 1.42862 acc: 0.69987 | v_loss: 1.26923 v_acc: 0.71419 |  iteration: 17467 teacher: 0 stage: sketch lr: 0.000334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 65 loss: 1.38098 acc: 0.70280 | v_loss: 1.41596 v_acc: 0.71777 |  iteration: 17468 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 66 loss: 1.49071 acc: 0.70866 | v_loss: 1.67760 v_acc: 0.69303 |  iteration: 17469 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 67 loss: 1.37946 acc: 0.72168 | v_loss: 1.52687 v_acc: 0.70117 |  iteration: 17470 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 68 loss: 1.39160 acc: 0.70475 | v_loss: 1.29562 v_acc: 0.72363 |  iteration: 17471 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 69 loss: 1.52849 acc: 0.69173 | v_loss: 1.37967 v_acc: 0.70410 |  iteration: 17472 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 70 loss: 1.28244 acc: 0.71973 | v_loss: 1.21407 v_acc: 0.71973 |  iteration: 17473 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 71 loss: 1.50521 acc: 0.69857 | v_loss: 1.43271 v_acc: 0.70150 |  iteration: 17474 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 72 loss: 1.39317 acc: 0.71191 | v_loss: 1.35607 v_acc: 0.71842 |  iteration: 17475 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 73 loss: 1.43768 acc: 0.70573 | v_loss: 1.35659 v_acc: 0.73014 |  iteration: 17476 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 74 loss: 1.50474 acc: 0.69694 | v_loss: 1.36402 v_acc: 0.71973 |  iteration: 17477 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 75 loss: 1.36871 acc: 0.71224 | v_loss: 1.37316 v_acc: 0.70964 |  iteration: 17478 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 76 loss: 1.46102 acc: 0.69987 | v_loss: 1.28048 v_acc: 0.72363 |  iteration: 17479 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 77 loss: 1.42545 acc: 0.70573 | v_loss: 1.28968 v_acc: 0.72135 |  iteration: 17480 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 78 loss: 1.43230 acc: 0.70410 | v_loss: 1.48903 v_acc: 0.69173 |  iteration: 17481 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 79 loss: 1.42502 acc: 0.71029 | v_loss: 1.33396 v_acc: 0.70898 |  iteration: 17482 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 80 loss: 1.47263 acc: 0.70247 | v_loss: 1.29113 v_acc: 0.71452 |  iteration: 17483 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 81 loss: 1.50297 acc: 0.69401 | v_loss: 1.29076 v_acc: 0.71940 |  iteration: 17484 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 82 loss: 1.45601 acc: 0.69564 | v_loss: 1.43271 v_acc: 0.70475 |  iteration: 17485 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 83 loss: 1.41406 acc: 0.69987 | v_loss: 1.30723 v_acc: 0.73210 |  iteration: 17486 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 84 loss: 1.45322 acc: 0.69368 | v_loss: 1.54213 v_acc: 0.71615 |  iteration: 17487 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 85 loss: 1.41783 acc: 0.70410 | v_loss: 1.28166 v_acc: 0.69759 |  iteration: 17488 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 86 loss: 1.48595 acc: 0.69824 | v_loss: 1.27523 v_acc: 0.70443 |  iteration: 17489 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 87 loss: 1.39297 acc: 0.71224 | v_loss: 1.44396 v_acc: 0.70312 |  iteration: 17490 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 88 loss: 1.43713 acc: 0.69824 | v_loss: 1.47780 v_acc: 0.70378 |  iteration: 17491 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 89 loss: 1.42520 acc: 0.70671 | v_loss: 1.52198 v_acc: 0.68978 |  iteration: 17492 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 90 loss: 1.44757 acc: 0.70117 | v_loss: 1.46323 v_acc: 0.70638 |  iteration: 17493 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 91 loss: 1.30854 acc: 0.71908 | v_loss: 1.42550 v_acc: 0.70410 |  iteration: 17494 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 92 loss: 1.56324 acc: 0.69368 | v_loss: 1.40800 v_acc: 0.70768 |  iteration: 17495 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 93 loss: 1.50890 acc: 0.69792 | v_loss: 1.40549 v_acc: 0.70475 |  iteration: 17496 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 94 loss: 1.40823 acc: 0.70378 | v_loss: 1.26540 v_acc: 0.71354 |  iteration: 17497 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 95 loss: 1.43212 acc: 0.70898 | v_loss: 1.31684 v_acc: 0.72461 |  iteration: 17498 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 96 loss: 1.32156 acc: 0.71354 | v_loss: 1.20066 v_acc: 0.71517 |  iteration: 17499 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 97 loss: 1.38708 acc: 0.70931 | v_loss: 1.34485 v_acc: 0.70703 |  iteration: 17500 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 98 loss: 1.33902 acc: 0.72070 | v_loss: 1.50587 v_acc: 0.69987 |  iteration: 17501 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 99 loss: 1.38755 acc: 0.71094 | v_loss: 1.33592 v_acc: 0.70833 |  iteration: 17502 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 100 loss: 1.42108 acc: 0.70671 | v_loss: 1.35628 v_acc: 0.69727 |  iteration: 17503 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 101 loss: 1.46721 acc: 0.69531 | v_loss: 1.24823 v_acc: 0.71094 |  iteration: 17504 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 102 loss: 1.33545 acc: 0.71777 | v_loss: 1.25157 v_acc: 0.70345 |  iteration: 17505 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 103 loss: 1.40667 acc: 0.69596 | v_loss: 1.23846 v_acc: 0.73503 |  iteration: 17506 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 104 loss: 1.36326 acc: 0.71159 | v_loss: 1.26258 v_acc: 0.72168 |  iteration: 17507 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 105 loss: 1.29503 acc: 0.70931 | v_loss: 1.34275 v_acc: 0.73145 |  iteration: 17508 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 106 loss: 1.49078 acc: 0.69694 | v_loss: 1.26261 v_acc: 0.72461 |  iteration: 17509 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 107 loss: 1.48244 acc: 0.69954 | v_loss: 1.31018 v_acc: 0.72103 |  iteration: 17510 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 108 loss: 1.37781 acc: 0.70866 | v_loss: 1.42121 v_acc: 0.71354 |  iteration: 17511 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 109 loss: 1.52352 acc: 0.69792 | v_loss: 1.41336 v_acc: 0.72201 |  iteration: 17512 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 110 loss: 1.49621 acc: 0.70280 | v_loss: 1.49342 v_acc: 0.70247 |  iteration: 17513 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 111 loss: 1.45286 acc: 0.69596 | v_loss: 1.42417 v_acc: 0.71615 |  iteration: 17514 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 112 loss: 1.39496 acc: 0.70964 | v_loss: 1.17364 v_acc: 0.74447 |  iteration: 17515 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 113 loss: 1.47355 acc: 0.70085 | v_loss: 1.25845 v_acc: 0.71322 |  iteration: 17516 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 114 loss: 1.40342 acc: 0.70736 | v_loss: 1.51915 v_acc: 0.69987 |  iteration: 17517 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 115 loss: 1.46118 acc: 0.69564 | v_loss: 1.23295 v_acc: 0.70671 |  iteration: 17518 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 116 loss: 1.39204 acc: 0.70312 | v_loss: 1.32414 v_acc: 0.71159 |  iteration: 17519 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 117 loss: 1.43417 acc: 0.70768 | v_loss: 1.35392 v_acc: 0.69336 |  iteration: 17520 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 118 loss: 1.38447 acc: 0.70898 | v_loss: 1.30575 v_acc: 0.71191 |  iteration: 17521 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 119 loss: 1.45867 acc: 0.70638 | v_loss: 1.36200 v_acc: 0.69629 |  iteration: 17522 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 120 loss: 1.42396 acc: 0.70085 | v_loss: 1.46624 v_acc: 0.71517 |  iteration: 17523 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 121 loss: 1.54738 acc: 0.70475 | v_loss: 1.30792 v_acc: 0.72689 |  iteration: 17524 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 122 loss: 1.35511 acc: 0.70605 | v_loss: 1.44170 v_acc: 0.70443 |  iteration: 17525 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 123 loss: 1.48041 acc: 0.69629 | v_loss: 1.37270 v_acc: 0.69922 |  iteration: 17526 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 124 loss: 1.47570 acc: 0.70736 | v_loss: 1.32930 v_acc: 0.70898 |  iteration: 17527 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 125 loss: 1.59864 acc: 0.69694 | v_loss: 1.54912 v_acc: 0.68815 |  iteration: 17528 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 126 loss: 1.44836 acc: 0.70182 | v_loss: 1.29431 v_acc: 0.72005 |  iteration: 17529 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 127 loss: 1.41572 acc: 0.70378 | v_loss: 1.59342 v_acc: 0.68424 |  iteration: 17530 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 128 loss: 1.44196 acc: 0.69661 | v_loss: 1.44859 v_acc: 0.69792 |  iteration: 17531 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 129 loss: 1.41247 acc: 0.71159 | v_loss: 1.51403 v_acc: 0.69173 |  iteration: 17532 teacher: 0 stage: sketch lr: 0.000334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 130 loss: 1.50348 acc: 0.70150 | v_loss: 1.37129 v_acc: 0.70020 |  iteration: 17533 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 131 loss: 1.52718 acc: 0.68620 | v_loss: 1.32684 v_acc: 0.70312 |  iteration: 17534 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 132 loss: 1.45216 acc: 0.70312 | v_loss: 1.33159 v_acc: 0.70085 |  iteration: 17535 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 133 loss: 1.44525 acc: 0.69922 | v_loss: 1.32421 v_acc: 0.71745 |  iteration: 17536 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 134 loss: 1.37070 acc: 0.71647 | v_loss: 1.52096 v_acc: 0.69173 |  iteration: 17537 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 135 loss: 1.37041 acc: 0.70443 | v_loss: 1.37413 v_acc: 0.70378 |  iteration: 17538 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 136 loss: 1.43129 acc: 0.69954 | v_loss: 1.34550 v_acc: 0.70833 |  iteration: 17539 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 137 loss: 1.41922 acc: 0.70638 | v_loss: 1.38447 v_acc: 0.71680 |  iteration: 17540 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 138 loss: 1.42817 acc: 0.69922 | v_loss: 1.26621 v_acc: 0.70573 |  iteration: 17541 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 139 loss: 1.45950 acc: 0.70085 | v_loss: 1.42973 v_acc: 0.70052 |  iteration: 17542 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 140 loss: 1.34821 acc: 0.70736 | v_loss: 1.43693 v_acc: 0.71126 |  iteration: 17543 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 141 loss: 1.37913 acc: 0.70898 | v_loss: 1.26972 v_acc: 0.71810 |  iteration: 17544 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 142 loss: 1.52959 acc: 0.69792 | v_loss: 1.26421 v_acc: 0.72298 |  iteration: 17545 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 143 loss: 1.41219 acc: 0.70833 | v_loss: 1.38564 v_acc: 0.71940 |  iteration: 17546 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 144 loss: 1.52776 acc: 0.69596 | v_loss: 1.41954 v_acc: 0.70475 |  iteration: 17547 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 145 loss: 1.39320 acc: 0.70540 | v_loss: 1.43052 v_acc: 0.70833 |  iteration: 17548 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 146 loss: 1.36497 acc: 0.71224 | v_loss: 1.22062 v_acc: 0.72559 |  iteration: 17549 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 147 loss: 1.37668 acc: 0.70117 | v_loss: 1.38867 v_acc: 0.72819 |  iteration: 17550 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 148 loss: 1.47853 acc: 0.69889 | v_loss: 1.47119 v_acc: 0.69824 |  iteration: 17551 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 149 loss: 1.48821 acc: 0.69987 | v_loss: 1.40178 v_acc: 0.72233 |  iteration: 17552 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 150 loss: 1.38241 acc: 0.71191 | v_loss: 1.24524 v_acc: 0.71810 |  iteration: 17553 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 151 loss: 1.45969 acc: 0.70703 | v_loss: 1.20567 v_acc: 0.73633 |  iteration: 17554 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 152 loss: 1.31424 acc: 0.71354 | v_loss: 1.21825 v_acc: 0.72559 |  iteration: 17555 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 153 loss: 1.49966 acc: 0.70247 | v_loss: 1.29138 v_acc: 0.70638 |  iteration: 17556 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 154 loss: 1.34782 acc: 0.71094 | v_loss: 1.45995 v_acc: 0.70052 |  iteration: 17557 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 155 loss: 1.47046 acc: 0.70671 | v_loss: 1.27177 v_acc: 0.71452 |  iteration: 17558 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 156 loss: 1.37520 acc: 0.71191 | v_loss: 1.42786 v_acc: 0.71647 |  iteration: 17559 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 157 loss: 1.43616 acc: 0.70280 | v_loss: 1.66542 v_acc: 0.69303 |  iteration: 17560 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 158 loss: 1.47019 acc: 0.69727 | v_loss: 1.51721 v_acc: 0.70117 |  iteration: 17561 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 159 loss: 1.35115 acc: 0.70703 | v_loss: 1.29031 v_acc: 0.72363 |  iteration: 17562 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 160 loss: 1.39833 acc: 0.71712 | v_loss: 1.37282 v_acc: 0.70410 |  iteration: 17563 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 161 loss: 1.47525 acc: 0.69922 | v_loss: 1.22242 v_acc: 0.71973 |  iteration: 17564 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 162 loss: 1.50273 acc: 0.69987 | v_loss: 1.41551 v_acc: 0.70150 |  iteration: 17565 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 163 loss: 1.42770 acc: 0.70573 | v_loss: 1.35733 v_acc: 0.71029 |  iteration: 17566 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 164 loss: 1.46807 acc: 0.70247 | v_loss: 1.34545 v_acc: 0.73079 |  iteration: 17567 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 165 loss: 1.39014 acc: 0.70801 | v_loss: 1.35482 v_acc: 0.71777 |  iteration: 17568 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 166 loss: 1.45150 acc: 0.70410 | v_loss: 1.37141 v_acc: 0.70410 |  iteration: 17569 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 167 loss: 1.48693 acc: 0.69889 | v_loss: 1.28496 v_acc: 0.72201 |  iteration: 17570 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 168 loss: 1.56281 acc: 0.69922 | v_loss: 1.30021 v_acc: 0.72005 |  iteration: 17571 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 169 loss: 1.39511 acc: 0.70052 | v_loss: 1.50623 v_acc: 0.69206 |  iteration: 17572 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 170 loss: 1.37179 acc: 0.69954 | v_loss: 1.33322 v_acc: 0.70931 |  iteration: 17573 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 171 loss: 1.45651 acc: 0.70117 | v_loss: 1.28744 v_acc: 0.71452 |  iteration: 17574 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 172 loss: 1.37725 acc: 0.71029 | v_loss: 1.28511 v_acc: 0.71940 |  iteration: 17575 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 173 loss: 1.35045 acc: 0.70898 | v_loss: 1.42363 v_acc: 0.70475 |  iteration: 17576 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 174 loss: 1.46008 acc: 0.70020 | v_loss: 1.31054 v_acc: 0.73210 |  iteration: 17577 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 175 loss: 1.45885 acc: 0.71191 | v_loss: 1.54462 v_acc: 0.71452 |  iteration: 17578 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 176 loss: 1.46075 acc: 0.69564 | v_loss: 1.28025 v_acc: 0.69759 |  iteration: 17579 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 177 loss: 1.48073 acc: 0.69466 | v_loss: 1.27366 v_acc: 0.70443 |  iteration: 17580 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 178 loss: 1.43618 acc: 0.69759 | v_loss: 1.43926 v_acc: 0.70378 |  iteration: 17581 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 179 loss: 1.44434 acc: 0.70215 | v_loss: 1.47312 v_acc: 0.70150 |  iteration: 17582 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 180 loss: 1.34187 acc: 0.71191 | v_loss: 1.51382 v_acc: 0.69368 |  iteration: 17583 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 181 loss: 1.43638 acc: 0.70345 | v_loss: 1.47614 v_acc: 0.70931 |  iteration: 17584 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 182 loss: 1.38039 acc: 0.70833 | v_loss: 1.41145 v_acc: 0.69759 |  iteration: 17585 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 183 loss: 1.34818 acc: 0.71712 | v_loss: 1.39818 v_acc: 0.71094 |  iteration: 17586 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 184 loss: 1.51530 acc: 0.69434 | v_loss: 1.40590 v_acc: 0.70605 |  iteration: 17587 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 185 loss: 1.48462 acc: 0.70475 | v_loss: 1.26322 v_acc: 0.71973 |  iteration: 17588 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 186 loss: 1.42895 acc: 0.70638 | v_loss: 1.32266 v_acc: 0.72428 |  iteration: 17589 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 187 loss: 1.42897 acc: 0.70671 | v_loss: 1.17567 v_acc: 0.70703 |  iteration: 17590 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 188 loss: 1.38478 acc: 0.71322 | v_loss: 1.35257 v_acc: 0.70150 |  iteration: 17591 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 189 loss: 1.50114 acc: 0.68815 | v_loss: 1.50937 v_acc: 0.69694 |  iteration: 17592 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 190 loss: 1.43375 acc: 0.69759 | v_loss: 1.32534 v_acc: 0.70443 |  iteration: 17593 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 191 loss: 1.35420 acc: 0.70540 | v_loss: 1.36324 v_acc: 0.69401 |  iteration: 17594 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 192 loss: 1.49409 acc: 0.70052 | v_loss: 1.24651 v_acc: 0.70508 |  iteration: 17595 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 193 loss: 1.47619 acc: 0.70182 | v_loss: 1.26057 v_acc: 0.70182 |  iteration: 17596 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 194 loss: 1.42449 acc: 0.71159 | v_loss: 1.23632 v_acc: 0.73307 |  iteration: 17597 teacher: 1 stage: sketch lr: 0.000333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 195 loss: 1.43555 acc: 0.69434 | v_loss: 1.26728 v_acc: 0.71842 |  iteration: 17598 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 196 loss: 1.43374 acc: 0.70280 | v_loss: 1.32136 v_acc: 0.73145 |  iteration: 17599 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 197 loss: 1.33111 acc: 0.71094 | v_loss: 1.26193 v_acc: 0.72461 |  iteration: 17600 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 198 loss: 1.47579 acc: 0.69629 | v_loss: 1.29928 v_acc: 0.72005 |  iteration: 17601 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 199 loss: 1.39401 acc: 0.70345 | v_loss: 1.40947 v_acc: 0.71224 |  iteration: 17602 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 200 loss: 1.35270 acc: 0.71126 | v_loss: 1.39410 v_acc: 0.72070 |  iteration: 17603 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 201 loss: 1.46409 acc: 0.70703 | v_loss: 1.49008 v_acc: 0.69954 |  iteration: 17604 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 202 loss: 1.45308 acc: 0.69596 | v_loss: 1.43093 v_acc: 0.71615 |  iteration: 17605 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 203 loss: 1.42925 acc: 0.69531 | v_loss: 1.17280 v_acc: 0.74544 |  iteration: 17606 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 204 loss: 1.50201 acc: 0.69531 | v_loss: 1.26134 v_acc: 0.70931 |  iteration: 17607 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 205 loss: 1.29326 acc: 0.71777 | v_loss: 1.52236 v_acc: 0.70247 |  iteration: 17608 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 206 loss: 1.43188 acc: 0.70280 | v_loss: 1.21644 v_acc: 0.70866 |  iteration: 17609 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 207 loss: 1.57130 acc: 0.68652 | v_loss: 1.32990 v_acc: 0.71159 |  iteration: 17610 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 208 loss: 1.25720 acc: 0.72103 | v_loss: 1.36492 v_acc: 0.69336 |  iteration: 17611 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 209 loss: 1.43352 acc: 0.70052 | v_loss: 1.29473 v_acc: 0.71191 |  iteration: 17612 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 210 loss: 1.39872 acc: 0.69987 | v_loss: 1.35986 v_acc: 0.69629 |  iteration: 17613 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 211 loss: 1.41483 acc: 0.70508 | v_loss: 1.48010 v_acc: 0.71517 |  iteration: 17614 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 212 loss: 1.45348 acc: 0.70312 | v_loss: 1.32353 v_acc: 0.72624 |  iteration: 17615 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 213 loss: 1.43508 acc: 0.69954 | v_loss: 1.45464 v_acc: 0.70443 |  iteration: 17616 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 214 loss: 1.46152 acc: 0.70085 | v_loss: 1.35965 v_acc: 0.70020 |  iteration: 17617 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 215 loss: 1.35621 acc: 0.70866 | v_loss: 1.32962 v_acc: 0.70703 |  iteration: 17618 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 216 loss: 1.47165 acc: 0.70052 | v_loss: 1.55293 v_acc: 0.68750 |  iteration: 17619 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 217 loss: 1.38300 acc: 0.70540 | v_loss: 1.30640 v_acc: 0.72005 |  iteration: 17620 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 218 loss: 1.39022 acc: 0.69727 | v_loss: 1.57801 v_acc: 0.68294 |  iteration: 17621 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 219 loss: 1.42447 acc: 0.71354 | v_loss: 1.44202 v_acc: 0.69889 |  iteration: 17622 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 220 loss: 1.49255 acc: 0.69824 | v_loss: 1.52091 v_acc: 0.68978 |  iteration: 17623 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 221 loss: 1.51253 acc: 0.70312 | v_loss: 1.37233 v_acc: 0.69792 |  iteration: 17624 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 222 loss: 1.44097 acc: 0.71354 | v_loss: 1.32528 v_acc: 0.70378 |  iteration: 17625 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 223 loss: 1.46862 acc: 0.70117 | v_loss: 1.32289 v_acc: 0.70215 |  iteration: 17626 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 224 loss: 1.41056 acc: 0.69922 | v_loss: 1.32503 v_acc: 0.71615 |  iteration: 17627 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 225 loss: 1.44851 acc: 0.70605 | v_loss: 1.54317 v_acc: 0.68945 |  iteration: 17628 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 226 loss: 1.48276 acc: 0.70671 | v_loss: 1.38972 v_acc: 0.70703 |  iteration: 17629 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 227 loss: 1.52618 acc: 0.69206 | v_loss: 1.34437 v_acc: 0.71029 |  iteration: 17630 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 228 loss: 1.39281 acc: 0.70410 | v_loss: 1.38948 v_acc: 0.71419 |  iteration: 17631 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 229 loss: 1.40736 acc: 0.70964 | v_loss: 1.29292 v_acc: 0.70378 |  iteration: 17632 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 230 loss: 1.47673 acc: 0.69043 | v_loss: 1.44837 v_acc: 0.69466 |  iteration: 17633 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 231 loss: 1.42811 acc: 0.70117 | v_loss: 1.42912 v_acc: 0.71289 |  iteration: 17634 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 232 loss: 1.37058 acc: 0.71517 | v_loss: 1.28630 v_acc: 0.71875 |  iteration: 17635 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 233 loss: 1.46161 acc: 0.70410 | v_loss: 1.25839 v_acc: 0.72754 |  iteration: 17636 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 234 loss: 1.45575 acc: 0.70931 | v_loss: 1.37945 v_acc: 0.71940 |  iteration: 17637 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 235 loss: 1.42979 acc: 0.70182 | v_loss: 1.41638 v_acc: 0.70345 |  iteration: 17638 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 236 loss: 1.39515 acc: 0.70345 | v_loss: 1.42018 v_acc: 0.70410 |  iteration: 17639 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 237 loss: 1.42887 acc: 0.71322 | v_loss: 1.22545 v_acc: 0.71387 |  iteration: 17640 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 238 loss: 1.43990 acc: 0.69922 | v_loss: 1.38324 v_acc: 0.72819 |  iteration: 17641 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 239 loss: 1.38432 acc: 0.70833 | v_loss: 1.47335 v_acc: 0.69954 |  iteration: 17642 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 240 loss: 1.55215 acc: 0.68783 | v_loss: 1.40173 v_acc: 0.72298 |  iteration: 17643 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 241 loss: 1.38351 acc: 0.71029 | v_loss: 1.25247 v_acc: 0.71615 |  iteration: 17644 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 242 loss: 1.47714 acc: 0.70573 | v_loss: 1.21666 v_acc: 0.73307 |  iteration: 17645 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 243 loss: 1.33388 acc: 0.70345 | v_loss: 1.22375 v_acc: 0.72428 |  iteration: 17646 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 244 loss: 1.43899 acc: 0.70540 | v_loss: 1.29571 v_acc: 0.70638 |  iteration: 17647 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 245 loss: 1.41086 acc: 0.71126 | v_loss: 1.47138 v_acc: 0.70052 |  iteration: 17648 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 246 loss: 1.27696 acc: 0.71517 | v_loss: 1.27188 v_acc: 0.71452 |  iteration: 17649 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 247 loss: 1.40037 acc: 0.69922 | v_loss: 1.44120 v_acc: 0.71647 |  iteration: 17650 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 248 loss: 1.45241 acc: 0.69954 | v_loss: 1.70032 v_acc: 0.69108 |  iteration: 17651 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 249 loss: 1.48487 acc: 0.69661 | v_loss: 1.53601 v_acc: 0.69759 |  iteration: 17652 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 250 loss: 1.61010 acc: 0.68490 | v_loss: 1.29397 v_acc: 0.72396 |  iteration: 17653 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 251 loss: 1.45973 acc: 0.69499 | v_loss: 1.36528 v_acc: 0.70898 |  iteration: 17654 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 252 loss: 1.39055 acc: 0.71842 | v_loss: 1.21373 v_acc: 0.72201 |  iteration: 17655 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 253 loss: 1.51801 acc: 0.69694 | v_loss: 1.41219 v_acc: 0.70312 |  iteration: 17656 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 254 loss: 1.53230 acc: 0.69434 | v_loss: 1.35358 v_acc: 0.71029 |  iteration: 17657 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 255 loss: 1.45577 acc: 0.70378 | v_loss: 1.35024 v_acc: 0.73079 |  iteration: 17658 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 256 loss: 1.44330 acc: 0.70540 | v_loss: 1.35499 v_acc: 0.71777 |  iteration: 17659 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 257 loss: 1.37224 acc: 0.70378 | v_loss: 1.37056 v_acc: 0.70410 |  iteration: 17660 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 258 loss: 1.48226 acc: 0.69596 | v_loss: 1.28076 v_acc: 0.72201 |  iteration: 17661 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 259 loss: 1.45271 acc: 0.70475 | v_loss: 1.29557 v_acc: 0.72135 |  iteration: 17662 teacher: 0 stage: sketch lr: 0.000333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 260 loss: 1.38843 acc: 0.71029 | v_loss: 1.48592 v_acc: 0.69043 |  iteration: 17663 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 261 loss: 1.37085 acc: 0.69824 | v_loss: 1.33389 v_acc: 0.70996 |  iteration: 17664 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 262 loss: 1.47146 acc: 0.69987 | v_loss: 1.29494 v_acc: 0.71549 |  iteration: 17665 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 263 loss: 1.34447 acc: 0.70475 | v_loss: 1.29300 v_acc: 0.71973 |  iteration: 17666 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 264 loss: 1.31034 acc: 0.72005 | v_loss: 1.42310 v_acc: 0.70573 |  iteration: 17667 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 265 loss: 1.38776 acc: 0.70443 | v_loss: 1.30534 v_acc: 0.73112 |  iteration: 17668 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 266 loss: 1.43019 acc: 0.69922 | v_loss: 1.53930 v_acc: 0.71452 |  iteration: 17669 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 267 loss: 1.45432 acc: 0.70247 | v_loss: 1.27957 v_acc: 0.69759 |  iteration: 17670 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 268 loss: 1.45759 acc: 0.70508 | v_loss: 1.27439 v_acc: 0.70443 |  iteration: 17671 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 269 loss: 1.44394 acc: 0.70540 | v_loss: 1.44604 v_acc: 0.70312 |  iteration: 17672 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 270 loss: 1.49521 acc: 0.70085 | v_loss: 1.48068 v_acc: 0.70378 |  iteration: 17673 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 271 loss: 1.45321 acc: 0.70410 | v_loss: 1.51945 v_acc: 0.68978 |  iteration: 17674 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 272 loss: 1.48758 acc: 0.69368 | v_loss: 1.46697 v_acc: 0.70638 |  iteration: 17675 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 273 loss: 1.42358 acc: 0.71419 | v_loss: 1.42402 v_acc: 0.70410 |  iteration: 17676 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 274 loss: 1.46843 acc: 0.70345 | v_loss: 1.40863 v_acc: 0.70768 |  iteration: 17677 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 275 loss: 1.36712 acc: 0.70931 | v_loss: 1.40326 v_acc: 0.70475 |  iteration: 17678 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 276 loss: 1.34866 acc: 0.70443 | v_loss: 1.26361 v_acc: 0.71354 |  iteration: 17679 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 277 loss: 1.43542 acc: 0.69954 | v_loss: 1.32196 v_acc: 0.72461 |  iteration: 17680 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 278 loss: 1.46005 acc: 0.70345 | v_loss: 1.18015 v_acc: 0.71517 |  iteration: 17681 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 279 loss: 1.42139 acc: 0.69954 | v_loss: 1.34327 v_acc: 0.71061 |  iteration: 17682 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 280 loss: 1.39261 acc: 0.70638 | v_loss: 1.51579 v_acc: 0.69954 |  iteration: 17683 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 281 loss: 1.40798 acc: 0.70150 | v_loss: 1.33337 v_acc: 0.71484 |  iteration: 17684 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 282 loss: 1.43912 acc: 0.70573 | v_loss: 1.37371 v_acc: 0.70312 |  iteration: 17685 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 283 loss: 1.51143 acc: 0.69792 | v_loss: 1.23691 v_acc: 0.71517 |  iteration: 17686 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 284 loss: 1.46418 acc: 0.70410 | v_loss: 1.25053 v_acc: 0.70345 |  iteration: 17687 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 285 loss: 1.34909 acc: 0.71224 | v_loss: 1.24332 v_acc: 0.73503 |  iteration: 17688 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 286 loss: 1.46929 acc: 0.69857 | v_loss: 1.26280 v_acc: 0.72168 |  iteration: 17689 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 287 loss: 1.41378 acc: 0.70345 | v_loss: 1.32542 v_acc: 0.73145 |  iteration: 17690 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 288 loss: 1.43714 acc: 0.70833 | v_loss: 1.26303 v_acc: 0.72363 |  iteration: 17691 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 289 loss: 1.41401 acc: 0.69759 | v_loss: 1.30098 v_acc: 0.72266 |  iteration: 17692 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 290 loss: 1.40945 acc: 0.70540 | v_loss: 1.40779 v_acc: 0.71289 |  iteration: 17693 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 291 loss: 1.51475 acc: 0.70085 | v_loss: 1.38285 v_acc: 0.72298 |  iteration: 17694 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 292 loss: 1.30939 acc: 0.70866 | v_loss: 1.48301 v_acc: 0.69922 |  iteration: 17695 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 293 loss: 1.40812 acc: 0.71191 | v_loss: 1.40965 v_acc: 0.71973 |  iteration: 17696 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 294 loss: 1.45809 acc: 0.70410 | v_loss: 1.17260 v_acc: 0.74544 |  iteration: 17697 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 295 loss: 1.38732 acc: 0.70117 | v_loss: 1.26987 v_acc: 0.70573 |  iteration: 17698 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 296 loss: 1.37930 acc: 0.70052 | v_loss: 1.51929 v_acc: 0.70247 |  iteration: 17699 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 297 loss: 1.57284 acc: 0.69499 | v_loss: 1.24372 v_acc: 0.70833 |  iteration: 17700 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 298 loss: 1.37261 acc: 0.70638 | v_loss: 1.32741 v_acc: 0.71257 |  iteration: 17701 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 299 loss: 1.49929 acc: 0.69368 | v_loss: 1.35928 v_acc: 0.69499 |  iteration: 17702 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 300 loss: 1.34534 acc: 0.71289 | v_loss: 1.30208 v_acc: 0.71777 |  iteration: 17703 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 301 loss: 1.56265 acc: 0.69238 | v_loss: 1.36830 v_acc: 0.69922 |  iteration: 17704 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 302 loss: 1.44252 acc: 0.70638 | v_loss: 1.46571 v_acc: 0.71582 |  iteration: 17705 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 303 loss: 1.40539 acc: 0.70443 | v_loss: 1.31942 v_acc: 0.72754 |  iteration: 17706 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 304 loss: 1.39044 acc: 0.69661 | v_loss: 1.44006 v_acc: 0.70540 |  iteration: 17707 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 305 loss: 1.48496 acc: 0.69564 | v_loss: 1.36597 v_acc: 0.69954 |  iteration: 17708 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 306 loss: 1.37542 acc: 0.69694 | v_loss: 1.31723 v_acc: 0.70866 |  iteration: 17709 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 307 loss: 1.43277 acc: 0.70703 | v_loss: 1.55878 v_acc: 0.68652 |  iteration: 17710 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 308 loss: 1.41398 acc: 0.69661 | v_loss: 1.30337 v_acc: 0.72005 |  iteration: 17711 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 309 loss: 1.41571 acc: 0.70898 | v_loss: 1.58004 v_acc: 0.68424 |  iteration: 17712 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 310 loss: 1.42005 acc: 0.70801 | v_loss: 1.44963 v_acc: 0.69792 |  iteration: 17713 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 311 loss: 1.44853 acc: 0.70215 | v_loss: 1.53254 v_acc: 0.69173 |  iteration: 17714 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 312 loss: 1.42679 acc: 0.70833 | v_loss: 1.36718 v_acc: 0.70020 |  iteration: 17715 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 313 loss: 1.42545 acc: 0.71029 | v_loss: 1.32093 v_acc: 0.70378 |  iteration: 17716 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 314 loss: 1.43000 acc: 0.70443 | v_loss: 1.32926 v_acc: 0.70215 |  iteration: 17717 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 315 loss: 1.43423 acc: 0.69922 | v_loss: 1.32171 v_acc: 0.71615 |  iteration: 17718 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 316 loss: 1.40705 acc: 0.70443 | v_loss: 1.54061 v_acc: 0.68945 |  iteration: 17719 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 317 loss: 1.38901 acc: 0.71484 | v_loss: 1.38206 v_acc: 0.70703 |  iteration: 17720 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 318 loss: 1.40209 acc: 0.70801 | v_loss: 1.35914 v_acc: 0.70833 |  iteration: 17721 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 319 loss: 1.39035 acc: 0.71647 | v_loss: 1.38453 v_acc: 0.71680 |  iteration: 17722 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 320 loss: 1.43613 acc: 0.71061 | v_loss: 1.27328 v_acc: 0.70573 |  iteration: 17723 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 321 loss: 1.49322 acc: 0.70768 | v_loss: 1.42640 v_acc: 0.69792 |  iteration: 17724 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 322 loss: 1.39968 acc: 0.70345 | v_loss: 1.42149 v_acc: 0.71289 |  iteration: 17725 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 323 loss: 1.45051 acc: 0.70150 | v_loss: 1.28055 v_acc: 0.71875 |  iteration: 17726 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 324 loss: 1.42680 acc: 0.69401 | v_loss: 1.25233 v_acc: 0.72754 |  iteration: 17727 teacher: 0 stage: sketch lr: 0.000332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 325 loss: 1.53365 acc: 0.69727 | v_loss: 1.38237 v_acc: 0.72233 |  iteration: 17728 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 326 loss: 1.32714 acc: 0.71940 | v_loss: 1.41861 v_acc: 0.70410 |  iteration: 17729 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 327 loss: 1.44082 acc: 0.70312 | v_loss: 1.42177 v_acc: 0.70833 |  iteration: 17730 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 328 loss: 1.50702 acc: 0.69531 | v_loss: 1.22016 v_acc: 0.72591 |  iteration: 17731 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 329 loss: 1.44529 acc: 0.70378 | v_loss: 1.39722 v_acc: 0.73112 |  iteration: 17732 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 330 loss: 1.44549 acc: 0.69596 | v_loss: 1.48068 v_acc: 0.69857 |  iteration: 17733 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 331 loss: 1.40913 acc: 0.69954 | v_loss: 1.42377 v_acc: 0.72070 |  iteration: 17734 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 332 loss: 1.40453 acc: 0.70345 | v_loss: 1.24629 v_acc: 0.72201 |  iteration: 17735 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 333 loss: 1.51596 acc: 0.68945 | v_loss: 1.19759 v_acc: 0.74023 |  iteration: 17736 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 334 loss: 1.54482 acc: 0.69661 | v_loss: 1.21167 v_acc: 0.72689 |  iteration: 17737 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 335 loss: 1.36594 acc: 0.71452 | v_loss: 1.27463 v_acc: 0.70768 |  iteration: 17738 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 336 loss: 1.40185 acc: 0.69173 | v_loss: 1.44628 v_acc: 0.69596 |  iteration: 17739 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 337 loss: 1.44143 acc: 0.70052 | v_loss: 1.27606 v_acc: 0.71224 |  iteration: 17740 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 338 loss: 1.47745 acc: 0.70671 | v_loss: 1.42918 v_acc: 0.71582 |  iteration: 17741 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 339 loss: 1.41205 acc: 0.70215 | v_loss: 1.65681 v_acc: 0.69368 |  iteration: 17742 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 340 loss: 1.48941 acc: 0.69206 | v_loss: 1.51665 v_acc: 0.70117 |  iteration: 17743 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 341 loss: 1.45024 acc: 0.69987 | v_loss: 1.29271 v_acc: 0.72363 |  iteration: 17744 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 342 loss: 1.49123 acc: 0.70052 | v_loss: 1.36701 v_acc: 0.70410 |  iteration: 17745 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 343 loss: 1.37601 acc: 0.70247 | v_loss: 1.21826 v_acc: 0.71810 |  iteration: 17746 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 344 loss: 1.49475 acc: 0.69076 | v_loss: 1.41200 v_acc: 0.70020 |  iteration: 17747 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 345 loss: 1.41174 acc: 0.69954 | v_loss: 1.35878 v_acc: 0.71094 |  iteration: 17748 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 346 loss: 1.46895 acc: 0.70736 | v_loss: 1.34551 v_acc: 0.72949 |  iteration: 17749 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 347 loss: 1.37251 acc: 0.70378 | v_loss: 1.35433 v_acc: 0.71777 |  iteration: 17750 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 348 loss: 1.37738 acc: 0.71484 | v_loss: 1.37013 v_acc: 0.70410 |  iteration: 17751 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 349 loss: 1.32894 acc: 0.71647 | v_loss: 1.27727 v_acc: 0.72233 |  iteration: 17752 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 350 loss: 1.49706 acc: 0.69759 | v_loss: 1.28911 v_acc: 0.72135 |  iteration: 17753 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 351 loss: 1.40973 acc: 0.70736 | v_loss: 1.49020 v_acc: 0.69303 |  iteration: 17754 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 352 loss: 1.43531 acc: 0.70117 | v_loss: 1.33728 v_acc: 0.71159 |  iteration: 17755 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 353 loss: 1.38195 acc: 0.70605 | v_loss: 1.28422 v_acc: 0.71549 |  iteration: 17756 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 354 loss: 1.41941 acc: 0.70150 | v_loss: 1.27629 v_acc: 0.71973 |  iteration: 17757 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 355 loss: 1.41702 acc: 0.70671 | v_loss: 1.42280 v_acc: 0.70573 |  iteration: 17758 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 356 loss: 1.57412 acc: 0.69271 | v_loss: 1.31231 v_acc: 0.73112 |  iteration: 17759 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 357 loss: 1.39487 acc: 0.69694 | v_loss: 1.54745 v_acc: 0.71452 |  iteration: 17760 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 358 loss: 1.43279 acc: 0.70052 | v_loss: 1.28026 v_acc: 0.69759 |  iteration: 17761 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 359 loss: 1.30179 acc: 0.70898 | v_loss: 1.27358 v_acc: 0.70443 |  iteration: 17762 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 360 loss: 1.39645 acc: 0.70605 | v_loss: 1.44466 v_acc: 0.70312 |  iteration: 17763 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 361 loss: 1.39021 acc: 0.70964 | v_loss: 1.47666 v_acc: 0.70378 |  iteration: 17764 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 362 loss: 1.52316 acc: 0.69954 | v_loss: 1.52080 v_acc: 0.68978 |  iteration: 17765 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 363 loss: 1.50281 acc: 0.70020 | v_loss: 1.46586 v_acc: 0.70638 |  iteration: 17766 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 364 loss: 1.48606 acc: 0.69564 | v_loss: 1.41972 v_acc: 0.70410 |  iteration: 17767 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 365 loss: 1.43220 acc: 0.70540 | v_loss: 1.40768 v_acc: 0.70768 |  iteration: 17768 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 366 loss: 1.44173 acc: 0.70312 | v_loss: 1.39638 v_acc: 0.70475 |  iteration: 17769 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 367 loss: 1.53901 acc: 0.68913 | v_loss: 1.26355 v_acc: 0.71354 |  iteration: 17770 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 368 loss: 1.41076 acc: 0.71159 | v_loss: 1.32110 v_acc: 0.72461 |  iteration: 17771 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 369 loss: 1.49106 acc: 0.70247 | v_loss: 1.19568 v_acc: 0.71419 |  iteration: 17772 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 370 loss: 1.51717 acc: 0.68815 | v_loss: 1.33996 v_acc: 0.70703 |  iteration: 17773 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 371 loss: 1.41005 acc: 0.70866 | v_loss: 1.49652 v_acc: 0.69987 |  iteration: 17774 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 372 loss: 1.40246 acc: 0.70638 | v_loss: 1.33672 v_acc: 0.70833 |  iteration: 17775 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 373 loss: 1.37137 acc: 0.70964 | v_loss: 1.35846 v_acc: 0.69727 |  iteration: 17776 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 374 loss: 1.48703 acc: 0.70150 | v_loss: 1.25267 v_acc: 0.71126 |  iteration: 17777 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 375 loss: 1.47428 acc: 0.69954 | v_loss: 1.24464 v_acc: 0.70345 |  iteration: 17778 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 376 loss: 1.46287 acc: 0.70768 | v_loss: 1.24189 v_acc: 0.73503 |  iteration: 17779 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 377 loss: 1.45742 acc: 0.69727 | v_loss: 1.26616 v_acc: 0.72168 |  iteration: 17780 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 378 loss: 1.55433 acc: 0.69889 | v_loss: 1.32954 v_acc: 0.73145 |  iteration: 17781 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 379 loss: 1.47680 acc: 0.70638 | v_loss: 1.25683 v_acc: 0.72461 |  iteration: 17782 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 380 loss: 1.41837 acc: 0.70378 | v_loss: 1.29405 v_acc: 0.72005 |  iteration: 17783 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 381 loss: 1.43100 acc: 0.71191 | v_loss: 1.40418 v_acc: 0.71224 |  iteration: 17784 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 382 loss: 1.50452 acc: 0.69206 | v_loss: 1.37859 v_acc: 0.72005 |  iteration: 17785 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 383 loss: 1.40687 acc: 0.70410 | v_loss: 1.48720 v_acc: 0.69922 |  iteration: 17786 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 384 loss: 1.68050 acc: 0.68327 | v_loss: 1.39890 v_acc: 0.71973 |  iteration: 17787 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 385 loss: 1.42318 acc: 0.69857 | v_loss: 1.17590 v_acc: 0.74544 |  iteration: 17788 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 386 loss: 1.42148 acc: 0.70573 | v_loss: 1.26427 v_acc: 0.70573 |  iteration: 17789 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 387 loss: 1.49697 acc: 0.69238 | v_loss: 1.50678 v_acc: 0.70247 |  iteration: 17790 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 388 loss: 1.44570 acc: 0.70150 | v_loss: 1.22944 v_acc: 0.70833 |  iteration: 17791 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 389 loss: 1.41621 acc: 0.70573 | v_loss: 1.32503 v_acc: 0.71257 |  iteration: 17792 teacher: 0 stage: sketch lr: 0.000331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 390 loss: 1.38449 acc: 0.69824 | v_loss: 1.35926 v_acc: 0.69499 |  iteration: 17793 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 391 loss: 1.46927 acc: 0.70052 | v_loss: 1.30245 v_acc: 0.70996 |  iteration: 17794 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 392 loss: 1.45579 acc: 0.69271 | v_loss: 1.36044 v_acc: 0.69434 |  iteration: 17795 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 393 loss: 1.37438 acc: 0.70247 | v_loss: 1.47153 v_acc: 0.71224 |  iteration: 17796 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 394 loss: 1.41402 acc: 0.69727 | v_loss: 1.31729 v_acc: 0.72786 |  iteration: 17797 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 395 loss: 1.35082 acc: 0.70898 | v_loss: 1.44426 v_acc: 0.70540 |  iteration: 17798 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 396 loss: 1.50709 acc: 0.69173 | v_loss: 1.37696 v_acc: 0.69857 |  iteration: 17799 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 397 loss: 1.39113 acc: 0.71549 | v_loss: 1.31283 v_acc: 0.70833 |  iteration: 17800 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 398 loss: 1.41603 acc: 0.70280 | v_loss: 1.56822 v_acc: 0.68522 |  iteration: 17801 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 399 loss: 1.41783 acc: 0.70833 | v_loss: 1.29723 v_acc: 0.72168 |  iteration: 17802 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 400 loss: 1.36610 acc: 0.70736 | v_loss: 1.59814 v_acc: 0.67969 |  iteration: 17803 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 401 loss: 1.50686 acc: 0.69336 | v_loss: 1.46623 v_acc: 0.69661 |  iteration: 17804 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 402 loss: 1.45641 acc: 0.70573 | v_loss: 1.51659 v_acc: 0.69173 |  iteration: 17805 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 403 loss: 1.59045 acc: 0.69466 | v_loss: 1.37811 v_acc: 0.70020 |  iteration: 17806 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 404 loss: 1.47517 acc: 0.70312 | v_loss: 1.32175 v_acc: 0.70345 |  iteration: 17807 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 405 loss: 1.43555 acc: 0.70736 | v_loss: 1.33452 v_acc: 0.70215 |  iteration: 17808 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 406 loss: 1.46266 acc: 0.69531 | v_loss: 1.32443 v_acc: 0.71615 |  iteration: 17809 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 407 loss: 1.43287 acc: 0.69759 | v_loss: 1.54202 v_acc: 0.68945 |  iteration: 17810 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 408 loss: 1.41365 acc: 0.69987 | v_loss: 1.38655 v_acc: 0.70703 |  iteration: 17811 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 409 loss: 1.40574 acc: 0.70573 | v_loss: 1.36278 v_acc: 0.70833 |  iteration: 17812 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 410 loss: 1.44764 acc: 0.70020 | v_loss: 1.38595 v_acc: 0.71582 |  iteration: 17813 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 411 loss: 1.40960 acc: 0.70475 | v_loss: 1.27771 v_acc: 0.70573 |  iteration: 17814 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 412 loss: 1.37190 acc: 0.70247 | v_loss: 1.42089 v_acc: 0.70052 |  iteration: 17815 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 413 loss: 1.45613 acc: 0.70117 | v_loss: 1.42630 v_acc: 0.71224 |  iteration: 17816 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 414 loss: 1.51001 acc: 0.69173 | v_loss: 1.28293 v_acc: 0.72201 |  iteration: 17817 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 415 loss: 1.38200 acc: 0.71224 | v_loss: 1.25598 v_acc: 0.72591 |  iteration: 17818 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 416 loss: 1.42450 acc: 0.70736 | v_loss: 1.37354 v_acc: 0.72266 |  iteration: 17819 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 417 loss: 1.41136 acc: 0.69987 | v_loss: 1.42841 v_acc: 0.70410 |  iteration: 17820 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 418 loss: 1.43615 acc: 0.69727 | v_loss: 1.43733 v_acc: 0.70833 |  iteration: 17821 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 419 loss: 1.43185 acc: 0.70150 | v_loss: 1.22428 v_acc: 0.71712 |  iteration: 17822 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 420 loss: 1.48724 acc: 0.70150 | v_loss: 1.40685 v_acc: 0.72786 |  iteration: 17823 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 421 loss: 1.42888 acc: 0.70964 | v_loss: 1.48112 v_acc: 0.69792 |  iteration: 17824 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 422 loss: 1.55482 acc: 0.69694 | v_loss: 1.40362 v_acc: 0.72070 |  iteration: 17825 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 423 loss: 1.44065 acc: 0.70898 | v_loss: 1.25019 v_acc: 0.71842 |  iteration: 17826 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 424 loss: 1.45395 acc: 0.70280 | v_loss: 1.22265 v_acc: 0.72884 |  iteration: 17827 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 425 loss: 1.48784 acc: 0.69336 | v_loss: 1.21931 v_acc: 0.72624 |  iteration: 17828 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 426 loss: 1.40933 acc: 0.70475 | v_loss: 1.30409 v_acc: 0.70410 |  iteration: 17829 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 427 loss: 1.39208 acc: 0.71029 | v_loss: 1.44862 v_acc: 0.69499 |  iteration: 17830 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 428 loss: 1.47502 acc: 0.70671 | v_loss: 1.30194 v_acc: 0.71224 |  iteration: 17831 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 429 loss: 1.41870 acc: 0.70573 | v_loss: 1.46114 v_acc: 0.71582 |  iteration: 17832 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 430 loss: 1.52286 acc: 0.69564 | v_loss: 1.64939 v_acc: 0.69401 |  iteration: 17833 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 431 loss: 1.46073 acc: 0.69792 | v_loss: 1.50807 v_acc: 0.69922 |  iteration: 17834 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 432 loss: 1.44214 acc: 0.70866 | v_loss: 1.30362 v_acc: 0.72135 |  iteration: 17835 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 433 loss: 1.42804 acc: 0.70215 | v_loss: 1.36327 v_acc: 0.70410 |  iteration: 17836 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 434 loss: 1.43830 acc: 0.70866 | v_loss: 1.22173 v_acc: 0.71973 |  iteration: 17837 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 435 loss: 1.45413 acc: 0.70964 | v_loss: 1.41014 v_acc: 0.70150 |  iteration: 17838 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 436 loss: 1.43775 acc: 0.70150 | v_loss: 1.36124 v_acc: 0.71029 |  iteration: 17839 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 437 loss: 1.51834 acc: 0.68587 | v_loss: 1.34890 v_acc: 0.73079 |  iteration: 17840 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 438 loss: 1.50569 acc: 0.69564 | v_loss: 1.36408 v_acc: 0.71777 |  iteration: 17841 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 439 loss: 1.37074 acc: 0.71354 | v_loss: 1.38030 v_acc: 0.70410 |  iteration: 17842 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 440 loss: 1.41063 acc: 0.70605 | v_loss: 1.27763 v_acc: 0.72233 |  iteration: 17843 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 441 loss: 1.49054 acc: 0.69727 | v_loss: 1.29924 v_acc: 0.72135 |  iteration: 17844 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 442 loss: 1.49779 acc: 0.69531 | v_loss: 1.46916 v_acc: 0.69303 |  iteration: 17845 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 443 loss: 1.43712 acc: 0.70964 | v_loss: 1.34783 v_acc: 0.71159 |  iteration: 17846 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 444 loss: 1.37533 acc: 0.69889 | v_loss: 1.27783 v_acc: 0.71549 |  iteration: 17847 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 445 loss: 1.43669 acc: 0.70215 | v_loss: 1.26966 v_acc: 0.71973 |  iteration: 17848 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 446 loss: 1.41825 acc: 0.70768 | v_loss: 1.41356 v_acc: 0.70573 |  iteration: 17849 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 447 loss: 1.40674 acc: 0.69238 | v_loss: 1.31235 v_acc: 0.73112 |  iteration: 17850 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 448 loss: 1.38222 acc: 0.70410 | v_loss: 1.53877 v_acc: 0.71452 |  iteration: 17851 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 449 loss: 1.46058 acc: 0.70931 | v_loss: 1.27702 v_acc: 0.69759 |  iteration: 17852 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 450 loss: 1.44246 acc: 0.70378 | v_loss: 1.26686 v_acc: 0.70443 |  iteration: 17853 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 451 loss: 1.41424 acc: 0.70020 | v_loss: 1.44431 v_acc: 0.70475 |  iteration: 17854 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 452 loss: 1.50522 acc: 0.69727 | v_loss: 1.47208 v_acc: 0.70443 |  iteration: 17855 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 453 loss: 1.46501 acc: 0.69857 | v_loss: 1.50964 v_acc: 0.69076 |  iteration: 17856 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 454 loss: 1.38340 acc: 0.70150 | v_loss: 1.47002 v_acc: 0.70605 |  iteration: 17857 teacher: 0 stage: sketch lr: 0.000331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 455 loss: 1.48511 acc: 0.69401 | v_loss: 1.41123 v_acc: 0.70736 |  iteration: 17858 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 456 loss: 1.36650 acc: 0.70443 | v_loss: 1.39311 v_acc: 0.70703 |  iteration: 17859 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 457 loss: 1.39233 acc: 0.71061 | v_loss: 1.42169 v_acc: 0.70443 |  iteration: 17860 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 458 loss: 1.33968 acc: 0.70215 | v_loss: 1.27635 v_acc: 0.71159 |  iteration: 17861 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 459 loss: 1.46998 acc: 0.69824 | v_loss: 1.31030 v_acc: 0.72233 |  iteration: 17862 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 460 loss: 1.43316 acc: 0.70085 | v_loss: 1.18360 v_acc: 0.71615 |  iteration: 17863 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 461 loss: 1.42769 acc: 0.70443 | v_loss: 1.34448 v_acc: 0.71061 |  iteration: 17864 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 462 loss: 1.51017 acc: 0.69531 | v_loss: 1.52466 v_acc: 0.69466 |  iteration: 17865 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 463 loss: 1.50712 acc: 0.68848 | v_loss: 1.32377 v_acc: 0.71419 |  iteration: 17866 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 464 loss: 1.38421 acc: 0.69987 | v_loss: 1.33920 v_acc: 0.70801 |  iteration: 17867 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 465 loss: 1.48044 acc: 0.69661 | v_loss: 1.23860 v_acc: 0.71940 |  iteration: 17868 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 466 loss: 1.40944 acc: 0.70345 | v_loss: 1.23809 v_acc: 0.70671 |  iteration: 17869 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 467 loss: 1.49428 acc: 0.69564 | v_loss: 1.24617 v_acc: 0.73568 |  iteration: 17870 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 468 loss: 1.41981 acc: 0.70508 | v_loss: 1.25602 v_acc: 0.72396 |  iteration: 17871 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 469 loss: 1.37281 acc: 0.71224 | v_loss: 1.33581 v_acc: 0.73242 |  iteration: 17872 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 470 loss: 1.47655 acc: 0.69564 | v_loss: 1.26194 v_acc: 0.72461 |  iteration: 17873 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 471 loss: 1.44067 acc: 0.70638 | v_loss: 1.30899 v_acc: 0.72005 |  iteration: 17874 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 472 loss: 1.37057 acc: 0.71289 | v_loss: 1.43187 v_acc: 0.71224 |  iteration: 17875 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 473 loss: 1.42942 acc: 0.69531 | v_loss: 1.39886 v_acc: 0.72070 |  iteration: 17876 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 474 loss: 1.39551 acc: 0.70378 | v_loss: 1.48297 v_acc: 0.69954 |  iteration: 17877 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 475 loss: 1.45102 acc: 0.70052 | v_loss: 1.42932 v_acc: 0.71615 |  iteration: 17878 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 476 loss: 1.44225 acc: 0.70345 | v_loss: 1.18768 v_acc: 0.74544 |  iteration: 17879 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 477 loss: 1.33900 acc: 0.70443 | v_loss: 1.24924 v_acc: 0.70931 |  iteration: 17880 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 478 loss: 1.37237 acc: 0.71452 | v_loss: 1.53554 v_acc: 0.70247 |  iteration: 17881 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 479 loss: 1.40227 acc: 0.70573 | v_loss: 1.21703 v_acc: 0.70866 |  iteration: 17882 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 480 loss: 1.48506 acc: 0.69238 | v_loss: 1.32715 v_acc: 0.71224 |  iteration: 17883 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 481 loss: 1.31533 acc: 0.71452 | v_loss: 1.37128 v_acc: 0.69368 |  iteration: 17884 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 482 loss: 1.34814 acc: 0.70378 | v_loss: 1.29273 v_acc: 0.71842 |  iteration: 17885 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 483 loss: 1.41515 acc: 0.70540 | v_loss: 1.36438 v_acc: 0.70215 |  iteration: 17886 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 484 loss: 1.41555 acc: 0.69954 | v_loss: 1.48414 v_acc: 0.72005 |  iteration: 17887 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 485 loss: 1.48880 acc: 0.69368 | v_loss: 1.32326 v_acc: 0.72786 |  iteration: 17888 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 486 loss: 1.28711 acc: 0.71289 | v_loss: 1.44523 v_acc: 0.70085 |  iteration: 17889 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 487 loss: 1.36342 acc: 0.70312 | v_loss: 1.37177 v_acc: 0.69076 |  iteration: 17890 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 488 loss: 1.56899 acc: 0.68750 | v_loss: 1.31349 v_acc: 0.70833 |  iteration: 17891 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 489 loss: 1.38655 acc: 0.70736 | v_loss: 1.57144 v_acc: 0.68522 |  iteration: 17892 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 490 loss: 1.40083 acc: 0.70605 | v_loss: 1.30236 v_acc: 0.72168 |  iteration: 17893 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 491 loss: 1.51435 acc: 0.69271 | v_loss: 1.59415 v_acc: 0.68262 |  iteration: 17894 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 492 loss: 1.42143 acc: 0.69954 | v_loss: 1.45425 v_acc: 0.69792 |  iteration: 17895 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 493 loss: 1.50025 acc: 0.69401 | v_loss: 1.53127 v_acc: 0.69173 |  iteration: 17896 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 494 loss: 1.37324 acc: 0.70768 | v_loss: 1.37064 v_acc: 0.70020 |  iteration: 17897 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 495 loss: 1.42224 acc: 0.70540 | v_loss: 1.32483 v_acc: 0.70638 |  iteration: 17898 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 496 loss: 1.47972 acc: 0.69336 | v_loss: 1.33150 v_acc: 0.70410 |  iteration: 17899 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 497 loss: 1.46547 acc: 0.69889 | v_loss: 1.33217 v_acc: 0.71842 |  iteration: 17900 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 498 loss: 1.47636 acc: 0.69889 | v_loss: 1.54618 v_acc: 0.69043 |  iteration: 17901 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 499 loss: 1.40814 acc: 0.70573 | v_loss: 1.37609 v_acc: 0.70671 |  iteration: 17902 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 500 loss: 1.45997 acc: 0.69564 | v_loss: 1.33742 v_acc: 0.71029 |  iteration: 17903 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 501 loss: 1.37325 acc: 0.71615 | v_loss: 1.38442 v_acc: 0.71680 |  iteration: 17904 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 502 loss: 1.39762 acc: 0.70280 | v_loss: 1.27140 v_acc: 0.70443 |  iteration: 17905 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 503 loss: 1.44277 acc: 0.70280 | v_loss: 1.41600 v_acc: 0.69889 |  iteration: 17906 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 504 loss: 1.42839 acc: 0.70312 | v_loss: 1.41752 v_acc: 0.71647 |  iteration: 17907 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 505 loss: 1.37477 acc: 0.71159 | v_loss: 1.28894 v_acc: 0.71777 |  iteration: 17908 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 506 loss: 1.53796 acc: 0.70475 | v_loss: 1.24867 v_acc: 0.72982 |  iteration: 17909 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 507 loss: 1.45632 acc: 0.70117 | v_loss: 1.36971 v_acc: 0.71615 |  iteration: 17910 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 508 loss: 1.38657 acc: 0.70898 | v_loss: 1.41850 v_acc: 0.70540 |  iteration: 17911 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 509 loss: 1.48319 acc: 0.69629 | v_loss: 1.42158 v_acc: 0.70410 |  iteration: 17912 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 510 loss: 1.34773 acc: 0.71484 | v_loss: 1.22350 v_acc: 0.71712 |  iteration: 17913 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 511 loss: 1.37405 acc: 0.70475 | v_loss: 1.38863 v_acc: 0.72786 |  iteration: 17914 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 512 loss: 1.43035 acc: 0.69694 | v_loss: 1.47848 v_acc: 0.69792 |  iteration: 17915 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 513 loss: 1.31111 acc: 0.70801 | v_loss: 1.42460 v_acc: 0.72070 |  iteration: 17916 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 514 loss: 1.47820 acc: 0.69694 | v_loss: 1.24431 v_acc: 0.72201 |  iteration: 17917 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 515 loss: 1.44135 acc: 0.70117 | v_loss: 1.18927 v_acc: 0.74447 |  iteration: 17918 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 516 loss: 1.36245 acc: 0.70996 | v_loss: 1.20633 v_acc: 0.72493 |  iteration: 17919 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 517 loss: 1.42515 acc: 0.70117 | v_loss: 1.27052 v_acc: 0.71126 |  iteration: 17920 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 518 loss: 1.35773 acc: 0.71810 | v_loss: 1.44773 v_acc: 0.70671 |  iteration: 17921 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 519 loss: 1.40289 acc: 0.70182 | v_loss: 1.27446 v_acc: 0.71549 |  iteration: 17922 teacher: 1 stage: sketch lr: 0.000330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 520 loss: 1.44988 acc: 0.69661 | v_loss: 1.49370 v_acc: 0.70475 |  iteration: 17923 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 521 loss: 1.44159 acc: 0.69466 | v_loss: 1.70035 v_acc: 0.68913 |  iteration: 17924 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 522 loss: 1.42884 acc: 0.69987 | v_loss: 1.54565 v_acc: 0.69531 |  iteration: 17925 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 523 loss: 1.39297 acc: 0.69694 | v_loss: 1.29607 v_acc: 0.72526 |  iteration: 17926 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 524 loss: 1.40889 acc: 0.70508 | v_loss: 1.36288 v_acc: 0.70964 |  iteration: 17927 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 525 loss: 1.45292 acc: 0.69987 | v_loss: 1.21242 v_acc: 0.72103 |  iteration: 17928 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 526 loss: 1.44678 acc: 0.69466 | v_loss: 1.40440 v_acc: 0.70410 |  iteration: 17929 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 527 loss: 1.36703 acc: 0.70410 | v_loss: 1.35379 v_acc: 0.71810 |  iteration: 17930 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 528 loss: 1.41982 acc: 0.71094 | v_loss: 1.35428 v_acc: 0.72982 |  iteration: 17931 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 529 loss: 1.38835 acc: 0.70247 | v_loss: 1.35584 v_acc: 0.71810 |  iteration: 17932 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 530 loss: 1.46815 acc: 0.69889 | v_loss: 1.36798 v_acc: 0.70508 |  iteration: 17933 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 531 loss: 1.34147 acc: 0.71354 | v_loss: 1.28196 v_acc: 0.72201 |  iteration: 17934 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 532 loss: 1.34173 acc: 0.70280 | v_loss: 1.29781 v_acc: 0.72005 |  iteration: 17935 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 533 loss: 1.37653 acc: 0.71549 | v_loss: 1.49312 v_acc: 0.69010 |  iteration: 17936 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 534 loss: 1.43149 acc: 0.69987 | v_loss: 1.33285 v_acc: 0.71159 |  iteration: 17937 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 535 loss: 1.40135 acc: 0.69987 | v_loss: 1.29127 v_acc: 0.71582 |  iteration: 17938 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 536 loss: 1.40811 acc: 0.70801 | v_loss: 1.28166 v_acc: 0.71973 |  iteration: 17939 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 537 loss: 1.49540 acc: 0.70312 | v_loss: 1.42778 v_acc: 0.70573 |  iteration: 17940 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 538 loss: 1.41334 acc: 0.71094 | v_loss: 1.31009 v_acc: 0.73112 |  iteration: 17941 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 539 loss: 1.32398 acc: 0.70671 | v_loss: 1.54452 v_acc: 0.71452 |  iteration: 17942 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 540 loss: 1.45595 acc: 0.69954 | v_loss: 1.27850 v_acc: 0.69759 |  iteration: 17943 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 541 loss: 1.31875 acc: 0.72168 | v_loss: 1.27177 v_acc: 0.70443 |  iteration: 17944 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 542 loss: 1.47690 acc: 0.70410 | v_loss: 1.44245 v_acc: 0.70312 |  iteration: 17945 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 543 loss: 1.33040 acc: 0.71322 | v_loss: 1.47358 v_acc: 0.70378 |  iteration: 17946 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 544 loss: 1.41262 acc: 0.69499 | v_loss: 1.51689 v_acc: 0.68978 |  iteration: 17947 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 545 loss: 1.31542 acc: 0.72233 | v_loss: 1.46812 v_acc: 0.70638 |  iteration: 17948 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 546 loss: 1.54948 acc: 0.69434 | v_loss: 1.42015 v_acc: 0.70410 |  iteration: 17949 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 547 loss: 1.45643 acc: 0.70638 | v_loss: 1.40631 v_acc: 0.70703 |  iteration: 17950 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 548 loss: 1.46741 acc: 0.71257 | v_loss: 1.40541 v_acc: 0.70443 |  iteration: 17951 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 549 loss: 1.47400 acc: 0.70378 | v_loss: 1.26216 v_acc: 0.71159 |  iteration: 17952 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 550 loss: 1.55943 acc: 0.69271 | v_loss: 1.31966 v_acc: 0.72396 |  iteration: 17953 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 551 loss: 1.38696 acc: 0.70508 | v_loss: 1.19435 v_acc: 0.70638 |  iteration: 17954 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 552 loss: 1.42612 acc: 0.70475 | v_loss: 1.34433 v_acc: 0.70280 |  iteration: 17955 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 553 loss: 1.48122 acc: 0.69368 | v_loss: 1.49931 v_acc: 0.69987 |  iteration: 17956 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 554 loss: 1.37795 acc: 0.71191 | v_loss: 1.33675 v_acc: 0.70605 |  iteration: 17957 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 555 loss: 1.42251 acc: 0.70345 | v_loss: 1.35618 v_acc: 0.69694 |  iteration: 17958 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 556 loss: 1.46400 acc: 0.69759 | v_loss: 1.25137 v_acc: 0.70638 |  iteration: 17959 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 557 loss: 1.35462 acc: 0.70964 | v_loss: 1.24739 v_acc: 0.70410 |  iteration: 17960 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 558 loss: 1.37663 acc: 0.70573 | v_loss: 1.24952 v_acc: 0.73470 |  iteration: 17961 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 559 loss: 1.33878 acc: 0.70247 | v_loss: 1.26806 v_acc: 0.72168 |  iteration: 17962 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 560 loss: 1.38345 acc: 0.70475 | v_loss: 1.35428 v_acc: 0.73145 |  iteration: 17963 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 561 loss: 1.35513 acc: 0.72624 | v_loss: 1.25814 v_acc: 0.72461 |  iteration: 17964 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 562 loss: 1.49103 acc: 0.70117 | v_loss: 1.31120 v_acc: 0.72103 |  iteration: 17965 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 563 loss: 1.44501 acc: 0.70573 | v_loss: 1.42662 v_acc: 0.71354 |  iteration: 17966 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 564 loss: 1.48102 acc: 0.69987 | v_loss: 1.40190 v_acc: 0.72428 |  iteration: 17967 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 565 loss: 1.37062 acc: 0.69889 | v_loss: 1.49475 v_acc: 0.70378 |  iteration: 17968 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 566 loss: 1.46818 acc: 0.70898 | v_loss: 1.42739 v_acc: 0.71452 |  iteration: 17969 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 567 loss: 1.37324 acc: 0.71224 | v_loss: 1.17850 v_acc: 0.74284 |  iteration: 17970 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 568 loss: 1.44942 acc: 0.70280 | v_loss: 1.26062 v_acc: 0.71126 |  iteration: 17971 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 569 loss: 1.44587 acc: 0.69629 | v_loss: 1.52879 v_acc: 0.69987 |  iteration: 17972 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 570 loss: 1.31183 acc: 0.72233 | v_loss: 1.22484 v_acc: 0.70671 |  iteration: 17973 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 571 loss: 1.44379 acc: 0.70247 | v_loss: 1.32588 v_acc: 0.71094 |  iteration: 17974 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 572 loss: 1.44769 acc: 0.70996 | v_loss: 1.36223 v_acc: 0.69466 |  iteration: 17975 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 573 loss: 1.45512 acc: 0.69238 | v_loss: 1.30107 v_acc: 0.70768 |  iteration: 17976 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 574 loss: 1.45778 acc: 0.69629 | v_loss: 1.35620 v_acc: 0.69368 |  iteration: 17977 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 575 loss: 1.40652 acc: 0.70508 | v_loss: 1.48999 v_acc: 0.70736 |  iteration: 17978 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 576 loss: 1.54746 acc: 0.69303 | v_loss: 1.31601 v_acc: 0.72754 |  iteration: 17979 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 577 loss: 1.44709 acc: 0.70931 | v_loss: 1.45367 v_acc: 0.70215 |  iteration: 17980 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 578 loss: 1.45904 acc: 0.70117 | v_loss: 1.34742 v_acc: 0.69954 |  iteration: 17981 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 579 loss: 1.43200 acc: 0.70182 | v_loss: 1.32932 v_acc: 0.70931 |  iteration: 17982 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 580 loss: 1.49015 acc: 0.69824 | v_loss: 1.53712 v_acc: 0.68815 |  iteration: 17983 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 581 loss: 1.47724 acc: 0.70671 | v_loss: 1.29430 v_acc: 0.72070 |  iteration: 17984 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 582 loss: 1.53451 acc: 0.70085 | v_loss: 1.58676 v_acc: 0.68359 |  iteration: 17985 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 583 loss: 1.46029 acc: 0.69531 | v_loss: 1.46914 v_acc: 0.69661 |  iteration: 17986 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 584 loss: 1.48591 acc: 0.69629 | v_loss: 1.51404 v_acc: 0.69238 |  iteration: 17987 teacher: 1 stage: sketch lr: 0.000330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 585 loss: 1.53276 acc: 0.68490 | v_loss: 1.37935 v_acc: 0.70182 |  iteration: 17988 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 586 loss: 1.45138 acc: 0.70215 | v_loss: 1.31964 v_acc: 0.70638 |  iteration: 17989 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 587 loss: 1.34055 acc: 0.71647 | v_loss: 1.33214 v_acc: 0.70410 |  iteration: 17990 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 588 loss: 1.42844 acc: 0.70638 | v_loss: 1.33209 v_acc: 0.71842 |  iteration: 17991 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 589 loss: 1.39708 acc: 0.70573 | v_loss: 1.53031 v_acc: 0.69271 |  iteration: 17992 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 590 loss: 1.49820 acc: 0.70280 | v_loss: 1.37327 v_acc: 0.70443 |  iteration: 17993 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 591 loss: 1.43359 acc: 0.69596 | v_loss: 1.35081 v_acc: 0.71029 |  iteration: 17994 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 592 loss: 1.43159 acc: 0.70833 | v_loss: 1.39325 v_acc: 0.71680 |  iteration: 17995 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 593 loss: 1.36255 acc: 0.70638 | v_loss: 1.27246 v_acc: 0.70573 |  iteration: 17996 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 594 loss: 1.44908 acc: 0.70703 | v_loss: 1.43235 v_acc: 0.69792 |  iteration: 17997 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 595 loss: 1.41446 acc: 0.70768 | v_loss: 1.43946 v_acc: 0.71224 |  iteration: 17998 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 596 loss: 1.38511 acc: 0.70052 | v_loss: 1.28781 v_acc: 0.71875 |  iteration: 17999 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 597 loss: 1.46516 acc: 0.69564 | v_loss: 1.26374 v_acc: 0.72754 |  iteration: 18000 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 598 loss: 1.41915 acc: 0.69466 | v_loss: 1.37374 v_acc: 0.71940 |  iteration: 18001 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 599 loss: 1.45370 acc: 0.69792 | v_loss: 1.42985 v_acc: 0.70345 |  iteration: 18002 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 600 loss: 1.51732 acc: 0.69727 | v_loss: 1.43530 v_acc: 0.70410 |  iteration: 18003 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 601 loss: 1.45953 acc: 0.69922 | v_loss: 1.22840 v_acc: 0.72591 |  iteration: 18004 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 602 loss: 1.37423 acc: 0.71322 | v_loss: 1.38988 v_acc: 0.73047 |  iteration: 18005 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 603 loss: 1.41112 acc: 0.70801 | v_loss: 1.47078 v_acc: 0.69759 |  iteration: 18006 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 604 loss: 1.38581 acc: 0.70671 | v_loss: 1.41541 v_acc: 0.72201 |  iteration: 18007 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 605 loss: 1.43952 acc: 0.70443 | v_loss: 1.23986 v_acc: 0.72233 |  iteration: 18008 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 606 loss: 1.39560 acc: 0.69727 | v_loss: 1.18699 v_acc: 0.74447 |  iteration: 18009 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 607 loss: 1.34956 acc: 0.71647 | v_loss: 1.20895 v_acc: 0.72493 |  iteration: 18010 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 608 loss: 1.36153 acc: 0.70866 | v_loss: 1.27677 v_acc: 0.71126 |  iteration: 18011 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 609 loss: 1.62225 acc: 0.68262 | v_loss: 1.45258 v_acc: 0.70671 |  iteration: 18012 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 610 loss: 1.37802 acc: 0.71029 | v_loss: 1.27060 v_acc: 0.71452 |  iteration: 18013 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 611 loss: 1.37687 acc: 0.70085 | v_loss: 1.44511 v_acc: 0.71582 |  iteration: 18014 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 612 loss: 1.44311 acc: 0.70866 | v_loss: 1.66626 v_acc: 0.69401 |  iteration: 18015 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 613 loss: 1.56882 acc: 0.69238 | v_loss: 1.52406 v_acc: 0.69922 |  iteration: 18016 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 614 loss: 1.32714 acc: 0.71029 | v_loss: 1.29252 v_acc: 0.72168 |  iteration: 18017 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 615 loss: 1.42169 acc: 0.70085 | v_loss: 1.37085 v_acc: 0.70312 |  iteration: 18018 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 616 loss: 1.43566 acc: 0.70443 | v_loss: 1.21507 v_acc: 0.72103 |  iteration: 18019 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 617 loss: 1.40782 acc: 0.70833 | v_loss: 1.41653 v_acc: 0.70150 |  iteration: 18020 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 618 loss: 1.40362 acc: 0.69954 | v_loss: 1.35422 v_acc: 0.71029 |  iteration: 18021 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 619 loss: 1.55434 acc: 0.70508 | v_loss: 1.34626 v_acc: 0.73079 |  iteration: 18022 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 620 loss: 1.42826 acc: 0.69466 | v_loss: 1.35520 v_acc: 0.71777 |  iteration: 18023 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 621 loss: 1.34200 acc: 0.71191 | v_loss: 1.36795 v_acc: 0.70410 |  iteration: 18024 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 622 loss: 1.45400 acc: 0.70573 | v_loss: 1.28308 v_acc: 0.72233 |  iteration: 18025 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 623 loss: 1.44449 acc: 0.69531 | v_loss: 1.29457 v_acc: 0.72135 |  iteration: 18026 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 624 loss: 1.48273 acc: 0.69824 | v_loss: 1.50250 v_acc: 0.69303 |  iteration: 18027 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 625 loss: 1.30361 acc: 0.70768 | v_loss: 1.33947 v_acc: 0.71159 |  iteration: 18028 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 626 loss: 1.38859 acc: 0.70703 | v_loss: 1.28170 v_acc: 0.71549 |  iteration: 18029 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 627 loss: 1.49089 acc: 0.69824 | v_loss: 1.28191 v_acc: 0.71973 |  iteration: 18030 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 628 loss: 1.36119 acc: 0.70280 | v_loss: 1.42819 v_acc: 0.70573 |  iteration: 18031 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 629 loss: 1.41577 acc: 0.69857 | v_loss: 1.31959 v_acc: 0.72949 |  iteration: 18032 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 630 loss: 1.40320 acc: 0.71322 | v_loss: 1.54831 v_acc: 0.71387 |  iteration: 18033 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 631 loss: 1.43361 acc: 0.70117 | v_loss: 1.27928 v_acc: 0.69759 |  iteration: 18034 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 632 loss: 1.46296 acc: 0.69727 | v_loss: 1.27648 v_acc: 0.70573 |  iteration: 18035 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 633 loss: 1.44596 acc: 0.70475 | v_loss: 1.43836 v_acc: 0.70312 |  iteration: 18036 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 634 loss: 1.37947 acc: 0.70638 | v_loss: 1.47156 v_acc: 0.70247 |  iteration: 18037 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 635 loss: 1.30725 acc: 0.70508 | v_loss: 1.51430 v_acc: 0.69368 |  iteration: 18038 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 636 loss: 1.40119 acc: 0.71257 | v_loss: 1.46897 v_acc: 0.70833 |  iteration: 18039 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 637 loss: 1.37119 acc: 0.70508 | v_loss: 1.41879 v_acc: 0.70182 |  iteration: 18040 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 638 loss: 1.47489 acc: 0.69889 | v_loss: 1.40190 v_acc: 0.70801 |  iteration: 18041 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 639 loss: 1.38387 acc: 0.71517 | v_loss: 1.40535 v_acc: 0.70573 |  iteration: 18042 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 640 loss: 1.37631 acc: 0.71289 | v_loss: 1.26594 v_acc: 0.71159 |  iteration: 18043 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 641 loss: 1.44246 acc: 0.70150 | v_loss: 1.31787 v_acc: 0.72396 |  iteration: 18044 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 642 loss: 1.46968 acc: 0.70280 | v_loss: 1.19950 v_acc: 0.70638 |  iteration: 18045 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 643 loss: 1.35259 acc: 0.70866 | v_loss: 1.34453 v_acc: 0.70247 |  iteration: 18046 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 644 loss: 1.45933 acc: 0.70052 | v_loss: 1.51081 v_acc: 0.69922 |  iteration: 18047 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 645 loss: 1.50512 acc: 0.69629 | v_loss: 1.34391 v_acc: 0.70833 |  iteration: 18048 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 646 loss: 1.43244 acc: 0.71257 | v_loss: 1.35419 v_acc: 0.69727 |  iteration: 18049 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 647 loss: 1.47574 acc: 0.68978 | v_loss: 1.24648 v_acc: 0.71126 |  iteration: 18050 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 648 loss: 1.46272 acc: 0.69922 | v_loss: 1.23968 v_acc: 0.70378 |  iteration: 18051 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 649 loss: 1.36296 acc: 0.70866 | v_loss: 1.25026 v_acc: 0.73568 |  iteration: 18052 teacher: 0 stage: sketch lr: 0.000329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 650 loss: 1.37147 acc: 0.70605 | v_loss: 1.26189 v_acc: 0.72461 |  iteration: 18053 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 651 loss: 1.35195 acc: 0.70833 | v_loss: 1.33996 v_acc: 0.72689 |  iteration: 18054 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 652 loss: 1.31819 acc: 0.70931 | v_loss: 1.26102 v_acc: 0.72852 |  iteration: 18055 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 653 loss: 1.45538 acc: 0.70410 | v_loss: 1.30578 v_acc: 0.72038 |  iteration: 18056 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 654 loss: 1.36040 acc: 0.71159 | v_loss: 1.42423 v_acc: 0.71224 |  iteration: 18057 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 655 loss: 1.44289 acc: 0.70573 | v_loss: 1.39643 v_acc: 0.72070 |  iteration: 18058 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 656 loss: 1.39006 acc: 0.70182 | v_loss: 1.48414 v_acc: 0.69954 |  iteration: 18059 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 657 loss: 1.28597 acc: 0.71029 | v_loss: 1.41889 v_acc: 0.71615 |  iteration: 18060 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 658 loss: 1.53556 acc: 0.69824 | v_loss: 1.17337 v_acc: 0.74414 |  iteration: 18061 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 659 loss: 1.46165 acc: 0.70378 | v_loss: 1.24657 v_acc: 0.70573 |  iteration: 18062 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 660 loss: 1.38113 acc: 0.70345 | v_loss: 1.52647 v_acc: 0.70345 |  iteration: 18063 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 661 loss: 1.35113 acc: 0.71973 | v_loss: 1.20062 v_acc: 0.71094 |  iteration: 18064 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 662 loss: 1.42833 acc: 0.70020 | v_loss: 1.32480 v_acc: 0.71224 |  iteration: 18065 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 663 loss: 1.41261 acc: 0.71289 | v_loss: 1.36881 v_acc: 0.69271 |  iteration: 18066 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 664 loss: 1.42970 acc: 0.69987 | v_loss: 1.29096 v_acc: 0.71191 |  iteration: 18067 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 665 loss: 1.50976 acc: 0.69954 | v_loss: 1.37118 v_acc: 0.69336 |  iteration: 18068 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 666 loss: 1.52260 acc: 0.70182 | v_loss: 1.46466 v_acc: 0.71257 |  iteration: 18069 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 667 loss: 1.47261 acc: 0.70638 | v_loss: 1.31679 v_acc: 0.72819 |  iteration: 18070 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 668 loss: 1.49680 acc: 0.70150 | v_loss: 1.43427 v_acc: 0.70312 |  iteration: 18071 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 669 loss: 1.41238 acc: 0.69889 | v_loss: 1.37497 v_acc: 0.69987 |  iteration: 18072 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 670 loss: 1.51486 acc: 0.69759 | v_loss: 1.32573 v_acc: 0.70964 |  iteration: 18073 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 671 loss: 1.50192 acc: 0.69076 | v_loss: 1.54830 v_acc: 0.68945 |  iteration: 18074 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 672 loss: 1.40082 acc: 0.70247 | v_loss: 1.29251 v_acc: 0.72135 |  iteration: 18075 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 673 loss: 1.49114 acc: 0.70671 | v_loss: 1.59761 v_acc: 0.68294 |  iteration: 18076 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 674 loss: 1.35297 acc: 0.71484 | v_loss: 1.44213 v_acc: 0.69889 |  iteration: 18077 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 675 loss: 1.43096 acc: 0.70215 | v_loss: 1.52486 v_acc: 0.69173 |  iteration: 18078 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 676 loss: 1.55943 acc: 0.68717 | v_loss: 1.36973 v_acc: 0.70020 |  iteration: 18079 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 677 loss: 1.47564 acc: 0.69206 | v_loss: 1.33869 v_acc: 0.70312 |  iteration: 18080 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 678 loss: 1.34538 acc: 0.71224 | v_loss: 1.33805 v_acc: 0.70020 |  iteration: 18081 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 679 loss: 1.43151 acc: 0.71419 | v_loss: 1.33706 v_acc: 0.71484 |  iteration: 18082 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 680 loss: 1.45952 acc: 0.70638 | v_loss: 1.52566 v_acc: 0.68978 |  iteration: 18083 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 681 loss: 1.53208 acc: 0.69303 | v_loss: 1.37069 v_acc: 0.70443 |  iteration: 18084 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 682 loss: 1.38542 acc: 0.70182 | v_loss: 1.35509 v_acc: 0.71029 |  iteration: 18085 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 683 loss: 1.52543 acc: 0.68848 | v_loss: 1.38530 v_acc: 0.71680 |  iteration: 18086 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 684 loss: 1.42570 acc: 0.69792 | v_loss: 1.26876 v_acc: 0.70703 |  iteration: 18087 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 685 loss: 1.39342 acc: 0.70443 | v_loss: 1.43312 v_acc: 0.70052 |  iteration: 18088 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 686 loss: 1.40306 acc: 0.70573 | v_loss: 1.43144 v_acc: 0.71224 |  iteration: 18089 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 687 loss: 1.37858 acc: 0.70801 | v_loss: 1.28318 v_acc: 0.72201 |  iteration: 18090 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 688 loss: 1.52156 acc: 0.69889 | v_loss: 1.25014 v_acc: 0.72591 |  iteration: 18091 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 689 loss: 1.41677 acc: 0.70280 | v_loss: 1.37028 v_acc: 0.71940 |  iteration: 18092 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 690 loss: 1.44788 acc: 0.69824 | v_loss: 1.41223 v_acc: 0.70540 |  iteration: 18093 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 691 loss: 1.35282 acc: 0.70573 | v_loss: 1.42454 v_acc: 0.70508 |  iteration: 18094 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 692 loss: 1.44975 acc: 0.69727 | v_loss: 1.22678 v_acc: 0.71452 |  iteration: 18095 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 693 loss: 1.38608 acc: 0.70736 | v_loss: 1.39048 v_acc: 0.72819 |  iteration: 18096 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 694 loss: 1.42916 acc: 0.69629 | v_loss: 1.48000 v_acc: 0.69759 |  iteration: 18097 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 695 loss: 1.43601 acc: 0.70605 | v_loss: 1.40782 v_acc: 0.72298 |  iteration: 18098 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 696 loss: 1.46407 acc: 0.69661 | v_loss: 1.24804 v_acc: 0.71615 |  iteration: 18099 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 697 loss: 1.49538 acc: 0.69238 | v_loss: 1.20544 v_acc: 0.73600 |  iteration: 18100 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 698 loss: 1.46954 acc: 0.69499 | v_loss: 1.21407 v_acc: 0.72656 |  iteration: 18101 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 699 loss: 1.41009 acc: 0.69694 | v_loss: 1.28035 v_acc: 0.70768 |  iteration: 18102 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 700 loss: 1.49120 acc: 0.69727 | v_loss: 1.45675 v_acc: 0.70052 |  iteration: 18103 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 701 loss: 1.39358 acc: 0.70443 | v_loss: 1.27084 v_acc: 0.71452 |  iteration: 18104 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 702 loss: 1.36975 acc: 0.70866 | v_loss: 1.43707 v_acc: 0.71647 |  iteration: 18105 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 703 loss: 1.49231 acc: 0.69401 | v_loss: 1.68923 v_acc: 0.69141 |  iteration: 18106 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 704 loss: 1.42941 acc: 0.69271 | v_loss: 1.52637 v_acc: 0.69727 |  iteration: 18107 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 705 loss: 1.40488 acc: 0.70540 | v_loss: 1.29205 v_acc: 0.72396 |  iteration: 18108 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 706 loss: 1.46490 acc: 0.69759 | v_loss: 1.36647 v_acc: 0.70996 |  iteration: 18109 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 707 loss: 1.36433 acc: 0.70312 | v_loss: 1.21126 v_acc: 0.72201 |  iteration: 18110 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 708 loss: 1.53969 acc: 0.69141 | v_loss: 1.42103 v_acc: 0.70378 |  iteration: 18111 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 709 loss: 1.39241 acc: 0.70801 | v_loss: 1.35661 v_acc: 0.71842 |  iteration: 18112 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 710 loss: 1.44272 acc: 0.69661 | v_loss: 1.36028 v_acc: 0.73014 |  iteration: 18113 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 711 loss: 1.31769 acc: 0.71387 | v_loss: 1.36868 v_acc: 0.71973 |  iteration: 18114 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 712 loss: 1.45859 acc: 0.69564 | v_loss: 1.37318 v_acc: 0.70964 |  iteration: 18115 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 713 loss: 1.51930 acc: 0.68392 | v_loss: 1.28251 v_acc: 0.72493 |  iteration: 18116 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 714 loss: 1.44725 acc: 0.69368 | v_loss: 1.29689 v_acc: 0.72168 |  iteration: 18117 teacher: 1 stage: sketch lr: 0.000328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 715 loss: 1.43579 acc: 0.70215 | v_loss: 1.46841 v_acc: 0.69303 |  iteration: 18118 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 716 loss: 1.41508 acc: 0.69531 | v_loss: 1.33645 v_acc: 0.71159 |  iteration: 18119 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 717 loss: 1.49571 acc: 0.70247 | v_loss: 1.28396 v_acc: 0.71549 |  iteration: 18120 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 718 loss: 1.39015 acc: 0.70475 | v_loss: 1.28042 v_acc: 0.71973 |  iteration: 18121 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 719 loss: 1.38614 acc: 0.70378 | v_loss: 1.42498 v_acc: 0.70573 |  iteration: 18122 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 720 loss: 1.48878 acc: 0.69499 | v_loss: 1.31257 v_acc: 0.73112 |  iteration: 18123 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 721 loss: 1.36278 acc: 0.70508 | v_loss: 1.54662 v_acc: 0.71452 |  iteration: 18124 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 722 loss: 1.44996 acc: 0.70801 | v_loss: 1.28579 v_acc: 0.69759 |  iteration: 18125 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 723 loss: 1.47096 acc: 0.70540 | v_loss: 1.27969 v_acc: 0.70443 |  iteration: 18126 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 724 loss: 1.52202 acc: 0.69661 | v_loss: 1.42965 v_acc: 0.70312 |  iteration: 18127 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 725 loss: 1.41431 acc: 0.71159 | v_loss: 1.46291 v_acc: 0.70378 |  iteration: 18128 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 726 loss: 1.52670 acc: 0.69694 | v_loss: 1.50562 v_acc: 0.68978 |  iteration: 18129 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 727 loss: 1.43368 acc: 0.70573 | v_loss: 1.47466 v_acc: 0.70638 |  iteration: 18130 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 728 loss: 1.46156 acc: 0.70182 | v_loss: 1.41384 v_acc: 0.70475 |  iteration: 18131 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 729 loss: 1.40303 acc: 0.70833 | v_loss: 1.39643 v_acc: 0.70638 |  iteration: 18132 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 730 loss: 1.42487 acc: 0.70573 | v_loss: 1.41876 v_acc: 0.70475 |  iteration: 18133 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 731 loss: 1.44444 acc: 0.70605 | v_loss: 1.27013 v_acc: 0.71354 |  iteration: 18134 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 732 loss: 1.51747 acc: 0.69076 | v_loss: 1.31288 v_acc: 0.72461 |  iteration: 18135 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 733 loss: 1.49474 acc: 0.70020 | v_loss: 1.19848 v_acc: 0.71517 |  iteration: 18136 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 734 loss: 1.46258 acc: 0.69727 | v_loss: 1.34252 v_acc: 0.70703 |  iteration: 18137 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 735 loss: 1.43333 acc: 0.70312 | v_loss: 1.50175 v_acc: 0.69824 |  iteration: 18138 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 736 loss: 1.51464 acc: 0.70280 | v_loss: 1.32355 v_acc: 0.71387 |  iteration: 18139 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 737 loss: 1.43761 acc: 0.69889 | v_loss: 1.33713 v_acc: 0.70182 |  iteration: 18140 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 738 loss: 1.44781 acc: 0.69010 | v_loss: 1.25065 v_acc: 0.71419 |  iteration: 18141 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 739 loss: 1.41168 acc: 0.70996 | v_loss: 1.24563 v_acc: 0.70703 |  iteration: 18142 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 740 loss: 1.37586 acc: 0.70671 | v_loss: 1.23651 v_acc: 0.73730 |  iteration: 18143 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 741 loss: 1.44151 acc: 0.70117 | v_loss: 1.26437 v_acc: 0.72461 |  iteration: 18144 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 742 loss: 1.51902 acc: 0.69629 | v_loss: 1.33214 v_acc: 0.72689 |  iteration: 18145 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 743 loss: 1.45525 acc: 0.69987 | v_loss: 1.26076 v_acc: 0.72852 |  iteration: 18146 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 744 loss: 1.38284 acc: 0.70638 | v_loss: 1.30125 v_acc: 0.72070 |  iteration: 18147 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 745 loss: 1.66969 acc: 0.68555 | v_loss: 1.40638 v_acc: 0.71354 |  iteration: 18148 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 746 loss: 1.32171 acc: 0.70866 | v_loss: 1.39182 v_acc: 0.72428 |  iteration: 18149 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 747 loss: 1.46923 acc: 0.69368 | v_loss: 1.48205 v_acc: 0.70150 |  iteration: 18150 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 748 loss: 1.42726 acc: 0.70215 | v_loss: 1.41039 v_acc: 0.71615 |  iteration: 18151 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 749 loss: 1.39099 acc: 0.70866 | v_loss: 1.17474 v_acc: 0.74544 |  iteration: 18152 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 750 loss: 1.44899 acc: 0.70345 | v_loss: 1.24832 v_acc: 0.70931 |  iteration: 18153 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 751 loss: 1.48164 acc: 0.69499 | v_loss: 1.50770 v_acc: 0.70247 |  iteration: 18154 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 752 loss: 1.47197 acc: 0.70410 | v_loss: 1.21241 v_acc: 0.70866 |  iteration: 18155 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 753 loss: 1.43556 acc: 0.70638 | v_loss: 1.33040 v_acc: 0.71159 |  iteration: 18156 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 754 loss: 1.48353 acc: 0.69792 | v_loss: 1.36387 v_acc: 0.69336 |  iteration: 18157 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 755 loss: 1.38469 acc: 0.70931 | v_loss: 1.29880 v_acc: 0.71191 |  iteration: 18158 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 756 loss: 1.53223 acc: 0.70703 | v_loss: 1.36204 v_acc: 0.69629 |  iteration: 18159 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 757 loss: 1.43773 acc: 0.70247 | v_loss: 1.45964 v_acc: 0.71517 |  iteration: 18160 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 758 loss: 1.34316 acc: 0.71745 | v_loss: 1.30995 v_acc: 0.72754 |  iteration: 18161 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 759 loss: 1.35331 acc: 0.70866 | v_loss: 1.44711 v_acc: 0.70508 |  iteration: 18162 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 760 loss: 1.43283 acc: 0.70508 | v_loss: 1.35627 v_acc: 0.69824 |  iteration: 18163 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 761 loss: 1.40205 acc: 0.70312 | v_loss: 1.32838 v_acc: 0.70801 |  iteration: 18164 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 762 loss: 1.40276 acc: 0.69889 | v_loss: 1.55971 v_acc: 0.68555 |  iteration: 18165 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 763 loss: 1.54150 acc: 0.69629 | v_loss: 1.29613 v_acc: 0.72135 |  iteration: 18166 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 764 loss: 1.44185 acc: 0.69857 | v_loss: 1.60357 v_acc: 0.67806 |  iteration: 18167 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 765 loss: 1.38443 acc: 0.70247 | v_loss: 1.45944 v_acc: 0.69759 |  iteration: 18168 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 766 loss: 1.42431 acc: 0.70117 | v_loss: 1.51897 v_acc: 0.69108 |  iteration: 18169 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 767 loss: 1.32529 acc: 0.71484 | v_loss: 1.38332 v_acc: 0.69954 |  iteration: 18170 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 768 loss: 1.42314 acc: 0.70117 | v_loss: 1.32065 v_acc: 0.70801 |  iteration: 18171 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 769 loss: 1.43010 acc: 0.70182 | v_loss: 1.33221 v_acc: 0.70605 |  iteration: 18172 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 770 loss: 1.44528 acc: 0.70410 | v_loss: 1.34211 v_acc: 0.71973 |  iteration: 18173 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 771 loss: 1.46162 acc: 0.70150 | v_loss: 1.55343 v_acc: 0.69076 |  iteration: 18174 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 772 loss: 1.40147 acc: 0.70475 | v_loss: 1.38350 v_acc: 0.71387 |  iteration: 18175 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 773 loss: 1.43123 acc: 0.70638 | v_loss: 1.33493 v_acc: 0.70866 |  iteration: 18176 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 774 loss: 1.46861 acc: 0.70052 | v_loss: 1.38764 v_acc: 0.71517 |  iteration: 18177 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 775 loss: 1.45440 acc: 0.69661 | v_loss: 1.27241 v_acc: 0.70475 |  iteration: 18178 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 776 loss: 1.43144 acc: 0.70703 | v_loss: 1.42082 v_acc: 0.69889 |  iteration: 18179 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 777 loss: 1.43473 acc: 0.70150 | v_loss: 1.42707 v_acc: 0.71615 |  iteration: 18180 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 778 loss: 1.48410 acc: 0.69857 | v_loss: 1.29293 v_acc: 0.71777 |  iteration: 18181 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 779 loss: 1.50010 acc: 0.69564 | v_loss: 1.25194 v_acc: 0.72884 |  iteration: 18182 teacher: 0 stage: sketch lr: 0.000328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 780 loss: 1.44287 acc: 0.70573 | v_loss: 1.36611 v_acc: 0.71615 |  iteration: 18183 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 781 loss: 1.35471 acc: 0.70475 | v_loss: 1.41567 v_acc: 0.70475 |  iteration: 18184 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 782 loss: 1.45528 acc: 0.69661 | v_loss: 1.41747 v_acc: 0.70540 |  iteration: 18185 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 783 loss: 1.45273 acc: 0.70508 | v_loss: 1.22701 v_acc: 0.71582 |  iteration: 18186 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 784 loss: 1.52521 acc: 0.69043 | v_loss: 1.38294 v_acc: 0.72754 |  iteration: 18187 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 785 loss: 1.44389 acc: 0.70247 | v_loss: 1.46472 v_acc: 0.69792 |  iteration: 18188 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 786 loss: 1.37340 acc: 0.71647 | v_loss: 1.40846 v_acc: 0.72070 |  iteration: 18189 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 787 loss: 1.54065 acc: 0.69629 | v_loss: 1.24510 v_acc: 0.72201 |  iteration: 18190 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 788 loss: 1.41974 acc: 0.70898 | v_loss: 1.19768 v_acc: 0.74023 |  iteration: 18191 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 789 loss: 1.46015 acc: 0.69466 | v_loss: 1.21012 v_acc: 0.72559 |  iteration: 18192 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 790 loss: 1.41371 acc: 0.70540 | v_loss: 1.28232 v_acc: 0.70736 |  iteration: 18193 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 791 loss: 1.44064 acc: 0.71191 | v_loss: 1.45759 v_acc: 0.69596 |  iteration: 18194 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 792 loss: 1.41755 acc: 0.71224 | v_loss: 1.27394 v_acc: 0.71257 |  iteration: 18195 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 793 loss: 1.39199 acc: 0.71061 | v_loss: 1.43770 v_acc: 0.71615 |  iteration: 18196 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 794 loss: 1.38185 acc: 0.70605 | v_loss: 1.66106 v_acc: 0.69401 |  iteration: 18197 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 795 loss: 1.52138 acc: 0.69694 | v_loss: 1.51917 v_acc: 0.69922 |  iteration: 18198 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 796 loss: 1.42914 acc: 0.70150 | v_loss: 1.28755 v_acc: 0.72103 |  iteration: 18199 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 797 loss: 1.38535 acc: 0.70736 | v_loss: 1.36788 v_acc: 0.70768 |  iteration: 18200 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 798 loss: 1.46185 acc: 0.70671 | v_loss: 1.21207 v_acc: 0.72363 |  iteration: 18201 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 799 loss: 1.36724 acc: 0.70898 | v_loss: 1.41223 v_acc: 0.70378 |  iteration: 18202 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 800 loss: 1.52975 acc: 0.69727 | v_loss: 1.34996 v_acc: 0.71810 |  iteration: 18203 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 801 loss: 1.37695 acc: 0.71094 | v_loss: 1.34876 v_acc: 0.73014 |  iteration: 18204 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 802 loss: 1.41584 acc: 0.70508 | v_loss: 1.36191 v_acc: 0.71973 |  iteration: 18205 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 803 loss: 1.35056 acc: 0.71387 | v_loss: 1.37359 v_acc: 0.70964 |  iteration: 18206 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 804 loss: 1.42793 acc: 0.70345 | v_loss: 1.27771 v_acc: 0.72493 |  iteration: 18207 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 805 loss: 1.48220 acc: 0.69499 | v_loss: 1.28971 v_acc: 0.72038 |  iteration: 18208 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 806 loss: 1.34819 acc: 0.70247 | v_loss: 1.46831 v_acc: 0.69368 |  iteration: 18209 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 807 loss: 1.43486 acc: 0.70833 | v_loss: 1.33615 v_acc: 0.71257 |  iteration: 18210 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 808 loss: 1.39637 acc: 0.70833 | v_loss: 1.28415 v_acc: 0.71615 |  iteration: 18211 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 809 loss: 1.48806 acc: 0.69759 | v_loss: 1.29392 v_acc: 0.71940 |  iteration: 18212 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 810 loss: 1.51370 acc: 0.69336 | v_loss: 1.42799 v_acc: 0.70475 |  iteration: 18213 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 811 loss: 1.44554 acc: 0.70540 | v_loss: 1.30114 v_acc: 0.73210 |  iteration: 18214 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 812 loss: 1.33055 acc: 0.71354 | v_loss: 1.53587 v_acc: 0.71615 |  iteration: 18215 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 813 loss: 1.39227 acc: 0.70996 | v_loss: 1.28601 v_acc: 0.69759 |  iteration: 18216 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 814 loss: 1.56625 acc: 0.69368 | v_loss: 1.27771 v_acc: 0.70703 |  iteration: 18217 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 815 loss: 1.40187 acc: 0.70312 | v_loss: 1.42478 v_acc: 0.70475 |  iteration: 18218 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 816 loss: 1.44587 acc: 0.70345 | v_loss: 1.46166 v_acc: 0.70378 |  iteration: 18219 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 817 loss: 1.43352 acc: 0.70638 | v_loss: 1.50784 v_acc: 0.68978 |  iteration: 18220 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 818 loss: 1.45562 acc: 0.70378 | v_loss: 1.46295 v_acc: 0.70638 |  iteration: 18221 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 819 loss: 1.50215 acc: 0.70182 | v_loss: 1.42176 v_acc: 0.70410 |  iteration: 18222 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 820 loss: 1.40091 acc: 0.70247 | v_loss: 1.40789 v_acc: 0.70768 |  iteration: 18223 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 821 loss: 1.45731 acc: 0.69857 | v_loss: 1.40713 v_acc: 0.70475 |  iteration: 18224 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 822 loss: 1.49350 acc: 0.69889 | v_loss: 1.27132 v_acc: 0.71354 |  iteration: 18225 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 823 loss: 1.38435 acc: 0.71224 | v_loss: 1.31917 v_acc: 0.72461 |  iteration: 18226 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 824 loss: 1.40829 acc: 0.70964 | v_loss: 1.18843 v_acc: 0.71517 |  iteration: 18227 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 825 loss: 1.43276 acc: 0.69954 | v_loss: 1.34693 v_acc: 0.70703 |  iteration: 18228 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 826 loss: 1.41433 acc: 0.69954 | v_loss: 1.49885 v_acc: 0.69987 |  iteration: 18229 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 827 loss: 1.38242 acc: 0.70443 | v_loss: 1.32542 v_acc: 0.71289 |  iteration: 18230 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 828 loss: 1.37424 acc: 0.71257 | v_loss: 1.36110 v_acc: 0.70280 |  iteration: 18231 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 829 loss: 1.37588 acc: 0.70833 | v_loss: 1.23372 v_acc: 0.71647 |  iteration: 18232 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 830 loss: 1.42690 acc: 0.70280 | v_loss: 1.23850 v_acc: 0.70605 |  iteration: 18233 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 831 loss: 1.37233 acc: 0.70964 | v_loss: 1.24767 v_acc: 0.73568 |  iteration: 18234 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 832 loss: 1.54462 acc: 0.69368 | v_loss: 1.25935 v_acc: 0.72201 |  iteration: 18235 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 833 loss: 1.38582 acc: 0.71354 | v_loss: 1.36797 v_acc: 0.72786 |  iteration: 18236 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 834 loss: 1.50653 acc: 0.69922 | v_loss: 1.26523 v_acc: 0.72233 |  iteration: 18237 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 835 loss: 1.37145 acc: 0.70671 | v_loss: 1.30615 v_acc: 0.72266 |  iteration: 18238 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 836 loss: 1.40007 acc: 0.70117 | v_loss: 1.42524 v_acc: 0.71289 |  iteration: 18239 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 837 loss: 1.33679 acc: 0.70736 | v_loss: 1.39225 v_acc: 0.72201 |  iteration: 18240 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 838 loss: 1.46945 acc: 0.70085 | v_loss: 1.48565 v_acc: 0.69824 |  iteration: 18241 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 839 loss: 1.39178 acc: 0.71777 | v_loss: 1.42718 v_acc: 0.71973 |  iteration: 18242 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 840 loss: 1.44600 acc: 0.70312 | v_loss: 1.17758 v_acc: 0.74544 |  iteration: 18243 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 841 loss: 1.50322 acc: 0.69303 | v_loss: 1.25716 v_acc: 0.70833 |  iteration: 18244 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 842 loss: 1.39834 acc: 0.70247 | v_loss: 1.52426 v_acc: 0.69987 |  iteration: 18245 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 843 loss: 1.37436 acc: 0.71224 | v_loss: 1.21659 v_acc: 0.70671 |  iteration: 18246 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 844 loss: 1.43671 acc: 0.70182 | v_loss: 1.33170 v_acc: 0.71257 |  iteration: 18247 teacher: 0 stage: sketch lr: 0.000327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 845 loss: 1.39698 acc: 0.70931 | v_loss: 1.37169 v_acc: 0.69368 |  iteration: 18248 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 846 loss: 1.45562 acc: 0.70215 | v_loss: 1.29399 v_acc: 0.71777 |  iteration: 18249 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 847 loss: 1.58284 acc: 0.69889 | v_loss: 1.35840 v_acc: 0.69629 |  iteration: 18250 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 848 loss: 1.40923 acc: 0.72103 | v_loss: 1.46487 v_acc: 0.71517 |  iteration: 18251 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 849 loss: 1.35584 acc: 0.71126 | v_loss: 1.31584 v_acc: 0.72689 |  iteration: 18252 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 850 loss: 1.34547 acc: 0.71582 | v_loss: 1.44444 v_acc: 0.70443 |  iteration: 18253 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 851 loss: 1.53504 acc: 0.68815 | v_loss: 1.36922 v_acc: 0.70150 |  iteration: 18254 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 852 loss: 1.43043 acc: 0.70736 | v_loss: 1.32779 v_acc: 0.70866 |  iteration: 18255 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 853 loss: 1.47161 acc: 0.69792 | v_loss: 1.54813 v_acc: 0.68815 |  iteration: 18256 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 854 loss: 1.47257 acc: 0.70247 | v_loss: 1.29422 v_acc: 0.72005 |  iteration: 18257 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 855 loss: 1.43052 acc: 0.70117 | v_loss: 1.58302 v_acc: 0.68424 |  iteration: 18258 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 856 loss: 1.42474 acc: 0.70443 | v_loss: 1.45613 v_acc: 0.69792 |  iteration: 18259 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 857 loss: 1.39878 acc: 0.70964 | v_loss: 1.51626 v_acc: 0.69173 |  iteration: 18260 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 858 loss: 1.46817 acc: 0.70052 | v_loss: 1.37613 v_acc: 0.70020 |  iteration: 18261 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 859 loss: 1.47098 acc: 0.71159 | v_loss: 1.32735 v_acc: 0.70475 |  iteration: 18262 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 860 loss: 1.45666 acc: 0.70052 | v_loss: 1.32514 v_acc: 0.70280 |  iteration: 18263 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 861 loss: 1.40864 acc: 0.70378 | v_loss: 1.33173 v_acc: 0.71842 |  iteration: 18264 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 862 loss: 1.43434 acc: 0.70573 | v_loss: 1.54106 v_acc: 0.69108 |  iteration: 18265 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 863 loss: 1.41336 acc: 0.70345 | v_loss: 1.37475 v_acc: 0.71126 |  iteration: 18266 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 864 loss: 1.37847 acc: 0.71257 | v_loss: 1.34572 v_acc: 0.71061 |  iteration: 18267 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 865 loss: 1.40924 acc: 0.70150 | v_loss: 1.38752 v_acc: 0.71484 |  iteration: 18268 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 866 loss: 1.39539 acc: 0.70964 | v_loss: 1.26367 v_acc: 0.70736 |  iteration: 18269 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 867 loss: 1.34549 acc: 0.71094 | v_loss: 1.43252 v_acc: 0.70052 |  iteration: 18270 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 868 loss: 1.52385 acc: 0.70052 | v_loss: 1.43769 v_acc: 0.71322 |  iteration: 18271 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 869 loss: 1.44930 acc: 0.70443 | v_loss: 1.28557 v_acc: 0.71875 |  iteration: 18272 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 870 loss: 1.45948 acc: 0.70736 | v_loss: 1.25678 v_acc: 0.72754 |  iteration: 18273 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 871 loss: 1.36090 acc: 0.71615 | v_loss: 1.36717 v_acc: 0.71940 |  iteration: 18274 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 872 loss: 1.48865 acc: 0.69596 | v_loss: 1.41920 v_acc: 0.70345 |  iteration: 18275 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 873 loss: 1.50839 acc: 0.69303 | v_loss: 1.42181 v_acc: 0.70475 |  iteration: 18276 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 874 loss: 1.41410 acc: 0.70182 | v_loss: 1.22980 v_acc: 0.71419 |  iteration: 18277 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 875 loss: 1.39639 acc: 0.70964 | v_loss: 1.38179 v_acc: 0.72754 |  iteration: 18278 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 876 loss: 1.34880 acc: 0.72070 | v_loss: 1.47716 v_acc: 0.69531 |  iteration: 18279 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 877 loss: 1.39170 acc: 0.70182 | v_loss: 1.42012 v_acc: 0.72266 |  iteration: 18280 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 878 loss: 1.40211 acc: 0.70605 | v_loss: 1.24820 v_acc: 0.71940 |  iteration: 18281 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 879 loss: 1.39251 acc: 0.70378 | v_loss: 1.18975 v_acc: 0.74284 |  iteration: 18282 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 880 loss: 1.50758 acc: 0.69336 | v_loss: 1.20892 v_acc: 0.72493 |  iteration: 18283 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 881 loss: 1.42052 acc: 0.69629 | v_loss: 1.27598 v_acc: 0.71126 |  iteration: 18284 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 882 loss: 1.41143 acc: 0.70020 | v_loss: 1.46735 v_acc: 0.70671 |  iteration: 18285 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 883 loss: 1.42961 acc: 0.70703 | v_loss: 1.27099 v_acc: 0.71582 |  iteration: 18286 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 884 loss: 1.46949 acc: 0.69792 | v_loss: 1.48939 v_acc: 0.69434 |  iteration: 18287 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 885 loss: 1.32616 acc: 0.71387 | v_loss: 1.71034 v_acc: 0.68978 |  iteration: 18288 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 886 loss: 1.49209 acc: 0.69336 | v_loss: 1.54682 v_acc: 0.69694 |  iteration: 18289 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 887 loss: 1.47770 acc: 0.69596 | v_loss: 1.29135 v_acc: 0.72135 |  iteration: 18290 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 888 loss: 1.34927 acc: 0.71126 | v_loss: 1.36403 v_acc: 0.70964 |  iteration: 18291 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 889 loss: 1.43423 acc: 0.70573 | v_loss: 1.21276 v_acc: 0.72266 |  iteration: 18292 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 890 loss: 1.44649 acc: 0.69727 | v_loss: 1.40716 v_acc: 0.70247 |  iteration: 18293 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 891 loss: 1.29724 acc: 0.71289 | v_loss: 1.35864 v_acc: 0.71484 |  iteration: 18294 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 892 loss: 1.37577 acc: 0.70736 | v_loss: 1.34443 v_acc: 0.72949 |  iteration: 18295 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 893 loss: 1.45295 acc: 0.70052 | v_loss: 1.35798 v_acc: 0.71810 |  iteration: 18296 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 894 loss: 1.52747 acc: 0.69303 | v_loss: 1.37346 v_acc: 0.70508 |  iteration: 18297 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 895 loss: 1.37446 acc: 0.70280 | v_loss: 1.27783 v_acc: 0.72201 |  iteration: 18298 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 896 loss: 1.42283 acc: 0.70280 | v_loss: 1.29333 v_acc: 0.72005 |  iteration: 18299 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 897 loss: 1.40032 acc: 0.69759 | v_loss: 1.47786 v_acc: 0.69206 |  iteration: 18300 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 898 loss: 1.39256 acc: 0.71224 | v_loss: 1.33846 v_acc: 0.71159 |  iteration: 18301 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 899 loss: 1.35895 acc: 0.71973 | v_loss: 1.28545 v_acc: 0.71549 |  iteration: 18302 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 900 loss: 1.46130 acc: 0.70410 | v_loss: 1.27204 v_acc: 0.71973 |  iteration: 18303 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 901 loss: 1.50149 acc: 0.69661 | v_loss: 1.41608 v_acc: 0.70573 |  iteration: 18304 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 902 loss: 1.31229 acc: 0.70931 | v_loss: 1.31965 v_acc: 0.73014 |  iteration: 18305 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 903 loss: 1.41874 acc: 0.70801 | v_loss: 1.56894 v_acc: 0.71582 |  iteration: 18306 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 904 loss: 1.48845 acc: 0.69466 | v_loss: 1.27656 v_acc: 0.70150 |  iteration: 18307 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 905 loss: 1.44080 acc: 0.70768 | v_loss: 1.27486 v_acc: 0.70573 |  iteration: 18308 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 906 loss: 1.54654 acc: 0.68913 | v_loss: 1.44105 v_acc: 0.70378 |  iteration: 18309 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 907 loss: 1.47678 acc: 0.68750 | v_loss: 1.47610 v_acc: 0.70150 |  iteration: 18310 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 908 loss: 1.45226 acc: 0.70182 | v_loss: 1.52362 v_acc: 0.69401 |  iteration: 18311 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 909 loss: 1.47719 acc: 0.69987 | v_loss: 1.46642 v_acc: 0.70605 |  iteration: 18312 teacher: 1 stage: sketch lr: 0.000327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 910 loss: 1.41786 acc: 0.70671 | v_loss: 1.42235 v_acc: 0.70410 |  iteration: 18313 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 911 loss: 1.47770 acc: 0.70020 | v_loss: 1.41302 v_acc: 0.70768 |  iteration: 18314 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 912 loss: 1.40593 acc: 0.70866 | v_loss: 1.39051 v_acc: 0.70475 |  iteration: 18315 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 913 loss: 1.45690 acc: 0.69499 | v_loss: 1.25681 v_acc: 0.71354 |  iteration: 18316 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 914 loss: 1.41853 acc: 0.70280 | v_loss: 1.32677 v_acc: 0.72461 |  iteration: 18317 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 915 loss: 1.44460 acc: 0.70768 | v_loss: 1.18536 v_acc: 0.71517 |  iteration: 18318 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 916 loss: 1.44863 acc: 0.70182 | v_loss: 1.34057 v_acc: 0.70703 |  iteration: 18319 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 917 loss: 1.58992 acc: 0.69271 | v_loss: 1.50344 v_acc: 0.69987 |  iteration: 18320 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 918 loss: 1.36604 acc: 0.70703 | v_loss: 1.34099 v_acc: 0.70833 |  iteration: 18321 teacher: 0 stage: sketch lr: 0.000327\n",
      "batch 919 loss: 1.40133 acc: 0.70540 | v_loss: 1.36073 v_acc: 0.69727 |  iteration: 18322 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 920 loss: 1.35694 acc: 0.71289 | v_loss: 1.25081 v_acc: 0.71126 |  iteration: 18323 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 921 loss: 1.46399 acc: 0.69694 | v_loss: 1.25063 v_acc: 0.70345 |  iteration: 18324 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 922 loss: 1.35773 acc: 0.71517 | v_loss: 1.24527 v_acc: 0.73503 |  iteration: 18325 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 923 loss: 1.41894 acc: 0.70280 | v_loss: 1.26970 v_acc: 0.72168 |  iteration: 18326 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 924 loss: 1.48985 acc: 0.70475 | v_loss: 1.35068 v_acc: 0.73145 |  iteration: 18327 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 925 loss: 1.35402 acc: 0.70573 | v_loss: 1.25885 v_acc: 0.72461 |  iteration: 18328 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 926 loss: 1.44010 acc: 0.70150 | v_loss: 1.30694 v_acc: 0.72233 |  iteration: 18329 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 927 loss: 1.43350 acc: 0.70410 | v_loss: 1.41730 v_acc: 0.71452 |  iteration: 18330 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 928 loss: 1.43117 acc: 0.70964 | v_loss: 1.39370 v_acc: 0.72624 |  iteration: 18331 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 929 loss: 1.43998 acc: 0.70736 | v_loss: 1.48641 v_acc: 0.70182 |  iteration: 18332 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 930 loss: 1.32614 acc: 0.71387 | v_loss: 1.41894 v_acc: 0.72135 |  iteration: 18333 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 931 loss: 1.55786 acc: 0.69401 | v_loss: 1.17274 v_acc: 0.74447 |  iteration: 18334 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 932 loss: 1.44485 acc: 0.69596 | v_loss: 1.25429 v_acc: 0.70964 |  iteration: 18335 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 933 loss: 1.45576 acc: 0.70443 | v_loss: 1.51310 v_acc: 0.69987 |  iteration: 18336 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 934 loss: 1.37605 acc: 0.70280 | v_loss: 1.22374 v_acc: 0.70638 |  iteration: 18337 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 935 loss: 1.41464 acc: 0.69889 | v_loss: 1.33037 v_acc: 0.71354 |  iteration: 18338 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 936 loss: 1.48282 acc: 0.69010 | v_loss: 1.36010 v_acc: 0.69499 |  iteration: 18339 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 937 loss: 1.48282 acc: 0.69857 | v_loss: 1.29726 v_acc: 0.70996 |  iteration: 18340 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 938 loss: 1.51588 acc: 0.69401 | v_loss: 1.36064 v_acc: 0.69434 |  iteration: 18341 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 939 loss: 1.36583 acc: 0.71159 | v_loss: 1.47098 v_acc: 0.71224 |  iteration: 18342 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 940 loss: 1.32105 acc: 0.70866 | v_loss: 1.31862 v_acc: 0.72656 |  iteration: 18343 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 941 loss: 1.46774 acc: 0.70345 | v_loss: 1.45544 v_acc: 0.70378 |  iteration: 18344 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 942 loss: 1.42444 acc: 0.70020 | v_loss: 1.35974 v_acc: 0.69922 |  iteration: 18345 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 943 loss: 1.34538 acc: 0.70345 | v_loss: 1.33363 v_acc: 0.70898 |  iteration: 18346 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 944 loss: 1.45956 acc: 0.69759 | v_loss: 1.54928 v_acc: 0.68815 |  iteration: 18347 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 945 loss: 1.36769 acc: 0.70768 | v_loss: 1.30885 v_acc: 0.72005 |  iteration: 18348 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 946 loss: 1.49198 acc: 0.71419 | v_loss: 1.59313 v_acc: 0.68424 |  iteration: 18349 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 947 loss: 1.48176 acc: 0.70280 | v_loss: 1.44526 v_acc: 0.69857 |  iteration: 18350 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 948 loss: 1.54287 acc: 0.69857 | v_loss: 1.53381 v_acc: 0.69238 |  iteration: 18351 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 949 loss: 1.50768 acc: 0.69434 | v_loss: 1.37010 v_acc: 0.70215 |  iteration: 18352 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 950 loss: 1.42532 acc: 0.70801 | v_loss: 1.32206 v_acc: 0.70540 |  iteration: 18353 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 951 loss: 1.55541 acc: 0.70312 | v_loss: 1.32559 v_acc: 0.70020 |  iteration: 18354 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 952 loss: 1.46147 acc: 0.69694 | v_loss: 1.32536 v_acc: 0.71484 |  iteration: 18355 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 953 loss: 1.45662 acc: 0.70150 | v_loss: 1.53774 v_acc: 0.68913 |  iteration: 18356 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 954 loss: 1.43572 acc: 0.70150 | v_loss: 1.38577 v_acc: 0.70736 |  iteration: 18357 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 955 loss: 1.43278 acc: 0.70410 | v_loss: 1.34367 v_acc: 0.70801 |  iteration: 18358 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 956 loss: 1.42490 acc: 0.70475 | v_loss: 1.38265 v_acc: 0.71582 |  iteration: 18359 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 957 loss: 1.40823 acc: 0.71289 | v_loss: 1.27854 v_acc: 0.70508 |  iteration: 18360 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 958 loss: 1.39288 acc: 0.70833 | v_loss: 1.43142 v_acc: 0.69889 |  iteration: 18361 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 959 loss: 1.50575 acc: 0.69401 | v_loss: 1.42667 v_acc: 0.71549 |  iteration: 18362 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 960 loss: 1.42616 acc: 0.70052 | v_loss: 1.28309 v_acc: 0.71680 |  iteration: 18363 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 961 loss: 1.32269 acc: 0.71712 | v_loss: 1.25856 v_acc: 0.72624 |  iteration: 18364 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 962 loss: 1.41725 acc: 0.70573 | v_loss: 1.38188 v_acc: 0.71484 |  iteration: 18365 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 963 loss: 1.43841 acc: 0.70931 | v_loss: 1.43516 v_acc: 0.70280 |  iteration: 18366 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 964 loss: 1.49802 acc: 0.69206 | v_loss: 1.43357 v_acc: 0.70410 |  iteration: 18367 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 965 loss: 1.38823 acc: 0.70703 | v_loss: 1.22200 v_acc: 0.71712 |  iteration: 18368 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 966 loss: 1.35826 acc: 0.70768 | v_loss: 1.39195 v_acc: 0.72786 |  iteration: 18369 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 967 loss: 1.42074 acc: 0.69629 | v_loss: 1.48579 v_acc: 0.69792 |  iteration: 18370 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 968 loss: 1.48255 acc: 0.69727 | v_loss: 1.44706 v_acc: 0.72201 |  iteration: 18371 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 969 loss: 1.46522 acc: 0.69922 | v_loss: 1.24315 v_acc: 0.72233 |  iteration: 18372 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 970 loss: 1.39891 acc: 0.70931 | v_loss: 1.18386 v_acc: 0.74447 |  iteration: 18373 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 971 loss: 1.39846 acc: 0.70475 | v_loss: 1.20915 v_acc: 0.72493 |  iteration: 18374 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 972 loss: 1.47227 acc: 0.70150 | v_loss: 1.27376 v_acc: 0.71126 |  iteration: 18375 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 973 loss: 1.34595 acc: 0.71452 | v_loss: 1.44887 v_acc: 0.70182 |  iteration: 18376 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 974 loss: 1.40071 acc: 0.70443 | v_loss: 1.27413 v_acc: 0.71452 |  iteration: 18377 teacher: 1 stage: sketch lr: 0.000326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 975 loss: 1.45940 acc: 0.70247 | v_loss: 1.43634 v_acc: 0.71647 |  iteration: 18378 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 976 loss: 1.50544 acc: 0.69434 | v_loss: 1.67467 v_acc: 0.69303 |  iteration: 18379 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 977 loss: 1.44399 acc: 0.69401 | v_loss: 1.52391 v_acc: 0.70117 |  iteration: 18380 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 978 loss: 1.45621 acc: 0.70378 | v_loss: 1.28938 v_acc: 0.72363 |  iteration: 18381 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 979 loss: 1.45092 acc: 0.69954 | v_loss: 1.37186 v_acc: 0.70410 |  iteration: 18382 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 980 loss: 1.41453 acc: 0.70052 | v_loss: 1.22542 v_acc: 0.71973 |  iteration: 18383 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 981 loss: 1.37454 acc: 0.71224 | v_loss: 1.41471 v_acc: 0.70150 |  iteration: 18384 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 982 loss: 1.45962 acc: 0.69238 | v_loss: 1.35523 v_acc: 0.71029 |  iteration: 18385 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 983 loss: 1.41866 acc: 0.70573 | v_loss: 1.34922 v_acc: 0.73079 |  iteration: 18386 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 984 loss: 1.59465 acc: 0.68978 | v_loss: 1.36438 v_acc: 0.71777 |  iteration: 18387 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 985 loss: 1.43258 acc: 0.70378 | v_loss: 1.37615 v_acc: 0.70410 |  iteration: 18388 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 986 loss: 1.50261 acc: 0.70052 | v_loss: 1.27571 v_acc: 0.72233 |  iteration: 18389 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 987 loss: 1.59154 acc: 0.68880 | v_loss: 1.29112 v_acc: 0.72135 |  iteration: 18390 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 988 loss: 1.49443 acc: 0.68978 | v_loss: 1.47299 v_acc: 0.69303 |  iteration: 18391 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 989 loss: 1.32340 acc: 0.71354 | v_loss: 1.33026 v_acc: 0.70931 |  iteration: 18392 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 990 loss: 1.39825 acc: 0.69336 | v_loss: 1.30227 v_acc: 0.71452 |  iteration: 18393 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 991 loss: 1.45266 acc: 0.69368 | v_loss: 1.30842 v_acc: 0.71940 |  iteration: 18394 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 992 loss: 1.33966 acc: 0.70573 | v_loss: 1.43713 v_acc: 0.70475 |  iteration: 18395 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 993 loss: 1.44267 acc: 0.70117 | v_loss: 1.30843 v_acc: 0.73210 |  iteration: 18396 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 994 loss: 1.40488 acc: 0.70736 | v_loss: 1.54594 v_acc: 0.71615 |  iteration: 18397 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 995 loss: 1.35800 acc: 0.71126 | v_loss: 1.27665 v_acc: 0.69759 |  iteration: 18398 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 996 loss: 1.38231 acc: 0.70898 | v_loss: 1.27867 v_acc: 0.70540 |  iteration: 18399 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 997 loss: 1.45657 acc: 0.70280 | v_loss: 1.44285 v_acc: 0.70312 |  iteration: 18400 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 998 loss: 1.55994 acc: 0.69401 | v_loss: 1.47772 v_acc: 0.70378 |  iteration: 18401 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 999 loss: 1.58861 acc: 0.69401 | v_loss: 1.52478 v_acc: 0.68815 |  iteration: 18402 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 1000 loss: 1.49270 acc: 0.69661 | v_loss: 1.47053 v_acc: 0.70638 |  iteration: 18403 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 1001 loss: 1.43463 acc: 0.70345 | v_loss: 1.42477 v_acc: 0.70410 |  iteration: 18404 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 1002 loss: 1.44082 acc: 0.69141 | v_loss: 1.40873 v_acc: 0.70768 |  iteration: 18405 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 1003 loss: 1.42724 acc: 0.71224 | v_loss: 1.39547 v_acc: 0.70475 |  iteration: 18406 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 1004 loss: 1.42412 acc: 0.70898 | v_loss: 1.26280 v_acc: 0.71354 |  iteration: 18407 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 1005 loss: 1.41054 acc: 0.69922 | v_loss: 1.32133 v_acc: 0.72461 |  iteration: 18408 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 1006 loss: 1.43841 acc: 0.69792 | v_loss: 1.17863 v_acc: 0.71582 |  iteration: 18409 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 1007 loss: 1.40075 acc: 0.71094 | v_loss: 1.33743 v_acc: 0.71094 |  iteration: 18410 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 1008 loss: 1.47357 acc: 0.69922 | v_loss: 1.50488 v_acc: 0.70182 |  iteration: 18411 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 1009 loss: 1.42673 acc: 0.69987 | v_loss: 1.33847 v_acc: 0.70833 |  iteration: 18412 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 1010 loss: 1.46792 acc: 0.70736 | v_loss: 1.34278 v_acc: 0.69629 |  iteration: 18413 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 1011 loss: 1.44824 acc: 0.69889 | v_loss: 1.25139 v_acc: 0.70638 |  iteration: 18414 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 1012 loss: 1.40812 acc: 0.70573 | v_loss: 1.24631 v_acc: 0.70410 |  iteration: 18415 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 1013 loss: 1.46325 acc: 0.70573 | v_loss: 1.22900 v_acc: 0.73926 |  iteration: 18416 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 1014 loss: 1.38327 acc: 0.70736 | v_loss: 1.26479 v_acc: 0.71875 |  iteration: 18417 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 1015 loss: 1.42401 acc: 0.71029 | v_loss: 1.32893 v_acc: 0.73112 |  iteration: 18418 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 1016 loss: 1.34905 acc: 0.70964 | v_loss: 1.25369 v_acc: 0.72461 |  iteration: 18419 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 1017 loss: 1.44387 acc: 0.69661 | v_loss: 1.29676 v_acc: 0.72005 |  iteration: 18420 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 1018 loss: 1.37022 acc: 0.70540 | v_loss: 1.40245 v_acc: 0.71191 |  iteration: 18421 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 1019 loss: 1.46362 acc: 0.69954 | v_loss: 1.39708 v_acc: 0.72396 |  iteration: 18422 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 1020 loss: 1.46236 acc: 0.70638 | v_loss: 1.49477 v_acc: 0.70182 |  iteration: 18423 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 1021 loss: 1.44589 acc: 0.69922 | v_loss: 1.41860 v_acc: 0.71777 |  iteration: 18424 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 1022 loss: 1.44593 acc: 0.70150 | v_loss: 1.17313 v_acc: 0.74382 |  iteration: 18425 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 1023 loss: 1.33109 acc: 0.70703 | v_loss: 1.26829 v_acc: 0.70996 |  iteration: 18426 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 1024 loss: 1.40781 acc: 0.70247 | v_loss: 1.53332 v_acc: 0.69987 |  iteration: 18427 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 1025 loss: 1.38057 acc: 0.69661 | v_loss: 1.21709 v_acc: 0.70671 |  iteration: 18428 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 1026 loss: 1.35607 acc: 0.71159 | v_loss: 1.33621 v_acc: 0.71257 |  iteration: 18429 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 1027 loss: 1.32858 acc: 0.70671 | v_loss: 1.37326 v_acc: 0.69368 |  iteration: 18430 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 1028 loss: 1.32312 acc: 0.71224 | v_loss: 1.28370 v_acc: 0.71842 |  iteration: 18431 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 1029 loss: 1.42986 acc: 0.70605 | v_loss: 1.36245 v_acc: 0.70215 |  iteration: 18432 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 1030 loss: 1.43886 acc: 0.70215 | v_loss: 1.49353 v_acc: 0.72005 |  iteration: 18433 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 1031 loss: 1.36739 acc: 0.70605 | v_loss: 1.32922 v_acc: 0.72786 |  iteration: 18434 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 1032 loss: 1.31944 acc: 0.72005 | v_loss: 1.45261 v_acc: 0.70540 |  iteration: 18435 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1033 loss: 1.56809 acc: 0.70020 | v_loss: 1.37039 v_acc: 0.69857 |  iteration: 18436 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1034 loss: 1.42001 acc: 0.70085 | v_loss: 1.30880 v_acc: 0.70833 |  iteration: 18437 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1035 loss: 1.48990 acc: 0.69466 | v_loss: 1.56054 v_acc: 0.68652 |  iteration: 18438 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1036 loss: 1.43374 acc: 0.69889 | v_loss: 1.30134 v_acc: 0.71973 |  iteration: 18439 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1037 loss: 1.51793 acc: 0.70020 | v_loss: 1.58460 v_acc: 0.68424 |  iteration: 18440 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1038 loss: 1.44919 acc: 0.70443 | v_loss: 1.45273 v_acc: 0.69792 |  iteration: 18441 teacher: 1 stage: sketch lr: 0.000325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1039 loss: 1.52128 acc: 0.69954 | v_loss: 1.51986 v_acc: 0.69173 |  iteration: 18442 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1040 loss: 1.43314 acc: 0.70801 | v_loss: 1.37817 v_acc: 0.70020 |  iteration: 18443 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1041 loss: 1.43771 acc: 0.70182 | v_loss: 1.31820 v_acc: 0.70345 |  iteration: 18444 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1042 loss: 1.42746 acc: 0.70475 | v_loss: 1.33998 v_acc: 0.69824 |  iteration: 18445 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1043 loss: 1.34464 acc: 0.70085 | v_loss: 1.33092 v_acc: 0.71549 |  iteration: 18446 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1044 loss: 1.41163 acc: 0.70117 | v_loss: 1.51485 v_acc: 0.69401 |  iteration: 18447 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1045 loss: 1.54400 acc: 0.69694 | v_loss: 1.37520 v_acc: 0.69922 |  iteration: 18448 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1046 loss: 1.42580 acc: 0.71387 | v_loss: 1.35206 v_acc: 0.71322 |  iteration: 18449 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1047 loss: 1.39233 acc: 0.70833 | v_loss: 1.38531 v_acc: 0.71777 |  iteration: 18450 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1048 loss: 1.44021 acc: 0.69368 | v_loss: 1.27077 v_acc: 0.70573 |  iteration: 18451 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1049 loss: 1.48848 acc: 0.69987 | v_loss: 1.42527 v_acc: 0.69792 |  iteration: 18452 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1050 loss: 1.47054 acc: 0.69564 | v_loss: 1.42019 v_acc: 0.71289 |  iteration: 18453 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1051 loss: 1.45208 acc: 0.69271 | v_loss: 1.28302 v_acc: 0.71875 |  iteration: 18454 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1052 loss: 1.38763 acc: 0.70964 | v_loss: 1.24927 v_acc: 0.72591 |  iteration: 18455 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1053 loss: 1.41797 acc: 0.70475 | v_loss: 1.37856 v_acc: 0.72266 |  iteration: 18456 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1054 loss: 1.34289 acc: 0.70768 | v_loss: 1.41238 v_acc: 0.70410 |  iteration: 18457 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1055 loss: 1.35332 acc: 0.70768 | v_loss: 1.42821 v_acc: 0.70833 |  iteration: 18458 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1056 loss: 1.49076 acc: 0.70312 | v_loss: 1.21760 v_acc: 0.72591 |  iteration: 18459 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1057 loss: 1.43444 acc: 0.69206 | v_loss: 1.39530 v_acc: 0.73177 |  iteration: 18460 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1058 loss: 1.37398 acc: 0.71387 | v_loss: 1.47555 v_acc: 0.69792 |  iteration: 18461 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1059 loss: 1.35161 acc: 0.71094 | v_loss: 1.42530 v_acc: 0.72070 |  iteration: 18462 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1060 loss: 1.41953 acc: 0.70052 | v_loss: 1.24265 v_acc: 0.72201 |  iteration: 18463 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1061 loss: 1.45534 acc: 0.69694 | v_loss: 1.19042 v_acc: 0.74023 |  iteration: 18464 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1062 loss: 1.50445 acc: 0.70247 | v_loss: 1.20819 v_acc: 0.72559 |  iteration: 18465 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1063 loss: 1.42707 acc: 0.71126 | v_loss: 1.26770 v_acc: 0.70638 |  iteration: 18466 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1064 loss: 1.32614 acc: 0.70117 | v_loss: 1.44742 v_acc: 0.70052 |  iteration: 18467 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1065 loss: 1.42966 acc: 0.71354 | v_loss: 1.27812 v_acc: 0.71419 |  iteration: 18468 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1066 loss: 1.38963 acc: 0.71354 | v_loss: 1.42910 v_acc: 0.71647 |  iteration: 18469 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1067 loss: 1.43945 acc: 0.69434 | v_loss: 1.68590 v_acc: 0.69303 |  iteration: 18470 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1068 loss: 1.35736 acc: 0.70182 | v_loss: 1.53672 v_acc: 0.70117 |  iteration: 18471 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1069 loss: 1.39712 acc: 0.70378 | v_loss: 1.29489 v_acc: 0.72363 |  iteration: 18472 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1070 loss: 1.45321 acc: 0.70247 | v_loss: 1.39060 v_acc: 0.70410 |  iteration: 18473 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1071 loss: 1.37029 acc: 0.70085 | v_loss: 1.22484 v_acc: 0.72201 |  iteration: 18474 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1072 loss: 1.57938 acc: 0.69336 | v_loss: 1.43889 v_acc: 0.70378 |  iteration: 18475 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1073 loss: 1.51458 acc: 0.69824 | v_loss: 1.35694 v_acc: 0.71810 |  iteration: 18476 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1074 loss: 1.40333 acc: 0.69661 | v_loss: 1.36196 v_acc: 0.73014 |  iteration: 18477 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1075 loss: 1.45130 acc: 0.69759 | v_loss: 1.36849 v_acc: 0.71973 |  iteration: 18478 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1076 loss: 1.46784 acc: 0.69792 | v_loss: 1.36969 v_acc: 0.70964 |  iteration: 18479 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1077 loss: 1.53703 acc: 0.69792 | v_loss: 1.28385 v_acc: 0.72493 |  iteration: 18480 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1078 loss: 1.55502 acc: 0.68978 | v_loss: 1.29034 v_acc: 0.72038 |  iteration: 18481 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1079 loss: 1.39357 acc: 0.70736 | v_loss: 1.50442 v_acc: 0.69303 |  iteration: 18482 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1080 loss: 1.41820 acc: 0.70866 | v_loss: 1.33160 v_acc: 0.70866 |  iteration: 18483 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1081 loss: 1.43967 acc: 0.70247 | v_loss: 1.31681 v_acc: 0.71354 |  iteration: 18484 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1082 loss: 1.35799 acc: 0.71126 | v_loss: 1.30540 v_acc: 0.71875 |  iteration: 18485 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1083 loss: 1.37089 acc: 0.70964 | v_loss: 1.43921 v_acc: 0.70475 |  iteration: 18486 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1084 loss: 1.41072 acc: 0.70085 | v_loss: 1.30660 v_acc: 0.73047 |  iteration: 18487 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1085 loss: 1.36198 acc: 0.70443 | v_loss: 1.52986 v_acc: 0.71452 |  iteration: 18488 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1086 loss: 1.48070 acc: 0.69954 | v_loss: 1.28638 v_acc: 0.69857 |  iteration: 18489 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1087 loss: 1.44545 acc: 0.70182 | v_loss: 1.27587 v_acc: 0.70280 |  iteration: 18490 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1088 loss: 1.48372 acc: 0.69987 | v_loss: 1.43266 v_acc: 0.70312 |  iteration: 18491 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1089 loss: 1.38333 acc: 0.71126 | v_loss: 1.47411 v_acc: 0.70378 |  iteration: 18492 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1090 loss: 1.47050 acc: 0.69661 | v_loss: 1.51914 v_acc: 0.68978 |  iteration: 18493 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1091 loss: 1.41328 acc: 0.70247 | v_loss: 1.47300 v_acc: 0.70768 |  iteration: 18494 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1092 loss: 1.44537 acc: 0.70801 | v_loss: 1.43056 v_acc: 0.70085 |  iteration: 18495 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1093 loss: 1.35466 acc: 0.71517 | v_loss: 1.42084 v_acc: 0.70931 |  iteration: 18496 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1094 loss: 1.42426 acc: 0.70410 | v_loss: 1.39059 v_acc: 0.70703 |  iteration: 18497 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1095 loss: 1.45215 acc: 0.69466 | v_loss: 1.25226 v_acc: 0.71875 |  iteration: 18498 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1096 loss: 1.42184 acc: 0.69987 | v_loss: 1.33220 v_acc: 0.72331 |  iteration: 18499 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1097 loss: 1.48784 acc: 0.69336 | v_loss: 1.15878 v_acc: 0.71615 |  iteration: 18500 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1098 loss: 1.53026 acc: 0.69271 | v_loss: 1.34464 v_acc: 0.71126 |  iteration: 18501 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1099 loss: 1.43614 acc: 0.70475 | v_loss: 1.51312 v_acc: 0.69954 |  iteration: 18502 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1100 loss: 1.46017 acc: 0.70410 | v_loss: 1.32487 v_acc: 0.70768 |  iteration: 18503 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1101 loss: 1.45362 acc: 0.70052 | v_loss: 1.36728 v_acc: 0.69661 |  iteration: 18504 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1102 loss: 1.46968 acc: 0.70540 | v_loss: 1.24134 v_acc: 0.70638 |  iteration: 18505 teacher: 0 stage: sketch lr: 0.000325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1103 loss: 1.33506 acc: 0.70833 | v_loss: 1.25740 v_acc: 0.70410 |  iteration: 18506 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1104 loss: 1.41249 acc: 0.70410 | v_loss: 1.23892 v_acc: 0.73958 |  iteration: 18507 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1105 loss: 1.43363 acc: 0.70638 | v_loss: 1.27244 v_acc: 0.71875 |  iteration: 18508 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1106 loss: 1.42641 acc: 0.70605 | v_loss: 1.34399 v_acc: 0.73242 |  iteration: 18509 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1107 loss: 1.41310 acc: 0.70247 | v_loss: 1.26358 v_acc: 0.71940 |  iteration: 18510 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1108 loss: 1.48960 acc: 0.70182 | v_loss: 1.30722 v_acc: 0.72168 |  iteration: 18511 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1109 loss: 1.43868 acc: 0.69857 | v_loss: 1.42153 v_acc: 0.71289 |  iteration: 18512 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1110 loss: 1.42967 acc: 0.70964 | v_loss: 1.39597 v_acc: 0.72070 |  iteration: 18513 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1111 loss: 1.41442 acc: 0.71224 | v_loss: 1.49011 v_acc: 0.69954 |  iteration: 18514 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1112 loss: 1.33268 acc: 0.71289 | v_loss: 1.43973 v_acc: 0.71615 |  iteration: 18515 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1113 loss: 1.46479 acc: 0.69401 | v_loss: 1.18182 v_acc: 0.74316 |  iteration: 18516 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1114 loss: 1.43236 acc: 0.70052 | v_loss: 1.26493 v_acc: 0.70931 |  iteration: 18517 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1115 loss: 1.46093 acc: 0.69922 | v_loss: 1.53715 v_acc: 0.70247 |  iteration: 18518 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1116 loss: 1.41318 acc: 0.71029 | v_loss: 1.21498 v_acc: 0.70671 |  iteration: 18519 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1117 loss: 1.44179 acc: 0.70410 | v_loss: 1.32768 v_acc: 0.71257 |  iteration: 18520 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1118 loss: 1.44191 acc: 0.70052 | v_loss: 1.36883 v_acc: 0.69368 |  iteration: 18521 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1119 loss: 1.40835 acc: 0.70996 | v_loss: 1.28869 v_acc: 0.71842 |  iteration: 18522 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1120 loss: 1.49024 acc: 0.69303 | v_loss: 1.35510 v_acc: 0.70215 |  iteration: 18523 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1121 loss: 1.37194 acc: 0.71029 | v_loss: 1.46190 v_acc: 0.72005 |  iteration: 18524 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1122 loss: 1.38085 acc: 0.71484 | v_loss: 1.31972 v_acc: 0.72786 |  iteration: 18525 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1123 loss: 1.46346 acc: 0.69954 | v_loss: 1.43610 v_acc: 0.70540 |  iteration: 18526 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1124 loss: 1.34177 acc: 0.70182 | v_loss: 1.36733 v_acc: 0.69857 |  iteration: 18527 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1125 loss: 1.45289 acc: 0.70085 | v_loss: 1.31492 v_acc: 0.70833 |  iteration: 18528 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1126 loss: 1.45598 acc: 0.69206 | v_loss: 1.55988 v_acc: 0.68490 |  iteration: 18529 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1127 loss: 1.48802 acc: 0.70605 | v_loss: 1.29374 v_acc: 0.72201 |  iteration: 18530 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1128 loss: 1.46709 acc: 0.69434 | v_loss: 1.58146 v_acc: 0.68327 |  iteration: 18531 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1129 loss: 1.41357 acc: 0.69922 | v_loss: 1.44736 v_acc: 0.69922 |  iteration: 18532 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1130 loss: 1.39864 acc: 0.71387 | v_loss: 1.50875 v_acc: 0.68978 |  iteration: 18533 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1131 loss: 1.47042 acc: 0.69596 | v_loss: 1.37475 v_acc: 0.69792 |  iteration: 18534 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1132 loss: 1.56398 acc: 0.69466 | v_loss: 1.31776 v_acc: 0.70378 |  iteration: 18535 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1133 loss: 1.52485 acc: 0.69499 | v_loss: 1.33145 v_acc: 0.70215 |  iteration: 18536 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1134 loss: 1.42015 acc: 0.70638 | v_loss: 1.32386 v_acc: 0.71615 |  iteration: 18537 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1135 loss: 1.49555 acc: 0.69564 | v_loss: 1.54543 v_acc: 0.68945 |  iteration: 18538 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1136 loss: 1.35505 acc: 0.70866 | v_loss: 1.38679 v_acc: 0.70703 |  iteration: 18539 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1137 loss: 1.38894 acc: 0.70801 | v_loss: 1.36061 v_acc: 0.70833 |  iteration: 18540 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1138 loss: 1.47157 acc: 0.69792 | v_loss: 1.38826 v_acc: 0.71647 |  iteration: 18541 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 1139 loss: 1.45881 acc: 0.70801 | v_loss: 1.27813 v_acc: 0.70475 |  iteration: 18542 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1140 loss: 1.46955 acc: 0.70736 | v_loss: 1.42523 v_acc: 0.69792 |  iteration: 18543 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1141 loss: 1.35095 acc: 0.71419 | v_loss: 1.42680 v_acc: 0.71289 |  iteration: 18544 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1142 loss: 1.48962 acc: 0.70020 | v_loss: 1.28422 v_acc: 0.71875 |  iteration: 18545 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1143 loss: 1.50740 acc: 0.69141 | v_loss: 1.25733 v_acc: 0.72754 |  iteration: 18546 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1144 loss: 1.37425 acc: 0.70182 | v_loss: 1.37099 v_acc: 0.71940 |  iteration: 18547 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1145 loss: 1.44388 acc: 0.70280 | v_loss: 1.42292 v_acc: 0.70345 |  iteration: 18548 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 1146 loss: 1.31250 acc: 0.70312 | v_loss: 1.42875 v_acc: 0.70410 |  iteration: 18549 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1147 loss: 1.48750 acc: 0.69857 | v_loss: 1.21601 v_acc: 0.72493 |  iteration: 18550 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1148 loss: 1.36336 acc: 0.70801 | v_loss: 1.39986 v_acc: 0.73112 |  iteration: 18551 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1149 loss: 1.60478 acc: 0.68620 | v_loss: 1.48282 v_acc: 0.69727 |  iteration: 18552 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1150 loss: 1.45609 acc: 0.69727 | v_loss: 1.42748 v_acc: 0.72201 |  iteration: 18553 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1151 loss: 1.46288 acc: 0.69661 | v_loss: 1.23851 v_acc: 0.72233 |  iteration: 18554 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1152 loss: 1.34211 acc: 0.71419 | v_loss: 1.19452 v_acc: 0.74349 |  iteration: 18555 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1153 loss: 1.40507 acc: 0.70605 | v_loss: 1.21073 v_acc: 0.72786 |  iteration: 18556 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1154 loss: 1.55382 acc: 0.69368 | v_loss: 1.27963 v_acc: 0.70768 |  iteration: 18557 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1155 loss: 1.57647 acc: 0.68327 | v_loss: 1.45336 v_acc: 0.69596 |  iteration: 18558 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1156 loss: 1.43630 acc: 0.70703 | v_loss: 1.28019 v_acc: 0.71224 |  iteration: 18559 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1157 loss: 1.43567 acc: 0.69759 | v_loss: 1.44638 v_acc: 0.71582 |  iteration: 18560 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1158 loss: 1.40427 acc: 0.70020 | v_loss: 1.65569 v_acc: 0.69401 |  iteration: 18561 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1159 loss: 1.36833 acc: 0.70964 | v_loss: 1.51280 v_acc: 0.69889 |  iteration: 18562 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1160 loss: 1.47395 acc: 0.70378 | v_loss: 1.29628 v_acc: 0.72363 |  iteration: 18563 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1161 loss: 1.35029 acc: 0.71387 | v_loss: 1.36296 v_acc: 0.70410 |  iteration: 18564 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1162 loss: 1.47286 acc: 0.68848 | v_loss: 1.21399 v_acc: 0.71973 |  iteration: 18565 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1163 loss: 1.48083 acc: 0.69466 | v_loss: 1.42178 v_acc: 0.70150 |  iteration: 18566 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1164 loss: 1.50282 acc: 0.69401 | v_loss: 1.35807 v_acc: 0.71029 |  iteration: 18567 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1165 loss: 1.59893 acc: 0.68783 | v_loss: 1.35616 v_acc: 0.73079 |  iteration: 18568 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1166 loss: 1.59539 acc: 0.68913 | v_loss: 1.36002 v_acc: 0.71777 |  iteration: 18569 teacher: 0 stage: sketch lr: 0.000324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1167 loss: 1.57963 acc: 0.68522 | v_loss: 1.36975 v_acc: 0.70410 |  iteration: 18570 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1168 loss: 1.32566 acc: 0.70573 | v_loss: 1.27890 v_acc: 0.72233 |  iteration: 18571 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1169 loss: 1.49738 acc: 0.68066 | v_loss: 1.30066 v_acc: 0.72135 |  iteration: 18572 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1170 loss: 1.48222 acc: 0.70768 | v_loss: 1.46326 v_acc: 0.69336 |  iteration: 18573 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1171 loss: 1.48032 acc: 0.69303 | v_loss: 1.34573 v_acc: 0.71387 |  iteration: 18574 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1172 loss: 1.38524 acc: 0.70345 | v_loss: 1.28330 v_acc: 0.71615 |  iteration: 18575 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1173 loss: 1.35661 acc: 0.70866 | v_loss: 1.27653 v_acc: 0.71615 |  iteration: 18576 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1174 loss: 1.41596 acc: 0.70280 | v_loss: 1.41029 v_acc: 0.70605 |  iteration: 18577 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1175 loss: 1.51045 acc: 0.69824 | v_loss: 1.31149 v_acc: 0.73112 |  iteration: 18578 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1176 loss: 1.46780 acc: 0.69401 | v_loss: 1.52936 v_acc: 0.71452 |  iteration: 18579 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1177 loss: 1.41736 acc: 0.69987 | v_loss: 1.29070 v_acc: 0.69759 |  iteration: 18580 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1178 loss: 1.38195 acc: 0.70443 | v_loss: 1.27457 v_acc: 0.70443 |  iteration: 18581 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1179 loss: 1.47919 acc: 0.69792 | v_loss: 1.44037 v_acc: 0.70312 |  iteration: 18582 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1180 loss: 1.43941 acc: 0.70052 | v_loss: 1.47597 v_acc: 0.70378 |  iteration: 18583 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1181 loss: 1.40433 acc: 0.70085 | v_loss: 1.52999 v_acc: 0.68978 |  iteration: 18584 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1182 loss: 1.44290 acc: 0.70280 | v_loss: 1.46892 v_acc: 0.70638 |  iteration: 18585 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1183 loss: 1.42454 acc: 0.69564 | v_loss: 1.42830 v_acc: 0.70410 |  iteration: 18586 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1184 loss: 1.50605 acc: 0.69336 | v_loss: 1.41878 v_acc: 0.70931 |  iteration: 18587 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1185 loss: 1.48010 acc: 0.70573 | v_loss: 1.39362 v_acc: 0.70703 |  iteration: 18588 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1186 loss: 1.42283 acc: 0.70508 | v_loss: 1.25202 v_acc: 0.71875 |  iteration: 18589 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1187 loss: 1.35805 acc: 0.71289 | v_loss: 1.31950 v_acc: 0.72331 |  iteration: 18590 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1188 loss: 1.56997 acc: 0.69303 | v_loss: 1.17180 v_acc: 0.71615 |  iteration: 18591 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1189 loss: 1.45951 acc: 0.69954 | v_loss: 1.34360 v_acc: 0.71126 |  iteration: 18592 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1190 loss: 1.35828 acc: 0.70898 | v_loss: 1.50621 v_acc: 0.69954 |  iteration: 18593 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1191 loss: 1.39628 acc: 0.70345 | v_loss: 1.31528 v_acc: 0.71484 |  iteration: 18594 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1192 loss: 1.47191 acc: 0.70150 | v_loss: 1.34365 v_acc: 0.70150 |  iteration: 18595 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1193 loss: 1.49109 acc: 0.69303 | v_loss: 1.25315 v_acc: 0.70638 |  iteration: 18596 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1194 loss: 1.39843 acc: 0.69889 | v_loss: 1.24775 v_acc: 0.70410 |  iteration: 18597 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1195 loss: 1.38434 acc: 0.71061 | v_loss: 1.23786 v_acc: 0.73926 |  iteration: 18598 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1196 loss: 1.48232 acc: 0.69792 | v_loss: 1.27318 v_acc: 0.71908 |  iteration: 18599 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1197 loss: 1.48380 acc: 0.69564 | v_loss: 1.36507 v_acc: 0.71452 |  iteration: 18600 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1198 loss: 1.38696 acc: 0.70150 | v_loss: 1.26373 v_acc: 0.72266 |  iteration: 18601 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1199 loss: 1.41690 acc: 0.70736 | v_loss: 1.30952 v_acc: 0.72331 |  iteration: 18602 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1200 loss: 1.51092 acc: 0.69824 | v_loss: 1.41350 v_acc: 0.71257 |  iteration: 18603 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1201 loss: 1.48094 acc: 0.70410 | v_loss: 1.38331 v_acc: 0.72331 |  iteration: 18604 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1202 loss: 1.52638 acc: 0.69531 | v_loss: 1.48751 v_acc: 0.69954 |  iteration: 18605 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1203 loss: 1.42525 acc: 0.71484 | v_loss: 1.40666 v_acc: 0.71615 |  iteration: 18606 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1204 loss: 1.39151 acc: 0.70671 | v_loss: 1.17254 v_acc: 0.74544 |  iteration: 18607 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1205 loss: 1.45020 acc: 0.71191 | v_loss: 1.27025 v_acc: 0.70931 |  iteration: 18608 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1206 loss: 1.48652 acc: 0.69987 | v_loss: 1.49608 v_acc: 0.70247 |  iteration: 18609 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1207 loss: 1.49897 acc: 0.70280 | v_loss: 1.23146 v_acc: 0.70866 |  iteration: 18610 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1208 loss: 1.32989 acc: 0.70801 | v_loss: 1.33861 v_acc: 0.71159 |  iteration: 18611 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1209 loss: 1.46336 acc: 0.69401 | v_loss: 1.37991 v_acc: 0.69336 |  iteration: 18612 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1210 loss: 1.48892 acc: 0.70410 | v_loss: 1.30086 v_acc: 0.71191 |  iteration: 18613 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1211 loss: 1.37246 acc: 0.70833 | v_loss: 1.36954 v_acc: 0.69629 |  iteration: 18614 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1212 loss: 1.44518 acc: 0.70443 | v_loss: 1.47832 v_acc: 0.71517 |  iteration: 18615 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1213 loss: 1.35392 acc: 0.70866 | v_loss: 1.32173 v_acc: 0.72689 |  iteration: 18616 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1214 loss: 1.41082 acc: 0.70052 | v_loss: 1.46349 v_acc: 0.70443 |  iteration: 18617 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1215 loss: 1.30121 acc: 0.71354 | v_loss: 1.36950 v_acc: 0.69922 |  iteration: 18618 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1216 loss: 1.44781 acc: 0.70605 | v_loss: 1.32908 v_acc: 0.70898 |  iteration: 18619 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1217 loss: 1.41395 acc: 0.70931 | v_loss: 1.55671 v_acc: 0.68815 |  iteration: 18620 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1218 loss: 1.37864 acc: 0.71322 | v_loss: 1.30681 v_acc: 0.72070 |  iteration: 18621 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1219 loss: 1.47891 acc: 0.69792 | v_loss: 1.58442 v_acc: 0.68490 |  iteration: 18622 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1220 loss: 1.46846 acc: 0.70378 | v_loss: 1.48050 v_acc: 0.69531 |  iteration: 18623 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1221 loss: 1.33898 acc: 0.70508 | v_loss: 1.54168 v_acc: 0.69238 |  iteration: 18624 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1222 loss: 1.41387 acc: 0.71191 | v_loss: 1.38856 v_acc: 0.70020 |  iteration: 18625 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1223 loss: 1.40295 acc: 0.70573 | v_loss: 1.32964 v_acc: 0.70312 |  iteration: 18626 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1224 loss: 1.42672 acc: 0.68978 | v_loss: 1.34044 v_acc: 0.70280 |  iteration: 18627 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1225 loss: 1.52610 acc: 0.70020 | v_loss: 1.34101 v_acc: 0.71810 |  iteration: 18628 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1226 loss: 1.36206 acc: 0.70117 | v_loss: 1.55686 v_acc: 0.69043 |  iteration: 18629 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1227 loss: 1.36126 acc: 0.70540 | v_loss: 1.39395 v_acc: 0.71061 |  iteration: 18630 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1228 loss: 1.42908 acc: 0.70085 | v_loss: 1.32998 v_acc: 0.71029 |  iteration: 18631 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1229 loss: 1.38625 acc: 0.70540 | v_loss: 1.38309 v_acc: 0.71452 |  iteration: 18632 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1230 loss: 1.43378 acc: 0.71712 | v_loss: 1.26166 v_acc: 0.70703 |  iteration: 18633 teacher: 1 stage: sketch lr: 0.000324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1231 loss: 1.42844 acc: 0.69922 | v_loss: 1.43689 v_acc: 0.69954 |  iteration: 18634 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1232 loss: 1.33062 acc: 0.71680 | v_loss: 1.42906 v_acc: 0.71289 |  iteration: 18635 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1233 loss: 1.40239 acc: 0.70768 | v_loss: 1.28215 v_acc: 0.71875 |  iteration: 18636 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1234 loss: 1.42153 acc: 0.70052 | v_loss: 1.25345 v_acc: 0.72754 |  iteration: 18637 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1235 loss: 1.38054 acc: 0.70182 | v_loss: 1.37843 v_acc: 0.71940 |  iteration: 18638 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1236 loss: 1.42447 acc: 0.69922 | v_loss: 1.42493 v_acc: 0.70345 |  iteration: 18639 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1237 loss: 1.48460 acc: 0.69401 | v_loss: 1.43036 v_acc: 0.70410 |  iteration: 18640 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1238 loss: 1.43413 acc: 0.69727 | v_loss: 1.21858 v_acc: 0.71712 |  iteration: 18641 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1239 loss: 1.40586 acc: 0.69889 | v_loss: 1.39987 v_acc: 0.73014 |  iteration: 18642 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 1240 loss: 1.50769 acc: 0.69401 | v_loss: 1.47826 v_acc: 0.69694 |  iteration: 18643 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1241 loss: 1.46259 acc: 0.70540 | v_loss: 1.43151 v_acc: 0.72168 |  iteration: 18644 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 1242 loss: 1.40383 acc: 0.70443 | v_loss: 1.24735 v_acc: 0.72233 |  iteration: 18645 teacher: 1 stage: sketch lr: 0.000324\n",
      "epoch 14 loss: 1.43363 acc: 0.70293 | v_loss: 1.36480 v_acc: 0.71077 \n"
     ]
    }
   ],
   "source": [
    "def process_raw_x(raw_x, n_past, n_inpaint, n_future):\n",
    "    raw_px, raw_rx, raw_len_x, raw_nrx, raw_gd = raw_x\n",
    "    past_px = raw_px[:,:n_past,:]\n",
    "    inpaint_px = raw_px[:,n_past:n_past + n_inpaint,:]\n",
    "    future_px = raw_px[:,n_future:,:]\n",
    "    past_rx = raw_rx[:,:n_past,:]\n",
    "    inpaint_rx = raw_rx[:,n_past:n_past + n_inpaint,:]\n",
    "    future_rx = raw_rx[:,n_future:,:]\n",
    "    past_len_x = raw_len_x[:,:n_past]\n",
    "    inpaint_len_x = raw_len_x[:,n_past:n_past + n_inpaint]\n",
    "    future_len_x = raw_len_x[:,n_future:]\n",
    "    past_nrx = raw_nrx[:,:n_past,:]\n",
    "    inpaint_nrx = raw_nrx[:,n_past:n_past + n_inpaint,:]\n",
    "    future_nrx = raw_nrx[:,n_future:,:]\n",
    "    past_gd = raw_gd[:,:n_past,:]\n",
    "    inpaint_gd = raw_gd[:,n_past:n_past + n_inpaint,:]\n",
    "    future_gd = raw_gd[:,n_future:,:]\n",
    "    re = [\n",
    "        past_px, past_rx, past_len_x, past_nrx, past_gd,\n",
    "        inpaint_px, inpaint_rx, inpaint_len_x, inpaint_nrx, inpaint_gd,\n",
    "        future_px, future_rx, future_len_x, future_nrx, future_gd,\n",
    "    ]\n",
    "    return re\n",
    "def get_acc(recon, gd):\n",
    "    recon = recon.cpu().detach().numpy()\n",
    "    gd = gd.cpu().detach().numpy()\n",
    "    return np.sum(recon == gd) / recon.size\n",
    "# stage-2 training\n",
    "model.set_stage(\"sketch\")\n",
    "device = torch.device(torch.cuda.current_device())\n",
    "losses = []\n",
    "step = 0\n",
    "n_past = 6\n",
    "n_future = 10\n",
    "n_inpaint = 4\n",
    "iteration = 0\n",
    "# save_period = 200\n",
    "print(vae_model.training)\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    print(\"epoch: %d\\n__________________________________________\" % (epoch), flush = True)\n",
    "    mean_loss = 0.0\n",
    "    mean_acc = 0.0\n",
    "    v_mean_loss = 0.0\n",
    "    v_mean_acc = 0.0\n",
    "    total = 0\n",
    "    for i,tr_data in enumerate(train_loader):\n",
    "        model.train()\n",
    "#         print(\"begin_time\", time.process_t\n",
    "\n",
    "\n",
    "\n",
    "ime())\n",
    "        j = i % len(validate_data)\n",
    "        raw_x = process_raw_x(tr_data, n_past, n_inpaint, n_future)\n",
    "        for k in range(len(raw_x)):\n",
    "            raw_x[k] = raw_x[k].to(device = device,non_blocking = True)\n",
    "        past_px, past_rx, past_len_x, past_nrx, past_gd, \\\n",
    "        inpaint_px, inpaint_rx, inpaint_len_x, inpaint_nrx, inpaint_gd,\\\n",
    "        future_px, future_rx, future_len_x, future_nrx, future_gd = raw_x\n",
    "        inpaint_gd_whole = inpaint_gd.contiguous().view(-1)\n",
    "        past_x = [past_px, past_rx, past_len_x, past_nrx, past_gd]\n",
    "        inpaint_x = [inpaint_px, inpaint_rx, inpaint_len_x, inpaint_nrx, inpaint_gd]\n",
    "        future_x = [future_px, future_rx, future_len_x, future_nrx, future_gd]\n",
    "        \n",
    "        # validate\n",
    "        v_raw_x = process_raw_x(validate_data[j], n_past, n_inpaint, n_future)\n",
    "        for k in range(len(v_raw_x)):\n",
    "            v_raw_x[k] = v_raw_x[k].to(device = device,non_blocking = True)\n",
    "        v_past_px, v_past_rx, v_past_len_x, v_past_nrx, v_past_gd, \\\n",
    "        v_inpaint_px, v_inpaint_rx, v_inpaint_len_x, v_inpaint_nrx, v_inpaint_gd,\\\n",
    "        v_future_px, v_future_rx, v_future_len_x, v_future_nrx, v_future_gd = v_raw_x\n",
    "        v_inpaint_gd_whole = v_inpaint_gd.contiguous().view(-1)\n",
    "        v_past_x = [v_past_px, v_past_rx, v_past_len_x, v_past_nrx, v_past_gd]\n",
    "        v_inpaint_x = [v_inpaint_px, v_inpaint_rx, v_inpaint_len_x, v_inpaint_nrx, v_inpaint_gd]\n",
    "        v_future_x = [v_future_px, v_future_rx, v_future_len_x, v_future_nrx, v_future_gd]\n",
    "        \n",
    "        scheduler.optimizer.zero_grad()\n",
    "        \n",
    "        recon_x, iteration, use_teacher, stage = model(past_x, future_x, inpaint_x)\n",
    "        \n",
    "        loss = F.cross_entropy(recon_x.view(-1, recon_x.size(-1)), inpaint_gd_whole, reduction = \"mean\") \n",
    "        acc = get_acc(recon_x.view(-1, recon_x.size(-1)).argmax(-1), inpaint_gd_whole)\n",
    "        loss.backward()\n",
    "        scheduler.step()    \n",
    "        total += 1\n",
    "        mean_loss += loss.item()\n",
    "        mean_acc += acc\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            v_recon_x, _,_,_ = model(v_past_x, v_future_x, v_inpaint_x)\n",
    "            v_loss = F.cross_entropy(v_recon_x.view(-1, v_recon_x.size(-1)), v_inpaint_gd_whole, reduction = \"mean\") \n",
    "            v_acc = get_acc(v_recon_x.view(-1, v_recon_x.size(-1)).argmax(-1), v_inpaint_gd_whole)\n",
    "            v_mean_loss += v_loss.item()\n",
    "            v_mean_acc += v_acc\n",
    "        print(\"batch %d loss: %.5f acc: %.5f | v_loss: %.5f v_acc: %.5f |  iteration: %d teacher: %d stage: %s lr: %f\" \\\n",
    "              % (i,loss.item(), acc, v_loss.item(), v_acc, iteration, use_teacher, stage, scheduler.rate()),flush = True)\n",
    "    mean_loss /= total\n",
    "    mean_acc /= total\n",
    "    v_mean_loss /= total\n",
    "    v_mean_acc /= total\n",
    "    print(\"epoch %d loss: %.5f acc: %.5f | v_loss: %.5f v_acc: %.5f \"  % (epoch,mean_loss, mean_acc, v_mean_loss, v_mean_acc),flush = True)\n",
    "    losses.append([mean_loss, v_mean_loss])\n",
    "    if (epoch + 1) % save_period == 0:\n",
    "        filename = \"sketchnet-\" + 'loss_' + str(v_mean_loss) + \"_acc_\" + str(v_mean_acc) + \"_epoch_\" +  str(epoch+1) + '_it_' + str(iteration) + \".pt\"\n",
    "        torch.save(model.cpu().state_dict(),os.path.join(save_path,filename))\n",
    "        model.cuda()\n",
    "    np.save(os.path.join(s_dir, \"sketchnet_log.npy\"),losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
